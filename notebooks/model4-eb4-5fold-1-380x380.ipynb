{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image\n",
    "from utils import bn_update, moving_average, copy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations as albu\n",
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in train_loader:\n",
    "#    print(x)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNet B0-B8.\n",
    "    Args:\n",
    "        cfg (CfgNode): configs\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        model_name = cfg.MODEL_NAME\n",
    "        pretrained = cfg.PRETRAINED\n",
    "        input_channels = cfg.IN_CHANNELS\n",
    "        pool_type = cfg.POOL_TYPE\n",
    "        drop_connect_rate = cfg.DROP_CONNECT\n",
    "        self.drop_rate = cfg.DROPOUT\n",
    "        cls_head = cfg.CLS_HEAD\n",
    "        num_total_classes = cfg.NUM_GRAPHEME_CLASSES + cfg.NUM_VOWEL_CLASSES + cfg.NUM_CONSONANT_CLASSES \\\n",
    "            + cfg.NUM_WORD_CLASSES\n",
    "\n",
    "        backbone = timm.create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=input_channels,\n",
    "            drop_connect_rate=drop_connect_rate,\n",
    "        )\n",
    "        self.conv_stem = backbone.conv_stem\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.act1 = backbone.act1\n",
    "        ### Original blocks ###\n",
    "        for i in range(len((backbone.blocks))):\n",
    "            setattr(self, \"block{}\".format(str(i)), backbone.blocks[i])\n",
    "        self.conv_head = backbone.conv_head\n",
    "        self.bn2 = backbone.bn2\n",
    "        self.act2 = backbone.act2\n",
    "        self.aux_block5 = backbone.blocks[5]\n",
    "        self.aux_num_features = self.block5[-1].bn3.num_features\n",
    "        self.aux_head4 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act4 = Swish()\n",
    "        self.aux_head5 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act5 = Swish()\n",
    "        self.global_pool = SelectAdaptivePool2d(pool_type=pool_type)\n",
    "        self.num_features = backbone.num_features * self.global_pool.feat_mult()\n",
    "        assert cls_head == 'linear'\n",
    "        if cls_head == \"linear\":\n",
    "            ### Baseline head ###\n",
    "            self.fc = nn.Linear(self.num_features, num_total_classes)            \n",
    "            self.aux_fc1 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            self.aux_fc2 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            \n",
    "            for fc in [self.fc, self.aux_fc1, self.aux_fc2]:\n",
    "                nn.init.zeros_(fc.bias.data)\n",
    "        elif cls_head == \"norm_softmax\":\n",
    "            ### NormSoftmax ###\n",
    "            self.grapheme_fc = NormSoftmax(self.num_features, num_grapheme_classes)\n",
    "            self.consonant_fc = NormSoftmax(self.num_features, num_consonant_classes)\n",
    "            self.vowel_fc = NormSoftmax(self.num_features, num_vowel_classes)\n",
    "        # Replace with Mish activation\n",
    "        if cfg.MODEL_ACTIVATION == \"mish\":\n",
    "            convert_swish_to_mish(self)\n",
    "        del backbone\n",
    "\n",
    "    def _features(self, x):\n",
    "        x = self.conv_stem(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x); b4 = x\n",
    "        x = self.block5(x); b4 = self.aux_block5(b4); b5 = x\n",
    "        x = self.block6(x)\n",
    "        x = self.conv_head(x); b4 = self.aux_head4(b4); b5 = self.aux_head5(b5)\n",
    "        x = self.bn2(x); b4 = self.bn4(b4); b5 = self.bn5(b5)\n",
    "        x = self.act2(x); b4 = self.act4(b4); b5 = self.act5(b5)\n",
    "        return b4, b5, x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(380, 380), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "\n",
    "        # _, _, x = self._features(x)\n",
    "        b4, b5, x = self._features(x)\n",
    "        x = self.global_pool(x); b4 = self.global_pool(b4); b5 = self.global_pool(b5)\n",
    "        x = torch.flatten(x, 1); b4 = torch.flatten(b4, 1); b5 = torch.flatten(b5, 1)\n",
    "        if self.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.drop_rate, training=self.training)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        aux_logits1 = self.aux_fc1(b4)\n",
    "        aux_logits2 = self.aux_fc2(b5)\n",
    "        \n",
    "        return logits, aux_logits1, aux_logits2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model4-ckps'\n",
    "def create_model(cfg):\n",
    "    model = BengaliNet(cfg)\n",
    "    model_file = os.path.join(MODEL_DIR, cfg.MODEL_NAME, cfg.CKP_NAME)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, preds3, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2) == len(preds3)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    recall_word = sklearn.metrics.recall_score(preds3, y[:, 3], average='macro')\n",
    "    \n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    metrics['recall_word'] = round(recall_word, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    metrics['acc_word'] = round((preds3 == y[:, 3]).sum() / len(y), 6)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    loss3 = F.cross_entropy(outputs[3], y_true[:, 3], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 + loss3 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2, loss3 = 0., 0., 0., 0.\n",
    "    preds0, preds1, preds2, preds3 = [], [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs, _, _ = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            preds3.append(torch.max(outputs[3], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            loss3 += F.cross_entropy(outputs[3], y[:, 3], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    preds3 = torch.cat(preds3, 0).cpu().numpy()\n",
    "    \n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, preds3, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    metrics['loss_word'] = round(loss3 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox_new(size, lam):\n",
    "    H = size[2]\n",
    "    W = size[3]\n",
    "\n",
    "    x_margin_rate = 0.2\n",
    "\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * (1-x_margin_rate*2) * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "    \n",
    "    min_x_center = np.int(W * x_margin_rate + cut_w / 2)\n",
    "    max_x_center = np.int(W * (1-x_margin_rate) - cut_w / 2)\n",
    "    #print(min_x_center, max_x_center, lam, cut_w)\n",
    "    min_y_center = cut_h // 2\n",
    "    max_y_center = H - cut_h // 2\n",
    "    if max_y_center == min_y_center:\n",
    "        max_y_center += 1\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(min_x_center, max_x_center)\n",
    "    cy = np.random.randint(min_y_center, max_y_center)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    \n",
    "    #print(bbx1, bbx2, bby1, bby2)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5696966192129116"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "        img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "        batch_size = img.size(0)\n",
    "        r = np.random.rand()\n",
    "\n",
    "        if r < 0.3:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            #img[:, :, bby1:bby2, bbx1:bbx2] = img[rand_index, :, bby1:bby2, bbx1:bbx2] #for new cutmix\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "            loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r > 0.7:\n",
    "            img = grid(img)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, targets)\n",
    "            loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        else:\n",
    "            orig_img, targets = mixup(orig_img, targets)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "            loss_primary = mixup_criterion(outputs, targets)\n",
    "            loss_aux1 = mixup_criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = mixup_criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "            #loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        lr_scheduler(optimizer, batch_idx, epoch)\n",
    "        optimizer.step()            \n",
    "        \n",
    "        current_lr = get_lrs(optimizer)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "            epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "            loss.item(), train_loss/(batch_idx+1)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = 0.\n",
    "\n",
    "def validate_and_save(model, model_file, val_loader, save=False):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        best_metrics = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "def train(args):\n",
    "    model, model_file = create_model(cfg)\n",
    "    model = model.cuda()\n",
    "\n",
    "    swa_model, _ = create_model(cfg)\n",
    "    swa_model = swa_model.cuda()\n",
    "    swa_model_file = model_file + '_swa'\n",
    "\n",
    "    optimizer = make_optimizer(model)\n",
    "    lr_scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    [model, swa_model], optimizer = amp.initialize([model, swa_model], optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        swa_model = nn.DataParallel(swa_model)\n",
    "    \n",
    "    validate_and_save(model, model_file, val_loader, save=False)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "        for epoch in range(args.num_epochs):\n",
    "            grid.set_prob(epoch, args.st_epochs)\n",
    "            train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\n",
    "            validate_and_save(model, model_file, val_loader, save=True)\n",
    "            \n",
    "            if (epoch+1) == args.swa_start and cycle == 1:\n",
    "                copy_model(swa_model, model)\n",
    "                swa_n = 0\n",
    "            if (epoch+1) >= args.swa_start and (epoch+1) % args.swa_freq == 0:\n",
    "                print('SWA>>>:')\n",
    "                moving_average(swa_model, model, 1.0 / (swa_n + 1))\n",
    "                swa_n += 1\n",
    "                bn_update(train_loader, swa_model)\n",
    "                validate_and_save(swa_model, swa_model_file, val_loader, save=True)\n",
    "\n",
    "        # reset scheduler at each cycle\n",
    "        lr_scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Namespace()\n",
    "cfg.MODEL_NAME = 'tf_efficientnet_b4'\n",
    "cfg.PRETRAINED = True\n",
    "cfg.IN_CHANNELS = 1\n",
    "cfg.POOL_TYPE = 'avg'\n",
    "cfg.CLS_HEAD = 'linear'\n",
    "cfg.MODEL_ACTIVATION = 'swish'\n",
    "cfg.DROP_CONNECT = 0.2\n",
    "cfg.DROPOUT= 0.\n",
    "cfg.NUM_WORD_CLASSES = 1295\n",
    "cfg.NUM_GRAPHEME_CLASSES = 168\n",
    "cfg.NUM_VOWEL_CLASSES = 11\n",
    "cfg.NUM_CONSONANT_CLASSES = 7\n",
    "cfg.CKP_NAME = 'model4_eb4_fold1_380.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, model_file = create_model(cfg)\n",
    "#model(torch.randn(2,1,137,236))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "\n",
    "args.base_lr = 4e-4\n",
    "args.num_epochs = 40\n",
    "args.warmup_epochs = 4\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 128\n",
    "args.val_batch_size = 512\n",
    "args.st_epochs = 5\n",
    "\n",
    "args.swa_start = 1000\n",
    "args.swa_freq = 2\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160635, 6) (40205, 6)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth, exist: True\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth...\n",
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth, exist: True\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth...\n",
      "\n",
      "val: {'recall': 0.989807, 'recall_grapheme': 0.985939, 'recall_vowel': 0.99416, 'recall_consonant': 0.993188, 'recall_word': 0.984312, 'acc_grapheme': 0.985549, 'acc_vowel': 0.99413, 'acc_consonant': 0.994628, 'acc_word': 0.984131, 'loss_grapheme': 0.18204, 'loss_vowel': 0.100559, 'loss_consonant': 0.074103, 'loss_word': 0.174815}\n",
      "CYCLE: 1\n",
      "    0 | 0.000100 | 160512/160635 | 18.0901 | 7.6703 ||\n",
      "val: {'recall': 0.993001, 'recall_grapheme': 0.990054, 'recall_vowel': 0.995737, 'recall_consonant': 0.996159, 'recall_word': 0.988352, 'acc_grapheme': 0.989156, 'acc_vowel': 0.995647, 'acc_consonant': 0.996617, 'acc_word': 0.98826, 'loss_grapheme': 0.100453, 'loss_vowel': 0.055413, 'loss_consonant': 0.040711, 'loss_word': 0.096096}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "    1 | 0.000199 | 160512/160635 | 3.8893 | 7.3996 ||\n",
      "val: {'recall': 0.994689, 'recall_grapheme': 0.992453, 'recall_vowel': 0.996848, 'recall_consonant': 0.997003, 'recall_word': 0.992153, 'acc_grapheme': 0.992886, 'acc_vowel': 0.996717, 'acc_consonant': 0.997513, 'acc_word': 0.99219, 'loss_grapheme': 0.086837, 'loss_vowel': 0.050121, 'loss_consonant': 0.037685, 'loss_word': 0.070708}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "    2 | 0.000296 | 160512/160635 | 2.1437 | 7.2389 ||\n",
      "val: {'recall': 0.993454, 'recall_grapheme': 0.990919, 'recall_vowel': 0.996053, 'recall_consonant': 0.995925, 'recall_word': 0.991095, 'acc_grapheme': 0.991916, 'acc_vowel': 0.995971, 'acc_consonant': 0.99714, 'acc_word': 0.991145, 'loss_grapheme': 0.09933, 'loss_vowel': 0.064802, 'loss_consonant': 0.040642, 'loss_word': 0.087517}\n",
      "    3 | 0.000390 | 160512/160635 | 1.3150 | 7.1458 ||\n",
      "val: {'recall': 0.994554, 'recall_grapheme': 0.992808, 'recall_vowel': 0.996188, 'recall_consonant': 0.996413, 'recall_word': 0.991604, 'acc_grapheme': 0.992488, 'acc_vowel': 0.996269, 'acc_consonant': 0.997264, 'acc_word': 0.991369, 'loss_grapheme': 0.047524, 'loss_vowel': 0.029116, 'loss_consonant': 0.019659, 'loss_word': 0.046031}\n",
      "    4 | 0.000385 | 160512/160635 | 6.9130 | 7.2978 |||\n",
      "val: {'recall': 0.994301, 'recall_grapheme': 0.992214, 'recall_vowel': 0.996617, 'recall_consonant': 0.99616, 'recall_word': 0.991392, 'acc_grapheme': 0.991916, 'acc_vowel': 0.996369, 'acc_consonant': 0.997239, 'acc_word': 0.991195, 'loss_grapheme': 0.052874, 'loss_vowel': 0.02922, 'loss_consonant': 0.02353, 'loss_word': 0.048814}\n",
      "    5 | 0.000378 | 160512/160635 | 11.9794 | 7.0813 |\n",
      "val: {'recall': 0.993793, 'recall_grapheme': 0.992175, 'recall_vowel': 0.995593, 'recall_consonant': 0.995228, 'recall_word': 0.992049, 'acc_grapheme': 0.992439, 'acc_vowel': 0.996269, 'acc_consonant': 0.997488, 'acc_word': 0.991867, 'loss_grapheme': 0.042015, 'loss_vowel': 0.023922, 'loss_consonant': 0.017168, 'loss_word': 0.03969}\n",
      "    6 | 0.000371 | 160512/160635 | 4.1162 | 6.8983 |||\n",
      "val: {'recall': 0.994541, 'recall_grapheme': 0.992879, 'recall_vowel': 0.995503, 'recall_consonant': 0.996904, 'recall_word': 0.992261, 'acc_grapheme': 0.993011, 'acc_vowel': 0.996344, 'acc_consonant': 0.997339, 'acc_word': 0.99219, 'loss_grapheme': 0.053395, 'loss_vowel': 0.033787, 'loss_consonant': 0.023965, 'loss_word': 0.047946}\n",
      "    7 | 0.000362 | 160512/160635 | 1.3308 | 6.9717 |||\n",
      "val: {'recall': 0.994615, 'recall_grapheme': 0.993967, 'recall_vowel': 0.99611, 'recall_consonant': 0.994416, 'recall_word': 0.993219, 'acc_grapheme': 0.994155, 'acc_vowel': 0.996717, 'acc_consonant': 0.997836, 'acc_word': 0.993036, 'loss_grapheme': 0.043278, 'loss_vowel': 0.024963, 'loss_consonant': 0.0179, 'loss_word': 0.03953}\n",
      "    8 | 0.000352 | 160512/160635 | 3.8705 | 6.7491 ||\n",
      "val: {'recall': 0.994676, 'recall_grapheme': 0.992896, 'recall_vowel': 0.996888, 'recall_consonant': 0.996025, 'recall_word': 0.993574, 'acc_grapheme': 0.993583, 'acc_vowel': 0.997015, 'acc_consonant': 0.99811, 'acc_word': 0.993434, 'loss_grapheme': 0.031614, 'loss_vowel': 0.016407, 'loss_consonant': 0.012956, 'loss_word': 0.030985}\n",
      "    9 | 0.000341 | 160512/160635 | 4.5536 | 7.0750 |||\n",
      "val: {'recall': 0.995171, 'recall_grapheme': 0.993648, 'recall_vowel': 0.99656, 'recall_consonant': 0.996826, 'recall_word': 0.992823, 'acc_grapheme': 0.993434, 'acc_vowel': 0.996916, 'acc_consonant': 0.997886, 'acc_word': 0.992687, 'loss_grapheme': 0.036298, 'loss_vowel': 0.020654, 'loss_consonant': 0.01445, 'loss_word': 0.034937}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   10 | 0.000330 | 160512/160635 | 0.5296 | 6.5995 ||\n",
      "val: {'recall': 0.99543, 'recall_grapheme': 0.994001, 'recall_vowel': 0.996815, 'recall_consonant': 0.996903, 'recall_word': 0.993839, 'acc_grapheme': 0.994329, 'acc_vowel': 0.997015, 'acc_consonant': 0.997911, 'acc_word': 0.993707, 'loss_grapheme': 0.027412, 'loss_vowel': 0.016515, 'loss_consonant': 0.011578, 'loss_word': 0.02867}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   11 | 0.000318 | 160512/160635 | 14.3120 | 6.6529 |\n",
      "val: {'recall': 0.995052, 'recall_grapheme': 0.99383, 'recall_vowel': 0.996151, 'recall_consonant': 0.996399, 'recall_word': 0.99312, 'acc_grapheme': 0.993906, 'acc_vowel': 0.996816, 'acc_consonant': 0.998159, 'acc_word': 0.993011, 'loss_grapheme': 0.028824, 'loss_vowel': 0.017249, 'loss_consonant': 0.010648, 'loss_word': 0.028426}\n",
      "   12 | 0.000305 | 160512/160635 | 3.4758 | 6.3812 |||\n",
      "val: {'recall': 0.995799, 'recall_grapheme': 0.994495, 'recall_vowel': 0.996966, 'recall_consonant': 0.997242, 'recall_word': 0.993664, 'acc_grapheme': 0.994578, 'acc_vowel': 0.997165, 'acc_consonant': 0.998184, 'acc_word': 0.993533, 'loss_grapheme': 0.024258, 'loss_vowel': 0.014236, 'loss_consonant': 0.007869, 'loss_word': 0.027824}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   13 | 0.000291 | 160512/160635 | 1.0145 | 6.4917 |||\n",
      "val: {'recall': 0.996178, 'recall_grapheme': 0.994982, 'recall_vowel': 0.997185, 'recall_consonant': 0.997565, 'recall_word': 0.994419, 'acc_grapheme': 0.994827, 'acc_vowel': 0.997612, 'acc_consonant': 0.998284, 'acc_word': 0.994304, 'loss_grapheme': 0.030855, 'loss_vowel': 0.017663, 'loss_consonant': 0.012179, 'loss_word': 0.027908}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   14 | 0.000277 | 160512/160635 | 0.6483 | 6.2129 ||\n",
      "val: {'recall': 0.996053, 'recall_grapheme': 0.994358, 'recall_vowel': 0.997656, 'recall_consonant': 0.997837, 'recall_word': 0.994408, 'acc_grapheme': 0.995249, 'acc_vowel': 0.997612, 'acc_consonant': 0.998508, 'acc_word': 0.994329, 'loss_grapheme': 0.021599, 'loss_vowel': 0.01269, 'loss_consonant': 0.008315, 'loss_word': 0.023194}\n",
      "   15 | 0.000262 | 160512/160635 | 0.5876 | 6.4056 |||\n",
      "val: {'recall': 0.995643, 'recall_grapheme': 0.99422, 'recall_vowel': 0.996473, 'recall_consonant': 0.99766, 'recall_word': 0.994115, 'acc_grapheme': 0.994578, 'acc_vowel': 0.997314, 'acc_consonant': 0.998408, 'acc_word': 0.99413, 'loss_grapheme': 0.02749, 'loss_vowel': 0.015825, 'loss_consonant': 0.010466, 'loss_word': 0.025695}\n",
      "   16 | 0.000247 | 160512/160635 | 0.5176 | 6.3585 ||\n",
      "val: {'recall': 0.996546, 'recall_grapheme': 0.995661, 'recall_vowel': 0.997318, 'recall_consonant': 0.997543, 'recall_word': 0.994957, 'acc_grapheme': 0.995772, 'acc_vowel': 0.997687, 'acc_consonant': 0.998458, 'acc_word': 0.995025, 'loss_grapheme': 0.019287, 'loss_vowel': 0.011361, 'loss_consonant': 0.007588, 'loss_word': 0.021688}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   17 | 0.000231 | 160512/160635 | 0.3857 | 6.4881 |||\n",
      "val: {'recall': 0.996152, 'recall_grapheme': 0.994626, 'recall_vowel': 0.99788, 'recall_consonant': 0.997478, 'recall_word': 0.994896, 'acc_grapheme': 0.995025, 'acc_vowel': 0.998035, 'acc_consonant': 0.998433, 'acc_word': 0.994901, 'loss_grapheme': 0.023501, 'loss_vowel': 0.012335, 'loss_consonant': 0.009223, 'loss_word': 0.023474}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 0.000216 | 160512/160635 | 6.9434 | 6.3158 ||\n",
      "val: {'recall': 0.995724, 'recall_grapheme': 0.99449, 'recall_vowel': 0.997135, 'recall_consonant': 0.99678, 'recall_word': 0.994528, 'acc_grapheme': 0.99505, 'acc_vowel': 0.997737, 'acc_consonant': 0.998358, 'acc_word': 0.994453, 'loss_grapheme': 0.021471, 'loss_vowel': 0.011642, 'loss_consonant': 0.006891, 'loss_word': 0.024257}\n",
      "   19 | 0.000200 | 160512/160635 | 8.3293 | 6.0808 |||\n",
      "val: {'recall': 0.995915, 'recall_grapheme': 0.994458, 'recall_vowel': 0.997321, 'recall_consonant': 0.997425, 'recall_word': 0.993835, 'acc_grapheme': 0.994628, 'acc_vowel': 0.997488, 'acc_consonant': 0.998309, 'acc_word': 0.993856, 'loss_grapheme': 0.025522, 'loss_vowel': 0.013144, 'loss_consonant': 0.007459, 'loss_word': 0.026758}\n",
      "   20 | 0.000184 | 160512/160635 | 6.2588 | 5.9597 |||\n",
      "val: {'recall': 0.996072, 'recall_grapheme': 0.994761, 'recall_vowel': 0.997538, 'recall_consonant': 0.997228, 'recall_word': 0.994618, 'acc_grapheme': 0.9952, 'acc_vowel': 0.997861, 'acc_consonant': 0.998508, 'acc_word': 0.994677, 'loss_grapheme': 0.025375, 'loss_vowel': 0.013979, 'loss_consonant': 0.008881, 'loss_word': 0.024677}\n",
      "   21 | 0.000169 | 160512/160635 | 0.8327 | 5.9950 ||\n",
      "val: {'recall': 0.996589, 'recall_grapheme': 0.995473, 'recall_vowel': 0.997707, 'recall_consonant': 0.997703, 'recall_word': 0.995149, 'acc_grapheme': 0.995672, 'acc_vowel': 0.997936, 'acc_consonant': 0.998831, 'acc_word': 0.995125, 'loss_grapheme': 0.019602, 'loss_vowel': 0.01181, 'loss_consonant': 0.006308, 'loss_word': 0.02173}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   22 | 0.000153 | 160512/160635 | 7.3399 | 6.2508 |||\n",
      "val: {'recall': 0.996546, 'recall_grapheme': 0.995528, 'recall_vowel': 0.997262, 'recall_consonant': 0.997866, 'recall_word': 0.995073, 'acc_grapheme': 0.995871, 'acc_vowel': 0.997687, 'acc_consonant': 0.998831, 'acc_word': 0.9951, 'loss_grapheme': 0.020407, 'loss_vowel': 0.012618, 'loss_consonant': 0.006441, 'loss_word': 0.023492}\n",
      "   23 | 0.000138 | 160512/160635 | 0.5261 | 5.8951 ||\n",
      "val: {'recall': 0.996183, 'recall_grapheme': 0.994761, 'recall_vowel': 0.997845, 'recall_consonant': 0.997365, 'recall_word': 0.994927, 'acc_grapheme': 0.995374, 'acc_vowel': 0.99801, 'acc_consonant': 0.998756, 'acc_word': 0.994926, 'loss_grapheme': 0.020337, 'loss_vowel': 0.010853, 'loss_consonant': 0.006234, 'loss_word': 0.021809}\n",
      "   24 | 0.000123 | 160512/160635 | 0.8925 | 5.6660 ||\n",
      "val: {'recall': 0.996142, 'recall_grapheme': 0.994874, 'recall_vowel': 0.997165, 'recall_consonant': 0.997655, 'recall_word': 0.994592, 'acc_grapheme': 0.995274, 'acc_vowel': 0.997811, 'acc_consonant': 0.998508, 'acc_word': 0.994603, 'loss_grapheme': 0.020923, 'loss_vowel': 0.01144, 'loss_consonant': 0.007263, 'loss_word': 0.022436}\n",
      "   25 | 0.000109 | 160512/160635 | 13.2653 | 5.8692 |\n",
      "val: {'recall': 0.996826, 'recall_grapheme': 0.995584, 'recall_vowel': 0.997708, 'recall_consonant': 0.998428, 'recall_word': 0.995467, 'acc_grapheme': 0.996095, 'acc_vowel': 0.998159, 'acc_consonant': 0.998831, 'acc_word': 0.995473, 'loss_grapheme': 0.018278, 'loss_vowel': 0.010137, 'loss_consonant': 0.005772, 'loss_word': 0.020218}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   26 | 0.000096 | 160512/160635 | 1.7734 | 5.7250 ||\n",
      "val: {'recall': 0.997193, 'recall_grapheme': 0.99591, 'recall_vowel': 0.998482, 'recall_consonant': 0.99847, 'recall_word': 0.995626, 'acc_grapheme': 0.996294, 'acc_vowel': 0.998408, 'acc_consonant': 0.998906, 'acc_word': 0.995697, 'loss_grapheme': 0.017795, 'loss_vowel': 0.009261, 'loss_consonant': 0.005734, 'loss_word': 0.020048}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   27 | 0.000082 | 160512/160635 | 5.4402 | 5.8033 ||\n",
      "val: {'recall': 0.996878, 'recall_grapheme': 0.995595, 'recall_vowel': 0.997859, 'recall_consonant': 0.998462, 'recall_word': 0.99535, 'acc_grapheme': 0.99607, 'acc_vowel': 0.998135, 'acc_consonant': 0.998856, 'acc_word': 0.995448, 'loss_grapheme': 0.017812, 'loss_vowel': 0.010427, 'loss_consonant': 0.005322, 'loss_word': 0.021241}\n",
      "   28 | 0.000070 | 160512/160635 | 5.9177 | 6.1216 |||\n",
      "val: {'recall': 0.996322, 'recall_grapheme': 0.994811, 'recall_vowel': 0.997926, 'recall_consonant': 0.997741, 'recall_word': 0.995096, 'acc_grapheme': 0.995548, 'acc_vowel': 0.998035, 'acc_consonant': 0.998682, 'acc_word': 0.9951, 'loss_grapheme': 0.019659, 'loss_vowel': 0.011743, 'loss_consonant': 0.005919, 'loss_word': 0.022595}\n",
      "   29 | 0.000059 | 160512/160635 | 0.3274 | 5.9230 |||\n",
      "val: {'recall': 0.996989, 'recall_grapheme': 0.99587, 'recall_vowel': 0.998145, 'recall_consonant': 0.998071, 'recall_word': 0.995552, 'acc_grapheme': 0.996195, 'acc_vowel': 0.998309, 'acc_consonant': 0.998856, 'acc_word': 0.995598, 'loss_grapheme': 0.017187, 'loss_vowel': 0.009717, 'loss_consonant': 0.005283, 'loss_word': 0.019591}\n",
      "   30 | 0.000048 | 160512/160635 | 6.6969 | 5.4658 |||\n",
      "val: {'recall': 0.997103, 'recall_grapheme': 0.996208, 'recall_vowel': 0.997992, 'recall_consonant': 0.998004, 'recall_word': 0.99572, 'acc_grapheme': 0.996468, 'acc_vowel': 0.998209, 'acc_consonant': 0.998856, 'acc_word': 0.995772, 'loss_grapheme': 0.016334, 'loss_vowel': 0.010243, 'loss_consonant': 0.005208, 'loss_word': 0.019153}\n",
      "   31 | 0.000038 | 160512/160635 | 13.6319 | 5.8085 ||\n",
      "val: {'recall': 0.996777, 'recall_grapheme': 0.995817, 'recall_vowel': 0.997627, 'recall_consonant': 0.997847, 'recall_word': 0.995284, 'acc_grapheme': 0.99602, 'acc_vowel': 0.99801, 'acc_consonant': 0.998732, 'acc_word': 0.995324, 'loss_grapheme': 0.019681, 'loss_vowel': 0.011996, 'loss_consonant': 0.006151, 'loss_word': 0.022047}\n",
      "   32 | 0.000029 | 160512/160635 | 3.6264 | 5.5435 |||\n",
      "val: {'recall': 0.997105, 'recall_grapheme': 0.996078, 'recall_vowel': 0.998179, 'recall_consonant': 0.998083, 'recall_word': 0.995659, 'acc_grapheme': 0.996468, 'acc_vowel': 0.998383, 'acc_consonant': 0.998955, 'acc_word': 0.995672, 'loss_grapheme': 0.016803, 'loss_vowel': 0.009176, 'loss_consonant': 0.005224, 'loss_word': 0.019569}\n",
      "   33 | 0.000022 | 160512/160635 | 3.4641 | 5.7279 |||\n",
      "val: {'recall': 0.997436, 'recall_grapheme': 0.996586, 'recall_vowel': 0.998322, 'recall_consonant': 0.998251, 'recall_word': 0.996033, 'acc_grapheme': 0.996617, 'acc_vowel': 0.998508, 'acc_consonant': 0.99908, 'acc_word': 0.996045, 'loss_grapheme': 0.017207, 'loss_vowel': 0.009145, 'loss_consonant': 0.00566, 'loss_word': 0.018626}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   34 | 0.000015 | 160512/160635 | 0.5798 | 5.6908 ||\n",
      "val: {'recall': 0.997023, 'recall_grapheme': 0.996091, 'recall_vowel': 0.997939, 'recall_consonant': 0.997973, 'recall_word': 0.995585, 'acc_grapheme': 0.996369, 'acc_vowel': 0.998209, 'acc_consonant': 0.99893, 'acc_word': 0.995622, 'loss_grapheme': 0.017083, 'loss_vowel': 0.009635, 'loss_consonant': 0.004963, 'loss_word': 0.019475}\n",
      "   35 | 0.000010 | 160512/160635 | 0.4900 | 5.4833 |||\n",
      "val: {'recall': 0.997122, 'recall_grapheme': 0.996136, 'recall_vowel': 0.998096, 'recall_consonant': 0.99812, 'recall_word': 0.995956, 'acc_grapheme': 0.996518, 'acc_vowel': 0.998358, 'acc_consonant': 0.999055, 'acc_word': 0.995996, 'loss_grapheme': 0.015771, 'loss_vowel': 0.008321, 'loss_consonant': 0.004877, 'loss_word': 0.01787}\n",
      "   36 | 0.000006 | 160512/160635 | 15.1934 | 5.6793 |\n",
      "val: {'recall': 0.996932, 'recall_grapheme': 0.995958, 'recall_vowel': 0.997859, 'recall_consonant': 0.997954, 'recall_word': 0.995676, 'acc_grapheme': 0.996344, 'acc_vowel': 0.998085, 'acc_consonant': 0.998881, 'acc_word': 0.995672, 'loss_grapheme': 0.018677, 'loss_vowel': 0.010483, 'loss_consonant': 0.005369, 'loss_word': 0.020676}\n",
      "   37 | 0.000002 | 160512/160635 | 0.3775 | 5.4224 ||\n",
      "val: {'recall': 0.997306, 'recall_grapheme': 0.9962, 'recall_vowel': 0.998189, 'recall_consonant': 0.998633, 'recall_word': 0.995911, 'acc_grapheme': 0.996468, 'acc_vowel': 0.998408, 'acc_consonant': 0.999055, 'acc_word': 0.995946, 'loss_grapheme': 0.016554, 'loss_vowel': 0.008925, 'loss_consonant': 0.004817, 'loss_word': 0.01909}\n",
      "   38 | 0.000001 | 160512/160635 | 6.7210 | 5.5749 |||\n",
      "val: {'recall': 0.996694, 'recall_grapheme': 0.995562, 'recall_vowel': 0.997798, 'recall_consonant': 0.997852, 'recall_word': 0.995146, 'acc_grapheme': 0.995946, 'acc_vowel': 0.998135, 'acc_consonant': 0.998707, 'acc_word': 0.995224, 'loss_grapheme': 0.019342, 'loss_vowel': 0.011278, 'loss_consonant': 0.005667, 'loss_word': 0.022314}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 0.000000 | 160512/160635 | 7.8842 | 5.5941 |||\n",
      "val: {'recall': 0.996998, 'recall_grapheme': 0.996024, 'recall_vowel': 0.997894, 'recall_consonant': 0.998048, 'recall_word': 0.995507, 'acc_grapheme': 0.996219, 'acc_vowel': 0.998159, 'acc_consonant': 0.998955, 'acc_word': 0.995573, 'loss_grapheme': 0.018155, 'loss_vowel': 0.009979, 'loss_consonant': 0.005383, 'loss_word': 0.020682}\n",
      "CYCLE: 2\n",
      "    0 | 0.000100 | 160512/160635 | 15.1474 | 5.6618 |\n",
      "val: {'recall': 0.996965, 'recall_grapheme': 0.995886, 'recall_vowel': 0.998182, 'recall_consonant': 0.997905, 'recall_word': 0.995375, 'acc_grapheme': 0.995996, 'acc_vowel': 0.998284, 'acc_consonant': 0.998831, 'acc_word': 0.995399, 'loss_grapheme': 0.022657, 'loss_vowel': 0.012857, 'loss_consonant': 0.008087, 'loss_word': 0.022106}\n",
      "    1 | 0.000199 | 160512/160635 | 7.0609 | 5.7685 ||\n",
      "val: {'recall': 0.996119, 'recall_grapheme': 0.994644, 'recall_vowel': 0.997592, 'recall_consonant': 0.997597, 'recall_word': 0.994267, 'acc_grapheme': 0.995075, 'acc_vowel': 0.997687, 'acc_consonant': 0.998334, 'acc_word': 0.99423, 'loss_grapheme': 0.022149, 'loss_vowel': 0.012233, 'loss_consonant': 0.00713, 'loss_word': 0.025037}\n",
      "    2 | 0.000296 | 160512/160635 | 0.4942 | 6.0735 ||\n",
      "val: {'recall': 0.996042, 'recall_grapheme': 0.994609, 'recall_vowel': 0.996978, 'recall_consonant': 0.997973, 'recall_word': 0.994327, 'acc_grapheme': 0.995175, 'acc_vowel': 0.997587, 'acc_consonant': 0.998458, 'acc_word': 0.99423, 'loss_grapheme': 0.025236, 'loss_vowel': 0.014601, 'loss_consonant': 0.010443, 'loss_word': 0.025697}\n",
      "    3 | 0.000390 | 160512/160635 | 6.2169 | 6.1587 ||\n",
      "val: {'recall': 0.995533, 'recall_grapheme': 0.994685, 'recall_vowel': 0.997089, 'recall_consonant': 0.995672, 'recall_word': 0.994222, 'acc_grapheme': 0.994752, 'acc_vowel': 0.997314, 'acc_consonant': 0.998408, 'acc_word': 0.994205, 'loss_grapheme': 0.023977, 'loss_vowel': 0.013939, 'loss_consonant': 0.009119, 'loss_word': 0.024197}\n",
      "    4 | 0.000385 | 160512/160635 | 0.5977 | 6.3690 ||\n",
      "val: {'recall': 0.994688, 'recall_grapheme': 0.993422, 'recall_vowel': 0.996826, 'recall_consonant': 0.995083, 'recall_word': 0.993735, 'acc_grapheme': 0.994006, 'acc_vowel': 0.997189, 'acc_consonant': 0.998159, 'acc_word': 0.993633, 'loss_grapheme': 0.026076, 'loss_vowel': 0.014624, 'loss_consonant': 0.009265, 'loss_word': 0.026421}\n",
      "    5 | 0.000378 | 160512/160635 | 0.4103 | 6.3250 |||\n",
      "val: {'recall': 0.996108, 'recall_grapheme': 0.995439, 'recall_vowel': 0.997203, 'recall_consonant': 0.996349, 'recall_word': 0.994645, 'acc_grapheme': 0.994702, 'acc_vowel': 0.997463, 'acc_consonant': 0.998159, 'acc_word': 0.994578, 'loss_grapheme': 0.023927, 'loss_vowel': 0.012634, 'loss_consonant': 0.007907, 'loss_word': 0.023435}\n",
      "    6 | 0.000371 | 160512/160635 | 5.1035 | 6.2980 ||\n",
      "val: {'recall': 0.996514, 'recall_grapheme': 0.99574, 'recall_vowel': 0.99725, 'recall_consonant': 0.997327, 'recall_word': 0.994951, 'acc_grapheme': 0.995498, 'acc_vowel': 0.997911, 'acc_consonant': 0.998358, 'acc_word': 0.994926, 'loss_grapheme': 0.02192, 'loss_vowel': 0.011885, 'loss_consonant': 0.008723, 'loss_word': 0.023091}\n",
      "    7 | 0.000362 | 160512/160635 | 9.8134 | 6.1068 ||\n",
      "val: {'recall': 0.995848, 'recall_grapheme': 0.995262, 'recall_vowel': 0.996679, 'recall_consonant': 0.996189, 'recall_word': 0.99409, 'acc_grapheme': 0.994851, 'acc_vowel': 0.997488, 'acc_consonant': 0.99796, 'acc_word': 0.994105, 'loss_grapheme': 0.036194, 'loss_vowel': 0.021693, 'loss_consonant': 0.015711, 'loss_word': 0.033655}\n",
      "    8 | 0.000352 | 160512/160635 | 13.7191 | 6.1993 ||\n",
      "val: {'recall': 0.996101, 'recall_grapheme': 0.994559, 'recall_vowel': 0.997456, 'recall_consonant': 0.99783, 'recall_word': 0.994455, 'acc_grapheme': 0.995274, 'acc_vowel': 0.997538, 'acc_consonant': 0.998184, 'acc_word': 0.994404, 'loss_grapheme': 0.025738, 'loss_vowel': 0.016014, 'loss_consonant': 0.011023, 'loss_word': 0.026143}\n",
      "    9 | 0.000341 | 160512/160635 | 1.1163 | 6.2209 ||\n",
      "val: {'recall': 0.996673, 'recall_grapheme': 0.995955, 'recall_vowel': 0.997182, 'recall_consonant': 0.997599, 'recall_word': 0.995095, 'acc_grapheme': 0.995672, 'acc_vowel': 0.997562, 'acc_consonant': 0.998533, 'acc_word': 0.995025, 'loss_grapheme': 0.019759, 'loss_vowel': 0.012708, 'loss_consonant': 0.006375, 'loss_word': 0.022342}\n",
      "   10 | 0.000330 | 160512/160635 | 14.7001 | 6.1803 ||\n",
      "val: {'recall': 0.995813, 'recall_grapheme': 0.994418, 'recall_vowel': 0.996899, 'recall_consonant': 0.997518, 'recall_word': 0.993852, 'acc_grapheme': 0.994279, 'acc_vowel': 0.997264, 'acc_consonant': 0.99806, 'acc_word': 0.993807, 'loss_grapheme': 0.026905, 'loss_vowel': 0.016075, 'loss_consonant': 0.009121, 'loss_word': 0.027841}\n",
      "   11 | 0.000318 | 160512/160635 | 1.1936 | 6.0683 ||\n",
      "val: {'recall': 0.996309, 'recall_grapheme': 0.995227, 'recall_vowel': 0.997323, 'recall_consonant': 0.997457, 'recall_word': 0.994753, 'acc_grapheme': 0.9952, 'acc_vowel': 0.997687, 'acc_consonant': 0.998383, 'acc_word': 0.994652, 'loss_grapheme': 0.024298, 'loss_vowel': 0.01389, 'loss_consonant': 0.008702, 'loss_word': 0.024486}\n",
      "   12 | 0.000305 | 160512/160635 | 6.3162 | 5.8995 ||\n",
      "val: {'recall': 0.996478, 'recall_grapheme': 0.995873, 'recall_vowel': 0.998056, 'recall_consonant': 0.996109, 'recall_word': 0.995206, 'acc_grapheme': 0.995647, 'acc_vowel': 0.99806, 'acc_consonant': 0.998234, 'acc_word': 0.995175, 'loss_grapheme': 0.020737, 'loss_vowel': 0.010452, 'loss_consonant': 0.007815, 'loss_word': 0.022251}\n",
      "   13 | 0.000291 | 160512/160635 | 4.3537 | 6.2916 |||\n",
      "val: {'recall': 0.996225, 'recall_grapheme': 0.99532, 'recall_vowel': 0.996849, 'recall_consonant': 0.997409, 'recall_word': 0.994723, 'acc_grapheme': 0.99515, 'acc_vowel': 0.997612, 'acc_consonant': 0.998284, 'acc_word': 0.994752, 'loss_grapheme': 0.022039, 'loss_vowel': 0.012348, 'loss_consonant': 0.007652, 'loss_word': 0.024717}\n",
      "   14 | 0.000277 | 160512/160635 | 6.5281 | 6.2259 |||\n",
      "val: {'recall': 0.995689, 'recall_grapheme': 0.994523, 'recall_vowel': 0.996978, 'recall_consonant': 0.99673, 'recall_word': 0.993853, 'acc_grapheme': 0.992737, 'acc_vowel': 0.996966, 'acc_consonant': 0.997587, 'acc_word': 0.993757, 'loss_grapheme': 0.033819, 'loss_vowel': 0.017402, 'loss_consonant': 0.011946, 'loss_word': 0.028375}\n",
      "   15 | 0.000262 | 160512/160635 | 6.9057 | 6.0553 ||\n",
      "val: {'recall': 0.996427, 'recall_grapheme': 0.995679, 'recall_vowel': 0.997742, 'recall_consonant': 0.996609, 'recall_word': 0.994493, 'acc_grapheme': 0.994976, 'acc_vowel': 0.997886, 'acc_consonant': 0.997985, 'acc_word': 0.994254, 'loss_grapheme': 0.023961, 'loss_vowel': 0.012846, 'loss_consonant': 0.009333, 'loss_word': 0.02616}\n",
      "   16 | 0.000247 | 160512/160635 | 12.5839 | 5.9350 |\n",
      "val: {'recall': 0.997086, 'recall_grapheme': 0.996185, 'recall_vowel': 0.998251, 'recall_consonant': 0.997724, 'recall_word': 0.995721, 'acc_grapheme': 0.996095, 'acc_vowel': 0.998035, 'acc_consonant': 0.998682, 'acc_word': 0.995622, 'loss_grapheme': 0.017873, 'loss_vowel': 0.01089, 'loss_consonant': 0.006067, 'loss_word': 0.020758}\n",
      "   17 | 0.000231 | 160512/160635 | 0.8254 | 5.7170 ||\n",
      "val: {'recall': 0.9965, 'recall_grapheme': 0.995374, 'recall_vowel': 0.997535, 'recall_consonant': 0.997719, 'recall_word': 0.995099, 'acc_grapheme': 0.995523, 'acc_vowel': 0.99801, 'acc_consonant': 0.998557, 'acc_word': 0.9951, 'loss_grapheme': 0.020143, 'loss_vowel': 0.012418, 'loss_consonant': 0.007032, 'loss_word': 0.022198}\n",
      "   18 | 0.000216 | 160512/160635 | 0.2293 | 6.0982 ||\n",
      "val: {'recall': 0.997085, 'recall_grapheme': 0.996762, 'recall_vowel': 0.996731, 'recall_consonant': 0.998085, 'recall_word': 0.995818, 'acc_grapheme': 0.996543, 'acc_vowel': 0.997936, 'acc_consonant': 0.998856, 'acc_word': 0.995772, 'loss_grapheme': 0.019034, 'loss_vowel': 0.011035, 'loss_consonant': 0.00608, 'loss_word': 0.020269}\n",
      "   19 | 0.000200 | 160512/160635 | 11.7779 | 5.7442 |\n",
      "val: {'recall': 0.997285, 'recall_grapheme': 0.996391, 'recall_vowel': 0.997793, 'recall_consonant': 0.998566, 'recall_word': 0.995814, 'acc_grapheme': 0.996344, 'acc_vowel': 0.998184, 'acc_consonant': 0.998906, 'acc_word': 0.995772, 'loss_grapheme': 0.01767, 'loss_vowel': 0.010381, 'loss_consonant': 0.006298, 'loss_word': 0.018616}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 0.000184 | 160512/160635 | 2.3764 | 5.7223 |||\n",
      "val: {'recall': 0.997594, 'recall_grapheme': 0.997003, 'recall_vowel': 0.998206, 'recall_consonant': 0.998163, 'recall_word': 0.996048, 'acc_grapheme': 0.996816, 'acc_vowel': 0.998334, 'acc_consonant': 0.998707, 'acc_word': 0.996045, 'loss_grapheme': 0.016159, 'loss_vowel': 0.00898, 'loss_consonant': 0.006009, 'loss_word': 0.017992}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   21 | 0.000170 | 144000/160635 | 0.3841 | 5.7211 ||\n",
      "val: {'recall': 0.997036, 'recall_grapheme': 0.995921, 'recall_vowel': 0.998079, 'recall_consonant': 0.998223, 'recall_word': 0.995117, 'acc_grapheme': 0.995821, 'acc_vowel': 0.998085, 'acc_consonant': 0.998607, 'acc_word': 0.99515, 'loss_grapheme': 0.02163, 'loss_vowel': 0.011954, 'loss_consonant': 0.007014, 'loss_word': 0.023616}\n",
      "   22 | 0.000153 | 160512/160635 | 0.1272 | 5.9251 ||\n",
      "val: {'recall': 0.997126, 'recall_grapheme': 0.995952, 'recall_vowel': 0.998073, 'recall_consonant': 0.998527, 'recall_word': 0.995642, 'acc_grapheme': 0.99602, 'acc_vowel': 0.998383, 'acc_consonant': 0.998732, 'acc_word': 0.995672, 'loss_grapheme': 0.019074, 'loss_vowel': 0.010626, 'loss_consonant': 0.006248, 'loss_word': 0.020794}\n",
      "   23 | 0.000138 | 160512/160635 | 4.2111 | 5.6950 ||\n",
      "val: {'recall': 0.996354, 'recall_grapheme': 0.995326, 'recall_vowel': 0.997822, 'recall_consonant': 0.996942, 'recall_word': 0.995217, 'acc_grapheme': 0.995772, 'acc_vowel': 0.99806, 'acc_consonant': 0.998533, 'acc_word': 0.995274, 'loss_grapheme': 0.020818, 'loss_vowel': 0.011409, 'loss_consonant': 0.006688, 'loss_word': 0.022368}\n",
      "   24 | 0.000123 | 160512/160635 | 0.8818 | 5.5164 ||\n",
      "val: {'recall': 0.997575, 'recall_grapheme': 0.996787, 'recall_vowel': 0.998261, 'recall_consonant': 0.998465, 'recall_word': 0.996168, 'acc_grapheme': 0.996592, 'acc_vowel': 0.998582, 'acc_consonant': 0.998831, 'acc_word': 0.996219, 'loss_grapheme': 0.016689, 'loss_vowel': 0.008592, 'loss_consonant': 0.005446, 'loss_word': 0.018649}\n",
      "   25 | 0.000109 | 160512/160635 | 8.0778 | 5.7825 ||\n",
      "val: {'recall': 0.997174, 'recall_grapheme': 0.996227, 'recall_vowel': 0.997728, 'recall_consonant': 0.998513, 'recall_word': 0.995441, 'acc_grapheme': 0.996095, 'acc_vowel': 0.998209, 'acc_consonant': 0.998732, 'acc_word': 0.995448, 'loss_grapheme': 0.020279, 'loss_vowel': 0.01081, 'loss_consonant': 0.006534, 'loss_word': 0.022734}\n",
      "   26 | 0.000096 | 160512/160635 | 2.3514 | 5.4508 ||\n",
      "val: {'recall': 0.997341, 'recall_grapheme': 0.996487, 'recall_vowel': 0.997895, 'recall_consonant': 0.998496, 'recall_word': 0.995787, 'acc_grapheme': 0.996418, 'acc_vowel': 0.998383, 'acc_consonant': 0.998881, 'acc_word': 0.995772, 'loss_grapheme': 0.018603, 'loss_vowel': 0.009854, 'loss_consonant': 0.00603, 'loss_word': 0.020379}\n",
      "   27 | 0.000082 | 160512/160635 | 13.4482 | 5.5298 |\n",
      "val: {'recall': 0.997614, 'recall_grapheme': 0.996888, 'recall_vowel': 0.99813, 'recall_consonant': 0.998549, 'recall_word': 0.99604, 'acc_grapheme': 0.996816, 'acc_vowel': 0.998458, 'acc_consonant': 0.999005, 'acc_word': 0.996095, 'loss_grapheme': 0.016604, 'loss_vowel': 0.008651, 'loss_consonant': 0.005039, 'loss_word': 0.018489}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_380.pth\n",
      "   28 | 0.000070 | 160512/160635 | 6.3666 | 5.4954 ||\n",
      "val: {'recall': 0.997449, 'recall_grapheme': 0.996784, 'recall_vowel': 0.997845, 'recall_consonant': 0.998383, 'recall_word': 0.996121, 'acc_grapheme': 0.996767, 'acc_vowel': 0.998284, 'acc_consonant': 0.998756, 'acc_word': 0.996145, 'loss_grapheme': 0.017648, 'loss_vowel': 0.010116, 'loss_consonant': 0.005486, 'loss_word': 0.020328}\n",
      "   29 | 0.000059 | 160512/160635 | 13.3830 | 5.2915 |\n",
      "val: {'recall': 0.997284, 'recall_grapheme': 0.996617, 'recall_vowel': 0.99785, 'recall_consonant': 0.998054, 'recall_word': 0.995797, 'acc_grapheme': 0.996393, 'acc_vowel': 0.998358, 'acc_consonant': 0.998831, 'acc_word': 0.995797, 'loss_grapheme': 0.019632, 'loss_vowel': 0.01038, 'loss_consonant': 0.006339, 'loss_word': 0.021557}\n",
      "   30 | 0.000053 | 082560/160635 | 10.9662 | 5.8176 |"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
