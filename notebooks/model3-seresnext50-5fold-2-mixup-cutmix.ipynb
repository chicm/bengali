{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/chec/data/bengali': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/chicm/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "#SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #img = crop_resize(img, pad=0)\n",
    "        #print(img.shape)\n",
    "        #if self.train_mode:\n",
    "        #    augs = get_train_augs()\n",
    "        #    img = augs(image=img)['image']\n",
    "\n",
    "        #img  = cv2.resize(img, (SIZE, SIZE))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        MEAN = [ 0.06922848809290576 ]\n",
    "        STD = [ 0.20515700083327537 ]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936591631689417"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model3_se_resnext50_fold2_mixup_cutmix.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 3e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.1\n",
    "args.patience = 0\n",
    "args.min_lr = 2e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160678, 5) (40162, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model3_se_resnext50_fold2_mixup_cutmix.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model3_se_resnext50_fold2_mixup_cutmix.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.984254, 'recall_grapheme': 0.976814, 'recall_vowel': 0.991676, 'recall_consonant': 0.99171, 'acc_grapheme': 0.974528, 'acc_vowel': 0.992978, 'acc_consonant': 0.991435, 'loss_grapheme': 0.214347, 'loss_vowel': 0.149057, 'loss_consonant': 0.108816}\n",
      "    1 | 0.000030 | 045056/160678 | 1.4220 | 1.8856 |\n",
      "val: {'recall': 0.983727, 'recall_grapheme': 0.976074, 'recall_vowel': 0.991217, 'recall_consonant': 0.991544, 'acc_grapheme': 0.974603, 'acc_vowel': 0.992804, 'acc_consonant': 0.991186, 'loss_grapheme': 0.203053, 'loss_vowel': 0.151237, 'loss_consonant': 0.10703}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000030 | 090112/160678 | 1.7320 | 2.2550 |\n",
      "val: {'recall': 0.983109, 'recall_grapheme': 0.975741, 'recall_vowel': 0.990863, 'recall_consonant': 0.99009, 'acc_grapheme': 0.974578, 'acc_vowel': 0.992655, 'acc_consonant': 0.99126, 'loss_grapheme': 0.19116, 'loss_vowel': 0.146013, 'loss_consonant': 0.104978}\n",
      "    3 | 0.000028 | 135168/160678 | 1.5671 | 2.2238 |\n",
      "val: {'recall': 0.983459, 'recall_grapheme': 0.975641, 'recall_vowel': 0.991604, 'recall_consonant': 0.990948, 'acc_grapheme': 0.97413, 'acc_vowel': 0.993103, 'acc_consonant': 0.991136, 'loss_grapheme': 0.218874, 'loss_vowel': 0.165622, 'loss_consonant': 0.122124}\n",
      "    5 | 0.000026 | 020480/160678 | 1.2641 | 2.2607 |\n",
      "val: {'recall': 0.983229, 'recall_grapheme': 0.976018, 'recall_vowel': 0.991318, 'recall_consonant': 0.989561, 'acc_grapheme': 0.974354, 'acc_vowel': 0.993028, 'acc_consonant': 0.99131, 'loss_grapheme': 0.214015, 'loss_vowel': 0.158783, 'loss_consonant': 0.110964}\n",
      "    6 | 0.000023 | 065536/160678 | 0.3876 | 2.0802 |\n",
      "val: {'recall': 0.983871, 'recall_grapheme': 0.976369, 'recall_vowel': 0.991408, 'recall_consonant': 0.991337, 'acc_grapheme': 0.974603, 'acc_vowel': 0.993078, 'acc_consonant': 0.991036, 'loss_grapheme': 0.182311, 'loss_vowel': 0.119377, 'loss_consonant': 0.086623}\n",
      "    7 | 0.000020 | 110592/160678 | 1.8680 | 2.1763 |\n",
      "val: {'recall': 0.983483, 'recall_grapheme': 0.975279, 'recall_vowel': 0.991297, 'recall_consonant': 0.992076, 'acc_grapheme': 0.97403, 'acc_vowel': 0.992978, 'acc_consonant': 0.991385, 'loss_grapheme': 0.240963, 'loss_vowel': 0.204002, 'loss_consonant': 0.138654}\n",
      "    8 | 0.000016 | 155648/160678 | 3.8800 | 2.0531 |\n",
      "val: {'recall': 0.983981, 'recall_grapheme': 0.976212, 'recall_vowel': 0.991662, 'recall_consonant': 0.991835, 'acc_grapheme': 0.974404, 'acc_vowel': 0.993252, 'acc_consonant': 0.991484, 'loss_grapheme': 0.19953, 'loss_vowel': 0.138141, 'loss_consonant': 0.101852}\n",
      "   10 | 0.000012 | 040960/160678 | 2.6385 | 2.1093 |\n",
      "val: {'recall': 0.983722, 'recall_grapheme': 0.975701, 'recall_vowel': 0.991647, 'recall_consonant': 0.99184, 'acc_grapheme': 0.974404, 'acc_vowel': 0.993227, 'acc_consonant': 0.991559, 'loss_grapheme': 0.193019, 'loss_vowel': 0.13555, 'loss_consonant': 0.101732}\n",
      "   11 | 0.000009 | 086016/160678 | 0.7642 | 2.0740 |\n",
      "val: {'recall': 0.983915, 'recall_grapheme': 0.97601, 'recall_vowel': 0.991611, 'recall_consonant': 0.992028, 'acc_grapheme': 0.974304, 'acc_vowel': 0.993128, 'acc_consonant': 0.991609, 'loss_grapheme': 0.198539, 'loss_vowel': 0.13816, 'loss_consonant': 0.103118}\n",
      "   12 | 0.000006 | 131072/160678 | 3.0397 | 1.9502 |\n",
      "val: {'recall': 0.983762, 'recall_grapheme': 0.975907, 'recall_vowel': 0.991411, 'recall_consonant': 0.991822, 'acc_grapheme': 0.974453, 'acc_vowel': 0.993153, 'acc_consonant': 0.991484, 'loss_grapheme': 0.198524, 'loss_vowel': 0.145731, 'loss_consonant': 0.106255}\n",
      "   14 | 0.000004 | 016384/160678 | 0.8800 | 1.8787 |\n",
      "val: {'recall': 0.983734, 'recall_grapheme': 0.975976, 'recall_vowel': 0.991357, 'recall_consonant': 0.991628, 'acc_grapheme': 0.974229, 'acc_vowel': 0.993128, 'acc_consonant': 0.991385, 'loss_grapheme': 0.198707, 'loss_vowel': 0.145565, 'loss_consonant': 0.102948}\n",
      "   15 | 0.000002 | 061440/160678 | 2.2031 | 1.9456 |\n",
      "val: {'recall': 0.983035, 'recall_grapheme': 0.975465, 'recall_vowel': 0.990957, 'recall_consonant': 0.990253, 'acc_grapheme': 0.974553, 'acc_vowel': 0.992829, 'acc_consonant': 0.991335, 'loss_grapheme': 0.179024, 'loss_vowel': 0.13086, 'loss_consonant': 0.094563}\n",
      "   16 | 0.000002 | 106496/160678 | 0.5970 | 2.2014 |\n",
      "val: {'recall': 0.983767, 'recall_grapheme': 0.975702, 'recall_vowel': 0.991521, 'recall_consonant': 0.992144, 'acc_grapheme': 0.974304, 'acc_vowel': 0.993153, 'acc_consonant': 0.991534, 'loss_grapheme': 0.21682, 'loss_vowel': 0.154542, 'loss_consonant': 0.115616}\n",
      "   17 | 0.000002 | 151552/160678 | 2.1298 | 2.1507 |\n",
      "val: {'recall': 0.983271, 'recall_grapheme': 0.976185, 'recall_vowel': 0.990767, 'recall_consonant': 0.989946, 'acc_grapheme': 0.974653, 'acc_vowel': 0.992729, 'acc_consonant': 0.991186, 'loss_grapheme': 0.174597, 'loss_vowel': 0.125404, 'loss_consonant': 0.09237}\n",
      "   19 | 0.000004 | 036864/160678 | 1.2001 | 2.2072 |\n",
      "val: {'recall': 0.982874, 'recall_grapheme': 0.975303, 'recall_vowel': 0.990605, 'recall_consonant': 0.990284, 'acc_grapheme': 0.974478, 'acc_vowel': 0.992729, 'acc_consonant': 0.991285, 'loss_grapheme': 0.209263, 'loss_vowel': 0.171717, 'loss_consonant': 0.116139}\n",
      "   20 | 0.000006 | 081920/160678 | 2.0963 | 2.0425 |\n",
      "val: {'recall': 0.982774, 'recall_grapheme': 0.975549, 'recall_vowel': 0.99099, 'recall_consonant': 0.989008, 'acc_grapheme': 0.974254, 'acc_vowel': 0.992729, 'acc_consonant': 0.99136, 'loss_grapheme': 0.190761, 'loss_vowel': 0.14555, 'loss_consonant': 0.105778}\n",
      "   21 | 0.000009 | 126976/160678 | 4.1639 | 2.2308 |\n",
      "val: {'recall': 0.983517, 'recall_grapheme': 0.975431, 'recall_vowel': 0.991263, 'recall_consonant': 0.991944, 'acc_grapheme': 0.97398, 'acc_vowel': 0.992978, 'acc_consonant': 0.99146, 'loss_grapheme': 0.27419, 'loss_vowel': 0.230252, 'loss_consonant': 0.154286}\n",
      "   23 | 0.000012 | 012288/160678 | 3.1173 | 2.3137 |\n",
      "val: {'recall': 0.983497, 'recall_grapheme': 0.975464, 'recall_vowel': 0.991451, 'recall_consonant': 0.991608, 'acc_grapheme': 0.974429, 'acc_vowel': 0.993003, 'acc_consonant': 0.99131, 'loss_grapheme': 0.214225, 'loss_vowel': 0.168397, 'loss_consonant': 0.119013}\n",
      "   24 | 0.000016 | 057344/160678 | 1.8311 | 2.0478 |\n",
      "val: {'recall': 0.982708, 'recall_grapheme': 0.9757, 'recall_vowel': 0.991387, 'recall_consonant': 0.988044, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992929, 'acc_consonant': 0.991211, 'loss_grapheme': 0.198342, 'loss_vowel': 0.151968, 'loss_consonant': 0.106934}\n",
      "   25 | 0.000020 | 102400/160678 | 1.7779 | 2.1653 |\n",
      "val: {'recall': 0.982706, 'recall_grapheme': 0.974994, 'recall_vowel': 0.990715, 'recall_consonant': 0.990124, 'acc_grapheme': 0.973781, 'acc_vowel': 0.992729, 'acc_consonant': 0.991211, 'loss_grapheme': 0.189257, 'loss_vowel': 0.161329, 'loss_consonant': 0.106898}\n",
      "   26 | 0.000023 | 147456/160678 | 0.4744 | 2.1520 |\n",
      "val: {'recall': 0.983554, 'recall_grapheme': 0.975368, 'recall_vowel': 0.991586, 'recall_consonant': 0.991893, 'acc_grapheme': 0.974503, 'acc_vowel': 0.993377, 'acc_consonant': 0.991435, 'loss_grapheme': 0.211142, 'loss_vowel': 0.159337, 'loss_consonant': 0.107503}\n",
      "   28 | 0.000026 | 032768/160678 | 1.8340 | 2.0844 |\n",
      "val: {'recall': 0.983316, 'recall_grapheme': 0.975438, 'recall_vowel': 0.990858, 'recall_consonant': 0.99153, 'acc_grapheme': 0.974429, 'acc_vowel': 0.992655, 'acc_consonant': 0.991509, 'loss_grapheme': 0.210152, 'loss_vowel': 0.166782, 'loss_consonant': 0.115232}\n",
      "   29 | 0.000028 | 077824/160678 | 2.1547 | 2.0423 |\n",
      "val: {'recall': 0.982465, 'recall_grapheme': 0.974894, 'recall_vowel': 0.99092, 'recall_consonant': 0.989151, 'acc_grapheme': 0.974204, 'acc_vowel': 0.992829, 'acc_consonant': 0.991385, 'loss_grapheme': 0.193129, 'loss_vowel': 0.141943, 'loss_consonant': 0.100435}\n",
      "   30 | 0.000030 | 122880/160678 | 1.0628 | 2.2795 |\n",
      "val: {'recall': 0.983548, 'recall_grapheme': 0.975623, 'recall_vowel': 0.990967, 'recall_consonant': 0.991978, 'acc_grapheme': 0.97413, 'acc_vowel': 0.992929, 'acc_consonant': 0.99146, 'loss_grapheme': 0.217367, 'loss_vowel': 0.167855, 'loss_consonant': 0.118571}\n",
      "   32 | 0.000030 | 008192/160678 | 3.1029 | 2.2538 |\n",
      "val: {'recall': 0.982884, 'recall_grapheme': 0.97537, 'recall_vowel': 0.990635, 'recall_consonant': 0.990163, 'acc_grapheme': 0.974429, 'acc_vowel': 0.992854, 'acc_consonant': 0.99141, 'loss_grapheme': 0.195307, 'loss_vowel': 0.15945, 'loss_consonant': 0.109355}\n",
      "   33 | 0.000030 | 053248/160678 | 0.8680 | 2.4647 |\n",
      "val: {'recall': 0.983202, 'recall_grapheme': 0.974993, 'recall_vowel': 0.991015, 'recall_consonant': 0.991809, 'acc_grapheme': 0.973906, 'acc_vowel': 0.993178, 'acc_consonant': 0.991435, 'loss_grapheme': 0.204036, 'loss_vowel': 0.153423, 'loss_consonant': 0.111406}\n",
      "   34 | 0.000028 | 098304/160678 | 2.0774 | 2.3146 |\n",
      "val: {'recall': 0.983396, 'recall_grapheme': 0.97628, 'recall_vowel': 0.990657, 'recall_consonant': 0.990369, 'acc_grapheme': 0.974777, 'acc_vowel': 0.992804, 'acc_consonant': 0.99131, 'loss_grapheme': 0.212697, 'loss_vowel': 0.182511, 'loss_consonant': 0.123211}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000026 | 143360/160678 | 3.6425 | 2.2030 |\n",
      "val: {'recall': 0.983605, 'recall_grapheme': 0.975908, 'recall_vowel': 0.991186, 'recall_consonant': 0.99142, 'acc_grapheme': 0.974453, 'acc_vowel': 0.993003, 'acc_consonant': 0.991484, 'loss_grapheme': 0.22006, 'loss_vowel': 0.155876, 'loss_consonant': 0.115851}\n",
      "   37 | 0.000023 | 028672/160678 | 3.6594 | 2.4070 |\n",
      "val: {'recall': 0.982949, 'recall_grapheme': 0.974992, 'recall_vowel': 0.991159, 'recall_consonant': 0.990651, 'acc_grapheme': 0.974204, 'acc_vowel': 0.993153, 'acc_consonant': 0.99141, 'loss_grapheme': 0.249065, 'loss_vowel': 0.197817, 'loss_consonant': 0.135849}\n",
      "   38 | 0.000020 | 073728/160678 | 3.2654 | 2.1153 |\n",
      "val: {'recall': 0.982934, 'recall_grapheme': 0.975593, 'recall_vowel': 0.990523, 'recall_consonant': 0.990027, 'acc_grapheme': 0.974254, 'acc_vowel': 0.992729, 'acc_consonant': 0.991484, 'loss_grapheme': 0.210753, 'loss_vowel': 0.164874, 'loss_consonant': 0.113794}\n",
      "   39 | 0.000016 | 118784/160678 | 2.4828 | 2.0828 |\n",
      "val: {'recall': 0.983254, 'recall_grapheme': 0.976122, 'recall_vowel': 0.990772, 'recall_consonant': 0.990001, 'acc_grapheme': 0.974951, 'acc_vowel': 0.992978, 'acc_consonant': 0.99141, 'loss_grapheme': 0.209112, 'loss_vowel': 0.170145, 'loss_consonant': 0.111924}\n",
      "   41 | 0.000012 | 004096/160678 | 3.4126 | 2.5707 |\n",
      "val: {'recall': 0.983657, 'recall_grapheme': 0.975485, 'recall_vowel': 0.991844, 'recall_consonant': 0.991815, 'acc_grapheme': 0.974478, 'acc_vowel': 0.993427, 'acc_consonant': 0.991534, 'loss_grapheme': 0.214524, 'loss_vowel': 0.157868, 'loss_consonant': 0.11276}\n",
      "   42 | 0.000009 | 049152/160678 | 1.8771 | 2.2674 |\n",
      "val: {'recall': 0.983462, 'recall_grapheme': 0.975928, 'recall_vowel': 0.991505, 'recall_consonant': 0.990489, 'acc_grapheme': 0.974429, 'acc_vowel': 0.993178, 'acc_consonant': 0.99141, 'loss_grapheme': 0.23588, 'loss_vowel': 0.183497, 'loss_consonant': 0.125177}\n",
      "   43 | 0.000006 | 094208/160678 | 1.8655 | 2.0951 |\n",
      "val: {'recall': 0.98317, 'recall_grapheme': 0.97559, 'recall_vowel': 0.991207, 'recall_consonant': 0.990291, 'acc_grapheme': 0.974453, 'acc_vowel': 0.993103, 'acc_consonant': 0.991484, 'loss_grapheme': 0.198039, 'loss_vowel': 0.152294, 'loss_consonant': 0.103591}\n",
      "   44 | 0.000004 | 139264/160678 | 0.8524 | 2.2854 |\n",
      "val: {'recall': 0.98392, 'recall_grapheme': 0.976124, 'recall_vowel': 0.992016, 'recall_consonant': 0.991417, 'acc_grapheme': 0.974155, 'acc_vowel': 0.993302, 'acc_consonant': 0.991484, 'loss_grapheme': 0.217839, 'loss_vowel': 0.146637, 'loss_consonant': 0.110469}\n",
      "   46 | 0.000002 | 024576/160678 | 0.6116 | 2.5626 |\n",
      "val: {'recall': 0.983816, 'recall_grapheme': 0.975884, 'recall_vowel': 0.991622, 'recall_consonant': 0.991873, 'acc_grapheme': 0.974453, 'acc_vowel': 0.993277, 'acc_consonant': 0.991609, 'loss_grapheme': 0.251469, 'loss_vowel': 0.195819, 'loss_consonant': 0.133229}\n",
      "   47 | 0.000002 | 069632/160678 | 3.9776 | 2.2295 |\n",
      "val: {'recall': 0.983194, 'recall_grapheme': 0.975543, 'recall_vowel': 0.991261, 'recall_consonant': 0.990428, 'acc_grapheme': 0.974553, 'acc_vowel': 0.993153, 'acc_consonant': 0.991484, 'loss_grapheme': 0.229106, 'loss_vowel': 0.190876, 'loss_consonant': 0.126241}\n",
      "   48 | 0.000002 | 114688/160678 | 2.8008 | 2.1566 |\n",
      "val: {'recall': 0.983621, 'recall_grapheme': 0.975609, 'recall_vowel': 0.991584, 'recall_consonant': 0.991683, 'acc_grapheme': 0.974379, 'acc_vowel': 0.993227, 'acc_consonant': 0.991534, 'loss_grapheme': 0.223551, 'loss_vowel': 0.16845, 'loss_consonant': 0.118371}\n",
      "   49 | 0.000004 | 159744/160678 | 2.5113 | 2.0518 |\n",
      "val: {'recall': 0.983597, 'recall_grapheme': 0.975532, 'recall_vowel': 0.991478, 'recall_consonant': 0.991843, 'acc_grapheme': 0.974528, 'acc_vowel': 0.993203, 'acc_consonant': 0.991684, 'loss_grapheme': 0.233697, 'loss_vowel': 0.184537, 'loss_consonant': 0.129287}\n",
      "   50 | 0.000006 | 019456/160678 | 1.9369 | 2.1476 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-c66035b4bf70>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.983334, 'recall_grapheme': 0.97579, 'recall_vowel': 0.990465, 'recall_consonant': 0.991293, 'acc_grapheme': 0.973184, 'acc_vowel': 0.991933, 'acc_consonant': 0.99009, 'loss_grapheme': 0.25881, 'loss_vowel': 0.200453, 'loss_consonant': 0.133431}\n",
      "    1 | 0.000040 | 045056/160678 | 3.6400 | 2.5026 |\n",
      "val: {'recall': 0.98278, 'recall_grapheme': 0.975052, 'recall_vowel': 0.989611, 'recall_consonant': 0.991407, 'acc_grapheme': 0.972711, 'acc_vowel': 0.991659, 'acc_consonant': 0.990165, 'loss_grapheme': 0.292719, 'loss_vowel': 0.242861, 'loss_consonant': 0.150753}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000039 | 090112/160678 | 4.0569 | 2.3631 |\n",
      "val: {'recall': 0.982796, 'recall_grapheme': 0.974925, 'recall_vowel': 0.989774, 'recall_consonant': 0.991559, 'acc_grapheme': 0.972636, 'acc_vowel': 0.991833, 'acc_consonant': 0.989667, 'loss_grapheme': 0.287815, 'loss_vowel': 0.252474, 'loss_consonant': 0.154994}\n",
      "    3 | 0.000037 | 135168/160678 | 2.2190 | 2.3725 |\n",
      "val: {'recall': 0.982799, 'recall_grapheme': 0.975084, 'recall_vowel': 0.990086, 'recall_consonant': 0.990941, 'acc_grapheme': 0.973009, 'acc_vowel': 0.991982, 'acc_consonant': 0.99014, 'loss_grapheme': 0.220253, 'loss_vowel': 0.169415, 'loss_consonant': 0.112443}\n",
      "    5 | 0.000034 | 020480/160678 | 2.2770 | 2.5581 |\n",
      "val: {'recall': 0.983016, 'recall_grapheme': 0.975674, 'recall_vowel': 0.989542, 'recall_consonant': 0.991173, 'acc_grapheme': 0.973009, 'acc_vowel': 0.991758, 'acc_consonant': 0.989891, 'loss_grapheme': 0.294731, 'loss_vowel': 0.244157, 'loss_consonant': 0.148621}\n",
      "    6 | 0.000030 | 065536/160678 | 1.5115 | 2.3731 |\n",
      "val: {'recall': 0.983273, 'recall_grapheme': 0.975966, 'recall_vowel': 0.990148, 'recall_consonant': 0.991014, 'acc_grapheme': 0.973383, 'acc_vowel': 0.991982, 'acc_consonant': 0.99024, 'loss_grapheme': 0.204085, 'loss_vowel': 0.160966, 'loss_consonant': 0.105398}\n",
      "    7 | 0.000026 | 110592/160678 | 2.2193 | 2.2696 |\n",
      "val: {'recall': 0.983318, 'recall_grapheme': 0.975849, 'recall_vowel': 0.990008, 'recall_consonant': 0.991565, 'acc_grapheme': 0.973433, 'acc_vowel': 0.992032, 'acc_consonant': 0.990439, 'loss_grapheme': 0.222632, 'loss_vowel': 0.169313, 'loss_consonant': 0.112784}\n",
      "    8 | 0.000021 | 155648/160678 | 4.2680 | 2.4452 |\n",
      "val: {'recall': 0.983229, 'recall_grapheme': 0.975421, 'recall_vowel': 0.990358, 'recall_consonant': 0.991716, 'acc_grapheme': 0.972611, 'acc_vowel': 0.991958, 'acc_consonant': 0.990115, 'loss_grapheme': 0.290725, 'loss_vowel': 0.225275, 'loss_consonant': 0.150125}\n",
      "   10 | 0.000015 | 040960/160678 | 2.4599 | 2.4323 |\n",
      "val: {'recall': 0.982539, 'recall_grapheme': 0.974566, 'recall_vowel': 0.989766, 'recall_consonant': 0.991258, 'acc_grapheme': 0.972362, 'acc_vowel': 0.991808, 'acc_consonant': 0.990314, 'loss_grapheme': 0.229148, 'loss_vowel': 0.18432, 'loss_consonant': 0.116001}\n",
      "   11 | 0.000011 | 086016/160678 | 1.7863 | 2.4848 |\n",
      "val: {'recall': 0.983178, 'recall_grapheme': 0.975573, 'recall_vowel': 0.9902, 'recall_consonant': 0.991365, 'acc_grapheme': 0.973258, 'acc_vowel': 0.991933, 'acc_consonant': 0.990314, 'loss_grapheme': 0.233706, 'loss_vowel': 0.182244, 'loss_consonant': 0.119671}\n",
      "   12 | 0.000007 | 131072/160678 | 2.2902 | 2.4272 |\n",
      "val: {'recall': 0.982584, 'recall_grapheme': 0.975051, 'recall_vowel': 0.989414, 'recall_consonant': 0.990818, 'acc_grapheme': 0.972486, 'acc_vowel': 0.991733, 'acc_consonant': 0.990215, 'loss_grapheme': 0.242948, 'loss_vowel': 0.19955, 'loss_consonant': 0.121442}\n",
      "   14 | 0.000004 | 016384/160678 | 3.9984 | 2.4797 |\n",
      "val: {'recall': 0.983162, 'recall_grapheme': 0.97559, 'recall_vowel': 0.990263, 'recall_consonant': 0.991205, 'acc_grapheme': 0.973109, 'acc_vowel': 0.992007, 'acc_consonant': 0.990165, 'loss_grapheme': 0.27687, 'loss_vowel': 0.224892, 'loss_consonant': 0.143006}\n",
      "   15 | 0.000002 | 061440/160678 | 3.5821 | 2.2798 |\n",
      "val: {'recall': 0.983141, 'recall_grapheme': 0.975464, 'recall_vowel': 0.990073, 'recall_consonant': 0.991564, 'acc_grapheme': 0.973059, 'acc_vowel': 0.991833, 'acc_consonant': 0.990215, 'loss_grapheme': 0.272718, 'loss_vowel': 0.220679, 'loss_consonant': 0.144408}\n",
      "   16 | 0.000001 | 106496/160678 | 4.2809 | 2.3677 |\n",
      "val: {'recall': 0.983242, 'recall_grapheme': 0.975569, 'recall_vowel': 0.990178, 'recall_consonant': 0.99165, 'acc_grapheme': 0.973159, 'acc_vowel': 0.991908, 'acc_consonant': 0.99019, 'loss_grapheme': 0.295182, 'loss_vowel': 0.238848, 'loss_consonant': 0.153138}\n",
      "   17 | 0.000002 | 151552/160678 | 0.9355 | 2.4074 |\n",
      "val: {'recall': 0.983442, 'recall_grapheme': 0.975798, 'recall_vowel': 0.990289, 'recall_consonant': 0.991882, 'acc_grapheme': 0.973482, 'acc_vowel': 0.991958, 'acc_consonant': 0.990563, 'loss_grapheme': 0.224576, 'loss_vowel': 0.161937, 'loss_consonant': 0.11571}\n",
      "** saved\n",
      "   19 | 0.000004 | 036864/160678 | 1.9750 | 2.5468 |\n",
      "val: {'recall': 0.982976, 'recall_grapheme': 0.975163, 'recall_vowel': 0.990024, 'recall_consonant': 0.991553, 'acc_grapheme': 0.972735, 'acc_vowel': 0.991958, 'acc_consonant': 0.990165, 'loss_grapheme': 0.278024, 'loss_vowel': 0.231657, 'loss_consonant': 0.144383}\n",
      "   20 | 0.000007 | 081920/160678 | 3.3340 | 2.7150 |\n",
      "val: {'recall': 0.982892, 'recall_grapheme': 0.975009, 'recall_vowel': 0.989746, 'recall_consonant': 0.991802, 'acc_grapheme': 0.972586, 'acc_vowel': 0.991709, 'acc_consonant': 0.989891, 'loss_grapheme': 0.324027, 'loss_vowel': 0.272149, 'loss_consonant': 0.171829}\n",
      "   21 | 0.000011 | 126976/160678 | 0.7728 | 2.4133 |\n",
      "val: {'recall': 0.983394, 'recall_grapheme': 0.976029, 'recall_vowel': 0.990189, 'recall_consonant': 0.991332, 'acc_grapheme': 0.973532, 'acc_vowel': 0.991958, 'acc_consonant': 0.99014, 'loss_grapheme': 0.242947, 'loss_vowel': 0.188111, 'loss_consonant': 0.12506}\n",
      "   23 | 0.000015 | 012288/160678 | 3.6841 | 2.2518 |\n",
      "val: {'recall': 0.982974, 'recall_grapheme': 0.975041, 'recall_vowel': 0.990259, 'recall_consonant': 0.991556, 'acc_grapheme': 0.972885, 'acc_vowel': 0.992082, 'acc_consonant': 0.99024, 'loss_grapheme': 0.255928, 'loss_vowel': 0.200641, 'loss_consonant': 0.133236}\n",
      "   24 | 0.000021 | 057344/160678 | 1.1713 | 2.3749 |\n",
      "val: {'recall': 0.982578, 'recall_grapheme': 0.974676, 'recall_vowel': 0.989752, 'recall_consonant': 0.991208, 'acc_grapheme': 0.972462, 'acc_vowel': 0.991858, 'acc_consonant': 0.990414, 'loss_grapheme': 0.227396, 'loss_vowel': 0.181899, 'loss_consonant': 0.115361}\n",
      "   25 | 0.000026 | 102400/160678 | 2.8456 | 2.2868 |\n",
      "val: {'recall': 0.983586, 'recall_grapheme': 0.976458, 'recall_vowel': 0.990187, 'recall_consonant': 0.991244, 'acc_grapheme': 0.973657, 'acc_vowel': 0.991982, 'acc_consonant': 0.990688, 'loss_grapheme': 0.193019, 'loss_vowel': 0.134905, 'loss_consonant': 0.095712}\n",
      "** saved\n",
      "   26 | 0.000030 | 147456/160678 | 2.0129 | 2.2724 |\n",
      "val: {'recall': 0.982959, 'recall_grapheme': 0.975254, 'recall_vowel': 0.98977, 'recall_consonant': 0.991559, 'acc_grapheme': 0.972735, 'acc_vowel': 0.991933, 'acc_consonant': 0.990314, 'loss_grapheme': 0.265089, 'loss_vowel': 0.219296, 'loss_consonant': 0.136216}\n",
      "   28 | 0.000034 | 032768/160678 | 3.1614 | 2.6375 |\n",
      "val: {'recall': 0.983435, 'recall_grapheme': 0.976046, 'recall_vowel': 0.990405, 'recall_consonant': 0.991245, 'acc_grapheme': 0.972885, 'acc_vowel': 0.992306, 'acc_consonant': 0.990065, 'loss_grapheme': 0.270544, 'loss_vowel': 0.215977, 'loss_consonant': 0.144694}\n",
      "   29 | 0.000037 | 077824/160678 | 4.3280 | 2.2565 |\n",
      "val: {'recall': 0.982433, 'recall_grapheme': 0.974185, 'recall_vowel': 0.989954, 'recall_consonant': 0.991406, 'acc_grapheme': 0.972312, 'acc_vowel': 0.992132, 'acc_consonant': 0.990439, 'loss_grapheme': 0.257205, 'loss_vowel': 0.21128, 'loss_consonant': 0.135309}\n",
      "   30 | 0.000039 | 122880/160678 | 2.0079 | 2.2594 |\n",
      "val: {'recall': 0.982373, 'recall_grapheme': 0.975148, 'recall_vowel': 0.988947, 'recall_consonant': 0.990251, 'acc_grapheme': 0.972486, 'acc_vowel': 0.991634, 'acc_consonant': 0.990339, 'loss_grapheme': 0.225077, 'loss_vowel': 0.177856, 'loss_consonant': 0.116954}\n",
      "   32 | 0.000040 | 008192/160678 | 2.7581 | 2.5893 |\n",
      "val: {'recall': 0.982777, 'recall_grapheme': 0.975326, 'recall_vowel': 0.990009, 'recall_consonant': 0.990449, 'acc_grapheme': 0.972935, 'acc_vowel': 0.991958, 'acc_consonant': 0.990289, 'loss_grapheme': 0.277125, 'loss_vowel': 0.227549, 'loss_consonant': 0.142372}\n",
      "   33 | 0.000039 | 053248/160678 | 2.7615 | 2.4525 |\n",
      "val: {'recall': 0.982622, 'recall_grapheme': 0.975256, 'recall_vowel': 0.989883, 'recall_consonant': 0.990091, 'acc_grapheme': 0.972735, 'acc_vowel': 0.991933, 'acc_consonant': 0.990439, 'loss_grapheme': 0.266101, 'loss_vowel': 0.214771, 'loss_consonant': 0.133546}\n",
      "   34 | 0.000037 | 098304/160678 | 2.4286 | 2.5469 |\n",
      "val: {'recall': 0.982693, 'recall_grapheme': 0.975281, 'recall_vowel': 0.989998, 'recall_consonant': 0.990215, 'acc_grapheme': 0.972885, 'acc_vowel': 0.991958, 'acc_consonant': 0.990663, 'loss_grapheme': 0.211069, 'loss_vowel': 0.158183, 'loss_consonant': 0.106246}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000034 | 143360/160678 | 1.5977 | 2.4454 |\n",
      "val: {'recall': 0.982846, 'recall_grapheme': 0.975443, 'recall_vowel': 0.990105, 'recall_consonant': 0.990392, 'acc_grapheme': 0.973084, 'acc_vowel': 0.992007, 'acc_consonant': 0.990464, 'loss_grapheme': 0.253422, 'loss_vowel': 0.191433, 'loss_consonant': 0.130282}\n",
      "   37 | 0.000030 | 028672/160678 | 2.2746 | 2.2861 |\n",
      "val: {'recall': 0.983051, 'recall_grapheme': 0.97526, 'recall_vowel': 0.99015, 'recall_consonant': 0.991537, 'acc_grapheme': 0.973283, 'acc_vowel': 0.992231, 'acc_consonant': 0.990513, 'loss_grapheme': 0.24445, 'loss_vowel': 0.191415, 'loss_consonant': 0.124084}\n",
      "   38 | 0.000026 | 073728/160678 | 1.2148 | 2.6391 |\n",
      "val: {'recall': 0.983084, 'recall_grapheme': 0.975452, 'recall_vowel': 0.990035, 'recall_consonant': 0.991398, 'acc_grapheme': 0.973233, 'acc_vowel': 0.992107, 'acc_consonant': 0.990563, 'loss_grapheme': 0.238574, 'loss_vowel': 0.178383, 'loss_consonant': 0.119639}\n",
      "   39 | 0.000021 | 118784/160678 | 0.2507 | 2.4659 |\n",
      "val: {'recall': 0.98343, 'recall_grapheme': 0.975764, 'recall_vowel': 0.990177, 'recall_consonant': 0.992015, 'acc_grapheme': 0.973159, 'acc_vowel': 0.992057, 'acc_consonant': 0.990364, 'loss_grapheme': 0.293698, 'loss_vowel': 0.229134, 'loss_consonant': 0.158086}\n",
      "   41 | 0.000015 | 004096/160678 | 2.0961 | 1.7320 |\n",
      "val: {'recall': 0.982628, 'recall_grapheme': 0.975132, 'recall_vowel': 0.989162, 'recall_consonant': 0.991085, 'acc_grapheme': 0.972885, 'acc_vowel': 0.991709, 'acc_consonant': 0.990688, 'loss_grapheme': 0.19873, 'loss_vowel': 0.14729, 'loss_consonant': 0.096846}\n",
      "   42 | 0.000011 | 049152/160678 | 4.2378 | 2.5682 |\n",
      "val: {'recall': 0.983304, 'recall_grapheme': 0.976034, 'recall_vowel': 0.990383, 'recall_consonant': 0.990762, 'acc_grapheme': 0.973109, 'acc_vowel': 0.991933, 'acc_consonant': 0.990389, 'loss_grapheme': 0.303482, 'loss_vowel': 0.244126, 'loss_consonant': 0.162442}\n",
      "   43 | 0.000007 | 094208/160678 | 1.6917 | 2.2759 |\n",
      "val: {'recall': 0.983276, 'recall_grapheme': 0.975884, 'recall_vowel': 0.98997, 'recall_consonant': 0.991366, 'acc_grapheme': 0.973134, 'acc_vowel': 0.991982, 'acc_consonant': 0.990563, 'loss_grapheme': 0.234658, 'loss_vowel': 0.181678, 'loss_consonant': 0.121624}\n",
      "   44 | 0.000004 | 139264/160678 | 2.0994 | 2.3752 |\n",
      "val: {'recall': 0.983283, 'recall_grapheme': 0.97556, 'recall_vowel': 0.99022, 'recall_consonant': 0.991791, 'acc_grapheme': 0.972686, 'acc_vowel': 0.991958, 'acc_consonant': 0.990289, 'loss_grapheme': 0.300314, 'loss_vowel': 0.252532, 'loss_consonant': 0.16071}\n",
      "   46 | 0.000002 | 024576/160678 | 2.3533 | 2.1830 |\n",
      "val: {'recall': 0.98208, 'recall_grapheme': 0.974469, 'recall_vowel': 0.989388, 'recall_consonant': 0.989995, 'acc_grapheme': 0.972362, 'acc_vowel': 0.991634, 'acc_consonant': 0.990264, 'loss_grapheme': 0.250246, 'loss_vowel': 0.200577, 'loss_consonant': 0.127314}\n",
      "   47 | 0.000001 | 069632/160678 | 2.1582 | 2.4068 |\n",
      "val: {'recall': 0.98331, 'recall_grapheme': 0.975467, 'recall_vowel': 0.990433, 'recall_consonant': 0.991873, 'acc_grapheme': 0.973209, 'acc_vowel': 0.992231, 'acc_consonant': 0.990638, 'loss_grapheme': 0.26528, 'loss_vowel': 0.209794, 'loss_consonant': 0.140503}\n",
      "   48 | 0.000002 | 114688/160678 | 3.7396 | 2.5697 |\n",
      "val: {'recall': 0.983344, 'recall_grapheme': 0.975908, 'recall_vowel': 0.989935, 'recall_consonant': 0.991623, 'acc_grapheme': 0.972935, 'acc_vowel': 0.991933, 'acc_consonant': 0.990588, 'loss_grapheme': 0.264693, 'loss_vowel': 0.213996, 'loss_consonant': 0.138059}\n",
      "   49 | 0.000004 | 159744/160678 | 1.3763 | 2.3958 |\n",
      "val: {'recall': 0.982592, 'recall_grapheme': 0.975251, 'recall_vowel': 0.989532, 'recall_consonant': 0.990332, 'acc_grapheme': 0.97291, 'acc_vowel': 0.991908, 'acc_consonant': 0.990762, 'loss_grapheme': 0.225377, 'loss_vowel': 0.176733, 'loss_consonant': 0.115131}\n",
      "   51 | 0.000007 | 045056/160678 | 0.9479 | 2.3575 |\n",
      "val: {'recall': 0.982446, 'recall_grapheme': 0.975089, 'recall_vowel': 0.989407, 'recall_consonant': 0.9902, 'acc_grapheme': 0.972661, 'acc_vowel': 0.991783, 'acc_consonant': 0.990414, 'loss_grapheme': 0.243253, 'loss_vowel': 0.194643, 'loss_consonant': 0.123688}\n",
      "   52 | 0.000011 | 090112/160678 | 3.4063 | 2.4847 |\n",
      "val: {'recall': 0.983264, 'recall_grapheme': 0.975728, 'recall_vowel': 0.990127, 'recall_consonant': 0.991473, 'acc_grapheme': 0.97281, 'acc_vowel': 0.991933, 'acc_consonant': 0.990264, 'loss_grapheme': 0.326957, 'loss_vowel': 0.268083, 'loss_consonant': 0.168251}\n",
      "   53 | 0.000015 | 135168/160678 | 3.7290 | 2.5165 |\n",
      "val: {'recall': 0.983283, 'recall_grapheme': 0.975489, 'recall_vowel': 0.990238, 'recall_consonant': 0.991918, 'acc_grapheme': 0.972835, 'acc_vowel': 0.991908, 'acc_consonant': 0.99024, 'loss_grapheme': 0.315735, 'loss_vowel': 0.254839, 'loss_consonant': 0.166239}\n",
      "   55 | 0.000020 | 020480/160678 | 2.1556 | 2.2369 |\n",
      "val: {'recall': 0.983225, 'recall_grapheme': 0.975724, 'recall_vowel': 0.990057, 'recall_consonant': 0.991396, 'acc_grapheme': 0.973233, 'acc_vowel': 0.992057, 'acc_consonant': 0.990663, 'loss_grapheme': 0.238624, 'loss_vowel': 0.190616, 'loss_consonant': 0.120227}\n",
      "   56 | 0.000026 | 065536/160678 | 1.2993 | 2.2870 |\n",
      "val: {'recall': 0.983131, 'recall_grapheme': 0.975555, 'recall_vowel': 0.989846, 'recall_consonant': 0.991568, 'acc_grapheme': 0.973283, 'acc_vowel': 0.991933, 'acc_consonant': 0.990638, 'loss_grapheme': 0.231504, 'loss_vowel': 0.173013, 'loss_consonant': 0.118145}\n",
      "   57 | 0.000030 | 110592/160678 | 1.4338 | 2.0946 |\n",
      "val: {'recall': 0.983058, 'recall_grapheme': 0.975391, 'recall_vowel': 0.990201, 'recall_consonant': 0.991249, 'acc_grapheme': 0.972511, 'acc_vowel': 0.991982, 'acc_consonant': 0.990713, 'loss_grapheme': 0.217815, 'loss_vowel': 0.164939, 'loss_consonant': 0.11079}\n",
      "   58 | 0.000034 | 155648/160678 | 1.4626 | 2.2502 |\n",
      "val: {'recall': 0.982559, 'recall_grapheme': 0.975067, 'recall_vowel': 0.989993, 'recall_consonant': 0.990108, 'acc_grapheme': 0.973034, 'acc_vowel': 0.992157, 'acc_consonant': 0.990688, 'loss_grapheme': 0.194753, 'loss_vowel': 0.149087, 'loss_consonant': 0.098878}\n",
      "   60 | 0.000037 | 040960/160678 | 1.5078 | 2.5464 |\n",
      "val: {'recall': 0.982829, 'recall_grapheme': 0.97566, 'recall_vowel': 0.989589, 'recall_consonant': 0.990405, 'acc_grapheme': 0.972785, 'acc_vowel': 0.991908, 'acc_consonant': 0.990489, 'loss_grapheme': 0.271411, 'loss_vowel': 0.235563, 'loss_consonant': 0.145085}\n",
      "   61 | 0.000039 | 086016/160678 | 3.2948 | 2.5195 |\n",
      "val: {'recall': 0.983117, 'recall_grapheme': 0.975818, 'recall_vowel': 0.98969, 'recall_consonant': 0.991141, 'acc_grapheme': 0.973333, 'acc_vowel': 0.991933, 'acc_consonant': 0.990414, 'loss_grapheme': 0.209352, 'loss_vowel': 0.159179, 'loss_consonant': 0.107453}\n",
      "   62 | 0.000040 | 131072/160678 | 3.2050 | 2.5022 |\n",
      "val: {'recall': 0.982932, 'recall_grapheme': 0.974881, 'recall_vowel': 0.990431, 'recall_consonant': 0.991536, 'acc_grapheme': 0.972661, 'acc_vowel': 0.992132, 'acc_consonant': 0.990364, 'loss_grapheme': 0.266149, 'loss_vowel': 0.201409, 'loss_consonant': 0.142148}\n",
      "   64 | 0.000039 | 016384/160678 | 0.5380 | 2.0806 |\n",
      "val: {'recall': 0.983281, 'recall_grapheme': 0.975738, 'recall_vowel': 0.99035, 'recall_consonant': 0.9913, 'acc_grapheme': 0.973383, 'acc_vowel': 0.992107, 'acc_consonant': 0.990862, 'loss_grapheme': 0.214246, 'loss_vowel': 0.154551, 'loss_consonant': 0.106317}\n",
      "   65 | 0.000037 | 061440/160678 | 0.9460 | 2.3784 |\n",
      "val: {'recall': 0.983301, 'recall_grapheme': 0.976049, 'recall_vowel': 0.989979, 'recall_consonant': 0.991126, 'acc_grapheme': 0.973408, 'acc_vowel': 0.992032, 'acc_consonant': 0.990489, 'loss_grapheme': 0.273566, 'loss_vowel': 0.199508, 'loss_consonant': 0.137736}\n",
      "   66 | 0.000034 | 106496/160678 | 1.6277 | 2.3339 |\n",
      "val: {'recall': 0.982718, 'recall_grapheme': 0.975502, 'recall_vowel': 0.989547, 'recall_consonant': 0.990319, 'acc_grapheme': 0.973034, 'acc_vowel': 0.991933, 'acc_consonant': 0.990588, 'loss_grapheme': 0.254568, 'loss_vowel': 0.21755, 'loss_consonant': 0.136818}\n",
      "   67 | 0.000030 | 151552/160678 | 0.2157 | 2.4398 |\n",
      "val: {'recall': 0.983357, 'recall_grapheme': 0.975906, 'recall_vowel': 0.990275, 'recall_consonant': 0.991342, 'acc_grapheme': 0.973482, 'acc_vowel': 0.992231, 'acc_consonant': 0.990713, 'loss_grapheme': 0.230682, 'loss_vowel': 0.16933, 'loss_consonant': 0.11791}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 0.000026 | 036864/160678 | 2.2043 | 2.5326 |\n",
      "val: {'recall': 0.983071, 'recall_grapheme': 0.975765, 'recall_vowel': 0.990299, 'recall_consonant': 0.990457, 'acc_grapheme': 0.973482, 'acc_vowel': 0.992231, 'acc_consonant': 0.990563, 'loss_grapheme': 0.259903, 'loss_vowel': 0.203122, 'loss_consonant': 0.135824}\n",
      "   70 | 0.000021 | 081920/160678 | 1.2931 | 2.6078 |\n",
      "val: {'recall': 0.98334, 'recall_grapheme': 0.976002, 'recall_vowel': 0.990586, 'recall_consonant': 0.990772, 'acc_grapheme': 0.973283, 'acc_vowel': 0.992107, 'acc_consonant': 0.990264, 'loss_grapheme': 0.351826, 'loss_vowel': 0.261734, 'loss_consonant': 0.184408}\n",
      "   71 | 0.000015 | 126976/160678 | 2.1249 | 2.2977 |\n",
      "val: {'recall': 0.983046, 'recall_grapheme': 0.975813, 'recall_vowel': 0.990283, 'recall_consonant': 0.990276, 'acc_grapheme': 0.973433, 'acc_vowel': 0.992107, 'acc_consonant': 0.990762, 'loss_grapheme': 0.236249, 'loss_vowel': 0.17963, 'loss_consonant': 0.122693}\n",
      "   73 | 0.000011 | 012288/160678 | 2.3508 | 2.3449 |\n",
      "val: {'recall': 0.983085, 'recall_grapheme': 0.975618, 'recall_vowel': 0.990571, 'recall_consonant': 0.990532, 'acc_grapheme': 0.973358, 'acc_vowel': 0.992281, 'acc_consonant': 0.990688, 'loss_grapheme': 0.23728, 'loss_vowel': 0.17834, 'loss_consonant': 0.124059}\n",
      "   74 | 0.000007 | 057344/160678 | 0.3139 | 2.2193 |\n",
      "val: {'recall': 0.98301, 'recall_grapheme': 0.976022, 'recall_vowel': 0.98984, 'recall_consonant': 0.990153, 'acc_grapheme': 0.973233, 'acc_vowel': 0.992157, 'acc_consonant': 0.990762, 'loss_grapheme': 0.205343, 'loss_vowel': 0.156819, 'loss_consonant': 0.107047}\n",
      "   75 | 0.000004 | 102400/160678 | 3.1982 | 2.4109 |\n",
      "val: {'recall': 0.983065, 'recall_grapheme': 0.975699, 'recall_vowel': 0.990333, 'recall_consonant': 0.99053, 'acc_grapheme': 0.973184, 'acc_vowel': 0.992281, 'acc_consonant': 0.990414, 'loss_grapheme': 0.297926, 'loss_vowel': 0.235898, 'loss_consonant': 0.159718}\n",
      "   76 | 0.000002 | 147456/160678 | 3.0988 | 2.4429 |\n",
      "val: {'recall': 0.98309, 'recall_grapheme': 0.975918, 'recall_vowel': 0.990073, 'recall_consonant': 0.990452, 'acc_grapheme': 0.973283, 'acc_vowel': 0.992207, 'acc_consonant': 0.990538, 'loss_grapheme': 0.269951, 'loss_vowel': 0.21489, 'loss_consonant': 0.14287}\n",
      "   78 | 0.000001 | 032768/160678 | 1.5783 | 2.5269 |\n",
      "val: {'recall': 0.982824, 'recall_grapheme': 0.975541, 'recall_vowel': 0.989816, 'recall_consonant': 0.990399, 'acc_grapheme': 0.973009, 'acc_vowel': 0.992132, 'acc_consonant': 0.990688, 'loss_grapheme': 0.220982, 'loss_vowel': 0.174333, 'loss_consonant': 0.115065}\n",
      "   79 | 0.000002 | 077824/160678 | 1.6600 | 2.1985 |\n",
      "val: {'recall': 0.983109, 'recall_grapheme': 0.976014, 'recall_vowel': 0.99012, 'recall_consonant': 0.990289, 'acc_grapheme': 0.973408, 'acc_vowel': 0.992182, 'acc_consonant': 0.990663, 'loss_grapheme': 0.22219, 'loss_vowel': 0.17878, 'loss_consonant': 0.115883}\n",
      "   80 | 0.000004 | 122880/160678 | 1.9500 | 2.4963 |\n",
      "val: {'recall': 0.982981, 'recall_grapheme': 0.975664, 'recall_vowel': 0.990017, 'recall_consonant': 0.990577, 'acc_grapheme': 0.973034, 'acc_vowel': 0.992182, 'acc_consonant': 0.990862, 'loss_grapheme': 0.24894, 'loss_vowel': 0.196052, 'loss_consonant': 0.131785}\n",
      "   82 | 0.000007 | 008192/160678 | 2.1798 | 2.9110 |\n",
      "val: {'recall': 0.983197, 'recall_grapheme': 0.976213, 'recall_vowel': 0.989948, 'recall_consonant': 0.990416, 'acc_grapheme': 0.973159, 'acc_vowel': 0.992132, 'acc_consonant': 0.990339, 'loss_grapheme': 0.287573, 'loss_vowel': 0.230645, 'loss_consonant': 0.150013}\n",
      "   83 | 0.000011 | 053248/160678 | 2.9086 | 2.4528 |\n",
      "val: {'recall': 0.982997, 'recall_grapheme': 0.975916, 'recall_vowel': 0.99003, 'recall_consonant': 0.990127, 'acc_grapheme': 0.973408, 'acc_vowel': 0.992132, 'acc_consonant': 0.990414, 'loss_grapheme': 0.256686, 'loss_vowel': 0.196678, 'loss_consonant': 0.13024}\n",
      "   84 | 0.000015 | 098304/160678 | 4.3653 | 2.4670 |\n",
      "val: {'recall': 0.982977, 'recall_grapheme': 0.975527, 'recall_vowel': 0.990306, 'recall_consonant': 0.990549, 'acc_grapheme': 0.973084, 'acc_vowel': 0.992132, 'acc_consonant': 0.990489, 'loss_grapheme': 0.354372, 'loss_vowel': 0.317566, 'loss_consonant': 0.189819}\n",
      "   85 | 0.000021 | 143360/160678 | 2.2240 | 2.3470 |\n",
      "val: {'recall': 0.982314, 'recall_grapheme': 0.975054, 'recall_vowel': 0.989523, 'recall_consonant': 0.989625, 'acc_grapheme': 0.972686, 'acc_vowel': 0.992007, 'acc_consonant': 0.990588, 'loss_grapheme': 0.205566, 'loss_vowel': 0.163308, 'loss_consonant': 0.107871}\n",
      "   87 | 0.000026 | 028672/160678 | 1.6791 | 2.1125 |\n",
      "val: {'recall': 0.982588, 'recall_grapheme': 0.975423, 'recall_vowel': 0.989623, 'recall_consonant': 0.989882, 'acc_grapheme': 0.972935, 'acc_vowel': 0.992007, 'acc_consonant': 0.990563, 'loss_grapheme': 0.224276, 'loss_vowel': 0.178768, 'loss_consonant': 0.11944}\n",
      "   89 | 0.000034 | 118784/160678 | 1.5097 | 2.3572 |\n",
      "val: {'recall': 0.98312, 'recall_grapheme': 0.975709, 'recall_vowel': 0.990596, 'recall_consonant': 0.990466, 'acc_grapheme': 0.973383, 'acc_vowel': 0.992331, 'acc_consonant': 0.990314, 'loss_grapheme': 0.276454, 'loss_vowel': 0.201537, 'loss_consonant': 0.13962}\n",
      "   91 | 0.000037 | 004096/160678 | 1.9296 | 2.0292 |\n",
      "val: {'recall': 0.982773, 'recall_grapheme': 0.975819, 'recall_vowel': 0.989646, 'recall_consonant': 0.989807, 'acc_grapheme': 0.973682, 'acc_vowel': 0.992082, 'acc_consonant': 0.990762, 'loss_grapheme': 0.199087, 'loss_vowel': 0.154077, 'loss_consonant': 0.102138}\n",
      "   92 | 0.000039 | 049152/160678 | 3.8847 | 2.4185 |\n",
      "val: {'recall': 0.983122, 'recall_grapheme': 0.975961, 'recall_vowel': 0.989948, 'recall_consonant': 0.990618, 'acc_grapheme': 0.973682, 'acc_vowel': 0.992207, 'acc_consonant': 0.990414, 'loss_grapheme': 0.258336, 'loss_vowel': 0.201231, 'loss_consonant': 0.140924}\n",
      "   93 | 0.000040 | 094208/160678 | 2.1481 | 2.4456 |\n",
      "val: {'recall': 0.982992, 'recall_grapheme': 0.97582, 'recall_vowel': 0.990016, 'recall_consonant': 0.99031, 'acc_grapheme': 0.973009, 'acc_vowel': 0.992107, 'acc_consonant': 0.990464, 'loss_grapheme': 0.25495, 'loss_vowel': 0.207063, 'loss_consonant': 0.138445}\n",
      "   94 | 0.000039 | 139264/160678 | 4.2711 | 2.4935 |\n",
      "val: {'recall': 0.982845, 'recall_grapheme': 0.975308, 'recall_vowel': 0.990451, 'recall_consonant': 0.990311, 'acc_grapheme': 0.972885, 'acc_vowel': 0.992331, 'acc_consonant': 0.990389, 'loss_grapheme': 0.272967, 'loss_vowel': 0.209678, 'loss_consonant': 0.141636}\n",
      "   96 | 0.000037 | 024576/160678 | 1.1613 | 2.2660 |\n",
      "val: {'recall': 0.983058, 'recall_grapheme': 0.975682, 'recall_vowel': 0.990387, 'recall_consonant': 0.99048, 'acc_grapheme': 0.973408, 'acc_vowel': 0.992381, 'acc_consonant': 0.990663, 'loss_grapheme': 0.232572, 'loss_vowel': 0.179615, 'loss_consonant': 0.127751}\n",
      "   97 | 0.000034 | 069632/160678 | 4.0047 | 2.2551 |\n",
      "val: {'recall': 0.983068, 'recall_grapheme': 0.975877, 'recall_vowel': 0.990315, 'recall_consonant': 0.990204, 'acc_grapheme': 0.973184, 'acc_vowel': 0.992207, 'acc_consonant': 0.990414, 'loss_grapheme': 0.305707, 'loss_vowel': 0.249242, 'loss_consonant': 0.171353}\n",
      "   98 | 0.000030 | 114688/160678 | 4.1174 | 2.1770 |\n",
      "val: {'recall': 0.982934, 'recall_grapheme': 0.975751, 'recall_vowel': 0.990208, 'recall_consonant': 0.990026, 'acc_grapheme': 0.973283, 'acc_vowel': 0.992306, 'acc_consonant': 0.990638, 'loss_grapheme': 0.222099, 'loss_vowel': 0.165543, 'loss_consonant': 0.114119}\n",
      "   99 | 0.000026 | 159744/160678 | 4.3050 | 2.4521 |\n",
      "val: {'recall': 0.983152, 'recall_grapheme': 0.975869, 'recall_vowel': 0.99057, 'recall_consonant': 0.990299, 'acc_grapheme': 0.973557, 'acc_vowel': 0.992331, 'acc_consonant': 0.990688, 'loss_grapheme': 0.285349, 'loss_vowel': 0.222479, 'loss_consonant': 0.152112}\n",
      "  101 | 0.000021 | 045056/160678 | 1.4606 | 2.4426 |\n",
      "val: {'recall': 0.982651, 'recall_grapheme': 0.975074, 'recall_vowel': 0.990177, 'recall_consonant': 0.990278, 'acc_grapheme': 0.973059, 'acc_vowel': 0.992356, 'acc_consonant': 0.990837, 'loss_grapheme': 0.24537, 'loss_vowel': 0.202032, 'loss_consonant': 0.133724}\n",
      "  102 | 0.000015 | 090112/160678 | 4.6845 | 2.4149 |\n",
      "val: {'recall': 0.983077, 'recall_grapheme': 0.975777, 'recall_vowel': 0.990429, 'recall_consonant': 0.990325, 'acc_grapheme': 0.973632, 'acc_vowel': 0.992431, 'acc_consonant': 0.990663, 'loss_grapheme': 0.253491, 'loss_vowel': 0.199798, 'loss_consonant': 0.135638}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 0.000011 | 135168/160678 | 1.8848 | 2.1883 |\n",
      "val: {'recall': 0.982861, 'recall_grapheme': 0.975267, 'recall_vowel': 0.990482, 'recall_consonant': 0.99043, 'acc_grapheme': 0.973134, 'acc_vowel': 0.99258, 'acc_consonant': 0.990837, 'loss_grapheme': 0.227469, 'loss_vowel': 0.186592, 'loss_consonant': 0.124151}\n",
      "  105 | 0.000007 | 020480/160678 | 0.6742 | 1.9005 |\n",
      "val: {'recall': 0.982829, 'recall_grapheme': 0.975553, 'recall_vowel': 0.990317, 'recall_consonant': 0.989893, 'acc_grapheme': 0.973457, 'acc_vowel': 0.99248, 'acc_consonant': 0.990937, 'loss_grapheme': 0.198153, 'loss_vowel': 0.151318, 'loss_consonant': 0.100997}\n",
      "  106 | 0.000004 | 065536/160678 | 3.3500 | 2.3603 |\n",
      "val: {'recall': 0.982799, 'recall_grapheme': 0.975256, 'recall_vowel': 0.990317, 'recall_consonant': 0.990366, 'acc_grapheme': 0.973233, 'acc_vowel': 0.992256, 'acc_consonant': 0.990613, 'loss_grapheme': 0.282934, 'loss_vowel': 0.220959, 'loss_consonant': 0.15033}\n",
      "  107 | 0.000002 | 110592/160678 | 4.0812 | 2.1880 |\n",
      "val: {'recall': 0.9826, 'recall_grapheme': 0.975116, 'recall_vowel': 0.990049, 'recall_consonant': 0.990117, 'acc_grapheme': 0.973059, 'acc_vowel': 0.992406, 'acc_consonant': 0.990837, 'loss_grapheme': 0.221612, 'loss_vowel': 0.182771, 'loss_consonant': 0.11744}\n",
      "  108 | 0.000001 | 155648/160678 | 1.7483 | 2.3362 |\n",
      "val: {'recall': 0.983087, 'recall_grapheme': 0.975767, 'recall_vowel': 0.990504, 'recall_consonant': 0.990311, 'acc_grapheme': 0.973507, 'acc_vowel': 0.992381, 'acc_consonant': 0.990738, 'loss_grapheme': 0.261128, 'loss_vowel': 0.19727, 'loss_consonant': 0.136137}\n",
      "  110 | 0.000002 | 040960/160678 | 2.2684 | 2.2128 |\n",
      "val: {'recall': 0.982875, 'recall_grapheme': 0.97547, 'recall_vowel': 0.990387, 'recall_consonant': 0.990171, 'acc_grapheme': 0.973457, 'acc_vowel': 0.992381, 'acc_consonant': 0.990613, 'loss_grapheme': 0.222044, 'loss_vowel': 0.180786, 'loss_consonant': 0.117311}\n",
      "  111 | 0.000004 | 086016/160678 | 1.8311 | 2.3115 |\n",
      "val: {'recall': 0.982634, 'recall_grapheme': 0.97504, 'recall_vowel': 0.990411, 'recall_consonant': 0.990046, 'acc_grapheme': 0.972935, 'acc_vowel': 0.992605, 'acc_consonant': 0.990787, 'loss_grapheme': 0.22764, 'loss_vowel': 0.183105, 'loss_consonant': 0.120002}\n",
      "  112 | 0.000007 | 131072/160678 | 2.2236 | 2.3340 |\n",
      "val: {'recall': 0.982817, 'recall_grapheme': 0.975278, 'recall_vowel': 0.990297, 'recall_consonant': 0.990417, 'acc_grapheme': 0.973233, 'acc_vowel': 0.992555, 'acc_consonant': 0.990812, 'loss_grapheme': 0.24581, 'loss_vowel': 0.200323, 'loss_consonant': 0.12767}\n",
      "  114 | 0.000011 | 016384/160678 | 1.0126 | 1.5758 |\n",
      "val: {'recall': 0.982818, 'recall_grapheme': 0.975653, 'recall_vowel': 0.990337, 'recall_consonant': 0.989629, 'acc_grapheme': 0.973408, 'acc_vowel': 0.992356, 'acc_consonant': 0.990663, 'loss_grapheme': 0.178652, 'loss_vowel': 0.127778, 'loss_consonant': 0.08719}\n",
      "  115 | 0.000015 | 061440/160678 | 0.3474 | 2.2440 |\n",
      "val: {'recall': 0.983077, 'recall_grapheme': 0.975728, 'recall_vowel': 0.990596, 'recall_consonant': 0.990257, 'acc_grapheme': 0.973706, 'acc_vowel': 0.992456, 'acc_consonant': 0.990738, 'loss_grapheme': 0.209998, 'loss_vowel': 0.153245, 'loss_consonant': 0.109104}\n",
      "  116 | 0.000021 | 106496/160678 | 0.3320 | 2.3512 |\n",
      "val: {'recall': 0.983119, 'recall_grapheme': 0.975884, 'recall_vowel': 0.990312, 'recall_consonant': 0.990393, 'acc_grapheme': 0.974005, 'acc_vowel': 0.99248, 'acc_consonant': 0.990937, 'loss_grapheme': 0.208927, 'loss_vowel': 0.148255, 'loss_consonant': 0.106009}\n",
      "  117 | 0.000026 | 151552/160678 | 4.1215 | 2.2564 |\n",
      "val: {'recall': 0.983266, 'recall_grapheme': 0.975841, 'recall_vowel': 0.990768, 'recall_consonant': 0.990613, 'acc_grapheme': 0.973731, 'acc_vowel': 0.992406, 'acc_consonant': 0.990738, 'loss_grapheme': 0.274961, 'loss_vowel': 0.208758, 'loss_consonant': 0.148381}\n",
      "  119 | 0.000030 | 036864/160678 | 0.1805 | 2.0222 |\n",
      "val: {'recall': 0.982731, 'recall_grapheme': 0.975494, 'recall_vowel': 0.989835, 'recall_consonant': 0.990102, 'acc_grapheme': 0.973184, 'acc_vowel': 0.992331, 'acc_consonant': 0.990912, 'loss_grapheme': 0.175992, 'loss_vowel': 0.123681, 'loss_consonant': 0.087218}\n",
      "  120 | 0.000034 | 081920/160678 | 0.1891 | 2.2331 |\n",
      "val: {'recall': 0.983507, 'recall_grapheme': 0.976047, 'recall_vowel': 0.990533, 'recall_consonant': 0.991403, 'acc_grapheme': 0.973607, 'acc_vowel': 0.992505, 'acc_consonant': 0.990962, 'loss_grapheme': 0.194289, 'loss_vowel': 0.135895, 'loss_consonant': 0.096223}\n",
      "  121 | 0.000037 | 126976/160678 | 1.8469 | 2.3083 |\n",
      "val: {'recall': 0.982074, 'recall_grapheme': 0.974778, 'recall_vowel': 0.989722, 'recall_consonant': 0.989016, 'acc_grapheme': 0.972337, 'acc_vowel': 0.992157, 'acc_consonant': 0.990787, 'loss_grapheme': 0.218325, 'loss_vowel': 0.183848, 'loss_consonant': 0.122588}\n",
      "  123 | 0.000039 | 012288/160678 | 1.7158 | 2.4940 |\n",
      "val: {'recall': 0.982767, 'recall_grapheme': 0.975334, 'recall_vowel': 0.990165, 'recall_consonant': 0.990233, 'acc_grapheme': 0.972885, 'acc_vowel': 0.992356, 'acc_consonant': 0.990464, 'loss_grapheme': 0.251971, 'loss_vowel': 0.202057, 'loss_consonant': 0.137536}\n",
      "  124 | 0.000040 | 057344/160678 | 1.7900 | 2.4804 |\n",
      "val: {'recall': 0.98312, 'recall_grapheme': 0.975377, 'recall_vowel': 0.99033, 'recall_consonant': 0.991396, 'acc_grapheme': 0.972984, 'acc_vowel': 0.992705, 'acc_consonant': 0.990538, 'loss_grapheme': 0.262387, 'loss_vowel': 0.203635, 'loss_consonant': 0.140007}\n",
      "  125 | 0.000039 | 102400/160678 | 0.4245 | 2.1047 |\n",
      "val: {'recall': 0.983027, 'recall_grapheme': 0.975495, 'recall_vowel': 0.990628, 'recall_consonant': 0.990491, 'acc_grapheme': 0.973258, 'acc_vowel': 0.992555, 'acc_consonant': 0.990912, 'loss_grapheme': 0.201081, 'loss_vowel': 0.155548, 'loss_consonant': 0.105685}\n",
      "  126 | 0.000037 | 147456/160678 | 0.5238 | 2.3389 |\n",
      "val: {'recall': 0.983038, 'recall_grapheme': 0.975514, 'recall_vowel': 0.990642, 'recall_consonant': 0.990485, 'acc_grapheme': 0.97398, 'acc_vowel': 0.992705, 'acc_consonant': 0.990812, 'loss_grapheme': 0.209814, 'loss_vowel': 0.158808, 'loss_consonant': 0.106826}\n",
      "  128 | 0.000034 | 032768/160678 | 4.5930 | 2.5520 |\n",
      "val: {'recall': 0.983335, 'recall_grapheme': 0.975741, 'recall_vowel': 0.990247, 'recall_consonant': 0.991612, 'acc_grapheme': 0.973457, 'acc_vowel': 0.99248, 'acc_consonant': 0.990837, 'loss_grapheme': 0.275504, 'loss_vowel': 0.214708, 'loss_consonant': 0.150602}\n",
      "  129 | 0.000030 | 077824/160678 | 0.8212 | 2.3952 |\n",
      "val: {'recall': 0.982444, 'recall_grapheme': 0.974524, 'recall_vowel': 0.990319, 'recall_consonant': 0.990411, 'acc_grapheme': 0.97281, 'acc_vowel': 0.992381, 'acc_consonant': 0.990862, 'loss_grapheme': 0.260531, 'loss_vowel': 0.212417, 'loss_consonant': 0.136738}\n",
      "  130 | 0.000026 | 122880/160678 | 2.1849 | 2.3647 |\n",
      "val: {'recall': 0.983696, 'recall_grapheme': 0.976367, 'recall_vowel': 0.990433, 'recall_consonant': 0.991617, 'acc_grapheme': 0.97398, 'acc_vowel': 0.992505, 'acc_consonant': 0.990887, 'loss_grapheme': 0.214165, 'loss_vowel': 0.15839, 'loss_consonant': 0.110116}\n",
      "** saved\n",
      "  132 | 0.000021 | 008192/160678 | 3.8116 | 2.3364 |\n",
      "val: {'recall': 0.982667, 'recall_grapheme': 0.975041, 'recall_vowel': 0.990009, 'recall_consonant': 0.990577, 'acc_grapheme': 0.973283, 'acc_vowel': 0.992256, 'acc_consonant': 0.991036, 'loss_grapheme': 0.237453, 'loss_vowel': 0.201432, 'loss_consonant': 0.127502}\n",
      "  133 | 0.000015 | 053248/160678 | 1.9981 | 2.3013 |\n",
      "val: {'recall': 0.982389, 'recall_grapheme': 0.974701, 'recall_vowel': 0.990171, 'recall_consonant': 0.989984, 'acc_grapheme': 0.97296, 'acc_vowel': 0.992306, 'acc_consonant': 0.990862, 'loss_grapheme': 0.210578, 'loss_vowel': 0.169052, 'loss_consonant': 0.110028}\n",
      "  134 | 0.000011 | 098304/160678 | 2.1303 | 2.2985 |\n",
      "val: {'recall': 0.983129, 'recall_grapheme': 0.975921, 'recall_vowel': 0.990531, 'recall_consonant': 0.990143, 'acc_grapheme': 0.973532, 'acc_vowel': 0.992605, 'acc_consonant': 0.990713, 'loss_grapheme': 0.245116, 'loss_vowel': 0.192819, 'loss_consonant': 0.131895}\n",
      "  135 | 0.000007 | 143360/160678 | 1.9349 | 2.2881 |\n",
      "val: {'recall': 0.982465, 'recall_grapheme': 0.97486, 'recall_vowel': 0.989906, 'recall_consonant': 0.990236, 'acc_grapheme': 0.97286, 'acc_vowel': 0.992406, 'acc_consonant': 0.990912, 'loss_grapheme': 0.246816, 'loss_vowel': 0.205924, 'loss_consonant': 0.133608}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  137 | 0.000004 | 028672/160678 | 3.3448 | 2.3063 |\n",
      "val: {'recall': 0.98255, 'recall_grapheme': 0.974628, 'recall_vowel': 0.990532, 'recall_consonant': 0.990411, 'acc_grapheme': 0.97291, 'acc_vowel': 0.992456, 'acc_consonant': 0.990912, 'loss_grapheme': 0.23915, 'loss_vowel': 0.199366, 'loss_consonant': 0.128746}\n",
      "  138 | 0.000002 | 073728/160678 | 2.2111 | 2.3301 |\n",
      "val: {'recall': 0.982383, 'recall_grapheme': 0.975359, 'recall_vowel': 0.990187, 'recall_consonant': 0.988627, 'acc_grapheme': 0.973184, 'acc_vowel': 0.992182, 'acc_consonant': 0.990837, 'loss_grapheme': 0.194891, 'loss_vowel': 0.142878, 'loss_consonant': 0.100957}\n",
      "  139 | 0.000001 | 118784/160678 | 1.9531 | 2.2566 |\n",
      "val: {'recall': 0.982705, 'recall_grapheme': 0.975047, 'recall_vowel': 0.990462, 'recall_consonant': 0.990264, 'acc_grapheme': 0.973059, 'acc_vowel': 0.992431, 'acc_consonant': 0.990688, 'loss_grapheme': 0.265059, 'loss_vowel': 0.225141, 'loss_consonant': 0.145029}\n",
      "  141 | 0.000002 | 004096/160678 | 4.0221 | 4.2044 |\n",
      "val: {'recall': 0.982928, 'recall_grapheme': 0.975399, 'recall_vowel': 0.990399, 'recall_consonant': 0.990515, 'acc_grapheme': 0.973507, 'acc_vowel': 0.992456, 'acc_consonant': 0.990762, 'loss_grapheme': 0.271522, 'loss_vowel': 0.22188, 'loss_consonant': 0.147389}\n",
      "  142 | 0.000004 | 049152/160678 | 3.9721 | 2.3031 |\n",
      "val: {'recall': 0.98212, 'recall_grapheme': 0.974632, 'recall_vowel': 0.990084, 'recall_consonant': 0.989132, 'acc_grapheme': 0.97286, 'acc_vowel': 0.992306, 'acc_consonant': 0.990912, 'loss_grapheme': 0.256758, 'loss_vowel': 0.230778, 'loss_consonant': 0.142291}\n",
      "  143 | 0.000007 | 094208/160678 | 2.0730 | 2.1621 |\n",
      "val: {'recall': 0.983079, 'recall_grapheme': 0.975638, 'recall_vowel': 0.990643, 'recall_consonant': 0.990396, 'acc_grapheme': 0.973756, 'acc_vowel': 0.992605, 'acc_consonant': 0.990837, 'loss_grapheme': 0.215264, 'loss_vowel': 0.163209, 'loss_consonant': 0.11163}\n",
      "  144 | 0.000011 | 139264/160678 | 3.3721 | 2.2825 |\n",
      "val: {'recall': 0.983329, 'recall_grapheme': 0.976008, 'recall_vowel': 0.990771, 'recall_consonant': 0.99053, 'acc_grapheme': 0.973756, 'acc_vowel': 0.992381, 'acc_consonant': 0.990613, 'loss_grapheme': 0.293837, 'loss_vowel': 0.236365, 'loss_consonant': 0.157803}\n",
      "  146 | 0.000015 | 024576/160678 | 2.7823 | 2.4748 |\n",
      "val: {'recall': 0.983531, 'recall_grapheme': 0.976329, 'recall_vowel': 0.990889, 'recall_consonant': 0.990577, 'acc_grapheme': 0.974005, 'acc_vowel': 0.99248, 'acc_consonant': 0.990663, 'loss_grapheme': 0.282919, 'loss_vowel': 0.202184, 'loss_consonant': 0.146273}\n",
      "  147 | 0.000020 | 069632/160678 | 1.9478 | 2.4673 |\n",
      "val: {'recall': 0.982792, 'recall_grapheme': 0.975336, 'recall_vowel': 0.990183, 'recall_consonant': 0.990313, 'acc_grapheme': 0.973358, 'acc_vowel': 0.992331, 'acc_consonant': 0.990738, 'loss_grapheme': 0.247459, 'loss_vowel': 0.20372, 'loss_consonant': 0.132807}\n",
      "  148 | 0.000026 | 114688/160678 | 0.9282 | 2.1714 |\n",
      "val: {'recall': 0.982948, 'recall_grapheme': 0.975716, 'recall_vowel': 0.99023, 'recall_consonant': 0.990129, 'acc_grapheme': 0.973632, 'acc_vowel': 0.992406, 'acc_consonant': 0.991061, 'loss_grapheme': 0.183604, 'loss_vowel': 0.133803, 'loss_consonant': 0.092331}\n",
      "  149 | 0.000030 | 159744/160678 | 3.0699 | 2.3070 |\n",
      "val: {'recall': 0.983081, 'recall_grapheme': 0.975871, 'recall_vowel': 0.990221, 'recall_consonant': 0.99036, 'acc_grapheme': 0.973457, 'acc_vowel': 0.992555, 'acc_consonant': 0.991086, 'loss_grapheme': 0.202502, 'loss_vowel': 0.154295, 'loss_consonant': 0.105124}\n",
      "  151 | 0.000034 | 045056/160678 | 1.8783 | 2.5772 |\n",
      "val: {'recall': 0.982712, 'recall_grapheme': 0.974882, 'recall_vowel': 0.990628, 'recall_consonant': 0.990458, 'acc_grapheme': 0.97281, 'acc_vowel': 0.992331, 'acc_consonant': 0.990912, 'loss_grapheme': 0.266669, 'loss_vowel': 0.246859, 'loss_consonant': 0.149141}\n",
      "  152 | 0.000037 | 090112/160678 | 1.8885 | 2.1491 |\n",
      "val: {'recall': 0.982511, 'recall_grapheme': 0.974847, 'recall_vowel': 0.990263, 'recall_consonant': 0.990087, 'acc_grapheme': 0.973009, 'acc_vowel': 0.99248, 'acc_consonant': 0.990937, 'loss_grapheme': 0.218889, 'loss_vowel': 0.182027, 'loss_consonant': 0.122474}\n",
      "  153 | 0.000039 | 135168/160678 | 4.3858 | 2.3192 |\n",
      "val: {'recall': 0.983124, 'recall_grapheme': 0.975308, 'recall_vowel': 0.990877, 'recall_consonant': 0.991001, 'acc_grapheme': 0.973507, 'acc_vowel': 0.992107, 'acc_consonant': 0.990513, 'loss_grapheme': 0.36174, 'loss_vowel': 0.285047, 'loss_consonant': 0.192738}\n",
      "  155 | 0.000040 | 020480/160678 | 3.3916 | 2.4727 |\n",
      "val: {'recall': 0.983515, 'recall_grapheme': 0.976385, 'recall_vowel': 0.99072, 'recall_consonant': 0.990568, 'acc_grapheme': 0.97403, 'acc_vowel': 0.992456, 'acc_consonant': 0.990987, 'loss_grapheme': 0.255555, 'loss_vowel': 0.19642, 'loss_consonant': 0.137261}\n",
      "  156 | 0.000039 | 065536/160678 | 2.0799 | 2.3904 |\n",
      "val: {'recall': 0.983833, 'recall_grapheme': 0.976645, 'recall_vowel': 0.991176, 'recall_consonant': 0.990868, 'acc_grapheme': 0.974105, 'acc_vowel': 0.99258, 'acc_consonant': 0.990638, 'loss_grapheme': 0.310052, 'loss_vowel': 0.24228, 'loss_consonant': 0.167103}\n",
      "** saved\n",
      "  157 | 0.000037 | 110592/160678 | 1.0241 | 2.2024 |\n",
      "val: {'recall': 0.983101, 'recall_grapheme': 0.975593, 'recall_vowel': 0.99035, 'recall_consonant': 0.990868, 'acc_grapheme': 0.97398, 'acc_vowel': 0.992555, 'acc_consonant': 0.990663, 'loss_grapheme': 0.245309, 'loss_vowel': 0.193575, 'loss_consonant': 0.128686}\n",
      "  158 | 0.000034 | 155648/160678 | 3.5396 | 2.2890 |\n",
      "val: {'recall': 0.983694, 'recall_grapheme': 0.975939, 'recall_vowel': 0.990877, 'recall_consonant': 0.99202, 'acc_grapheme': 0.97398, 'acc_vowel': 0.99253, 'acc_consonant': 0.990787, 'loss_grapheme': 0.291301, 'loss_vowel': 0.227712, 'loss_consonant': 0.154014}\n",
      "  160 | 0.000030 | 040960/160678 | 2.1020 | 2.4315 |\n",
      "val: {'recall': 0.983319, 'recall_grapheme': 0.976229, 'recall_vowel': 0.990284, 'recall_consonant': 0.990536, 'acc_grapheme': 0.97408, 'acc_vowel': 0.99263, 'acc_consonant': 0.991086, 'loss_grapheme': 0.242951, 'loss_vowel': 0.187303, 'loss_consonant': 0.126127}\n",
      "  161 | 0.000026 | 086016/160678 | 0.3165 | 2.2070 |\n",
      "val: {'recall': 0.983193, 'recall_grapheme': 0.976069, 'recall_vowel': 0.990133, 'recall_consonant': 0.9905, 'acc_grapheme': 0.974055, 'acc_vowel': 0.992505, 'acc_consonant': 0.991235, 'loss_grapheme': 0.203745, 'loss_vowel': 0.157209, 'loss_consonant': 0.10528}\n",
      "  162 | 0.000020 | 131072/160678 | 1.8324 | 2.1512 |\n",
      "val: {'recall': 0.983118, 'recall_grapheme': 0.975764, 'recall_vowel': 0.990406, 'recall_consonant': 0.990537, 'acc_grapheme': 0.973682, 'acc_vowel': 0.992605, 'acc_consonant': 0.991186, 'loss_grapheme': 0.211402, 'loss_vowel': 0.172378, 'loss_consonant': 0.113009}\n",
      "  164 | 0.000015 | 016384/160678 | 0.8407 | 2.6889 |\n",
      "val: {'recall': 0.983422, 'recall_grapheme': 0.976248, 'recall_vowel': 0.990551, 'recall_consonant': 0.990639, 'acc_grapheme': 0.974254, 'acc_vowel': 0.99268, 'acc_consonant': 0.991111, 'loss_grapheme': 0.238186, 'loss_vowel': 0.191448, 'loss_consonant': 0.127089}\n",
      "  165 | 0.000011 | 061440/160678 | 1.8044 | 2.0688 |\n",
      "val: {'recall': 0.98331, 'recall_grapheme': 0.97584, 'recall_vowel': 0.99086, 'recall_consonant': 0.990702, 'acc_grapheme': 0.973731, 'acc_vowel': 0.992729, 'acc_consonant': 0.99131, 'loss_grapheme': 0.204351, 'loss_vowel': 0.152124, 'loss_consonant': 0.107311}\n",
      "  166 | 0.000007 | 106496/160678 | 0.0946 | 2.2454 |\n",
      "val: {'recall': 0.983238, 'recall_grapheme': 0.975942, 'recall_vowel': 0.990485, 'recall_consonant': 0.990584, 'acc_grapheme': 0.974379, 'acc_vowel': 0.992729, 'acc_consonant': 0.99146, 'loss_grapheme': 0.175867, 'loss_vowel': 0.125172, 'loss_consonant': 0.089608}\n",
      "  167 | 0.000004 | 151552/160678 | 2.9160 | 2.2232 |\n",
      "val: {'recall': 0.983313, 'recall_grapheme': 0.975926, 'recall_vowel': 0.990777, 'recall_consonant': 0.990625, 'acc_grapheme': 0.97398, 'acc_vowel': 0.99263, 'acc_consonant': 0.990937, 'loss_grapheme': 0.250557, 'loss_vowel': 0.183539, 'loss_consonant': 0.12726}\n",
      "  169 | 0.000002 | 036864/160678 | 3.2833 | 2.2258 |\n",
      "val: {'recall': 0.983268, 'recall_grapheme': 0.976238, 'recall_vowel': 0.990813, 'recall_consonant': 0.989783, 'acc_grapheme': 0.973955, 'acc_vowel': 0.99258, 'acc_consonant': 0.990862, 'loss_grapheme': 0.297955, 'loss_vowel': 0.225043, 'loss_consonant': 0.159877}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  170 | 0.000001 | 081920/160678 | 4.4904 | 2.2401 |\n",
      "val: {'recall': 0.983074, 'recall_grapheme': 0.975628, 'recall_vowel': 0.990485, 'recall_consonant': 0.990555, 'acc_grapheme': 0.973881, 'acc_vowel': 0.99263, 'acc_consonant': 0.991285, 'loss_grapheme': 0.225951, 'loss_vowel': 0.182671, 'loss_consonant': 0.123234}\n",
      "  171 | 0.000002 | 126976/160678 | 0.8315 | 2.3236 |\n",
      "val: {'recall': 0.983007, 'recall_grapheme': 0.975459, 'recall_vowel': 0.990566, 'recall_consonant': 0.990545, 'acc_grapheme': 0.973731, 'acc_vowel': 0.992655, 'acc_consonant': 0.991011, 'loss_grapheme': 0.248269, 'loss_vowel': 0.207533, 'loss_consonant': 0.133853}\n",
      "  173 | 0.000004 | 012288/160678 | 1.2718 | 2.5957 |\n",
      "val: {'recall': 0.98332, 'recall_grapheme': 0.975863, 'recall_vowel': 0.990857, 'recall_consonant': 0.990697, 'acc_grapheme': 0.974254, 'acc_vowel': 0.99253, 'acc_consonant': 0.991011, 'loss_grapheme': 0.251176, 'loss_vowel': 0.186988, 'loss_consonant': 0.130776}\n",
      "  174 | 0.000007 | 057344/160678 | 2.7565 | 2.1673 |\n",
      "val: {'recall': 0.98315, 'recall_grapheme': 0.975637, 'recall_vowel': 0.990745, 'recall_consonant': 0.990582, 'acc_grapheme': 0.973706, 'acc_vowel': 0.992705, 'acc_consonant': 0.991061, 'loss_grapheme': 0.239824, 'loss_vowel': 0.180055, 'loss_consonant': 0.124114}\n",
      "  175 | 0.000011 | 102400/160678 | 1.7057 | 2.3765 |\n",
      "val: {'recall': 0.983594, 'recall_grapheme': 0.976363, 'recall_vowel': 0.990854, 'recall_consonant': 0.990797, 'acc_grapheme': 0.974279, 'acc_vowel': 0.99268, 'acc_consonant': 0.991111, 'loss_grapheme': 0.205986, 'loss_vowel': 0.142416, 'loss_consonant': 0.104318}\n",
      "  176 | 0.000015 | 147456/160678 | 0.0576 | 2.1637 |\n",
      "val: {'recall': 0.983368, 'recall_grapheme': 0.976337, 'recall_vowel': 0.990634, 'recall_consonant': 0.990166, 'acc_grapheme': 0.974404, 'acc_vowel': 0.992655, 'acc_consonant': 0.991136, 'loss_grapheme': 0.180894, 'loss_vowel': 0.125217, 'loss_consonant': 0.089656}\n",
      "  178 | 0.000020 | 032768/160678 | 3.9479 | 2.5065 |\n",
      "val: {'recall': 0.983019, 'recall_grapheme': 0.976034, 'recall_vowel': 0.990819, 'recall_consonant': 0.989189, 'acc_grapheme': 0.973881, 'acc_vowel': 0.99268, 'acc_consonant': 0.990937, 'loss_grapheme': 0.270486, 'loss_vowel': 0.232617, 'loss_consonant': 0.151735}\n",
      "  179 | 0.000026 | 077824/160678 | 1.6738 | 1.9330 |\n",
      "val: {'recall': 0.982755, 'recall_grapheme': 0.975386, 'recall_vowel': 0.990161, 'recall_consonant': 0.990088, 'acc_grapheme': 0.973955, 'acc_vowel': 0.992555, 'acc_consonant': 0.99126, 'loss_grapheme': 0.187386, 'loss_vowel': 0.142495, 'loss_consonant': 0.094239}\n",
      "  180 | 0.000030 | 122880/160678 | 1.0540 | 2.1708 |\n",
      "val: {'recall': 0.983228, 'recall_grapheme': 0.976177, 'recall_vowel': 0.991058, 'recall_consonant': 0.9895, 'acc_grapheme': 0.974379, 'acc_vowel': 0.992779, 'acc_consonant': 0.990962, 'loss_grapheme': 0.228002, 'loss_vowel': 0.167285, 'loss_consonant': 0.116417}\n",
      "  182 | 0.000034 | 008192/160678 | 3.3421 | 1.5941 |\n",
      "val: {'recall': 0.983094, 'recall_grapheme': 0.975899, 'recall_vowel': 0.990244, 'recall_consonant': 0.990335, 'acc_grapheme': 0.97403, 'acc_vowel': 0.992505, 'acc_consonant': 0.99126, 'loss_grapheme': 0.200734, 'loss_vowel': 0.152091, 'loss_consonant': 0.104955}\n",
      "  183 | 0.000037 | 053248/160678 | 0.9440 | 2.0867 |\n",
      "val: {'recall': 0.982685, 'recall_grapheme': 0.975054, 'recall_vowel': 0.990582, 'recall_consonant': 0.990051, 'acc_grapheme': 0.97291, 'acc_vowel': 0.992555, 'acc_consonant': 0.990987, 'loss_grapheme': 0.204056, 'loss_vowel': 0.161754, 'loss_consonant': 0.111688}\n",
      "  184 | 0.000039 | 098304/160678 | 1.9204 | 2.1114 |\n",
      "val: {'recall': 0.98353, 'recall_grapheme': 0.975954, 'recall_vowel': 0.990871, 'recall_consonant': 0.991342, 'acc_grapheme': 0.974379, 'acc_vowel': 0.992729, 'acc_consonant': 0.990987, 'loss_grapheme': 0.208384, 'loss_vowel': 0.155212, 'loss_consonant': 0.102739}\n",
      "  185 | 0.000040 | 143360/160678 | 2.0574 | 2.1560 |\n",
      "val: {'recall': 0.983293, 'recall_grapheme': 0.975186, 'recall_vowel': 0.991243, 'recall_consonant': 0.991558, 'acc_grapheme': 0.973756, 'acc_vowel': 0.992904, 'acc_consonant': 0.990937, 'loss_grapheme': 0.234098, 'loss_vowel': 0.196872, 'loss_consonant': 0.129133}\n",
      "  187 | 0.000039 | 028672/160678 | 1.5367 | 1.7829 |\n",
      "val: {'recall': 0.983741, 'recall_grapheme': 0.976382, 'recall_vowel': 0.990793, 'recall_consonant': 0.991406, 'acc_grapheme': 0.974752, 'acc_vowel': 0.992729, 'acc_consonant': 0.991285, 'loss_grapheme': 0.172272, 'loss_vowel': 0.115168, 'loss_consonant': 0.083742}\n",
      "  188 | 0.000037 | 073728/160678 | 2.2498 | 2.3322 |\n",
      "val: {'recall': 0.983744, 'recall_grapheme': 0.976297, 'recall_vowel': 0.99073, 'recall_consonant': 0.991652, 'acc_grapheme': 0.97398, 'acc_vowel': 0.992754, 'acc_consonant': 0.991136, 'loss_grapheme': 0.239807, 'loss_vowel': 0.189689, 'loss_consonant': 0.132451}\n",
      "  189 | 0.000034 | 118784/160678 | 2.0439 | 2.3504 |\n",
      "val: {'recall': 0.983075, 'recall_grapheme': 0.975591, 'recall_vowel': 0.990672, 'recall_consonant': 0.990448, 'acc_grapheme': 0.97398, 'acc_vowel': 0.992705, 'acc_consonant': 0.990787, 'loss_grapheme': 0.261315, 'loss_vowel': 0.202574, 'loss_consonant': 0.142901}\n",
      "  191 | 0.000030 | 004096/160678 | 1.9035 | 2.9703 |\n",
      "val: {'recall': 0.983299, 'recall_grapheme': 0.976278, 'recall_vowel': 0.990449, 'recall_consonant': 0.990189, 'acc_grapheme': 0.97408, 'acc_vowel': 0.99263, 'acc_consonant': 0.991061, 'loss_grapheme': 0.225939, 'loss_vowel': 0.191293, 'loss_consonant': 0.126469}\n",
      "  192 | 0.000026 | 049152/160678 | 1.7210 | 2.3618 |\n",
      "val: {'recall': 0.983434, 'recall_grapheme': 0.975859, 'recall_vowel': 0.990668, 'recall_consonant': 0.991349, 'acc_grapheme': 0.974503, 'acc_vowel': 0.992804, 'acc_consonant': 0.99131, 'loss_grapheme': 0.190536, 'loss_vowel': 0.149168, 'loss_consonant': 0.102779}\n",
      "  193 | 0.000021 | 094208/160678 | 3.4139 | 2.2012 |\n",
      "val: {'recall': 0.983915, 'recall_grapheme': 0.9763, 'recall_vowel': 0.991233, 'recall_consonant': 0.991827, 'acc_grapheme': 0.974553, 'acc_vowel': 0.992779, 'acc_consonant': 0.991061, 'loss_grapheme': 0.259782, 'loss_vowel': 0.206518, 'loss_consonant': 0.145473}\n",
      "** saved\n",
      "  194 | 0.000015 | 139264/160678 | 1.7105 | 2.1203 |\n",
      "val: {'recall': 0.983698, 'recall_grapheme': 0.97635, 'recall_vowel': 0.990679, 'recall_consonant': 0.991413, 'acc_grapheme': 0.974229, 'acc_vowel': 0.99268, 'acc_consonant': 0.991111, 'loss_grapheme': 0.1945, 'loss_vowel': 0.153307, 'loss_consonant': 0.106487}\n",
      "  196 | 0.000011 | 024576/160678 | 1.0415 | 2.4383 |\n",
      "val: {'recall': 0.983739, 'recall_grapheme': 0.976129, 'recall_vowel': 0.990961, 'recall_consonant': 0.991738, 'acc_grapheme': 0.974404, 'acc_vowel': 0.992754, 'acc_consonant': 0.991161, 'loss_grapheme': 0.228723, 'loss_vowel': 0.185964, 'loss_consonant': 0.124597}\n",
      "  197 | 0.000007 | 069632/160678 | 0.0511 | 2.2074 |\n",
      "val: {'recall': 0.984027, 'recall_grapheme': 0.976538, 'recall_vowel': 0.991134, 'recall_consonant': 0.991898, 'acc_grapheme': 0.974578, 'acc_vowel': 0.992854, 'acc_consonant': 0.991186, 'loss_grapheme': 0.216496, 'loss_vowel': 0.154265, 'loss_consonant': 0.112844}\n",
      "** saved\n",
      "  198 | 0.000004 | 114688/160678 | 3.3525 | 2.2944 |\n",
      "val: {'recall': 0.984022, 'recall_grapheme': 0.976538, 'recall_vowel': 0.991168, 'recall_consonant': 0.991843, 'acc_grapheme': 0.974229, 'acc_vowel': 0.992779, 'acc_consonant': 0.991161, 'loss_grapheme': 0.262493, 'loss_vowel': 0.207433, 'loss_consonant': 0.142628}\n",
      "  199 | 0.000002 | 159744/160678 | 2.0967 | 2.3830 |\n",
      "val: {'recall': 0.983027, 'recall_grapheme': 0.975542, 'recall_vowel': 0.990669, 'recall_consonant': 0.990356, 'acc_grapheme': 0.973955, 'acc_vowel': 0.99258, 'acc_consonant': 0.991235, 'loss_grapheme': 0.21826, 'loss_vowel': 0.189952, 'loss_consonant': 0.124571}\n",
      "  201 | 0.000001 | 045056/160678 | 4.0092 | 2.1967 |\n",
      "val: {'recall': 0.983962, 'recall_grapheme': 0.976527, 'recall_vowel': 0.991254, 'recall_consonant': 0.991537, 'acc_grapheme': 0.97418, 'acc_vowel': 0.992879, 'acc_consonant': 0.990962, 'loss_grapheme': 0.231307, 'loss_vowel': 0.179282, 'loss_consonant': 0.125255}\n",
      "  202 | 0.000002 | 090112/160678 | 3.9445 | 2.1005 |\n",
      "val: {'recall': 0.983862, 'recall_grapheme': 0.976437, 'recall_vowel': 0.991078, 'recall_consonant': 0.991496, 'acc_grapheme': 0.974329, 'acc_vowel': 0.992879, 'acc_consonant': 0.991061, 'loss_grapheme': 0.234173, 'loss_vowel': 0.186954, 'loss_consonant': 0.129495}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  203 | 0.000004 | 135168/160678 | 2.2688 | 2.1419 |\n",
      "val: {'recall': 0.983428, 'recall_grapheme': 0.975805, 'recall_vowel': 0.990562, 'recall_consonant': 0.991541, 'acc_grapheme': 0.974155, 'acc_vowel': 0.992605, 'acc_consonant': 0.991211, 'loss_grapheme': 0.238234, 'loss_vowel': 0.211634, 'loss_consonant': 0.137286}\n",
      "  205 | 0.000007 | 020480/160678 | 3.9685 | 2.5105 |\n",
      "val: {'recall': 0.983705, 'recall_grapheme': 0.976083, 'recall_vowel': 0.991177, 'recall_consonant': 0.991476, 'acc_grapheme': 0.974155, 'acc_vowel': 0.992879, 'acc_consonant': 0.991086, 'loss_grapheme': 0.251153, 'loss_vowel': 0.20111, 'loss_consonant': 0.136639}\n",
      "  206 | 0.000011 | 065536/160678 | 4.1559 | 2.5022 |\n",
      "val: {'recall': 0.983343, 'recall_grapheme': 0.976023, 'recall_vowel': 0.990775, 'recall_consonant': 0.99055, 'acc_grapheme': 0.97408, 'acc_vowel': 0.992705, 'acc_consonant': 0.991235, 'loss_grapheme': 0.235226, 'loss_vowel': 0.198388, 'loss_consonant': 0.131999}\n",
      "  207 | 0.000015 | 110592/160678 | 0.4002 | 2.2394 |\n",
      "val: {'recall': 0.983373, 'recall_grapheme': 0.975657, 'recall_vowel': 0.990669, 'recall_consonant': 0.99151, 'acc_grapheme': 0.973931, 'acc_vowel': 0.992779, 'acc_consonant': 0.991161, 'loss_grapheme': 0.233532, 'loss_vowel': 0.18961, 'loss_consonant': 0.128937}\n",
      "  208 | 0.000020 | 155648/160678 | 3.0509 | 2.1502 |\n",
      "val: {'recall': 0.983244, 'recall_grapheme': 0.975751, 'recall_vowel': 0.991132, 'recall_consonant': 0.990343, 'acc_grapheme': 0.973831, 'acc_vowel': 0.993053, 'acc_consonant': 0.991036, 'loss_grapheme': 0.250449, 'loss_vowel': 0.205625, 'loss_consonant': 0.137448}\n",
      "  210 | 0.000026 | 040960/160678 | 0.6146 | 2.1112 |\n",
      "val: {'recall': 0.983441, 'recall_grapheme': 0.975939, 'recall_vowel': 0.990541, 'recall_consonant': 0.991345, 'acc_grapheme': 0.974254, 'acc_vowel': 0.992705, 'acc_consonant': 0.991061, 'loss_grapheme': 0.209039, 'loss_vowel': 0.163745, 'loss_consonant': 0.111428}\n",
      "  211 | 0.000030 | 086016/160678 | 3.0785 | 2.1815 |\n",
      "val: {'recall': 0.983446, 'recall_grapheme': 0.976291, 'recall_vowel': 0.990997, 'recall_consonant': 0.990204, 'acc_grapheme': 0.974155, 'acc_vowel': 0.992779, 'acc_consonant': 0.991235, 'loss_grapheme': 0.268714, 'loss_vowel': 0.231472, 'loss_consonant': 0.143097}\n",
      "  212 | 0.000034 | 131072/160678 | 2.0865 | 2.2979 |\n",
      "val: {'recall': 0.983408, 'recall_grapheme': 0.975459, 'recall_vowel': 0.991159, 'recall_consonant': 0.991556, 'acc_grapheme': 0.973781, 'acc_vowel': 0.992779, 'acc_consonant': 0.991111, 'loss_grapheme': 0.254052, 'loss_vowel': 0.217638, 'loss_consonant': 0.141786}\n",
      "  214 | 0.000037 | 016384/160678 | 0.7757 | 2.4720 |\n",
      "val: {'recall': 0.983256, 'recall_grapheme': 0.976598, 'recall_vowel': 0.990428, 'recall_consonant': 0.989401, 'acc_grapheme': 0.974304, 'acc_vowel': 0.99268, 'acc_consonant': 0.991335, 'loss_grapheme': 0.223697, 'loss_vowel': 0.184594, 'loss_consonant': 0.124389}\n",
      "  215 | 0.000039 | 061440/160678 | 1.6860 | 2.0864 |\n",
      "val: {'recall': 0.983103, 'recall_grapheme': 0.976165, 'recall_vowel': 0.990745, 'recall_consonant': 0.989335, 'acc_grapheme': 0.97418, 'acc_vowel': 0.992954, 'acc_consonant': 0.991211, 'loss_grapheme': 0.195381, 'loss_vowel': 0.145449, 'loss_consonant': 0.103642}\n",
      "  216 | 0.000040 | 106496/160678 | 1.6611 | 2.3302 |\n",
      "val: {'recall': 0.983018, 'recall_grapheme': 0.975603, 'recall_vowel': 0.990645, 'recall_consonant': 0.990218, 'acc_grapheme': 0.973682, 'acc_vowel': 0.992705, 'acc_consonant': 0.991211, 'loss_grapheme': 0.251004, 'loss_vowel': 0.20637, 'loss_consonant': 0.137945}\n",
      "  217 | 0.000039 | 151552/160678 | 1.2686 | 2.0280 |\n",
      "val: {'recall': 0.98316, 'recall_grapheme': 0.975616, 'recall_vowel': 0.990699, 'recall_consonant': 0.99071, 'acc_grapheme': 0.97413, 'acc_vowel': 0.992829, 'acc_consonant': 0.99131, 'loss_grapheme': 0.193398, 'loss_vowel': 0.142041, 'loss_consonant': 0.100185}\n",
      "  219 | 0.000037 | 036864/160678 | 2.1374 | 2.2336 |\n",
      "val: {'recall': 0.983196, 'recall_grapheme': 0.975972, 'recall_vowel': 0.990459, 'recall_consonant': 0.990383, 'acc_grapheme': 0.974005, 'acc_vowel': 0.99248, 'acc_consonant': 0.991435, 'loss_grapheme': 0.205799, 'loss_vowel': 0.174801, 'loss_consonant': 0.117862}\n",
      "  220 | 0.000034 | 081920/160678 | 3.6944 | 2.2260 |\n",
      "val: {'recall': 0.982829, 'recall_grapheme': 0.975667, 'recall_vowel': 0.990552, 'recall_consonant': 0.98943, 'acc_grapheme': 0.973856, 'acc_vowel': 0.992555, 'acc_consonant': 0.991235, 'loss_grapheme': 0.266163, 'loss_vowel': 0.214058, 'loss_consonant': 0.145334}\n",
      "  221 | 0.000030 | 126976/160678 | 1.7884 | 2.3210 |\n",
      "val: {'recall': 0.983732, 'recall_grapheme': 0.975849, 'recall_vowel': 0.991382, 'recall_consonant': 0.991848, 'acc_grapheme': 0.97403, 'acc_vowel': 0.992904, 'acc_consonant': 0.991335, 'loss_grapheme': 0.222223, 'loss_vowel': 0.176559, 'loss_consonant': 0.118735}\n",
      "  223 | 0.000026 | 012288/160678 | 2.0586 | 2.0357 |\n",
      "val: {'recall': 0.983416, 'recall_grapheme': 0.975507, 'recall_vowel': 0.991042, 'recall_consonant': 0.99161, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992829, 'acc_consonant': 0.991335, 'loss_grapheme': 0.209717, 'loss_vowel': 0.154999, 'loss_consonant': 0.108255}\n",
      "  224 | 0.000021 | 057344/160678 | 1.2314 | 2.1819 |\n",
      "val: {'recall': 0.983764, 'recall_grapheme': 0.975951, 'recall_vowel': 0.991058, 'recall_consonant': 0.992096, 'acc_grapheme': 0.974279, 'acc_vowel': 0.992879, 'acc_consonant': 0.99141, 'loss_grapheme': 0.233988, 'loss_vowel': 0.166406, 'loss_consonant': 0.127307}\n",
      "  225 | 0.000015 | 102400/160678 | 1.9771 | 2.2341 |\n",
      "val: {'recall': 0.983326, 'recall_grapheme': 0.975758, 'recall_vowel': 0.990298, 'recall_consonant': 0.991489, 'acc_grapheme': 0.974055, 'acc_vowel': 0.992655, 'acc_consonant': 0.991136, 'loss_grapheme': 0.235957, 'loss_vowel': 0.200976, 'loss_consonant': 0.128991}\n",
      "  226 | 0.000011 | 147456/160678 | 0.1699 | 2.1845 |\n",
      "val: {'recall': 0.982791, 'recall_grapheme': 0.976028, 'recall_vowel': 0.990111, 'recall_consonant': 0.988997, 'acc_grapheme': 0.974852, 'acc_vowel': 0.99253, 'acc_consonant': 0.991111, 'loss_grapheme': 0.1597, 'loss_vowel': 0.10663, 'loss_consonant': 0.080313}\n",
      "  228 | 0.000007 | 032768/160678 | 1.9419 | 2.3655 |\n",
      "val: {'recall': 0.98356, 'recall_grapheme': 0.976013, 'recall_vowel': 0.990518, 'recall_consonant': 0.991697, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992754, 'acc_consonant': 0.991385, 'loss_grapheme': 0.241088, 'loss_vowel': 0.201389, 'loss_consonant': 0.134669}\n",
      "  229 | 0.000004 | 077824/160678 | 1.1867 | 2.3384 |\n",
      "val: {'recall': 0.983392, 'recall_grapheme': 0.976196, 'recall_vowel': 0.990681, 'recall_consonant': 0.990494, 'acc_grapheme': 0.974329, 'acc_vowel': 0.992779, 'acc_consonant': 0.99131, 'loss_grapheme': 0.226363, 'loss_vowel': 0.176706, 'loss_consonant': 0.120446}\n",
      "  230 | 0.000002 | 122880/160678 | 3.8584 | 2.2553 |\n",
      "val: {'recall': 0.983489, 'recall_grapheme': 0.975889, 'recall_vowel': 0.990516, 'recall_consonant': 0.991663, 'acc_grapheme': 0.974155, 'acc_vowel': 0.992829, 'acc_consonant': 0.99131, 'loss_grapheme': 0.221573, 'loss_vowel': 0.180819, 'loss_consonant': 0.121683}\n",
      "  232 | 0.000001 | 008192/160678 | 2.9320 | 2.0534 |\n",
      "val: {'recall': 0.983534, 'recall_grapheme': 0.976222, 'recall_vowel': 0.991107, 'recall_consonant': 0.990586, 'acc_grapheme': 0.974429, 'acc_vowel': 0.993003, 'acc_consonant': 0.991335, 'loss_grapheme': 0.211595, 'loss_vowel': 0.156552, 'loss_consonant': 0.114422}\n",
      "  233 | 0.000002 | 053248/160678 | 1.4806 | 2.2841 |\n",
      "val: {'recall': 0.983818, 'recall_grapheme': 0.976388, 'recall_vowel': 0.990871, 'recall_consonant': 0.991626, 'acc_grapheme': 0.974279, 'acc_vowel': 0.992854, 'acc_consonant': 0.991435, 'loss_grapheme': 0.197342, 'loss_vowel': 0.145657, 'loss_consonant': 0.104926}\n",
      "  234 | 0.000004 | 098304/160678 | 3.3533 | 2.4652 |\n",
      "val: {'recall': 0.983665, 'recall_grapheme': 0.97649, 'recall_vowel': 0.990981, 'recall_consonant': 0.990698, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992829, 'acc_consonant': 0.991435, 'loss_grapheme': 0.219595, 'loss_vowel': 0.162806, 'loss_consonant': 0.118903}\n",
      "  235 | 0.000007 | 143360/160678 | 2.1204 | 2.1520 |\n",
      "val: {'recall': 0.983147, 'recall_grapheme': 0.975694, 'recall_vowel': 0.990761, 'recall_consonant': 0.99044, 'acc_grapheme': 0.974329, 'acc_vowel': 0.992754, 'acc_consonant': 0.99136, 'loss_grapheme': 0.222796, 'loss_vowel': 0.184126, 'loss_consonant': 0.125762}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  237 | 0.000011 | 028672/160678 | 1.7566 | 2.1513 |\n",
      "val: {'recall': 0.983431, 'recall_grapheme': 0.976164, 'recall_vowel': 0.990984, 'recall_consonant': 0.99041, 'acc_grapheme': 0.974379, 'acc_vowel': 0.992754, 'acc_consonant': 0.991435, 'loss_grapheme': 0.187703, 'loss_vowel': 0.137314, 'loss_consonant': 0.096427}\n",
      "  238 | 0.000015 | 073728/160678 | 1.9309 | 2.0376 |\n",
      "val: {'recall': 0.983448, 'recall_grapheme': 0.976286, 'recall_vowel': 0.990745, 'recall_consonant': 0.990474, 'acc_grapheme': 0.974429, 'acc_vowel': 0.992854, 'acc_consonant': 0.991509, 'loss_grapheme': 0.203835, 'loss_vowel': 0.15776, 'loss_consonant': 0.106257}\n",
      "  239 | 0.000020 | 118784/160678 | 0.6480 | 2.1948 |\n",
      "val: {'recall': 0.982903, 'recall_grapheme': 0.975394, 'recall_vowel': 0.990489, 'recall_consonant': 0.990335, 'acc_grapheme': 0.973682, 'acc_vowel': 0.992655, 'acc_consonant': 0.991285, 'loss_grapheme': 0.216014, 'loss_vowel': 0.177446, 'loss_consonant': 0.118972}\n",
      "  241 | 0.000026 | 004096/160678 | 1.0244 | 1.6120 |\n",
      "val: {'recall': 0.983151, 'recall_grapheme': 0.975881, 'recall_vowel': 0.990392, 'recall_consonant': 0.990451, 'acc_grapheme': 0.974055, 'acc_vowel': 0.99268, 'acc_consonant': 0.991385, 'loss_grapheme': 0.195855, 'loss_vowel': 0.150546, 'loss_consonant': 0.103616}\n",
      "  242 | 0.000030 | 049152/160678 | 2.6845 | 2.3602 |\n",
      "val: {'recall': 0.984069, 'recall_grapheme': 0.976412, 'recall_vowel': 0.991312, 'recall_consonant': 0.992142, 'acc_grapheme': 0.974628, 'acc_vowel': 0.992829, 'acc_consonant': 0.991385, 'loss_grapheme': 0.230671, 'loss_vowel': 0.158604, 'loss_consonant': 0.118966}\n",
      "** saved\n",
      "  243 | 0.000034 | 094208/160678 | 3.0635 | 2.4976 |\n",
      "val: {'recall': 0.98312, 'recall_grapheme': 0.975934, 'recall_vowel': 0.990911, 'recall_consonant': 0.989703, 'acc_grapheme': 0.974404, 'acc_vowel': 0.992705, 'acc_consonant': 0.991484, 'loss_grapheme': 0.245723, 'loss_vowel': 0.217518, 'loss_consonant': 0.139868}\n",
      "  244 | 0.000037 | 139264/160678 | 1.7888 | 2.2486 |\n",
      "val: {'recall': 0.983707, 'recall_grapheme': 0.975779, 'recall_vowel': 0.991328, 'recall_consonant': 0.991942, 'acc_grapheme': 0.974279, 'acc_vowel': 0.992729, 'acc_consonant': 0.991061, 'loss_grapheme': 0.293566, 'loss_vowel': 0.246141, 'loss_consonant': 0.166922}\n",
      "  246 | 0.000039 | 024576/160678 | 3.7430 | 2.4263 |\n",
      "val: {'recall': 0.983832, 'recall_grapheme': 0.976215, 'recall_vowel': 0.991253, 'recall_consonant': 0.991647, 'acc_grapheme': 0.974478, 'acc_vowel': 0.992929, 'acc_consonant': 0.991235, 'loss_grapheme': 0.258146, 'loss_vowel': 0.215908, 'loss_consonant': 0.138229}\n",
      "  247 | 0.000040 | 069632/160678 | 3.8668 | 2.3974 |\n",
      "val: {'recall': 0.98398, 'recall_grapheme': 0.97627, 'recall_vowel': 0.991476, 'recall_consonant': 0.991902, 'acc_grapheme': 0.974254, 'acc_vowel': 0.992754, 'acc_consonant': 0.991335, 'loss_grapheme': 0.270455, 'loss_vowel': 0.212422, 'loss_consonant': 0.14268}\n",
      "  248 | 0.000039 | 114688/160678 | 1.5487 | 2.2978 |\n",
      "val: {'recall': 0.982989, 'recall_grapheme': 0.975223, 'recall_vowel': 0.99084, 'recall_consonant': 0.990669, 'acc_grapheme': 0.973557, 'acc_vowel': 0.992829, 'acc_consonant': 0.991061, 'loss_grapheme': 0.23998, 'loss_vowel': 0.201137, 'loss_consonant': 0.139141}\n",
      "  249 | 0.000037 | 159744/160678 | 2.8814 | 2.0594 |\n",
      "val: {'recall': 0.983337, 'recall_grapheme': 0.975439, 'recall_vowel': 0.991114, 'recall_consonant': 0.991356, 'acc_grapheme': 0.974329, 'acc_vowel': 0.992729, 'acc_consonant': 0.991186, 'loss_grapheme': 0.203526, 'loss_vowel': 0.147332, 'loss_consonant': 0.104046}\n",
      "  251 | 0.000034 | 045056/160678 | 2.0412 | 1.8972 |\n",
      "val: {'recall': 0.982881, 'recall_grapheme': 0.975281, 'recall_vowel': 0.990838, 'recall_consonant': 0.990126, 'acc_grapheme': 0.973906, 'acc_vowel': 0.992754, 'acc_consonant': 0.991061, 'loss_grapheme': 0.20382, 'loss_vowel': 0.176839, 'loss_consonant': 0.114707}\n",
      "  252 | 0.000030 | 090112/160678 | 2.0334 | 2.2121 |\n",
      "val: {'recall': 0.983571, 'recall_grapheme': 0.97557, 'recall_vowel': 0.991104, 'recall_consonant': 0.992041, 'acc_grapheme': 0.974379, 'acc_vowel': 0.992904, 'acc_consonant': 0.99141, 'loss_grapheme': 0.2334, 'loss_vowel': 0.186679, 'loss_consonant': 0.133647}\n",
      "  253 | 0.000026 | 135168/160678 | 3.7900 | 2.2171 |\n",
      "val: {'recall': 0.983556, 'recall_grapheme': 0.975764, 'recall_vowel': 0.991162, 'recall_consonant': 0.991536, 'acc_grapheme': 0.974453, 'acc_vowel': 0.993003, 'acc_consonant': 0.991061, 'loss_grapheme': 0.216085, 'loss_vowel': 0.172102, 'loss_consonant': 0.120572}\n",
      "  255 | 0.000021 | 020480/160678 | 1.3468 | 2.5183 |\n",
      "val: {'recall': 0.983304, 'recall_grapheme': 0.975276, 'recall_vowel': 0.991025, 'recall_consonant': 0.99164, 'acc_grapheme': 0.974005, 'acc_vowel': 0.992904, 'acc_consonant': 0.99146, 'loss_grapheme': 0.244601, 'loss_vowel': 0.212471, 'loss_consonant': 0.13551}\n",
      "  256 | 0.000015 | 065536/160678 | 0.2402 | 2.3448 |\n",
      "val: {'recall': 0.983517, 'recall_grapheme': 0.975645, 'recall_vowel': 0.991295, 'recall_consonant': 0.991484, 'acc_grapheme': 0.974404, 'acc_vowel': 0.993103, 'acc_consonant': 0.991211, 'loss_grapheme': 0.179248, 'loss_vowel': 0.129979, 'loss_consonant': 0.095731}\n",
      "  257 | 0.000011 | 110592/160678 | 2.0529 | 2.0432 |\n",
      "val: {'recall': 0.982978, 'recall_grapheme': 0.975694, 'recall_vowel': 0.990516, 'recall_consonant': 0.990009, 'acc_grapheme': 0.974155, 'acc_vowel': 0.99268, 'acc_consonant': 0.991161, 'loss_grapheme': 0.186524, 'loss_vowel': 0.140668, 'loss_consonant': 0.098933}\n",
      "  258 | 0.000007 | 155648/160678 | 0.2828 | 2.1744 |\n",
      "val: {'recall': 0.983349, 'recall_grapheme': 0.975363, 'recall_vowel': 0.991289, 'recall_consonant': 0.991382, 'acc_grapheme': 0.974279, 'acc_vowel': 0.992954, 'acc_consonant': 0.991235, 'loss_grapheme': 0.188203, 'loss_vowel': 0.141381, 'loss_consonant': 0.100965}\n",
      "  260 | 0.000004 | 040960/160678 | 0.6289 | 2.2095 |\n",
      "val: {'recall': 0.983985, 'recall_grapheme': 0.976481, 'recall_vowel': 0.991379, 'recall_consonant': 0.991598, 'acc_grapheme': 0.975101, 'acc_vowel': 0.992978, 'acc_consonant': 0.991285, 'loss_grapheme': 0.191211, 'loss_vowel': 0.128157, 'loss_consonant': 0.095251}\n",
      "  261 | 0.000002 | 086016/160678 | 1.3354 | 2.2329 |\n",
      "val: {'recall': 0.983361, 'recall_grapheme': 0.975622, 'recall_vowel': 0.990888, 'recall_consonant': 0.99131, 'acc_grapheme': 0.974379, 'acc_vowel': 0.992954, 'acc_consonant': 0.99126, 'loss_grapheme': 0.189188, 'loss_vowel': 0.137148, 'loss_consonant': 0.099199}\n",
      "  262 | 0.000001 | 131072/160678 | 1.9016 | 2.0939 |\n",
      "val: {'recall': 0.983478, 'recall_grapheme': 0.975352, 'recall_vowel': 0.991502, 'recall_consonant': 0.991706, 'acc_grapheme': 0.974329, 'acc_vowel': 0.993053, 'acc_consonant': 0.99146, 'loss_grapheme': 0.20264, 'loss_vowel': 0.154536, 'loss_consonant': 0.107797}\n",
      "  264 | 0.000002 | 016384/160678 | 1.4224 | 2.0590 |\n",
      "val: {'recall': 0.983894, 'recall_grapheme': 0.976034, 'recall_vowel': 0.99165, 'recall_consonant': 0.991859, 'acc_grapheme': 0.974329, 'acc_vowel': 0.993053, 'acc_consonant': 0.991435, 'loss_grapheme': 0.211796, 'loss_vowel': 0.159236, 'loss_consonant': 0.111491}\n",
      "  265 | 0.000004 | 061440/160678 | 0.7596 | 1.9469 |\n",
      "val: {'recall': 0.982945, 'recall_grapheme': 0.975693, 'recall_vowel': 0.990343, 'recall_consonant': 0.990053, 'acc_grapheme': 0.973931, 'acc_vowel': 0.992555, 'acc_consonant': 0.991061, 'loss_grapheme': 0.1857, 'loss_vowel': 0.14314, 'loss_consonant': 0.1}\n",
      "  266 | 0.000007 | 106496/160678 | 0.9410 | 2.2460 |\n",
      "val: {'recall': 0.984149, 'recall_grapheme': 0.976535, 'recall_vowel': 0.991681, 'recall_consonant': 0.991847, 'acc_grapheme': 0.974453, 'acc_vowel': 0.993103, 'acc_consonant': 0.991186, 'loss_grapheme': 0.255056, 'loss_vowel': 0.188996, 'loss_consonant': 0.137575}\n",
      "** saved\n",
      "  267 | 0.000011 | 151552/160678 | 2.1281 | 2.1897 |\n",
      "val: {'recall': 0.983399, 'recall_grapheme': 0.976291, 'recall_vowel': 0.990795, 'recall_consonant': 0.99022, 'acc_grapheme': 0.974678, 'acc_vowel': 0.992804, 'acc_consonant': 0.991211, 'loss_grapheme': 0.211783, 'loss_vowel': 0.17203, 'loss_consonant': 0.116885}\n",
      "  269 | 0.000015 | 036864/160678 | 2.5539 | 2.0915 |\n",
      "val: {'recall': 0.983083, 'recall_grapheme': 0.975726, 'recall_vowel': 0.990395, 'recall_consonant': 0.990486, 'acc_grapheme': 0.974478, 'acc_vowel': 0.992705, 'acc_consonant': 0.99131, 'loss_grapheme': 0.193072, 'loss_vowel': 0.153247, 'loss_consonant': 0.103615}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  270 | 0.000021 | 081920/160678 | 2.0218 | 2.2593 |\n",
      "val: {'recall': 0.983335, 'recall_grapheme': 0.975043, 'recall_vowel': 0.991614, 'recall_consonant': 0.991639, 'acc_grapheme': 0.974005, 'acc_vowel': 0.993078, 'acc_consonant': 0.991335, 'loss_grapheme': 0.222014, 'loss_vowel': 0.173602, 'loss_consonant': 0.124221}\n",
      "  271 | 0.000026 | 126976/160678 | 1.7406 | 2.1598 |\n",
      "val: {'recall': 0.983128, 'recall_grapheme': 0.974962, 'recall_vowel': 0.991236, 'recall_consonant': 0.991352, 'acc_grapheme': 0.974453, 'acc_vowel': 0.992879, 'acc_consonant': 0.991285, 'loss_grapheme': 0.19939, 'loss_vowel': 0.160041, 'loss_consonant': 0.110777}\n",
      "  273 | 0.000030 | 012288/160678 | 0.7693 | 2.3012 |\n",
      "val: {'recall': 0.984254, 'recall_grapheme': 0.976814, 'recall_vowel': 0.991676, 'recall_consonant': 0.99171, 'acc_grapheme': 0.974528, 'acc_vowel': 0.992978, 'acc_consonant': 0.991435, 'loss_grapheme': 0.214347, 'loss_vowel': 0.149057, 'loss_consonant': 0.108816}\n",
      "** saved\n",
      "  274 | 0.000034 | 057344/160678 | 4.5033 | 2.3136 |\n",
      "val: {'recall': 0.983632, 'recall_grapheme': 0.975545, 'recall_vowel': 0.991596, 'recall_consonant': 0.991843, 'acc_grapheme': 0.974229, 'acc_vowel': 0.992829, 'acc_consonant': 0.991136, 'loss_grapheme': 0.292645, 'loss_vowel': 0.215999, 'loss_consonant': 0.158905}\n",
      "  275 | 0.000037 | 102400/160678 | 2.0323 | 2.0877 |\n",
      "val: {'recall': 0.982696, 'recall_grapheme': 0.974638, 'recall_vowel': 0.991033, 'recall_consonant': 0.990473, 'acc_grapheme': 0.973806, 'acc_vowel': 0.992804, 'acc_consonant': 0.99136, 'loss_grapheme': 0.230023, 'loss_vowel': 0.191289, 'loss_consonant': 0.128917}\n",
      "  276 | 0.000039 | 147456/160678 | 1.9659 | 2.2492 |\n",
      "val: {'recall': 0.983206, 'recall_grapheme': 0.975287, 'recall_vowel': 0.991282, 'recall_consonant': 0.990966, 'acc_grapheme': 0.973831, 'acc_vowel': 0.992954, 'acc_consonant': 0.991559, 'loss_grapheme': 0.243172, 'loss_vowel': 0.168861, 'loss_consonant': 0.121849}\n",
      "  278 | 0.000040 | 032768/160678 | 4.3014 | 2.2984 |\n",
      "val: {'recall': 0.983367, 'recall_grapheme': 0.975327, 'recall_vowel': 0.991075, 'recall_consonant': 0.991738, 'acc_grapheme': 0.974453, 'acc_vowel': 0.992854, 'acc_consonant': 0.991559, 'loss_grapheme': 0.222553, 'loss_vowel': 0.181733, 'loss_consonant': 0.123969}\n",
      "  279 | 0.000039 | 077824/160678 | 3.5473 | 2.0834 |\n",
      "val: {'recall': 0.983008, 'recall_grapheme': 0.975438, 'recall_vowel': 0.990539, 'recall_consonant': 0.990619, 'acc_grapheme': 0.974279, 'acc_vowel': 0.992655, 'acc_consonant': 0.991186, 'loss_grapheme': 0.198208, 'loss_vowel': 0.150733, 'loss_consonant': 0.1063}\n",
      "  280 | 0.000037 | 122880/160678 | 1.3162 | 2.2009 |\n",
      "val: {'recall': 0.982837, 'recall_grapheme': 0.974559, 'recall_vowel': 0.990866, 'recall_consonant': 0.991365, 'acc_grapheme': 0.973731, 'acc_vowel': 0.992829, 'acc_consonant': 0.991136, 'loss_grapheme': 0.217816, 'loss_vowel': 0.176074, 'loss_consonant': 0.123517}\n",
      "  282 | 0.000034 | 008192/160678 | 3.1389 | 2.6500 |\n",
      "val: {'recall': 0.983289, 'recall_grapheme': 0.975037, 'recall_vowel': 0.990895, 'recall_consonant': 0.992188, 'acc_grapheme': 0.974279, 'acc_vowel': 0.992954, 'acc_consonant': 0.991186, 'loss_grapheme': 0.257318, 'loss_vowel': 0.218206, 'loss_consonant': 0.155191}\n",
      "  283 | 0.000030 | 053248/160678 | 2.0952 | 2.3463 |\n",
      "val: {'recall': 0.983158, 'recall_grapheme': 0.975018, 'recall_vowel': 0.990763, 'recall_consonant': 0.991834, 'acc_grapheme': 0.973557, 'acc_vowel': 0.992729, 'acc_consonant': 0.99131, 'loss_grapheme': 0.264496, 'loss_vowel': 0.214081, 'loss_consonant': 0.15089}\n",
      "  284 | 0.000026 | 098304/160678 | 4.2878 | 2.0215 |\n",
      "val: {'recall': 0.983516, 'recall_grapheme': 0.975511, 'recall_vowel': 0.991138, 'recall_consonant': 0.991904, 'acc_grapheme': 0.97408, 'acc_vowel': 0.992954, 'acc_consonant': 0.991385, 'loss_grapheme': 0.247532, 'loss_vowel': 0.204605, 'loss_consonant': 0.138109}\n",
      "  285 | 0.000021 | 143360/160678 | 4.2005 | 2.3111 |\n",
      "val: {'recall': 0.982774, 'recall_grapheme': 0.974432, 'recall_vowel': 0.99065, 'recall_consonant': 0.991581, 'acc_grapheme': 0.973955, 'acc_vowel': 0.992779, 'acc_consonant': 0.99136, 'loss_grapheme': 0.219854, 'loss_vowel': 0.184055, 'loss_consonant': 0.123197}\n",
      "  287 | 0.000015 | 028672/160678 | 2.4904 | 2.3982 |\n",
      "val: {'recall': 0.983449, 'recall_grapheme': 0.975408, 'recall_vowel': 0.991223, 'recall_consonant': 0.991759, 'acc_grapheme': 0.974304, 'acc_vowel': 0.993178, 'acc_consonant': 0.991484, 'loss_grapheme': 0.232736, 'loss_vowel': 0.176518, 'loss_consonant': 0.12325}\n",
      "  288 | 0.000011 | 073728/160678 | 3.7965 | 2.2663 |\n",
      "val: {'recall': 0.983197, 'recall_grapheme': 0.975199, 'recall_vowel': 0.991104, 'recall_consonant': 0.991287, 'acc_grapheme': 0.974279, 'acc_vowel': 0.993028, 'acc_consonant': 0.99126, 'loss_grapheme': 0.213415, 'loss_vowel': 0.171499, 'loss_consonant': 0.118826}\n",
      "  289 | 0.000007 | 118784/160678 | 1.9257 | 2.2686 |\n",
      "val: {'recall': 0.982755, 'recall_grapheme': 0.975156, 'recall_vowel': 0.990696, 'recall_consonant': 0.990011, 'acc_grapheme': 0.97403, 'acc_vowel': 0.992804, 'acc_consonant': 0.99131, 'loss_grapheme': 0.198193, 'loss_vowel': 0.155296, 'loss_consonant': 0.107871}\n",
      "  291 | 0.000004 | 004096/160678 | 1.9908 | 1.7721 |\n",
      "val: {'recall': 0.982708, 'recall_grapheme': 0.974906, 'recall_vowel': 0.990441, 'recall_consonant': 0.990578, 'acc_grapheme': 0.974005, 'acc_vowel': 0.99253, 'acc_consonant': 0.991484, 'loss_grapheme': 0.23809, 'loss_vowel': 0.206903, 'loss_consonant': 0.138051}\n",
      "  292 | 0.000002 | 049152/160678 | 0.8453 | 2.3625 |\n",
      "val: {'recall': 0.983839, 'recall_grapheme': 0.976001, 'recall_vowel': 0.991544, 'recall_consonant': 0.991811, 'acc_grapheme': 0.974279, 'acc_vowel': 0.993203, 'acc_consonant': 0.991609, 'loss_grapheme': 0.237487, 'loss_vowel': 0.179143, 'loss_consonant': 0.128098}\n",
      "  293 | 0.000001 | 094208/160678 | 1.0271 | 2.0489 |\n",
      "val: {'recall': 0.983463, 'recall_grapheme': 0.975207, 'recall_vowel': 0.991525, 'recall_consonant': 0.991912, 'acc_grapheme': 0.974155, 'acc_vowel': 0.993153, 'acc_consonant': 0.991783, 'loss_grapheme': 0.212221, 'loss_vowel': 0.158393, 'loss_consonant': 0.114302}\n",
      "  294 | 0.000002 | 139264/160678 | 0.5916 | 2.2301 |\n",
      "val: {'recall': 0.983981, 'recall_grapheme': 0.976063, 'recall_vowel': 0.991926, 'recall_consonant': 0.99187, 'acc_grapheme': 0.974653, 'acc_vowel': 0.993128, 'acc_consonant': 0.991385, 'loss_grapheme': 0.245679, 'loss_vowel': 0.175318, 'loss_consonant': 0.128755}\n",
      "  296 | 0.000004 | 024576/160678 | 2.6810 | 2.0241 |\n",
      "val: {'recall': 0.983229, 'recall_grapheme': 0.974869, 'recall_vowel': 0.991523, 'recall_consonant': 0.991653, 'acc_grapheme': 0.974105, 'acc_vowel': 0.993227, 'acc_consonant': 0.991659, 'loss_grapheme': 0.210078, 'loss_vowel': 0.159127, 'loss_consonant': 0.112249}\n",
      "  297 | 0.000007 | 069632/160678 | 2.0036 | 1.9235 |\n",
      "val: {'recall': 0.982926, 'recall_grapheme': 0.975261, 'recall_vowel': 0.990654, 'recall_consonant': 0.990526, 'acc_grapheme': 0.974105, 'acc_vowel': 0.992705, 'acc_consonant': 0.991634, 'loss_grapheme': 0.190192, 'loss_vowel': 0.147457, 'loss_consonant': 0.105814}\n",
      "  298 | 0.000011 | 114688/160678 | 2.8609 | 2.1386 |\n",
      "val: {'recall': 0.983679, 'recall_grapheme': 0.975721, 'recall_vowel': 0.991077, 'recall_consonant': 0.992196, 'acc_grapheme': 0.974678, 'acc_vowel': 0.993078, 'acc_consonant': 0.991858, 'loss_grapheme': 0.228974, 'loss_vowel': 0.183406, 'loss_consonant': 0.126021}\n",
      "  299 | 0.000015 | 159744/160678 | 0.8375 | 2.1510 |\n",
      "val: {'recall': 0.983319, 'recall_grapheme': 0.975377, 'recall_vowel': 0.991154, 'recall_consonant': 0.991368, 'acc_grapheme': 0.974553, 'acc_vowel': 0.993078, 'acc_consonant': 0.99146, 'loss_grapheme': 0.186918, 'loss_vowel': 0.139286, 'loss_consonant': 0.099678}\n",
      "  301 | 0.000020 | 045056/160678 | 1.3948 | 2.3176 |\n",
      "val: {'recall': 0.982858, 'recall_grapheme': 0.975126, 'recall_vowel': 0.990731, 'recall_consonant': 0.990452, 'acc_grapheme': 0.974379, 'acc_vowel': 0.992829, 'acc_consonant': 0.991385, 'loss_grapheme': 0.204008, 'loss_vowel': 0.167008, 'loss_consonant': 0.111242}\n",
      "  302 | 0.000026 | 090112/160678 | 2.7173 | 2.3787 |\n",
      "val: {'recall': 0.983072, 'recall_grapheme': 0.974942, 'recall_vowel': 0.990661, 'recall_consonant': 0.991743, 'acc_grapheme': 0.973756, 'acc_vowel': 0.992929, 'acc_consonant': 0.99146, 'loss_grapheme': 0.222089, 'loss_vowel': 0.167836, 'loss_consonant': 0.117427}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  303 | 0.000030 | 135168/160678 | 0.9878 | 2.2201 |\n",
      "val: {'recall': 0.983684, 'recall_grapheme': 0.975709, 'recall_vowel': 0.991264, 'recall_consonant': 0.992053, 'acc_grapheme': 0.974379, 'acc_vowel': 0.993078, 'acc_consonant': 0.991385, 'loss_grapheme': 0.240206, 'loss_vowel': 0.184247, 'loss_consonant': 0.133195}\n",
      "  305 | 0.000034 | 020480/160678 | 1.7379 | 2.2473 |\n",
      "val: {'recall': 0.982881, 'recall_grapheme': 0.975303, 'recall_vowel': 0.990729, 'recall_consonant': 0.990192, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992655, 'acc_consonant': 0.991435, 'loss_grapheme': 0.207132, 'loss_vowel': 0.165091, 'loss_consonant': 0.114362}\n",
      "  306 | 0.000037 | 065536/160678 | 1.5356 | 1.9651 |\n",
      "val: {'recall': 0.983431, 'recall_grapheme': 0.976016, 'recall_vowel': 0.991293, 'recall_consonant': 0.990399, 'acc_grapheme': 0.974503, 'acc_vowel': 0.992954, 'acc_consonant': 0.991385, 'loss_grapheme': 0.192663, 'loss_vowel': 0.134286, 'loss_consonant': 0.096645}\n",
      "  307 | 0.000039 | 110592/160678 | 0.5308 | 2.1619 |\n",
      "val: {'recall': 0.983633, 'recall_grapheme': 0.976168, 'recall_vowel': 0.991326, 'recall_consonant': 0.990871, 'acc_grapheme': 0.974304, 'acc_vowel': 0.993153, 'acc_consonant': 0.99146, 'loss_grapheme': 0.229175, 'loss_vowel': 0.163416, 'loss_consonant': 0.117431}\n",
      "  308 | 0.000040 | 155648/160678 | 2.2059 | 2.1067 |\n",
      "val: {'recall': 0.983388, 'recall_grapheme': 0.975326, 'recall_vowel': 0.991296, 'recall_consonant': 0.991603, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992929, 'acc_consonant': 0.991484, 'loss_grapheme': 0.237874, 'loss_vowel': 0.185588, 'loss_consonant': 0.13149}\n",
      "  310 | 0.000039 | 040960/160678 | 3.0131 | 2.1724 |\n",
      "val: {'recall': 0.983338, 'recall_grapheme': 0.975613, 'recall_vowel': 0.990933, 'recall_consonant': 0.991193, 'acc_grapheme': 0.97418, 'acc_vowel': 0.992978, 'acc_consonant': 0.991335, 'loss_grapheme': 0.227589, 'loss_vowel': 0.175485, 'loss_consonant': 0.122821}\n",
      "  311 | 0.000037 | 086016/160678 | 1.8903 | 2.2430 |\n",
      "val: {'recall': 0.982724, 'recall_grapheme': 0.97528, 'recall_vowel': 0.990881, 'recall_consonant': 0.989455, 'acc_grapheme': 0.974279, 'acc_vowel': 0.99263, 'acc_consonant': 0.991235, 'loss_grapheme': 0.205581, 'loss_vowel': 0.153863, 'loss_consonant': 0.111517}\n",
      "  312 | 0.000034 | 131072/160678 | 1.5227 | 1.9957 |\n",
      "val: {'recall': 0.982621, 'recall_grapheme': 0.97459, 'recall_vowel': 0.991363, 'recall_consonant': 0.989942, 'acc_grapheme': 0.973806, 'acc_vowel': 0.992779, 'acc_consonant': 0.99131, 'loss_grapheme': 0.197599, 'loss_vowel': 0.156556, 'loss_consonant': 0.106663}\n",
      "  314 | 0.000030 | 016384/160678 | 1.9301 | 2.2628 |\n",
      "val: {'recall': 0.983574, 'recall_grapheme': 0.975569, 'recall_vowel': 0.99161, 'recall_consonant': 0.991548, 'acc_grapheme': 0.974354, 'acc_vowel': 0.993153, 'acc_consonant': 0.99146, 'loss_grapheme': 0.250675, 'loss_vowel': 0.177464, 'loss_consonant': 0.130014}\n",
      "  315 | 0.000026 | 061440/160678 | 1.8952 | 2.1222 |\n",
      "val: {'recall': 0.982189, 'recall_grapheme': 0.975206, 'recall_vowel': 0.990482, 'recall_consonant': 0.987862, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992555, 'acc_consonant': 0.991136, 'loss_grapheme': 0.195251, 'loss_vowel': 0.126652, 'loss_consonant': 0.106683}\n",
      "  316 | 0.000021 | 106496/160678 | 1.8892 | 1.9540 |\n",
      "val: {'recall': 0.983266, 'recall_grapheme': 0.975441, 'recall_vowel': 0.991523, 'recall_consonant': 0.990661, 'acc_grapheme': 0.974279, 'acc_vowel': 0.993252, 'acc_consonant': 0.991509, 'loss_grapheme': 0.184401, 'loss_vowel': 0.129223, 'loss_consonant': 0.090984}\n",
      "  317 | 0.000015 | 151552/160678 | 2.0208 | 2.2542 |\n",
      "val: {'recall': 0.983432, 'recall_grapheme': 0.975554, 'recall_vowel': 0.991207, 'recall_consonant': 0.991412, 'acc_grapheme': 0.974155, 'acc_vowel': 0.993053, 'acc_consonant': 0.99146, 'loss_grapheme': 0.226248, 'loss_vowel': 0.17656, 'loss_consonant': 0.120082}\n",
      "  317 | 0.000011 | 157696/160678 | 1.9686 | 2.2264 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-813ae6dcb078>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.051099, 'recall_grapheme': 0.000989, 'recall_vowel': 0.088401, 'recall_consonant': 0.114016, 'acc_grapheme': 0.00371, 'acc_vowel': 0.109706, 'acc_consonant': 0.367138, 'loss_grapheme': 5.189187, 'loss_vowel': 2.427056, 'loss_consonant': 1.819271}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.002000 | 045056/160678 | 1.3201 | 3.3993 |\n",
      "val: {'recall': 0.924224, 'recall_grapheme': 0.907742, 'recall_vowel': 0.940068, 'recall_consonant': 0.941345, 'acc_grapheme': 0.879164, 'acc_vowel': 0.939271, 'acc_consonant': 0.954086, 'loss_grapheme': 0.769752, 'loss_vowel': 0.467442, 'loss_consonant': 0.276683}\n",
      "** saved\n",
      "    2 | 0.002000 | 090112/160678 | 1.4723 | 3.8490 |\n",
      "val: {'recall': 0.946836, 'recall_grapheme': 0.922803, 'recall_vowel': 0.971076, 'recall_consonant': 0.970662, 'acc_grapheme': 0.90613, 'acc_vowel': 0.962925, 'acc_consonant': 0.960112, 'loss_grapheme': 1.044443, 'loss_vowel': 0.359403, 'loss_consonant': 0.220015}\n",
      "** saved\n",
      "    3 | 0.002000 | 135168/160678 | 4.2459 | 3.7544 |\n",
      "val: {'recall': 0.949923, 'recall_grapheme': 0.926272, 'recall_vowel': 0.970635, 'recall_consonant': 0.976511, 'acc_grapheme': 0.909641, 'acc_vowel': 0.952243, 'acc_consonant': 0.93815, 'loss_grapheme': 0.689081, 'loss_vowel': 0.414539, 'loss_consonant': 0.269692}\n",
      "** saved\n",
      "    5 | 0.002000 | 020480/160678 | 2.8932 | 3.0387 |\n",
      "val: {'recall': 0.964789, 'recall_grapheme': 0.946605, 'recall_vowel': 0.982219, 'recall_consonant': 0.983724, 'acc_grapheme': 0.94328, 'acc_vowel': 0.983293, 'acc_consonant': 0.981102, 'loss_grapheme': 0.349244, 'loss_vowel': 0.1842, 'loss_consonant': 0.13301}\n",
      "** saved\n",
      "    6 | 0.002000 | 065536/160678 | 5.2102 | 3.0704 |\n",
      "val: {'recall': 0.966901, 'recall_grapheme': 0.954109, 'recall_vowel': 0.978149, 'recall_consonant': 0.981239, 'acc_grapheme': 0.951422, 'acc_vowel': 0.975599, 'acc_consonant': 0.980429, 'loss_grapheme': 0.4113, 'loss_vowel': 0.293947, 'loss_consonant': 0.158847}\n",
      "** saved\n",
      "    7 | 0.002000 | 110592/160678 | 3.7610 | 3.0907 |\n",
      "val: {'recall': 0.971357, 'recall_grapheme': 0.956326, 'recall_vowel': 0.984452, 'recall_consonant': 0.988325, 'acc_grapheme': 0.951895, 'acc_vowel': 0.985708, 'acc_consonant': 0.982521, 'loss_grapheme': 0.438426, 'loss_vowel': 0.292416, 'loss_consonant': 0.188106}\n",
      "** saved\n",
      "    8 | 0.002000 | 155648/160678 | 0.8879 | 2.9938 |\n",
      "val: {'recall': 0.975169, 'recall_grapheme': 0.963081, 'recall_vowel': 0.986583, 'recall_consonant': 0.987931, 'acc_grapheme': 0.959738, 'acc_vowel': 0.987625, 'acc_consonant': 0.986405, 'loss_grapheme': 0.282095, 'loss_vowel': 0.225256, 'loss_consonant': 0.148973}\n",
      "** saved\n",
      "   10 | 0.002000 | 040960/160678 | 2.7892 | 2.2259 |\n",
      "val: {'recall': 0.976345, 'recall_grapheme': 0.96522, 'recall_vowel': 0.986668, 'recall_consonant': 0.988272, 'acc_grapheme': 0.960186, 'acc_vowel': 0.986953, 'acc_consonant': 0.985982, 'loss_grapheme': 0.272368, 'loss_vowel': 0.216155, 'loss_consonant': 0.115443}\n",
      "** saved\n",
      "   11 | 0.002000 | 086016/160678 | 4.7057 | 2.7144 |\n",
      "val: {'recall': 0.976539, 'recall_grapheme': 0.965101, 'recall_vowel': 0.98685, 'recall_consonant': 0.989107, 'acc_grapheme': 0.962128, 'acc_vowel': 0.986779, 'acc_consonant': 0.98516, 'loss_grapheme': 0.39537, 'loss_vowel': 0.2842, 'loss_consonant': 0.1622}\n",
      "** saved\n",
      "   12 | 0.002000 | 131072/160678 | 2.4814 | 2.8326 |\n",
      "val: {'recall': 0.974591, 'recall_grapheme': 0.963813, 'recall_vowel': 0.983607, 'recall_consonant': 0.98713, 'acc_grapheme': 0.958767, 'acc_vowel': 0.986355, 'acc_consonant': 0.984961, 'loss_grapheme': 0.280754, 'loss_vowel': 0.202055, 'loss_consonant': 0.134624}\n",
      "   14 | 0.000200 | 016384/160678 | 2.4913 | 2.3965 |\n",
      "val: {'recall': 0.980716, 'recall_grapheme': 0.972155, 'recall_vowel': 0.988304, 'recall_consonant': 0.990248, 'acc_grapheme': 0.969872, 'acc_vowel': 0.990364, 'acc_consonant': 0.988671, 'loss_grapheme': 0.290521, 'loss_vowel': 0.227481, 'loss_consonant': 0.149197}\n",
      "** saved\n",
      "   15 | 0.000200 | 061440/160678 | 1.8742 | 2.5318 |\n",
      "val: {'recall': 0.981156, 'recall_grapheme': 0.972757, 'recall_vowel': 0.988438, 'recall_consonant': 0.990671, 'acc_grapheme': 0.970021, 'acc_vowel': 0.990439, 'acc_consonant': 0.989169, 'loss_grapheme': 0.309467, 'loss_vowel': 0.254322, 'loss_consonant': 0.151698}\n",
      "** saved\n",
      "   16 | 0.000200 | 106496/160678 | 3.7756 | 2.6484 |\n",
      "val: {'recall': 0.981502, 'recall_grapheme': 0.972953, 'recall_vowel': 0.988852, 'recall_consonant': 0.991249, 'acc_grapheme': 0.970569, 'acc_vowel': 0.990563, 'acc_consonant': 0.988945, 'loss_grapheme': 0.282333, 'loss_vowel': 0.223487, 'loss_consonant': 0.143323}\n",
      "** saved\n",
      "   17 | 0.000200 | 151552/160678 | 3.0331 | 2.3753 |\n",
      "val: {'recall': 0.98179, 'recall_grapheme': 0.973435, 'recall_vowel': 0.989282, 'recall_consonant': 0.991006, 'acc_grapheme': 0.970893, 'acc_vowel': 0.990688, 'acc_consonant': 0.990065, 'loss_grapheme': 0.285643, 'loss_vowel': 0.232334, 'loss_consonant': 0.140227}\n",
      "** saved\n",
      "   19 | 0.000200 | 036864/160678 | 1.6191 | 2.3945 |\n",
      "val: {'recall': 0.982122, 'recall_grapheme': 0.974196, 'recall_vowel': 0.98896, 'recall_consonant': 0.991135, 'acc_grapheme': 0.972188, 'acc_vowel': 0.991136, 'acc_consonant': 0.989368, 'loss_grapheme': 0.255028, 'loss_vowel': 0.198349, 'loss_consonant': 0.125435}\n",
      "** saved\n",
      "   20 | 0.000200 | 081920/160678 | 1.3688 | 2.2687 |\n",
      "val: {'recall': 0.982854, 'recall_grapheme': 0.974916, 'recall_vowel': 0.990399, 'recall_consonant': 0.991183, 'acc_grapheme': 0.972636, 'acc_vowel': 0.991509, 'acc_consonant': 0.989841, 'loss_grapheme': 0.197706, 'loss_vowel': 0.15255, 'loss_consonant': 0.100258}\n",
      "** saved\n",
      "   21 | 0.000200 | 126976/160678 | 2.4794 | 2.6110 |\n",
      "val: {'recall': 0.982487, 'recall_grapheme': 0.974437, 'recall_vowel': 0.989978, 'recall_consonant': 0.991096, 'acc_grapheme': 0.971964, 'acc_vowel': 0.991385, 'acc_consonant': 0.989717, 'loss_grapheme': 0.279855, 'loss_vowel': 0.248361, 'loss_consonant': 0.149239}\n",
      "   23 | 0.000020 | 012288/160678 | 3.6290 | 2.4268 |\n",
      "val: {'recall': 0.982986, 'recall_grapheme': 0.97541, 'recall_vowel': 0.990209, 'recall_consonant': 0.990916, 'acc_grapheme': 0.972561, 'acc_vowel': 0.991659, 'acc_consonant': 0.989567, 'loss_grapheme': 0.268893, 'loss_vowel': 0.21238, 'loss_consonant': 0.136874}\n",
      "** saved\n",
      "   24 | 0.000020 | 057344/160678 | 1.3199 | 2.5452 |\n",
      "val: {'recall': 0.983237, 'recall_grapheme': 0.975663, 'recall_vowel': 0.99051, 'recall_consonant': 0.991113, 'acc_grapheme': 0.973308, 'acc_vowel': 0.991982, 'acc_consonant': 0.99004, 'loss_grapheme': 0.261584, 'loss_vowel': 0.206993, 'loss_consonant': 0.131908}\n",
      "** saved\n",
      "   25 | 0.000020 | 102400/160678 | 3.7092 | 2.7187 |\n",
      "val: {'recall': 0.982972, 'recall_grapheme': 0.97539, 'recall_vowel': 0.990034, 'recall_consonant': 0.991072, 'acc_grapheme': 0.97296, 'acc_vowel': 0.991709, 'acc_consonant': 0.989891, 'loss_grapheme': 0.278642, 'loss_vowel': 0.222642, 'loss_consonant': 0.142004}\n",
      "   26 | 0.000010 | 147456/160678 | 2.2591 | 2.4441 |\n",
      "val: {'recall': 0.983267, 'recall_grapheme': 0.975674, 'recall_vowel': 0.990152, 'recall_consonant': 0.991568, 'acc_grapheme': 0.972711, 'acc_vowel': 0.991733, 'acc_consonant': 0.989617, 'loss_grapheme': 0.305606, 'loss_vowel': 0.252759, 'loss_consonant': 0.162607}\n",
      "** saved\n",
      "   28 | 0.000010 | 032768/160678 | 3.3505 | 2.6368 |\n",
      "val: {'recall': 0.983242, 'recall_grapheme': 0.975525, 'recall_vowel': 0.990361, 'recall_consonant': 0.991556, 'acc_grapheme': 0.972486, 'acc_vowel': 0.991733, 'acc_consonant': 0.989841, 'loss_grapheme': 0.328635, 'loss_vowel': 0.273679, 'loss_consonant': 0.170533}\n",
      "   29 | 0.000010 | 077824/160678 | 1.6584 | 2.3168 |\n",
      "val: {'recall': 0.983237, 'recall_grapheme': 0.97576, 'recall_vowel': 0.990334, 'recall_consonant': 0.991095, 'acc_grapheme': 0.973433, 'acc_vowel': 0.991958, 'acc_consonant': 0.990165, 'loss_grapheme': 0.19515, 'loss_vowel': 0.141327, 'loss_consonant': 0.09988}\n",
      "   33 | 0.000010 | 053248/160678 | 2.8452 | 2.4918 |\n",
      "val: {'recall': 0.982927, 'recall_grapheme': 0.975398, 'recall_vowel': 0.989962, 'recall_consonant': 0.990949, 'acc_grapheme': 0.973084, 'acc_vowel': 0.991858, 'acc_consonant': 0.99004, 'loss_grapheme': 0.23522, 'loss_vowel': 0.186508, 'loss_consonant': 0.119693}\n",
      "   34 | 0.000010 | 098304/160678 | 1.9898 | 2.5472 |\n",
      "val: {'recall': 0.982908, 'recall_grapheme': 0.975282, 'recall_vowel': 0.990083, 'recall_consonant': 0.990986, 'acc_grapheme': 0.97281, 'acc_vowel': 0.991858, 'acc_consonant': 0.989991, 'loss_grapheme': 0.242885, 'loss_vowel': 0.188053, 'loss_consonant': 0.121778}\n",
      "   35 | 0.000010 | 143360/160678 | 0.5553 | 2.2703 |\n",
      "val: {'recall': 0.982778, 'recall_grapheme': 0.975176, 'recall_vowel': 0.989907, 'recall_consonant': 0.990855, 'acc_grapheme': 0.972935, 'acc_vowel': 0.991758, 'acc_consonant': 0.990015, 'loss_grapheme': 0.229537, 'loss_vowel': 0.182932, 'loss_consonant': 0.115055}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000010 | 159744/160678 | 0.7214 | 2.2880 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-813ae6dcb078>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mtrain_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
