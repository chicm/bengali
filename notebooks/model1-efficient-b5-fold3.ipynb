{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class PlainRAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "        super(PlainRAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PlainRAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                beta2_t = beta2 ** state['step']\n",
    "                N_sma_max = 2 / (1 - beta2) - 1\n",
    "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:                    \n",
    "                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, warmup = warmup)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AdamW, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                \n",
    "                if group['warmup'] > state['step']:\n",
    "                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n",
    "                else:\n",
    "                    scheduled_lr = group['lr']\n",
    "\n",
    "                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n",
    "                \n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n",
    "\n",
    "                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install opencv-python\\n!pip install fastparquet\\n!pip install pyarrow\\n!pip install snappy\\n!conda install python-snappy -y\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install opencv-python\n",
    "!pip install fastparquet\n",
    "!pip install pyarrow\n",
    "!pip install snappy\n",
    "!conda install python-snappy -y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/mnt/chicm/data/bengali': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor img, y in train_loader:\\n    print(img.size(), y.size())\\n    print(y)\\n    #print(img)\\n    #plt.imshow(img.squeeze()[0].numpy())\\n    break\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for img, y in train_loader:\n",
    "    print(img.size(), y.size())\n",
    "    print(y)\n",
    "    #print(img)\n",
    "    #plt.imshow(img.squeeze()[0].numpy())\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nargs = Namespace()\\nargs.backbone = 'se_resnext50_32x4d'\\nargs.ckp_name = 'best_model.pth'\\nargs.predict = False\\n\\nbnet = create_model(args)[0].cuda()\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "\n",
    "bnet = create_model(args)[0].cuda()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum().item()\n",
    "        res.append(correct_k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23429200577078846"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                #img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                #loss = mixup_criterion(outputs, targets)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'efficientnet-b5'\n",
    "args.ckp_name = 'model1-efficientnet-b5-fold3.pth'\n",
    "args.predict = False\n",
    "args.optim = 'RAdam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 512\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160716, 5) (40124, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "model file: ./models/efficientnet-b5/model1-efficientnet-b5-fold3.pth, exist: True\n",
      "loading ./models/efficientnet-b5/model1-efficientnet-b5-fold3.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.972502, 'recall_grapheme': 0.958517, 'recall_vowel': 0.98564, 'recall_consonant': 0.987333, 'acc_grapheme': 0.954715, 'acc_vowel': 0.985819, 'acc_consonant': 0.984947, 'loss_grapheme': 0.351261, 'loss_vowel': 0.206123, 'loss_consonant': 0.148548}\n",
      "    0 | 0.000020 | 102400/160716 | 4.2182 | 2.1066 |\n",
      "val: {'recall': 0.971282, 'recall_grapheme': 0.956321, 'recall_vowel': 0.986756, 'recall_consonant': 0.985729, 'acc_grapheme': 0.953818, 'acc_vowel': 0.986317, 'acc_consonant': 0.98552, 'loss_grapheme': 0.257258, 'loss_vowel': 0.135454, 'loss_consonant': 0.105727}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000020 | 044544/160716 | 0.3431 | 1.9726 |\n",
      "val: {'recall': 0.971608, 'recall_grapheme': 0.957112, 'recall_vowel': 0.986689, 'recall_consonant': 0.98552, 'acc_grapheme': 0.954715, 'acc_vowel': 0.986666, 'acc_consonant': 0.985844, 'loss_grapheme': 0.228628, 'loss_vowel': 0.112308, 'loss_consonant': 0.092933}\n",
      "    1 | 0.000019 | 146944/160716 | 1.9499 | 2.2288 |\n",
      "val: {'recall': 0.972378, 'recall_grapheme': 0.958125, 'recall_vowel': 0.986949, 'recall_consonant': 0.986314, 'acc_grapheme': 0.955239, 'acc_vowel': 0.986866, 'acc_consonant': 0.985769, 'loss_grapheme': 0.232332, 'loss_vowel': 0.114276, 'loss_consonant': 0.09483}\n",
      "    2 | 0.000017 | 089088/160716 | 0.2546 | 1.9880 |\n",
      "val: {'recall': 0.971439, 'recall_grapheme': 0.956894, 'recall_vowel': 0.986659, 'recall_consonant': 0.985308, 'acc_grapheme': 0.955239, 'acc_vowel': 0.987065, 'acc_consonant': 0.986118, 'loss_grapheme': 0.215971, 'loss_vowel': 0.100056, 'loss_consonant': 0.083712}\n",
      "    3 | 0.000015 | 031232/160716 | 0.2619 | 1.9711 |\n",
      "val: {'recall': 0.972125, 'recall_grapheme': 0.957883, 'recall_vowel': 0.986888, 'recall_consonant': 0.985844, 'acc_grapheme': 0.955638, 'acc_vowel': 0.987065, 'acc_consonant': 0.986068, 'loss_grapheme': 0.210813, 'loss_vowel': 0.098526, 'loss_consonant': 0.082262}\n",
      "    3 | 0.000013 | 133632/160716 | 0.3071 | 2.0980 |\n",
      "val: {'recall': 0.972781, 'recall_grapheme': 0.958252, 'recall_vowel': 0.986805, 'recall_consonant': 0.987817, 'acc_grapheme': 0.956435, 'acc_vowel': 0.98709, 'acc_consonant': 0.985919, 'loss_grapheme': 0.222273, 'loss_vowel': 0.111456, 'loss_consonant': 0.090897}\n",
      "** saved\n",
      "    4 | 0.000011 | 075776/160716 | 2.6618 | 1.9860 |\n",
      "val: {'recall': 0.972472, 'recall_grapheme': 0.958576, 'recall_vowel': 0.986972, 'recall_consonant': 0.985766, 'acc_grapheme': 0.956809, 'acc_vowel': 0.987464, 'acc_consonant': 0.986392, 'loss_grapheme': 0.204001, 'loss_vowel': 0.093611, 'loss_consonant': 0.079685}\n",
      "    5 | 0.000008 | 017920/160716 | 4.9352 | 1.9406 |\n",
      "val: {'recall': 0.973205, 'recall_grapheme': 0.959172, 'recall_vowel': 0.98717, 'recall_consonant': 0.987307, 'acc_grapheme': 0.956834, 'acc_vowel': 0.987489, 'acc_consonant': 0.986243, 'loss_grapheme': 0.20942, 'loss_vowel': 0.099842, 'loss_consonant': 0.083128}\n",
      "** saved\n",
      "    5 | 0.000006 | 120320/160716 | 0.2744 | 2.1349 |\n",
      "val: {'recall': 0.97293, 'recall_grapheme': 0.959096, 'recall_vowel': 0.987395, 'recall_consonant': 0.986133, 'acc_grapheme': 0.957033, 'acc_vowel': 0.987564, 'acc_consonant': 0.986342, 'loss_grapheme': 0.210428, 'loss_vowel': 0.102038, 'loss_consonant': 0.083583}\n",
      "    6 | 0.000004 | 062464/160716 | 5.4759 | 2.1645 |\n",
      "val: {'recall': 0.973417, 'recall_grapheme': 0.959484, 'recall_vowel': 0.987351, 'recall_consonant': 0.987349, 'acc_grapheme': 0.957282, 'acc_vowel': 0.987539, 'acc_consonant': 0.986417, 'loss_grapheme': 0.21235, 'loss_vowel': 0.101586, 'loss_consonant': 0.08378}\n",
      "** saved\n",
      "    7 | 0.000002 | 004608/160716 | 0.2480 | 1.8298 |\n",
      "val: {'recall': 0.973114, 'recall_grapheme': 0.959549, 'recall_vowel': 0.987323, 'recall_consonant': 0.986035, 'acc_grapheme': 0.957681, 'acc_vowel': 0.987638, 'acc_consonant': 0.986542, 'loss_grapheme': 0.198198, 'loss_vowel': 0.090327, 'loss_consonant': 0.076466}\n",
      "    7 | 0.000001 | 107008/160716 | 5.5801 | 2.0593 |\n",
      "val: {'recall': 0.973038, 'recall_grapheme': 0.959364, 'recall_vowel': 0.987328, 'recall_consonant': 0.986096, 'acc_grapheme': 0.957307, 'acc_vowel': 0.987588, 'acc_consonant': 0.986616, 'loss_grapheme': 0.205746, 'loss_vowel': 0.097466, 'loss_consonant': 0.080733}\n",
      "    8 | 0.000001 | 049152/160716 | 0.2097 | 1.9406 |\n",
      "val: {'recall': 0.973213, 'recall_grapheme': 0.9597, 'recall_vowel': 0.987309, 'recall_consonant': 0.986143, 'acc_grapheme': 0.957557, 'acc_vowel': 0.987738, 'acc_consonant': 0.986592, 'loss_grapheme': 0.200608, 'loss_vowel': 0.092951, 'loss_consonant': 0.077982}\n",
      "    8 | 0.000001 | 151552/160716 | 5.1495 | 2.0829 |\n",
      "val: {'recall': 0.973138, 'recall_grapheme': 0.95952, 'recall_vowel': 0.98729, 'recall_consonant': 0.986221, 'acc_grapheme': 0.957407, 'acc_vowel': 0.987588, 'acc_consonant': 0.986592, 'loss_grapheme': 0.205208, 'loss_vowel': 0.096501, 'loss_consonant': 0.080085}\n",
      "    9 | 0.000002 | 093696/160716 | 3.2628 | 2.1188 |\n",
      "val: {'recall': 0.973679, 'recall_grapheme': 0.959765, 'recall_vowel': 0.987213, 'recall_consonant': 0.987973, 'acc_grapheme': 0.957457, 'acc_vowel': 0.987514, 'acc_consonant': 0.986442, 'loss_grapheme': 0.208735, 'loss_vowel': 0.09927, 'loss_consonant': 0.082362}\n",
      "** saved\n",
      "   10 | 0.000004 | 035840/160716 | 4.2071 | 1.7427 |\n",
      "val: {'recall': 0.973293, 'recall_grapheme': 0.959535, 'recall_vowel': 0.987325, 'recall_consonant': 0.986776, 'acc_grapheme': 0.957681, 'acc_vowel': 0.987663, 'acc_consonant': 0.986616, 'loss_grapheme': 0.198581, 'loss_vowel': 0.091207, 'loss_consonant': 0.076884}\n",
      "   10 | 0.000006 | 138240/160716 | 5.1346 | 2.1013 |\n",
      "val: {'recall': 0.973612, 'recall_grapheme': 0.960038, 'recall_vowel': 0.987421, 'recall_consonant': 0.986952, 'acc_grapheme': 0.957532, 'acc_vowel': 0.987564, 'acc_consonant': 0.986691, 'loss_grapheme': 0.210514, 'loss_vowel': 0.102027, 'loss_consonant': 0.083772}\n",
      "   11 | 0.000008 | 080384/160716 | 0.2052 | 1.8996 |\n",
      "val: {'recall': 0.973495, 'recall_grapheme': 0.959976, 'recall_vowel': 0.98742, 'recall_consonant': 0.986608, 'acc_grapheme': 0.95803, 'acc_vowel': 0.987713, 'acc_consonant': 0.98699, 'loss_grapheme': 0.195784, 'loss_vowel': 0.089495, 'loss_consonant': 0.075514}\n",
      "   12 | 0.000010 | 022528/160716 | 5.1821 | 2.5947 |\n",
      "val: {'recall': 0.97461, 'recall_grapheme': 0.96134, 'recall_vowel': 0.987517, 'recall_consonant': 0.988244, 'acc_grapheme': 0.958977, 'acc_vowel': 0.987937, 'acc_consonant': 0.986666, 'loss_grapheme': 0.199819, 'loss_vowel': 0.093293, 'loss_consonant': 0.079221}\n",
      "** saved\n",
      "   12 | 0.000013 | 124928/160716 | 4.6724 | 2.1155 |\n",
      "val: {'recall': 0.973698, 'recall_grapheme': 0.960855, 'recall_vowel': 0.987695, 'recall_consonant': 0.985385, 'acc_grapheme': 0.959102, 'acc_vowel': 0.988037, 'acc_consonant': 0.986916, 'loss_grapheme': 0.188982, 'loss_vowel': 0.083503, 'loss_consonant': 0.071369}\n",
      "   13 | 0.000015 | 067072/160716 | 4.4451 | 1.8778 |\n",
      "val: {'recall': 0.973968, 'recall_grapheme': 0.960229, 'recall_vowel': 0.987353, 'recall_consonant': 0.98806, 'acc_grapheme': 0.958828, 'acc_vowel': 0.988012, 'acc_consonant': 0.987065, 'loss_grapheme': 0.187632, 'loss_vowel': 0.082335, 'loss_consonant': 0.069432}\n",
      "   14 | 0.000017 | 009216/160716 | 0.2649 | 1.8784 |\n",
      "val: {'recall': 0.974578, 'recall_grapheme': 0.961143, 'recall_vowel': 0.988334, 'recall_consonant': 0.987694, 'acc_grapheme': 0.959476, 'acc_vowel': 0.988162, 'acc_consonant': 0.98699, 'loss_grapheme': 0.194667, 'loss_vowel': 0.090077, 'loss_consonant': 0.076322}\n",
      "   14 | 0.000019 | 111616/160716 | 0.2061 | 1.8135 |\n",
      "val: {'recall': 0.973941, 'recall_grapheme': 0.961404, 'recall_vowel': 0.988208, 'recall_consonant': 0.984746, 'acc_grapheme': 0.960497, 'acc_vowel': 0.988685, 'acc_consonant': 0.987065, 'loss_grapheme': 0.177144, 'loss_vowel': 0.073886, 'loss_consonant': 0.064902}\n",
      "   15 | 0.000020 | 053760/160716 | 2.7317 | 2.1135 |\n",
      "val: {'recall': 0.975117, 'recall_grapheme': 0.961076, 'recall_vowel': 0.988066, 'recall_consonant': 0.990249, 'acc_grapheme': 0.959874, 'acc_vowel': 0.988386, 'acc_consonant': 0.987364, 'loss_grapheme': 0.189143, 'loss_vowel': 0.088443, 'loss_consonant': 0.07442}\n",
      "** saved\n",
      "   15 | 0.000020 | 156160/160716 | 5.3231 | 2.1448 |\n",
      "val: {'recall': 0.975785, 'recall_grapheme': 0.962514, 'recall_vowel': 0.988252, 'recall_consonant': 0.989862, 'acc_grapheme': 0.960373, 'acc_vowel': 0.988685, 'acc_consonant': 0.987638, 'loss_grapheme': 0.187038, 'loss_vowel': 0.084568, 'loss_consonant': 0.07166}\n",
      "** saved\n",
      "   16 | 0.000020 | 098304/160716 | 5.5727 | 2.1574 |\n",
      "val: {'recall': 0.975668, 'recall_grapheme': 0.96233, 'recall_vowel': 0.988403, 'recall_consonant': 0.989607, 'acc_grapheme': 0.959924, 'acc_vowel': 0.988685, 'acc_consonant': 0.987389, 'loss_grapheme': 0.187491, 'loss_vowel': 0.086251, 'loss_consonant': 0.074713}\n",
      "   17 | 0.000019 | 040448/160716 | 3.2189 | 1.9639 |\n",
      "val: {'recall': 0.976368, 'recall_grapheme': 0.963104, 'recall_vowel': 0.988824, 'recall_consonant': 0.990439, 'acc_grapheme': 0.961021, 'acc_vowel': 0.989059, 'acc_consonant': 0.987713, 'loss_grapheme': 0.181578, 'loss_vowel': 0.081358, 'loss_consonant': 0.069864}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   17 | 0.000017 | 142848/160716 | 3.2950 | 2.0804 |\n",
      "val: {'recall': 0.975868, 'recall_grapheme': 0.962795, 'recall_vowel': 0.988644, 'recall_consonant': 0.989238, 'acc_grapheme': 0.96122, 'acc_vowel': 0.988785, 'acc_consonant': 0.987289, 'loss_grapheme': 0.19474, 'loss_vowel': 0.094407, 'loss_consonant': 0.076584}\n",
      "   18 | 0.000015 | 084992/160716 | 0.1718 | 2.1900 |\n",
      "val: {'recall': 0.976608, 'recall_grapheme': 0.963522, 'recall_vowel': 0.988494, 'recall_consonant': 0.990895, 'acc_grapheme': 0.96142, 'acc_vowel': 0.988835, 'acc_consonant': 0.987688, 'loss_grapheme': 0.187796, 'loss_vowel': 0.086718, 'loss_consonant': 0.073475}\n",
      "** saved\n",
      "   19 | 0.000013 | 027136/160716 | 5.3920 | 2.0520 |\n",
      "val: {'recall': 0.976072, 'recall_grapheme': 0.963455, 'recall_vowel': 0.988503, 'recall_consonant': 0.988877, 'acc_grapheme': 0.961544, 'acc_vowel': 0.989034, 'acc_consonant': 0.987912, 'loss_grapheme': 0.180497, 'loss_vowel': 0.081091, 'loss_consonant': 0.068234}\n",
      "   19 | 0.000011 | 129536/160716 | 0.1326 | 2.1885 |\n",
      "val: {'recall': 0.976258, 'recall_grapheme': 0.964152, 'recall_vowel': 0.988888, 'recall_consonant': 0.987841, 'acc_grapheme': 0.961868, 'acc_vowel': 0.989134, 'acc_consonant': 0.987539, 'loss_grapheme': 0.191908, 'loss_vowel': 0.0923, 'loss_consonant': 0.076058}\n",
      "   20 | 0.000008 | 071680/160716 | 0.2306 | 1.8353 |\n",
      "val: {'recall': 0.976249, 'recall_grapheme': 0.964279, 'recall_vowel': 0.988572, 'recall_consonant': 0.987865, 'acc_grapheme': 0.962292, 'acc_vowel': 0.989084, 'acc_consonant': 0.988037, 'loss_grapheme': 0.171494, 'loss_vowel': 0.074127, 'loss_consonant': 0.064421}\n",
      "   21 | 0.000006 | 013824/160716 | 0.1829 | 1.5829 |\n",
      "val: {'recall': 0.976258, 'recall_grapheme': 0.964251, 'recall_vowel': 0.988982, 'recall_consonant': 0.987548, 'acc_grapheme': 0.962292, 'acc_vowel': 0.989208, 'acc_consonant': 0.987838, 'loss_grapheme': 0.176082, 'loss_vowel': 0.078414, 'loss_consonant': 0.067022}\n",
      "   21 | 0.000004 | 116224/160716 | 0.3365 | 1.7432 |\n",
      "val: {'recall': 0.976357, 'recall_grapheme': 0.964009, 'recall_vowel': 0.988387, 'recall_consonant': 0.989024, 'acc_grapheme': 0.962242, 'acc_vowel': 0.989109, 'acc_consonant': 0.987912, 'loss_grapheme': 0.168889, 'loss_vowel': 0.073158, 'loss_consonant': 0.063245}\n",
      "   22 | 0.000002 | 058368/160716 | 2.4816 | 2.2532 |\n",
      "val: {'recall': 0.976628, 'recall_grapheme': 0.964451, 'recall_vowel': 0.988728, 'recall_consonant': 0.988882, 'acc_grapheme': 0.962317, 'acc_vowel': 0.989109, 'acc_consonant': 0.987738, 'loss_grapheme': 0.183099, 'loss_vowel': 0.085974, 'loss_consonant': 0.071667}\n",
      "** saved\n",
      "   23 | 0.000001 | 000512/160716 | 1.7813 | 1.7813 |\n",
      "val: {'recall': 0.976544, 'recall_grapheme': 0.964499, 'recall_vowel': 0.988253, 'recall_consonant': 0.988927, 'acc_grapheme': 0.962566, 'acc_vowel': 0.988959, 'acc_consonant': 0.987863, 'loss_grapheme': 0.172437, 'loss_vowel': 0.07658, 'loss_consonant': 0.065399}\n",
      "   23 | 0.000001 | 102912/160716 | 2.9881 | 2.0585 |\n",
      "val: {'recall': 0.976651, 'recall_grapheme': 0.964378, 'recall_vowel': 0.988858, 'recall_consonant': 0.988988, 'acc_grapheme': 0.962417, 'acc_vowel': 0.989084, 'acc_consonant': 0.987888, 'loss_grapheme': 0.178268, 'loss_vowel': 0.080722, 'loss_consonant': 0.067703}\n",
      "** saved\n",
      "   24 | 0.000001 | 045056/160716 | 0.1417 | 2.6221 |\n",
      "val: {'recall': 0.976523, 'recall_grapheme': 0.964155, 'recall_vowel': 0.988762, 'recall_consonant': 0.989022, 'acc_grapheme': 0.961644, 'acc_vowel': 0.98876, 'acc_consonant': 0.987564, 'loss_grapheme': 0.206663, 'loss_vowel': 0.104722, 'loss_consonant': 0.082896}\n",
      "   24 | 0.000002 | 147456/160716 | 0.1849 | 2.1351 |\n",
      "val: {'recall': 0.976715, 'recall_grapheme': 0.964114, 'recall_vowel': 0.98846, 'recall_consonant': 0.990173, 'acc_grapheme': 0.962367, 'acc_vowel': 0.989084, 'acc_consonant': 0.987987, 'loss_grapheme': 0.173167, 'loss_vowel': 0.076913, 'loss_consonant': 0.065435}\n",
      "** saved\n",
      "   25 | 0.000004 | 089600/160716 | 5.2752 | 1.7782 |\n",
      "val: {'recall': 0.976097, 'recall_grapheme': 0.964147, 'recall_vowel': 0.988387, 'recall_consonant': 0.987708, 'acc_grapheme': 0.962641, 'acc_vowel': 0.989034, 'acc_consonant': 0.988062, 'loss_grapheme': 0.166172, 'loss_vowel': 0.071136, 'loss_consonant': 0.061616}\n",
      "   26 | 0.000006 | 031744/160716 | 5.0667 | 1.9757 |\n",
      "val: {'recall': 0.976798, 'recall_grapheme': 0.964953, 'recall_vowel': 0.988502, 'recall_consonant': 0.988785, 'acc_grapheme': 0.962392, 'acc_vowel': 0.988984, 'acc_consonant': 0.988062, 'loss_grapheme': 0.172852, 'loss_vowel': 0.077441, 'loss_consonant': 0.065553}\n",
      "** saved\n",
      "   26 | 0.000008 | 134144/160716 | 0.8375 | 1.9390 |\n",
      "val: {'recall': 0.977118, 'recall_grapheme': 0.965097, 'recall_vowel': 0.988854, 'recall_consonant': 0.989425, 'acc_grapheme': 0.962566, 'acc_vowel': 0.989283, 'acc_consonant': 0.988187, 'loss_grapheme': 0.176698, 'loss_vowel': 0.080028, 'loss_consonant': 0.067437}\n",
      "** saved\n",
      "   27 | 0.000010 | 076288/160716 | 5.2494 | 1.9793 |\n",
      "val: {'recall': 0.976923, 'recall_grapheme': 0.964776, 'recall_vowel': 0.988783, 'recall_consonant': 0.989357, 'acc_grapheme': 0.962441, 'acc_vowel': 0.989208, 'acc_consonant': 0.988087, 'loss_grapheme': 0.178184, 'loss_vowel': 0.08309, 'loss_consonant': 0.069089}\n",
      "   28 | 0.000013 | 018432/160716 | 5.2373 | 2.2787 |\n",
      "val: {'recall': 0.97637, 'recall_grapheme': 0.964559, 'recall_vowel': 0.988842, 'recall_consonant': 0.987521, 'acc_grapheme': 0.962541, 'acc_vowel': 0.989358, 'acc_consonant': 0.988311, 'loss_grapheme': 0.175583, 'loss_vowel': 0.081508, 'loss_consonant': 0.066907}\n",
      "   28 | 0.000015 | 120832/160716 | 3.1820 | 2.0476 |\n",
      "val: {'recall': 0.97693, 'recall_grapheme': 0.964564, 'recall_vowel': 0.988891, 'recall_consonant': 0.989701, 'acc_grapheme': 0.962741, 'acc_vowel': 0.989233, 'acc_consonant': 0.988062, 'loss_grapheme': 0.172899, 'loss_vowel': 0.078261, 'loss_consonant': 0.06743}\n",
      "   29 | 0.000017 | 062976/160716 | 5.3851 | 1.8491 |\n",
      "val: {'recall': 0.976514, 'recall_grapheme': 0.964879, 'recall_vowel': 0.988151, 'recall_consonant': 0.988146, 'acc_grapheme': 0.962392, 'acc_vowel': 0.989258, 'acc_consonant': 0.988486, 'loss_grapheme': 0.169055, 'loss_vowel': 0.073465, 'loss_consonant': 0.062589}\n",
      "   30 | 0.000019 | 005120/160716 | 4.3302 | 2.5531 |\n",
      "val: {'recall': 0.977251, 'recall_grapheme': 0.964569, 'recall_vowel': 0.988636, 'recall_consonant': 0.991229, 'acc_grapheme': 0.962167, 'acc_vowel': 0.989109, 'acc_consonant': 0.987912, 'loss_grapheme': 0.187113, 'loss_vowel': 0.089544, 'loss_consonant': 0.07459}\n",
      "** saved\n",
      "   30 | 0.000020 | 107520/160716 | 0.1592 | 1.8954 |\n",
      "val: {'recall': 0.977427, 'recall_grapheme': 0.964929, 'recall_vowel': 0.988936, 'recall_consonant': 0.990914, 'acc_grapheme': 0.962441, 'acc_vowel': 0.989308, 'acc_consonant': 0.988461, 'loss_grapheme': 0.169426, 'loss_vowel': 0.073668, 'loss_consonant': 0.064495}\n",
      "** saved\n",
      "   31 | 0.000020 | 049664/160716 | 0.1480 | 1.8063 |\n",
      "val: {'recall': 0.977475, 'recall_grapheme': 0.965156, 'recall_vowel': 0.989224, 'recall_consonant': 0.990363, 'acc_grapheme': 0.96294, 'acc_vowel': 0.989557, 'acc_consonant': 0.988511, 'loss_grapheme': 0.16021, 'loss_vowel': 0.06771, 'loss_consonant': 0.059009}\n",
      "** saved\n",
      "   31 | 0.000020 | 152064/160716 | 1.4252 | 1.9334 |\n",
      "val: {'recall': 0.977562, 'recall_grapheme': 0.965253, 'recall_vowel': 0.989329, 'recall_consonant': 0.990412, 'acc_grapheme': 0.963488, 'acc_vowel': 0.989732, 'acc_consonant': 0.988735, 'loss_grapheme': 0.171917, 'loss_vowel': 0.076019, 'loss_consonant': 0.063974}\n",
      "** saved\n",
      "   32 | 0.000019 | 094208/160716 | 5.0229 | 1.9058 |\n",
      "val: {'recall': 0.977989, 'recall_grapheme': 0.965529, 'recall_vowel': 0.989565, 'recall_consonant': 0.991333, 'acc_grapheme': 0.963214, 'acc_vowel': 0.989607, 'acc_consonant': 0.98871, 'loss_grapheme': 0.174154, 'loss_vowel': 0.078731, 'loss_consonant': 0.066561}\n",
      "** saved\n",
      "   33 | 0.000017 | 036352/160716 | 0.1867 | 2.0534 |\n",
      "val: {'recall': 0.97818, 'recall_grapheme': 0.96611, 'recall_vowel': 0.989166, 'recall_consonant': 0.991332, 'acc_grapheme': 0.963563, 'acc_vowel': 0.989632, 'acc_consonant': 0.98861, 'loss_grapheme': 0.173081, 'loss_vowel': 0.080864, 'loss_consonant': 0.066603}\n",
      "** saved\n",
      "   33 | 0.000015 | 138752/160716 | 3.1861 | 2.0355 |\n",
      "val: {'recall': 0.977791, 'recall_grapheme': 0.965414, 'recall_vowel': 0.989214, 'recall_consonant': 0.991121, 'acc_grapheme': 0.963114, 'acc_vowel': 0.989632, 'acc_consonant': 0.988884, 'loss_grapheme': 0.168245, 'loss_vowel': 0.076553, 'loss_consonant': 0.063888}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 0.000013 | 080896/160716 | 0.9736 | 2.0494 |\n",
      "val: {'recall': 0.978156, 'recall_grapheme': 0.96601, 'recall_vowel': 0.989071, 'recall_consonant': 0.991534, 'acc_grapheme': 0.964036, 'acc_vowel': 0.989458, 'acc_consonant': 0.98871, 'loss_grapheme': 0.167407, 'loss_vowel': 0.07534, 'loss_consonant': 0.06353}\n",
      "   35 | 0.000011 | 023040/160716 | 0.1384 | 1.8158 |\n",
      "val: {'recall': 0.97789, 'recall_grapheme': 0.965648, 'recall_vowel': 0.988779, 'recall_consonant': 0.991484, 'acc_grapheme': 0.963737, 'acc_vowel': 0.989532, 'acc_consonant': 0.98861, 'loss_grapheme': 0.163584, 'loss_vowel': 0.073873, 'loss_consonant': 0.063052}\n",
      "   35 | 0.000008 | 125440/160716 | 0.1793 | 1.9527 |\n",
      "val: {'recall': 0.978487, 'recall_grapheme': 0.966544, 'recall_vowel': 0.989356, 'recall_consonant': 0.991506, 'acc_grapheme': 0.96441, 'acc_vowel': 0.989582, 'acc_consonant': 0.98861, 'loss_grapheme': 0.165012, 'loss_vowel': 0.073973, 'loss_consonant': 0.062595}\n",
      "** saved\n",
      "   36 | 0.000006 | 067584/160716 | 0.1859 | 1.9843 |\n",
      "val: {'recall': 0.978144, 'recall_grapheme': 0.966071, 'recall_vowel': 0.989013, 'recall_consonant': 0.99142, 'acc_grapheme': 0.964261, 'acc_vowel': 0.989632, 'acc_consonant': 0.988735, 'loss_grapheme': 0.163799, 'loss_vowel': 0.073567, 'loss_consonant': 0.063063}\n",
      "   37 | 0.000004 | 009728/160716 | 0.1172 | 1.4444 |\n",
      "val: {'recall': 0.978253, 'recall_grapheme': 0.966224, 'recall_vowel': 0.989257, 'recall_consonant': 0.991308, 'acc_grapheme': 0.964036, 'acc_vowel': 0.989732, 'acc_consonant': 0.989009, 'loss_grapheme': 0.159441, 'loss_vowel': 0.069423, 'loss_consonant': 0.0594}\n",
      "   37 | 0.000002 | 112128/160716 | 5.5410 | 2.0526 |\n",
      "val: {'recall': 0.978125, 'recall_grapheme': 0.965813, 'recall_vowel': 0.989226, 'recall_consonant': 0.991649, 'acc_grapheme': 0.964061, 'acc_vowel': 0.989682, 'acc_consonant': 0.988785, 'loss_grapheme': 0.164822, 'loss_vowel': 0.074815, 'loss_consonant': 0.063487}\n",
      "   38 | 0.000001 | 054272/160716 | 3.4737 | 2.1392 |\n",
      "val: {'recall': 0.978161, 'recall_grapheme': 0.965712, 'recall_vowel': 0.989566, 'recall_consonant': 0.991656, 'acc_grapheme': 0.963787, 'acc_vowel': 0.989682, 'acc_consonant': 0.988785, 'loss_grapheme': 0.175638, 'loss_vowel': 0.084201, 'loss_consonant': 0.069141}\n",
      "   38 | 0.000001 | 156672/160716 | 0.2128 | 2.1511 |\n",
      "val: {'recall': 0.978192, 'recall_grapheme': 0.965924, 'recall_vowel': 0.989338, 'recall_consonant': 0.991582, 'acc_grapheme': 0.964061, 'acc_vowel': 0.989632, 'acc_consonant': 0.98881, 'loss_grapheme': 0.171446, 'loss_vowel': 0.080531, 'loss_consonant': 0.066589}\n",
      "   39 | 0.000001 | 098816/160716 | 2.3413 | 2.1153 |\n",
      "val: {'recall': 0.978107, 'recall_grapheme': 0.965666, 'recall_vowel': 0.989584, 'recall_consonant': 0.991514, 'acc_grapheme': 0.963887, 'acc_vowel': 0.989906, 'acc_consonant': 0.98876, 'loss_grapheme': 0.165163, 'loss_vowel': 0.075186, 'loss_consonant': 0.063281}\n",
      "   40 | 0.000002 | 040960/160716 | 3.2721 | 2.1198 |\n",
      "val: {'recall': 0.978556, 'recall_grapheme': 0.966436, 'recall_vowel': 0.989744, 'recall_consonant': 0.991611, 'acc_grapheme': 0.96436, 'acc_vowel': 0.989807, 'acc_consonant': 0.988835, 'loss_grapheme': 0.166895, 'loss_vowel': 0.076445, 'loss_consonant': 0.063963}\n",
      "** saved\n",
      "   40 | 0.000004 | 143360/160716 | 0.1679 | 2.0164 |\n",
      "val: {'recall': 0.978175, 'recall_grapheme': 0.96609, 'recall_vowel': 0.989194, 'recall_consonant': 0.991325, 'acc_grapheme': 0.964036, 'acc_vowel': 0.989657, 'acc_consonant': 0.988785, 'loss_grapheme': 0.165774, 'loss_vowel': 0.075024, 'loss_consonant': 0.062405}\n",
      "   41 | 0.000006 | 085504/160716 | 4.7226 | 1.9229 |\n",
      "val: {'recall': 0.978484, 'recall_grapheme': 0.966493, 'recall_vowel': 0.989672, 'recall_consonant': 0.991278, 'acc_grapheme': 0.964485, 'acc_vowel': 0.989832, 'acc_consonant': 0.988835, 'loss_grapheme': 0.158135, 'loss_vowel': 0.069155, 'loss_consonant': 0.059151}\n",
      "   42 | 0.000008 | 027648/160716 | 4.2427 | 2.2306 |\n",
      "val: {'recall': 0.978525, 'recall_grapheme': 0.966318, 'recall_vowel': 0.989889, 'recall_consonant': 0.991577, 'acc_grapheme': 0.964286, 'acc_vowel': 0.989856, 'acc_consonant': 0.988909, 'loss_grapheme': 0.171905, 'loss_vowel': 0.080525, 'loss_consonant': 0.067187}\n",
      "   42 | 0.000011 | 130048/160716 | 4.8110 | 1.9715 |\n",
      "val: {'recall': 0.978157, 'recall_grapheme': 0.965799, 'recall_vowel': 0.989439, 'recall_consonant': 0.99159, 'acc_grapheme': 0.964535, 'acc_vowel': 0.989931, 'acc_consonant': 0.988635, 'loss_grapheme': 0.158503, 'loss_vowel': 0.068997, 'loss_consonant': 0.060236}\n",
      "   43 | 0.000013 | 072192/160716 | 0.1669 | 1.8143 |\n",
      "val: {'recall': 0.978599, 'recall_grapheme': 0.966686, 'recall_vowel': 0.989551, 'recall_consonant': 0.991472, 'acc_grapheme': 0.96446, 'acc_vowel': 0.989906, 'acc_consonant': 0.988585, 'loss_grapheme': 0.157558, 'loss_vowel': 0.06781, 'loss_consonant': 0.058849}\n",
      "** saved\n",
      "   43 | 0.000015 | 076800/160716 | 0.1178 | 1.8070 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-54080d9d42c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-df23bee99ed8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtrain_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;31m#do_mixup = False #(np.random.random() < 0.4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.078475, 'recall_grapheme': 0.000506, 'recall_vowel': 0.07305, 'recall_consonant': 0.239839, 'acc_grapheme': 0.011415, 'acc_vowel': 0.118358, 'acc_consonant': 0.10966, 'loss_grapheme': 5.12518, 'loss_vowel': 2.381504, 'loss_consonant': 1.953163}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.001000 | 102400/160716 | 2.4490 | 6.8871 |\n",
      "val: {'recall': 0.657914, 'recall_grapheme': 0.429999, 'recall_vowel': 0.872831, 'recall_consonant': 0.898829, 'acc_grapheme': 0.417655, 'acc_vowel': 0.861056, 'acc_consonant': 0.875411, 'loss_grapheme': 2.54123, 'loss_vowel': 0.624734, 'loss_consonant': 0.434316}\n",
      "** saved\n",
      "    1 | 0.001000 | 044544/160716 | 4.4086 | 4.5990 |\n",
      "val: {'recall': 0.919566, 'recall_grapheme': 0.87381, 'recall_vowel': 0.962532, 'recall_consonant': 0.968112, 'acc_grapheme': 0.834189, 'acc_vowel': 0.952846, 'acc_consonant': 0.944721, 'loss_grapheme': 1.081165, 'loss_vowel': 0.422073, 'loss_consonant': 0.281901}\n",
      "** saved\n",
      "    1 | 0.001000 | 146944/160716 | 4.9064 | 4.1739 |\n",
      "val: {'recall': 0.946307, 'recall_grapheme': 0.919329, 'recall_vowel': 0.969034, 'recall_consonant': 0.977538, 'acc_grapheme': 0.905443, 'acc_vowel': 0.964809, 'acc_consonant': 0.960074, 'loss_grapheme': 0.606626, 'loss_vowel': 0.342083, 'loss_consonant': 0.269471}\n",
      "** saved\n",
      "    2 | 0.001000 | 089088/160716 | 0.7553 | 3.5082 |\n",
      "val: {'recall': 0.952219, 'recall_grapheme': 0.93097, 'recall_vowel': 0.978035, 'recall_consonant': 0.968902, 'acc_grapheme': 0.919873, 'acc_vowel': 0.978691, 'acc_consonant': 0.979588, 'loss_grapheme': 0.395553, 'loss_vowel': 0.240933, 'loss_consonant': 0.167819}\n",
      "** saved\n",
      "    3 | 0.001000 | 031232/160716 | 1.4458 | 3.6412 |\n",
      "val: {'recall': 0.959962, 'recall_grapheme': 0.939677, 'recall_vowel': 0.977282, 'recall_consonant': 0.98321, 'acc_grapheme': 0.913867, 'acc_vowel': 0.970267, 'acc_consonant': 0.959027, 'loss_grapheme': 0.791841, 'loss_vowel': 0.34796, 'loss_consonant': 0.258135}\n",
      "** saved\n",
      "    3 | 0.001000 | 111104/160716 | 5.2669 | 3.4856 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-54080d9d42c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-715bce35ae28>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
