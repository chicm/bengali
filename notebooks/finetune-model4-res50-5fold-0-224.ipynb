{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image\n",
    "from utils import bn_update, moving_average, copy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/chec/data/bengali': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/chicm/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "def class_balanced_sampler(labels):\n",
    "    class_counts = np.bincount(labels)\n",
    "    total_samples = len(labels)\n",
    "    sample_weights = np.zeros_like(labels).astype(np.float32)\n",
    "    for idx, label in enumerate(labels):\n",
    "        sample_weights[idx] = total_samples / class_counts[label]\n",
    "    # return sample_weights\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "        num_samples=total_samples)\n",
    "    return sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations as albu\n",
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)\n",
    "finetune_class = 'vowel_diacritic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    print('fold:', ifold)\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    sampler = class_balanced_sampler(train[finetune_class])\n",
    "    print('sampler length: {}'.format(sampler.weights.shape))\n",
    "\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=False, num_workers=8, drop_last=False, pin_memory=True, sampler=sampler)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False, pin_memory=True)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in train_loader:\n",
    "#    print(x)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNetOld(nn.Module):\n",
    "    def __init__(self, backbone_name='se_resnext50_32x4d'):\n",
    "        super(BengaliNetOld, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.n_word = 1295\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant + self.n_word\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        self.num_p2_features = self.backbone.layer2[-1].se_module.fc2.out_channels\n",
    "        self.num_p3_features = self.backbone.layer3[-1].se_module.fc2.out_channels\n",
    "        self.p2_head = nn.Conv2d(self.num_p2_features, self.num_p2_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.p3_head = nn.Conv2d(self.num_p3_features, self.num_p3_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_p2_features * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_p3_features * 4)\n",
    "        self.act2 = Swish()\n",
    "        self.act3 = Swish()\n",
    "        \n",
    "        self.fc_aux1 = nn.Linear(self.num_p3_features * 4, self.num_classes)\n",
    "        self.fc_aux2 = nn.Linear(self.num_p2_features * 4, self.num_classes)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        for fc in [self.fc, self.fc_aux1, self.fc_aux2]:\n",
    "            nn.init.zeros_(fc.bias.data)\n",
    "\n",
    "        print('init model4')\n",
    "        \n",
    "    def features(self, x):\n",
    "        x = self.backbone.layer0(x); #print(x.size())\n",
    "        x = self.backbone.layer1(x); #print(x.size())\n",
    "        x = self.backbone.layer2(x); p2 = x; p2 = self.p2_head(p2); p2 = self.bn2(p2); p2 = self.act2(p2) #print(x.size())\n",
    "        x = self.backbone.layer3(x); p3 = x; p3 = self.p3_head(p3); p3 = self.bn3(p3); p3 = self.act3(p3) #print(x.size())\n",
    "        x = self.backbone.layer4(x); #print(x.size())\n",
    "        return x, p2, p3\n",
    "        \n",
    "    def logits(self, x, p2, p3):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        p2 = self.avg_pool(p2)\n",
    "        p2 = torch.flatten(p2, 1)\n",
    "        \n",
    "        p3 = self.avg_pool(p3)\n",
    "        p3 = torch.flatten(p3, 1)\n",
    "        return self.fc(x), self.fc_aux1(p3), self.fc_aux2(p2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x, p2, p3 = self.features(x)\n",
    "        x, logits_aux1, logits_aux2 = self.logits(x, p2, p3)\n",
    "\n",
    "        return x, logits_aux1, logits_aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name='se_resnext50_32x4d'):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.n_word = 1295\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant + self.n_word\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        \n",
    "        self.num_p2_features = self.backbone.layer2[-1].se_module.fc2.out_channels\n",
    "        self.num_p3_features = self.backbone.layer3[-1].se_module.fc2.out_channels\n",
    "        self.p2_head = nn.Conv2d(self.num_p2_features, self.num_p2_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.p3_head = nn.Conv2d(self.num_p3_features, self.num_p3_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_p2_features * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_p3_features * 4)\n",
    "        self.act2 = Swish()\n",
    "        self.act3 = Swish()\n",
    "        \n",
    "        \n",
    "        #self.fc = nn.Linear(self.num_features, num_total_classes)\n",
    "        #self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        self.fc_g = nn.Linear(self.backbone.last_linear.in_features, 168)\n",
    "        self.fc_v = nn.Linear(self.backbone.last_linear.in_features, 11)\n",
    "        self.fc_c = nn.Linear(self.backbone.last_linear.in_features, 7)\n",
    "        self.fc_w = nn.Linear(self.backbone.last_linear.in_features, 1295)\n",
    "\n",
    "        \n",
    "        self.fc_aux1 = nn.Linear(self.num_p3_features * 4, self.num_classes)\n",
    "        self.fc_aux2 = nn.Linear(self.num_p2_features * 4, self.num_classes)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #for fc in [self.fc, self.fc_aux1, self.fc_aux2]:\n",
    "        #    nn.init.zeros_(fc.bias.data)\n",
    "        for fc in [self.fc_g, self.fc_v, self.fc_c, self.fc_w, self.fc_aux1, self.fc_aux2]:\n",
    "            nn.init.zeros_(fc.bias.data)\n",
    "\n",
    "        print('init model4')\n",
    "        \n",
    "    def features(self, x):\n",
    "        x = self.backbone.layer0(x); #print(x.size())\n",
    "        x = self.backbone.layer1(x); #print(x.size())\n",
    "        x = self.backbone.layer2(x); p2 = x; p2 = self.p2_head(p2); p2 = self.bn2(p2); p2 = self.act2(p2) #print(x.size())\n",
    "        x = self.backbone.layer3(x); p3 = x; p3 = self.p3_head(p3); p3 = self.bn3(p3); p3 = self.act3(p3) #print(x.size())\n",
    "        x = self.backbone.layer4(x); #print(x.size())\n",
    "        return x, p2, p3\n",
    "        \n",
    "    def logits(self, x, p2, p3):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        p2 = self.avg_pool(p2)\n",
    "        p2 = torch.flatten(p2, 1)\n",
    "        \n",
    "        p3 = self.avg_pool(p3)\n",
    "        p3 = torch.flatten(p3, 1)\n",
    "        \n",
    "        #logits = self.fc(x)\n",
    "        g, v, c, w = self.fc_g(x), self.fc_v(x), self.fc_c(x), self.fc_w(x)\n",
    "        logits = torch.cat([g, v, c, w], 1)\n",
    "        \n",
    "        return logits, self.fc_aux1(p3), self.fc_aux2(p2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x, p2, p3 = self.features(x)\n",
    "        x, logits_aux1, logits_aux2 = self.logits(x, p2, p3)\n",
    "\n",
    "        return x, logits_aux1, logits_aux2\n",
    "    \n",
    "    def set_mode(self, mode, is_freeze_bn=True):\n",
    "        self.mode = mode\n",
    "        if mode in ['eval', 'valid', 'test']:\n",
    "            self.eval()\n",
    "\n",
    "        elif mode in ['train']:\n",
    "            self.train()\n",
    "        if is_freeze_bn == True:  ##freeze\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "                    m.weight.requires_grad = False\n",
    "                    m.bias.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model4_se_resnext50_fold0_224_cv9976.pth\r\n",
      "model4_se_resnext50_fold0_224_cv9977.pth\r\n",
      "model4_se_resnext50_fold0_224_cv9978.pth\r\n",
      "model4_se_resnext50_fold0_224_cv998106.pth\r\n",
      "model4_se_resnext50_fold0_224_swa_cv998273.pth\r\n",
      "model4_se_resnext50_fold4_224_cv997979.pth\r\n",
      "model4_se_resnext50_fold4_224_swa_cv998285.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./model4-ckps/se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir ./model4-finetune-ckps/se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model():\n",
    "    model_old = BengaliNetOld()\n",
    "    model_old.load_state_dict(torch.load('./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold0_224_cv998106.pth'))    \n",
    "    \n",
    "    model = BengaliNet()\n",
    "    model.load_state_dict(torch.load('./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold0_224_cv998106.pth'), strict=False)\n",
    "    model.fc_g.weight.data = model_old.fc.weight.data[:168] \n",
    "    model.fc_v.weight.data = model_old.fc.weight.data[168:168+11] \n",
    "    model.fc_c.weight.data = model_old.fc.weight.data[168+11:168+11+7] \n",
    "    model.fc_w.weight.data = model_old.fc.weight.data[168+11+7:] \n",
    "    model = model.cuda()\n",
    "    model = amp.initialize(model, opt_level='O1')\n",
    "    model = nn.DataParallel(model)\n",
    "    print(validate(model, val_loader))\n",
    "    torch.save(model.module.state_dict(), './model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model4-finetune-ckps'\n",
    "def create_model(args):\n",
    "    model = BengaliNet()\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, preds3, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2) == len(preds3)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(y[:, 0], preds0, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(y[:, 1], preds1, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(y[:, 2], preds2, average='macro')\n",
    "    recall_word = sklearn.metrics.recall_score(y[:, 3], preds3, average='macro')\n",
    "    \n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    old_recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    old_recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    old_recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    old_recall_word = sklearn.metrics.recall_score(preds3, y[:, 3], average='macro')\n",
    "    \n",
    "    old_scores = [old_recall_grapheme, old_recall_vowel, old_recall_consonant]\n",
    "    old_final_recall_score = np.average(old_scores, weights=[2, 1, 1])\n",
    "\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    metrics['recall_word'] = round(recall_word, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    metrics['acc_word'] = round((preds3 == y[:, 3]).sum() / len(y), 6)  \n",
    "    \n",
    "    metrics['old_recall'] = round(old_final_recall_score, 6)\n",
    "    metrics['old_recall_grapheme'] = round(old_recall_grapheme, 6)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    loss3 = F.cross_entropy(outputs[3], y_true[:, 3], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 + loss3 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    #model.eval()\n",
    "    model.module.set_mode('valid', is_freeze_bn=True)\n",
    "\n",
    "    loss0, loss1, loss2, loss3 = 0., 0., 0., 0.\n",
    "    preds0, preds1, preds2, preds3 = [], [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs, _, _ = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            preds3.append(torch.max(outputs[3], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            loss3 += F.cross_entropy(outputs[3], y[:, 3], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    preds3 = torch.cat(preds3, 0).cpu().numpy()\n",
    "    \n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, preds3, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    metrics['loss_word'] = round(loss3 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox_new(size, lam):\n",
    "    H = size[2]\n",
    "    W = size[3]\n",
    "\n",
    "    x_margin_rate = 0.2\n",
    "\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * (1-x_margin_rate*2) * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "    \n",
    "    min_x_center = np.int(W * x_margin_rate + cut_w / 2)\n",
    "    max_x_center = np.int(W * (1-x_margin_rate) - cut_w / 2)\n",
    "    #print(min_x_center, max_x_center, lam, cut_w)\n",
    "    min_y_center = cut_h // 2\n",
    "    max_y_center = H - cut_h // 2\n",
    "    if max_y_center == min_y_center:\n",
    "        max_y_center += 1\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(min_x_center, max_x_center)\n",
    "    cy = np.random.randint(min_y_center, max_y_center)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    \n",
    "    #print(bbx1, bbx2, bby1, bby2)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22082541296591707"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_for_finetune(net):\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "    if finetune_class == 'grapheme_root':\n",
    "        for param in net.fc_g.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif finetune_class == 'vowel_diacritic':\n",
    "        for param in net.fc_v.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in net.fc_c.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid):\n",
    "    train_loss = 0\n",
    "    bg = time.time()\n",
    "\n",
    "    for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "        img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "        batch_size = img.size(0)\n",
    "        r = np.random.rand()\n",
    "\n",
    "        #if True:\n",
    "        #    outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "        #    loss = criterion(outputs, targets)\n",
    "            #loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            #loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            #loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        if r < 0.4:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            #img[:, :, bby1:bby2, bbx1:bbx2] = img[rand_index, :, bby1:bby2, bbx1:bbx2] #for new cutmix\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            #loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "            #loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "            #loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r < 0.7:\n",
    "            img = grid(img)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss = criterion(outputs, targets)\n",
    "            #loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            #loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            #loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        else:\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        #else:\n",
    "        #    orig_img, targets = mixup(orig_img, targets)\n",
    "        #    outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "        #    loss = mixup_criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        lr_scheduler(optimizer, batch_idx, epoch)\n",
    "        optimizer.step()            \n",
    "        \n",
    "        current_lr = get_lrs(optimizer)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} | {:.2f} |'.format(\n",
    "            epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "            loss.item(), train_loss/(batch_idx+1), (time.time() - bg) / 60), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "best_metrics = 0.\n",
    "best_metrics_swa = 0.\n",
    "\n",
    "\n",
    "def validate_and_save(model, model_file, val_loader, save=False):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    print('current best_metrics:', best_metrics)\n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        print('saving...')\n",
    "        best_metrics = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.module.set_mode('train', is_freeze_bn=True)\n",
    "\n",
    "def validate_and_save_swa(model, model_file, val_loader, save=False):\n",
    "    global best_metrics_swa\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics_swa:\n",
    "        best_metrics_swa = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.module.set_mode('train', is_freeze_bn=True)\n",
    "\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    model, model_file = create_model(args)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    freeze_for_finetune(model)\n",
    "\n",
    "    swa_args = copy.deepcopy(args)\n",
    "    swa_args.ckp_name = args.ckp_name + '_swa'\n",
    "    swa_model, swa_model_file = create_model(swa_args)\n",
    "    swa_model = swa_model.cuda()\n",
    "\n",
    "    optimizer = make_optimizer(model)\n",
    "    lr_scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    [model, swa_model], optimizer = amp.initialize([model, swa_model], optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    #[model, swa_model], optimizer = amp.initialize(\n",
    "    #    [model, swa_model], optimizer, opt_level=\"O2\",verbosity=0, keep_batchnorm_fp32=True)\n",
    "    \n",
    "    #opt_level=\"O2\", keep_batchnorm_fp32=True\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        swa_model = nn.DataParallel(swa_model)\n",
    "    \n",
    "    validate_and_save(model, model_file, val_loader, save=False)\n",
    "\n",
    "    swa_model_loaded = False\n",
    "    if os.path.exists(swa_model_file):\n",
    "        swa_model_loaded = True\n",
    "        validate_and_save_swa(swa_model, swa_model_file, val_loader, save=False)\n",
    "        \n",
    "    model.module.set_mode('train', is_freeze_bn=True)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "        for epoch in range(args.start_epoch, args.num_epochs):\n",
    "            grid.set_prob(epoch, args.st_epochs)\n",
    "            train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\n",
    "            validate_and_save(model, model_file, val_loader, save=True)\n",
    "            \n",
    "            if (epoch+1) == args.swa_start and cycle == 1:\n",
    "                if not swa_model_loaded:\n",
    "                    copy_model(swa_model, model)\n",
    "                #swa_n = 0\n",
    "                swa_n = args.swa_n\n",
    "            if (epoch+1) >= args.swa_start and (epoch+1) % args.swa_freq == 0:\n",
    "                print('SWA>>>:')\n",
    "                moving_average(swa_model, model, 1.0 / (swa_n + 1))\n",
    "                swa_n += 1\n",
    "                bn_update(train_loader, swa_model)\n",
    "                validate_and_save_swa(swa_model, swa_model_file, val_loader, save=True)\n",
    "\n",
    "        #args.base_lr = 2e-4\n",
    "        #args.num_epochs = 40\n",
    "        #args.warmup_epochs = 1\n",
    "\n",
    "        # reset scheduler at each cycle\n",
    "        lr_scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    del model\n",
    "    del swa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, model_file = create_model(cfg)\n",
    "#model(torch.randn(2,1,137,236))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model4_finetune_res50_fold0.pth'\n",
    "args.base_lr = 8e-5\n",
    "args.num_epochs = 20\n",
    "args.start_epoch = 0\n",
    "args.warmup_epochs = 10\n",
    "args.num_cycles = 1\n",
    "args.batch_size = 1536\n",
    "args.val_batch_size = 1024\n",
    "args.st_epochs = 5\n",
    "\n",
    "args.swa_start = 3000\n",
    "args.swa_freq = 3\n",
    "args.swa_n = 5\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.998145, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997673, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.0\n",
      "saving...\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 0.1703 | 2.9572 | 1.51 ||\n",
      "val: {'recall': 0.998137, 'recall_grapheme': 0.997593, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997663, 'old_recall_grapheme': 0.997177, 'loss_grapheme': 0.018906, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    1 | 0.000016 | 089460/160596 | 0.1921 | 3.1864 | 1.55 ||\n",
      "val: {'recall': 0.99812, 'recall_grapheme': 0.997558, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997644, 'old_recall_grapheme': 0.997139, 'loss_grapheme': 0.019173, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    2 | 0.000023 | 089460/160596 | 7.5410 | 2.5330 | 1.66 ||\n",
      "val: {'recall': 0.998133, 'recall_grapheme': 0.997584, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.99766, 'old_recall_grapheme': 0.997171, 'loss_grapheme': 0.019482, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    3 | 0.000029 | 089460/160596 | 6.1226 | 3.0282 | 1.77 ||\n",
      "val: {'recall': 0.998124, 'recall_grapheme': 0.997567, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997647, 'old_recall_grapheme': 0.997145, 'loss_grapheme': 0.020151, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    4 | 0.000034 | 089460/160596 | 10.3705 | 3.1072 | 2.01 |\n",
      "val: {'recall': 0.99813, 'recall_grapheme': 0.997577, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997608, 'old_recall_grapheme': 0.997066, 'loss_grapheme': 0.021094, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    5 | 0.000038 | 089460/160596 | 0.2230 | 2.5881 | 2.07 ||\n",
      "val: {'recall': 0.998121, 'recall_grapheme': 0.99756, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997615, 'old_recall_grapheme': 0.99708, 'loss_grapheme': 0.021863, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    6 | 0.000041 | 089460/160596 | 3.2945 | 2.4692 | 2.12 |\n",
      "val: {'recall': 0.998138, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997637, 'old_recall_grapheme': 0.997125, 'loss_grapheme': 0.022691, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    7 | 0.000042 | 089460/160596 | 4.1165 | 2.4416 | 2.09 ||\n",
      "val: {'recall': 0.998134, 'recall_grapheme': 0.997586, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997631, 'old_recall_grapheme': 0.997112, 'loss_grapheme': 0.023652, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    8 | 0.000042 | 089460/160596 | 0.1755 | 2.2430 | 2.09 ||\n",
      "val: {'recall': 0.99813, 'recall_grapheme': 0.997578, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997631, 'old_recall_grapheme': 0.997113, 'loss_grapheme': 0.024462, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    9 | 0.000040 | 089460/160596 | 0.3430 | 2.7862 | 2.12 ||\n",
      "val: {'recall': 0.99812, 'recall_grapheme': 0.997558, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997602, 'old_recall_grapheme': 0.997054, 'loss_grapheme': 0.025484, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   10 | 0.000034 | 089460/160596 | 0.3099 | 2.6487 | 2.00 ||\n",
      "val: {'recall': 0.998134, 'recall_grapheme': 0.997586, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997631, 'old_recall_grapheme': 0.997112, 'loss_grapheme': 0.026442, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   11 | 0.000028 | 089460/160596 | 0.1589 | 1.9001 | 2.19 |\n",
      "val: {'recall': 0.998115, 'recall_grapheme': 0.997548, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997568, 'old_recall_grapheme': 0.996986, 'loss_grapheme': 0.026967, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   12 | 0.000022 | 089460/160596 | 6.4740 | 2.3896 | 1.95 |\n",
      "val: {'recall': 0.998115, 'recall_grapheme': 0.997548, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997571, 'old_recall_grapheme': 0.996993, 'loss_grapheme': 0.027367, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   13 | 0.000017 | 089460/160596 | 5.2082 | 2.5639 | 2.10 ||\n",
      "val: {'recall': 0.998129, 'recall_grapheme': 0.997576, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997591, 'old_recall_grapheme': 0.997033, 'loss_grapheme': 0.027804, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   14 | 0.000012 | 089460/160596 | 0.2835 | 2.4260 | 2.17 ||\n",
      "val: {'recall': 0.998129, 'recall_grapheme': 0.997576, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997611, 'old_recall_grapheme': 0.997073, 'loss_grapheme': 0.028181, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   15 | 0.000008 | 089460/160596 | 10.3031 | 2.5568 | 2.22 |\n",
      "val: {'recall': 0.998133, 'recall_grapheme': 0.997585, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997618, 'old_recall_grapheme': 0.997086, 'loss_grapheme': 0.028383, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 0.000004 | 089460/160596 | 0.1920 | 2.3398 | 2.19 ||\n",
      "val: {'recall': 0.998133, 'recall_grapheme': 0.997585, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997597, 'old_recall_grapheme': 0.997045, 'loss_grapheme': 0.028549, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   17 | 0.000002 | 089460/160596 | 0.3027 | 3.0908 | 1.99 |\n",
      "val: {'recall': 0.998133, 'recall_grapheme': 0.997585, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997618, 'old_recall_grapheme': 0.997086, 'loss_grapheme': 0.028634, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   18 | 0.000001 | 089460/160596 | 0.1892 | 2.0680 | 2.24 ||\n",
      "val: {'recall': 0.998133, 'recall_grapheme': 0.997585, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997618, 'old_recall_grapheme': 0.997086, 'loss_grapheme': 0.028665, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   19 | 0.000000 | 089460/160596 | 9.2808 | 2.3253 | 2.16 |\n",
      "val: {'recall': 0.998133, 'recall_grapheme': 0.997585, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997618, 'old_recall_grapheme': 0.997086, 'loss_grapheme': 0.028668, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.998145, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997673, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 9.7820 | 2.7304 | 1.49 ||\n",
      "val: {'recall': 0.998111, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998445, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998807, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997663, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.047809, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    1 | 0.000016 | 089460/160596 | 0.1597 | 2.7166 | 1.64 ||\n",
      "val: {'recall': 0.998115, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998461, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998832, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997666, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.047744, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    2 | 0.000023 | 089460/160596 | 9.3161 | 2.3527 | 1.83 ||\n",
      "val: {'recall': 0.998105, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998421, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998758, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997653, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.046005, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    3 | 0.000029 | 089460/160596 | 7.3668 | 2.8547 | 1.86 ||\n",
      "val: {'recall': 0.998112, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998449, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998807, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997663, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.046583, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    4 | 0.000034 | 089460/160596 | 0.2471 | 3.2390 | 1.94 ||\n",
      "val: {'recall': 0.998112, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998449, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998807, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997663, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.049257, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    5 | 0.000038 | 089460/160596 | 0.3077 | 2.2394 | 2.20 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998438, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.046293, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    6 | 0.000041 | 089460/160596 | 0.1531 | 2.6791 | 2.28 ||\n",
      "val: {'recall': 0.998112, 'recall_grapheme': 0.997608, 'recall_vowel': 0.99845, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998807, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997663, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.045935, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    7 | 0.000042 | 089460/160596 | 6.3979 | 3.0303 | 2.26 ||\n",
      "val: {'recall': 0.998112, 'recall_grapheme': 0.997608, 'recall_vowel': 0.99845, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998807, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997663, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048046, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    8 | 0.000042 | 089460/160596 | 0.2815 | 2.3605 | 2.14 ||\n",
      "val: {'recall': 0.998119, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998478, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998832, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997666, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.045935, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "    9 | 0.000040 | 089460/160596 | 0.1443 | 3.0739 | 1.90 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998436, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.047637, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   10 | 0.000034 | 089460/160596 | 0.3130 | 2.3295 | 2.28 ||\n",
      "val: {'recall': 0.998135, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998543, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998807, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997659, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.046127, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   11 | 0.000028 | 089460/160596 | 0.1704 | 2.9152 | 2.02 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998438, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.047421, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 0.000022 | 089460/160596 | 0.3204 | 2.7616 | 2.17 |||\n",
      "val: {'recall': 0.998142, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998571, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998832, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997661, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048081, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   13 | 0.000017 | 089460/160596 | 0.2931 | 2.6291 | 2.19 ||\n",
      "val: {'recall': 0.998106, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998426, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998758, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997653, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.047388, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   14 | 0.000012 | 089460/160596 | 0.1893 | 3.1454 | 2.15 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998438, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048472, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   15 | 0.000008 | 089460/160596 | 0.1771 | 2.9064 | 2.14 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998438, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.04858, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   16 | 0.000004 | 089460/160596 | 0.3530 | 3.1542 | 1.96 ||\n",
      "val: {'recall': 0.998106, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998426, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998758, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997653, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.049294, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   17 | 0.000002 | 089460/160596 | 0.1630 | 2.8477 | 2.13 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998438, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.049215, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   18 | 0.000001 | 089460/160596 | 0.1773 | 3.4084 | 2.11 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998438, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.049292, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "   19 | 0.000000 | 089460/160596 | 0.1542 | 2.4990 | 2.11 ||\n",
      "val: {'recall': 0.998109, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998438, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997656, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.049281, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.998145, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997673, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.061712, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 0.1640 | 1.7948 | 1.57 ||\n",
      "val: {'recall': 0.998146, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998787, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997681, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.060167, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998145\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    1 | 0.000016 | 089460/160596 | 0.1648 | 2.6934 | 1.66 ||\n",
      "val: {'recall': 0.998145, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997673, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.057629, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998146\n",
      "    2 | 0.000023 | 089460/160596 | 0.1253 | 2.8365 | 1.81 ||\n",
      "val: {'recall': 0.998145, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997672, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.056512, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998146\n",
      "    3 | 0.000029 | 089460/160596 | 3.8713 | 2.7603 | 1.95 ||\n",
      "val: {'recall': 0.998145, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998781, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997673, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.053904, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998146\n",
      "    4 | 0.000034 | 089460/160596 | 7.1619 | 2.8195 | 2.07 ||\n",
      "val: {'recall': 0.998146, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998787, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997681, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.051846, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998146\n",
      "    5 | 0.000038 | 089460/160596 | 0.2210 | 2.9619 | 2.23 ||\n",
      "val: {'recall': 0.998153, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998815, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997675, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.051624, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998146\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    6 | 0.000041 | 089460/160596 | 3.1063 | 2.5341 | 2.17 ||\n",
      "val: {'recall': 0.998153, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998815, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997675, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.048656, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 | 0.000042 | 089460/160596 | 0.1897 | 3.5978 | 2.06 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.052274, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998153\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    8 | 0.000042 | 089460/160596 | 6.0626 | 2.9391 | 2.14 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.050694, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99816\n",
      "    9 | 0.000040 | 089460/160596 | 0.1511 | 2.8665 | 2.19 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.050454, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99816\n",
      "   10 | 0.000034 | 089460/160596 | 0.2177 | 2.6136 | 2.41 ||\n",
      "val: {'recall': 0.998152, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998809, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997672, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.047252, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99816\n",
      "   11 | 0.000028 | 089460/160596 | 4.3492 | 2.9574 | 2.28 |||\n",
      "val: {'recall': 0.998162, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997682, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99816\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "   12 | 0.000022 | 089460/160596 | 0.2442 | 3.6474 | 2.08 ||\n",
      "val: {'recall': 0.998162, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997682, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.050898, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   13 | 0.000017 | 089460/160596 | 0.1795 | 1.7590 | 2.48 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.047608, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   14 | 0.000012 | 089460/160596 | 0.1874 | 2.3562 | 2.24 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.046941, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   15 | 0.000008 | 089460/160596 | 0.1943 | 2.7136 | 2.20 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.046388, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   16 | 0.000004 | 089460/160596 | 0.1236 | 2.5559 | 2.29 ||\n",
      "val: {'recall': 0.998159, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998836, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998932, 'acc_word': 0.997217, 'old_recall': 0.997666, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.046402, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   17 | 0.000002 | 089460/160596 | 0.1427 | 2.3644 | 2.51 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.045996, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   18 | 0.000001 | 089460/160596 | 6.4171 | 3.0245 | 2.18 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.045996, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   19 | 0.000000 | 089460/160596 | 3.2800 | 3.4624 | 2.00 ||\n",
      "val: {'recall': 0.99816, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998842, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998956, 'acc_word': 0.997217, 'old_recall': 0.997674, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.045991, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.998162, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997682, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 6.1910 | 3.0087 | 1.59 ||\n",
      "val: {'recall': 0.998154, 'recall_grapheme': 0.997593, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997672, 'old_recall_grapheme': 0.997177, 'loss_grapheme': 0.0189, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    1 | 0.000016 | 089460/160596 | 7.6506 | 2.7998 | 1.72 |\n",
      "val: {'recall': 0.998154, 'recall_grapheme': 0.997593, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997672, 'old_recall_grapheme': 0.997177, 'loss_grapheme': 0.019138, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000023 | 089460/160596 | 0.1538 | 2.5567 | 1.90 ||\n",
      "val: {'recall': 0.998154, 'recall_grapheme': 0.997593, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997672, 'old_recall_grapheme': 0.997177, 'loss_grapheme': 0.019496, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    3 | 0.000029 | 089460/160596 | 0.1910 | 2.5929 | 2.17 |\n",
      "val: {'recall': 0.998137, 'recall_grapheme': 0.99756, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997607, 'old_recall_grapheme': 0.997047, 'loss_grapheme': 0.020002, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    4 | 0.000034 | 089460/160596 | 0.2000 | 2.7012 | 2.12 |||\n",
      "val: {'recall': 0.998145, 'recall_grapheme': 0.997576, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997624, 'old_recall_grapheme': 0.99708, 'loss_grapheme': 0.020714, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    5 | 0.000038 | 089460/160596 | 0.1359 | 2.7778 | 2.40 ||\n",
      "val: {'recall': 0.998141, 'recall_grapheme': 0.997567, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997627, 'old_recall_grapheme': 0.997088, 'loss_grapheme': 0.021534, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    6 | 0.000041 | 089460/160596 | 0.1826 | 2.9073 | 2.21 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997626, 'old_recall_grapheme': 0.997084, 'loss_grapheme': 0.022731, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    7 | 0.000042 | 089460/160596 | 0.2938 | 2.5285 | 2.24 ||\n",
      "val: {'recall': 0.998154, 'recall_grapheme': 0.997593, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997676, 'old_recall_grapheme': 0.997184, 'loss_grapheme': 0.023564, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    8 | 0.000042 | 089460/160596 | 0.1784 | 2.6215 | 2.35 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997646, 'old_recall_grapheme': 0.997125, 'loss_grapheme': 0.024784, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    9 | 0.000040 | 089460/160596 | 2.8319 | 3.0466 | 2.14 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997646, 'old_recall_grapheme': 0.997125, 'loss_grapheme': 0.026209, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   10 | 0.000034 | 089460/160596 | 3.7922 | 2.8243 | 2.19 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997646, 'old_recall_grapheme': 0.997125, 'loss_grapheme': 0.02742, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   11 | 0.000028 | 089460/160596 | 0.2476 | 2.4014 | 2.43 | |\n",
      "val: {'recall': 0.998142, 'recall_grapheme': 0.997569, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.99761, 'old_recall_grapheme': 0.997052, 'loss_grapheme': 0.028249, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   12 | 0.000022 | 089460/160596 | 0.2522 | 2.3836 | 2.39 ||\n",
      "val: {'recall': 0.998128, 'recall_grapheme': 0.997541, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997566, 'old_recall_grapheme': 0.996965, 'loss_grapheme': 0.028826, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   13 | 0.000017 | 089460/160596 | 0.1716 | 2.4627 | 2.21 |\n",
      "val: {'recall': 0.998142, 'recall_grapheme': 0.997569, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.99761, 'old_recall_grapheme': 0.997052, 'loss_grapheme': 0.029224, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   14 | 0.000012 | 089460/160596 | 0.2931 | 1.9356 | 2.26 ||\n",
      "val: {'recall': 0.998142, 'recall_grapheme': 0.997569, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997416, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.99761, 'old_recall_grapheme': 0.997052, 'loss_grapheme': 0.029512, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   15 | 0.000008 | 089460/160596 | 0.2955 | 2.5304 | 2.22 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997626, 'old_recall_grapheme': 0.997084, 'loss_grapheme': 0.029737, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   16 | 0.000004 | 089460/160596 | 0.1725 | 3.1288 | 2.13 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997626, 'old_recall_grapheme': 0.997084, 'loss_grapheme': 0.029892, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   17 | 0.000002 | 089460/160596 | 0.1556 | 2.3748 | 2.39 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997626, 'old_recall_grapheme': 0.997084, 'loss_grapheme': 0.029967, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "   18 | 0.000001 | 089460/160596 | 0.2528 | 2.8442 | 2.13 ||\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997626, 'old_recall_grapheme': 0.997084, 'loss_grapheme': 0.029993, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 0.000000 | 089460/160596 | 0.1976 | 2.2427 | 2.26 |\n",
      "val: {'recall': 0.998155, 'recall_grapheme': 0.997595, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.997441, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997626, 'old_recall_grapheme': 0.997084, 'loss_grapheme': 0.029996, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.998162, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998582, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998857, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997682, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048159, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 0.1688 | 2.5762 | 1.65 ||\n",
      "val: {'recall': 0.998124, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998433, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998782, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.99767, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.047896, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    1 | 0.000016 | 089460/160596 | 11.0766 | 3.2943 | 1.77 |\n",
      "val: {'recall': 0.998127, 'recall_grapheme': 0.997608, 'recall_vowel': 0.998445, 'recall_consonant': 0.998848, 'recall_word': 0.997165, 'acc_grapheme': 0.99749, 'acc_vowel': 0.998807, 'acc_consonant': 0.998981, 'acc_word': 0.997217, 'old_recall': 0.997672, 'old_recall_grapheme': 0.997197, 'loss_grapheme': 0.018819, 'loss_vowel': 0.048682, 'loss_consonant': 0.047829, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.998162\n",
      "    2 | 0.000023 | 089460/160596 | 0.2058 | 2.9046 | 1.89 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a32ae825230b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         train_loader, val_loader = get_train_val_loaders(\n\u001b[1;32m      6\u001b[0m             batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-d723ed925816>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_start\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-d723ed925816>\u001b[0m in \u001b[0;36mvalidate_and_save\u001b[0;34m(model, model_file, val_loader, save)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbest_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current best_metrics:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-00ac01bd309e>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpreds2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpreds3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for x in ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']:\n",
    "        finetune_class = x\n",
    "        #dataset use finetune_class\n",
    "        train_loader, val_loader = get_train_val_loaders(\n",
    "            batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)\n",
    "        train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.997599, 'recall_grapheme': 0.997435, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997316, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997988, 'old_recall_grapheme': 0.997634, 'loss_grapheme': 0.012611, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.0\n",
      "saving...\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 9.7284 | 5.1435 | 1.53 ||\n",
      "val: {'recall': 0.997604, 'recall_grapheme': 0.997445, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997341, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997993, 'old_recall_grapheme': 0.997644, 'loss_grapheme': 0.012664, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    1 | 0.000016 | 089460/160596 | 0.0715 | 4.8492 | 1.59 ||\n",
      "val: {'recall': 0.997612, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.998039, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997604\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    2 | 0.000023 | 089460/160596 | 4.1406 | 4.5930 | 1.74 |||\n",
      "val: {'recall': 0.997559, 'recall_grapheme': 0.997354, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997267, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997876, 'old_recall_grapheme': 0.997411, 'loss_grapheme': 0.013091, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "    3 | 0.000029 | 089460/160596 | 6.5505 | 5.2001 | 1.82 ||\n",
      "val: {'recall': 0.997547, 'recall_grapheme': 0.997331, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997658, 'old_recall_grapheme': 0.996975, 'loss_grapheme': 0.013467, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "    4 | 0.000034 | 089460/160596 | 6.5734 | 5.1172 | 2.00 ||\n",
      "val: {'recall': 0.997549, 'recall_grapheme': 0.997334, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997566, 'old_recall_grapheme': 0.99679, 'loss_grapheme': 0.01382, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "    5 | 0.000038 | 089460/160596 | 10.4989 | 5.7089 | 1.99 ||\n",
      "val: {'recall': 0.997536, 'recall_grapheme': 0.997308, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997553, 'old_recall_grapheme': 0.996764, 'loss_grapheme': 0.014886, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "    6 | 0.000041 | 089460/160596 | 0.1085 | 4.8819 | 2.18 ||\n",
      "val: {'recall': 0.997501, 'recall_grapheme': 0.997238, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997068, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997485, 'old_recall_grapheme': 0.996628, 'loss_grapheme': 0.015807, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "    7 | 0.000042 | 089460/160596 | 4.4068 | 4.7285 | 2.10 ||\n",
      "val: {'recall': 0.997501, 'recall_grapheme': 0.997238, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997068, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997505, 'old_recall_grapheme': 0.996669, 'loss_grapheme': 0.016545, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "    8 | 0.000042 | 089460/160596 | 0.1404 | 5.1410 | 2.13 ||\n",
      "val: {'recall': 0.997532, 'recall_grapheme': 0.997301, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997544, 'old_recall_grapheme': 0.996746, 'loss_grapheme': 0.016914, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "    9 | 0.000040 | 089460/160596 | 4.4390 | 5.2525 | 1.98 ||\n",
      "val: {'recall': 0.997535, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997552, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.017571, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   10 | 0.000034 | 089460/160596 | 11.0524 | 5.1987 | 2.13 |\n",
      "val: {'recall': 0.997573, 'recall_grapheme': 0.997382, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997591, 'old_recall_grapheme': 0.996842, 'loss_grapheme': 0.018923, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   11 | 0.000028 | 089460/160596 | 11.1530 | 4.9847 | 2.10 ||\n",
      "val: {'recall': 0.997573, 'recall_grapheme': 0.997382, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997591, 'old_recall_grapheme': 0.996842, 'loss_grapheme': 0.019612, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   12 | 0.000022 | 089460/160596 | 9.2806 | 4.4619 | 2.11 ||\n",
      "val: {'recall': 0.997568, 'recall_grapheme': 0.997372, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997586, 'old_recall_grapheme': 0.996832, 'loss_grapheme': 0.020344, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   13 | 0.000017 | 089460/160596 | 0.1299 | 4.9661 | 2.05 ||\n",
      "val: {'recall': 0.997547, 'recall_grapheme': 0.99733, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99757, 'old_recall_grapheme': 0.996799, 'loss_grapheme': 0.020761, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   14 | 0.000012 | 089460/160596 | 0.1874 | 5.5957 | 1.92 ||\n",
      "val: {'recall': 0.997547, 'recall_grapheme': 0.99733, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99757, 'old_recall_grapheme': 0.996799, 'loss_grapheme': 0.021613, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 0.000008 | 089460/160596 | 0.0529 | 4.5044 | 2.13 ||\n",
      "val: {'recall': 0.99754, 'recall_grapheme': 0.997317, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997564, 'old_recall_grapheme': 0.996786, 'loss_grapheme': 0.021738, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   16 | 0.000004 | 089460/160596 | 5.8024 | 5.1690 | 2.05 |||\n",
      "val: {'recall': 0.99753, 'recall_grapheme': 0.997295, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997093, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997547, 'old_recall_grapheme': 0.996752, 'loss_grapheme': 0.021883, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   17 | 0.000002 | 089460/160596 | 0.1557 | 4.7194 | 2.12 ||\n",
      "val: {'recall': 0.997562, 'recall_grapheme': 0.997359, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99758, 'old_recall_grapheme': 0.99682, 'loss_grapheme': 0.021944, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   18 | 0.000001 | 089460/160596 | 10.2892 | 4.9502 | 2.10 |\n",
      "val: {'recall': 0.997562, 'recall_grapheme': 0.997359, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99758, 'old_recall_grapheme': 0.99682, 'loss_grapheme': 0.021994, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "   19 | 0.000000 | 089460/160596 | 7.4245 | 4.6886 | 2.16 ||\n",
      "val: {'recall': 0.997562, 'recall_grapheme': 0.997359, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99758, 'old_recall_grapheme': 0.99682, 'loss_grapheme': 0.021999, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.997612, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.998039, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 2.4964 | 5.1706 | 1.48 ||\n",
      "val: {'recall': 0.997613, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998105, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998708, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997991, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.00556, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997612\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    1 | 0.000016 | 089460/160596 | 8.0899 | 5.9714 | 1.59 |||\n",
      "val: {'recall': 0.997648, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998244, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997971, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.005759, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997613\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    2 | 0.000023 | 089460/160596 | 11.8239 | 5.1052 | 1.81 |\n",
      "val: {'recall': 0.997648, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998244, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997971, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.005988, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997648\n",
      "    3 | 0.000029 | 089460/160596 | 8.5591 | 5.5185 | 1.86 |||\n",
      "val: {'recall': 0.997649, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998247, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997976, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.006626, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997648\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    4 | 0.000034 | 089460/160596 | 0.1058 | 4.9609 | 1.93 ||\n",
      "val: {'recall': 0.997651, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998258, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997975, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.007242, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997649\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    5 | 0.000038 | 089460/160596 | 2.1151 | 5.1206 | 2.20 ||\n",
      "val: {'recall': 0.997651, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998258, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99798, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.008207, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997651\n",
      "    6 | 0.000041 | 089460/160596 | 5.5848 | 5.2339 | 2.18 ||\n",
      "val: {'recall': 0.997651, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998258, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997975, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.009842, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997651\n",
      "    7 | 0.000042 | 089460/160596 | 0.1698 | 3.9995 | 2.31 ||\n",
      "val: {'recall': 0.99765, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998253, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99798, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.012552, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997651\n",
      "    8 | 0.000042 | 089460/160596 | 9.4105 | 5.4858 | 2.08 ||\n",
      "val: {'recall': 0.997674, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998347, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997999, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.016016, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997651\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    9 | 0.000040 | 089460/160596 | 0.2199 | 5.5721 | 2.29 ||\n",
      "val: {'recall': 0.997646, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998237, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997977, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.022355, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 | 0.000034 | 089460/160596 | 4.3462 | 5.7685 | 2.13 |||\n",
      "val: {'recall': 0.997672, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998342, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997999, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.028682, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997674\n",
      "   11 | 0.000028 | 089460/160596 | 5.9411 | 4.2174 | 2.34 ||\n",
      "val: {'recall': 0.997672, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998342, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997999, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.032831, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997674\n",
      "   12 | 0.000022 | 089460/160596 | 4.1325 | 5.5647 | 2.14 |||\n",
      "val: {'recall': 0.997666, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998318, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997996, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.038961, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997674\n",
      "   13 | 0.000017 | 089460/160596 | 0.2084 | 4.8803 | 2.15 ||\n",
      "val: {'recall': 0.997666, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998318, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997996, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.043076, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997674\n",
      "   14 | 0.000012 | 089460/160596 | 0.1200 | 5.3458 | 2.09 ||\n",
      "val: {'recall': 0.99767, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998331, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997995, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.045796, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997674\n",
      "   15 | 0.000008 | 089460/160596 | 8.1655 | 4.8086 | 2.11 ||\n",
      "val: {'recall': 0.997691, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997998, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997674\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "   16 | 0.000004 | 089460/160596 | 6.2297 | 4.4675 | 2.31 ||\n",
      "val: {'recall': 0.997691, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997998, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047976, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997691\n",
      "   17 | 0.000002 | 089460/160596 | 2.5620 | 4.9278 | 2.11 ||\n",
      "val: {'recall': 0.99767, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998331, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997995, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.048584, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997691\n",
      "   18 | 0.000001 | 089460/160596 | 6.9137 | 4.7434 | 2.33 |||\n",
      "val: {'recall': 0.997691, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997998, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.0489, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997691\n",
      "   19 | 0.000000 | 089460/160596 | 1.1400 | 5.1742 | 2.22 ||\n",
      "val: {'recall': 0.997691, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997998, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.048918, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997691\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.997691, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997998, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997691\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 12.4708 | 5.0579 | 1.58 |\n",
      "val: {'recall': 0.997825, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997964, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997956, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.0046, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997691\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    1 | 0.000016 | 089460/160596 | 7.8487 | 5.3791 | 1.74 ||\n",
      "val: {'recall': 0.997838, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997944, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997825\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    2 | 0.000023 | 089460/160596 | 7.8830 | 5.4295 | 1.91 ||\n",
      "val: {'recall': 0.99783, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997982, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997943, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.005079, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    3 | 0.000029 | 089460/160596 | 12.5206 | 4.9070 | 1.99 |\n",
      "val: {'recall': 0.997821, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997949, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998807, 'acc_word': 0.997217, 'old_recall': 0.997635, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.005298, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    4 | 0.000034 | 089460/160596 | 6.3221 | 5.1818 | 2.08 ||\n",
      "val: {'recall': 0.997821, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997949, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998807, 'acc_word': 0.997217, 'old_recall': 0.997635, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.005761, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 | 0.000038 | 089460/160596 | 9.6173 | 5.6947 | 2.19 ||\n",
      "val: {'recall': 0.997798, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997854, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998782, 'acc_word': 0.997217, 'old_recall': 0.997628, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.006549, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    6 | 0.000041 | 089460/160596 | 0.1253 | 5.2910 | 2.14 ||\n",
      "val: {'recall': 0.997799, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997859, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998807, 'acc_word': 0.997217, 'old_recall': 0.997636, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.007912, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    7 | 0.000042 | 089460/160596 | 7.9552 | 4.9036 | 2.30 ||\n",
      "val: {'recall': 0.997821, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997949, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998807, 'acc_word': 0.997217, 'old_recall': 0.997635, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.009509, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    8 | 0.000042 | 089460/160596 | 11.7138 | 5.1047 | 2.39 |\n",
      "val: {'recall': 0.997821, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997949, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998807, 'acc_word': 0.997217, 'old_recall': 0.997635, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.012078, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    9 | 0.000040 | 089460/160596 | 0.4132 | 5.5010 | 2.18 ||\n",
      "val: {'recall': 0.997821, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997949, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998807, 'acc_word': 0.997217, 'old_recall': 0.997635, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.015988, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   10 | 0.000034 | 089460/160596 | 0.2030 | 5.2271 | 2.27 ||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.019779, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   11 | 0.000028 | 089460/160596 | 0.1766 | 5.5070 | 2.20 ||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.023639, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   12 | 0.000022 | 089460/160596 | 5.1166 | 5.0853 | 2.24 |||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.02754, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   13 | 0.000017 | 089460/160596 | 0.1536 | 4.5003 | 2.30 ||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.030146, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   14 | 0.000012 | 089460/160596 | 5.6350 | 4.8218 | 2.26 |||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.032212, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   15 | 0.000008 | 089460/160596 | 0.1916 | 4.7689 | 2.38 ||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.03353, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   16 | 0.000004 | 089460/160596 | 0.7480 | 4.9470 | 2.32 ||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.034209, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   17 | 0.000002 | 089460/160596 | 4.1360 | 5.0647 | 2.22 |||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.034668, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   18 | 0.000001 | 089460/160596 | 0.1774 | 5.4647 | 2.07 |||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.034971, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   19 | 0.000000 | 089460/160596 | 0.1886 | 4.4491 | 2.28 ||\n",
      "val: {'recall': 0.997823, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.997954, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998832, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.034985, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.997838, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997944, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 0.0881 | 4.7000 | 1.62 ||\n",
      "val: {'recall': 0.997834, 'recall_grapheme': 0.997451, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997341, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997933, 'old_recall_grapheme': 0.997714, 'loss_grapheme': 0.012868, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000016 | 089460/160596 | 0.1030 | 4.9418 | 1.76 ||\n",
      "val: {'recall': 0.997808, 'recall_grapheme': 0.9974, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997242, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997804, 'old_recall_grapheme': 0.997457, 'loss_grapheme': 0.013034, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    2 | 0.000023 | 089460/160596 | 3.8748 | 4.9595 | 1.85 ||\n",
      "val: {'recall': 0.997772, 'recall_grapheme': 0.997327, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997192, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997672, 'old_recall_grapheme': 0.997192, 'loss_grapheme': 0.013275, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    3 | 0.000029 | 089460/160596 | 0.1156 | 4.4821 | 2.04 |||\n",
      "val: {'recall': 0.997779, 'recall_grapheme': 0.997341, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997192, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997589, 'old_recall_grapheme': 0.997026, 'loss_grapheme': 0.013668, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    4 | 0.000034 | 089460/160596 | 10.2494 | 4.8324 | 2.20 |\n",
      "val: {'recall': 0.997767, 'recall_grapheme': 0.997317, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997464, 'old_recall_grapheme': 0.996777, 'loss_grapheme': 0.01407, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    5 | 0.000038 | 089460/160596 | 0.1670 | 5.0801 | 2.33 ||\n",
      "val: {'recall': 0.997762, 'recall_grapheme': 0.997308, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997433, 'old_recall_grapheme': 0.996713, 'loss_grapheme': 0.014939, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    6 | 0.000041 | 089460/160596 | 6.9295 | 4.0159 | 2.56 ||\n",
      "val: {'recall': 0.997756, 'recall_grapheme': 0.997295, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997093, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997431, 'old_recall_grapheme': 0.996711, 'loss_grapheme': 0.015464, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    7 | 0.000042 | 089460/160596 | 6.7610 | 4.4421 | 2.31 ||\n",
      "val: {'recall': 0.997767, 'recall_grapheme': 0.997318, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997463, 'old_recall_grapheme': 0.996774, 'loss_grapheme': 0.015843, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    8 | 0.000042 | 089460/160596 | 0.1366 | 5.2097 | 2.14 ||\n",
      "val: {'recall': 0.997742, 'recall_grapheme': 0.997267, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99747, 'old_recall_grapheme': 0.996787, 'loss_grapheme': 0.017902, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    9 | 0.000040 | 089460/160596 | 5.1427 | 4.6240 | 2.40 |||\n",
      "val: {'recall': 0.997767, 'recall_grapheme': 0.997318, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997463, 'old_recall_grapheme': 0.996774, 'loss_grapheme': 0.018476, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   10 | 0.000034 | 089460/160596 | 11.0610 | 4.2949 | 2.35 |\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.018871, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   11 | 0.000028 | 089460/160596 | 4.2575 | 5.2733 | 2.18 ||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.020375, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   12 | 0.000022 | 089460/160596 | 0.1812 | 4.6796 | 2.19 ||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.020559, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   13 | 0.000017 | 089460/160596 | 0.1748 | 5.6431 | 2.20 ||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.021565, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   14 | 0.000012 | 089460/160596 | 7.3362 | 4.8915 | 2.24 |||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.022347, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   15 | 0.000008 | 089460/160596 | 0.1857 | 4.9011 | 2.26 ||\n",
      "val: {'recall': 0.997778, 'recall_grapheme': 0.99734, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99748, 'old_recall_grapheme': 0.996809, 'loss_grapheme': 0.023097, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   16 | 0.000004 | 089460/160596 | 6.0492 | 4.5310 | 2.22 ||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.023147, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   17 | 0.000002 | 089460/160596 | 9.2761 | 4.6259 | 2.22 ||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.023116, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 0.000001 | 089460/160596 | 3.1216 | 4.4779 | 2.23 ||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.023137, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "   19 | 0.000000 | 089460/160596 | 6.8637 | 3.9008 | 2.51 ||\n",
      "val: {'recall': 0.997761, 'recall_grapheme': 0.997305, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997457, 'old_recall_grapheme': 0.996762, 'loss_grapheme': 0.023134, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.997838, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997944, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.047237, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "CYCLE: 1\n",
      "    0 | 0.000008 | 089460/160596 | 0.0635 | 4.5402 | 1.66 |||\n",
      "val: {'recall': 0.997838, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998418, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997944, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.048106, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    1 | 0.000016 | 089460/160596 | 0.1342 | 4.7718 | 1.83 |||\n",
      "val: {'recall': 0.997816, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998331, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997942, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.051082, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    2 | 0.000023 | 089460/160596 | 6.2955 | 5.1656 | 1.90 ||\n",
      "val: {'recall': 0.997809, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998303, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998733, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997939, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.056104, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "    3 | 0.000029 | 089460/160596 | 1.5830 | 4.2844 | 2.08 ||\n",
      "val: {'recall': 0.99784, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998425, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997944, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.058288, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997838\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    4 | 0.000034 | 089460/160596 | 11.6994 | 5.0863 | 2.23 |\n",
      "val: {'recall': 0.997833, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998397, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997941, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.06565, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99784\n",
      "    5 | 0.000038 | 089460/160596 | 2.0082 | 5.6103 | 2.33 ||\n",
      "val: {'recall': 0.997833, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998397, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997941, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.076172, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99784\n",
      "    6 | 0.000041 | 089460/160596 | 6.9947 | 4.5551 | 2.49 ||\n",
      "val: {'recall': 0.997836, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998409, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997948, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.077327, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99784\n",
      "    7 | 0.000042 | 089460/160596 | 6.3401 | 5.4710 | 2.30 |||\n",
      "val: {'recall': 0.997836, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998409, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997948, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.084329, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99784\n",
      "    8 | 0.000042 | 089460/160596 | 10.7636 | 4.7870 | 2.37 ||\n",
      "val: {'recall': 0.997842, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998434, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998807, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997951, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.08702, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.99784\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    9 | 0.000040 | 089460/160596 | 5.5259 | 5.8234 | 2.22 ||\n",
      "val: {'recall': 0.997833, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998398, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998758, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997942, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.095328, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997842\n",
      "   10 | 0.000034 | 089460/160596 | 0.2244 | 4.6748 | 2.45 ||\n",
      "val: {'recall': 0.997839, 'recall_grapheme': 0.997459, 'recall_vowel': 0.998423, 'recall_consonant': 0.998015, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998782, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997945, 'old_recall_grapheme': 0.997737, 'loss_grapheme': 0.012829, 'loss_vowel': 0.092443, 'loss_consonant': 0.004851, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997842\n",
      "   11 | 0.000031 | 066048/160596 | 0.2245 | 5.1232 | 1.01 |||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a32ae825230b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         train_loader, val_loader = get_train_val_loaders(\n\u001b[1;32m      6\u001b[0m             batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-d723ed925816>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-98b588f75273>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_no_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpost_backward_models_are_masters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_models_are_masters\u001b[0;34m(scaler, params, stashed_grads, scale_override)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mstashed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mgrads_needing_unscale_with_stash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Clear the stash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[1;32m    182\u001b[0m                                              \u001b[0mmaster_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                              \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                                              out_scale/stashed_have_scale)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Defer to update_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed_python\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, a, b)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                                                  \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                                                                  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                                                                  self.dynamic)\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36maxpby_check_overflow_python\u001b[0;34m(model_grad, stashed_grad, master_grad, a, b, check_overflow)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Exception handling for 18.04 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcpu_sum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for x in ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']:\n",
    "        finetune_class = x\n",
    "        #dataset use finetune_class\n",
    "        train_loader, val_loader = get_train_val_loaders(\n",
    "            batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)\n",
    "        train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth, exist: True\n",
      "loading ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth...\n",
      "init model4\n",
      "model file: ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.997562, 'recall_grapheme': 0.99736, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997391, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.998109, 'old_recall_grapheme': 0.997877, 'loss_grapheme': 0.012186, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.0\n",
      "saving...\n",
      "CYCLE: 1\n",
      "    0 | 0.000016 | 089460/160596 | 0.0435 | 4.7303 | 1.52 ||\n",
      "val: {'recall': 0.997582, 'recall_grapheme': 0.997401, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997366, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.998066, 'old_recall_grapheme': 0.997791, 'loss_grapheme': 0.012252, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997562\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    1 | 0.000031 | 089460/160596 | 0.0553 | 5.5662 | 1.55 |||\n",
      "val: {'recall': 0.997599, 'recall_grapheme': 0.997435, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997316, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997988, 'old_recall_grapheme': 0.997634, 'loss_grapheme': 0.012611, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997582\n",
      "saving...\n",
      "###>>>>> saved ./model4-finetune-ckps/se_resnext50_32x4d/model4_finetune_res50_fold0.pth\n",
      "    2 | 0.000046 | 089460/160596 | 10.3188 | 5.4924 | 1.73 ||\n",
      "val: {'recall': 0.997583, 'recall_grapheme': 0.997402, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997242, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997889, 'old_recall_grapheme': 0.997436, 'loss_grapheme': 0.013361, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "    3 | 0.000060 | 089460/160596 | 2.0757 | 5.6277 | 1.77 ||\n",
      "val: {'recall': 0.997586, 'recall_grapheme': 0.997408, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997192, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99763, 'old_recall_grapheme': 0.996918, 'loss_grapheme': 0.014454, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "    4 | 0.000072 | 089460/160596 | 0.1175 | 5.2480 | 1.85 ||\n",
      "val: {'recall': 0.997545, 'recall_grapheme': 0.997325, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997563, 'old_recall_grapheme': 0.996785, 'loss_grapheme': 0.01516, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "    5 | 0.000069 | 089460/160596 | 0.1238 | 5.0280 | 2.04 |||\n",
      "val: {'recall': 0.997548, 'recall_grapheme': 0.997332, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997604, 'old_recall_grapheme': 0.996867, 'loss_grapheme': 0.016724, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "    6 | 0.000066 | 089460/160596 | 6.7547 | 5.0535 | 1.96 ||\n",
      "val: {'recall': 0.997539, 'recall_grapheme': 0.997314, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997558, 'old_recall_grapheme': 0.996775, 'loss_grapheme': 0.016964, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "    7 | 0.000061 | 089460/160596 | 8.0017 | 5.1064 | 1.97 ||\n",
      "val: {'recall': 0.997556, 'recall_grapheme': 0.997348, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997217, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997575, 'old_recall_grapheme': 0.996808, 'loss_grapheme': 0.018706, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "    8 | 0.000057 | 089460/160596 | 9.6001 | 4.8044 | 1.98 ||\n",
      "val: {'recall': 0.997561, 'recall_grapheme': 0.997358, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997217, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997586, 'old_recall_grapheme': 0.996831, 'loss_grapheme': 0.020691, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "    9 | 0.000052 | 089460/160596 | 3.4438 | 4.4151 | 2.14 ||\n",
      "val: {'recall': 0.997556, 'recall_grapheme': 0.997348, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997217, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997643, 'old_recall_grapheme': 0.996945, 'loss_grapheme': 0.021886, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   10 | 0.000048 | 089460/160596 | 0.0984 | 5.1467 | 2.05 ||\n",
      "val: {'recall': 0.997555, 'recall_grapheme': 0.997346, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997192, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.99758, 'old_recall_grapheme': 0.996819, 'loss_grapheme': 0.024712, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   11 | 0.000043 | 089460/160596 | 3.1868 | 4.9108 | 2.05 ||\n",
      "val: {'recall': 0.99755, 'recall_grapheme': 0.997337, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997574, 'old_recall_grapheme': 0.996807, 'loss_grapheme': 0.027805, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   12 | 0.000038 | 089460/160596 | 2.7114 | 4.7316 | 1.98 |||\n",
      "val: {'recall': 0.997545, 'recall_grapheme': 0.997327, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997142, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997569, 'old_recall_grapheme': 0.996796, 'loss_grapheme': 0.030177, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   13 | 0.000033 | 089460/160596 | 6.7204 | 5.6764 | 1.85 ||\n",
      "val: {'recall': 0.997553, 'recall_grapheme': 0.997342, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997192, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997661, 'old_recall_grapheme': 0.996981, 'loss_grapheme': 0.033233, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   14 | 0.000028 | 089460/160596 | 9.1342 | 4.9345 | 2.09 ||\n",
      "val: {'recall': 0.997557, 'recall_grapheme': 0.99735, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997217, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997673, 'old_recall_grapheme': 0.997004, 'loss_grapheme': 0.035283, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 0.000023 | 089460/160596 | 0.1825 | 4.7170 | 2.08 |||\n",
      "val: {'recall': 0.997553, 'recall_grapheme': 0.997342, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997192, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997661, 'old_recall_grapheme': 0.996981, 'loss_grapheme': 0.037644, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   16 | 0.000019 | 089460/160596 | 0.1292 | 4.2994 | 2.06 ||\n",
      "val: {'recall': 0.99755, 'recall_grapheme': 0.997337, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997574, 'old_recall_grapheme': 0.996807, 'loss_grapheme': 0.038869, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   17 | 0.000015 | 089460/160596 | 0.1810 | 4.9253 | 2.15 |||\n",
      "val: {'recall': 0.997553, 'recall_grapheme': 0.997342, 'recall_vowel': 0.998099, 'recall_consonant': 0.997429, 'recall_word': 0.997165, 'acc_grapheme': 0.997192, 'acc_vowel': 0.998683, 'acc_consonant': 0.998857, 'acc_word': 0.997217, 'old_recall': 0.997661, 'old_recall_grapheme': 0.996981, 'loss_grapheme': 0.040167, 'loss_vowel': 0.005505, 'loss_consonant': 0.004546, 'loss_word': 0.012468}\n",
      "current best_metrics: 0.997599\n",
      "   18 | 0.000012 | 093696/160596 | 10.0541 | 4.9298 | 1.28 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a32ae825230b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         train_loader, val_loader = get_train_val_loaders(\n\u001b[1;32m      6\u001b[0m             batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-d723ed925816>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-98b588f75273>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_aux1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_aux2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m#loss_aux1 = criterion(outputs_aux1, targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for x in ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']:\n",
    "        finetune_class = x\n",
    "        #dataset use finetune_class\n",
    "        train_loader, val_loader = get_train_val_loaders(\n",
    "            batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)\n",
    "        train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n",
      "sampler length: torch.Size([160596])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
