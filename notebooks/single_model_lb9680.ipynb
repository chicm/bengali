{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install opencv-python\\n!pip install fastparquet\\n!pip install pyarrow\\n!pip install snappy\\n!conda install python-snappy -y\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install opencv-python\n",
    "!pip install fastparquet\n",
    "!pip install pyarrow\n",
    "!pip install snappy\n",
    "!conda install python-snappy -y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengaliai-cv19.zip\t   test_image_data_3.parquet\r\n",
      "class_map.csv\t\t   train.csv\r\n",
      "sample_submission.csv\t   train_image_data_0.parquet\r\n",
      "test.csv\t\t   train_image_data_1.parquet\r\n",
      "test_image_data_0.parquet  train_image_data_2.parquet\r\n",
      "test_image_data_1.parquet  train_image_data_3.parquet\r\n",
      "test_image_data_2.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/chicm/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_type</th>\n",
       "      <th>label</th>\n",
       "      <th>component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>0</td>\n",
       "      <td>ং</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>1</td>\n",
       "      <td>ঃ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>2</td>\n",
       "      <td>অ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>3</td>\n",
       "      <td>আ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>4</td>\n",
       "      <td>ই</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  component_type  label component\n",
       "0  grapheme_root      0         ং\n",
       "1  grapheme_root      1         ঃ\n",
       "2  grapheme_root      2         অ\n",
       "3  grapheme_root      3         আ\n",
       "4  grapheme_root      4         ই"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200840, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.image_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72     5736\n",
       "64     5596\n",
       "13     5420\n",
       "107    5321\n",
       "23     5149\n",
       "       ... \n",
       "130     144\n",
       "158     143\n",
       "102     141\n",
       "33      136\n",
       "73      130\n",
       "Name: grapheme_root, Length: 168, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.grapheme_root.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>32322</th>\n",
       "      <th>32323</th>\n",
       "      <th>32324</th>\n",
       "      <th>32325</th>\n",
       "      <th>32326</th>\n",
       "      <th>32327</th>\n",
       "      <th>32328</th>\n",
       "      <th>32329</th>\n",
       "      <th>32330</th>\n",
       "      <th>32331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>251</td>\n",
       "      <td>244</td>\n",
       "      <td>238</td>\n",
       "      <td>245</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>248</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
       "0  Train_0  254  253  252  253  251  252  253  251  251  ...    253    253   \n",
       "1  Train_1  251  244  238  245  248  246  246  247  251  ...    255    255   \n",
       "2  Train_2  251  250  249  250  249  245  247  252  252  ...    254    253   \n",
       "3  Train_3  247  247  249  253  253  252  251  251  250  ...    254    254   \n",
       "4  Train_4  249  248  246  246  248  244  242  242  229  ...    255    255   \n",
       "\n",
       "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
       "0    253    253    253    253    253    253    253    251  \n",
       "1    255    255    255    255    255    255    255    254  \n",
       "2    252    252    253    253    253    253    251    249  \n",
       "3    254    254    254    253    253    252    251    252  \n",
       "4    255    255    255    255    255    255    255    255  \n",
       "\n",
       "[5 rows x 32333 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50210, 32333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32322</th>\n",
       "      <th>32323</th>\n",
       "      <th>32324</th>\n",
       "      <th>32325</th>\n",
       "      <th>32326</th>\n",
       "      <th>32327</th>\n",
       "      <th>32328</th>\n",
       "      <th>32329</th>\n",
       "      <th>32330</th>\n",
       "      <th>32331</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Train_0</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_1</td>\n",
       "      <td>251</td>\n",
       "      <td>244</td>\n",
       "      <td>238</td>\n",
       "      <td>245</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_2</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_3</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_4</td>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>248</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>229</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9  ...  32322  32323  \\\n",
       "image_id                                                    ...                 \n",
       "Train_0   254  253  252  253  251  252  253  251  251  253  ...    253    253   \n",
       "Train_1   251  244  238  245  248  246  246  247  251  252  ...    255    255   \n",
       "Train_2   251  250  249  250  249  245  247  252  252  252  ...    254    253   \n",
       "Train_3   247  247  249  253  253  252  251  251  250  250  ...    254    254   \n",
       "Train_4   249  248  246  246  248  244  242  242  229  225  ...    255    255   \n",
       "\n",
       "          32324  32325  32326  32327  32328  32329  32330  32331  \n",
       "image_id                                                          \n",
       "Train_0     253    253    253    253    253    253    253    251  \n",
       "Train_1     255    255    255    255    255    255    255    254  \n",
       "Train_2     252    252    253    253    253    253    251    249  \n",
       "Train_3     254    254    254    253    253    252    251    252  \n",
       "Train_4     255    255    255    255    255    255    255    255  \n",
       "\n",
       "[5 rows x 32332 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Train_0', 'Train_1', 'Train_2', 'Train_3', 'Train_4', 'Train_5',\n",
       "       'Train_6', 'Train_7', 'Train_8', 'Train_9',\n",
       "       ...\n",
       "       'Train_50200', 'Train_50201', 'Train_50202', 'Train_50203',\n",
       "       'Train_50204', 'Train_50205', 'Train_50206', 'Train_50207',\n",
       "       'Train_50208', 'Train_50209'],\n",
       "      dtype='object', name='image_id', length=50210)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = 255 - df.iloc[10, 1:].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img2 = cv2.resize(img, (256, 128))\n",
    "#plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = get_train_augs(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 137, 236])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=augs(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    train = train_df.iloc[:split_index]\n",
    "    val = train_df.iloc[split_index:]\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(50210, 32332)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor img, y in train_loader:\\n    print(img.size(), y.size())\\n    print(y)\\n    #print(img)\\n    #plt.imshow(img.squeeze()[0].numpy())\\n    break\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for img, y in train_loader:\n",
    "    print(img.size(), y.size())\n",
    "    print(y)\n",
    "    #print(img)\n",
    "    #plt.imshow(img.squeeze()[0].numpy())\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048, 5, 8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/best_model.pth, exist: False\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "\n",
    "bnet = create_model(args)[0].cuda()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 137, 236])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 186])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum().item()\n",
    "        res.append(correct_k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(50210, 32332)\n"
     ]
    }
   ],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(batch_size=32, val_batch_size=128, dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parallel.data_parallel.DataParallel"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 146, in forward\n    \"them on device: {}\".format(self.src_device_obj, t.device))\nRuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-b8d4784e56d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-5a448d477a7c>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 146, in forward\n    \"them on device: {}\".format(self.src_device_obj, t.device))\nRuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(180756, 5) (20084, 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/best_model.pth, exist: False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.beta(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler.step(best_metrics)\n",
    "    else:\n",
    "        lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            outputs = model(img)\n",
    "            #loss = mixup_criterion(outputs, targets)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #with amp.scale_loss(loss*batch_size, optimizer) as scaled_loss:\n",
    "            #    scaled_loss.backward()\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 5e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 8\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 50\n",
    "args.batch_size = 512\n",
    "args.val_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(180756, 5) (20084, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/best_model.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/best_model.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.9671440534027664, 'recall_grapheme': 0.9493775668155872, 'recall_vowel': 0.9814981361011735, 'recall_consonant': 0.9883229438787181, 'acc_grapheme': 0.9517028480382393, 'acc_vowel': 0.986705835490938, 'acc_consonant': 0.9859589723162716, 'loss_grapheme': 0.16853864101317984, 'loss_vowel': 0.06034584744378785, 'loss_consonant': 0.04872297896400578}\n",
      "    0 | 0.000010 | 051200/180756 | 0.0994 | 0.0825 |val: {'recall': 0.9740534755083553, 'recall_grapheme': 0.9603027657701281, 'recall_vowel': 0.9860325981284788, 'recall_consonant': 0.9895757723646864, 'acc_grapheme': 0.9601672973511253, 'acc_vowel': 0.988797052380004, 'acc_consonant': 0.9891953794064927, 'loss_grapheme': 0.13787380800473217, 'loss_vowel': 0.04863242665222265, 'loss_consonant': 0.03757896084539493}\n",
      "** saved\n",
      "    0 | 0.000010 | 102400/180756 | 0.0460 | 0.0741 |val: {'recall': 0.9749220658515402, 'recall_grapheme': 0.9619530557647916, 'recall_vowel': 0.986462546838192, 'recall_consonant': 0.9893196050383853, 'acc_grapheme': 0.9620593507269468, 'acc_vowel': 0.9895937064329815, 'acc_consonant': 0.9892949611631149, 'loss_grapheme': 0.13537521273034236, 'loss_vowel': 0.04674217501999111, 'loss_consonant': 0.03797635113758482}\n",
      "** saved\n",
      "    0 | 0.000010 | 153600/180756 | 0.0428 | 0.0696 |val: {'recall': 0.9751739051237696, 'recall_grapheme': 0.9625710565256457, 'recall_vowel': 0.9869184216290331, 'recall_consonant': 0.9886350858147537, 'acc_grapheme': 0.963752240589524, 'acc_vowel': 0.989892451702848, 'acc_consonant': 0.9892451702848039, 'loss_grapheme': 0.1302957535264882, 'loss_vowel': 0.04573672168213541, 'loss_consonant': 0.03696964922428036}\n",
      "** saved\n",
      "    1 | 0.000010 | 024064/180756 | 0.0315 | 0.0446 |val: {'recall': 0.9750624542312984, 'recall_grapheme': 0.96214045550981, 'recall_vowel': 0.9860316101541315, 'recall_consonant': 0.9899372957514421, 'acc_grapheme': 0.9628560047799243, 'acc_vowel': 0.9897928699462258, 'acc_consonant': 0.9896434973112925, 'loss_grapheme': 0.13007670221896647, 'loss_vowel': 0.0457381858362237, 'loss_consonant': 0.03684783816408812}\n",
      "    1 | 0.000010 | 075264/180756 | 0.0438 | 0.0428 |val: {'recall': 0.9759409026484658, 'recall_grapheme': 0.9636359918427835, 'recall_vowel': 0.9864726812052974, 'recall_consonant': 0.9900189457029984, 'acc_grapheme': 0.9634037044413464, 'acc_vowel': 0.9897928699462258, 'acc_consonant': 0.9895439155546704, 'loss_grapheme': 0.13118413714530625, 'loss_vowel': 0.04574202052437198, 'loss_consonant': 0.03706903120265779}\n",
      "** saved\n",
      "    1 | 0.000010 | 126464/180756 | 0.0284 | 0.0415 |val: {'recall': 0.975758683760602, 'recall_grapheme': 0.9635425928691448, 'recall_vowel': 0.9865034991646037, 'recall_consonant': 0.989446050139515, 'acc_grapheme': 0.9634037044413464, 'acc_vowel': 0.9900916152160925, 'acc_consonant': 0.9895439155546704, 'loss_grapheme': 0.13320959082069542, 'loss_vowel': 0.0474076366263114, 'loss_consonant': 0.03851307458170997}\n",
      "    1 | 0.000010 | 177664/180756 | 0.0108 | 0.0408 |val: {'recall': 0.9758321965375945, 'recall_grapheme': 0.9639961565512216, 'recall_vowel': 0.98578982659673, 'recall_consonant': 0.9895466464512046, 'acc_grapheme': 0.9635530770762796, 'acc_vowel': 0.9901911969727146, 'acc_consonant': 0.9896932881896037, 'loss_grapheme': 0.13242811317155143, 'loss_vowel': 0.047923585079837384, 'loss_consonant': 0.03905498176617253}\n",
      "    2 | 0.000010 | 048128/180756 | 0.0181 | 0.0272 |val: {'recall': 0.9762434966258606, 'recall_grapheme': 0.9635731978791721, 'recall_vowel': 0.9873939229524357, 'recall_consonant': 0.990433667792663, 'acc_grapheme': 0.963752240589524, 'acc_vowel': 0.9902409878510257, 'acc_consonant': 0.9896434973112925, 'loss_grapheme': 0.13413968997466044, 'loss_vowel': 0.046674263937922976, 'loss_consonant': 0.040138983769237316}\n",
      "** saved\n",
      "    2 | 0.000010 | 099328/180756 | 0.0164 | 0.0279 |val: {'recall': 0.9767467077027782, 'recall_grapheme': 0.9652673685066775, 'recall_vowel': 0.9867037520302285, 'recall_consonant': 0.9897483417675291, 'acc_grapheme': 0.963802031467835, 'acc_vowel': 0.9900916152160925, 'acc_consonant': 0.9897430790679148, 'loss_grapheme': 0.13543192653203956, 'loss_vowel': 0.04801121944688844, 'loss_consonant': 0.03999328656017104}\n",
      "** saved\n",
      "    2 | 0.000010 | 150528/180756 | 0.0257 | 0.0276 |val: {'recall': 0.9756676160111016, 'recall_grapheme': 0.963348952827112, 'recall_vowel': 0.9869176017314344, 'recall_consonant': 0.9890549566587482, 'acc_grapheme': 0.9626070503883688, 'acc_vowel': 0.989842660824537, 'acc_consonant': 0.9895439155546704, 'loss_grapheme': 0.1370451587102632, 'loss_vowel': 0.048894861261580144, 'loss_consonant': 0.04149442328278512}\n",
      "    3 | 0.000010 | 020992/180756 | 0.0257 | 0.0186 |val: {'recall': 0.9750903667000965, 'recall_grapheme': 0.9617796787321257, 'recall_vowel': 0.9875159977342037, 'recall_consonant': 0.989286111601931, 'acc_grapheme': 0.9629057956582354, 'acc_vowel': 0.9902409878510257, 'acc_consonant': 0.9896434973112925, 'loss_grapheme': 0.13863841909451496, 'loss_vowel': 0.048751229262641645, 'loss_consonant': 0.04169369877583713}\n",
      "    3 | 0.000010 | 072192/180756 | 0.0149 | 0.0194 |val: {'recall': 0.975513950873411, 'recall_grapheme': 0.9627367424769842, 'recall_vowel': 0.9874413018437749, 'recall_consonant': 0.9891410166959008, 'acc_grapheme': 0.9628062139016133, 'acc_vowel': 0.9901911969727146, 'acc_consonant': 0.989344752041426, 'loss_grapheme': 0.13962754175687211, 'loss_vowel': 0.04926418270444614, 'loss_consonant': 0.04404609994189337}\n",
      "    3 | 0.000010 | 123392/180756 | 0.0267 | 0.0188 |val: {'recall': 0.975491376972071, 'recall_grapheme': 0.9627564582782294, 'recall_vowel': 0.9873238548634167, 'recall_consonant': 0.9891287364684087, 'acc_grapheme': 0.9635530770762796, 'acc_vowel': 0.9899422425811591, 'acc_consonant': 0.9895439155546704, 'loss_grapheme': 0.14005507930914401, 'loss_vowel': 0.050053033439839086, 'loss_consonant': 0.04268180319712566}\n",
      "    3 | 0.000006 | 174592/180756 | 0.0103 | 0.0187 |val: {'recall': 0.9750254339937822, 'recall_grapheme': 0.9620989700180514, 'recall_vowel': 0.9867678436340352, 'recall_consonant': 0.9891359523049906, 'acc_grapheme': 0.9628062139016133, 'acc_vowel': 0.989892451702848, 'acc_consonant': 0.9896434973112925, 'loss_grapheme': 0.1422623556179251, 'loss_vowel': 0.04986587422607762, 'loss_consonant': 0.0425505136451121}\n",
      "    4 | 0.000006 | 045056/180756 | 0.0079 | 0.0125 |val: {'recall': 0.9746264675335751, 'recall_grapheme': 0.9611692792115449, 'recall_vowel': 0.9866422234274782, 'recall_consonant': 0.9895250882837322, 'acc_grapheme': 0.9627066321449911, 'acc_vowel': 0.9899422425811591, 'acc_consonant': 0.9899422425811591, 'loss_grapheme': 0.14236097852444415, 'loss_vowel': 0.050550898667992505, 'loss_consonant': 0.04268252984909061}\n",
      "    4 | 0.000006 | 096256/180756 | 0.0130 | 0.0131 |val: {'recall': 0.9754500454206412, 'recall_grapheme': 0.9627243018527364, 'recall_vowel': 0.9869395636013163, 'recall_consonant': 0.9894120143757761, 'acc_grapheme': 0.9631547500497909, 'acc_vowel': 0.9897928699462258, 'acc_consonant': 0.9896434973112925, 'loss_grapheme': 0.1453313167483131, 'loss_vowel': 0.05171688442044086, 'loss_consonant': 0.043270910256318754}\n",
      "    4 | 0.000006 | 147456/180756 | 0.0103 | 0.0130 |val: {'recall': 0.9758045329108987, 'recall_grapheme': 0.9629346757363484, 'recall_vowel': 0.9883485391227331, 'recall_consonant': 0.989000241048165, 'acc_grapheme': 0.9633539135630352, 'acc_vowel': 0.9903405696076478, 'acc_consonant': 0.989344752041426, 'loss_grapheme': 0.14388527639404614, 'loss_vowel': 0.05220696629815025, 'loss_consonant': 0.044115977181877375}\n",
      "    5 | 0.000004 | 017920/180756 | 0.0097 | 0.0095 |val: {'recall': 0.9758115659550795, 'recall_grapheme': 0.9629279107060386, 'recall_vowel': 0.9880483056226347, 'recall_consonant': 0.989342136785606, 'acc_grapheme': 0.9637024497112129, 'acc_vowel': 0.9902907787293368, 'acc_consonant': 0.9895937064329815, 'loss_grapheme': 0.1432989347363297, 'loss_vowel': 0.05266706078348348, 'loss_consonant': 0.044463879557345355}\n",
      "    5 | 0.000004 | 069120/180756 | 0.0072 | 0.0100 |val: {'recall': 0.9758275561146927, 'recall_grapheme': 0.9633199531342337, 'recall_vowel': 0.9879507008626547, 'recall_consonant': 0.9887196173276491, 'acc_grapheme': 0.9636028679545907, 'acc_vowel': 0.9902409878510257, 'acc_consonant': 0.989344752041426, 'loss_grapheme': 0.14613257596939594, 'loss_vowel': 0.05266115874841474, 'loss_consonant': 0.0448664104860158}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 | 0.000004 | 085248/180756 | 0.0069 | 0.0100 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-00277f74151f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mtrain_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mnotify\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwaiter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwaiters_to_notify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mall_waiters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) # no any augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.976747, 'recall_grapheme': 0.965267, 'recall_vowel': 0.986704, 'recall_consonant': 0.989748, 'acc_grapheme': 0.963802, 'acc_vowel': 0.990092, 'acc_consonant': 0.989743, 'loss_grapheme': 0.135432, 'loss_vowel': 0.048011, 'loss_consonant': 0.039993}\n",
      "    0 | 0.000010 | 051200/180756 | 4.7450 | 4.0992 |\n",
      "val: {'recall': 0.963693, 'recall_grapheme': 0.947814, 'recall_vowel': 0.974848, 'recall_consonant': 0.984297, 'acc_grapheme': 0.928152, 'acc_vowel': 0.962856, 'acc_consonant': 0.969478, 'loss_grapheme': 0.463083, 'loss_vowel': 0.247168, 'loss_consonant': 0.142234}\n",
      "    0 | 0.000010 | 102400/180756 | 3.7406 | 3.6959 |\n",
      "val: {'recall': 0.970157, 'recall_grapheme': 0.954592, 'recall_vowel': 0.982368, 'recall_consonant': 0.989077, 'acc_grapheme': 0.945877, 'acc_vowel': 0.978391, 'acc_consonant': 0.983967, 'loss_grapheme': 0.372751, 'loss_vowel': 0.206895, 'loss_consonant': 0.1229}\n",
      "    0 | 0.000010 | 153600/180756 | 4.4351 | 3.5165 |\n",
      "val: {'recall': 0.970651, 'recall_grapheme': 0.955192, 'recall_vowel': 0.982385, 'recall_consonant': 0.989833, 'acc_grapheme': 0.947172, 'acc_vowel': 0.981577, 'acc_consonant': 0.983818, 'loss_grapheme': 0.375125, 'loss_vowel': 0.195665, 'loss_consonant': 0.127896}\n",
      "    1 | 0.000010 | 024064/180756 | 3.9232 | 3.0214 |\n",
      "val: {'recall': 0.971033, 'recall_grapheme': 0.955547, 'recall_vowel': 0.982889, 'recall_consonant': 0.990151, 'acc_grapheme': 0.95011, 'acc_vowel': 0.982274, 'acc_consonant': 0.984913, 'loss_grapheme': 0.3867, 'loss_vowel': 0.199148, 'loss_consonant': 0.126845}\n",
      "    1 | 0.000006 | 075264/180756 | 4.1044 | 3.0879 |\n",
      "val: {'recall': 0.971035, 'recall_grapheme': 0.955004, 'recall_vowel': 0.983644, 'recall_consonant': 0.990491, 'acc_grapheme': 0.949861, 'acc_vowel': 0.983121, 'acc_consonant': 0.98581, 'loss_grapheme': 0.361984, 'loss_vowel': 0.191709, 'loss_consonant': 0.123712}\n",
      "    1 | 0.000006 | 126464/180756 | 2.8043 | 3.0372 |\n",
      "val: {'recall': 0.97019, 'recall_grapheme': 0.953997, 'recall_vowel': 0.982794, 'recall_consonant': 0.98997, 'acc_grapheme': 0.947919, 'acc_vowel': 0.982125, 'acc_consonant': 0.984565, 'loss_grapheme': 0.409513, 'loss_vowel': 0.196711, 'loss_consonant': 0.131472}\n",
      "    1 | 0.000006 | 177664/180756 | 2.1379 | 3.0271 |\n",
      "val: {'recall': 0.971165, 'recall_grapheme': 0.955324, 'recall_vowel': 0.983768, 'recall_consonant': 0.990244, 'acc_grapheme': 0.952201, 'acc_vowel': 0.983967, 'acc_consonant': 0.986308, 'loss_grapheme': 0.321493, 'loss_vowel': 0.170142, 'loss_consonant': 0.113065}\n",
      "    2 | 0.000006 | 048128/180756 | 4.2759 | 3.0783 |\n",
      "val: {'recall': 0.970275, 'recall_grapheme': 0.95377, 'recall_vowel': 0.983072, 'recall_consonant': 0.990488, 'acc_grapheme': 0.948915, 'acc_vowel': 0.982573, 'acc_consonant': 0.984714, 'loss_grapheme': 0.410202, 'loss_vowel': 0.206609, 'loss_consonant': 0.135286}\n",
      "    2 | 0.000004 | 099328/180756 | 1.5747 | 3.0093 |\n",
      "val: {'recall': 0.970895, 'recall_grapheme': 0.954507, 'recall_vowel': 0.984196, 'recall_consonant': 0.99037, 'acc_grapheme': 0.952002, 'acc_vowel': 0.984167, 'acc_consonant': 0.985959, 'loss_grapheme': 0.351002, 'loss_vowel': 0.179956, 'loss_consonant': 0.12262}\n",
      "    2 | 0.000004 | 150528/180756 | 4.3741 | 2.9909 |\n",
      "val: {'recall': 0.970137, 'recall_grapheme': 0.953565, 'recall_vowel': 0.982577, 'recall_consonant': 0.99084, 'acc_grapheme': 0.951454, 'acc_vowel': 0.982772, 'acc_consonant': 0.985212, 'loss_grapheme': 0.3937, 'loss_vowel': 0.198877, 'loss_consonant': 0.13048}\n",
      "    3 | 0.000004 | 020992/180756 | 0.9716 | 2.7991 |\n",
      "val: {'recall': 0.971505, 'recall_grapheme': 0.956448, 'recall_vowel': 0.984113, 'recall_consonant': 0.989012, 'acc_grapheme': 0.953744, 'acc_vowel': 0.98561, 'acc_consonant': 0.987602, 'loss_grapheme': 0.298331, 'loss_vowel': 0.152671, 'loss_consonant': 0.107855}\n",
      "    3 | 0.000004 | 072192/180756 | 3.6900 | 2.9108 |\n",
      "val: {'recall': 0.970866, 'recall_grapheme': 0.955007, 'recall_vowel': 0.983157, 'recall_consonant': 0.990295, 'acc_grapheme': 0.951703, 'acc_vowel': 0.983619, 'acc_consonant': 0.985461, 'loss_grapheme': 0.35397, 'loss_vowel': 0.182834, 'loss_consonant': 0.12164}\n",
      "    3 | 0.000002 | 123392/180756 | 3.6066 | 2.8743 |\n",
      "val: {'recall': 0.971144, 'recall_grapheme': 0.955204, 'recall_vowel': 0.983555, 'recall_consonant': 0.990614, 'acc_grapheme': 0.952699, 'acc_vowel': 0.984864, 'acc_consonant': 0.986308, 'loss_grapheme': 0.341825, 'loss_vowel': 0.167364, 'loss_consonant': 0.116564}\n",
      "    3 | 0.000002 | 174592/180756 | 4.3577 | 2.8709 |\n",
      "val: {'recall': 0.972333, 'recall_grapheme': 0.957074, 'recall_vowel': 0.984147, 'recall_consonant': 0.991038, 'acc_grapheme': 0.954043, 'acc_vowel': 0.984864, 'acc_consonant': 0.987054, 'loss_grapheme': 0.337129, 'loss_vowel': 0.166454, 'loss_consonant': 0.116437}\n",
      "    4 | 0.000002 | 045056/180756 | 0.9858 | 3.0601 |\n",
      "val: {'recall': 0.971315, 'recall_grapheme': 0.955222, 'recall_vowel': 0.984066, 'recall_consonant': 0.990751, 'acc_grapheme': 0.952748, 'acc_vowel': 0.984415, 'acc_consonant': 0.986357, 'loss_grapheme': 0.32196, 'loss_vowel': 0.1686, 'loss_consonant': 0.114456}\n",
      "    4 | 0.000002 | 096256/180756 | 1.1953 | 2.8790 |\n",
      "val: {'recall': 0.971721, 'recall_grapheme': 0.955779, 'recall_vowel': 0.984051, 'recall_consonant': 0.991274, 'acc_grapheme': 0.953396, 'acc_vowel': 0.984814, 'acc_consonant': 0.986955, 'loss_grapheme': 0.326267, 'loss_vowel': 0.163234, 'loss_consonant': 0.112503}\n",
      "    4 | 0.000001 | 147456/180756 | 0.9051 | 2.8962 |\n",
      "val: {'recall': 0.972323, 'recall_grapheme': 0.957852, 'recall_vowel': 0.984456, 'recall_consonant': 0.989132, 'acc_grapheme': 0.955288, 'acc_vowel': 0.986656, 'acc_consonant': 0.987851, 'loss_grapheme': 0.275664, 'loss_vowel': 0.138693, 'loss_consonant': 0.10058}\n",
      "    5 | 0.000001 | 017920/180756 | 0.6275 | 2.9190 |\n",
      "val: {'recall': 0.970506, 'recall_grapheme': 0.954018, 'recall_vowel': 0.983428, 'recall_consonant': 0.990558, 'acc_grapheme': 0.95011, 'acc_vowel': 0.983918, 'acc_consonant': 0.984864, 'loss_grapheme': 0.405666, 'loss_vowel': 0.193282, 'loss_consonant': 0.130923}\n",
      "    5 | 0.000001 | 069120/180756 | 4.3164 | 2.8821 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-122109ec29a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m#print('train:', train_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m#save_model(model, model_file+'_latest')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-0e344cb1f778>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.976747, 'recall_grapheme': 0.965267, 'recall_vowel': 0.986704, 'recall_consonant': 0.989748, 'acc_grapheme': 0.963802, 'acc_vowel': 0.990092, 'acc_consonant': 0.989743, 'loss_grapheme': 0.135432, 'loss_vowel': 0.048011, 'loss_consonant': 0.039993}\n",
      "    0 | 0.000048 | 102400/180756 | 2.6321 | 3.3057 |\n",
      "val: {'recall': 0.970491, 'recall_grapheme': 0.954772, 'recall_vowel': 0.983103, 'recall_consonant': 0.989318, 'acc_grapheme': 0.952251, 'acc_vowel': 0.98322, 'acc_consonant': 0.985162, 'loss_grapheme': 0.347249, 'loss_vowel': 0.173147, 'loss_consonant': 0.115511}\n",
      "    1 | 0.000043 | 024064/180756 | 4.2951 | 2.7619 |\n",
      "val: {'recall': 0.968969, 'recall_grapheme': 0.951771, 'recall_vowel': 0.982496, 'recall_consonant': 0.989839, 'acc_grapheme': 0.950707, 'acc_vowel': 0.983021, 'acc_consonant': 0.984565, 'loss_grapheme': 0.34995, 'loss_vowel': 0.167536, 'loss_consonant': 0.112798}\n",
      "    1 | 0.000035 | 126464/180756 | 4.1030 | 2.9337 |\n",
      "val: {'recall': 0.969143, 'recall_grapheme': 0.951986, 'recall_vowel': 0.982753, 'recall_consonant': 0.989847, 'acc_grapheme': 0.949512, 'acc_vowel': 0.98332, 'acc_consonant': 0.984216, 'loss_grapheme': 0.388579, 'loss_vowel': 0.182685, 'loss_consonant': 0.120717}\n",
      "    2 | 0.000026 | 048128/180756 | 0.9789 | 2.7180 |\n",
      "val: {'recall': 0.970828, 'recall_grapheme': 0.955022, 'recall_vowel': 0.983208, 'recall_consonant': 0.99006, 'acc_grapheme': 0.953396, 'acc_vowel': 0.984067, 'acc_consonant': 0.984167, 'loss_grapheme': 0.367802, 'loss_vowel': 0.177641, 'loss_consonant': 0.115087}\n",
      "    2 | 0.000016 | 150528/180756 | 1.5387 | 2.6548 |\n",
      "val: {'recall': 0.971447, 'recall_grapheme': 0.955781, 'recall_vowel': 0.984209, 'recall_consonant': 0.990016, 'acc_grapheme': 0.953047, 'acc_vowel': 0.984963, 'acc_consonant': 0.985113, 'loss_grapheme': 0.376621, 'loss_vowel': 0.172289, 'loss_consonant': 0.11998}\n",
      "    3 | 0.000008 | 072192/180756 | 3.9016 | 2.4956 |\n",
      "val: {'recall': 0.972398, 'recall_grapheme': 0.957406, 'recall_vowel': 0.984564, 'recall_consonant': 0.990215, 'acc_grapheme': 0.956035, 'acc_vowel': 0.98581, 'acc_consonant': 0.986059, 'loss_grapheme': 0.323264, 'loss_vowel': 0.14981, 'loss_consonant': 0.105812}\n",
      "    3 | 0.000003 | 174592/180756 | 3.7372 | 2.5971 |\n",
      "val: {'recall': 0.972687, 'recall_grapheme': 0.957856, 'recall_vowel': 0.984719, 'recall_consonant': 0.990316, 'acc_grapheme': 0.956284, 'acc_vowel': 0.986606, 'acc_consonant': 0.987054, 'loss_grapheme': 0.291488, 'loss_vowel': 0.139039, 'loss_consonant': 0.097383}\n",
      "    4 | 0.000001 | 096256/180756 | 2.8385 | 2.5180 |\n",
      "val: {'recall': 0.972937, 'recall_grapheme': 0.958258, 'recall_vowel': 0.984886, 'recall_consonant': 0.990345, 'acc_grapheme': 0.956134, 'acc_vowel': 0.985859, 'acc_consonant': 0.986009, 'loss_grapheme': 0.334788, 'loss_vowel': 0.162023, 'loss_consonant': 0.108535}\n",
      "    5 | 0.000003 | 017920/180756 | 1.0227 | 2.7237 |\n",
      "val: {'recall': 0.971654, 'recall_grapheme': 0.95622, 'recall_vowel': 0.983991, 'recall_consonant': 0.990183, 'acc_grapheme': 0.954392, 'acc_vowel': 0.985511, 'acc_consonant': 0.985561, 'loss_grapheme': 0.351709, 'loss_vowel': 0.165513, 'loss_consonant': 0.114523}\n",
      "    5 | 0.000008 | 120320/180756 | 2.6643 | 2.5640 |\n",
      "val: {'recall': 0.97252, 'recall_grapheme': 0.957481, 'recall_vowel': 0.98455, 'recall_consonant': 0.99057, 'acc_grapheme': 0.955188, 'acc_vowel': 0.98566, 'acc_consonant': 0.986357, 'loss_grapheme': 0.357282, 'loss_vowel': 0.169423, 'loss_consonant': 0.110803}\n",
      "    6 | 0.000016 | 041984/180756 | 1.1060 | 2.5879 |\n",
      "val: {'recall': 0.972855, 'recall_grapheme': 0.958111, 'recall_vowel': 0.984907, 'recall_consonant': 0.990289, 'acc_grapheme': 0.955537, 'acc_vowel': 0.98561, 'acc_consonant': 0.985312, 'loss_grapheme': 0.356116, 'loss_vowel': 0.171679, 'loss_consonant': 0.112938}\n",
      "    6 | 0.000025 | 144384/180756 | 3.5600 | 2.5216 |\n",
      "val: {'recall': 0.972369, 'recall_grapheme': 0.957102, 'recall_vowel': 0.984785, 'recall_consonant': 0.990486, 'acc_grapheme': 0.955487, 'acc_vowel': 0.986308, 'acc_consonant': 0.986606, 'loss_grapheme': 0.290646, 'loss_vowel': 0.138927, 'loss_consonant': 0.097661}\n",
      "    7 | 0.000035 | 066048/180756 | 2.0612 | 2.5278 |\n",
      "val: {'recall': 0.971974, 'recall_grapheme': 0.956105, 'recall_vowel': 0.984602, 'recall_consonant': 0.991083, 'acc_grapheme': 0.956383, 'acc_vowel': 0.986009, 'acc_consonant': 0.985959, 'loss_grapheme': 0.318964, 'loss_vowel': 0.15332, 'loss_consonant': 0.11289}\n",
      "    7 | 0.000043 | 168448/180756 | 3.1260 | 2.4978 |\n",
      "val: {'recall': 0.973939, 'recall_grapheme': 0.960217, 'recall_vowel': 0.9851, 'recall_consonant': 0.990222, 'acc_grapheme': 0.958773, 'acc_vowel': 0.986905, 'acc_consonant': 0.98805, 'loss_grapheme': 0.261529, 'loss_vowel': 0.135556, 'loss_consonant': 0.084359}\n",
      "    8 | 0.000048 | 090112/180756 | 2.4270 | 2.4908 |\n",
      "val: {'recall': 0.973375, 'recall_grapheme': 0.958536, 'recall_vowel': 0.985484, 'recall_consonant': 0.990946, 'acc_grapheme': 0.957528, 'acc_vowel': 0.987005, 'acc_consonant': 0.986905, 'loss_grapheme': 0.255537, 'loss_vowel': 0.134702, 'loss_consonant': 0.095546}\n",
      "    9 | 0.000050 | 011776/180756 | 1.9842 | 2.4616 |\n",
      "val: {'recall': 0.97249, 'recall_grapheme': 0.956669, 'recall_vowel': 0.984657, 'recall_consonant': 0.991964, 'acc_grapheme': 0.956632, 'acc_vowel': 0.986059, 'acc_consonant': 0.987403, 'loss_grapheme': 0.329253, 'loss_vowel': 0.1668, 'loss_consonant': 0.10941}\n",
      "    9 | 0.000048 | 114176/180756 | 2.5289 | 2.4238 |\n",
      "val: {'recall': 0.973635, 'recall_grapheme': 0.958872, 'recall_vowel': 0.985762, 'recall_consonant': 0.991037, 'acc_grapheme': 0.957578, 'acc_vowel': 0.987254, 'acc_consonant': 0.987751, 'loss_grapheme': 0.312005, 'loss_vowel': 0.130625, 'loss_consonant': 0.100109}\n",
      "   10 | 0.000043 | 035840/180756 | 0.8977 | 2.2134 |\n",
      "val: {'recall': 0.975405, 'recall_grapheme': 0.962241, 'recall_vowel': 0.985455, 'recall_consonant': 0.991682, 'acc_grapheme': 0.960068, 'acc_vowel': 0.98805, 'acc_consonant': 0.989046, 'loss_grapheme': 0.242782, 'loss_vowel': 0.116695, 'loss_consonant': 0.084591}\n",
      "   10 | 0.000035 | 138240/180756 | 3.1260 | 2.2963 |\n",
      "val: {'recall': 0.972979, 'recall_grapheme': 0.958128, 'recall_vowel': 0.984068, 'recall_consonant': 0.991593, 'acc_grapheme': 0.95713, 'acc_vowel': 0.98581, 'acc_consonant': 0.987054, 'loss_grapheme': 0.30146, 'loss_vowel': 0.156453, 'loss_consonant': 0.11659}\n",
      "   11 | 0.000026 | 059904/180756 | 2.0176 | 2.0774 |\n",
      "val: {'recall': 0.975105, 'recall_grapheme': 0.962989, 'recall_vowel': 0.98525, 'recall_consonant': 0.989192, 'acc_grapheme': 0.961462, 'acc_vowel': 0.987204, 'acc_consonant': 0.989544, 'loss_grapheme': 0.228583, 'loss_vowel': 0.119316, 'loss_consonant': 0.083102}\n",
      "   11 | 0.000016 | 162304/180756 | 2.1960 | 2.1257 |\n",
      "val: {'recall': 0.974196, 'recall_grapheme': 0.961338, 'recall_vowel': 0.985628, 'recall_consonant': 0.988479, 'acc_grapheme': 0.959968, 'acc_vowel': 0.987502, 'acc_consonant': 0.988498, 'loss_grapheme': 0.279051, 'loss_vowel': 0.144291, 'loss_consonant': 0.099836}\n",
      "   12 | 0.000008 | 083968/180756 | 2.4956 | 2.0858 |\n",
      "val: {'recall': 0.97499, 'recall_grapheme': 0.961509, 'recall_vowel': 0.986151, 'recall_consonant': 0.99079, 'acc_grapheme': 0.960217, 'acc_vowel': 0.988, 'acc_consonant': 0.988946, 'loss_grapheme': 0.252919, 'loss_vowel': 0.128673, 'loss_consonant': 0.09039}\n",
      "   13 | 0.000003 | 005632/180756 | 0.6069 | 2.1811 |\n",
      "val: {'recall': 0.975841, 'recall_grapheme': 0.96291, 'recall_vowel': 0.986581, 'recall_consonant': 0.990965, 'acc_grapheme': 0.961113, 'acc_vowel': 0.98805, 'acc_consonant': 0.988996, 'loss_grapheme': 0.235786, 'loss_vowel': 0.12078, 'loss_consonant': 0.08773}\n",
      "   13 | 0.000001 | 108032/180756 | 2.8015 | 2.1623 |\n",
      "val: {'recall': 0.975086, 'recall_grapheme': 0.96164, 'recall_vowel': 0.986154, 'recall_consonant': 0.990909, 'acc_grapheme': 0.958026, 'acc_vowel': 0.987602, 'acc_consonant': 0.988548, 'loss_grapheme': 0.295644, 'loss_vowel': 0.142621, 'loss_consonant': 0.106418}\n",
      "   14 | 0.000003 | 029696/180756 | 1.8851 | 2.0784 |\n",
      "val: {'recall': 0.975826, 'recall_grapheme': 0.963173, 'recall_vowel': 0.985906, 'recall_consonant': 0.991055, 'acc_grapheme': 0.961711, 'acc_vowel': 0.9881, 'acc_consonant': 0.989245, 'loss_grapheme': 0.219487, 'loss_vowel': 0.114273, 'loss_consonant': 0.081095}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 0.000008 | 132096/180756 | 1.4441 | 2.1436 |\n",
      "val: {'recall': 0.975953, 'recall_grapheme': 0.963098, 'recall_vowel': 0.986712, 'recall_consonant': 0.990902, 'acc_grapheme': 0.960715, 'acc_vowel': 0.9882, 'acc_consonant': 0.988996, 'loss_grapheme': 0.253276, 'loss_vowel': 0.126174, 'loss_consonant': 0.089953}\n",
      "   15 | 0.000016 | 053760/180756 | 1.8645 | 2.1354 |\n",
      "val: {'recall': 0.975832, 'recall_grapheme': 0.962598, 'recall_vowel': 0.98682, 'recall_consonant': 0.991312, 'acc_grapheme': 0.960964, 'acc_vowel': 0.988747, 'acc_consonant': 0.989046, 'loss_grapheme': 0.227563, 'loss_vowel': 0.114589, 'loss_consonant': 0.087643}\n",
      "   15 | 0.000025 | 156160/180756 | 2.1907 | 2.1694 |\n",
      "val: {'recall': 0.975313, 'recall_grapheme': 0.962305, 'recall_vowel': 0.986477, 'recall_consonant': 0.990162, 'acc_grapheme': 0.959669, 'acc_vowel': 0.987901, 'acc_consonant': 0.988498, 'loss_grapheme': 0.262925, 'loss_vowel': 0.130997, 'loss_consonant': 0.0935}\n",
      "   16 | 0.000035 | 077824/180756 | 2.8184 | 2.1238 |\n",
      "val: {'recall': 0.974088, 'recall_grapheme': 0.960354, 'recall_vowel': 0.985992, 'recall_consonant': 0.989653, 'acc_grapheme': 0.958126, 'acc_vowel': 0.987552, 'acc_consonant': 0.988847, 'loss_grapheme': 0.264267, 'loss_vowel': 0.130878, 'loss_consonant': 0.092331}\n",
      "   16 | 0.000043 | 180224/180756 | 2.6912 | 2.0962 |\n",
      "val: {'recall': 0.974646, 'recall_grapheme': 0.960937, 'recall_vowel': 0.985872, 'recall_consonant': 0.990838, 'acc_grapheme': 0.960964, 'acc_vowel': 0.987951, 'acc_consonant': 0.988498, 'loss_grapheme': 0.250379, 'loss_vowel': 0.121841, 'loss_consonant': 0.096532}\n",
      "   17 | 0.000048 | 101888/180756 | 1.1753 | 2.0607 |\n",
      "val: {'recall': 0.975268, 'recall_grapheme': 0.962911, 'recall_vowel': 0.98683, 'recall_consonant': 0.98842, 'acc_grapheme': 0.962756, 'acc_vowel': 0.988996, 'acc_consonant': 0.989195, 'loss_grapheme': 0.206105, 'loss_vowel': 0.110054, 'loss_consonant': 0.07654}\n",
      "   18 | 0.000050 | 023552/180756 | 1.1008 | 2.1140 |\n",
      "val: {'recall': 0.974085, 'recall_grapheme': 0.960024, 'recall_vowel': 0.985893, 'recall_consonant': 0.990398, 'acc_grapheme': 0.95952, 'acc_vowel': 0.988, 'acc_consonant': 0.988897, 'loss_grapheme': 0.216986, 'loss_vowel': 0.116001, 'loss_consonant': 0.08305}\n",
      "   18 | 0.000048 | 125952/180756 | 2.3877 | 2.0020 |\n",
      "val: {'recall': 0.975815, 'recall_grapheme': 0.963397, 'recall_vowel': 0.986136, 'recall_consonant': 0.990327, 'acc_grapheme': 0.96191, 'acc_vowel': 0.988249, 'acc_consonant': 0.989395, 'loss_grapheme': 0.203817, 'loss_vowel': 0.105399, 'loss_consonant': 0.071234}\n",
      "   19 | 0.000043 | 047616/180756 | 2.7743 | 2.1441 |\n",
      "val: {'recall': 0.973117, 'recall_grapheme': 0.961823, 'recall_vowel': 0.983652, 'recall_consonant': 0.98517, 'acc_grapheme': 0.95962, 'acc_vowel': 0.987801, 'acc_consonant': 0.988847, 'loss_grapheme': 0.281695, 'loss_vowel': 0.119949, 'loss_consonant': 0.096597}\n",
      "   19 | 0.000035 | 150016/180756 | 2.0190 | 2.0314 |\n",
      "val: {'recall': 0.974494, 'recall_grapheme': 0.961342, 'recall_vowel': 0.985837, 'recall_consonant': 0.989456, 'acc_grapheme': 0.960516, 'acc_vowel': 0.987851, 'acc_consonant': 0.989395, 'loss_grapheme': 0.250144, 'loss_vowel': 0.123331, 'loss_consonant': 0.087898}\n",
      "   20 | 0.000026 | 071680/180756 | 1.7138 | 1.8833 |\n",
      "val: {'recall': 0.974974, 'recall_grapheme': 0.961979, 'recall_vowel': 0.986525, 'recall_consonant': 0.989413, 'acc_grapheme': 0.961064, 'acc_vowel': 0.988598, 'acc_consonant': 0.988996, 'loss_grapheme': 0.254866, 'loss_vowel': 0.120795, 'loss_consonant': 0.085143}\n",
      "   20 | 0.000016 | 174080/180756 | 2.1577 | 1.9059 |\n",
      "val: {'recall': 0.97596, 'recall_grapheme': 0.963739, 'recall_vowel': 0.987014, 'recall_consonant': 0.989349, 'acc_grapheme': 0.961761, 'acc_vowel': 0.988847, 'acc_consonant': 0.989444, 'loss_grapheme': 0.248357, 'loss_vowel': 0.119723, 'loss_consonant': 0.090549}\n",
      "   21 | 0.000008 | 095744/180756 | 1.4569 | 1.8639 |\n",
      "val: {'recall': 0.976989, 'recall_grapheme': 0.965343, 'recall_vowel': 0.986637, 'recall_consonant': 0.990634, 'acc_grapheme': 0.9643, 'acc_vowel': 0.988747, 'acc_consonant': 0.989643, 'loss_grapheme': 0.212731, 'loss_vowel': 0.108042, 'loss_consonant': 0.077629}\n",
      "** saved\n",
      "   22 | 0.000003 | 017408/180756 | 2.4995 | 2.0018 |\n",
      "val: {'recall': 0.976555, 'recall_grapheme': 0.965032, 'recall_vowel': 0.986721, 'recall_consonant': 0.989434, 'acc_grapheme': 0.962806, 'acc_vowel': 0.988648, 'acc_consonant': 0.989295, 'loss_grapheme': 0.24758, 'loss_vowel': 0.122428, 'loss_consonant': 0.089128}\n",
      "   22 | 0.000001 | 119808/180756 | 1.7164 | 1.8665 |\n",
      "val: {'recall': 0.977518, 'recall_grapheme': 0.966575, 'recall_vowel': 0.986492, 'recall_consonant': 0.99043, 'acc_grapheme': 0.964599, 'acc_vowel': 0.988648, 'acc_consonant': 0.989693, 'loss_grapheme': 0.212083, 'loss_vowel': 0.107614, 'loss_consonant': 0.077472}\n",
      "** saved\n",
      "   23 | 0.000003 | 041472/180756 | 0.6182 | 1.8160 |\n",
      "val: {'recall': 0.976446, 'recall_grapheme': 0.964562, 'recall_vowel': 0.986175, 'recall_consonant': 0.990485, 'acc_grapheme': 0.964001, 'acc_vowel': 0.988697, 'acc_consonant': 0.989793, 'loss_grapheme': 0.199765, 'loss_vowel': 0.099203, 'loss_consonant': 0.072656}\n",
      "   23 | 0.000008 | 143872/180756 | 0.4509 | 1.8693 |\n",
      "val: {'recall': 0.976104, 'recall_grapheme': 0.964117, 'recall_vowel': 0.986007, 'recall_consonant': 0.990176, 'acc_grapheme': 0.962059, 'acc_vowel': 0.988747, 'acc_consonant': 0.989345, 'loss_grapheme': 0.234362, 'loss_vowel': 0.110322, 'loss_consonant': 0.085742}\n",
      "   24 | 0.000016 | 065536/180756 | 2.6165 | 1.9578 |\n",
      "val: {'recall': 0.976532, 'recall_grapheme': 0.964505, 'recall_vowel': 0.987143, 'recall_consonant': 0.989975, 'acc_grapheme': 0.963155, 'acc_vowel': 0.989046, 'acc_consonant': 0.989295, 'loss_grapheme': 0.227746, 'loss_vowel': 0.108708, 'loss_consonant': 0.082857}\n",
      "   24 | 0.000025 | 167936/180756 | 1.4021 | 1.9250 |\n",
      "val: {'recall': 0.976438, 'recall_grapheme': 0.965441, 'recall_vowel': 0.986653, 'recall_consonant': 0.988218, 'acc_grapheme': 0.963404, 'acc_vowel': 0.988797, 'acc_consonant': 0.989146, 'loss_grapheme': 0.217434, 'loss_vowel': 0.105437, 'loss_consonant': 0.085748}\n",
      "   25 | 0.000035 | 089600/180756 | 2.0161 | 1.9055 |\n",
      "val: {'recall': 0.976296, 'recall_grapheme': 0.963563, 'recall_vowel': 0.98742, 'recall_consonant': 0.990639, 'acc_grapheme': 0.962458, 'acc_vowel': 0.989096, 'acc_consonant': 0.989693, 'loss_grapheme': 0.230796, 'loss_vowel': 0.112546, 'loss_consonant': 0.089857}\n",
      "   26 | 0.000043 | 011264/180756 | 1.4235 | 1.8707 |\n",
      "val: {'recall': 0.976303, 'recall_grapheme': 0.964184, 'recall_vowel': 0.986755, 'recall_consonant': 0.990091, 'acc_grapheme': 0.962408, 'acc_vowel': 0.988299, 'acc_consonant': 0.989096, 'loss_grapheme': 0.207838, 'loss_vowel': 0.104013, 'loss_consonant': 0.080884}\n",
      "   26 | 0.000048 | 113664/180756 | 2.6896 | 1.8965 |\n",
      "val: {'recall': 0.97608, 'recall_grapheme': 0.964062, 'recall_vowel': 0.986074, 'recall_consonant': 0.990122, 'acc_grapheme': 0.963453, 'acc_vowel': 0.988449, 'acc_consonant': 0.989195, 'loss_grapheme': 0.204246, 'loss_vowel': 0.104096, 'loss_consonant': 0.074544}\n",
      "   27 | 0.000050 | 035328/180756 | 2.6701 | 1.8439 |\n",
      "val: {'recall': 0.976119, 'recall_grapheme': 0.963386, 'recall_vowel': 0.986752, 'recall_consonant': 0.99095, 'acc_grapheme': 0.963802, 'acc_vowel': 0.989096, 'acc_consonant': 0.989693, 'loss_grapheme': 0.209646, 'loss_vowel': 0.09587, 'loss_consonant': 0.074981}\n",
      "   27 | 0.000048 | 137728/180756 | 2.3562 | 1.9422 |\n",
      "val: {'recall': 0.976067, 'recall_grapheme': 0.963914, 'recall_vowel': 0.986806, 'recall_consonant': 0.989635, 'acc_grapheme': 0.962358, 'acc_vowel': 0.988996, 'acc_consonant': 0.989544, 'loss_grapheme': 0.203741, 'loss_vowel': 0.099614, 'loss_consonant': 0.083093}\n",
      "   28 | 0.000043 | 059392/180756 | 2.0249 | 1.8262 |\n",
      "val: {'recall': 0.975931, 'recall_grapheme': 0.963305, 'recall_vowel': 0.987691, 'recall_consonant': 0.989423, 'acc_grapheme': 0.962259, 'acc_vowel': 0.988897, 'acc_consonant': 0.988747, 'loss_grapheme': 0.218975, 'loss_vowel': 0.112519, 'loss_consonant': 0.078863}\n",
      "   28 | 0.000035 | 161792/180756 | 2.0069 | 1.8542 |\n",
      "val: {'recall': 0.975465, 'recall_grapheme': 0.963233, 'recall_vowel': 0.985943, 'recall_consonant': 0.98945, 'acc_grapheme': 0.962906, 'acc_vowel': 0.988349, 'acc_consonant': 0.989046, 'loss_grapheme': 0.229944, 'loss_vowel': 0.112278, 'loss_consonant': 0.08578}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 0.000025 | 083456/180756 | 2.1302 | 1.8212 |\n",
      "val: {'recall': 0.975264, 'recall_grapheme': 0.963009, 'recall_vowel': 0.985824, 'recall_consonant': 0.989215, 'acc_grapheme': 0.962259, 'acc_vowel': 0.988847, 'acc_consonant': 0.989395, 'loss_grapheme': 0.25456, 'loss_vowel': 0.112377, 'loss_consonant': 0.092488}\n",
      "   30 | 0.000016 | 005120/180756 | 1.9771 | 1.8698 |\n",
      "val: {'recall': 0.976228, 'recall_grapheme': 0.964582, 'recall_vowel': 0.986567, 'recall_consonant': 0.989181, 'acc_grapheme': 0.963304, 'acc_vowel': 0.988797, 'acc_consonant': 0.990042, 'loss_grapheme': 0.227433, 'loss_vowel': 0.107885, 'loss_consonant': 0.087771}\n",
      "   30 | 0.000008 | 107520/180756 | 2.0428 | 1.8308 |\n",
      "val: {'recall': 0.976243, 'recall_grapheme': 0.964728, 'recall_vowel': 0.9871, 'recall_consonant': 0.988418, 'acc_grapheme': 0.964499, 'acc_vowel': 0.988996, 'acc_consonant': 0.989544, 'loss_grapheme': 0.212259, 'loss_vowel': 0.102034, 'loss_consonant': 0.078471}\n",
      "   31 | 0.000003 | 029184/180756 | 2.1366 | 1.7291 |\n",
      "val: {'recall': 0.976166, 'recall_grapheme': 0.964891, 'recall_vowel': 0.986611, 'recall_consonant': 0.988271, 'acc_grapheme': 0.963653, 'acc_vowel': 0.989096, 'acc_consonant': 0.989345, 'loss_grapheme': 0.221471, 'loss_vowel': 0.097239, 'loss_consonant': 0.081024}\n",
      "   31 | 0.000001 | 131584/180756 | 1.0245 | 1.7839 |\n",
      "val: {'recall': 0.9764, 'recall_grapheme': 0.964702, 'recall_vowel': 0.986549, 'recall_consonant': 0.989646, 'acc_grapheme': 0.96435, 'acc_vowel': 0.989295, 'acc_consonant': 0.989793, 'loss_grapheme': 0.206866, 'loss_vowel': 0.097105, 'loss_consonant': 0.077244}\n",
      "   32 | 0.000003 | 053248/180756 | 1.5961 | 1.7184 |\n",
      "val: {'recall': 0.975858, 'recall_grapheme': 0.964211, 'recall_vowel': 0.986439, 'recall_consonant': 0.988572, 'acc_grapheme': 0.963453, 'acc_vowel': 0.989096, 'acc_consonant': 0.989693, 'loss_grapheme': 0.22188, 'loss_vowel': 0.106683, 'loss_consonant': 0.079296}\n",
      "   32 | 0.000008 | 155648/180756 | 0.2253 | 1.8208 |\n",
      "val: {'recall': 0.976199, 'recall_grapheme': 0.96526, 'recall_vowel': 0.986247, 'recall_consonant': 0.988028, 'acc_grapheme': 0.963503, 'acc_vowel': 0.988897, 'acc_consonant': 0.989195, 'loss_grapheme': 0.213572, 'loss_vowel': 0.097303, 'loss_consonant': 0.078229}\n",
      "   33 | 0.000016 | 077312/180756 | 1.9001 | 1.8215 |\n",
      "val: {'recall': 0.97729, 'recall_grapheme': 0.965291, 'recall_vowel': 0.98684, 'recall_consonant': 0.991739, 'acc_grapheme': 0.963553, 'acc_vowel': 0.989046, 'acc_consonant': 0.990291, 'loss_grapheme': 0.216392, 'loss_vowel': 0.100815, 'loss_consonant': 0.081337}\n",
      "   33 | 0.000025 | 179712/180756 | 1.8180 | 1.8478 |\n",
      "val: {'recall': 0.977071, 'recall_grapheme': 0.96537, 'recall_vowel': 0.987645, 'recall_consonant': 0.989898, 'acc_grapheme': 0.963802, 'acc_vowel': 0.989793, 'acc_consonant': 0.989743, 'loss_grapheme': 0.218171, 'loss_vowel': 0.104919, 'loss_consonant': 0.08169}\n",
      "   34 | 0.000035 | 101376/180756 | 2.7372 | 1.7841 |\n",
      "val: {'recall': 0.975284, 'recall_grapheme': 0.963581, 'recall_vowel': 0.985296, 'recall_consonant': 0.988676, 'acc_grapheme': 0.960267, 'acc_vowel': 0.988498, 'acc_consonant': 0.988946, 'loss_grapheme': 0.261379, 'loss_vowel': 0.109533, 'loss_consonant': 0.097125}\n",
      "   35 | 0.000043 | 023040/180756 | 2.3997 | 1.9775 |\n",
      "val: {'recall': 0.972687, 'recall_grapheme': 0.962121, 'recall_vowel': 0.982937, 'recall_consonant': 0.983569, 'acc_grapheme': 0.960118, 'acc_vowel': 0.987652, 'acc_consonant': 0.988449, 'loss_grapheme': 0.259531, 'loss_vowel': 0.115651, 'loss_consonant': 0.095856}\n",
      "   35 | 0.000048 | 125440/180756 | 1.3265 | 1.8829 |\n",
      "val: {'recall': 0.974973, 'recall_grapheme': 0.96234, 'recall_vowel': 0.985528, 'recall_consonant': 0.989685, 'acc_grapheme': 0.960466, 'acc_vowel': 0.987403, 'acc_consonant': 0.989594, 'loss_grapheme': 0.239338, 'loss_vowel': 0.113115, 'loss_consonant': 0.081878}\n",
      "   36 | 0.000050 | 047104/180756 | 2.3548 | 1.8451 |\n",
      "val: {'recall': 0.97337, 'recall_grapheme': 0.962629, 'recall_vowel': 0.983243, 'recall_consonant': 0.984981, 'acc_grapheme': 0.962507, 'acc_vowel': 0.98815, 'acc_consonant': 0.989444, 'loss_grapheme': 0.225461, 'loss_vowel': 0.100376, 'loss_consonant': 0.089237}\n",
      "   36 | 0.000048 | 149504/180756 | 1.0531 | 1.8070 |\n",
      "val: {'recall': 0.974185, 'recall_grapheme': 0.963486, 'recall_vowel': 0.984726, 'recall_consonant': 0.985043, 'acc_grapheme': 0.962308, 'acc_vowel': 0.987851, 'acc_consonant': 0.989046, 'loss_grapheme': 0.23329, 'loss_vowel': 0.100324, 'loss_consonant': 0.080935}\n",
      "   37 | 0.000043 | 071168/180756 | 1.4275 | 1.7338 |\n",
      "val: {'recall': 0.976877, 'recall_grapheme': 0.966361, 'recall_vowel': 0.985777, 'recall_consonant': 0.989011, 'acc_grapheme': 0.963553, 'acc_vowel': 0.988648, 'acc_consonant': 0.989892, 'loss_grapheme': 0.212834, 'loss_vowel': 0.099679, 'loss_consonant': 0.07569}\n",
      "   37 | 0.000035 | 173568/180756 | 1.9034 | 1.7298 |\n",
      "val: {'recall': 0.97663, 'recall_grapheme': 0.96516, 'recall_vowel': 0.987291, 'recall_consonant': 0.988908, 'acc_grapheme': 0.965943, 'acc_vowel': 0.989395, 'acc_consonant': 0.989096, 'loss_grapheme': 0.188763, 'loss_vowel': 0.092418, 'loss_consonant': 0.079356}\n",
      "   38 | 0.000025 | 095232/180756 | 2.3049 | 1.7257 |\n",
      "val: {'recall': 0.977467, 'recall_grapheme': 0.965714, 'recall_vowel': 0.985823, 'recall_consonant': 0.992619, 'acc_grapheme': 0.963653, 'acc_vowel': 0.988996, 'acc_consonant': 0.990191, 'loss_grapheme': 0.211569, 'loss_vowel': 0.091662, 'loss_consonant': 0.079426}\n",
      "   39 | 0.000016 | 016896/180756 | 1.5190 | 1.6689 |\n",
      "val: {'recall': 0.977515, 'recall_grapheme': 0.966725, 'recall_vowel': 0.987309, 'recall_consonant': 0.989302, 'acc_grapheme': 0.965495, 'acc_vowel': 0.989195, 'acc_consonant': 0.989942, 'loss_grapheme': 0.201274, 'loss_vowel': 0.093829, 'loss_consonant': 0.074087}\n",
      "   39 | 0.000008 | 119296/180756 | 2.2984 | 1.7026 |\n",
      "val: {'recall': 0.977617, 'recall_grapheme': 0.966133, 'recall_vowel': 0.986882, 'recall_consonant': 0.991319, 'acc_grapheme': 0.964947, 'acc_vowel': 0.988996, 'acc_consonant': 0.990141, 'loss_grapheme': 0.211604, 'loss_vowel': 0.098212, 'loss_consonant': 0.077503}\n",
      "** saved\n",
      "   40 | 0.000003 | 040960/180756 | 1.3729 | 1.7113 |\n",
      "val: {'recall': 0.977221, 'recall_grapheme': 0.965308, 'recall_vowel': 0.987306, 'recall_consonant': 0.990963, 'acc_grapheme': 0.964051, 'acc_vowel': 0.989146, 'acc_consonant': 0.99054, 'loss_grapheme': 0.215912, 'loss_vowel': 0.101413, 'loss_consonant': 0.077508}\n",
      "   40 | 0.000001 | 143360/180756 | 1.3047 | 1.7406 |\n",
      "val: {'recall': 0.976857, 'recall_grapheme': 0.965316, 'recall_vowel': 0.986923, 'recall_consonant': 0.989875, 'acc_grapheme': 0.963951, 'acc_vowel': 0.988897, 'acc_consonant': 0.989942, 'loss_grapheme': 0.223984, 'loss_vowel': 0.099071, 'loss_consonant': 0.081204}\n",
      "   41 | 0.000003 | 065024/180756 | 1.9779 | 1.7078 |\n",
      "val: {'recall': 0.977235, 'recall_grapheme': 0.96564, 'recall_vowel': 0.987133, 'recall_consonant': 0.990528, 'acc_grapheme': 0.963503, 'acc_vowel': 0.988747, 'acc_consonant': 0.989843, 'loss_grapheme': 0.227839, 'loss_vowel': 0.100688, 'loss_consonant': 0.08218}\n",
      "   41 | 0.000008 | 167424/180756 | 1.9724 | 1.7361 |\n",
      "val: {'recall': 0.976589, 'recall_grapheme': 0.96539, 'recall_vowel': 0.986391, 'recall_consonant': 0.989184, 'acc_grapheme': 0.963902, 'acc_vowel': 0.988598, 'acc_consonant': 0.989594, 'loss_grapheme': 0.22293, 'loss_vowel': 0.099386, 'loss_consonant': 0.081455}\n",
      "   42 | 0.000016 | 089088/180756 | 2.5369 | 1.6990 |\n",
      "val: {'recall': 0.97539, 'recall_grapheme': 0.963323, 'recall_vowel': 0.985837, 'recall_consonant': 0.989077, 'acc_grapheme': 0.961412, 'acc_vowel': 0.98815, 'acc_consonant': 0.989544, 'loss_grapheme': 0.256111, 'loss_vowel': 0.105498, 'loss_consonant': 0.091808}\n",
      "   43 | 0.000025 | 010752/180756 | 1.7243 | 1.9657 |\n",
      "val: {'recall': 0.975406, 'recall_grapheme': 0.962891, 'recall_vowel': 0.986931, 'recall_consonant': 0.98891, 'acc_grapheme': 0.960864, 'acc_vowel': 0.988747, 'acc_consonant': 0.989793, 'loss_grapheme': 0.252266, 'loss_vowel': 0.100185, 'loss_consonant': 0.088691}\n",
      "   43 | 0.000035 | 113152/180756 | 2.3852 | 1.7241 |\n",
      "val: {'recall': 0.973909, 'recall_grapheme': 0.961057, 'recall_vowel': 0.9852, 'recall_consonant': 0.988323, 'acc_grapheme': 0.96181, 'acc_vowel': 0.9881, 'acc_consonant': 0.989843, 'loss_grapheme': 0.220242, 'loss_vowel': 0.106876, 'loss_consonant': 0.083322}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 0.000043 | 034816/180756 | 2.4030 | 1.6295 |\n",
      "val: {'recall': 0.977254, 'recall_grapheme': 0.965811, 'recall_vowel': 0.986481, 'recall_consonant': 0.990911, 'acc_grapheme': 0.965296, 'acc_vowel': 0.989245, 'acc_consonant': 0.990092, 'loss_grapheme': 0.19666, 'loss_vowel': 0.09188, 'loss_consonant': 0.075409}\n",
      "   44 | 0.000048 | 137216/180756 | 1.4246 | 1.7253 |\n",
      "val: {'recall': 0.97696, 'recall_grapheme': 0.965599, 'recall_vowel': 0.98644, 'recall_consonant': 0.990203, 'acc_grapheme': 0.9644, 'acc_vowel': 0.988797, 'acc_consonant': 0.990888, 'loss_grapheme': 0.213592, 'loss_vowel': 0.102283, 'loss_consonant': 0.083357}\n",
      "   45 | 0.000050 | 058880/180756 | 2.3604 | 1.7133 |\n",
      "val: {'recall': 0.97637, 'recall_grapheme': 0.9649, 'recall_vowel': 0.984253, 'recall_consonant': 0.991427, 'acc_grapheme': 0.962756, 'acc_vowel': 0.9881, 'acc_consonant': 0.990241, 'loss_grapheme': 0.216874, 'loss_vowel': 0.094685, 'loss_consonant': 0.082476}\n",
      "   45 | 0.000048 | 161280/180756 | 1.5262 | 1.7388 |\n",
      "val: {'recall': 0.975478, 'recall_grapheme': 0.966039, 'recall_vowel': 0.984849, 'recall_consonant': 0.984984, 'acc_grapheme': 0.962906, 'acc_vowel': 0.988299, 'acc_consonant': 0.989843, 'loss_grapheme': 0.236061, 'loss_vowel': 0.095471, 'loss_consonant': 0.085794}\n",
      "   46 | 0.000043 | 082944/180756 | 0.2389 | 1.6957 |\n",
      "val: {'recall': 0.977989, 'recall_grapheme': 0.967166, 'recall_vowel': 0.98697, 'recall_consonant': 0.990654, 'acc_grapheme': 0.964947, 'acc_vowel': 0.988946, 'acc_consonant': 0.99044, 'loss_grapheme': 0.201631, 'loss_vowel': 0.093857, 'loss_consonant': 0.075027}\n",
      "** saved\n",
      "   47 | 0.000035 | 004608/180756 | 2.4160 | 1.6966 |\n",
      "val: {'recall': 0.976048, 'recall_grapheme': 0.964593, 'recall_vowel': 0.985265, 'recall_consonant': 0.989741, 'acc_grapheme': 0.962806, 'acc_vowel': 0.988548, 'acc_consonant': 0.989195, 'loss_grapheme': 0.218473, 'loss_vowel': 0.099334, 'loss_consonant': 0.085833}\n",
      "   47 | 0.000025 | 107008/180756 | 1.1702 | 1.6682 |\n",
      "val: {'recall': 0.976206, 'recall_grapheme': 0.96396, 'recall_vowel': 0.985635, 'recall_consonant': 0.99127, 'acc_grapheme': 0.9643, 'acc_vowel': 0.989146, 'acc_consonant': 0.989942, 'loss_grapheme': 0.194438, 'loss_vowel': 0.088648, 'loss_consonant': 0.069174}\n",
      "   48 | 0.000016 | 028672/180756 | 1.7062 | 1.5211 |\n",
      "val: {'recall': 0.977867, 'recall_grapheme': 0.967345, 'recall_vowel': 0.987331, 'recall_consonant': 0.989446, 'acc_grapheme': 0.964798, 'acc_vowel': 0.989793, 'acc_consonant': 0.99039, 'loss_grapheme': 0.210357, 'loss_vowel': 0.091628, 'loss_consonant': 0.07548}\n",
      "   48 | 0.000008 | 131072/180756 | 1.2917 | 1.6219 |\n",
      "val: {'recall': 0.978264, 'recall_grapheme': 0.967822, 'recall_vowel': 0.986796, 'recall_consonant': 0.990615, 'acc_grapheme': 0.966789, 'acc_vowel': 0.989693, 'acc_consonant': 0.990689, 'loss_grapheme': 0.181179, 'loss_vowel': 0.087153, 'loss_consonant': 0.066685}\n",
      "** saved\n",
      "   49 | 0.000003 | 052736/180756 | 1.4375 | 1.6977 |\n",
      "val: {'recall': 0.977596, 'recall_grapheme': 0.966898, 'recall_vowel': 0.986663, 'recall_consonant': 0.989924, 'acc_grapheme': 0.965644, 'acc_vowel': 0.989494, 'acc_consonant': 0.990639, 'loss_grapheme': 0.202763, 'loss_vowel': 0.094671, 'loss_consonant': 0.073434}\n",
      "   49 | 0.000001 | 155136/180756 | 1.7534 | 1.6345 |\n",
      "val: {'recall': 0.977534, 'recall_grapheme': 0.967912, 'recall_vowel': 0.987039, 'recall_consonant': 0.987272, 'acc_grapheme': 0.966341, 'acc_vowel': 0.989494, 'acc_consonant': 0.99044, 'loss_grapheme': 0.195448, 'loss_vowel': 0.087717, 'loss_consonant': 0.069946}\n",
      "   49 | 0.000003 | 180736/180756 | 0.0333 | 1.6498 |"
     ]
    }
   ],
   "source": [
    "train(args) # mixup no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.978264, 'recall_grapheme': 0.967822, 'recall_vowel': 0.986796, 'recall_consonant': 0.990615, 'acc_grapheme': 0.966789, 'acc_vowel': 0.989693, 'acc_consonant': 0.990689, 'loss_grapheme': 0.181179, 'loss_vowel': 0.087153, 'loss_consonant': 0.066685}\n",
      "    0 | 0.000048 | 102400/180756 | 1.0828 | 1.7958 |\n",
      "val: {'recall': 0.975461, 'recall_grapheme': 0.962395, 'recall_vowel': 0.985495, 'recall_consonant': 0.991559, 'acc_grapheme': 0.96201, 'acc_vowel': 0.988946, 'acc_consonant': 0.989295, 'loss_grapheme': 0.226953, 'loss_vowel': 0.114416, 'loss_consonant': 0.077727}\n",
      "    1 | 0.000043 | 024064/180756 | 0.8055 | 1.9220 |\n",
      "val: {'recall': 0.974818, 'recall_grapheme': 0.963383, 'recall_vowel': 0.985371, 'recall_consonant': 0.987136, 'acc_grapheme': 0.960466, 'acc_vowel': 0.988498, 'acc_consonant': 0.988946, 'loss_grapheme': 0.260732, 'loss_vowel': 0.106805, 'loss_consonant': 0.088922}\n",
      "    1 | 0.000035 | 126464/180756 | 2.0229 | 1.7724 |\n",
      "val: {'recall': 0.974556, 'recall_grapheme': 0.962777, 'recall_vowel': 0.983155, 'recall_consonant': 0.989514, 'acc_grapheme': 0.963155, 'acc_vowel': 0.98805, 'acc_consonant': 0.989195, 'loss_grapheme': 0.215, 'loss_vowel': 0.109129, 'loss_consonant': 0.08066}\n",
      "    2 | 0.000026 | 048128/180756 | 1.0412 | 1.5576 |\n",
      "val: {'recall': 0.976783, 'recall_grapheme': 0.965976, 'recall_vowel': 0.986089, 'recall_consonant': 0.989094, 'acc_grapheme': 0.965694, 'acc_vowel': 0.989544, 'acc_consonant': 0.990341, 'loss_grapheme': 0.177428, 'loss_vowel': 0.0891, 'loss_consonant': 0.064629}\n",
      "    2 | 0.000016 | 150528/180756 | 0.1791 | 1.6309 |\n",
      "val: {'recall': 0.976163, 'recall_grapheme': 0.964997, 'recall_vowel': 0.985086, 'recall_consonant': 0.989573, 'acc_grapheme': 0.965445, 'acc_vowel': 0.989195, 'acc_consonant': 0.990888, 'loss_grapheme': 0.179091, 'loss_vowel': 0.088035, 'loss_consonant': 0.066992}\n",
      "    3 | 0.000008 | 072192/180756 | 0.6296 | 1.7316 |\n",
      "val: {'recall': 0.977203, 'recall_grapheme': 0.965001, 'recall_vowel': 0.986047, 'recall_consonant': 0.992763, 'acc_grapheme': 0.965595, 'acc_vowel': 0.989295, 'acc_consonant': 0.990639, 'loss_grapheme': 0.192343, 'loss_vowel': 0.095564, 'loss_consonant': 0.069466}\n",
      "    3 | 0.000003 | 174592/180756 | 2.0861 | 1.6501 |\n",
      "val: {'recall': 0.976853, 'recall_grapheme': 0.96514, 'recall_vowel': 0.986427, 'recall_consonant': 0.990702, 'acc_grapheme': 0.965395, 'acc_vowel': 0.989245, 'acc_consonant': 0.991287, 'loss_grapheme': 0.200202, 'loss_vowel': 0.096861, 'loss_consonant': 0.070752}\n",
      "    4 | 0.000001 | 096256/180756 | 1.4400 | 1.6684 |\n",
      "val: {'recall': 0.976797, 'recall_grapheme': 0.964982, 'recall_vowel': 0.986224, 'recall_consonant': 0.990999, 'acc_grapheme': 0.965843, 'acc_vowel': 0.989345, 'acc_consonant': 0.991237, 'loss_grapheme': 0.201032, 'loss_vowel': 0.099244, 'loss_consonant': 0.071681}\n",
      "    5 | 0.000003 | 017920/180756 | 1.5668 | 1.6411 |\n",
      "val: {'recall': 0.977076, 'recall_grapheme': 0.965899, 'recall_vowel': 0.985949, 'recall_consonant': 0.990557, 'acc_grapheme': 0.966441, 'acc_vowel': 0.989345, 'acc_consonant': 0.991137, 'loss_grapheme': 0.183385, 'loss_vowel': 0.099698, 'loss_consonant': 0.068284}\n",
      "    5 | 0.000008 | 120320/180756 | 0.3639 | 1.6541 |\n",
      "val: {'recall': 0.977848, 'recall_grapheme': 0.967318, 'recall_vowel': 0.98618, 'recall_consonant': 0.990574, 'acc_grapheme': 0.968233, 'acc_vowel': 0.989992, 'acc_consonant': 0.99059, 'loss_grapheme': 0.159408, 'loss_vowel': 0.084908, 'loss_consonant': 0.060419}\n",
      "    6 | 0.000016 | 041984/180756 | 2.3501 | 1.5679 |\n",
      "val: {'recall': 0.976048, 'recall_grapheme': 0.964556, 'recall_vowel': 0.985147, 'recall_consonant': 0.989933, 'acc_grapheme': 0.9643, 'acc_vowel': 0.989195, 'acc_consonant': 0.990838, 'loss_grapheme': 0.206252, 'loss_vowel': 0.097867, 'loss_consonant': 0.072482}\n",
      "    6 | 0.000025 | 144384/180756 | 0.5170 | 1.6736 |\n",
      "val: {'recall': 0.977271, 'recall_grapheme': 0.966997, 'recall_vowel': 0.985559, 'recall_consonant': 0.989532, 'acc_grapheme': 0.965445, 'acc_vowel': 0.988847, 'acc_consonant': 0.991287, 'loss_grapheme': 0.196258, 'loss_vowel': 0.09919, 'loss_consonant': 0.071445}\n",
      "    7 | 0.000035 | 066048/180756 | 1.8821 | 1.6447 |\n",
      "val: {'recall': 0.975533, 'recall_grapheme': 0.963754, 'recall_vowel': 0.984754, 'recall_consonant': 0.98987, 'acc_grapheme': 0.963702, 'acc_vowel': 0.988449, 'acc_consonant': 0.990888, 'loss_grapheme': 0.200311, 'loss_vowel': 0.101657, 'loss_consonant': 0.071337}\n",
      "    7 | 0.000043 | 168448/180756 | 1.1272 | 1.6894 |\n",
      "val: {'recall': 0.975275, 'recall_grapheme': 0.963678, 'recall_vowel': 0.985282, 'recall_consonant': 0.988462, 'acc_grapheme': 0.965395, 'acc_vowel': 0.988598, 'acc_consonant': 0.99044, 'loss_grapheme': 0.186068, 'loss_vowel': 0.099241, 'loss_consonant': 0.065501}\n",
      "    8 | 0.000048 | 090112/180756 | 2.0946 | 1.7356 |\n",
      "val: {'recall': 0.972862, 'recall_grapheme': 0.960996, 'recall_vowel': 0.984802, 'recall_consonant': 0.984654, 'acc_grapheme': 0.962806, 'acc_vowel': 0.988548, 'acc_consonant': 0.990042, 'loss_grapheme': 0.212268, 'loss_vowel': 0.102722, 'loss_consonant': 0.071019}\n",
      "    9 | 0.000050 | 011776/180756 | 1.7269 | 1.7895 |\n",
      "val: {'recall': 0.976447, 'recall_grapheme': 0.9646, 'recall_vowel': 0.985169, 'recall_consonant': 0.991418, 'acc_grapheme': 0.963553, 'acc_vowel': 0.98805, 'acc_consonant': 0.989992, 'loss_grapheme': 0.212753, 'loss_vowel': 0.107622, 'loss_consonant': 0.084512}\n",
      "    9 | 0.000048 | 114176/180756 | 2.2575 | 1.7550 |\n",
      "val: {'recall': 0.973839, 'recall_grapheme': 0.961234, 'recall_vowel': 0.984193, 'recall_consonant': 0.988697, 'acc_grapheme': 0.962209, 'acc_vowel': 0.98815, 'acc_consonant': 0.989544, 'loss_grapheme': 0.224938, 'loss_vowel': 0.1049, 'loss_consonant': 0.081679}\n",
      "   10 | 0.000043 | 035840/180756 | 1.8318 | 1.7036 |\n",
      "val: {'recall': 0.975206, 'recall_grapheme': 0.962377, 'recall_vowel': 0.985229, 'recall_consonant': 0.990841, 'acc_grapheme': 0.963702, 'acc_vowel': 0.9881, 'acc_consonant': 0.989146, 'loss_grapheme': 0.20377, 'loss_vowel': 0.104067, 'loss_consonant': 0.073856}\n",
      "   10 | 0.000035 | 138240/180756 | 2.5766 | 1.6830 |\n",
      "val: {'recall': 0.976176, 'recall_grapheme': 0.965355, 'recall_vowel': 0.983729, 'recall_consonant': 0.990266, 'acc_grapheme': 0.964897, 'acc_vowel': 0.988598, 'acc_consonant': 0.990689, 'loss_grapheme': 0.206556, 'loss_vowel': 0.098123, 'loss_consonant': 0.073789}\n",
      "   11 | 0.000026 | 059904/180756 | 1.5825 | 1.6196 |\n",
      "val: {'recall': 0.977031, 'recall_grapheme': 0.965654, 'recall_vowel': 0.985145, 'recall_consonant': 0.99167, 'acc_grapheme': 0.964599, 'acc_vowel': 0.988697, 'acc_consonant': 0.990888, 'loss_grapheme': 0.211128, 'loss_vowel': 0.095295, 'loss_consonant': 0.078102}\n",
      "   11 | 0.000016 | 162304/180756 | 0.7853 | 1.6175 |\n",
      "val: {'recall': 0.976825, 'recall_grapheme': 0.965549, 'recall_vowel': 0.984935, 'recall_consonant': 0.991267, 'acc_grapheme': 0.965495, 'acc_vowel': 0.989096, 'acc_consonant': 0.99044, 'loss_grapheme': 0.201195, 'loss_vowel': 0.092458, 'loss_consonant': 0.070723}\n",
      "   12 | 0.000008 | 083968/180756 | 1.4234 | 1.6798 |\n",
      "val: {'recall': 0.977087, 'recall_grapheme': 0.965827, 'recall_vowel': 0.985244, 'recall_consonant': 0.991449, 'acc_grapheme': 0.965843, 'acc_vowel': 0.989594, 'acc_consonant': 0.991038, 'loss_grapheme': 0.194985, 'loss_vowel': 0.088394, 'loss_consonant': 0.070293}\n",
      "   13 | 0.000003 | 005632/180756 | 2.0927 | 1.4952 |\n",
      "val: {'recall': 0.977728, 'recall_grapheme': 0.966768, 'recall_vowel': 0.985637, 'recall_consonant': 0.991738, 'acc_grapheme': 0.967138, 'acc_vowel': 0.989594, 'acc_consonant': 0.991386, 'loss_grapheme': 0.198012, 'loss_vowel': 0.097135, 'loss_consonant': 0.069988}\n",
      "   13 | 0.000001 | 108032/180756 | 1.0297 | 1.6468 |\n",
      "val: {'recall': 0.977455, 'recall_grapheme': 0.966243, 'recall_vowel': 0.985778, 'recall_consonant': 0.991556, 'acc_grapheme': 0.96659, 'acc_vowel': 0.989494, 'acc_consonant': 0.990888, 'loss_grapheme': 0.200082, 'loss_vowel': 0.092549, 'loss_consonant': 0.070819}\n",
      "   14 | 0.000003 | 029696/180756 | 1.6071 | 1.6066 |\n",
      "val: {'recall': 0.977844, 'recall_grapheme': 0.966922, 'recall_vowel': 0.985507, 'recall_consonant': 0.992025, 'acc_grapheme': 0.967586, 'acc_vowel': 0.989395, 'acc_consonant': 0.991486, 'loss_grapheme': 0.190851, 'loss_vowel': 0.095491, 'loss_consonant': 0.068916}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 0.000008 | 132096/180756 | 1.6636 | 1.6448 |\n",
      "val: {'recall': 0.977799, 'recall_grapheme': 0.966922, 'recall_vowel': 0.985832, 'recall_consonant': 0.991521, 'acc_grapheme': 0.967138, 'acc_vowel': 0.989046, 'acc_consonant': 0.991336, 'loss_grapheme': 0.196955, 'loss_vowel': 0.091504, 'loss_consonant': 0.069337}\n",
      "   15 | 0.000016 | 053760/180756 | 1.7029 | 1.6748 |\n",
      "val: {'recall': 0.978034, 'recall_grapheme': 0.966968, 'recall_vowel': 0.986587, 'recall_consonant': 0.991614, 'acc_grapheme': 0.967935, 'acc_vowel': 0.989295, 'acc_consonant': 0.991585, 'loss_grapheme': 0.196397, 'loss_vowel': 0.095467, 'loss_consonant': 0.071954}\n",
      "   15 | 0.000025 | 156160/180756 | 2.1143 | 1.6859 |\n",
      "val: {'recall': 0.976275, 'recall_grapheme': 0.964587, 'recall_vowel': 0.984895, 'recall_consonant': 0.99103, 'acc_grapheme': 0.964848, 'acc_vowel': 0.989096, 'acc_consonant': 0.991087, 'loss_grapheme': 0.196546, 'loss_vowel': 0.092777, 'loss_consonant': 0.068522}\n",
      "   16 | 0.000035 | 077824/180756 | 1.6581 | 1.7060 |\n",
      "val: {'recall': 0.975932, 'recall_grapheme': 0.962716, 'recall_vowel': 0.986637, 'recall_consonant': 0.99166, 'acc_grapheme': 0.962657, 'acc_vowel': 0.988946, 'acc_consonant': 0.990789, 'loss_grapheme': 0.216944, 'loss_vowel': 0.103639, 'loss_consonant': 0.071879}\n",
      "   16 | 0.000043 | 180224/180756 | 2.4073 | 1.6983 |\n",
      "val: {'recall': 0.973818, 'recall_grapheme': 0.960462, 'recall_vowel': 0.984362, 'recall_consonant': 0.989986, 'acc_grapheme': 0.961512, 'acc_vowel': 0.98805, 'acc_consonant': 0.989843, 'loss_grapheme': 0.22651, 'loss_vowel': 0.106923, 'loss_consonant': 0.085382}\n",
      "   17 | 0.000048 | 101888/180756 | 1.9112 | 1.6546 |\n",
      "val: {'recall': 0.97445, 'recall_grapheme': 0.961381, 'recall_vowel': 0.984911, 'recall_consonant': 0.990128, 'acc_grapheme': 0.962358, 'acc_vowel': 0.988349, 'acc_consonant': 0.989793, 'loss_grapheme': 0.211966, 'loss_vowel': 0.096832, 'loss_consonant': 0.075144}\n",
      "   18 | 0.000050 | 023552/180756 | 2.0083 | 1.5526 |\n",
      "val: {'recall': 0.975056, 'recall_grapheme': 0.965652, 'recall_vowel': 0.983099, 'recall_consonant': 0.985822, 'acc_grapheme': 0.96425, 'acc_vowel': 0.988249, 'acc_consonant': 0.99049, 'loss_grapheme': 0.194404, 'loss_vowel': 0.088366, 'loss_consonant': 0.068646}\n",
      "   18 | 0.000048 | 125952/180756 | 2.0430 | 1.6231 |\n",
      "val: {'recall': 0.974943, 'recall_grapheme': 0.962081, 'recall_vowel': 0.984625, 'recall_consonant': 0.990987, 'acc_grapheme': 0.961611, 'acc_vowel': 0.989295, 'acc_consonant': 0.990042, 'loss_grapheme': 0.232075, 'loss_vowel': 0.099122, 'loss_consonant': 0.075996}\n",
      "   19 | 0.000043 | 047616/180756 | 2.2435 | 1.7428 |\n",
      "val: {'recall': 0.976314, 'recall_grapheme': 0.965863, 'recall_vowel': 0.985349, 'recall_consonant': 0.98818, 'acc_grapheme': 0.964549, 'acc_vowel': 0.988449, 'acc_consonant': 0.990789, 'loss_grapheme': 0.201658, 'loss_vowel': 0.103945, 'loss_consonant': 0.074647}\n",
      "   19 | 0.000035 | 150016/180756 | 0.4263 | 1.6774 |\n",
      "val: {'recall': 0.977233, 'recall_grapheme': 0.964975, 'recall_vowel': 0.986778, 'recall_consonant': 0.992204, 'acc_grapheme': 0.964897, 'acc_vowel': 0.989345, 'acc_consonant': 0.99049, 'loss_grapheme': 0.192232, 'loss_vowel': 0.088195, 'loss_consonant': 0.071185}\n",
      "   20 | 0.000026 | 071680/180756 | 2.2474 | 1.7121 |\n",
      "val: {'recall': 0.976669, 'recall_grapheme': 0.96673, 'recall_vowel': 0.986436, 'recall_consonant': 0.98678, 'acc_grapheme': 0.965943, 'acc_vowel': 0.989693, 'acc_consonant': 0.991038, 'loss_grapheme': 0.209311, 'loss_vowel': 0.095052, 'loss_consonant': 0.078631}\n",
      "   20 | 0.000016 | 174080/180756 | 1.3784 | 1.6863 |\n",
      "val: {'recall': 0.977037, 'recall_grapheme': 0.966858, 'recall_vowel': 0.986272, 'recall_consonant': 0.988159, 'acc_grapheme': 0.966242, 'acc_vowel': 0.989743, 'acc_consonant': 0.990838, 'loss_grapheme': 0.203158, 'loss_vowel': 0.093328, 'loss_consonant': 0.074298}\n",
      "   21 | 0.000008 | 095744/180756 | 1.6754 | 1.5746 |\n",
      "val: {'recall': 0.976941, 'recall_grapheme': 0.966412, 'recall_vowel': 0.985568, 'recall_consonant': 0.989373, 'acc_grapheme': 0.966242, 'acc_vowel': 0.989395, 'acc_consonant': 0.990739, 'loss_grapheme': 0.202994, 'loss_vowel': 0.088812, 'loss_consonant': 0.072419}\n",
      "   22 | 0.000003 | 017408/180756 | 0.5372 | 1.5055 |\n",
      "val: {'recall': 0.977405, 'recall_grapheme': 0.967285, 'recall_vowel': 0.985665, 'recall_consonant': 0.989384, 'acc_grapheme': 0.967038, 'acc_vowel': 0.989693, 'acc_consonant': 0.991038, 'loss_grapheme': 0.186409, 'loss_vowel': 0.092506, 'loss_consonant': 0.067766}\n",
      "   22 | 0.000001 | 064000/180756 | 2.2826 | 1.6030 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-4ab679a5bbed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mixup with augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-122109ec29a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) # mixup with augmentation 9782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.978264, 'recall_grapheme': 0.967822, 'recall_vowel': 0.986796, 'recall_consonant': 0.990615, 'acc_grapheme': 0.966789, 'acc_vowel': 0.989693, 'acc_consonant': 0.990689, 'loss_grapheme': 0.181179, 'loss_vowel': 0.087153, 'loss_consonant': 0.066685}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.000048 | 102400/180756 | 0.1216 | 0.1066 |\n",
      "val: {'recall': 0.977223, 'recall_grapheme': 0.966235, 'recall_vowel': 0.987834, 'recall_consonant': 0.988588, 'acc_grapheme': 0.967088, 'acc_vowel': 0.989942, 'acc_consonant': 0.990191, 'loss_grapheme': 0.123551, 'loss_vowel': 0.044626, 'loss_consonant': 0.03469}\n",
      "    1 | 0.000043 | 024064/180756 | 0.1011 | 0.0690 |\n",
      "val: {'recall': 0.978634, 'recall_grapheme': 0.96837, 'recall_vowel': 0.986834, 'recall_consonant': 0.990964, 'acc_grapheme': 0.967536, 'acc_vowel': 0.990241, 'acc_consonant': 0.990341, 'loss_grapheme': 0.121514, 'loss_vowel': 0.043641, 'loss_consonant': 0.036495}\n",
      "** saved\n",
      "    1 | 0.000035 | 126464/180756 | 0.0582 | 0.0694 |\n",
      "val: {'recall': 0.980114, 'recall_grapheme': 0.970052, 'recall_vowel': 0.988605, 'recall_consonant': 0.991749, 'acc_grapheme': 0.969777, 'acc_vowel': 0.989793, 'acc_consonant': 0.991436, 'loss_grapheme': 0.114751, 'loss_vowel': 0.044889, 'loss_consonant': 0.032215}\n",
      "** saved\n",
      "    2 | 0.000026 | 048128/180756 | 0.0375 | 0.0523 |\n",
      "val: {'recall': 0.980399, 'recall_grapheme': 0.970989, 'recall_vowel': 0.987814, 'recall_consonant': 0.991802, 'acc_grapheme': 0.969877, 'acc_vowel': 0.99049, 'acc_consonant': 0.990988, 'loss_grapheme': 0.114736, 'loss_vowel': 0.043686, 'loss_consonant': 0.034764}\n",
      "** saved\n",
      "    2 | 0.000016 | 150528/180756 | 0.0536 | 0.0512 |\n",
      "val: {'recall': 0.97985, 'recall_grapheme': 0.97108, 'recall_vowel': 0.989336, 'recall_consonant': 0.987903, 'acc_grapheme': 0.971221, 'acc_vowel': 0.990988, 'acc_consonant': 0.991934, 'loss_grapheme': 0.110171, 'loss_vowel': 0.040683, 'loss_consonant': 0.031632}\n",
      "    3 | 0.000008 | 072192/180756 | 0.0148 | 0.0409 |\n",
      "val: {'recall': 0.98059, 'recall_grapheme': 0.970633, 'recall_vowel': 0.988984, 'recall_consonant': 0.992111, 'acc_grapheme': 0.970424, 'acc_vowel': 0.991038, 'acc_consonant': 0.991834, 'loss_grapheme': 0.112943, 'loss_vowel': 0.041583, 'loss_consonant': 0.032111}\n",
      "** saved\n",
      "    3 | 0.000003 | 174592/180756 | 0.0446 | 0.0396 |\n",
      "val: {'recall': 0.981367, 'recall_grapheme': 0.971693, 'recall_vowel': 0.989107, 'recall_consonant': 0.992973, 'acc_grapheme': 0.97137, 'acc_vowel': 0.991187, 'acc_consonant': 0.992033, 'loss_grapheme': 0.109779, 'loss_vowel': 0.040665, 'loss_consonant': 0.03216}\n",
      "** saved\n",
      "    4 | 0.000001 | 096256/180756 | 0.0406 | 0.0359 |\n",
      "val: {'recall': 0.981627, 'recall_grapheme': 0.972756, 'recall_vowel': 0.988789, 'recall_consonant': 0.992206, 'acc_grapheme': 0.971769, 'acc_vowel': 0.991087, 'acc_consonant': 0.991735, 'loss_grapheme': 0.108682, 'loss_vowel': 0.041077, 'loss_consonant': 0.032429}\n",
      "** saved\n",
      "    5 | 0.000003 | 017920/180756 | 0.0550 | 0.0376 |\n",
      "val: {'recall': 0.98099, 'recall_grapheme': 0.971069, 'recall_vowel': 0.988637, 'recall_consonant': 0.993184, 'acc_grapheme': 0.97152, 'acc_vowel': 0.991137, 'acc_consonant': 0.992083, 'loss_grapheme': 0.1101, 'loss_vowel': 0.04138, 'loss_consonant': 0.032421}\n",
      "    5 | 0.000008 | 120320/180756 | 0.0256 | 0.0366 |\n",
      "val: {'recall': 0.98149, 'recall_grapheme': 0.972696, 'recall_vowel': 0.987932, 'recall_consonant': 0.992637, 'acc_grapheme': 0.971968, 'acc_vowel': 0.991087, 'acc_consonant': 0.991785, 'loss_grapheme': 0.112059, 'loss_vowel': 0.041659, 'loss_consonant': 0.033705}\n",
      "    6 | 0.000016 | 041984/180756 | 0.0485 | 0.0368 |\n",
      "val: {'recall': 0.981542, 'recall_grapheme': 0.973132, 'recall_vowel': 0.988321, 'recall_consonant': 0.991585, 'acc_grapheme': 0.970773, 'acc_vowel': 0.990888, 'acc_consonant': 0.991237, 'loss_grapheme': 0.117412, 'loss_vowel': 0.042239, 'loss_consonant': 0.036863}\n",
      "    6 | 0.000025 | 144384/180756 | 0.0364 | 0.0416 |\n",
      "val: {'recall': 0.979869, 'recall_grapheme': 0.969491, 'recall_vowel': 0.987997, 'recall_consonant': 0.992494, 'acc_grapheme': 0.968482, 'acc_vowel': 0.991237, 'acc_consonant': 0.991984, 'loss_grapheme': 0.122266, 'loss_vowel': 0.042145, 'loss_consonant': 0.033493}\n",
      "    7 | 0.000035 | 066048/180756 | 0.0323 | 0.0490 |\n",
      "val: {'recall': 0.979571, 'recall_grapheme': 0.969542, 'recall_vowel': 0.989096, 'recall_consonant': 0.990105, 'acc_grapheme': 0.967636, 'acc_vowel': 0.990938, 'acc_consonant': 0.990141, 'loss_grapheme': 0.133636, 'loss_vowel': 0.045287, 'loss_consonant': 0.040443}\n",
      "    7 | 0.000043 | 168448/180756 | 0.0606 | 0.0545 |\n",
      "val: {'recall': 0.978846, 'recall_grapheme': 0.968731, 'recall_vowel': 0.986639, 'recall_consonant': 0.991285, 'acc_grapheme': 0.966192, 'acc_vowel': 0.989643, 'acc_consonant': 0.990042, 'loss_grapheme': 0.131617, 'loss_vowel': 0.052658, 'loss_consonant': 0.039826}\n",
      "    8 | 0.000048 | 090112/180756 | 0.0492 | 0.0519 |\n",
      "val: {'recall': 0.97918, 'recall_grapheme': 0.97002, 'recall_vowel': 0.988088, 'recall_consonant': 0.988592, 'acc_grapheme': 0.966939, 'acc_vowel': 0.990042, 'acc_consonant': 0.99044, 'loss_grapheme': 0.124944, 'loss_vowel': 0.048327, 'loss_consonant': 0.038857}\n",
      "    9 | 0.000050 | 011776/180756 | 0.0445 | 0.0501 |\n",
      "val: {'recall': 0.979221, 'recall_grapheme': 0.968128, 'recall_vowel': 0.987863, 'recall_consonant': 0.992767, 'acc_grapheme': 0.966789, 'acc_vowel': 0.990639, 'acc_consonant': 0.991038, 'loss_grapheme': 0.129704, 'loss_vowel': 0.048287, 'loss_consonant': 0.038646}\n",
      "    9 | 0.000048 | 114176/180756 | 0.0517 | 0.0488 |\n",
      "val: {'recall': 0.974065, 'recall_grapheme': 0.964834, 'recall_vowel': 0.986424, 'recall_consonant': 0.980167, 'acc_grapheme': 0.964997, 'acc_vowel': 0.989892, 'acc_consonant': 0.989494, 'loss_grapheme': 0.142604, 'loss_vowel': 0.052305, 'loss_consonant': 0.04029}\n",
      "   10 | 0.000043 | 035840/180756 | 0.0303 | 0.0369 |\n",
      "val: {'recall': 0.979036, 'recall_grapheme': 0.969438, 'recall_vowel': 0.988454, 'recall_consonant': 0.988814, 'acc_grapheme': 0.968233, 'acc_vowel': 0.99054, 'acc_consonant': 0.990241, 'loss_grapheme': 0.13285, 'loss_vowel': 0.047038, 'loss_consonant': 0.039247}\n",
      "   10 | 0.000035 | 138240/180756 | 0.0214 | 0.0355 |\n",
      "val: {'recall': 0.980115, 'recall_grapheme': 0.971786, 'recall_vowel': 0.988512, 'recall_consonant': 0.988375, 'acc_grapheme': 0.970623, 'acc_vowel': 0.990888, 'acc_consonant': 0.991038, 'loss_grapheme': 0.122833, 'loss_vowel': 0.048469, 'loss_consonant': 0.036121}\n",
      "   11 | 0.000026 | 059904/180756 | 0.0246 | 0.0246 |\n",
      "val: {'recall': 0.980514, 'recall_grapheme': 0.971969, 'recall_vowel': 0.988123, 'recall_consonant': 0.989995, 'acc_grapheme': 0.96908, 'acc_vowel': 0.990739, 'acc_consonant': 0.990838, 'loss_grapheme': 0.1292, 'loss_vowel': 0.049054, 'loss_consonant': 0.040706}\n",
      "   11 | 0.000016 | 162304/180756 | 0.0211 | 0.0236 |\n",
      "val: {'recall': 0.980684, 'recall_grapheme': 0.971737, 'recall_vowel': 0.98687, 'recall_consonant': 0.992393, 'acc_grapheme': 0.971071, 'acc_vowel': 0.99054, 'acc_consonant': 0.991336, 'loss_grapheme': 0.122896, 'loss_vowel': 0.050504, 'loss_consonant': 0.038983}\n",
      "   12 | 0.000008 | 083968/180756 | 0.0278 | 0.0188 |\n",
      "val: {'recall': 0.981987, 'recall_grapheme': 0.974463, 'recall_vowel': 0.987752, 'recall_consonant': 0.991271, 'acc_grapheme': 0.971868, 'acc_vowel': 0.990988, 'acc_consonant': 0.991735, 'loss_grapheme': 0.120185, 'loss_vowel': 0.046937, 'loss_consonant': 0.037152}\n",
      "** saved\n",
      "   13 | 0.000003 | 005632/180756 | 0.0107 | 0.0138 |\n",
      "val: {'recall': 0.981676, 'recall_grapheme': 0.973704, 'recall_vowel': 0.987674, 'recall_consonant': 0.991621, 'acc_grapheme': 0.972316, 'acc_vowel': 0.990689, 'acc_consonant': 0.991735, 'loss_grapheme': 0.118654, 'loss_vowel': 0.047991, 'loss_consonant': 0.036248}\n",
      "   13 | 0.000001 | 108032/180756 | 0.0117 | 0.0155 |\n",
      "val: {'recall': 0.981626, 'recall_grapheme': 0.973354, 'recall_vowel': 0.98815, 'recall_consonant': 0.991645, 'acc_grapheme': 0.972266, 'acc_vowel': 0.990838, 'acc_consonant': 0.991834, 'loss_grapheme': 0.117976, 'loss_vowel': 0.047583, 'loss_consonant': 0.036146}\n",
      "   14 | 0.000003 | 029696/180756 | 0.0092 | 0.0158 |\n",
      "val: {'recall': 0.981414, 'recall_grapheme': 0.973183, 'recall_vowel': 0.987855, 'recall_consonant': 0.991435, 'acc_grapheme': 0.972067, 'acc_vowel': 0.990838, 'acc_consonant': 0.991834, 'loss_grapheme': 0.117788, 'loss_vowel': 0.047152, 'loss_consonant': 0.036289}\n",
      "   14 | 0.000008 | 132096/180756 | 0.0068 | 0.0158 |\n",
      "val: {'recall': 0.981395, 'recall_grapheme': 0.974121, 'recall_vowel': 0.9882, 'recall_consonant': 0.989138, 'acc_grapheme': 0.972416, 'acc_vowel': 0.990988, 'acc_consonant': 0.991834, 'loss_grapheme': 0.120497, 'loss_vowel': 0.046571, 'loss_consonant': 0.038332}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 0.000016 | 053760/180756 | 0.0345 | 0.0179 |\n",
      "val: {'recall': 0.981747, 'recall_grapheme': 0.973284, 'recall_vowel': 0.98907, 'recall_consonant': 0.99135, 'acc_grapheme': 0.971769, 'acc_vowel': 0.991336, 'acc_consonant': 0.991735, 'loss_grapheme': 0.120667, 'loss_vowel': 0.046991, 'loss_consonant': 0.037535}\n",
      "   15 | 0.000025 | 156160/180756 | 0.0267 | 0.0203 |\n",
      "val: {'recall': 0.980073, 'recall_grapheme': 0.972929, 'recall_vowel': 0.986836, 'recall_consonant': 0.987597, 'acc_grapheme': 0.971022, 'acc_vowel': 0.990291, 'acc_consonant': 0.991187, 'loss_grapheme': 0.125328, 'loss_vowel': 0.051576, 'loss_consonant': 0.042777}\n",
      "   16 | 0.000035 | 077824/180756 | 0.0336 | 0.0288 |\n",
      "val: {'recall': 0.977407, 'recall_grapheme': 0.966984, 'recall_vowel': 0.988511, 'recall_consonant': 0.987149, 'acc_grapheme': 0.966989, 'acc_vowel': 0.99044, 'acc_consonant': 0.99049, 'loss_grapheme': 0.136528, 'loss_vowel': 0.050481, 'loss_consonant': 0.039815}\n",
      "   16 | 0.000043 | 180224/180756 | 0.0312 | 0.0349 |\n",
      "val: {'recall': 0.979724, 'recall_grapheme': 0.969839, 'recall_vowel': 0.989461, 'recall_consonant': 0.989759, 'acc_grapheme': 0.967686, 'acc_vowel': 0.990341, 'acc_consonant': 0.991137, 'loss_grapheme': 0.137535, 'loss_vowel': 0.051181, 'loss_consonant': 0.041894}\n",
      "   17 | 0.000048 | 101888/180756 | 0.0368 | 0.0400 |\n",
      "val: {'recall': 0.978319, 'recall_grapheme': 0.968916, 'recall_vowel': 0.989437, 'recall_consonant': 0.986005, 'acc_grapheme': 0.966491, 'acc_vowel': 0.990141, 'acc_consonant': 0.989544, 'loss_grapheme': 0.144112, 'loss_vowel': 0.04867, 'loss_consonant': 0.045346}\n",
      "   18 | 0.000050 | 023552/180756 | 0.0441 | 0.0363 |\n",
      "val: {'recall': 0.978523, 'recall_grapheme': 0.969471, 'recall_vowel': 0.988824, 'recall_consonant': 0.986324, 'acc_grapheme': 0.968482, 'acc_vowel': 0.990092, 'acc_consonant': 0.991287, 'loss_grapheme': 0.131237, 'loss_vowel': 0.048347, 'loss_consonant': 0.0408}\n",
      "   18 | 0.000048 | 125952/180756 | 0.0458 | 0.0364 |\n",
      "val: {'recall': 0.97782, 'recall_grapheme': 0.969891, 'recall_vowel': 0.985682, 'recall_consonant': 0.985816, 'acc_grapheme': 0.967188, 'acc_vowel': 0.989594, 'acc_consonant': 0.989892, 'loss_grapheme': 0.136511, 'loss_vowel': 0.053526, 'loss_consonant': 0.041581}\n",
      "   19 | 0.000043 | 047616/180756 | 0.0199 | 0.0245 |\n",
      "val: {'recall': 0.97969, 'recall_grapheme': 0.968742, 'recall_vowel': 0.988164, 'recall_consonant': 0.99311, 'acc_grapheme': 0.968781, 'acc_vowel': 0.990141, 'acc_consonant': 0.991087, 'loss_grapheme': 0.135346, 'loss_vowel': 0.053041, 'loss_consonant': 0.039872}\n",
      "   19 | 0.000035 | 150016/180756 | 0.0440 | 0.0250 |\n",
      "val: {'recall': 0.977345, 'recall_grapheme': 0.969517, 'recall_vowel': 0.985523, 'recall_consonant': 0.984823, 'acc_grapheme': 0.968383, 'acc_vowel': 0.989942, 'acc_consonant': 0.989892, 'loss_grapheme': 0.129444, 'loss_vowel': 0.051384, 'loss_consonant': 0.043359}\n",
      "   20 | 0.000026 | 071680/180756 | 0.0162 | 0.0177 |\n",
      "val: {'recall': 0.981251, 'recall_grapheme': 0.972256, 'recall_vowel': 0.988798, 'recall_consonant': 0.991694, 'acc_grapheme': 0.970872, 'acc_vowel': 0.99044, 'acc_consonant': 0.991336, 'loss_grapheme': 0.130574, 'loss_vowel': 0.048814, 'loss_consonant': 0.038816}\n",
      "   20 | 0.000016 | 174080/180756 | 0.0085 | 0.0157 |\n",
      "val: {'recall': 0.981933, 'recall_grapheme': 0.973632, 'recall_vowel': 0.9887, 'recall_consonant': 0.991769, 'acc_grapheme': 0.971968, 'acc_vowel': 0.990739, 'acc_consonant': 0.991984, 'loss_grapheme': 0.128256, 'loss_vowel': 0.048205, 'loss_consonant': 0.038666}\n",
      "   21 | 0.000008 | 095744/180756 | 0.0155 | 0.0112 |\n",
      "val: {'recall': 0.981803, 'recall_grapheme': 0.973335, 'recall_vowel': 0.988071, 'recall_consonant': 0.992471, 'acc_grapheme': 0.971968, 'acc_vowel': 0.990739, 'acc_consonant': 0.991635, 'loss_grapheme': 0.126973, 'loss_vowel': 0.04787, 'loss_consonant': 0.039401}\n",
      "   22 | 0.000003 | 017408/180756 | 0.0070 | 0.0096 |\n",
      "val: {'recall': 0.98248, 'recall_grapheme': 0.975054, 'recall_vowel': 0.988326, 'recall_consonant': 0.991487, 'acc_grapheme': 0.973063, 'acc_vowel': 0.990838, 'acc_consonant': 0.991934, 'loss_grapheme': 0.125785, 'loss_vowel': 0.048437, 'loss_consonant': 0.039302}\n",
      "** saved\n",
      "   22 | 0.000001 | 119808/180756 | 0.0097 | 0.0101 |\n",
      "val: {'recall': 0.982495, 'recall_grapheme': 0.974712, 'recall_vowel': 0.989119, 'recall_consonant': 0.991436, 'acc_grapheme': 0.972615, 'acc_vowel': 0.991187, 'acc_consonant': 0.991984, 'loss_grapheme': 0.12548, 'loss_vowel': 0.047534, 'loss_consonant': 0.038616}\n",
      "** saved\n",
      "   23 | 0.000003 | 041472/180756 | 0.0114 | 0.0098 |\n",
      "val: {'recall': 0.982824, 'recall_grapheme': 0.974935, 'recall_vowel': 0.988783, 'recall_consonant': 0.992641, 'acc_grapheme': 0.972764, 'acc_vowel': 0.991038, 'acc_consonant': 0.992083, 'loss_grapheme': 0.125657, 'loss_vowel': 0.048525, 'loss_consonant': 0.038285}\n",
      "** saved\n",
      "   23 | 0.000008 | 143872/180756 | 0.0127 | 0.0096 |\n",
      "val: {'recall': 0.982244, 'recall_grapheme': 0.973428, 'recall_vowel': 0.989187, 'recall_consonant': 0.992934, 'acc_grapheme': 0.972117, 'acc_vowel': 0.991187, 'acc_consonant': 0.991735, 'loss_grapheme': 0.126576, 'loss_vowel': 0.04858, 'loss_consonant': 0.039212}\n",
      "   24 | 0.000016 | 065536/180756 | 0.0202 | 0.0109 |\n",
      "val: {'recall': 0.980803, 'recall_grapheme': 0.974016, 'recall_vowel': 0.988986, 'recall_consonant': 0.986193, 'acc_grapheme': 0.971769, 'acc_vowel': 0.990639, 'acc_consonant': 0.991336, 'loss_grapheme': 0.131263, 'loss_vowel': 0.051329, 'loss_consonant': 0.040732}\n",
      "   24 | 0.000025 | 167936/180756 | 0.0263 | 0.0134 |\n",
      "val: {'recall': 0.981156, 'recall_grapheme': 0.972724, 'recall_vowel': 0.988849, 'recall_consonant': 0.990326, 'acc_grapheme': 0.971221, 'acc_vowel': 0.990739, 'acc_consonant': 0.991685, 'loss_grapheme': 0.137521, 'loss_vowel': 0.049393, 'loss_consonant': 0.040573}\n",
      "   25 | 0.000035 | 089600/180756 | 0.0316 | 0.0201 |\n",
      "val: {'recall': 0.978543, 'recall_grapheme': 0.971624, 'recall_vowel': 0.985306, 'recall_consonant': 0.985621, 'acc_grapheme': 0.968582, 'acc_vowel': 0.989793, 'acc_consonant': 0.990291, 'loss_grapheme': 0.142059, 'loss_vowel': 0.054757, 'loss_consonant': 0.048071}\n",
      "   26 | 0.000043 | 011264/180756 | 0.0227 | 0.0261 |\n",
      "val: {'recall': 0.978744, 'recall_grapheme': 0.96938, 'recall_vowel': 0.988152, 'recall_consonant': 0.988065, 'acc_grapheme': 0.967238, 'acc_vowel': 0.99049, 'acc_consonant': 0.990291, 'loss_grapheme': 0.141367, 'loss_vowel': 0.053006, 'loss_consonant': 0.048819}\n",
      "   26 | 0.000048 | 113664/180756 | 0.0316 | 0.0336 |\n",
      "val: {'recall': 0.979833, 'recall_grapheme': 0.970787, 'recall_vowel': 0.987181, 'recall_consonant': 0.990577, 'acc_grapheme': 0.966839, 'acc_vowel': 0.988946, 'acc_consonant': 0.99044, 'loss_grapheme': 0.144273, 'loss_vowel': 0.057766, 'loss_consonant': 0.042821}\n",
      "   27 | 0.000050 | 035328/180756 | 0.0266 | 0.0280 |\n",
      "val: {'recall': 0.979048, 'recall_grapheme': 0.968605, 'recall_vowel': 0.988379, 'recall_consonant': 0.990605, 'acc_grapheme': 0.968482, 'acc_vowel': 0.990092, 'acc_consonant': 0.991087, 'loss_grapheme': 0.13795, 'loss_vowel': 0.053522, 'loss_consonant': 0.042216}\n",
      "   27 | 0.000048 | 137728/180756 | 0.0283 | 0.0310 |\n",
      "val: {'recall': 0.976763, 'recall_grapheme': 0.965292, 'recall_vowel': 0.989272, 'recall_consonant': 0.987195, 'acc_grapheme': 0.966292, 'acc_vowel': 0.990291, 'acc_consonant': 0.99044, 'loss_grapheme': 0.138113, 'loss_vowel': 0.05364, 'loss_consonant': 0.044655}\n",
      "   28 | 0.000043 | 059392/180756 | 0.0382 | 0.0223 |\n",
      "val: {'recall': 0.979974, 'recall_grapheme': 0.968574, 'recall_vowel': 0.989258, 'recall_consonant': 0.99349, 'acc_grapheme': 0.966789, 'acc_vowel': 0.99044, 'acc_consonant': 0.990739, 'loss_grapheme': 0.143557, 'loss_vowel': 0.053376, 'loss_consonant': 0.044394}\n",
      "   28 | 0.000035 | 161792/180756 | 0.0306 | 0.0219 |\n",
      "val: {'recall': 0.981231, 'recall_grapheme': 0.972713, 'recall_vowel': 0.98956, 'recall_consonant': 0.98994, 'acc_grapheme': 0.970325, 'acc_vowel': 0.991386, 'acc_consonant': 0.990739, 'loss_grapheme': 0.135481, 'loss_vowel': 0.047967, 'loss_consonant': 0.042065}\n",
      "   29 | 0.000025 | 083456/180756 | 0.0091 | 0.0136 |\n",
      "val: {'recall': 0.980829, 'recall_grapheme': 0.971489, 'recall_vowel': 0.989104, 'recall_consonant': 0.991233, 'acc_grapheme': 0.969976, 'acc_vowel': 0.990988, 'acc_consonant': 0.991237, 'loss_grapheme': 0.133444, 'loss_vowel': 0.047763, 'loss_consonant': 0.041714}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 0.000016 | 005120/180756 | 0.0040 | 0.0095 |\n",
      "val: {'recall': 0.980807, 'recall_grapheme': 0.971388, 'recall_vowel': 0.989321, 'recall_consonant': 0.991133, 'acc_grapheme': 0.970773, 'acc_vowel': 0.991386, 'acc_consonant': 0.991635, 'loss_grapheme': 0.131566, 'loss_vowel': 0.046659, 'loss_consonant': 0.043141}\n",
      "   30 | 0.000008 | 107520/180756 | 0.0062 | 0.0092 |\n",
      "val: {'recall': 0.981161, 'recall_grapheme': 0.972228, 'recall_vowel': 0.989257, 'recall_consonant': 0.990932, 'acc_grapheme': 0.970773, 'acc_vowel': 0.991187, 'acc_consonant': 0.991486, 'loss_grapheme': 0.130839, 'loss_vowel': 0.04676, 'loss_consonant': 0.04234}\n",
      "   31 | 0.000003 | 029184/180756 | 0.0045 | 0.0078 |\n",
      "val: {'recall': 0.981978, 'recall_grapheme': 0.973454, 'recall_vowel': 0.989662, 'recall_consonant': 0.991341, 'acc_grapheme': 0.971968, 'acc_vowel': 0.991486, 'acc_consonant': 0.991336, 'loss_grapheme': 0.129607, 'loss_vowel': 0.046659, 'loss_consonant': 0.041849}\n",
      "   31 | 0.000001 | 131584/180756 | 0.0099 | 0.0074 |\n",
      "val: {'recall': 0.981716, 'recall_grapheme': 0.972305, 'recall_vowel': 0.989915, 'recall_consonant': 0.992337, 'acc_grapheme': 0.971271, 'acc_vowel': 0.991585, 'acc_consonant': 0.991635, 'loss_grapheme': 0.129044, 'loss_vowel': 0.046575, 'loss_consonant': 0.041313}\n",
      "   32 | 0.000003 | 053248/180756 | 0.0265 | 0.0078 |\n",
      "val: {'recall': 0.981667, 'recall_grapheme': 0.972019, 'recall_vowel': 0.989949, 'recall_consonant': 0.99268, 'acc_grapheme': 0.970972, 'acc_vowel': 0.991585, 'acc_consonant': 0.991884, 'loss_grapheme': 0.130537, 'loss_vowel': 0.046488, 'loss_consonant': 0.041368}\n",
      "   32 | 0.000008 | 155648/180756 | 0.0055 | 0.0078 |\n",
      "val: {'recall': 0.98152, 'recall_grapheme': 0.971876, 'recall_vowel': 0.989674, 'recall_consonant': 0.992654, 'acc_grapheme': 0.970424, 'acc_vowel': 0.991436, 'acc_consonant': 0.991735, 'loss_grapheme': 0.133011, 'loss_vowel': 0.047378, 'loss_consonant': 0.042287}\n",
      "   33 | 0.000016 | 077312/180756 | 0.0046 | 0.0085 |\n",
      "val: {'recall': 0.981072, 'recall_grapheme': 0.971285, 'recall_vowel': 0.989082, 'recall_consonant': 0.992636, 'acc_grapheme': 0.969578, 'acc_vowel': 0.991137, 'acc_consonant': 0.991486, 'loss_grapheme': 0.137683, 'loss_vowel': 0.049374, 'loss_consonant': 0.043974}\n",
      "   33 | 0.000025 | 179712/180756 | 0.0051 | 0.0105 |\n",
      "val: {'recall': 0.980557, 'recall_grapheme': 0.971067, 'recall_vowel': 0.988952, 'recall_consonant': 0.991142, 'acc_grapheme': 0.970076, 'acc_vowel': 0.990689, 'acc_consonant': 0.991087, 'loss_grapheme': 0.143556, 'loss_vowel': 0.050608, 'loss_consonant': 0.046054}\n",
      "   34 | 0.000035 | 101376/180756 | 0.0285 | 0.0178 |\n",
      "val: {'recall': 0.978821, 'recall_grapheme': 0.968676, 'recall_vowel': 0.987852, 'recall_consonant': 0.99008, 'acc_grapheme': 0.966292, 'acc_vowel': 0.99044, 'acc_consonant': 0.990888, 'loss_grapheme': 0.158188, 'loss_vowel': 0.051695, 'loss_consonant': 0.048078}\n",
      "   35 | 0.000043 | 023040/180756 | 0.0218 | 0.0244 |\n",
      "val: {'recall': 0.97747, 'recall_grapheme': 0.966646, 'recall_vowel': 0.987763, 'recall_consonant': 0.988825, 'acc_grapheme': 0.96659, 'acc_vowel': 0.989544, 'acc_consonant': 0.99054, 'loss_grapheme': 0.147898, 'loss_vowel': 0.052458, 'loss_consonant': 0.044741}\n",
      "   35 | 0.000048 | 125440/180756 | 0.0194 | 0.0282 |\n",
      "val: {'recall': 0.976298, 'recall_grapheme': 0.965154, 'recall_vowel': 0.985973, 'recall_consonant': 0.988912, 'acc_grapheme': 0.964648, 'acc_vowel': 0.989444, 'acc_consonant': 0.989594, 'loss_grapheme': 0.150116, 'loss_vowel': 0.058093, 'loss_consonant': 0.052964}\n",
      "   36 | 0.000050 | 047104/180756 | 0.0174 | 0.0252 |\n",
      "val: {'recall': 0.978053, 'recall_grapheme': 0.965364, 'recall_vowel': 0.987906, 'recall_consonant': 0.993579, 'acc_grapheme': 0.967736, 'acc_vowel': 0.989793, 'acc_consonant': 0.989992, 'loss_grapheme': 0.136103, 'loss_vowel': 0.054887, 'loss_consonant': 0.048702}\n",
      "   36 | 0.000048 | 149504/180756 | 0.0495 | 0.0257 |\n",
      "val: {'recall': 0.979515, 'recall_grapheme': 0.969891, 'recall_vowel': 0.987557, 'recall_consonant': 0.990719, 'acc_grapheme': 0.968731, 'acc_vowel': 0.989793, 'acc_consonant': 0.990789, 'loss_grapheme': 0.143189, 'loss_vowel': 0.055189, 'loss_consonant': 0.044998}\n",
      "   37 | 0.000043 | 070656/180756 | 0.0261 | 0.0183 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe047eb3f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/mnt/chicm/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-82f70366a153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# augmentation without mixup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-6e100fc974b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) # augmentation without mixup 9828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./models/se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
