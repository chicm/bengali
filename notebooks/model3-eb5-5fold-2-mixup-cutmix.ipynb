{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        #if self.train_mode:\n",
    "        #    augs = get_train_augs()\n",
    "        #    img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3070408134596917"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'efficientnet-b5'\n",
    "args.ckp_name = 'model3_efficientnet-b5_fold2_mixup_cutmix.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 1e-4\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.1\n",
    "args.patience = 2\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 512\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160678, 5) (40162, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "model file: ./models/efficientnet-b5/model3_efficientnet-b5_fold2_mixup_cutmix.pth, exist: True\n",
      "loading ./models/efficientnet-b5/model3_efficientnet-b5_fold2_mixup_cutmix.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.983301, 'recall_grapheme': 0.976311, 'recall_vowel': 0.991086, 'recall_consonant': 0.989495, 'acc_grapheme': 0.975151, 'acc_vowel': 0.99248, 'acc_consonant': 0.990987, 'loss_grapheme': 0.176468, 'loss_vowel': 0.131437, 'loss_consonant': 0.097022}\n",
      "    0 | 0.000100 | 102400/160678 | 4.1286 | 2.5209 |\n",
      "val: {'recall': 0.982782, 'recall_grapheme': 0.976237, 'recall_vowel': 0.990603, 'recall_consonant': 0.988052, 'acc_grapheme': 0.9752, 'acc_vowel': 0.992356, 'acc_consonant': 0.990538, 'loss_grapheme': 0.180455, 'loss_vowel': 0.139938, 'loss_consonant': 0.105501}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000098 | 044544/160678 | 3.6575 | 2.5281 |\n",
      "val: {'recall': 0.982937, 'recall_grapheme': 0.976284, 'recall_vowel': 0.990583, 'recall_consonant': 0.988598, 'acc_grapheme': 0.974877, 'acc_vowel': 0.992281, 'acc_consonant': 0.991061, 'loss_grapheme': 0.188077, 'loss_vowel': 0.140257, 'loss_consonant': 0.105528}\n",
      "    1 | 0.000093 | 146944/160678 | 1.2643 | 2.4541 |\n",
      "val: {'recall': 0.981999, 'recall_grapheme': 0.974077, 'recall_vowel': 0.990528, 'recall_consonant': 0.989316, 'acc_grapheme': 0.974777, 'acc_vowel': 0.992381, 'acc_consonant': 0.990713, 'loss_grapheme': 0.175797, 'loss_vowel': 0.136692, 'loss_consonant': 0.099664}\n",
      "    2 | 0.000086 | 089088/160678 | 3.3413 | 2.2776 |\n",
      "val: {'recall': 0.982517, 'recall_grapheme': 0.974558, 'recall_vowel': 0.990717, 'recall_consonant': 0.990233, 'acc_grapheme': 0.974877, 'acc_vowel': 0.992456, 'acc_consonant': 0.990912, 'loss_grapheme': 0.171229, 'loss_vowel': 0.118096, 'loss_consonant': 0.092903}\n",
      "    3 | 0.000075 | 031232/160678 | 3.3601 | 2.4512 |\n",
      "val: {'recall': 0.983171, 'recall_grapheme': 0.976542, 'recall_vowel': 0.990851, 'recall_consonant': 0.988748, 'acc_grapheme': 0.975624, 'acc_vowel': 0.992431, 'acc_consonant': 0.991011, 'loss_grapheme': 0.177183, 'loss_vowel': 0.139825, 'loss_consonant': 0.101575}\n",
      "    3 | 0.000063 | 133632/160678 | 3.1037 | 2.3055 |\n",
      "val: {'recall': 0.98317, 'recall_grapheme': 0.976954, 'recall_vowel': 0.990858, 'recall_consonant': 0.987914, 'acc_grapheme': 0.975449, 'acc_vowel': 0.992555, 'acc_consonant': 0.991086, 'loss_grapheme': 0.157531, 'loss_vowel': 0.114978, 'loss_consonant': 0.089834}\n",
      "    4 | 0.000051 | 075776/160678 | 3.9285 | 2.3970 |\n",
      "val: {'recall': 0.983561, 'recall_grapheme': 0.976659, 'recall_vowel': 0.990964, 'recall_consonant': 0.989962, 'acc_grapheme': 0.976221, 'acc_vowel': 0.992406, 'acc_consonant': 0.990912, 'loss_grapheme': 0.176865, 'loss_vowel': 0.133803, 'loss_consonant': 0.102052}\n",
      "** saved\n",
      "    5 | 0.000038 | 017920/160678 | 3.4765 | 2.0493 |\n",
      "val: {'recall': 0.983912, 'recall_grapheme': 0.97797, 'recall_vowel': 0.9909, 'recall_consonant': 0.988807, 'acc_grapheme': 0.976545, 'acc_vowel': 0.992655, 'acc_consonant': 0.991136, 'loss_grapheme': 0.166607, 'loss_vowel': 0.119383, 'loss_consonant': 0.09135}\n",
      "** saved\n",
      "    5 | 0.000026 | 120320/160678 | 4.3992 | 2.2893 |\n",
      "val: {'recall': 0.983801, 'recall_grapheme': 0.977416, 'recall_vowel': 0.990997, 'recall_consonant': 0.989376, 'acc_grapheme': 0.975923, 'acc_vowel': 0.992779, 'acc_consonant': 0.991136, 'loss_grapheme': 0.164624, 'loss_vowel': 0.119143, 'loss_consonant': 0.092486}\n",
      "    6 | 0.000015 | 062464/160678 | 4.5900 | 2.3216 |\n",
      "val: {'recall': 0.983598, 'recall_grapheme': 0.977257, 'recall_vowel': 0.991266, 'recall_consonant': 0.988612, 'acc_grapheme': 0.975898, 'acc_vowel': 0.992879, 'acc_consonant': 0.991136, 'loss_grapheme': 0.160266, 'loss_vowel': 0.119439, 'loss_consonant': 0.091889}\n",
      "    7 | 0.000008 | 004608/160678 | 4.4325 | 3.1256 |\n",
      "val: {'recall': 0.983818, 'recall_grapheme': 0.977459, 'recall_vowel': 0.991066, 'recall_consonant': 0.989288, 'acc_grapheme': 0.976072, 'acc_vowel': 0.992779, 'acc_consonant': 0.99126, 'loss_grapheme': 0.168746, 'loss_vowel': 0.12742, 'loss_consonant': 0.096328}\n",
      "    7 | 0.000003 | 107008/160678 | 3.9458 | 2.5093 |\n",
      "val: {'recall': 0.98401, 'recall_grapheme': 0.977528, 'recall_vowel': 0.991065, 'recall_consonant': 0.989919, 'acc_grapheme': 0.976296, 'acc_vowel': 0.992829, 'acc_consonant': 0.991235, 'loss_grapheme': 0.174451, 'loss_vowel': 0.132897, 'loss_consonant': 0.099482}\n",
      "** saved\n",
      "    8 | 0.000001 | 049152/160678 | 2.6393 | 2.3283 |\n",
      "val: {'recall': 0.983685, 'recall_grapheme': 0.977252, 'recall_vowel': 0.99086, 'recall_consonant': 0.989378, 'acc_grapheme': 0.976147, 'acc_vowel': 0.992729, 'acc_consonant': 0.991285, 'loss_grapheme': 0.168046, 'loss_vowel': 0.127122, 'loss_consonant': 0.097051}\n",
      "    8 | 0.000003 | 151552/160678 | 1.9910 | 2.3018 |\n",
      "val: {'recall': 0.983883, 'recall_grapheme': 0.977401, 'recall_vowel': 0.990865, 'recall_consonant': 0.989867, 'acc_grapheme': 0.976097, 'acc_vowel': 0.992779, 'acc_consonant': 0.991285, 'loss_grapheme': 0.161722, 'loss_vowel': 0.119774, 'loss_consonant': 0.091342}\n",
      "    9 | 0.000008 | 093696/160678 | 0.2116 | 2.3398 |\n",
      "val: {'recall': 0.983809, 'recall_grapheme': 0.977151, 'recall_vowel': 0.990861, 'recall_consonant': 0.990073, 'acc_grapheme': 0.975923, 'acc_vowel': 0.992829, 'acc_consonant': 0.99136, 'loss_grapheme': 0.166, 'loss_vowel': 0.124956, 'loss_consonant': 0.095412}\n",
      "   10 | 0.000015 | 035840/160678 | 2.2231 | 2.3002 |\n",
      "val: {'recall': 0.983824, 'recall_grapheme': 0.977471, 'recall_vowel': 0.990944, 'recall_consonant': 0.989411, 'acc_grapheme': 0.976047, 'acc_vowel': 0.992779, 'acc_consonant': 0.991186, 'loss_grapheme': 0.165937, 'loss_vowel': 0.125964, 'loss_consonant': 0.093232}\n",
      "   10 | 0.000026 | 138240/160678 | 1.8220 | 2.2020 |\n",
      "val: {'recall': 0.983613, 'recall_grapheme': 0.976789, 'recall_vowel': 0.990843, 'recall_consonant': 0.990032, 'acc_grapheme': 0.976072, 'acc_vowel': 0.992729, 'acc_consonant': 0.991086, 'loss_grapheme': 0.1607, 'loss_vowel': 0.115982, 'loss_consonant': 0.089515}\n",
      "   11 | 0.000038 | 080384/160678 | 3.8618 | 2.3996 |\n",
      "val: {'recall': 0.983632, 'recall_grapheme': 0.976848, 'recall_vowel': 0.990947, 'recall_consonant': 0.989886, 'acc_grapheme': 0.976022, 'acc_vowel': 0.992605, 'acc_consonant': 0.991111, 'loss_grapheme': 0.166102, 'loss_vowel': 0.129417, 'loss_consonant': 0.098712}\n",
      "   12 | 0.000050 | 022528/160678 | 0.5481 | 2.5537 |\n",
      "val: {'recall': 0.983585, 'recall_grapheme': 0.976801, 'recall_vowel': 0.990976, 'recall_consonant': 0.98976, 'acc_grapheme': 0.975947, 'acc_vowel': 0.99263, 'acc_consonant': 0.991435, 'loss_grapheme': 0.170864, 'loss_vowel': 0.131467, 'loss_consonant': 0.101253}\n",
      "   12 | 0.000063 | 124928/160678 | 4.1552 | 2.3816 |\n",
      "val: {'recall': 0.983674, 'recall_grapheme': 0.977257, 'recall_vowel': 0.991042, 'recall_consonant': 0.989138, 'acc_grapheme': 0.976321, 'acc_vowel': 0.992456, 'acc_consonant': 0.99126, 'loss_grapheme': 0.160137, 'loss_vowel': 0.120625, 'loss_consonant': 0.096621}\n",
      "   13 | 0.000075 | 067072/160678 | 2.8160 | 2.4280 |\n",
      "val: {'recall': 0.983579, 'recall_grapheme': 0.976745, 'recall_vowel': 0.990803, 'recall_consonant': 0.990024, 'acc_grapheme': 0.975947, 'acc_vowel': 0.992605, 'acc_consonant': 0.991211, 'loss_grapheme': 0.164212, 'loss_vowel': 0.12523, 'loss_consonant': 0.097663}\n",
      "   14 | 0.000086 | 009216/160678 | 3.4075 | 2.2222 |\n",
      "val: {'recall': 0.983366, 'recall_grapheme': 0.977079, 'recall_vowel': 0.990437, 'recall_consonant': 0.988869, 'acc_grapheme': 0.975798, 'acc_vowel': 0.99258, 'acc_consonant': 0.991111, 'loss_grapheme': 0.155776, 'loss_vowel': 0.113455, 'loss_consonant': 0.090539}\n",
      "   14 | 0.000093 | 111616/160678 | 3.1826 | 2.2829 |\n",
      "val: {'recall': 0.983136, 'recall_grapheme': 0.976062, 'recall_vowel': 0.990383, 'recall_consonant': 0.990036, 'acc_grapheme': 0.975748, 'acc_vowel': 0.99253, 'acc_consonant': 0.991285, 'loss_grapheme': 0.153991, 'loss_vowel': 0.102271, 'loss_consonant': 0.087446}\n",
      "   15 | 0.000098 | 053760/160678 | 1.8121 | 2.3588 |\n",
      "val: {'recall': 0.983772, 'recall_grapheme': 0.976832, 'recall_vowel': 0.991246, 'recall_consonant': 0.990179, 'acc_grapheme': 0.976047, 'acc_vowel': 0.992505, 'acc_consonant': 0.991061, 'loss_grapheme': 0.160401, 'loss_vowel': 0.111266, 'loss_consonant': 0.090413}\n",
      "   15 | 0.000100 | 156160/160678 | 2.1603 | 2.3438 |\n",
      "val: {'recall': 0.982905, 'recall_grapheme': 0.975693, 'recall_vowel': 0.990364, 'recall_consonant': 0.989871, 'acc_grapheme': 0.975599, 'acc_vowel': 0.992456, 'acc_consonant': 0.991235, 'loss_grapheme': 0.163736, 'loss_vowel': 0.127968, 'loss_consonant': 0.095677}\n",
      "   16 | 0.000098 | 098304/160678 | 1.8516 | 2.3252 |\n",
      "val: {'recall': 0.984519, 'recall_grapheme': 0.978411, 'recall_vowel': 0.990936, 'recall_consonant': 0.99032, 'acc_grapheme': 0.976719, 'acc_vowel': 0.992655, 'acc_consonant': 0.99141, 'loss_grapheme': 0.158414, 'loss_vowel': 0.117182, 'loss_consonant': 0.094244}\n",
      "** saved\n",
      "   17 | 0.000093 | 040448/160678 | 3.7218 | 2.2149 |\n",
      "val: {'recall': 0.982879, 'recall_grapheme': 0.975731, 'recall_vowel': 0.990848, 'recall_consonant': 0.989204, 'acc_grapheme': 0.975723, 'acc_vowel': 0.992879, 'acc_consonant': 0.991509, 'loss_grapheme': 0.155792, 'loss_vowel': 0.115942, 'loss_consonant': 0.091607}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 0.000086 | 142848/160678 | 3.2847 | 2.2679 |\n",
      "val: {'recall': 0.984129, 'recall_grapheme': 0.977729, 'recall_vowel': 0.991241, 'recall_consonant': 0.989818, 'acc_grapheme': 0.976993, 'acc_vowel': 0.993053, 'acc_consonant': 0.99136, 'loss_grapheme': 0.153269, 'loss_vowel': 0.111629, 'loss_consonant': 0.087498}\n",
      "   18 | 0.000075 | 084992/160678 | 2.3258 | 2.1739 |\n",
      "val: {'recall': 0.983811, 'recall_grapheme': 0.977035, 'recall_vowel': 0.991345, 'recall_consonant': 0.989827, 'acc_grapheme': 0.97642, 'acc_vowel': 0.992904, 'acc_consonant': 0.99141, 'loss_grapheme': 0.149146, 'loss_vowel': 0.106552, 'loss_consonant': 0.083931}\n",
      "   19 | 0.000063 | 027136/160678 | 4.3916 | 2.3412 |\n",
      "val: {'recall': 0.984097, 'recall_grapheme': 0.977401, 'recall_vowel': 0.991001, 'recall_consonant': 0.990586, 'acc_grapheme': 0.976918, 'acc_vowel': 0.992879, 'acc_consonant': 0.991659, 'loss_grapheme': 0.153934, 'loss_vowel': 0.111527, 'loss_consonant': 0.091117}\n",
      "   19 | 0.000051 | 129536/160678 | 1.8129 | 2.3079 |\n",
      "val: {'recall': 0.983998, 'recall_grapheme': 0.977068, 'recall_vowel': 0.991474, 'recall_consonant': 0.990381, 'acc_grapheme': 0.976595, 'acc_vowel': 0.993028, 'acc_consonant': 0.991783, 'loss_grapheme': 0.157547, 'loss_vowel': 0.116767, 'loss_consonant': 0.091551}\n",
      "   20 | 0.000038 | 071680/160678 | 2.2735 | 2.2608 |\n",
      "val: {'recall': 0.983807, 'recall_grapheme': 0.976608, 'recall_vowel': 0.991653, 'recall_consonant': 0.990356, 'acc_grapheme': 0.976669, 'acc_vowel': 0.993178, 'acc_consonant': 0.991484, 'loss_grapheme': 0.147992, 'loss_vowel': 0.108337, 'loss_consonant': 0.086527}\n",
      "   21 | 0.000026 | 013824/160678 | 3.9595 | 1.9550 |\n",
      "val: {'recall': 0.984735, 'recall_grapheme': 0.978476, 'recall_vowel': 0.991646, 'recall_consonant': 0.99034, 'acc_grapheme': 0.977167, 'acc_vowel': 0.993178, 'acc_consonant': 0.991808, 'loss_grapheme': 0.14755, 'loss_vowel': 0.106522, 'loss_consonant': 0.086381}\n",
      "** saved\n",
      "   21 | 0.000015 | 116224/160678 | 1.0059 | 2.3454 |\n",
      "val: {'recall': 0.984359, 'recall_grapheme': 0.97794, 'recall_vowel': 0.991183, 'recall_consonant': 0.990374, 'acc_grapheme': 0.977217, 'acc_vowel': 0.992954, 'acc_consonant': 0.992132, 'loss_grapheme': 0.15803, 'loss_vowel': 0.119746, 'loss_consonant': 0.095091}\n",
      "   22 | 0.000008 | 058368/160678 | 1.7740 | 2.2316 |\n",
      "val: {'recall': 0.984553, 'recall_grapheme': 0.978374, 'recall_vowel': 0.991289, 'recall_consonant': 0.990175, 'acc_grapheme': 0.977292, 'acc_vowel': 0.993078, 'acc_consonant': 0.991883, 'loss_grapheme': 0.15094, 'loss_vowel': 0.112026, 'loss_consonant': 0.089958}\n",
      "   23 | 0.000003 | 000512/160678 | 2.7655 | 2.7655 |\n",
      "val: {'recall': 0.98454, 'recall_grapheme': 0.97798, 'recall_vowel': 0.991344, 'recall_consonant': 0.990857, 'acc_grapheme': 0.977242, 'acc_vowel': 0.993103, 'acc_consonant': 0.992007, 'loss_grapheme': 0.151242, 'loss_vowel': 0.110948, 'loss_consonant': 0.089356}\n",
      "   23 | 0.000001 | 102912/160678 | 3.2121 | 2.2614 |\n",
      "val: {'recall': 0.984604, 'recall_grapheme': 0.978068, 'recall_vowel': 0.991457, 'recall_consonant': 0.990824, 'acc_grapheme': 0.977118, 'acc_vowel': 0.993128, 'acc_consonant': 0.991982, 'loss_grapheme': 0.150167, 'loss_vowel': 0.111904, 'loss_consonant': 0.089292}\n",
      "   24 | 0.000003 | 045056/160678 | 2.4158 | 2.3722 |\n",
      "val: {'recall': 0.984576, 'recall_grapheme': 0.978351, 'recall_vowel': 0.991285, 'recall_consonant': 0.990316, 'acc_grapheme': 0.977367, 'acc_vowel': 0.993078, 'acc_consonant': 0.991858, 'loss_grapheme': 0.160366, 'loss_vowel': 0.122651, 'loss_consonant': 0.096407}\n",
      "   24 | 0.000008 | 147456/160678 | 3.2791 | 2.3426 |\n",
      "val: {'recall': 0.98443, 'recall_grapheme': 0.978296, 'recall_vowel': 0.991095, 'recall_consonant': 0.990032, 'acc_grapheme': 0.977416, 'acc_vowel': 0.992978, 'acc_consonant': 0.991758, 'loss_grapheme': 0.154463, 'loss_vowel': 0.117126, 'loss_consonant': 0.093129}\n",
      "   25 | 0.000015 | 089600/160678 | 2.1826 | 2.1976 |\n",
      "val: {'recall': 0.984301, 'recall_grapheme': 0.978108, 'recall_vowel': 0.990955, 'recall_consonant': 0.990031, 'acc_grapheme': 0.977342, 'acc_vowel': 0.992929, 'acc_consonant': 0.991758, 'loss_grapheme': 0.15258, 'loss_vowel': 0.11533, 'loss_consonant': 0.091818}\n",
      "   26 | 0.000026 | 031744/160678 | 0.1947 | 2.1825 |\n",
      "val: {'recall': 0.984176, 'recall_grapheme': 0.97776, 'recall_vowel': 0.991206, 'recall_consonant': 0.98998, 'acc_grapheme': 0.977267, 'acc_vowel': 0.993003, 'acc_consonant': 0.991833, 'loss_grapheme': 0.14689, 'loss_vowel': 0.108711, 'loss_consonant': 0.087092}\n",
      "   26 | 0.000038 | 134144/160678 | 1.9713 | 2.2451 |\n",
      "val: {'recall': 0.984439, 'recall_grapheme': 0.978438, 'recall_vowel': 0.991201, 'recall_consonant': 0.989679, 'acc_grapheme': 0.977167, 'acc_vowel': 0.992978, 'acc_consonant': 0.991933, 'loss_grapheme': 0.155397, 'loss_vowel': 0.114019, 'loss_consonant': 0.091862}\n",
      "   27 | 0.000050 | 076288/160678 | 2.3250 | 2.2619 |\n",
      "val: {'recall': 0.984461, 'recall_grapheme': 0.978677, 'recall_vowel': 0.991507, 'recall_consonant': 0.988984, 'acc_grapheme': 0.977043, 'acc_vowel': 0.993053, 'acc_consonant': 0.991709, 'loss_grapheme': 0.154884, 'loss_vowel': 0.116556, 'loss_consonant': 0.092064}\n",
      "   28 | 0.000063 | 018432/160678 | 2.1078 | 2.3349 |\n",
      "val: {'recall': 0.983779, 'recall_grapheme': 0.976828, 'recall_vowel': 0.990993, 'recall_consonant': 0.990465, 'acc_grapheme': 0.976943, 'acc_vowel': 0.992904, 'acc_consonant': 0.991659, 'loss_grapheme': 0.163244, 'loss_vowel': 0.126714, 'loss_consonant': 0.097563}\n",
      "   28 | 0.000075 | 120832/160678 | 0.9521 | 2.2280 |\n",
      "val: {'recall': 0.984238, 'recall_grapheme': 0.977857, 'recall_vowel': 0.991988, 'recall_consonant': 0.98925, 'acc_grapheme': 0.977217, 'acc_vowel': 0.993128, 'acc_consonant': 0.991509, 'loss_grapheme': 0.148958, 'loss_vowel': 0.112584, 'loss_consonant': 0.086547}\n",
      "   29 | 0.000086 | 062976/160678 | 3.2051 | 2.1286 |\n",
      "val: {'recall': 0.984823, 'recall_grapheme': 0.978666, 'recall_vowel': 0.991576, 'recall_consonant': 0.990387, 'acc_grapheme': 0.977441, 'acc_vowel': 0.993178, 'acc_consonant': 0.991659, 'loss_grapheme': 0.140699, 'loss_vowel': 0.107963, 'loss_consonant': 0.081564}\n",
      "** saved\n",
      "   30 | 0.000093 | 005120/160678 | 3.7608 | 2.6626 |\n",
      "val: {'recall': 0.984613, 'recall_grapheme': 0.978421, 'recall_vowel': 0.991432, 'recall_consonant': 0.990177, 'acc_grapheme': 0.977192, 'acc_vowel': 0.992904, 'acc_consonant': 0.991634, 'loss_grapheme': 0.155997, 'loss_vowel': 0.117704, 'loss_consonant': 0.092187}\n",
      "   30 | 0.000098 | 107520/160678 | 3.2017 | 2.1588 |\n",
      "val: {'recall': 0.984095, 'recall_grapheme': 0.976765, 'recall_vowel': 0.991491, 'recall_consonant': 0.991359, 'acc_grapheme': 0.97769, 'acc_vowel': 0.993352, 'acc_consonant': 0.991534, 'loss_grapheme': 0.148958, 'loss_vowel': 0.114596, 'loss_consonant': 0.09234}\n",
      "   31 | 0.000100 | 049664/160678 | 1.8912 | 2.3567 |\n",
      "val: {'recall': 0.985047, 'recall_grapheme': 0.978504, 'recall_vowel': 0.991792, 'recall_consonant': 0.991388, 'acc_grapheme': 0.978064, 'acc_vowel': 0.993252, 'acc_consonant': 0.991709, 'loss_grapheme': 0.171867, 'loss_vowel': 0.12936, 'loss_consonant': 0.101686}\n",
      "** saved\n",
      "   31 | 0.000098 | 152064/160678 | 2.0776 | 2.2675 |\n",
      "val: {'recall': 0.98425, 'recall_grapheme': 0.977979, 'recall_vowel': 0.990685, 'recall_consonant': 0.990357, 'acc_grapheme': 0.977641, 'acc_vowel': 0.992505, 'acc_consonant': 0.991484, 'loss_grapheme': 0.155324, 'loss_vowel': 0.11557, 'loss_consonant': 0.08999}\n",
      "   32 | 0.000093 | 094208/160678 | 1.9008 | 2.3039 |\n",
      "val: {'recall': 0.985377, 'recall_grapheme': 0.979174, 'recall_vowel': 0.991674, 'recall_consonant': 0.991487, 'acc_grapheme': 0.978114, 'acc_vowel': 0.993028, 'acc_consonant': 0.992007, 'loss_grapheme': 0.152157, 'loss_vowel': 0.117835, 'loss_consonant': 0.091544}\n",
      "** saved\n",
      "   33 | 0.000086 | 036352/160678 | 1.2812 | 2.2315 |\n",
      "val: {'recall': 0.984323, 'recall_grapheme': 0.97719, 'recall_vowel': 0.991904, 'recall_consonant': 0.991008, 'acc_grapheme': 0.977416, 'acc_vowel': 0.993476, 'acc_consonant': 0.991808, 'loss_grapheme': 0.153834, 'loss_vowel': 0.129365, 'loss_consonant': 0.092095}\n",
      "   33 | 0.000075 | 138752/160678 | 2.8407 | 2.2824 |\n",
      "val: {'recall': 0.984887, 'recall_grapheme': 0.97875, 'recall_vowel': 0.991312, 'recall_consonant': 0.990735, 'acc_grapheme': 0.97789, 'acc_vowel': 0.993103, 'acc_consonant': 0.991709, 'loss_grapheme': 0.166854, 'loss_vowel': 0.128522, 'loss_consonant': 0.096887}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 0.000063 | 080896/160678 | 3.6998 | 2.2891 |\n",
      "val: {'recall': 0.985003, 'recall_grapheme': 0.978464, 'recall_vowel': 0.991901, 'recall_consonant': 0.991182, 'acc_grapheme': 0.978014, 'acc_vowel': 0.993178, 'acc_consonant': 0.991709, 'loss_grapheme': 0.16377, 'loss_vowel': 0.125727, 'loss_consonant': 0.095097}\n",
      "   35 | 0.000051 | 023040/160678 | 2.2858 | 2.0400 |\n",
      "val: {'recall': 0.985402, 'recall_grapheme': 0.979038, 'recall_vowel': 0.992249, 'recall_consonant': 0.991283, 'acc_grapheme': 0.978512, 'acc_vowel': 0.993427, 'acc_consonant': 0.992057, 'loss_grapheme': 0.154684, 'loss_vowel': 0.11942, 'loss_consonant': 0.091604}\n",
      "** saved\n",
      "   35 | 0.000038 | 125440/160678 | 1.1666 | 2.2376 |\n",
      "val: {'recall': 0.984924, 'recall_grapheme': 0.978415, 'recall_vowel': 0.991613, 'recall_consonant': 0.991253, 'acc_grapheme': 0.978686, 'acc_vowel': 0.993402, 'acc_consonant': 0.991982, 'loss_grapheme': 0.147367, 'loss_vowel': 0.108847, 'loss_consonant': 0.087892}\n",
      "   36 | 0.000026 | 067584/160678 | 0.2988 | 2.3504 |\n",
      "val: {'recall': 0.985614, 'recall_grapheme': 0.979959, 'recall_vowel': 0.99206, 'recall_consonant': 0.99048, 'acc_grapheme': 0.97906, 'acc_vowel': 0.993476, 'acc_consonant': 0.991933, 'loss_grapheme': 0.150821, 'loss_vowel': 0.118761, 'loss_consonant': 0.092956}\n",
      "** saved\n",
      "   37 | 0.000015 | 009728/160678 | 2.0193 | 2.2977 |\n",
      "val: {'recall': 0.985374, 'recall_grapheme': 0.979068, 'recall_vowel': 0.991864, 'recall_consonant': 0.991495, 'acc_grapheme': 0.978637, 'acc_vowel': 0.993377, 'acc_consonant': 0.992007, 'loss_grapheme': 0.145382, 'loss_vowel': 0.109579, 'loss_consonant': 0.086879}\n",
      "   37 | 0.000008 | 112128/160678 | 1.9255 | 2.2193 |\n",
      "val: {'recall': 0.985516, 'recall_grapheme': 0.979285, 'recall_vowel': 0.991889, 'recall_consonant': 0.991606, 'acc_grapheme': 0.97891, 'acc_vowel': 0.993476, 'acc_consonant': 0.992082, 'loss_grapheme': 0.144861, 'loss_vowel': 0.111183, 'loss_consonant': 0.08777}\n",
      "   38 | 0.000003 | 054272/160678 | 1.9003 | 2.1642 |\n",
      "val: {'recall': 0.985721, 'recall_grapheme': 0.979554, 'recall_vowel': 0.99216, 'recall_consonant': 0.991618, 'acc_grapheme': 0.97896, 'acc_vowel': 0.993601, 'acc_consonant': 0.992157, 'loss_grapheme': 0.145571, 'loss_vowel': 0.110696, 'loss_consonant': 0.08749}\n",
      "** saved\n",
      "   38 | 0.000001 | 156672/160678 | 1.9069 | 2.2268 |\n",
      "val: {'recall': 0.985756, 'recall_grapheme': 0.979919, 'recall_vowel': 0.992041, 'recall_consonant': 0.991144, 'acc_grapheme': 0.979309, 'acc_vowel': 0.993501, 'acc_consonant': 0.992182, 'loss_grapheme': 0.152619, 'loss_vowel': 0.119829, 'loss_consonant': 0.093151}\n",
      "** saved\n",
      "   39 | 0.000003 | 098816/160678 | 3.3663 | 2.2659 |\n",
      "val: {'recall': 0.985563, 'recall_grapheme': 0.979562, 'recall_vowel': 0.991989, 'recall_consonant': 0.991138, 'acc_grapheme': 0.979035, 'acc_vowel': 0.993551, 'acc_consonant': 0.992157, 'loss_grapheme': 0.147402, 'loss_vowel': 0.113692, 'loss_consonant': 0.089057}\n",
      "   40 | 0.000008 | 040960/160678 | 1.9563 | 2.2581 |\n",
      "val: {'recall': 0.985416, 'recall_grapheme': 0.979614, 'recall_vowel': 0.991885, 'recall_consonant': 0.990553, 'acc_grapheme': 0.97896, 'acc_vowel': 0.993501, 'acc_consonant': 0.992057, 'loss_grapheme': 0.155854, 'loss_vowel': 0.123825, 'loss_consonant': 0.095835}\n",
      "   40 | 0.000015 | 143360/160678 | 0.1708 | 2.1788 |\n",
      "val: {'recall': 0.985814, 'recall_grapheme': 0.979791, 'recall_vowel': 0.992203, 'recall_consonant': 0.991471, 'acc_grapheme': 0.978886, 'acc_vowel': 0.993551, 'acc_consonant': 0.992032, 'loss_grapheme': 0.139488, 'loss_vowel': 0.104074, 'loss_consonant': 0.082589}\n",
      "** saved\n",
      "   41 | 0.000026 | 085504/160678 | 3.2364 | 2.4240 |\n",
      "val: {'recall': 0.985497, 'recall_grapheme': 0.979602, 'recall_vowel': 0.991918, 'recall_consonant': 0.990866, 'acc_grapheme': 0.978562, 'acc_vowel': 0.993576, 'acc_consonant': 0.991958, 'loss_grapheme': 0.156511, 'loss_vowel': 0.124458, 'loss_consonant': 0.098206}\n",
      "   42 | 0.000038 | 027648/160678 | 1.5221 | 2.1276 |\n",
      "val: {'recall': 0.985212, 'recall_grapheme': 0.978878, 'recall_vowel': 0.991965, 'recall_consonant': 0.991127, 'acc_grapheme': 0.978437, 'acc_vowel': 0.993352, 'acc_consonant': 0.992032, 'loss_grapheme': 0.146287, 'loss_vowel': 0.108629, 'loss_consonant': 0.086382}\n",
      "   42 | 0.000051 | 130048/160678 | 2.8002 | 2.2897 |\n",
      "val: {'recall': 0.984888, 'recall_grapheme': 0.978766, 'recall_vowel': 0.991341, 'recall_consonant': 0.990678, 'acc_grapheme': 0.977989, 'acc_vowel': 0.993277, 'acc_consonant': 0.991982, 'loss_grapheme': 0.150012, 'loss_vowel': 0.115485, 'loss_consonant': 0.092683}\n",
      "   43 | 0.000063 | 072192/160678 | 0.9268 | 2.0526 |\n",
      "val: {'recall': 0.985194, 'recall_grapheme': 0.979201, 'recall_vowel': 0.991959, 'recall_consonant': 0.990415, 'acc_grapheme': 0.978288, 'acc_vowel': 0.993277, 'acc_consonant': 0.991908, 'loss_grapheme': 0.135275, 'loss_vowel': 0.100671, 'loss_consonant': 0.078717}\n",
      "   44 | 0.000075 | 014336/160678 | 0.2963 | 1.9698 |\n",
      "val: {'recall': 0.985072, 'recall_grapheme': 0.978989, 'recall_vowel': 0.991634, 'recall_consonant': 0.990676, 'acc_grapheme': 0.978163, 'acc_vowel': 0.993377, 'acc_consonant': 0.991883, 'loss_grapheme': 0.150131, 'loss_vowel': 0.115595, 'loss_consonant': 0.09128}\n",
      "   44 | 0.000086 | 116736/160678 | 2.8997 | 2.1621 |\n",
      "val: {'recall': 0.985723, 'recall_grapheme': 0.979915, 'recall_vowel': 0.992342, 'recall_consonant': 0.990722, 'acc_grapheme': 0.978487, 'acc_vowel': 0.993551, 'acc_consonant': 0.991908, 'loss_grapheme': 0.148926, 'loss_vowel': 0.115651, 'loss_consonant': 0.08647}\n",
      "   45 | 0.000093 | 058880/160678 | 2.0738 | 2.1767 |\n",
      "val: {'recall': 0.985513, 'recall_grapheme': 0.979158, 'recall_vowel': 0.991547, 'recall_consonant': 0.992188, 'acc_grapheme': 0.978537, 'acc_vowel': 0.993327, 'acc_consonant': 0.992431, 'loss_grapheme': 0.143167, 'loss_vowel': 0.107965, 'loss_consonant': 0.08766}\n",
      "   46 | 0.000098 | 001024/160678 | 1.7989 | 1.8673 |\n",
      "val: {'recall': 0.985305, 'recall_grapheme': 0.979471, 'recall_vowel': 0.991936, 'recall_consonant': 0.990344, 'acc_grapheme': 0.978213, 'acc_vowel': 0.993352, 'acc_consonant': 0.992107, 'loss_grapheme': 0.145002, 'loss_vowel': 0.120164, 'loss_consonant': 0.089386}\n",
      "   46 | 0.000100 | 103424/160678 | 2.7463 | 2.3305 |\n",
      "val: {'recall': 0.985332, 'recall_grapheme': 0.978962, 'recall_vowel': 0.991706, 'recall_consonant': 0.991699, 'acc_grapheme': 0.978288, 'acc_vowel': 0.993302, 'acc_consonant': 0.992057, 'loss_grapheme': 0.150318, 'loss_vowel': 0.110186, 'loss_consonant': 0.091219}\n",
      "   47 | 0.000098 | 045568/160678 | 3.0560 | 2.1275 |\n",
      "val: {'recall': 0.985046, 'recall_grapheme': 0.978654, 'recall_vowel': 0.992159, 'recall_consonant': 0.990719, 'acc_grapheme': 0.978537, 'acc_vowel': 0.993576, 'acc_consonant': 0.992082, 'loss_grapheme': 0.143724, 'loss_vowel': 0.108623, 'loss_consonant': 0.087676}\n",
      "   47 | 0.000093 | 147968/160678 | 1.2347 | 2.1880 |\n",
      "val: {'recall': 0.984456, 'recall_grapheme': 0.978593, 'recall_vowel': 0.990975, 'recall_consonant': 0.989666, 'acc_grapheme': 0.978114, 'acc_vowel': 0.993452, 'acc_consonant': 0.992231, 'loss_grapheme': 0.142544, 'loss_vowel': 0.106731, 'loss_consonant': 0.085986}\n",
      "   48 | 0.000086 | 090112/160678 | 2.3732 | 2.2009 |\n",
      "val: {'recall': 0.985117, 'recall_grapheme': 0.978933, 'recall_vowel': 0.991123, 'recall_consonant': 0.991478, 'acc_grapheme': 0.978089, 'acc_vowel': 0.993203, 'acc_consonant': 0.992107, 'loss_grapheme': 0.141883, 'loss_vowel': 0.105392, 'loss_consonant': 0.083565}\n",
      "   49 | 0.000075 | 032256/160678 | 1.8999 | 2.3765 |\n",
      "val: {'recall': 0.985424, 'recall_grapheme': 0.979455, 'recall_vowel': 0.991731, 'recall_consonant': 0.991054, 'acc_grapheme': 0.97891, 'acc_vowel': 0.993501, 'acc_consonant': 0.992157, 'loss_grapheme': 0.140054, 'loss_vowel': 0.110296, 'loss_consonant': 0.087822}\n",
      "   49 | 0.000063 | 134656/160678 | 2.0596 | 2.2724 |\n",
      "val: {'recall': 0.985556, 'recall_grapheme': 0.979544, 'recall_vowel': 0.992124, 'recall_consonant': 0.991012, 'acc_grapheme': 0.97891, 'acc_vowel': 0.993526, 'acc_consonant': 0.992107, 'loss_grapheme': 0.145176, 'loss_vowel': 0.117058, 'loss_consonant': 0.089284}\n",
      "   50 | 0.000051 | 076800/160678 | 2.1067 | 2.2646 |\n",
      "val: {'recall': 0.985397, 'recall_grapheme': 0.978629, 'recall_vowel': 0.992041, 'recall_consonant': 0.992289, 'acc_grapheme': 0.978985, 'acc_vowel': 0.993576, 'acc_consonant': 0.992207, 'loss_grapheme': 0.134609, 'loss_vowel': 0.093687, 'loss_consonant': 0.078446}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 0.000038 | 018944/160678 | 1.9761 | 2.4795 |\n",
      "val: {'recall': 0.985394, 'recall_grapheme': 0.980221, 'recall_vowel': 0.991855, 'recall_consonant': 0.98928, 'acc_grapheme': 0.979508, 'acc_vowel': 0.993626, 'acc_consonant': 0.992306, 'loss_grapheme': 0.149616, 'loss_vowel': 0.116633, 'loss_consonant': 0.093396}\n",
      "   51 | 0.000026 | 121344/160678 | 0.5766 | 2.3603 |\n",
      "val: {'recall': 0.984973, 'recall_grapheme': 0.979312, 'recall_vowel': 0.991869, 'recall_consonant': 0.989399, 'acc_grapheme': 0.978886, 'acc_vowel': 0.993402, 'acc_consonant': 0.992082, 'loss_grapheme': 0.146957, 'loss_vowel': 0.109192, 'loss_consonant': 0.090654}\n",
      "   52 | 0.000015 | 063488/160678 | 4.1035 | 2.1606 |\n",
      "val: {'recall': 0.985739, 'recall_grapheme': 0.979883, 'recall_vowel': 0.992193, 'recall_consonant': 0.990999, 'acc_grapheme': 0.979383, 'acc_vowel': 0.993651, 'acc_consonant': 0.992306, 'loss_grapheme': 0.137067, 'loss_vowel': 0.100586, 'loss_consonant': 0.083185}\n",
      "   53 | 0.000008 | 005632/160678 | 1.5757 | 2.1919 |\n",
      "val: {'recall': 0.985983, 'recall_grapheme': 0.980141, 'recall_vowel': 0.992104, 'recall_consonant': 0.991547, 'acc_grapheme': 0.979458, 'acc_vowel': 0.993601, 'acc_consonant': 0.992231, 'loss_grapheme': 0.145112, 'loss_vowel': 0.107756, 'loss_consonant': 0.089278}\n",
      "** saved\n",
      "   53 | 0.000003 | 108032/160678 | 1.7592 | 2.1457 |\n",
      "val: {'recall': 0.985952, 'recall_grapheme': 0.980073, 'recall_vowel': 0.992035, 'recall_consonant': 0.991626, 'acc_grapheme': 0.979309, 'acc_vowel': 0.993676, 'acc_consonant': 0.992331, 'loss_grapheme': 0.134412, 'loss_vowel': 0.098249, 'loss_consonant': 0.080941}\n",
      "   54 | 0.000001 | 050176/160678 | 1.8879 | 2.1603 |\n",
      "val: {'recall': 0.985856, 'recall_grapheme': 0.97994, 'recall_vowel': 0.992042, 'recall_consonant': 0.991503, 'acc_grapheme': 0.979433, 'acc_vowel': 0.993501, 'acc_consonant': 0.992281, 'loss_grapheme': 0.13867, 'loss_vowel': 0.101966, 'loss_consonant': 0.084131}\n",
      "   54 | 0.000003 | 152576/160678 | 1.2598 | 2.2855 |\n",
      "val: {'recall': 0.985712, 'recall_grapheme': 0.980015, 'recall_vowel': 0.99226, 'recall_consonant': 0.990559, 'acc_grapheme': 0.979408, 'acc_vowel': 0.993651, 'acc_consonant': 0.992281, 'loss_grapheme': 0.148992, 'loss_vowel': 0.115201, 'loss_consonant': 0.091992}\n",
      "   55 | 0.000008 | 094720/160678 | 1.6053 | 2.2366 |\n",
      "val: {'recall': 0.985576, 'recall_grapheme': 0.979817, 'recall_vowel': 0.992137, 'recall_consonant': 0.990531, 'acc_grapheme': 0.979359, 'acc_vowel': 0.993576, 'acc_consonant': 0.992331, 'loss_grapheme': 0.141634, 'loss_vowel': 0.107544, 'loss_consonant': 0.08714}\n",
      "   56 | 0.000015 | 036864/160678 | 0.4182 | 2.1204 |\n",
      "val: {'recall': 0.985834, 'recall_grapheme': 0.979528, 'recall_vowel': 0.992199, 'recall_consonant': 0.99208, 'acc_grapheme': 0.979184, 'acc_vowel': 0.993651, 'acc_consonant': 0.992207, 'loss_grapheme': 0.13523, 'loss_vowel': 0.099284, 'loss_consonant': 0.081446}\n",
      "   56 | 0.000026 | 139264/160678 | 3.9770 | 2.1201 |\n",
      "val: {'recall': 0.98573, 'recall_grapheme': 0.980319, 'recall_vowel': 0.99218, 'recall_consonant': 0.990103, 'acc_grapheme': 0.979682, 'acc_vowel': 0.993526, 'acc_consonant': 0.992182, 'loss_grapheme': 0.131815, 'loss_vowel': 0.0949, 'loss_consonant': 0.078014}\n",
      "   57 | 0.000038 | 081408/160678 | 3.8574 | 2.1453 |\n",
      "val: {'recall': 0.985724, 'recall_grapheme': 0.979864, 'recall_vowel': 0.991707, 'recall_consonant': 0.99146, 'acc_grapheme': 0.978985, 'acc_vowel': 0.993427, 'acc_consonant': 0.992555, 'loss_grapheme': 0.137632, 'loss_vowel': 0.099619, 'loss_consonant': 0.08036}\n",
      "   58 | 0.000051 | 023552/160678 | 2.2134 | 2.3764 |\n",
      "val: {'recall': 0.985987, 'recall_grapheme': 0.980341, 'recall_vowel': 0.991618, 'recall_consonant': 0.991649, 'acc_grapheme': 0.979483, 'acc_vowel': 0.993576, 'acc_consonant': 0.992505, 'loss_grapheme': 0.139719, 'loss_vowel': 0.101596, 'loss_consonant': 0.081233}\n",
      "** saved\n",
      "   58 | 0.000063 | 125952/160678 | 0.6271 | 2.0806 |\n",
      "val: {'recall': 0.984911, 'recall_grapheme': 0.979188, 'recall_vowel': 0.992132, 'recall_consonant': 0.989135, 'acc_grapheme': 0.978985, 'acc_vowel': 0.99385, 'acc_consonant': 0.992032, 'loss_grapheme': 0.128729, 'loss_vowel': 0.089397, 'loss_consonant': 0.073277}\n",
      "   59 | 0.000075 | 068096/160678 | 1.9553 | 2.0866 |\n",
      "val: {'recall': 0.985858, 'recall_grapheme': 0.98001, 'recall_vowel': 0.991717, 'recall_consonant': 0.991692, 'acc_grapheme': 0.979284, 'acc_vowel': 0.993626, 'acc_consonant': 0.992182, 'loss_grapheme': 0.132415, 'loss_vowel': 0.099546, 'loss_consonant': 0.078921}\n",
      "   60 | 0.000086 | 010240/160678 | 4.1193 | 2.4317 |\n",
      "val: {'recall': 0.985323, 'recall_grapheme': 0.978751, 'recall_vowel': 0.991529, 'recall_consonant': 0.99226, 'acc_grapheme': 0.978637, 'acc_vowel': 0.993377, 'acc_consonant': 0.992057, 'loss_grapheme': 0.14487, 'loss_vowel': 0.109655, 'loss_consonant': 0.08706}\n",
      "   60 | 0.000093 | 112640/160678 | 1.0697 | 2.2549 |\n",
      "val: {'recall': 0.985593, 'recall_grapheme': 0.979819, 'recall_vowel': 0.991219, 'recall_consonant': 0.991513, 'acc_grapheme': 0.97896, 'acc_vowel': 0.993402, 'acc_consonant': 0.992231, 'loss_grapheme': 0.124938, 'loss_vowel': 0.090383, 'loss_consonant': 0.077108}\n",
      "   61 | 0.000098 | 054784/160678 | 1.6986 | 2.3163 |\n",
      "val: {'recall': 0.985727, 'recall_grapheme': 0.980157, 'recall_vowel': 0.991544, 'recall_consonant': 0.991049, 'acc_grapheme': 0.97901, 'acc_vowel': 0.993327, 'acc_consonant': 0.992306, 'loss_grapheme': 0.136849, 'loss_vowel': 0.10185, 'loss_consonant': 0.079953}\n",
      "   61 | 0.000100 | 157184/160678 | 2.2649 | 2.2036 |\n",
      "val: {'recall': 0.984904, 'recall_grapheme': 0.979107, 'recall_vowel': 0.991614, 'recall_consonant': 0.989788, 'acc_grapheme': 0.978562, 'acc_vowel': 0.993551, 'acc_consonant': 0.992207, 'loss_grapheme': 0.135903, 'loss_vowel': 0.094989, 'loss_consonant': 0.079173}\n",
      "   62 | 0.000098 | 099328/160678 | 2.0015 | 2.2212 |\n",
      "val: {'recall': 0.984968, 'recall_grapheme': 0.978423, 'recall_vowel': 0.991457, 'recall_consonant': 0.991569, 'acc_grapheme': 0.978612, 'acc_vowel': 0.993277, 'acc_consonant': 0.992431, 'loss_grapheme': 0.129868, 'loss_vowel': 0.095231, 'loss_consonant': 0.078688}\n",
      "   63 | 0.000093 | 041472/160678 | 1.9757 | 2.1091 |\n",
      "val: {'recall': 0.985156, 'recall_grapheme': 0.979116, 'recall_vowel': 0.991497, 'recall_consonant': 0.990895, 'acc_grapheme': 0.978238, 'acc_vowel': 0.993501, 'acc_consonant': 0.992356, 'loss_grapheme': 0.13546, 'loss_vowel': 0.089061, 'loss_consonant': 0.078081}\n",
      "   63 | 0.000086 | 143872/160678 | 2.6069 | 2.2309 |\n",
      "val: {'recall': 0.985736, 'recall_grapheme': 0.980118, 'recall_vowel': 0.991722, 'recall_consonant': 0.990986, 'acc_grapheme': 0.979359, 'acc_vowel': 0.993551, 'acc_consonant': 0.992779, 'loss_grapheme': 0.129518, 'loss_vowel': 0.086775, 'loss_consonant': 0.074523}\n",
      "   64 | 0.000075 | 086016/160678 | 4.2414 | 2.3380 |\n",
      "val: {'recall': 0.985568, 'recall_grapheme': 0.979522, 'recall_vowel': 0.991589, 'recall_consonant': 0.991638, 'acc_grapheme': 0.978686, 'acc_vowel': 0.993302, 'acc_consonant': 0.992505, 'loss_grapheme': 0.134285, 'loss_vowel': 0.092012, 'loss_consonant': 0.078921}\n",
      "   65 | 0.000063 | 028160/160678 | 1.4073 | 2.2932 |\n",
      "val: {'recall': 0.9861, 'recall_grapheme': 0.980561, 'recall_vowel': 0.991985, 'recall_consonant': 0.991291, 'acc_grapheme': 0.979334, 'acc_vowel': 0.99375, 'acc_consonant': 0.99258, 'loss_grapheme': 0.134411, 'loss_vowel': 0.094433, 'loss_consonant': 0.082004}\n",
      "** saved\n",
      "   65 | 0.000051 | 130560/160678 | 2.0570 | 2.1578 |\n",
      "val: {'recall': 0.986081, 'recall_grapheme': 0.980408, 'recall_vowel': 0.992062, 'recall_consonant': 0.991445, 'acc_grapheme': 0.979508, 'acc_vowel': 0.9938, 'acc_consonant': 0.992729, 'loss_grapheme': 0.120967, 'loss_vowel': 0.077139, 'loss_consonant': 0.069759}\n",
      "   66 | 0.000038 | 072704/160678 | 1.0513 | 2.0648 |\n",
      "val: {'recall': 0.986301, 'recall_grapheme': 0.981216, 'recall_vowel': 0.992014, 'recall_consonant': 0.99076, 'acc_grapheme': 0.979906, 'acc_vowel': 0.993725, 'acc_consonant': 0.992505, 'loss_grapheme': 0.114028, 'loss_vowel': 0.071676, 'loss_consonant': 0.065625}\n",
      "** saved\n",
      "   67 | 0.000026 | 014848/160678 | 0.8134 | 2.4125 |\n",
      "val: {'recall': 0.986111, 'recall_grapheme': 0.980677, 'recall_vowel': 0.991844, 'recall_consonant': 0.991246, 'acc_grapheme': 0.979732, 'acc_vowel': 0.993725, 'acc_consonant': 0.992505, 'loss_grapheme': 0.125123, 'loss_vowel': 0.087697, 'loss_consonant': 0.076609}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 0.000015 | 117248/160678 | 1.5119 | 2.2508 |\n",
      "val: {'recall': 0.986385, 'recall_grapheme': 0.980441, 'recall_vowel': 0.992114, 'recall_consonant': 0.992543, 'acc_grapheme': 0.979359, 'acc_vowel': 0.993875, 'acc_consonant': 0.992779, 'loss_grapheme': 0.123924, 'loss_vowel': 0.081958, 'loss_consonant': 0.074836}\n",
      "** saved\n",
      "   68 | 0.000008 | 059392/160678 | 3.8897 | 2.1341 |\n",
      "val: {'recall': 0.985991, 'recall_grapheme': 0.980429, 'recall_vowel': 0.992289, 'recall_consonant': 0.990816, 'acc_grapheme': 0.979483, 'acc_vowel': 0.9939, 'acc_consonant': 0.992605, 'loss_grapheme': 0.118697, 'loss_vowel': 0.079302, 'loss_consonant': 0.071134}\n",
      "   69 | 0.000003 | 001536/160678 | 0.9043 | 3.0253 |\n",
      "val: {'recall': 0.986294, 'recall_grapheme': 0.980866, 'recall_vowel': 0.992004, 'recall_consonant': 0.991439, 'acc_grapheme': 0.979857, 'acc_vowel': 0.9939, 'acc_consonant': 0.992754, 'loss_grapheme': 0.128473, 'loss_vowel': 0.089759, 'loss_consonant': 0.079451}\n",
      "   69 | 0.000001 | 103936/160678 | 1.4022 | 2.2339 |\n",
      "val: {'recall': 0.985973, 'recall_grapheme': 0.980393, 'recall_vowel': 0.992053, 'recall_consonant': 0.991054, 'acc_grapheme': 0.979433, 'acc_vowel': 0.99385, 'acc_consonant': 0.99268, 'loss_grapheme': 0.119345, 'loss_vowel': 0.079014, 'loss_consonant': 0.072704}\n",
      "   70 | 0.000003 | 046080/160678 | 3.3917 | 2.2599 |\n",
      "val: {'recall': 0.986156, 'recall_grapheme': 0.980767, 'recall_vowel': 0.992047, 'recall_consonant': 0.991044, 'acc_grapheme': 0.979608, 'acc_vowel': 0.993825, 'acc_consonant': 0.99268, 'loss_grapheme': 0.120365, 'loss_vowel': 0.081155, 'loss_consonant': 0.073874}\n",
      "   70 | 0.000008 | 148480/160678 | 1.3200 | 2.2306 |\n",
      "val: {'recall': 0.986232, 'recall_grapheme': 0.980667, 'recall_vowel': 0.99208, 'recall_consonant': 0.991512, 'acc_grapheme': 0.979682, 'acc_vowel': 0.99385, 'acc_consonant': 0.992705, 'loss_grapheme': 0.119831, 'loss_vowel': 0.080771, 'loss_consonant': 0.072674}\n",
      "   71 | 0.000015 | 090624/160678 | 1.7486 | 2.1623 |\n",
      "val: {'recall': 0.98631, 'recall_grapheme': 0.98054, 'recall_vowel': 0.992021, 'recall_consonant': 0.992137, 'acc_grapheme': 0.979931, 'acc_vowel': 0.993974, 'acc_consonant': 0.992879, 'loss_grapheme': 0.117636, 'loss_vowel': 0.079035, 'loss_consonant': 0.070335}\n",
      "   72 | 0.000026 | 032768/160678 | 3.4193 | 2.2807 |\n",
      "val: {'recall': 0.986259, 'recall_grapheme': 0.980838, 'recall_vowel': 0.991934, 'recall_consonant': 0.991425, 'acc_grapheme': 0.979956, 'acc_vowel': 0.99375, 'acc_consonant': 0.992854, 'loss_grapheme': 0.124075, 'loss_vowel': 0.084188, 'loss_consonant': 0.073533}\n",
      "   72 | 0.000038 | 135168/160678 | 4.3219 | 2.2565 |\n",
      "val: {'recall': 0.986333, 'recall_grapheme': 0.981045, 'recall_vowel': 0.992122, 'recall_consonant': 0.991119, 'acc_grapheme': 0.980155, 'acc_vowel': 0.993925, 'acc_consonant': 0.992904, 'loss_grapheme': 0.129807, 'loss_vowel': 0.088744, 'loss_consonant': 0.078285}\n",
      "   73 | 0.000050 | 077312/160678 | 1.9953 | 2.2006 |\n",
      "val: {'recall': 0.986352, 'recall_grapheme': 0.980858, 'recall_vowel': 0.992481, 'recall_consonant': 0.991213, 'acc_grapheme': 0.980355, 'acc_vowel': 0.993974, 'acc_consonant': 0.992829, 'loss_grapheme': 0.11968, 'loss_vowel': 0.085964, 'loss_consonant': 0.072469}\n",
      "   74 | 0.000063 | 019456/160678 | 3.4081 | 2.4529 |\n",
      "val: {'recall': 0.985486, 'recall_grapheme': 0.979738, 'recall_vowel': 0.991464, 'recall_consonant': 0.991003, 'acc_grapheme': 0.979458, 'acc_vowel': 0.993452, 'acc_consonant': 0.992729, 'loss_grapheme': 0.125538, 'loss_vowel': 0.08415, 'loss_consonant': 0.075214}\n",
      "   74 | 0.000075 | 121856/160678 | 3.2407 | 2.2758 |\n",
      "val: {'recall': 0.986303, 'recall_grapheme': 0.981142, 'recall_vowel': 0.991924, 'recall_consonant': 0.991003, 'acc_grapheme': 0.979632, 'acc_vowel': 0.993775, 'acc_consonant': 0.992779, 'loss_grapheme': 0.129239, 'loss_vowel': 0.084227, 'loss_consonant': 0.07708}\n",
      "   75 | 0.000086 | 064000/160678 | 1.6195 | 2.1342 |\n",
      "val: {'recall': 0.986186, 'recall_grapheme': 0.980663, 'recall_vowel': 0.991845, 'recall_consonant': 0.991571, 'acc_grapheme': 0.980628, 'acc_vowel': 0.993725, 'acc_consonant': 0.992904, 'loss_grapheme': 0.112438, 'loss_vowel': 0.071314, 'loss_consonant': 0.065742}\n",
      "   76 | 0.000093 | 006144/160678 | 1.0095 | 2.0000 |\n",
      "val: {'recall': 0.985581, 'recall_grapheme': 0.979653, 'recall_vowel': 0.991353, 'recall_consonant': 0.991664, 'acc_grapheme': 0.979159, 'acc_vowel': 0.993576, 'acc_consonant': 0.99258, 'loss_grapheme': 0.118262, 'loss_vowel': 0.072175, 'loss_consonant': 0.069142}\n",
      "   76 | 0.000098 | 108544/160678 | 3.0068 | 2.1001 |\n",
      "val: {'recall': 0.986186, 'recall_grapheme': 0.980847, 'recall_vowel': 0.991779, 'recall_consonant': 0.991271, 'acc_grapheme': 0.979159, 'acc_vowel': 0.993476, 'acc_consonant': 0.992381, 'loss_grapheme': 0.123228, 'loss_vowel': 0.075991, 'loss_consonant': 0.068476}\n",
      "   77 | 0.000100 | 050688/160678 | 2.1135 | 2.2474 |\n",
      "val: {'recall': 0.986428, 'recall_grapheme': 0.981331, 'recall_vowel': 0.992014, 'recall_consonant': 0.991038, 'acc_grapheme': 0.979981, 'acc_vowel': 0.993775, 'acc_consonant': 0.99268, 'loss_grapheme': 0.118445, 'loss_vowel': 0.066439, 'loss_consonant': 0.06597}\n",
      "** saved\n",
      "   77 | 0.000098 | 153088/160678 | 1.9725 | 2.3084 |\n",
      "val: {'recall': 0.98577, 'recall_grapheme': 0.979887, 'recall_vowel': 0.99143, 'recall_consonant': 0.991879, 'acc_grapheme': 0.978811, 'acc_vowel': 0.993377, 'acc_consonant': 0.992356, 'loss_grapheme': 0.125811, 'loss_vowel': 0.076764, 'loss_consonant': 0.073452}\n",
      "   78 | 0.000093 | 095232/160678 | 2.2313 | 2.2114 |\n",
      "val: {'recall': 0.985508, 'recall_grapheme': 0.979928, 'recall_vowel': 0.991444, 'recall_consonant': 0.990731, 'acc_grapheme': 0.978935, 'acc_vowel': 0.993452, 'acc_consonant': 0.99253, 'loss_grapheme': 0.120385, 'loss_vowel': 0.071838, 'loss_consonant': 0.066514}\n",
      "   79 | 0.000086 | 037376/160678 | 2.2965 | 1.9402 |\n",
      "val: {'recall': 0.986291, 'recall_grapheme': 0.981078, 'recall_vowel': 0.992218, 'recall_consonant': 0.990792, 'acc_grapheme': 0.980205, 'acc_vowel': 0.9939, 'acc_consonant': 0.992879, 'loss_grapheme': 0.115647, 'loss_vowel': 0.075616, 'loss_consonant': 0.064432}\n",
      "   79 | 0.000075 | 139776/160678 | 3.6029 | 2.1194 |\n",
      "val: {'recall': 0.986711, 'recall_grapheme': 0.981326, 'recall_vowel': 0.992079, 'recall_consonant': 0.992113, 'acc_grapheme': 0.979807, 'acc_vowel': 0.99375, 'acc_consonant': 0.993078, 'loss_grapheme': 0.114382, 'loss_vowel': 0.068803, 'loss_consonant': 0.064505}\n",
      "** saved\n",
      "   80 | 0.000063 | 081920/160678 | 1.6986 | 2.2360 |\n",
      "val: {'recall': 0.986318, 'recall_grapheme': 0.98069, 'recall_vowel': 0.991938, 'recall_consonant': 0.991956, 'acc_grapheme': 0.980056, 'acc_vowel': 0.993476, 'acc_consonant': 0.992904, 'loss_grapheme': 0.119998, 'loss_vowel': 0.07831, 'loss_consonant': 0.070762}\n",
      "   81 | 0.000050 | 024064/160678 | 3.6132 | 2.3177 |\n",
      "val: {'recall': 0.986955, 'recall_grapheme': 0.981652, 'recall_vowel': 0.992043, 'recall_consonant': 0.992471, 'acc_grapheme': 0.980454, 'acc_vowel': 0.99385, 'acc_consonant': 0.993003, 'loss_grapheme': 0.126933, 'loss_vowel': 0.083352, 'loss_consonant': 0.075598}\n",
      "** saved\n",
      "   81 | 0.000038 | 126464/160678 | 2.8172 | 2.3725 |\n",
      "val: {'recall': 0.986687, 'recall_grapheme': 0.98113, 'recall_vowel': 0.991915, 'recall_consonant': 0.992574, 'acc_grapheme': 0.980429, 'acc_vowel': 0.99375, 'acc_consonant': 0.992804, 'loss_grapheme': 0.116719, 'loss_vowel': 0.067006, 'loss_consonant': 0.067845}\n",
      "   82 | 0.000026 | 068608/160678 | 1.3347 | 2.2789 |\n",
      "val: {'recall': 0.986993, 'recall_grapheme': 0.981937, 'recall_vowel': 0.991916, 'recall_consonant': 0.992181, 'acc_grapheme': 0.980927, 'acc_vowel': 0.993875, 'acc_consonant': 0.992904, 'loss_grapheme': 0.115208, 'loss_vowel': 0.070516, 'loss_consonant': 0.067483}\n",
      "** saved\n",
      "   83 | 0.000015 | 010752/160678 | 1.7250 | 2.3052 |\n",
      "val: {'recall': 0.987101, 'recall_grapheme': 0.981823, 'recall_vowel': 0.992165, 'recall_consonant': 0.992595, 'acc_grapheme': 0.980952, 'acc_vowel': 0.993925, 'acc_consonant': 0.993153, 'loss_grapheme': 0.105133, 'loss_vowel': 0.061217, 'loss_consonant': 0.059849}\n",
      "** saved\n",
      "   83 | 0.000008 | 113152/160678 | 2.9900 | 2.0569 |\n",
      "val: {'recall': 0.987211, 'recall_grapheme': 0.981978, 'recall_vowel': 0.992309, 'recall_consonant': 0.992577, 'acc_grapheme': 0.981002, 'acc_vowel': 0.993999, 'acc_consonant': 0.992978, 'loss_grapheme': 0.102183, 'loss_vowel': 0.057516, 'loss_consonant': 0.056677}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   84 | 0.000003 | 055296/160678 | 2.9789 | 2.0887 |\n",
      "val: {'recall': 0.986909, 'recall_grapheme': 0.981669, 'recall_vowel': 0.992307, 'recall_consonant': 0.991991, 'acc_grapheme': 0.981002, 'acc_vowel': 0.993875, 'acc_consonant': 0.993003, 'loss_grapheme': 0.101106, 'loss_vowel': 0.056224, 'loss_consonant': 0.056271}\n",
      "   84 | 0.000001 | 157696/160678 | 0.4382 | 2.1363 |\n",
      "val: {'recall': 0.987353, 'recall_grapheme': 0.982409, 'recall_vowel': 0.992569, 'recall_consonant': 0.992023, 'acc_grapheme': 0.981151, 'acc_vowel': 0.994049, 'acc_consonant': 0.992929, 'loss_grapheme': 0.111583, 'loss_vowel': 0.069706, 'loss_consonant': 0.063832}\n",
      "** saved\n",
      "   85 | 0.000003 | 099840/160678 | 3.3070 | 2.2258 |\n",
      "val: {'recall': 0.987046, 'recall_grapheme': 0.981916, 'recall_vowel': 0.992387, 'recall_consonant': 0.991963, 'acc_grapheme': 0.980927, 'acc_vowel': 0.99395, 'acc_consonant': 0.992954, 'loss_grapheme': 0.111342, 'loss_vowel': 0.066183, 'loss_consonant': 0.064928}\n",
      "   86 | 0.000008 | 041984/160678 | 3.4245 | 2.1044 |\n",
      "val: {'recall': 0.987242, 'recall_grapheme': 0.982152, 'recall_vowel': 0.992493, 'recall_consonant': 0.99217, 'acc_grapheme': 0.981151, 'acc_vowel': 0.994074, 'acc_consonant': 0.992978, 'loss_grapheme': 0.104576, 'loss_vowel': 0.060379, 'loss_consonant': 0.059206}\n",
      "   86 | 0.000015 | 144384/160678 | 4.0352 | 2.1746 |\n",
      "val: {'recall': 0.986838, 'recall_grapheme': 0.981457, 'recall_vowel': 0.992457, 'recall_consonant': 0.991979, 'acc_grapheme': 0.980678, 'acc_vowel': 0.993974, 'acc_consonant': 0.993028, 'loss_grapheme': 0.106844, 'loss_vowel': 0.063734, 'loss_consonant': 0.0616}\n",
      "   87 | 0.000026 | 086528/160678 | 2.6171 | 2.2159 |\n",
      "val: {'recall': 0.987283, 'recall_grapheme': 0.982409, 'recall_vowel': 0.992457, 'recall_consonant': 0.991858, 'acc_grapheme': 0.981027, 'acc_vowel': 0.994074, 'acc_consonant': 0.993103, 'loss_grapheme': 0.10778, 'loss_vowel': 0.061307, 'loss_consonant': 0.062407}\n",
      "   88 | 0.000038 | 028672/160678 | 0.7756 | 2.3763 |\n",
      "val: {'recall': 0.987093, 'recall_grapheme': 0.98216, 'recall_vowel': 0.992288, 'recall_consonant': 0.991764, 'acc_grapheme': 0.980977, 'acc_vowel': 0.99395, 'acc_consonant': 0.992829, 'loss_grapheme': 0.103973, 'loss_vowel': 0.059593, 'loss_consonant': 0.060448}\n",
      "   88 | 0.000050 | 131072/160678 | 3.5545 | 2.3107 |\n",
      "val: {'recall': 0.98715, 'recall_grapheme': 0.982289, 'recall_vowel': 0.992418, 'recall_consonant': 0.991604, 'acc_grapheme': 0.981226, 'acc_vowel': 0.9938, 'acc_consonant': 0.992779, 'loss_grapheme': 0.107889, 'loss_vowel': 0.062738, 'loss_consonant': 0.06252}\n",
      "   89 | 0.000063 | 073216/160678 | 4.0642 | 2.0730 |\n",
      "val: {'recall': 0.986297, 'recall_grapheme': 0.980814, 'recall_vowel': 0.991966, 'recall_consonant': 0.991596, 'acc_grapheme': 0.980379, 'acc_vowel': 0.993626, 'acc_consonant': 0.992978, 'loss_grapheme': 0.102546, 'loss_vowel': 0.057331, 'loss_consonant': 0.058906}\n",
      "   90 | 0.000075 | 015360/160678 | 1.4427 | 2.0182 |\n",
      "val: {'recall': 0.985989, 'recall_grapheme': 0.979734, 'recall_vowel': 0.99195, 'recall_consonant': 0.992538, 'acc_grapheme': 0.979383, 'acc_vowel': 0.993651, 'acc_consonant': 0.992505, 'loss_grapheme': 0.106079, 'loss_vowel': 0.059242, 'loss_consonant': 0.056795}\n",
      "   90 | 0.000086 | 117760/160678 | 2.6334 | 2.0893 |\n",
      "val: {'recall': 0.986278, 'recall_grapheme': 0.980183, 'recall_vowel': 0.992101, 'recall_consonant': 0.992644, 'acc_grapheme': 0.98033, 'acc_vowel': 0.993626, 'acc_consonant': 0.992555, 'loss_grapheme': 0.102558, 'loss_vowel': 0.058045, 'loss_consonant': 0.057368}\n",
      "   91 | 0.000093 | 059904/160678 | 1.9447 | 2.2632 |\n",
      "val: {'recall': 0.986169, 'recall_grapheme': 0.980663, 'recall_vowel': 0.991737, 'recall_consonant': 0.991612, 'acc_grapheme': 0.98018, 'acc_vowel': 0.993651, 'acc_consonant': 0.992754, 'loss_grapheme': 0.107007, 'loss_vowel': 0.058411, 'loss_consonant': 0.061515}\n",
      "   92 | 0.000098 | 002048/160678 | 2.0143 | 2.1536 |\n",
      "val: {'recall': 0.98659, 'recall_grapheme': 0.981347, 'recall_vowel': 0.991514, 'recall_consonant': 0.992149, 'acc_grapheme': 0.979981, 'acc_vowel': 0.993825, 'acc_consonant': 0.992954, 'loss_grapheme': 0.103023, 'loss_vowel': 0.0573, 'loss_consonant': 0.057045}\n",
      "   92 | 0.000100 | 104448/160678 | 3.6223 | 2.2372 |\n",
      "val: {'recall': 0.986225, 'recall_grapheme': 0.980702, 'recall_vowel': 0.991886, 'recall_consonant': 0.991608, 'acc_grapheme': 0.979832, 'acc_vowel': 0.9938, 'acc_consonant': 0.992854, 'loss_grapheme': 0.101658, 'loss_vowel': 0.055299, 'loss_consonant': 0.055829}\n",
      "   93 | 0.000098 | 046592/160678 | 0.2562 | 2.1423 |\n",
      "val: {'recall': 0.986034, 'recall_grapheme': 0.980721, 'recall_vowel': 0.991312, 'recall_consonant': 0.991381, 'acc_grapheme': 0.980056, 'acc_vowel': 0.993676, 'acc_consonant': 0.992829, 'loss_grapheme': 0.103253, 'loss_vowel': 0.052419, 'loss_consonant': 0.05492}\n",
      "   93 | 0.000093 | 148992/160678 | 1.9036 | 2.1574 |\n",
      "val: {'recall': 0.986365, 'recall_grapheme': 0.981281, 'recall_vowel': 0.992096, 'recall_consonant': 0.9908, 'acc_grapheme': 0.98028, 'acc_vowel': 0.99385, 'acc_consonant': 0.992978, 'loss_grapheme': 0.099559, 'loss_vowel': 0.051877, 'loss_consonant': 0.054872}\n",
      "   94 | 0.000086 | 091136/160678 | 3.0995 | 2.0846 |\n",
      "val: {'recall': 0.986479, 'recall_grapheme': 0.981084, 'recall_vowel': 0.991996, 'recall_consonant': 0.991753, 'acc_grapheme': 0.980753, 'acc_vowel': 0.993676, 'acc_consonant': 0.992978, 'loss_grapheme': 0.101042, 'loss_vowel': 0.052714, 'loss_consonant': 0.056197}\n",
      "   95 | 0.000075 | 033280/160678 | 1.3146 | 2.2856 |\n",
      "val: {'recall': 0.98585, 'recall_grapheme': 0.980482, 'recall_vowel': 0.991377, 'recall_consonant': 0.991058, 'acc_grapheme': 0.98013, 'acc_vowel': 0.993626, 'acc_consonant': 0.992854, 'loss_grapheme': 0.099378, 'loss_vowel': 0.053462, 'loss_consonant': 0.054929}\n",
      "   95 | 0.000063 | 135680/160678 | 1.8870 | 2.1593 |\n",
      "val: {'recall': 0.986427, 'recall_grapheme': 0.982019, 'recall_vowel': 0.991893, 'recall_consonant': 0.989776, 'acc_grapheme': 0.980828, 'acc_vowel': 0.993601, 'acc_consonant': 0.992655, 'loss_grapheme': 0.09852, 'loss_vowel': 0.052723, 'loss_consonant': 0.055354}\n",
      "   96 | 0.000050 | 077824/160678 | 3.1938 | 2.2718 |\n",
      "val: {'recall': 0.986771, 'recall_grapheme': 0.98157, 'recall_vowel': 0.991813, 'recall_consonant': 0.992133, 'acc_grapheme': 0.980554, 'acc_vowel': 0.993576, 'acc_consonant': 0.993203, 'loss_grapheme': 0.098141, 'loss_vowel': 0.049102, 'loss_consonant': 0.052967}\n",
      "   97 | 0.000038 | 019968/160678 | 0.3704 | 2.1432 |\n",
      "val: {'recall': 0.986492, 'recall_grapheme': 0.981379, 'recall_vowel': 0.991942, 'recall_consonant': 0.991266, 'acc_grapheme': 0.980728, 'acc_vowel': 0.993875, 'acc_consonant': 0.993003, 'loss_grapheme': 0.090536, 'loss_vowel': 0.046961, 'loss_consonant': 0.048409}\n",
      "   97 | 0.000026 | 122368/160678 | 1.9410 | 2.2116 |\n",
      "val: {'recall': 0.987287, 'recall_grapheme': 0.982323, 'recall_vowel': 0.992405, 'recall_consonant': 0.992097, 'acc_grapheme': 0.981027, 'acc_vowel': 0.994049, 'acc_consonant': 0.993003, 'loss_grapheme': 0.099098, 'loss_vowel': 0.05462, 'loss_consonant': 0.054849}\n",
      "   98 | 0.000015 | 064512/160678 | 1.4455 | 2.1353 |\n",
      "val: {'recall': 0.986699, 'recall_grapheme': 0.981447, 'recall_vowel': 0.992139, 'recall_consonant': 0.991763, 'acc_grapheme': 0.981102, 'acc_vowel': 0.993925, 'acc_consonant': 0.993053, 'loss_grapheme': 0.094781, 'loss_vowel': 0.051471, 'loss_consonant': 0.051885}\n",
      "   99 | 0.000008 | 006656/160678 | 2.6197 | 2.0730 |\n",
      "val: {'recall': 0.987006, 'recall_grapheme': 0.982086, 'recall_vowel': 0.991908, 'recall_consonant': 0.991945, 'acc_grapheme': 0.981475, 'acc_vowel': 0.993825, 'acc_consonant': 0.993252, 'loss_grapheme': 0.089267, 'loss_vowel': 0.045722, 'loss_consonant': 0.046754}\n",
      "   99 | 0.000003 | 109056/160678 | 2.7521 | 2.1531 |\n",
      "val: {'recall': 0.986862, 'recall_grapheme': 0.982056, 'recall_vowel': 0.991851, 'recall_consonant': 0.991483, 'acc_grapheme': 0.981151, 'acc_vowel': 0.9938, 'acc_consonant': 0.993103, 'loss_grapheme': 0.09474, 'loss_vowel': 0.051131, 'loss_consonant': 0.052072}\n",
      "  100 | 0.000001 | 051200/160678 | 1.8690 | 2.0345 |\n",
      "val: {'recall': 0.986973, 'recall_grapheme': 0.982094, 'recall_vowel': 0.99217, 'recall_consonant': 0.991532, 'acc_grapheme': 0.98145, 'acc_vowel': 0.9939, 'acc_consonant': 0.993327, 'loss_grapheme': 0.092042, 'loss_vowel': 0.049045, 'loss_consonant': 0.048676}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 | 0.000003 | 153600/160678 | 4.0812 | 2.1984 |\n",
      "val: {'recall': 0.987027, 'recall_grapheme': 0.982086, 'recall_vowel': 0.992296, 'recall_consonant': 0.991642, 'acc_grapheme': 0.981351, 'acc_vowel': 0.99395, 'acc_consonant': 0.993178, 'loss_grapheme': 0.096477, 'loss_vowel': 0.053106, 'loss_consonant': 0.053384}\n",
      "  101 | 0.000008 | 095744/160678 | 2.4905 | 2.1333 |\n",
      "val: {'recall': 0.986739, 'recall_grapheme': 0.981932, 'recall_vowel': 0.991962, 'recall_consonant': 0.99113, 'acc_grapheme': 0.981425, 'acc_vowel': 0.993875, 'acc_consonant': 0.993128, 'loss_grapheme': 0.090146, 'loss_vowel': 0.04565, 'loss_consonant': 0.047584}\n",
      "  102 | 0.000015 | 037888/160678 | 1.9988 | 2.2417 |\n",
      "val: {'recall': 0.986958, 'recall_grapheme': 0.982412, 'recall_vowel': 0.991738, 'recall_consonant': 0.991271, 'acc_grapheme': 0.981201, 'acc_vowel': 0.993825, 'acc_consonant': 0.993153, 'loss_grapheme': 0.093644, 'loss_vowel': 0.04946, 'loss_consonant': 0.051053}\n",
      "  102 | 0.000026 | 140288/160678 | 1.7892 | 2.1610 |\n",
      "val: {'recall': 0.986748, 'recall_grapheme': 0.981829, 'recall_vowel': 0.991771, 'recall_consonant': 0.991562, 'acc_grapheme': 0.980778, 'acc_vowel': 0.993925, 'acc_consonant': 0.993028, 'loss_grapheme': 0.09384, 'loss_vowel': 0.04816, 'loss_consonant': 0.050882}\n",
      "  103 | 0.000038 | 082432/160678 | 0.6679 | 1.9995 |\n",
      "val: {'recall': 0.986801, 'recall_grapheme': 0.981681, 'recall_vowel': 0.992456, 'recall_consonant': 0.991386, 'acc_grapheme': 0.981002, 'acc_vowel': 0.99395, 'acc_consonant': 0.993252, 'loss_grapheme': 0.093019, 'loss_vowel': 0.051914, 'loss_consonant': 0.048851}\n",
      "  104 | 0.000050 | 024576/160678 | 0.1137 | 2.2542 |\n",
      "val: {'recall': 0.986716, 'recall_grapheme': 0.982084, 'recall_vowel': 0.991858, 'recall_consonant': 0.990838, 'acc_grapheme': 0.980828, 'acc_vowel': 0.993825, 'acc_consonant': 0.992929, 'loss_grapheme': 0.0862, 'loss_vowel': 0.043372, 'loss_consonant': 0.0445}\n",
      "  104 | 0.000063 | 126976/160678 | 1.2687 | 2.1861 |\n",
      "val: {'recall': 0.986787, 'recall_grapheme': 0.981336, 'recall_vowel': 0.992023, 'recall_consonant': 0.992455, 'acc_grapheme': 0.98033, 'acc_vowel': 0.993875, 'acc_consonant': 0.993078, 'loss_grapheme': 0.090622, 'loss_vowel': 0.043397, 'loss_consonant': 0.04654}\n",
      "  105 | 0.000075 | 069120/160678 | 3.9334 | 2.1305 |\n",
      "val: {'recall': 0.987137, 'recall_grapheme': 0.982317, 'recall_vowel': 0.992777, 'recall_consonant': 0.991138, 'acc_grapheme': 0.981699, 'acc_vowel': 0.994174, 'acc_consonant': 0.993203, 'loss_grapheme': 0.099189, 'loss_vowel': 0.056303, 'loss_consonant': 0.051987}\n",
      "  106 | 0.000086 | 011264/160678 | 2.2367 | 1.9881 |\n",
      "val: {'recall': 0.987587, 'recall_grapheme': 0.982909, 'recall_vowel': 0.992258, 'recall_consonant': 0.992271, 'acc_grapheme': 0.981898, 'acc_vowel': 0.993676, 'acc_consonant': 0.993053, 'loss_grapheme': 0.092755, 'loss_vowel': 0.051715, 'loss_consonant': 0.050916}\n",
      "** saved\n",
      "  106 | 0.000093 | 113664/160678 | 2.6615 | 2.1881 |\n",
      "val: {'recall': 0.986073, 'recall_grapheme': 0.979728, 'recall_vowel': 0.992067, 'recall_consonant': 0.992769, 'acc_grapheme': 0.980155, 'acc_vowel': 0.99385, 'acc_consonant': 0.99268, 'loss_grapheme': 0.090773, 'loss_vowel': 0.044826, 'loss_consonant': 0.047738}\n",
      "  107 | 0.000098 | 055808/160678 | 0.9386 | 2.1727 |\n",
      "val: {'recall': 0.986376, 'recall_grapheme': 0.981402, 'recall_vowel': 0.992005, 'recall_consonant': 0.990695, 'acc_grapheme': 0.980429, 'acc_vowel': 0.99395, 'acc_consonant': 0.993178, 'loss_grapheme': 0.091841, 'loss_vowel': 0.043314, 'loss_consonant': 0.048289}\n",
      "  107 | 0.000100 | 158208/160678 | 3.6452 | 2.1979 |\n",
      "val: {'recall': 0.986365, 'recall_grapheme': 0.981691, 'recall_vowel': 0.991546, 'recall_consonant': 0.99053, 'acc_grapheme': 0.980031, 'acc_vowel': 0.993526, 'acc_consonant': 0.99248, 'loss_grapheme': 0.104717, 'loss_vowel': 0.055798, 'loss_consonant': 0.053073}\n",
      "  108 | 0.000098 | 100352/160678 | 1.9206 | 2.1160 |\n",
      "val: {'recall': 0.986619, 'recall_grapheme': 0.981767, 'recall_vowel': 0.991743, 'recall_consonant': 0.991199, 'acc_grapheme': 0.980927, 'acc_vowel': 0.99385, 'acc_consonant': 0.992729, 'loss_grapheme': 0.094675, 'loss_vowel': 0.044991, 'loss_consonant': 0.045748}\n",
      "  109 | 0.000093 | 042496/160678 | 2.0462 | 2.0493 |\n",
      "val: {'recall': 0.987165, 'recall_grapheme': 0.982184, 'recall_vowel': 0.991926, 'recall_consonant': 0.992367, 'acc_grapheme': 0.980753, 'acc_vowel': 0.993775, 'acc_consonant': 0.992829, 'loss_grapheme': 0.086871, 'loss_vowel': 0.040281, 'loss_consonant': 0.042053}\n",
      "  109 | 0.000086 | 144896/160678 | 0.9452 | 2.1263 |\n",
      "val: {'recall': 0.986954, 'recall_grapheme': 0.981762, 'recall_vowel': 0.992563, 'recall_consonant': 0.991728, 'acc_grapheme': 0.980877, 'acc_vowel': 0.994223, 'acc_consonant': 0.993302, 'loss_grapheme': 0.089018, 'loss_vowel': 0.043506, 'loss_consonant': 0.044368}\n",
      "  110 | 0.000075 | 087040/160678 | 1.9699 | 2.1869 |\n",
      "val: {'recall': 0.986692, 'recall_grapheme': 0.981886, 'recall_vowel': 0.991677, 'recall_consonant': 0.99132, 'acc_grapheme': 0.980877, 'acc_vowel': 0.993875, 'acc_consonant': 0.993128, 'loss_grapheme': 0.088787, 'loss_vowel': 0.041119, 'loss_consonant': 0.043061}\n",
      "  111 | 0.000063 | 029184/160678 | 0.4637 | 1.9548 |\n",
      "val: {'recall': 0.987178, 'recall_grapheme': 0.981311, 'recall_vowel': 0.992727, 'recall_consonant': 0.993362, 'acc_grapheme': 0.980579, 'acc_vowel': 0.994099, 'acc_consonant': 0.993128, 'loss_grapheme': 0.085456, 'loss_vowel': 0.038731, 'loss_consonant': 0.040061}\n",
      "  111 | 0.000051 | 131584/160678 | 3.1425 | 2.0576 |\n",
      "val: {'recall': 0.988103, 'recall_grapheme': 0.983077, 'recall_vowel': 0.992297, 'recall_consonant': 0.993959, 'acc_grapheme': 0.9816, 'acc_vowel': 0.993925, 'acc_consonant': 0.993526, 'loss_grapheme': 0.091019, 'loss_vowel': 0.046282, 'loss_consonant': 0.044954}\n",
      "** saved\n",
      "  112 | 0.000038 | 073728/160678 | 3.8043 | 2.0947 |\n",
      "val: {'recall': 0.98801, 'recall_grapheme': 0.982952, 'recall_vowel': 0.992272, 'recall_consonant': 0.993865, 'acc_grapheme': 0.981799, 'acc_vowel': 0.994024, 'acc_consonant': 0.993452, 'loss_grapheme': 0.086691, 'loss_vowel': 0.041913, 'loss_consonant': 0.042716}\n",
      "  113 | 0.000026 | 015872/160678 | 0.7511 | 1.5810 |\n",
      "val: {'recall': 0.987563, 'recall_grapheme': 0.982512, 'recall_vowel': 0.99226, 'recall_consonant': 0.992967, 'acc_grapheme': 0.981525, 'acc_vowel': 0.99395, 'acc_consonant': 0.993402, 'loss_grapheme': 0.084281, 'loss_vowel': 0.039643, 'loss_consonant': 0.039846}\n",
      "  113 | 0.000015 | 118272/160678 | 2.3394 | 2.1244 |\n",
      "val: {'recall': 0.987823, 'recall_grapheme': 0.983228, 'recall_vowel': 0.992127, 'recall_consonant': 0.99271, 'acc_grapheme': 0.981724, 'acc_vowel': 0.993974, 'acc_consonant': 0.993377, 'loss_grapheme': 0.085818, 'loss_vowel': 0.041413, 'loss_consonant': 0.042456}\n",
      "  114 | 0.000008 | 060416/160678 | 4.0324 | 2.1056 |\n",
      "val: {'recall': 0.987553, 'recall_grapheme': 0.983, 'recall_vowel': 0.991976, 'recall_consonant': 0.992235, 'acc_grapheme': 0.981699, 'acc_vowel': 0.99395, 'acc_consonant': 0.993203, 'loss_grapheme': 0.083301, 'loss_vowel': 0.037561, 'loss_consonant': 0.039061}\n",
      "  115 | 0.000003 | 002560/160678 | 0.4906 | 1.6610 |\n",
      "val: {'recall': 0.987712, 'recall_grapheme': 0.983089, 'recall_vowel': 0.991999, 'recall_consonant': 0.992669, 'acc_grapheme': 0.981849, 'acc_vowel': 0.99395, 'acc_consonant': 0.993501, 'loss_grapheme': 0.084645, 'loss_vowel': 0.039441, 'loss_consonant': 0.040724}\n",
      "  115 | 0.000001 | 104960/160678 | 2.1226 | 1.9448 |\n",
      "val: {'recall': 0.987372, 'recall_grapheme': 0.982574, 'recall_vowel': 0.991911, 'recall_consonant': 0.992428, 'acc_grapheme': 0.9814, 'acc_vowel': 0.993875, 'acc_consonant': 0.993476, 'loss_grapheme': 0.082147, 'loss_vowel': 0.036832, 'loss_consonant': 0.037767}\n",
      "  116 | 0.000003 | 047104/160678 | 3.2527 | 2.3586 |\n",
      "val: {'recall': 0.987454, 'recall_grapheme': 0.98268, 'recall_vowel': 0.991754, 'recall_consonant': 0.992703, 'acc_grapheme': 0.981774, 'acc_vowel': 0.9939, 'acc_consonant': 0.993526, 'loss_grapheme': 0.084534, 'loss_vowel': 0.039214, 'loss_consonant': 0.04122}\n",
      "  116 | 0.000008 | 149504/160678 | 2.9972 | 2.2148 |\n",
      "val: {'recall': 0.986975, 'recall_grapheme': 0.982254, 'recall_vowel': 0.991972, 'recall_consonant': 0.991419, 'acc_grapheme': 0.981475, 'acc_vowel': 0.993974, 'acc_consonant': 0.993377, 'loss_grapheme': 0.085407, 'loss_vowel': 0.03987, 'loss_consonant': 0.041094}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  117 | 0.000015 | 091648/160678 | 1.8658 | 2.0752 |\n",
      "val: {'recall': 0.987171, 'recall_grapheme': 0.982778, 'recall_vowel': 0.992007, 'recall_consonant': 0.991121, 'acc_grapheme': 0.981724, 'acc_vowel': 0.993974, 'acc_consonant': 0.993128, 'loss_grapheme': 0.081713, 'loss_vowel': 0.036795, 'loss_consonant': 0.038026}\n",
      "  118 | 0.000026 | 033792/160678 | 2.0477 | 2.1255 |\n",
      "val: {'recall': 0.987485, 'recall_grapheme': 0.983092, 'recall_vowel': 0.992382, 'recall_consonant': 0.991372, 'acc_grapheme': 0.981948, 'acc_vowel': 0.993974, 'acc_consonant': 0.993551, 'loss_grapheme': 0.082686, 'loss_vowel': 0.038439, 'loss_consonant': 0.039308}\n",
      "  118 | 0.000038 | 136192/160678 | 1.8875 | 2.1460 |\n",
      "val: {'recall': 0.987293, 'recall_grapheme': 0.982672, 'recall_vowel': 0.992106, 'recall_consonant': 0.991722, 'acc_grapheme': 0.981724, 'acc_vowel': 0.993925, 'acc_consonant': 0.993252, 'loss_grapheme': 0.087775, 'loss_vowel': 0.04228, 'loss_consonant': 0.042987}\n",
      "  119 | 0.000050 | 078336/160678 | 3.0339 | 2.0333 |\n",
      "val: {'recall': 0.987207, 'recall_grapheme': 0.982273, 'recall_vowel': 0.992398, 'recall_consonant': 0.991885, 'acc_grapheme': 0.981375, 'acc_vowel': 0.994024, 'acc_consonant': 0.993626, 'loss_grapheme': 0.085785, 'loss_vowel': 0.039371, 'loss_consonant': 0.040513}\n",
      "  120 | 0.000063 | 020480/160678 | 3.8406 | 1.8471 |\n",
      "val: {'recall': 0.987284, 'recall_grapheme': 0.982039, 'recall_vowel': 0.992276, 'recall_consonant': 0.992782, 'acc_grapheme': 0.9815, 'acc_vowel': 0.994049, 'acc_consonant': 0.993725, 'loss_grapheme': 0.087925, 'loss_vowel': 0.044207, 'loss_consonant': 0.042731}\n",
      "  120 | 0.000075 | 122880/160678 | 4.2446 | 2.1091 |\n",
      "val: {'recall': 0.986999, 'recall_grapheme': 0.981433, 'recall_vowel': 0.992519, 'recall_consonant': 0.992612, 'acc_grapheme': 0.98145, 'acc_vowel': 0.994223, 'acc_consonant': 0.993501, 'loss_grapheme': 0.085568, 'loss_vowel': 0.041523, 'loss_consonant': 0.042388}\n",
      "  121 | 0.000086 | 065024/160678 | 1.8343 | 2.1312 |\n",
      "val: {'recall': 0.986986, 'recall_grapheme': 0.982054, 'recall_vowel': 0.991992, 'recall_consonant': 0.991845, 'acc_grapheme': 0.98155, 'acc_vowel': 0.994024, 'acc_consonant': 0.993277, 'loss_grapheme': 0.088871, 'loss_vowel': 0.043929, 'loss_consonant': 0.04403}\n",
      "  122 | 0.000093 | 007168/160678 | 1.7841 | 2.4245 |\n",
      "val: {'recall': 0.98669, 'recall_grapheme': 0.981843, 'recall_vowel': 0.99219, 'recall_consonant': 0.990883, 'acc_grapheme': 0.981425, 'acc_vowel': 0.99385, 'acc_consonant': 0.993377, 'loss_grapheme': 0.08161, 'loss_vowel': 0.036979, 'loss_consonant': 0.037777}\n",
      "  122 | 0.000098 | 109568/160678 | 1.7654 | 2.0411 |\n",
      "val: {'recall': 0.986481, 'recall_grapheme': 0.980162, 'recall_vowel': 0.99255, 'recall_consonant': 0.993051, 'acc_grapheme': 0.980554, 'acc_vowel': 0.994174, 'acc_consonant': 0.993252, 'loss_grapheme': 0.087144, 'loss_vowel': 0.038792, 'loss_consonant': 0.039131}\n",
      "  123 | 0.000100 | 051712/160678 | 1.6004 | 2.1599 |\n",
      "val: {'recall': 0.987707, 'recall_grapheme': 0.982383, 'recall_vowel': 0.992687, 'recall_consonant': 0.993376, 'acc_grapheme': 0.9816, 'acc_vowel': 0.994149, 'acc_consonant': 0.993551, 'loss_grapheme': 0.090228, 'loss_vowel': 0.046275, 'loss_consonant': 0.042999}\n",
      "  123 | 0.000098 | 154112/160678 | 2.8610 | 2.0537 |\n",
      "val: {'recall': 0.986889, 'recall_grapheme': 0.981428, 'recall_vowel': 0.992647, 'recall_consonant': 0.992054, 'acc_grapheme': 0.981475, 'acc_vowel': 0.994099, 'acc_consonant': 0.993153, 'loss_grapheme': 0.086545, 'loss_vowel': 0.041715, 'loss_consonant': 0.04162}\n",
      "  124 | 0.000093 | 096256/160678 | 2.3955 | 2.1057 |\n",
      "val: {'recall': 0.986528, 'recall_grapheme': 0.981196, 'recall_vowel': 0.992029, 'recall_consonant': 0.99169, 'acc_grapheme': 0.981027, 'acc_vowel': 0.993974, 'acc_consonant': 0.993377, 'loss_grapheme': 0.08572, 'loss_vowel': 0.03971, 'loss_consonant': 0.039073}\n",
      "  125 | 0.000086 | 038400/160678 | 2.7553 | 2.0765 |\n",
      "val: {'recall': 0.98718, 'recall_grapheme': 0.982306, 'recall_vowel': 0.992497, 'recall_consonant': 0.991612, 'acc_grapheme': 0.981898, 'acc_vowel': 0.994273, 'acc_consonant': 0.993452, 'loss_grapheme': 0.085501, 'loss_vowel': 0.04056, 'loss_consonant': 0.040013}\n",
      "  125 | 0.000075 | 140800/160678 | 3.1644 | 2.1277 |\n",
      "val: {'recall': 0.987027, 'recall_grapheme': 0.982035, 'recall_vowel': 0.992134, 'recall_consonant': 0.991904, 'acc_grapheme': 0.9815, 'acc_vowel': 0.994049, 'acc_consonant': 0.993178, 'loss_grapheme': 0.087237, 'loss_vowel': 0.043935, 'loss_consonant': 0.043577}\n",
      "  126 | 0.000063 | 082944/160678 | 2.1816 | 2.0999 |\n",
      "val: {'recall': 0.986784, 'recall_grapheme': 0.982227, 'recall_vowel': 0.991687, 'recall_consonant': 0.990994, 'acc_grapheme': 0.981799, 'acc_vowel': 0.993825, 'acc_consonant': 0.993302, 'loss_grapheme': 0.080912, 'loss_vowel': 0.035627, 'loss_consonant': 0.035053}\n",
      "  127 | 0.000051 | 025088/160678 | 3.6687 | 2.1817 |\n",
      "val: {'recall': 0.987101, 'recall_grapheme': 0.982245, 'recall_vowel': 0.991918, 'recall_consonant': 0.991993, 'acc_grapheme': 0.981624, 'acc_vowel': 0.993974, 'acc_consonant': 0.993277, 'loss_grapheme': 0.084017, 'loss_vowel': 0.039374, 'loss_consonant': 0.038453}\n",
      "  127 | 0.000038 | 127488/160678 | 3.5949 | 2.1180 |\n",
      "val: {'recall': 0.98723, 'recall_grapheme': 0.982664, 'recall_vowel': 0.992569, 'recall_consonant': 0.991023, 'acc_grapheme': 0.981948, 'acc_vowel': 0.994348, 'acc_consonant': 0.993352, 'loss_grapheme': 0.080373, 'loss_vowel': 0.036186, 'loss_consonant': 0.035888}\n",
      "  128 | 0.000026 | 069632/160678 | 2.1978 | 1.9928 |\n",
      "val: {'recall': 0.987757, 'recall_grapheme': 0.983852, 'recall_vowel': 0.992279, 'recall_consonant': 0.991046, 'acc_grapheme': 0.982595, 'acc_vowel': 0.994174, 'acc_consonant': 0.993377, 'loss_grapheme': 0.079358, 'loss_vowel': 0.035363, 'loss_consonant': 0.035325}\n",
      "  129 | 0.000015 | 011776/160678 | 3.7332 | 1.7641 |\n",
      "val: {'recall': 0.987299, 'recall_grapheme': 0.982773, 'recall_vowel': 0.9922, 'recall_consonant': 0.991449, 'acc_grapheme': 0.982346, 'acc_vowel': 0.994223, 'acc_consonant': 0.993476, 'loss_grapheme': 0.080062, 'loss_vowel': 0.036794, 'loss_consonant': 0.035333}\n",
      "  129 | 0.000008 | 114176/160678 | 2.3153 | 2.0845 |\n",
      "val: {'recall': 0.987722, 'recall_grapheme': 0.983503, 'recall_vowel': 0.992198, 'recall_consonant': 0.991684, 'acc_grapheme': 0.98262, 'acc_vowel': 0.994149, 'acc_consonant': 0.993626, 'loss_grapheme': 0.080658, 'loss_vowel': 0.037586, 'loss_consonant': 0.036798}\n",
      "  130 | 0.000003 | 056320/160678 | 4.3789 | 2.1243 |\n",
      "val: {'recall': 0.987342, 'recall_grapheme': 0.982978, 'recall_vowel': 0.992395, 'recall_consonant': 0.991017, 'acc_grapheme': 0.982322, 'acc_vowel': 0.994248, 'acc_consonant': 0.993427, 'loss_grapheme': 0.080383, 'loss_vowel': 0.03667, 'loss_consonant': 0.036136}\n",
      "  130 | 0.000001 | 158720/160678 | 0.8630 | 2.0068 |\n",
      "val: {'recall': 0.987692, 'recall_grapheme': 0.983272, 'recall_vowel': 0.992318, 'recall_consonant': 0.991905, 'acc_grapheme': 0.982695, 'acc_vowel': 0.994099, 'acc_consonant': 0.993701, 'loss_grapheme': 0.080096, 'loss_vowel': 0.037477, 'loss_consonant': 0.035835}\n",
      "  131 | 0.000003 | 100864/160678 | 3.1849 | 2.1152 |\n",
      "val: {'recall': 0.987539, 'recall_grapheme': 0.983156, 'recall_vowel': 0.99231, 'recall_consonant': 0.991534, 'acc_grapheme': 0.982297, 'acc_vowel': 0.994174, 'acc_consonant': 0.993551, 'loss_grapheme': 0.076562, 'loss_vowel': 0.032448, 'loss_consonant': 0.032368}\n",
      "  132 | 0.000008 | 043008/160678 | 0.8222 | 2.0414 |\n",
      "val: {'recall': 0.987455, 'recall_grapheme': 0.982929, 'recall_vowel': 0.992357, 'recall_consonant': 0.991605, 'acc_grapheme': 0.982222, 'acc_vowel': 0.994248, 'acc_consonant': 0.993501, 'loss_grapheme': 0.079477, 'loss_vowel': 0.035741, 'loss_consonant': 0.03491}\n",
      "  132 | 0.000015 | 145408/160678 | 1.7596 | 2.1411 |\n",
      "val: {'recall': 0.987455, 'recall_grapheme': 0.982886, 'recall_vowel': 0.992175, 'recall_consonant': 0.991873, 'acc_grapheme': 0.982297, 'acc_vowel': 0.994174, 'acc_consonant': 0.993402, 'loss_grapheme': 0.078954, 'loss_vowel': 0.034033, 'loss_consonant': 0.034041}\n",
      "  133 | 0.000026 | 087552/160678 | 1.8210 | 2.1412 |\n",
      "val: {'recall': 0.987892, 'recall_grapheme': 0.983378, 'recall_vowel': 0.992514, 'recall_consonant': 0.992297, 'acc_grapheme': 0.982471, 'acc_vowel': 0.994273, 'acc_consonant': 0.993676, 'loss_grapheme': 0.077384, 'loss_vowel': 0.034391, 'loss_consonant': 0.033912}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  134 | 0.000038 | 029696/160678 | 4.0381 | 2.1550 |\n",
      "val: {'recall': 0.988071, 'recall_grapheme': 0.983689, 'recall_vowel': 0.992547, 'recall_consonant': 0.992359, 'acc_grapheme': 0.982546, 'acc_vowel': 0.994099, 'acc_consonant': 0.993576, 'loss_grapheme': 0.078805, 'loss_vowel': 0.036621, 'loss_consonant': 0.035895}\n",
      "  134 | 0.000051 | 132096/160678 | 4.1580 | 2.0846 |\n",
      "val: {'recall': 0.987577, 'recall_grapheme': 0.98293, 'recall_vowel': 0.992483, 'recall_consonant': 0.991964, 'acc_grapheme': 0.98277, 'acc_vowel': 0.994223, 'acc_consonant': 0.993576, 'loss_grapheme': 0.07869, 'loss_vowel': 0.03665, 'loss_consonant': 0.036304}\n",
      "  135 | 0.000063 | 074240/160678 | 1.9431 | 2.0436 |\n",
      "val: {'recall': 0.987482, 'recall_grapheme': 0.983351, 'recall_vowel': 0.99225, 'recall_consonant': 0.990975, 'acc_grapheme': 0.982371, 'acc_vowel': 0.993974, 'acc_consonant': 0.993302, 'loss_grapheme': 0.078803, 'loss_vowel': 0.036645, 'loss_consonant': 0.034531}\n",
      "  136 | 0.000075 | 016384/160678 | 2.1622 | 2.2439 |\n",
      "val: {'recall': 0.987808, 'recall_grapheme': 0.98376, 'recall_vowel': 0.992877, 'recall_consonant': 0.990837, 'acc_grapheme': 0.98277, 'acc_vowel': 0.994273, 'acc_consonant': 0.993725, 'loss_grapheme': 0.081365, 'loss_vowel': 0.043807, 'loss_consonant': 0.03915}\n",
      "  136 | 0.000086 | 118784/160678 | 1.3563 | 2.2469 |\n",
      "val: {'recall': 0.987251, 'recall_grapheme': 0.981688, 'recall_vowel': 0.99247, 'recall_consonant': 0.993156, 'acc_grapheme': 0.981674, 'acc_vowel': 0.994348, 'acc_consonant': 0.993725, 'loss_grapheme': 0.084224, 'loss_vowel': 0.04171, 'loss_consonant': 0.039397}\n",
      "  137 | 0.000093 | 060928/160678 | 1.8412 | 2.1612 |\n",
      "val: {'recall': 0.987695, 'recall_grapheme': 0.982784, 'recall_vowel': 0.993158, 'recall_consonant': 0.992056, 'acc_grapheme': 0.982272, 'acc_vowel': 0.994248, 'acc_consonant': 0.99385, 'loss_grapheme': 0.080821, 'loss_vowel': 0.036704, 'loss_consonant': 0.036853}\n",
      "  138 | 0.000098 | 003072/160678 | 3.0298 | 2.3132 |\n",
      "val: {'recall': 0.988022, 'recall_grapheme': 0.984159, 'recall_vowel': 0.992212, 'recall_consonant': 0.991557, 'acc_grapheme': 0.982795, 'acc_vowel': 0.993974, 'acc_consonant': 0.9938, 'loss_grapheme': 0.080363, 'loss_vowel': 0.040071, 'loss_consonant': 0.036793}\n",
      "  138 | 0.000100 | 105472/160678 | 1.7647 | 2.0690 |\n",
      "val: {'recall': 0.987476, 'recall_grapheme': 0.983131, 'recall_vowel': 0.992054, 'recall_consonant': 0.991586, 'acc_grapheme': 0.982695, 'acc_vowel': 0.994124, 'acc_consonant': 0.993476, 'loss_grapheme': 0.076293, 'loss_vowel': 0.034973, 'loss_consonant': 0.032565}\n",
      "  139 | 0.000098 | 047616/160678 | 1.6415 | 2.1374 |\n",
      "val: {'recall': 0.986599, 'recall_grapheme': 0.981401, 'recall_vowel': 0.992451, 'recall_consonant': 0.991144, 'acc_grapheme': 0.981002, 'acc_vowel': 0.994049, 'acc_consonant': 0.993302, 'loss_grapheme': 0.083015, 'loss_vowel': 0.040148, 'loss_consonant': 0.036842}\n",
      "  139 | 0.000093 | 150016/160678 | 0.8172 | 2.1364 |\n",
      "val: {'recall': 0.986794, 'recall_grapheme': 0.98159, 'recall_vowel': 0.992235, 'recall_consonant': 0.99176, 'acc_grapheme': 0.982073, 'acc_vowel': 0.993925, 'acc_consonant': 0.993551, 'loss_grapheme': 0.081365, 'loss_vowel': 0.040103, 'loss_consonant': 0.035988}\n",
      "  140 | 0.000086 | 092160/160678 | 1.6999 | 2.1448 |\n",
      "val: {'recall': 0.987299, 'recall_grapheme': 0.982465, 'recall_vowel': 0.992178, 'recall_consonant': 0.992089, 'acc_grapheme': 0.981799, 'acc_vowel': 0.993974, 'acc_consonant': 0.993551, 'loss_grapheme': 0.079167, 'loss_vowel': 0.036335, 'loss_consonant': 0.034088}\n",
      "  141 | 0.000075 | 034304/160678 | 2.7226 | 1.8449 |\n",
      "val: {'recall': 0.987568, 'recall_grapheme': 0.983151, 'recall_vowel': 0.992178, 'recall_consonant': 0.991792, 'acc_grapheme': 0.981624, 'acc_vowel': 0.9938, 'acc_consonant': 0.993701, 'loss_grapheme': 0.079453, 'loss_vowel': 0.034965, 'loss_consonant': 0.033045}\n",
      "  141 | 0.000063 | 136704/160678 | 1.7577 | 1.9988 |\n",
      "val: {'recall': 0.987856, 'recall_grapheme': 0.983208, 'recall_vowel': 0.992498, 'recall_consonant': 0.992511, 'acc_grapheme': 0.982371, 'acc_vowel': 0.994149, 'acc_consonant': 0.993676, 'loss_grapheme': 0.08067, 'loss_vowel': 0.036765, 'loss_consonant': 0.035496}\n",
      "  142 | 0.000051 | 078848/160678 | 2.0103 | 2.0786 |\n",
      "val: {'recall': 0.987483, 'recall_grapheme': 0.983223, 'recall_vowel': 0.992386, 'recall_consonant': 0.991099, 'acc_grapheme': 0.982844, 'acc_vowel': 0.994198, 'acc_consonant': 0.993452, 'loss_grapheme': 0.07669, 'loss_vowel': 0.032656, 'loss_consonant': 0.030616}\n",
      "  143 | 0.000038 | 020992/160678 | 1.6745 | 2.5512 |\n",
      "val: {'recall': 0.987932, 'recall_grapheme': 0.983769, 'recall_vowel': 0.992427, 'recall_consonant': 0.991764, 'acc_grapheme': 0.982595, 'acc_vowel': 0.994223, 'acc_consonant': 0.993626, 'loss_grapheme': 0.075848, 'loss_vowel': 0.03253, 'loss_consonant': 0.031256}\n",
      "  143 | 0.000026 | 123392/160678 | 1.5826 | 2.2239 |\n",
      "val: {'recall': 0.988028, 'recall_grapheme': 0.983535, 'recall_vowel': 0.992574, 'recall_consonant': 0.992467, 'acc_grapheme': 0.982571, 'acc_vowel': 0.994223, 'acc_consonant': 0.9938, 'loss_grapheme': 0.082054, 'loss_vowel': 0.039157, 'loss_consonant': 0.035723}\n",
      "  144 | 0.000015 | 065536/160678 | 0.8920 | 2.0661 |\n",
      "val: {'recall': 0.988087, 'recall_grapheme': 0.983899, 'recall_vowel': 0.99285, 'recall_consonant': 0.991699, 'acc_grapheme': 0.983342, 'acc_vowel': 0.994273, 'acc_consonant': 0.993825, 'loss_grapheme': 0.07642, 'loss_vowel': 0.034758, 'loss_consonant': 0.032179}\n",
      "  145 | 0.000008 | 007680/160678 | 2.4082 | 1.9880 |\n",
      "val: {'recall': 0.987805, 'recall_grapheme': 0.983398, 'recall_vowel': 0.992847, 'recall_consonant': 0.991576, 'acc_grapheme': 0.983019, 'acc_vowel': 0.994298, 'acc_consonant': 0.993725, 'loss_grapheme': 0.075801, 'loss_vowel': 0.033652, 'loss_consonant': 0.030958}\n",
      "  145 | 0.000003 | 110080/160678 | 1.2190 | 2.1362 |\n",
      "val: {'recall': 0.987814, 'recall_grapheme': 0.983364, 'recall_vowel': 0.992884, 'recall_consonant': 0.991644, 'acc_grapheme': 0.98282, 'acc_vowel': 0.994373, 'acc_consonant': 0.99385, 'loss_grapheme': 0.075235, 'loss_vowel': 0.033106, 'loss_consonant': 0.030604}\n",
      "  146 | 0.000001 | 052224/160678 | 1.2629 | 2.1356 |\n",
      "val: {'recall': 0.987915, 'recall_grapheme': 0.983558, 'recall_vowel': 0.992854, 'recall_consonant': 0.991689, 'acc_grapheme': 0.982944, 'acc_vowel': 0.994323, 'acc_consonant': 0.99385, 'loss_grapheme': 0.07523, 'loss_vowel': 0.033436, 'loss_consonant': 0.030833}\n",
      "  146 | 0.000003 | 154624/160678 | 1.9821 | 2.1236 |\n",
      "val: {'recall': 0.987916, 'recall_grapheme': 0.983627, 'recall_vowel': 0.992844, 'recall_consonant': 0.991564, 'acc_grapheme': 0.983069, 'acc_vowel': 0.994323, 'acc_consonant': 0.9938, 'loss_grapheme': 0.074424, 'loss_vowel': 0.032725, 'loss_consonant': 0.030149}\n",
      "  147 | 0.000008 | 096768/160678 | 1.9899 | 2.1386 |\n",
      "val: {'recall': 0.988025, 'recall_grapheme': 0.983707, 'recall_vowel': 0.992861, 'recall_consonant': 0.991825, 'acc_grapheme': 0.982944, 'acc_vowel': 0.994348, 'acc_consonant': 0.993925, 'loss_grapheme': 0.075788, 'loss_vowel': 0.034127, 'loss_consonant': 0.031419}\n",
      "  148 | 0.000015 | 038912/160678 | 2.0527 | 2.1220 |\n",
      "val: {'recall': 0.98796, 'recall_grapheme': 0.984032, 'recall_vowel': 0.992516, 'recall_consonant': 0.991262, 'acc_grapheme': 0.983044, 'acc_vowel': 0.994248, 'acc_consonant': 0.9938, 'loss_grapheme': 0.07339, 'loss_vowel': 0.03157, 'loss_consonant': 0.029055}\n",
      "  148 | 0.000026 | 141312/160678 | 1.0086 | 2.1450 |\n",
      "val: {'recall': 0.987755, 'recall_grapheme': 0.983197, 'recall_vowel': 0.992198, 'recall_consonant': 0.992429, 'acc_grapheme': 0.982919, 'acc_vowel': 0.994099, 'acc_consonant': 0.9939, 'loss_grapheme': 0.07557, 'loss_vowel': 0.032748, 'loss_consonant': 0.030123}\n",
      "  149 | 0.000038 | 083456/160678 | 3.1259 | 2.0537 |\n",
      "val: {'recall': 0.987655, 'recall_grapheme': 0.982814, 'recall_vowel': 0.992641, 'recall_consonant': 0.992348, 'acc_grapheme': 0.982994, 'acc_vowel': 0.994248, 'acc_consonant': 0.994024, 'loss_grapheme': 0.075532, 'loss_vowel': 0.033913, 'loss_consonant': 0.031137}\n",
      "  150 | 0.000050 | 025600/160678 | 1.9508 | 2.4435 |\n",
      "val: {'recall': 0.987867, 'recall_grapheme': 0.983172, 'recall_vowel': 0.992605, 'recall_consonant': 0.99252, 'acc_grapheme': 0.98262, 'acc_vowel': 0.994149, 'acc_consonant': 0.99395, 'loss_grapheme': 0.076872, 'loss_vowel': 0.035299, 'loss_consonant': 0.032464}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  150 | 0.000063 | 128000/160678 | 0.8950 | 2.1408 |\n",
      "val: {'recall': 0.988174, 'recall_grapheme': 0.984081, 'recall_vowel': 0.992518, 'recall_consonant': 0.992017, 'acc_grapheme': 0.982795, 'acc_vowel': 0.994149, 'acc_consonant': 0.9939, 'loss_grapheme': 0.076678, 'loss_vowel': 0.035728, 'loss_consonant': 0.032817}\n",
      "** saved\n",
      "  151 | 0.000075 | 070144/160678 | 1.5744 | 2.2191 |\n",
      "val: {'recall': 0.98813, 'recall_grapheme': 0.983324, 'recall_vowel': 0.992771, 'recall_consonant': 0.993102, 'acc_grapheme': 0.982496, 'acc_vowel': 0.994273, 'acc_consonant': 0.993925, 'loss_grapheme': 0.07754, 'loss_vowel': 0.034452, 'loss_consonant': 0.032111}\n",
      "  152 | 0.000086 | 012288/160678 | 0.3801 | 2.0123 |\n",
      "val: {'recall': 0.98752, 'recall_grapheme': 0.982945, 'recall_vowel': 0.99299, 'recall_consonant': 0.9912, 'acc_grapheme': 0.982247, 'acc_vowel': 0.994398, 'acc_consonant': 0.993825, 'loss_grapheme': 0.07706, 'loss_vowel': 0.035688, 'loss_consonant': 0.0327}\n",
      "  152 | 0.000093 | 114688/160678 | 1.8573 | 2.0058 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-813ae6dcb078>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;31m#print('train:', train_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;31m#save_model(model, model_file+'_latest')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0e344cb1f778>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.055809, 'recall_grapheme': 0.002094, 'recall_vowel': 0.082583, 'recall_consonant': 0.136466, 'acc_grapheme': 0.004756, 'acc_vowel': 0.062123, 'acc_consonant': 0.30372, 'loss_grapheme': 5.147646, 'loss_vowel': 2.432934, 'loss_consonant': 1.875116}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.001000 | 102400/160678 | 4.3291 | 5.1119 |\n",
      "val: {'recall': 0.921762, 'recall_grapheme': 0.88298, 'recall_vowel': 0.956336, 'recall_consonant': 0.964751, 'acc_grapheme': 0.860615, 'acc_vowel': 0.940367, 'acc_consonant': 0.948284, 'loss_grapheme': 0.89797, 'loss_vowel': 0.407851, 'loss_consonant': 0.264921}\n",
      "** saved\n",
      "    1 | 0.001000 | 044544/160678 | 3.7370 | 3.7624 |\n",
      "val: {'recall': 0.94627, 'recall_grapheme': 0.920104, 'recall_vowel': 0.971516, 'recall_consonant': 0.973355, 'acc_grapheme': 0.910637, 'acc_vowel': 0.968154, 'acc_consonant': 0.964071, 'loss_grapheme': 0.673879, 'loss_vowel': 0.235241, 'loss_consonant': 0.180345}\n",
      "** saved\n",
      "    1 | 0.001000 | 146944/160678 | 3.8561 | 3.5787 |\n",
      "val: {'recall': 0.957307, 'recall_grapheme': 0.93805, 'recall_vowel': 0.973764, 'recall_consonant': 0.979362, 'acc_grapheme': 0.926871, 'acc_vowel': 0.965739, 'acc_consonant': 0.968129, 'loss_grapheme': 0.570661, 'loss_vowel': 0.316512, 'loss_consonant': 0.214272}\n",
      "** saved\n",
      "    2 | 0.001000 | 089088/160678 | 1.4590 | 3.5254 |\n",
      "val: {'recall': 0.9516, 'recall_grapheme': 0.933051, 'recall_vowel': 0.960802, 'recall_consonant': 0.979495, 'acc_grapheme': 0.915343, 'acc_vowel': 0.92585, 'acc_consonant': 0.972113, 'loss_grapheme': 0.608745, 'loss_vowel': 0.420628, 'loss_consonant': 0.180169}\n",
      "    3 | 0.001000 | 031232/160678 | 5.5236 | 3.6621 |\n",
      "val: {'recall': 0.960347, 'recall_grapheme': 0.939374, 'recall_vowel': 0.979814, 'recall_consonant': 0.982827, 'acc_grapheme': 0.940267, 'acc_vowel': 0.980877, 'acc_consonant': 0.970619, 'loss_grapheme': 0.56647, 'loss_vowel': 0.318652, 'loss_consonant': 0.232374}\n",
      "** saved\n",
      "    3 | 0.001000 | 133632/160678 | 2.4453 | 3.4317 |\n",
      "val: {'recall': 0.967989, 'recall_grapheme': 0.952625, 'recall_vowel': 0.984732, 'recall_consonant': 0.981976, 'acc_grapheme': 0.947986, 'acc_vowel': 0.985011, 'acc_consonant': 0.983268, 'loss_grapheme': 0.415989, 'loss_vowel': 0.214679, 'loss_consonant': 0.158145}\n",
      "** saved\n",
      "    4 | 0.001000 | 075776/160678 | 4.2450 | 3.2046 |\n",
      "val: {'recall': 0.968351, 'recall_grapheme': 0.95449, 'recall_vowel': 0.980667, 'recall_consonant': 0.983756, 'acc_grapheme': 0.95177, 'acc_vowel': 0.985658, 'acc_consonant': 0.981948, 'loss_grapheme': 0.383849, 'loss_vowel': 0.199833, 'loss_consonant': 0.13789}\n",
      "** saved\n",
      "    5 | 0.001000 | 017920/160678 | 2.2340 | 3.0839 |\n",
      "val: {'recall': 0.971564, 'recall_grapheme': 0.957721, 'recall_vowel': 0.987413, 'recall_consonant': 0.983403, 'acc_grapheme': 0.952368, 'acc_vowel': 0.986604, 'acc_consonant': 0.984836, 'loss_grapheme': 0.430072, 'loss_vowel': 0.250308, 'loss_consonant': 0.160094}\n",
      "** saved\n",
      "    5 | 0.001000 | 120320/160678 | 2.0048 | 3.0173 |\n",
      "val: {'recall': 0.969778, 'recall_grapheme': 0.953824, 'recall_vowel': 0.985859, 'recall_consonant': 0.985603, 'acc_grapheme': 0.950749, 'acc_vowel': 0.985807, 'acc_consonant': 0.983766, 'loss_grapheme': 0.355885, 'loss_vowel': 0.216163, 'loss_consonant': 0.146471}\n",
      "    6 | 0.001000 | 062464/160678 | 1.7618 | 2.9654 |\n",
      "val: {'recall': 0.971035, 'recall_grapheme': 0.958211, 'recall_vowel': 0.98102, 'recall_consonant': 0.986699, 'acc_grapheme': 0.948509, 'acc_vowel': 0.98521, 'acc_consonant': 0.979433, 'loss_grapheme': 0.369651, 'loss_vowel': 0.232786, 'loss_consonant': 0.16532}\n",
      "    7 | 0.001000 | 004608/160678 | 3.1571 | 2.8616 |\n",
      "val: {'recall': 0.973777, 'recall_grapheme': 0.962525, 'recall_vowel': 0.986141, 'recall_consonant': 0.983917, 'acc_grapheme': 0.961705, 'acc_vowel': 0.987127, 'acc_consonant': 0.986405, 'loss_grapheme': 0.341696, 'loss_vowel': 0.17041, 'loss_consonant': 0.130498}\n",
      "** saved\n",
      "    7 | 0.001000 | 107008/160678 | 2.7208 | 2.8947 |\n",
      "val: {'recall': 0.972355, 'recall_grapheme': 0.959357, 'recall_vowel': 0.985272, 'recall_consonant': 0.985434, 'acc_grapheme': 0.95441, 'acc_vowel': 0.987675, 'acc_consonant': 0.987401, 'loss_grapheme': 0.328374, 'loss_vowel': 0.191096, 'loss_consonant': 0.132593}\n",
      "    8 | 0.001000 | 049152/160678 | 2.9817 | 2.8341 |\n",
      "val: {'recall': 0.974381, 'recall_grapheme': 0.961771, 'recall_vowel': 0.986424, 'recall_consonant': 0.987557, 'acc_grapheme': 0.961879, 'acc_vowel': 0.986579, 'acc_consonant': 0.985235, 'loss_grapheme': 0.402518, 'loss_vowel': 0.250391, 'loss_consonant': 0.161449}\n",
      "** saved\n",
      "    8 | 0.001000 | 151552/160678 | 4.7319 | 2.7896 |\n",
      "val: {'recall': 0.974482, 'recall_grapheme': 0.963512, 'recall_vowel': 0.986122, 'recall_consonant': 0.984781, 'acc_grapheme': 0.96056, 'acc_vowel': 0.987824, 'acc_consonant': 0.985807, 'loss_grapheme': 0.27378, 'loss_vowel': 0.205459, 'loss_consonant': 0.138053}\n",
      "** saved\n",
      "    9 | 0.001000 | 093696/160678 | 4.6581 | 2.8589 |\n",
      "val: {'recall': 0.973174, 'recall_grapheme': 0.961964, 'recall_vowel': 0.987869, 'recall_consonant': 0.9809, 'acc_grapheme': 0.959489, 'acc_vowel': 0.988795, 'acc_consonant': 0.986903, 'loss_grapheme': 0.300725, 'loss_vowel': 0.221791, 'loss_consonant': 0.137321}\n",
      "   10 | 0.001000 | 035840/160678 | 1.9566 | 2.7999 |\n",
      "val: {'recall': 0.977199, 'recall_grapheme': 0.966181, 'recall_vowel': 0.988074, 'recall_consonant': 0.988358, 'acc_grapheme': 0.962153, 'acc_vowel': 0.988895, 'acc_consonant': 0.984587, 'loss_grapheme': 0.271158, 'loss_vowel': 0.193955, 'loss_consonant': 0.134146}\n",
      "** saved\n",
      "   10 | 0.001000 | 138240/160678 | 1.2988 | 2.7164 |\n",
      "val: {'recall': 0.975423, 'recall_grapheme': 0.965267, 'recall_vowel': 0.987925, 'recall_consonant': 0.983231, 'acc_grapheme': 0.964768, 'acc_vowel': 0.989791, 'acc_consonant': 0.987052, 'loss_grapheme': 0.231069, 'loss_vowel': 0.150264, 'loss_consonant': 0.116806}\n",
      "   11 | 0.001000 | 080384/160678 | 0.9395 | 2.7553 |\n",
      "val: {'recall': 0.976303, 'recall_grapheme': 0.965272, 'recall_vowel': 0.988091, 'recall_consonant': 0.986576, 'acc_grapheme': 0.96041, 'acc_vowel': 0.988646, 'acc_consonant': 0.985658, 'loss_grapheme': 0.256266, 'loss_vowel': 0.165553, 'loss_consonant': 0.129207}\n",
      "   12 | 0.001000 | 022528/160678 | 1.0138 | 2.3344 |\n",
      "val: {'recall': 0.976188, 'recall_grapheme': 0.965015, 'recall_vowel': 0.986347, 'recall_consonant': 0.988377, 'acc_grapheme': 0.96539, 'acc_vowel': 0.988696, 'acc_consonant': 0.9877, 'loss_grapheme': 0.232301, 'loss_vowel': 0.12875, 'loss_consonant': 0.099826}\n",
      "   12 | 0.000100 | 124928/160678 | 1.1043 | 2.5778 |\n",
      "val: {'recall': 0.981707, 'recall_grapheme': 0.974492, 'recall_vowel': 0.989828, 'recall_consonant': 0.988017, 'acc_grapheme': 0.972711, 'acc_vowel': 0.991186, 'acc_consonant': 0.989567, 'loss_grapheme': 0.222853, 'loss_vowel': 0.174605, 'loss_consonant': 0.115222}\n",
      "** saved\n",
      "   13 | 0.000100 | 067072/160678 | 1.9827 | 2.5429 |\n",
      "val: {'recall': 0.981864, 'recall_grapheme': 0.973508, 'recall_vowel': 0.990829, 'recall_consonant': 0.989613, 'acc_grapheme': 0.972885, 'acc_vowel': 0.991758, 'acc_consonant': 0.989816, 'loss_grapheme': 0.200803, 'loss_vowel': 0.149642, 'loss_consonant': 0.108543}\n",
      "** saved\n",
      "   14 | 0.000100 | 009216/160678 | 1.7311 | 2.3035 |\n",
      "val: {'recall': 0.982157, 'recall_grapheme': 0.974517, 'recall_vowel': 0.990497, 'recall_consonant': 0.989096, 'acc_grapheme': 0.973507, 'acc_vowel': 0.991858, 'acc_consonant': 0.989966, 'loss_grapheme': 0.176155, 'loss_vowel': 0.121626, 'loss_consonant': 0.091078}\n",
      "** saved\n",
      "   14 | 0.000100 | 111616/160678 | 3.1588 | 2.5112 |\n",
      "val: {'recall': 0.98203, 'recall_grapheme': 0.973777, 'recall_vowel': 0.990173, 'recall_consonant': 0.990392, 'acc_grapheme': 0.973184, 'acc_vowel': 0.991758, 'acc_consonant': 0.990289, 'loss_grapheme': 0.196281, 'loss_vowel': 0.149383, 'loss_consonant': 0.107203}\n",
      "   15 | 0.000100 | 053760/160678 | 1.8297 | 2.4265 |\n",
      "val: {'recall': 0.981644, 'recall_grapheme': 0.973677, 'recall_vowel': 0.989988, 'recall_consonant': 0.989235, 'acc_grapheme': 0.973358, 'acc_vowel': 0.991958, 'acc_consonant': 0.990314, 'loss_grapheme': 0.195058, 'loss_vowel': 0.145572, 'loss_consonant': 0.106463}\n",
      "   15 | 0.000100 | 156160/160678 | 3.3754 | 2.3584 |\n",
      "val: {'recall': 0.982229, 'recall_grapheme': 0.975147, 'recall_vowel': 0.990315, 'recall_consonant': 0.988305, 'acc_grapheme': 0.97398, 'acc_vowel': 0.992057, 'acc_consonant': 0.990513, 'loss_grapheme': 0.187603, 'loss_vowel': 0.131788, 'loss_consonant': 0.100219}\n",
      "** saved\n",
      "   16 | 0.000020 | 098304/160678 | 2.2578 | 2.4976 |\n",
      "val: {'recall': 0.982541, 'recall_grapheme': 0.97535, 'recall_vowel': 0.990633, 'recall_consonant': 0.988828, 'acc_grapheme': 0.974653, 'acc_vowel': 0.992107, 'acc_consonant': 0.990638, 'loss_grapheme': 0.199453, 'loss_vowel': 0.148691, 'loss_consonant': 0.109471}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   17 | 0.000020 | 040448/160678 | 1.3836 | 2.3352 |\n",
      "val: {'recall': 0.982445, 'recall_grapheme': 0.974879, 'recall_vowel': 0.990231, 'recall_consonant': 0.989792, 'acc_grapheme': 0.974155, 'acc_vowel': 0.992107, 'acc_consonant': 0.990812, 'loss_grapheme': 0.182533, 'loss_vowel': 0.13802, 'loss_consonant': 0.102619}\n",
      "   17 | 0.000020 | 142848/160678 | 1.9077 | 2.4087 |\n",
      "val: {'recall': 0.982927, 'recall_grapheme': 0.9754, 'recall_vowel': 0.990945, 'recall_consonant': 0.989961, 'acc_grapheme': 0.974354, 'acc_vowel': 0.992256, 'acc_consonant': 0.990787, 'loss_grapheme': 0.180132, 'loss_vowel': 0.132313, 'loss_consonant': 0.098958}\n",
      "** saved\n",
      "   18 | 0.000020 | 084992/160678 | 1.2952 | 2.2707 |\n",
      "val: {'recall': 0.982633, 'recall_grapheme': 0.975842, 'recall_vowel': 0.990668, 'recall_consonant': 0.98818, 'acc_grapheme': 0.974852, 'acc_vowel': 0.992082, 'acc_consonant': 0.990812, 'loss_grapheme': 0.179789, 'loss_vowel': 0.129625, 'loss_consonant': 0.097027}\n",
      "   19 | 0.000020 | 027136/160678 | 2.5687 | 2.3408 |\n",
      "val: {'recall': 0.982733, 'recall_grapheme': 0.975771, 'recall_vowel': 0.990667, 'recall_consonant': 0.988721, 'acc_grapheme': 0.974752, 'acc_vowel': 0.992182, 'acc_consonant': 0.990962, 'loss_grapheme': 0.169217, 'loss_vowel': 0.118937, 'loss_consonant': 0.090663}\n",
      "   19 | 0.000020 | 129536/160678 | 0.2043 | 2.3719 |\n",
      "val: {'recall': 0.982617, 'recall_grapheme': 0.975433, 'recall_vowel': 0.990963, 'recall_consonant': 0.988641, 'acc_grapheme': 0.974578, 'acc_vowel': 0.992306, 'acc_consonant': 0.990912, 'loss_grapheme': 0.177373, 'loss_vowel': 0.133064, 'loss_consonant': 0.099869}\n",
      "   20 | 0.000020 | 071680/160678 | 1.8745 | 2.4000 |\n",
      "val: {'recall': 0.982814, 'recall_grapheme': 0.975219, 'recall_vowel': 0.991051, 'recall_consonant': 0.989769, 'acc_grapheme': 0.974777, 'acc_vowel': 0.992331, 'acc_consonant': 0.990837, 'loss_grapheme': 0.180373, 'loss_vowel': 0.133997, 'loss_consonant': 0.099871}\n",
      "   21 | 0.000020 | 013824/160678 | 1.3974 | 2.2096 |\n",
      "val: {'recall': 0.982944, 'recall_grapheme': 0.97562, 'recall_vowel': 0.991076, 'recall_consonant': 0.98946, 'acc_grapheme': 0.974852, 'acc_vowel': 0.992406, 'acc_consonant': 0.990812, 'loss_grapheme': 0.183093, 'loss_vowel': 0.136305, 'loss_consonant': 0.103142}\n",
      "** saved\n",
      "   21 | 0.000020 | 116224/160678 | 0.6919 | 2.3568 |\n",
      "val: {'recall': 0.982739, 'recall_grapheme': 0.975982, 'recall_vowel': 0.990813, 'recall_consonant': 0.988179, 'acc_grapheme': 0.975176, 'acc_vowel': 0.992381, 'acc_consonant': 0.990738, 'loss_grapheme': 0.17607, 'loss_vowel': 0.131899, 'loss_consonant': 0.098325}\n",
      "   22 | 0.000020 | 058368/160678 | 3.1322 | 2.3114 |\n",
      "val: {'recall': 0.983011, 'recall_grapheme': 0.975643, 'recall_vowel': 0.990796, 'recall_consonant': 0.989961, 'acc_grapheme': 0.975026, 'acc_vowel': 0.992331, 'acc_consonant': 0.990912, 'loss_grapheme': 0.173691, 'loss_vowel': 0.130012, 'loss_consonant': 0.097576}\n",
      "** saved\n",
      "   23 | 0.000020 | 000512/160678 | 1.3411 | 1.3411 |\n",
      "val: {'recall': 0.982929, 'recall_grapheme': 0.975805, 'recall_vowel': 0.990721, 'recall_consonant': 0.989384, 'acc_grapheme': 0.974877, 'acc_vowel': 0.992182, 'acc_consonant': 0.990937, 'loss_grapheme': 0.173677, 'loss_vowel': 0.126391, 'loss_consonant': 0.095848}\n",
      "   24 | 0.000020 | 045056/160678 | 2.0696 | 2.5679 |\n",
      "val: {'recall': 0.983261, 'recall_grapheme': 0.976346, 'recall_vowel': 0.990999, 'recall_consonant': 0.989354, 'acc_grapheme': 0.975225, 'acc_vowel': 0.992431, 'acc_consonant': 0.990912, 'loss_grapheme': 0.186275, 'loss_vowel': 0.143326, 'loss_consonant': 0.106776}\n",
      "   24 | 0.000020 | 147456/160678 | 2.3037 | 2.4034 |\n",
      "val: {'recall': 0.982765, 'recall_grapheme': 0.975867, 'recall_vowel': 0.991201, 'recall_consonant': 0.988124, 'acc_grapheme': 0.974951, 'acc_vowel': 0.992605, 'acc_consonant': 0.990787, 'loss_grapheme': 0.171681, 'loss_vowel': 0.12735, 'loss_consonant': 0.096936}\n",
      "   25 | 0.000020 | 089600/160678 | 1.5007 | 2.4999 |\n",
      "val: {'recall': 0.982801, 'recall_grapheme': 0.975493, 'recall_vowel': 0.990838, 'recall_consonant': 0.98938, 'acc_grapheme': 0.975001, 'acc_vowel': 0.992456, 'acc_consonant': 0.990837, 'loss_grapheme': 0.187722, 'loss_vowel': 0.14478, 'loss_consonant': 0.10781}\n",
      "   26 | 0.000020 | 031744/160678 | 3.8762 | 2.6034 |\n",
      "val: {'recall': 0.982833, 'recall_grapheme': 0.97571, 'recall_vowel': 0.990897, 'recall_consonant': 0.989015, 'acc_grapheme': 0.974976, 'acc_vowel': 0.992456, 'acc_consonant': 0.990987, 'loss_grapheme': 0.185436, 'loss_vowel': 0.142098, 'loss_consonant': 0.105773}\n",
      "   26 | 0.000020 | 134144/160678 | 1.7780 | 2.4083 |\n",
      "val: {'recall': 0.982742, 'recall_grapheme': 0.975377, 'recall_vowel': 0.990727, 'recall_consonant': 0.989489, 'acc_grapheme': 0.974827, 'acc_vowel': 0.992456, 'acc_consonant': 0.991011, 'loss_grapheme': 0.174187, 'loss_vowel': 0.130414, 'loss_consonant': 0.100014}\n",
      "   27 | 0.000020 | 076288/160678 | 0.7234 | 2.3105 |\n",
      "val: {'recall': 0.982909, 'recall_grapheme': 0.975541, 'recall_vowel': 0.991104, 'recall_consonant': 0.989451, 'acc_grapheme': 0.975026, 'acc_vowel': 0.99253, 'acc_consonant': 0.991161, 'loss_grapheme': 0.167222, 'loss_vowel': 0.121417, 'loss_consonant': 0.094626}\n",
      "   28 | 0.000020 | 018432/160678 | 0.9533 | 2.4452 |\n",
      "val: {'recall': 0.983045, 'recall_grapheme': 0.975846, 'recall_vowel': 0.991146, 'recall_consonant': 0.989341, 'acc_grapheme': 0.974976, 'acc_vowel': 0.992505, 'acc_consonant': 0.991036, 'loss_grapheme': 0.176913, 'loss_vowel': 0.132291, 'loss_consonant': 0.100899}\n",
      "   28 | 0.000020 | 120832/160678 | 4.1427 | 2.3778 |\n",
      "val: {'recall': 0.983135, 'recall_grapheme': 0.976383, 'recall_vowel': 0.990535, 'recall_consonant': 0.989238, 'acc_grapheme': 0.975723, 'acc_vowel': 0.992331, 'acc_consonant': 0.991036, 'loss_grapheme': 0.17047, 'loss_vowel': 0.125587, 'loss_consonant': 0.095208}\n",
      "   29 | 0.000020 | 062976/160678 | 1.3623 | 2.2874 |\n",
      "val: {'recall': 0.983077, 'recall_grapheme': 0.97627, 'recall_vowel': 0.990578, 'recall_consonant': 0.989192, 'acc_grapheme': 0.97525, 'acc_vowel': 0.992456, 'acc_consonant': 0.991061, 'loss_grapheme': 0.166488, 'loss_vowel': 0.121052, 'loss_consonant': 0.092238}\n",
      "   29 | 0.000020 | 072192/160678 | 2.0402 | 2.3309 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-813ae6dcb078>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
