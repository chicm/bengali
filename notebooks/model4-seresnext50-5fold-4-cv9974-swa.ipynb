{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image\n",
    "from utils import bn_update, moving_average, copy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations as albu\n",
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arange(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in train_loader:\n",
    "#    print(x)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet4(nn.Module):\n",
    "    def __init__(self, backbone_name='se_resnext50_32x4d'):\n",
    "        super(BengaliNet4, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.n_word = 1295\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant + self.n_word\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        self.num_p2_features = self.backbone.layer2[-1].se_module.fc2.out_channels\n",
    "        self.num_p3_features = self.backbone.layer3[-1].se_module.fc2.out_channels\n",
    "        self.p2_head = nn.Conv2d(self.num_p2_features, self.num_p2_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.p3_head = nn.Conv2d(self.num_p3_features, self.num_p3_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_p2_features * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_p3_features * 4)\n",
    "        self.act2 = Swish()\n",
    "        self.act3 = Swish()\n",
    "        \n",
    "        self.fc_aux1 = nn.Linear(self.num_p3_features * 4, self.num_classes)\n",
    "        self.fc_aux2 = nn.Linear(self.num_p2_features * 4, self.num_classes)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        for fc in [self.fc, self.fc_aux1, self.fc_aux2]:\n",
    "            nn.init.zeros_(fc.bias.data)\n",
    "\n",
    "        print('init model4')\n",
    "        \n",
    "    def features(self, x):\n",
    "        x = self.backbone.layer0(x); #print(x.size())\n",
    "        x = self.backbone.layer1(x); #print(x.size())\n",
    "        x = self.backbone.layer2(x); p2 = x; p2 = self.p2_head(p2); p2 = self.bn2(p2); p2 = self.act2(p2) #print(x.size())\n",
    "        x = self.backbone.layer3(x); p3 = x; p3 = self.p3_head(p3); p3 = self.bn3(p3); p3 = self.act3(p3) #print(x.size())\n",
    "        x = self.backbone.layer4(x); #print(x.size())\n",
    "        return x, p2, p3\n",
    "        \n",
    "    def logits(self, x, p2, p3):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        p2 = self.avg_pool(p2)\n",
    "        p2 = torch.flatten(p2, 1)\n",
    "        \n",
    "        p3 = self.avg_pool(p3)\n",
    "        p3 = torch.flatten(p3, 1)\n",
    "        return self.fc(x), self.fc_aux1(p3), self.fc_aux2(p2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x, p2, p3 = self.features(x)\n",
    "        x, logits_aux1, logits_aux2 = self.logits(x, p2, p3)\n",
    "\n",
    "        return x, logits_aux1, logits_aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model4-ckps'\n",
    "def create_model(args):\n",
    "    model = BengaliNet4(args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, preds3, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2) == len(preds3)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    recall_word = sklearn.metrics.recall_score(preds3, y[:, 3], average='macro')\n",
    "    \n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    metrics['recall_word'] = round(recall_word, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    metrics['acc_word'] = round((preds3 == y[:, 3]).sum() / len(y), 6)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    loss3 = F.cross_entropy(outputs[3], y_true[:, 3], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 + loss3 #, loss0.item(), loss1.item(), loss2.item()\n",
    "    #return loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2, loss3 = 0., 0., 0., 0.\n",
    "    preds0, preds1, preds2, preds3 = [], [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(x)\n",
    "            #avg_outputs = torch.mean(torch.stack([outputs, outputs_aux1, outputs_aux2], 0), 0)\n",
    "            outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            preds3.append(torch.max(outputs[3], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            loss3 += F.cross_entropy(outputs[3], y[:, 3], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    preds3 = torch.cat(preds3, 0).cpu().numpy()\n",
    "    \n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, preds3, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    metrics['loss_word'] = round(loss3 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19675782312158685"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "        img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "        batch_size = img.size(0)\n",
    "        r = np.random.rand()\n",
    "\n",
    "        if r < 0.3:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            #img[:, :, bby1:bby2, bbx1:bbx2] = img[rand_index, :, bby1:bby2, bbx1:bbx2] #for new cutmix\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "            loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r > 0.7:\n",
    "            img = grid(img)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, targets)\n",
    "            loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        else:\n",
    "            orig_img, targets = mixup(orig_img, targets)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "            loss_primary = mixup_criterion(outputs, targets)\n",
    "            loss_aux1 = mixup_criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = mixup_criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "            #loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        lr_scheduler(optimizer, batch_idx, epoch)\n",
    "        optimizer.step()            \n",
    "        \n",
    "        current_lr = get_lrs(optimizer)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "            epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "            loss.item(), train_loss/(batch_idx+1)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = 0.\n",
    "\n",
    "def validate_and_save(model, model_file, val_loader, save=False):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        best_metrics = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "def train(args):\n",
    "    model, model_file = create_model(args)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    #for param in model.backbone.parameters():\n",
    "    #    param.requires_grad = False\n",
    "\n",
    "    swa_model, _ = create_model(args)\n",
    "    swa_model = swa_model.cuda()\n",
    "    swa_model_file = model_file\n",
    "\n",
    "    optimizer = make_optimizer(model)\n",
    "    lr_scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    [model, swa_model], optimizer = amp.initialize([model, swa_model], optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        swa_model = nn.DataParallel(swa_model)\n",
    "    \n",
    "    validate_and_save(model, model_file, val_loader, save=False)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "        for epoch in range(args.start_epoch, args.num_epochs):\n",
    "            grid.set_prob(epoch, args.st_epochs)\n",
    "            train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\n",
    "            validate_and_save(model, model_file, val_loader, save=True)\n",
    "            \n",
    "            if (epoch+1) == args.swa_start and cycle == 1:\n",
    "                copy_model(swa_model, model)\n",
    "                swa_n = 0\n",
    "            if (epoch+1) >= args.swa_start and (epoch+1) % args.swa_freq == 0:\n",
    "                print('SWA>>>:')\n",
    "                moving_average(swa_model, model, 1.0 / (swa_n + 1))\n",
    "                swa_n += 1\n",
    "                bn_update(train_loader, swa_model)\n",
    "                validate_and_save(swa_model, swa_model_file, val_loader, save=True)\n",
    "\n",
    "        # reset scheduler at each cycle\n",
    "        lr_scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model4_se_resnext50_fold4_224.pth'\n",
    "\n",
    "args.base_lr = 1e-4\n",
    "\n",
    "args.num_epochs = 100\n",
    "args.start_epoch = 0\n",
    "args.swa_start = 20\n",
    "args.swa_freq = 4\n",
    "\n",
    "args.warmup_epochs = 5\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 640\n",
    "args.val_batch_size = 1024\n",
    "args.st_epochs = 10\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160735, 6) (40105, 6)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.backbone.parameters():\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate(nn.DataParallel(model), val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224.pth...\n",
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224.pth...\n",
      "\n",
      "val: {'recall': 0.997996, 'recall_grapheme': 0.99697, 'recall_vowel': 0.998936, 'recall_consonant': 0.999109, 'recall_word': 0.996648, 'acc_grapheme': 0.996883, 'acc_vowel': 0.998728, 'acc_consonant': 0.999052, 'acc_word': 0.996609, 'loss_grapheme': 0.012523, 'loss_vowel': 0.00635, 'loss_consonant': 0.005016, 'loss_word': 0.014546}\n",
      "CYCLE: 1\n",
      "    0 | 0.000020 | 160640/160735 | 7.2063 | 8.9963 ||\n",
      "val: {'recall': 0.996887, 'recall_grapheme': 0.995296, 'recall_vowel': 0.998344, 'recall_consonant': 0.998611, 'recall_word': 0.994477, 'acc_grapheme': 0.995188, 'acc_vowel': 0.998304, 'acc_consonant': 0.998504, 'acc_word': 0.99444, 'loss_grapheme': 0.092351, 'loss_vowel': 0.057241, 'loss_consonant': 0.046277, 'loss_word': 0.065656}\n",
      "    1 | 0.000040 | 160640/160735 | 6.9019 | 9.1035 |||\n",
      "val: {'recall': 0.996345, 'recall_grapheme': 0.994431, 'recall_vowel': 0.99823, 'recall_consonant': 0.998285, 'recall_word': 0.994105, 'acc_grapheme': 0.994739, 'acc_vowel': 0.998205, 'acc_consonant': 0.998479, 'acc_word': 0.994041, 'loss_grapheme': 0.097285, 'loss_vowel': 0.061309, 'loss_consonant': 0.048026, 'loss_word': 0.068595}\n",
      "    2 | 0.000060 | 160640/160735 | 2.2789 | 9.6976 |||\n",
      "val: {'recall': 0.996482, 'recall_grapheme': 0.994438, 'recall_vowel': 0.998507, 'recall_consonant': 0.998545, 'recall_word': 0.993983, 'acc_grapheme': 0.994764, 'acc_vowel': 0.998329, 'acc_consonant': 0.998329, 'acc_word': 0.993841, 'loss_grapheme': 0.074785, 'loss_vowel': 0.05014, 'loss_consonant': 0.037198, 'loss_word': 0.051902}\n",
      "    3 | 0.000080 | 160640/160735 | 10.5095 | 10.7770 |\n",
      "val: {'recall': 0.99592, 'recall_grapheme': 0.993749, 'recall_vowel': 0.997834, 'recall_consonant': 0.998347, 'recall_word': 0.993368, 'acc_grapheme': 0.99429, 'acc_vowel': 0.998055, 'acc_consonant': 0.99798, 'acc_word': 0.993243, 'loss_grapheme': 0.080324, 'loss_vowel': 0.050191, 'loss_consonant': 0.036257, 'loss_word': 0.060048}\n",
      "    4 | 0.000099 | 160640/160735 | 5.8896 | 9.9594 |||\n",
      "val: {'recall': 0.996842, 'recall_grapheme': 0.995631, 'recall_vowel': 0.998411, 'recall_consonant': 0.997693, 'recall_word': 0.995136, 'acc_grapheme': 0.995636, 'acc_vowel': 0.998554, 'acc_consonant': 0.998678, 'acc_word': 0.995063, 'loss_grapheme': 0.054658, 'loss_vowel': 0.037807, 'loss_consonant': 0.026532, 'loss_word': 0.040307}\n",
      "    5 | 0.000099 | 160640/160735 | 20.5468 | 9.9925 ||\n",
      "val: {'recall': 0.996085, 'recall_grapheme': 0.994611, 'recall_vowel': 0.99803, 'recall_consonant': 0.997086, 'recall_word': 0.993738, 'acc_grapheme': 0.994564, 'acc_vowel': 0.99803, 'acc_consonant': 0.99813, 'acc_word': 0.993642, 'loss_grapheme': 0.090255, 'loss_vowel': 0.057196, 'loss_consonant': 0.041073, 'loss_word': 0.065977}\n",
      "    6 | 0.000099 | 160640/160735 | 12.4363 | 10.1224 |\n",
      "val: {'recall': 0.996465, 'recall_grapheme': 0.994835, 'recall_vowel': 0.998027, 'recall_consonant': 0.998165, 'recall_word': 0.994149, 'acc_grapheme': 0.994714, 'acc_vowel': 0.99803, 'acc_consonant': 0.998404, 'acc_word': 0.994066, 'loss_grapheme': 0.068357, 'loss_vowel': 0.04186, 'loss_consonant': 0.030883, 'loss_word': 0.048283}\n",
      "    7 | 0.000098 | 160640/160735 | 2.8188 | 10.0546 ||\n",
      "val: {'recall': 0.997323, 'recall_grapheme': 0.995884, 'recall_vowel': 0.998528, 'recall_consonant': 0.998997, 'recall_word': 0.995077, 'acc_grapheme': 0.99606, 'acc_vowel': 0.998454, 'acc_consonant': 0.998629, 'acc_word': 0.995063, 'loss_grapheme': 0.040604, 'loss_vowel': 0.026866, 'loss_consonant': 0.021067, 'loss_word': 0.030635}\n",
      "    8 | 0.000098 | 160640/160735 | 3.1324 | 9.6344 ||\n",
      "val: {'recall': 0.996448, 'recall_grapheme': 0.994631, 'recall_vowel': 0.998368, 'recall_consonant': 0.99816, 'recall_word': 0.993967, 'acc_grapheme': 0.994465, 'acc_vowel': 0.998205, 'acc_consonant': 0.997905, 'acc_word': 0.993791, 'loss_grapheme': 0.087407, 'loss_vowel': 0.058145, 'loss_consonant': 0.045073, 'loss_word': 0.058272}\n",
      "    9 | 0.000098 | 160640/160735 | 3.0511 | 10.0904 ||\n",
      "val: {'recall': 0.996751, 'recall_grapheme': 0.995095, 'recall_vowel': 0.998022, 'recall_consonant': 0.998793, 'recall_word': 0.994762, 'acc_grapheme': 0.995387, 'acc_vowel': 0.998304, 'acc_consonant': 0.998529, 'acc_word': 0.994689, 'loss_grapheme': 0.049006, 'loss_vowel': 0.030435, 'loss_consonant': 0.024793, 'loss_word': 0.036618}\n",
      "   10 | 0.000097 | 160640/160735 | 2.9399 | 10.1761 ||\n",
      "val: {'recall': 0.996584, 'recall_grapheme': 0.994752, 'recall_vowel': 0.998281, 'recall_consonant': 0.998552, 'recall_word': 0.99441, 'acc_grapheme': 0.994888, 'acc_vowel': 0.998329, 'acc_consonant': 0.998329, 'acc_word': 0.994265, 'loss_grapheme': 0.069979, 'loss_vowel': 0.044185, 'loss_consonant': 0.036117, 'loss_word': 0.049894}\n",
      "   11 | 0.000096 | 160640/160735 | 3.1088 | 9.9225 |||\n",
      "val: {'recall': 0.995825, 'recall_grapheme': 0.993604, 'recall_vowel': 0.99837, 'recall_consonant': 0.997722, 'recall_word': 0.993831, 'acc_grapheme': 0.99419, 'acc_vowel': 0.998205, 'acc_consonant': 0.998479, 'acc_word': 0.993692, 'loss_grapheme': 0.059429, 'loss_vowel': 0.038939, 'loss_consonant': 0.030685, 'loss_word': 0.043003}\n",
      "   12 | 0.000096 | 160640/160735 | 21.3361 | 9.9668 ||\n",
      "val: {'recall': 0.995867, 'recall_grapheme': 0.993682, 'recall_vowel': 0.998163, 'recall_consonant': 0.997941, 'recall_word': 0.993507, 'acc_grapheme': 0.994265, 'acc_vowel': 0.998005, 'acc_consonant': 0.998105, 'acc_word': 0.993392, 'loss_grapheme': 0.078349, 'loss_vowel': 0.045929, 'loss_consonant': 0.042968, 'loss_word': 0.058256}\n",
      "   13 | 0.000095 | 160640/160735 | 2.8224 | 9.6503 |||\n",
      "val: {'recall': 0.996554, 'recall_grapheme': 0.995245, 'recall_vowel': 0.997892, 'recall_consonant': 0.997834, 'recall_word': 0.994473, 'acc_grapheme': 0.995138, 'acc_vowel': 0.99813, 'acc_consonant': 0.998205, 'acc_word': 0.994365, 'loss_grapheme': 0.08214, 'loss_vowel': 0.060768, 'loss_consonant': 0.042771, 'loss_word': 0.052296}\n",
      "   14 | 0.000095 | 160640/160735 | 7.7353 | 9.8421 |||\n",
      "val: {'recall': 0.996797, 'recall_grapheme': 0.995203, 'recall_vowel': 0.998697, 'recall_consonant': 0.998087, 'recall_word': 0.994794, 'acc_grapheme': 0.995337, 'acc_vowel': 0.998454, 'acc_consonant': 0.998479, 'acc_word': 0.994739, 'loss_grapheme': 0.04539, 'loss_vowel': 0.029843, 'loss_consonant': 0.023928, 'loss_word': 0.033408}\n",
      "   15 | 0.000094 | 160640/160735 | 23.5063 | 9.8647 ||\n",
      "val: {'recall': 0.995387, 'recall_grapheme': 0.992476, 'recall_vowel': 0.99816, 'recall_consonant': 0.998437, 'recall_word': 0.992332, 'acc_grapheme': 0.992894, 'acc_vowel': 0.997756, 'acc_consonant': 0.99818, 'acc_word': 0.992096, 'loss_grapheme': 0.086044, 'loss_vowel': 0.049893, 'loss_consonant': 0.039005, 'loss_word': 0.06658}\n",
      "   16 | 0.000093 | 160640/160735 | 10.5427 | 9.6380 ||\n",
      "val: {'recall': 0.996788, 'recall_grapheme': 0.995011, 'recall_vowel': 0.998485, 'recall_consonant': 0.998644, 'recall_word': 0.994245, 'acc_grapheme': 0.994963, 'acc_vowel': 0.998329, 'acc_consonant': 0.998255, 'acc_word': 0.994165, 'loss_grapheme': 0.067502, 'loss_vowel': 0.041417, 'loss_consonant': 0.033465, 'loss_word': 0.047626}\n",
      "   17 | 0.000092 | 160640/160735 | 7.8437 | 9.4359 ||\n",
      "val: {'recall': 0.996468, 'recall_grapheme': 0.994378, 'recall_vowel': 0.998346, 'recall_consonant': 0.99877, 'recall_word': 0.994526, 'acc_grapheme': 0.995213, 'acc_vowel': 0.998379, 'acc_consonant': 0.998454, 'acc_word': 0.994539, 'loss_grapheme': 0.0556, 'loss_vowel': 0.03968, 'loss_consonant': 0.029244, 'loss_word': 0.037826}\n",
      "   18 | 0.000091 | 160640/160735 | 7.3108 | 10.2153 ||\n",
      "val: {'recall': 0.995238, 'recall_grapheme': 0.992884, 'recall_vowel': 0.998128, 'recall_consonant': 0.997057, 'recall_word': 0.993033, 'acc_grapheme': 0.993542, 'acc_vowel': 0.998055, 'acc_consonant': 0.997881, 'acc_word': 0.992993, 'loss_grapheme': 0.091014, 'loss_vowel': 0.06239, 'loss_consonant': 0.048533, 'loss_word': 0.069166}\n",
      "   19 | 0.000090 | 160640/160735 | 2.8944 | 10.3272 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996736, 'recall_grapheme': 0.995015, 'recall_vowel': 0.998763, 'recall_consonant': 0.99815, 'recall_word': 0.995207, 'acc_grapheme': 0.995587, 'acc_vowel': 0.998454, 'acc_consonant': 0.998255, 'acc_word': 0.995138, 'loss_grapheme': 0.048455, 'loss_vowel': 0.03448, 'loss_consonant': 0.02715, 'loss_word': 0.035359}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997661, 'recall_grapheme': 0.996518, 'recall_vowel': 0.998785, 'recall_consonant': 0.998825, 'recall_word': 0.99593, 'acc_grapheme': 0.996734, 'acc_vowel': 0.998604, 'acc_consonant': 0.998604, 'acc_word': 0.995911, 'loss_grapheme': 0.014654, 'loss_vowel': 0.006566, 'loss_consonant': 0.005967, 'loss_word': 0.017012}\n",
      "   20 | 0.000090 | 160640/160735 | 2.7408 | 9.8741 |||\n",
      "val: {'recall': 0.996216, 'recall_grapheme': 0.994165, 'recall_vowel': 0.998325, 'recall_consonant': 0.998209, 'recall_word': 0.99393, 'acc_grapheme': 0.994689, 'acc_vowel': 0.99818, 'acc_consonant': 0.998005, 'acc_word': 0.993841, 'loss_grapheme': 0.071171, 'loss_vowel': 0.050296, 'loss_consonant': 0.035578, 'loss_word': 0.046127}\n",
      "   21 | 0.000089 | 160640/160735 | 11.0795 | 9.5905 ||\n",
      "val: {'recall': 0.996013, 'recall_grapheme': 0.994075, 'recall_vowel': 0.998554, 'recall_consonant': 0.997348, 'recall_word': 0.99395, 'acc_grapheme': 0.994465, 'acc_vowel': 0.998354, 'acc_consonant': 0.998105, 'acc_word': 0.993791, 'loss_grapheme': 0.083916, 'loss_vowel': 0.053358, 'loss_consonant': 0.041388, 'loss_word': 0.057141}\n",
      "   22 | 0.000088 | 160640/160735 | 2.9177 | 10.3787 ||\n",
      "val: {'recall': 0.996602, 'recall_grapheme': 0.994952, 'recall_vowel': 0.998246, 'recall_consonant': 0.99826, 'recall_word': 0.993952, 'acc_grapheme': 0.995013, 'acc_vowel': 0.99808, 'acc_consonant': 0.998055, 'acc_word': 0.993866, 'loss_grapheme': 0.048227, 'loss_vowel': 0.031233, 'loss_consonant': 0.024595, 'loss_word': 0.036344}\n",
      "   23 | 0.000086 | 160640/160735 | 2.7116 | 8.7228 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996745, 'recall_grapheme': 0.995293, 'recall_vowel': 0.998726, 'recall_consonant': 0.997669, 'recall_word': 0.995217, 'acc_grapheme': 0.995686, 'acc_vowel': 0.998604, 'acc_consonant': 0.998529, 'acc_word': 0.995138, 'loss_grapheme': 0.039229, 'loss_vowel': 0.025224, 'loss_consonant': 0.02021, 'loss_word': 0.030821}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:27<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.99779, 'recall_grapheme': 0.996722, 'recall_vowel': 0.998771, 'recall_consonant': 0.998945, 'recall_word': 0.996381, 'acc_grapheme': 0.996858, 'acc_vowel': 0.998803, 'acc_consonant': 0.998778, 'acc_word': 0.99636, 'loss_grapheme': 0.013412, 'loss_vowel': 0.006075, 'loss_consonant': 0.005278, 'loss_word': 0.015595}\n",
      "   24 | 0.000085 | 160640/160735 | 2.6623 | 8.8956 ||\n",
      "val: {'recall': 0.996228, 'recall_grapheme': 0.994168, 'recall_vowel': 0.998183, 'recall_consonant': 0.998392, 'recall_word': 0.994012, 'acc_grapheme': 0.994564, 'acc_vowel': 0.998105, 'acc_consonant': 0.998055, 'acc_word': 0.993841, 'loss_grapheme': 0.081853, 'loss_vowel': 0.051156, 'loss_consonant': 0.038242, 'loss_word': 0.056635}\n",
      "   25 | 0.000084 | 160640/160735 | 20.2366 | 9.2726 ||\n",
      "val: {'recall': 0.996541, 'recall_grapheme': 0.995087, 'recall_vowel': 0.998324, 'recall_consonant': 0.997669, 'recall_word': 0.99467, 'acc_grapheme': 0.995312, 'acc_vowel': 0.998454, 'acc_consonant': 0.998554, 'acc_word': 0.994589, 'loss_grapheme': 0.045965, 'loss_vowel': 0.031826, 'loss_consonant': 0.025106, 'loss_word': 0.033505}\n",
      "   26 | 0.000083 | 160640/160735 | 16.0780 | 8.9808 ||\n",
      "val: {'recall': 0.996587, 'recall_grapheme': 0.994894, 'recall_vowel': 0.998304, 'recall_consonant': 0.998255, 'recall_word': 0.994811, 'acc_grapheme': 0.995312, 'acc_vowel': 0.998404, 'acc_consonant': 0.998479, 'acc_word': 0.994764, 'loss_grapheme': 0.054475, 'loss_vowel': 0.036777, 'loss_consonant': 0.028218, 'loss_word': 0.038255}\n",
      "   27 | 0.000082 | 160640/160735 | 6.8925 | 9.2161 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997166, 'recall_grapheme': 0.995674, 'recall_vowel': 0.998526, 'recall_consonant': 0.99879, 'recall_word': 0.995209, 'acc_grapheme': 0.995587, 'acc_vowel': 0.998678, 'acc_consonant': 0.998554, 'acc_word': 0.995163, 'loss_grapheme': 0.055813, 'loss_vowel': 0.038727, 'loss_consonant': 0.029452, 'loss_word': 0.037052}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997949, 'recall_grapheme': 0.996859, 'recall_vowel': 0.999044, 'recall_consonant': 0.999034, 'recall_word': 0.996498, 'acc_grapheme': 0.997008, 'acc_vowel': 0.998903, 'acc_consonant': 0.998928, 'acc_word': 0.996459, 'loss_grapheme': 0.01306, 'loss_vowel': 0.006098, 'loss_consonant': 0.005131, 'loss_word': 0.014867}\n",
      "   28 | 0.000081 | 160640/160735 | 3.0009 | 8.7068 |||\n",
      "val: {'recall': 0.996876, 'recall_grapheme': 0.995209, 'recall_vowel': 0.998565, 'recall_consonant': 0.998523, 'recall_word': 0.994809, 'acc_grapheme': 0.995163, 'acc_vowel': 0.998554, 'acc_consonant': 0.998304, 'acc_word': 0.994839, 'loss_grapheme': 0.072575, 'loss_vowel': 0.049707, 'loss_consonant': 0.034532, 'loss_word': 0.048046}\n",
      "   29 | 0.000079 | 160640/160735 | 2.7516 | 9.3475 |||\n",
      "val: {'recall': 0.99648, 'recall_grapheme': 0.994482, 'recall_vowel': 0.998183, 'recall_consonant': 0.998773, 'recall_word': 0.994156, 'acc_grapheme': 0.994814, 'acc_vowel': 0.998304, 'acc_consonant': 0.998529, 'acc_word': 0.994115, 'loss_grapheme': 0.055324, 'loss_vowel': 0.037108, 'loss_consonant': 0.025528, 'loss_word': 0.040562}\n",
      "   30 | 0.000078 | 160640/160735 | 11.0669 | 8.8887 ||\n",
      "val: {'recall': 0.996463, 'recall_grapheme': 0.994972, 'recall_vowel': 0.998505, 'recall_consonant': 0.997403, 'recall_word': 0.994755, 'acc_grapheme': 0.995138, 'acc_vowel': 0.998429, 'acc_consonant': 0.998379, 'acc_word': 0.994714, 'loss_grapheme': 0.070957, 'loss_vowel': 0.050057, 'loss_consonant': 0.035094, 'loss_word': 0.044574}\n",
      "   31 | 0.000077 | 160640/160735 | 11.1037 | 10.1026 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.995878, 'recall_grapheme': 0.993621, 'recall_vowel': 0.998462, 'recall_consonant': 0.997808, 'recall_word': 0.993379, 'acc_grapheme': 0.994265, 'acc_vowel': 0.99828, 'acc_consonant': 0.997955, 'acc_word': 0.993243, 'loss_grapheme': 0.07361, 'loss_vowel': 0.051162, 'loss_consonant': 0.039372, 'loss_word': 0.048875}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997958, 'recall_grapheme': 0.996877, 'recall_vowel': 0.999031, 'recall_consonant': 0.999048, 'recall_word': 0.996642, 'acc_grapheme': 0.996983, 'acc_vowel': 0.998878, 'acc_consonant': 0.998978, 'acc_word': 0.996634, 'loss_grapheme': 0.012878, 'loss_vowel': 0.006123, 'loss_consonant': 0.005088, 'loss_word': 0.014622}\n",
      "   32 | 0.000075 | 160640/160735 | 10.1188 | 10.2896 |\n",
      "val: {'recall': 0.996206, 'recall_grapheme': 0.994184, 'recall_vowel': 0.998406, 'recall_consonant': 0.99805, 'recall_word': 0.994384, 'acc_grapheme': 0.994764, 'acc_vowel': 0.99823, 'acc_consonant': 0.998205, 'acc_word': 0.99424, 'loss_grapheme': 0.067127, 'loss_vowel': 0.041262, 'loss_consonant': 0.031707, 'loss_word': 0.052903}\n",
      "   33 | 0.000074 | 160640/160735 | 10.7510 | 9.0113 ||\n",
      "val: {'recall': 0.997059, 'recall_grapheme': 0.995609, 'recall_vowel': 0.998302, 'recall_consonant': 0.998716, 'recall_word': 0.994906, 'acc_grapheme': 0.995487, 'acc_vowel': 0.998529, 'acc_consonant': 0.998554, 'acc_word': 0.994863, 'loss_grapheme': 0.081519, 'loss_vowel': 0.060171, 'loss_consonant': 0.041886, 'loss_word': 0.05319}\n",
      "   34 | 0.000073 | 160640/160735 | 5.9358 | 9.2631 |||\n",
      "val: {'recall': 0.996824, 'recall_grapheme': 0.995184, 'recall_vowel': 0.998548, 'recall_consonant': 0.99838, 'recall_word': 0.994404, 'acc_grapheme': 0.994988, 'acc_vowel': 0.998479, 'acc_consonant': 0.99828, 'acc_word': 0.994315, 'loss_grapheme': 0.076744, 'loss_vowel': 0.05214, 'loss_consonant': 0.038925, 'loss_word': 0.052814}\n",
      "   35 | 0.000071 | 160640/160735 | 2.6247 | 8.6681 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997405, 'recall_grapheme': 0.996084, 'recall_vowel': 0.998628, 'recall_consonant': 0.998826, 'recall_word': 0.995534, 'acc_grapheme': 0.996085, 'acc_vowel': 0.998604, 'acc_consonant': 0.998629, 'acc_word': 0.995462, 'loss_grapheme': 0.040426, 'loss_vowel': 0.025269, 'loss_consonant': 0.020582, 'loss_word': 0.028131}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997847, 'recall_grapheme': 0.996747, 'recall_vowel': 0.998923, 'recall_consonant': 0.998973, 'recall_word': 0.996515, 'acc_grapheme': 0.996983, 'acc_vowel': 0.998828, 'acc_consonant': 0.998928, 'acc_word': 0.996459, 'loss_grapheme': 0.012444, 'loss_vowel': 0.005792, 'loss_consonant': 0.004789, 'loss_word': 0.014392}\n",
      "   36 | 0.000070 | 160640/160735 | 2.4591 | 9.5849 ||\n",
      "val: {'recall': 0.997051, 'recall_grapheme': 0.99551, 'recall_vowel': 0.998442, 'recall_consonant': 0.998743, 'recall_word': 0.994736, 'acc_grapheme': 0.995312, 'acc_vowel': 0.998429, 'acc_consonant': 0.998529, 'acc_word': 0.994664, 'loss_grapheme': 0.058091, 'loss_vowel': 0.039995, 'loss_consonant': 0.030726, 'loss_word': 0.038259}\n",
      "   37 | 0.000068 | 160640/160735 | 17.0201 | 9.0888 ||\n",
      "val: {'recall': 0.996949, 'recall_grapheme': 0.995763, 'recall_vowel': 0.998537, 'recall_consonant': 0.997732, 'recall_word': 0.994914, 'acc_grapheme': 0.995512, 'acc_vowel': 0.998479, 'acc_consonant': 0.998604, 'acc_word': 0.994814, 'loss_grapheme': 0.077722, 'loss_vowel': 0.052659, 'loss_consonant': 0.039194, 'loss_word': 0.05046}\n",
      "   38 | 0.000067 | 160640/160735 | 2.4074 | 8.9806 |||\n",
      "val: {'recall': 0.996733, 'recall_grapheme': 0.995018, 'recall_vowel': 0.998639, 'recall_consonant': 0.998259, 'recall_word': 0.994479, 'acc_grapheme': 0.994913, 'acc_vowel': 0.998504, 'acc_consonant': 0.998354, 'acc_word': 0.99439, 'loss_grapheme': 0.064055, 'loss_vowel': 0.040935, 'loss_consonant': 0.031582, 'loss_word': 0.041632}\n",
      "   39 | 0.000065 | 160640/160735 | 10.8676 | 8.6267 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997206, 'recall_grapheme': 0.996034, 'recall_vowel': 0.998674, 'recall_consonant': 0.998083, 'recall_word': 0.995191, 'acc_grapheme': 0.995811, 'acc_vowel': 0.998479, 'acc_consonant': 0.998479, 'acc_word': 0.995088, 'loss_grapheme': 0.046189, 'loss_vowel': 0.031545, 'loss_consonant': 0.023767, 'loss_word': 0.031001}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997987, 'recall_grapheme': 0.996987, 'recall_vowel': 0.998986, 'recall_consonant': 0.99899, 'recall_word': 0.996622, 'acc_grapheme': 0.997133, 'acc_vowel': 0.998928, 'acc_consonant': 0.999003, 'acc_word': 0.996584, 'loss_grapheme': 0.012166, 'loss_vowel': 0.005628, 'loss_consonant': 0.004617, 'loss_word': 0.014131}\n",
      "   40 | 0.000064 | 160640/160735 | 17.0889 | 9.2321 ||\n",
      "val: {'recall': 0.997512, 'recall_grapheme': 0.996708, 'recall_vowel': 0.998819, 'recall_consonant': 0.997813, 'recall_word': 0.995937, 'acc_grapheme': 0.996559, 'acc_vowel': 0.998678, 'acc_consonant': 0.998678, 'acc_word': 0.995911, 'loss_grapheme': 0.035443, 'loss_vowel': 0.024669, 'loss_consonant': 0.018746, 'loss_word': 0.024647}\n",
      "   41 | 0.000062 | 160640/160735 | 7.8566 | 9.4581 |||\n",
      "val: {'recall': 0.99641, 'recall_grapheme': 0.994994, 'recall_vowel': 0.998443, 'recall_consonant': 0.997209, 'recall_word': 0.994488, 'acc_grapheme': 0.994963, 'acc_vowel': 0.998454, 'acc_consonant': 0.998429, 'acc_word': 0.99439, 'loss_grapheme': 0.06134, 'loss_vowel': 0.037556, 'loss_consonant': 0.029721, 'loss_word': 0.041023}\n",
      "   42 | 0.000061 | 160640/160735 | 2.8893 | 9.4877 |||\n",
      "val: {'recall': 0.996764, 'recall_grapheme': 0.995706, 'recall_vowel': 0.998606, 'recall_consonant': 0.997039, 'recall_word': 0.995186, 'acc_grapheme': 0.995562, 'acc_vowel': 0.998479, 'acc_consonant': 0.998479, 'acc_word': 0.995113, 'loss_grapheme': 0.062713, 'loss_vowel': 0.041252, 'loss_consonant': 0.030595, 'loss_word': 0.040557}\n",
      "   43 | 0.000059 | 160640/160735 | 2.2778 | 8.8193 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996923, 'recall_grapheme': 0.995416, 'recall_vowel': 0.99868, 'recall_consonant': 0.998182, 'recall_word': 0.994917, 'acc_grapheme': 0.995711, 'acc_vowel': 0.998629, 'acc_consonant': 0.998654, 'acc_word': 0.994863, 'loss_grapheme': 0.036051, 'loss_vowel': 0.025018, 'loss_consonant': 0.019061, 'loss_word': 0.026532}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997947, 'recall_grapheme': 0.996928, 'recall_vowel': 0.998948, 'recall_consonant': 0.998984, 'recall_word': 0.996735, 'acc_grapheme': 0.997108, 'acc_vowel': 0.998878, 'acc_consonant': 0.998978, 'acc_word': 0.996709, 'loss_grapheme': 0.012128, 'loss_vowel': 0.00565, 'loss_consonant': 0.00461, 'loss_word': 0.014042}\n",
      "   44 | 0.000058 | 160640/160735 | 2.3755 | 8.5588 |||\n",
      "val: {'recall': 0.996975, 'recall_grapheme': 0.995373, 'recall_vowel': 0.998651, 'recall_consonant': 0.998501, 'recall_word': 0.994901, 'acc_grapheme': 0.995262, 'acc_vowel': 0.998554, 'acc_consonant': 0.998604, 'acc_word': 0.994814, 'loss_grapheme': 0.057497, 'loss_vowel': 0.038481, 'loss_consonant': 0.029004, 'loss_word': 0.03859}\n",
      "   45 | 0.000056 | 160640/160735 | 20.9787 | 9.3497 ||\n",
      "val: {'recall': 0.995576, 'recall_grapheme': 0.993757, 'recall_vowel': 0.998092, 'recall_consonant': 0.996695, 'recall_word': 0.992603, 'acc_grapheme': 0.993417, 'acc_vowel': 0.998055, 'acc_consonant': 0.99798, 'acc_word': 0.992495, 'loss_grapheme': 0.064153, 'loss_vowel': 0.038115, 'loss_consonant': 0.031569, 'loss_word': 0.054519}\n",
      "   46 | 0.000055 | 160640/160735 | 11.1138 | 9.2417 |\n",
      "val: {'recall': 0.996764, 'recall_grapheme': 0.99499, 'recall_vowel': 0.998686, 'recall_consonant': 0.998389, 'recall_word': 0.99419, 'acc_grapheme': 0.994789, 'acc_vowel': 0.998529, 'acc_consonant': 0.998554, 'acc_word': 0.994041, 'loss_grapheme': 0.07786, 'loss_vowel': 0.049741, 'loss_consonant': 0.036872, 'loss_word': 0.053375}\n",
      "   47 | 0.000053 | 160640/160735 | 14.8232 | 8.9709 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997584, 'recall_grapheme': 0.996608, 'recall_vowel': 0.998616, 'recall_consonant': 0.998502, 'recall_word': 0.995698, 'acc_grapheme': 0.99626, 'acc_vowel': 0.998554, 'acc_consonant': 0.998629, 'acc_word': 0.995612, 'loss_grapheme': 0.052856, 'loss_vowel': 0.03688, 'loss_consonant': 0.028794, 'loss_word': 0.033856}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:27<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997968, 'recall_grapheme': 0.997015, 'recall_vowel': 0.998852, 'recall_consonant': 0.99899, 'recall_word': 0.99668, 'acc_grapheme': 0.997133, 'acc_vowel': 0.998878, 'acc_consonant': 0.999003, 'acc_word': 0.996659, 'loss_grapheme': 0.01199, 'loss_vowel': 0.005575, 'loss_consonant': 0.004537, 'loss_word': 0.013973}\n",
      "   48 | 0.000052 | 160640/160735 | 2.3749 | 8.9976 |||\n",
      "val: {'recall': 0.997627, 'recall_grapheme': 0.996359, 'recall_vowel': 0.998783, 'recall_consonant': 0.999007, 'recall_word': 0.995528, 'acc_grapheme': 0.99626, 'acc_vowel': 0.998629, 'acc_consonant': 0.998778, 'acc_word': 0.995512, 'loss_grapheme': 0.047333, 'loss_vowel': 0.033324, 'loss_consonant': 0.025439, 'loss_word': 0.030223}\n",
      "   49 | 0.000050 | 160640/160735 | 20.2220 | 8.9018 ||\n",
      "val: {'recall': 0.997156, 'recall_grapheme': 0.995824, 'recall_vowel': 0.998549, 'recall_consonant': 0.998427, 'recall_word': 0.995003, 'acc_grapheme': 0.995861, 'acc_vowel': 0.998479, 'acc_consonant': 0.998629, 'acc_word': 0.994988, 'loss_grapheme': 0.042712, 'loss_vowel': 0.026388, 'loss_consonant': 0.020726, 'loss_word': 0.031784}\n",
      "   50 | 0.000048 | 160640/160735 | 15.7975 | 8.5876 ||\n",
      "val: {'recall': 0.997446, 'recall_grapheme': 0.996232, 'recall_vowel': 0.998856, 'recall_consonant': 0.998463, 'recall_word': 0.995912, 'acc_grapheme': 0.99631, 'acc_vowel': 0.998678, 'acc_consonant': 0.998753, 'acc_word': 0.995911, 'loss_grapheme': 0.04751, 'loss_vowel': 0.033216, 'loss_consonant': 0.023768, 'loss_word': 0.031112}\n",
      "   51 | 0.000047 | 160640/160735 | 9.0128 | 8.9981 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996258, 'recall_grapheme': 0.994695, 'recall_vowel': 0.998617, 'recall_consonant': 0.997027, 'recall_word': 0.994127, 'acc_grapheme': 0.994639, 'acc_vowel': 0.998404, 'acc_consonant': 0.99823, 'acc_word': 0.994066, 'loss_grapheme': 0.071948, 'loss_vowel': 0.039318, 'loss_consonant': 0.032135, 'loss_word': 0.057442}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998016, 'recall_grapheme': 0.997124, 'recall_vowel': 0.998858, 'recall_consonant': 0.998959, 'recall_word': 0.996751, 'acc_grapheme': 0.997182, 'acc_vowel': 0.998878, 'acc_consonant': 0.998978, 'acc_word': 0.996709, 'loss_grapheme': 0.012, 'loss_vowel': 0.005573, 'loss_consonant': 0.004552, 'loss_word': 0.01395}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224.pth\n",
      "   52 | 0.000045 | 160640/160735 | 20.0081 | 9.2368 |\n",
      "val: {'recall': 0.997487, 'recall_grapheme': 0.996309, 'recall_vowel': 0.998962, 'recall_consonant': 0.998367, 'recall_word': 0.995203, 'acc_grapheme': 0.995836, 'acc_vowel': 0.998654, 'acc_consonant': 0.998604, 'acc_word': 0.995138, 'loss_grapheme': 0.046585, 'loss_vowel': 0.029439, 'loss_consonant': 0.023378, 'loss_word': 0.032892}\n",
      "   53 | 0.000044 | 160640/160735 | 4.9275 | 9.0875 |||\n",
      "val: {'recall': 0.997215, 'recall_grapheme': 0.995551, 'recall_vowel': 0.998968, 'recall_consonant': 0.998789, 'recall_word': 0.995171, 'acc_grapheme': 0.995462, 'acc_vowel': 0.998604, 'acc_consonant': 0.998529, 'acc_word': 0.995063, 'loss_grapheme': 0.057652, 'loss_vowel': 0.036213, 'loss_consonant': 0.027111, 'loss_word': 0.039551}\n",
      "   54 | 0.000042 | 160640/160735 | 2.4205 | 9.6498 |||\n",
      "val: {'recall': 0.997408, 'recall_grapheme': 0.996047, 'recall_vowel': 0.99873, 'recall_consonant': 0.99881, 'recall_word': 0.995286, 'acc_grapheme': 0.995936, 'acc_vowel': 0.998604, 'acc_consonant': 0.998678, 'acc_word': 0.995188, 'loss_grapheme': 0.028636, 'loss_vowel': 0.01725, 'loss_consonant': 0.013646, 'loss_word': 0.022801}\n",
      "   55 | 0.000041 | 160640/160735 | 10.1007 | 8.7695 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997244, 'recall_grapheme': 0.996072, 'recall_vowel': 0.998603, 'recall_consonant': 0.998227, 'recall_word': 0.995128, 'acc_grapheme': 0.995786, 'acc_vowel': 0.998629, 'acc_consonant': 0.998504, 'acc_word': 0.995088, 'loss_grapheme': 0.036971, 'loss_vowel': 0.022222, 'loss_consonant': 0.017496, 'loss_word': 0.026749}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998065, 'recall_grapheme': 0.997172, 'recall_vowel': 0.998924, 'recall_consonant': 0.99899, 'recall_word': 0.996666, 'acc_grapheme': 0.997182, 'acc_vowel': 0.998828, 'acc_consonant': 0.999003, 'acc_word': 0.996634, 'loss_grapheme': 0.012032, 'loss_vowel': 0.005597, 'loss_consonant': 0.004496, 'loss_word': 0.013968}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224.pth\n",
      "   56 | 0.000039 | 160640/160735 | 2.4012 | 9.0481 |||\n",
      "val: {'recall': 0.996776, 'recall_grapheme': 0.994924, 'recall_vowel': 0.998905, 'recall_consonant': 0.998353, 'recall_word': 0.994663, 'acc_grapheme': 0.995262, 'acc_vowel': 0.998629, 'acc_consonant': 0.998554, 'acc_word': 0.994564, 'loss_grapheme': 0.067465, 'loss_vowel': 0.042019, 'loss_consonant': 0.031543, 'loss_word': 0.043291}\n",
      "   57 | 0.000038 | 160640/160735 | 12.1311 | 9.5808 ||\n",
      "val: {'recall': 0.996007, 'recall_grapheme': 0.993806, 'recall_vowel': 0.998231, 'recall_consonant': 0.998187, 'recall_word': 0.993946, 'acc_grapheme': 0.99429, 'acc_vowel': 0.99798, 'acc_consonant': 0.998005, 'acc_word': 0.993816, 'loss_grapheme': 0.108259, 'loss_vowel': 0.05876, 'loss_consonant': 0.042543, 'loss_word': 0.064642}\n",
      "   58 | 0.000036 | 160640/160735 | 19.9818 | 8.7020 ||\n",
      "val: {'recall': 0.997015, 'recall_grapheme': 0.995306, 'recall_vowel': 0.998551, 'recall_consonant': 0.998898, 'recall_word': 0.994619, 'acc_grapheme': 0.995337, 'acc_vowel': 0.998429, 'acc_consonant': 0.998579, 'acc_word': 0.994489, 'loss_grapheme': 0.060146, 'loss_vowel': 0.039164, 'loss_consonant': 0.030107, 'loss_word': 0.039071}\n",
      "   59 | 0.000035 | 160640/160735 | 15.7186 | 8.8500 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996647, 'recall_grapheme': 0.994538, 'recall_vowel': 0.998715, 'recall_consonant': 0.998795, 'recall_word': 0.993757, 'acc_grapheme': 0.994415, 'acc_vowel': 0.998429, 'acc_consonant': 0.998379, 'acc_word': 0.993642, 'loss_grapheme': 0.090655, 'loss_vowel': 0.056546, 'loss_consonant': 0.041791, 'loss_word': 0.058677}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998025, 'recall_grapheme': 0.997108, 'recall_vowel': 0.998918, 'recall_consonant': 0.998965, 'recall_word': 0.996712, 'acc_grapheme': 0.997282, 'acc_vowel': 0.998828, 'acc_consonant': 0.999003, 'acc_word': 0.996684, 'loss_grapheme': 0.011892, 'loss_vowel': 0.005579, 'loss_consonant': 0.004442, 'loss_word': 0.013836}\n",
      "   60 | 0.000033 | 160640/160735 | 15.3656 | 8.1899 ||\n",
      "val: {'recall': 0.997484, 'recall_grapheme': 0.996054, 'recall_vowel': 0.998721, 'recall_consonant': 0.999108, 'recall_word': 0.995791, 'acc_grapheme': 0.99626, 'acc_vowel': 0.998753, 'acc_consonant': 0.998903, 'acc_word': 0.995736, 'loss_grapheme': 0.041781, 'loss_vowel': 0.030703, 'loss_consonant': 0.022011, 'loss_word': 0.027359}\n",
      "   61 | 0.000032 | 160640/160735 | 6.4781 | 9.0502 |||\n",
      "val: {'recall': 0.996754, 'recall_grapheme': 0.994647, 'recall_vowel': 0.998871, 'recall_consonant': 0.998851, 'recall_word': 0.994159, 'acc_grapheme': 0.994664, 'acc_vowel': 0.998429, 'acc_consonant': 0.998304, 'acc_word': 0.993991, 'loss_grapheme': 0.08409, 'loss_vowel': 0.048296, 'loss_consonant': 0.0363, 'loss_word': 0.057434}\n",
      "   62 | 0.000030 | 160640/160735 | 2.2369 | 9.0765 |||\n",
      "val: {'recall': 0.997333, 'recall_grapheme': 0.995811, 'recall_vowel': 0.998714, 'recall_consonant': 0.998996, 'recall_word': 0.995171, 'acc_grapheme': 0.995761, 'acc_vowel': 0.998579, 'acc_consonant': 0.998753, 'acc_word': 0.995113, 'loss_grapheme': 0.053354, 'loss_vowel': 0.035891, 'loss_consonant': 0.026257, 'loss_word': 0.035048}\n",
      "   63 | 0.000029 | 160640/160735 | 8.2373 | 8.6280 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997016, 'recall_grapheme': 0.995294, 'recall_vowel': 0.998634, 'recall_consonant': 0.998842, 'recall_word': 0.99488, 'acc_grapheme': 0.995512, 'acc_vowel': 0.998579, 'acc_consonant': 0.998554, 'acc_word': 0.994839, 'loss_grapheme': 0.050531, 'loss_vowel': 0.030571, 'loss_consonant': 0.024269, 'loss_word': 0.036587}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.99802, 'recall_grapheme': 0.997051, 'recall_vowel': 0.998918, 'recall_consonant': 0.999062, 'recall_word': 0.996658, 'acc_grapheme': 0.997108, 'acc_vowel': 0.998828, 'acc_consonant': 0.999028, 'acc_word': 0.996634, 'loss_grapheme': 0.011997, 'loss_vowel': 0.005654, 'loss_consonant': 0.004505, 'loss_word': 0.013893}\n",
      "   64 | 0.000027 | 160640/160735 | 21.8352 | 9.1280 ||\n",
      "val: {'recall': 0.997013, 'recall_grapheme': 0.995243, 'recall_vowel': 0.998672, 'recall_consonant': 0.998893, 'recall_word': 0.994905, 'acc_grapheme': 0.995188, 'acc_vowel': 0.998529, 'acc_consonant': 0.998654, 'acc_word': 0.994814, 'loss_grapheme': 0.060236, 'loss_vowel': 0.036134, 'loss_consonant': 0.028753, 'loss_word': 0.039993}\n",
      "   65 | 0.000026 | 160640/160735 | 11.2755 | 9.1909 ||\n",
      "val: {'recall': 0.997129, 'recall_grapheme': 0.995635, 'recall_vowel': 0.99866, 'recall_consonant': 0.998587, 'recall_word': 0.995194, 'acc_grapheme': 0.995636, 'acc_vowel': 0.998554, 'acc_consonant': 0.998778, 'acc_word': 0.995063, 'loss_grapheme': 0.058647, 'loss_vowel': 0.037971, 'loss_consonant': 0.029799, 'loss_word': 0.038241}\n",
      "   66 | 0.000025 | 160640/160735 | 7.6136 | 8.2275 |||\n",
      "val: {'recall': 0.997286, 'recall_grapheme': 0.996086, 'recall_vowel': 0.998579, 'recall_consonant': 0.998392, 'recall_word': 0.99488, 'acc_grapheme': 0.995686, 'acc_vowel': 0.998554, 'acc_consonant': 0.998629, 'acc_word': 0.994739, 'loss_grapheme': 0.05219, 'loss_vowel': 0.032264, 'loss_consonant': 0.025293, 'loss_word': 0.036565}\n",
      "   67 | 0.000023 | 160640/160735 | 7.6662 | 9.3353 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996966, 'recall_grapheme': 0.995301, 'recall_vowel': 0.998901, 'recall_consonant': 0.998362, 'recall_word': 0.994668, 'acc_grapheme': 0.995213, 'acc_vowel': 0.998604, 'acc_consonant': 0.998479, 'acc_word': 0.994465, 'loss_grapheme': 0.053789, 'loss_vowel': 0.031313, 'loss_consonant': 0.024193, 'loss_word': 0.038026}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997974, 'recall_grapheme': 0.997068, 'recall_vowel': 0.998794, 'recall_consonant': 0.998965, 'recall_word': 0.996688, 'acc_grapheme': 0.997157, 'acc_vowel': 0.998803, 'acc_consonant': 0.999003, 'acc_word': 0.996659, 'loss_grapheme': 0.011955, 'loss_vowel': 0.00564, 'loss_consonant': 0.004495, 'loss_word': 0.013896}\n",
      "   68 | 0.000022 | 160640/160735 | 1.9978 | 8.9245 |||\n",
      "val: {'recall': 0.997038, 'recall_grapheme': 0.995451, 'recall_vowel': 0.998845, 'recall_consonant': 0.998405, 'recall_word': 0.9948, 'acc_grapheme': 0.995487, 'acc_vowel': 0.998554, 'acc_consonant': 0.998554, 'acc_word': 0.994639, 'loss_grapheme': 0.044183, 'loss_vowel': 0.024446, 'loss_consonant': 0.020402, 'loss_word': 0.031456}\n",
      "   69 | 0.000021 | 160640/160735 | 21.1337 | 8.4095 ||\n",
      "val: {'recall': 0.996927, 'recall_grapheme': 0.995515, 'recall_vowel': 0.998414, 'recall_consonant': 0.998264, 'recall_word': 0.994736, 'acc_grapheme': 0.995213, 'acc_vowel': 0.998354, 'acc_consonant': 0.998529, 'acc_word': 0.994589, 'loss_grapheme': 0.049525, 'loss_vowel': 0.027836, 'loss_consonant': 0.023422, 'loss_word': 0.038369}\n",
      "   70 | 0.000019 | 160640/160735 | 20.1163 | 8.8851 ||\n",
      "val: {'recall': 0.9978, 'recall_grapheme': 0.996927, 'recall_vowel': 0.998926, 'recall_consonant': 0.998419, 'recall_word': 0.99603, 'acc_grapheme': 0.996459, 'acc_vowel': 0.998728, 'acc_consonant': 0.998828, 'acc_word': 0.995986, 'loss_grapheme': 0.038109, 'loss_vowel': 0.026575, 'loss_consonant': 0.019645, 'loss_word': 0.026023}\n",
      "   71 | 0.000018 | 160640/160735 | 11.8021 | 8.9410 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997463, 'recall_grapheme': 0.996272, 'recall_vowel': 0.998771, 'recall_consonant': 0.998537, 'recall_word': 0.99553, 'acc_grapheme': 0.99601, 'acc_vowel': 0.998654, 'acc_consonant': 0.998778, 'acc_word': 0.995412, 'loss_grapheme': 0.050821, 'loss_vowel': 0.034892, 'loss_consonant': 0.026241, 'loss_word': 0.032325}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998052, 'recall_grapheme': 0.9971, 'recall_vowel': 0.998946, 'recall_consonant': 0.999062, 'recall_word': 0.996703, 'acc_grapheme': 0.997182, 'acc_vowel': 0.998853, 'acc_consonant': 0.999028, 'acc_word': 0.996684, 'loss_grapheme': 0.011912, 'loss_vowel': 0.005565, 'loss_consonant': 0.004457, 'loss_word': 0.01384}\n",
      "   72 | 0.000017 | 160640/160735 | 2.0109 | 8.9994 |||\n",
      "val: {'recall': 0.997586, 'recall_grapheme': 0.996245, 'recall_vowel': 0.99888, 'recall_consonant': 0.998975, 'recall_word': 0.995973, 'acc_grapheme': 0.996335, 'acc_vowel': 0.998803, 'acc_consonant': 0.998828, 'acc_word': 0.995886, 'loss_grapheme': 0.050827, 'loss_vowel': 0.033973, 'loss_consonant': 0.025404, 'loss_word': 0.031093}\n",
      "   73 | 0.000016 | 160640/160735 | 7.4387 | 8.8468 |||\n",
      "val: {'recall': 0.996989, 'recall_grapheme': 0.995392, 'recall_vowel': 0.99878, 'recall_consonant': 0.998391, 'recall_word': 0.995023, 'acc_grapheme': 0.995387, 'acc_vowel': 0.998604, 'acc_consonant': 0.998678, 'acc_word': 0.994913, 'loss_grapheme': 0.070664, 'loss_vowel': 0.044417, 'loss_consonant': 0.033055, 'loss_word': 0.047374}\n",
      "   74 | 0.000015 | 160640/160735 | 2.1403 | 8.8592 |||\n",
      "val: {'recall': 0.997188, 'recall_grapheme': 0.995704, 'recall_vowel': 0.998804, 'recall_consonant': 0.998542, 'recall_word': 0.995167, 'acc_grapheme': 0.995562, 'acc_vowel': 0.998703, 'acc_consonant': 0.998703, 'acc_word': 0.995063, 'loss_grapheme': 0.042593, 'loss_vowel': 0.025321, 'loss_consonant': 0.020188, 'loss_word': 0.030365}\n",
      "   75 | 0.000014 | 160640/160735 | 8.5010 | 8.8427 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997394, 'recall_grapheme': 0.996177, 'recall_vowel': 0.998738, 'recall_consonant': 0.998485, 'recall_word': 0.995365, 'acc_grapheme': 0.995986, 'acc_vowel': 0.998604, 'acc_consonant': 0.998803, 'acc_word': 0.995238, 'loss_grapheme': 0.050408, 'loss_vowel': 0.032651, 'loss_consonant': 0.024473, 'loss_word': 0.033021}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:27<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998044, 'recall_grapheme': 0.997128, 'recall_vowel': 0.998889, 'recall_consonant': 0.999031, 'recall_word': 0.996583, 'acc_grapheme': 0.997207, 'acc_vowel': 0.998803, 'acc_consonant': 0.999003, 'acc_word': 0.996559, 'loss_grapheme': 0.011925, 'loss_vowel': 0.00564, 'loss_consonant': 0.004484, 'loss_word': 0.013817}\n",
      "   76 | 0.000012 | 160640/160735 | 1.8405 | 8.8291 |||\n",
      "val: {'recall': 0.997465, 'recall_grapheme': 0.996347, 'recall_vowel': 0.998739, 'recall_consonant': 0.998428, 'recall_word': 0.995685, 'acc_grapheme': 0.996185, 'acc_vowel': 0.998629, 'acc_consonant': 0.998828, 'acc_word': 0.995636, 'loss_grapheme': 0.039625, 'loss_vowel': 0.028298, 'loss_consonant': 0.020769, 'loss_word': 0.026639}\n",
      "   77 | 0.000011 | 160640/160735 | 9.6821 | 9.0363 |||\n",
      "val: {'recall': 0.9973, 'recall_grapheme': 0.996012, 'recall_vowel': 0.998773, 'recall_consonant': 0.998404, 'recall_word': 0.995172, 'acc_grapheme': 0.995886, 'acc_vowel': 0.998678, 'acc_consonant': 0.998728, 'acc_word': 0.995038, 'loss_grapheme': 0.057538, 'loss_vowel': 0.034168, 'loss_consonant': 0.025667, 'loss_word': 0.040158}\n",
      "   78 | 0.000010 | 160640/160735 | 11.5792 | 8.5832 |\n",
      "val: {'recall': 0.996394, 'recall_grapheme': 0.994613, 'recall_vowel': 0.998214, 'recall_consonant': 0.998134, 'recall_word': 0.994192, 'acc_grapheme': 0.994814, 'acc_vowel': 0.99828, 'acc_consonant': 0.998255, 'acc_word': 0.994041, 'loss_grapheme': 0.096892, 'loss_vowel': 0.052126, 'loss_consonant': 0.0383, 'loss_word': 0.057486}\n",
      "   79 | 0.000010 | 160640/160735 | 21.9437 | 8.2446 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997681, 'recall_grapheme': 0.996498, 'recall_vowel': 0.998694, 'recall_consonant': 0.999035, 'recall_word': 0.9959, 'acc_grapheme': 0.996384, 'acc_vowel': 0.998678, 'acc_consonant': 0.998853, 'acc_word': 0.995811, 'loss_grapheme': 0.035235, 'loss_vowel': 0.02512, 'loss_consonant': 0.019056, 'loss_word': 0.023799}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998011, 'recall_grapheme': 0.997048, 'recall_vowel': 0.998918, 'recall_consonant': 0.999031, 'recall_word': 0.996656, 'acc_grapheme': 0.997207, 'acc_vowel': 0.998828, 'acc_consonant': 0.999003, 'acc_word': 0.996634, 'loss_grapheme': 0.011908, 'loss_vowel': 0.005572, 'loss_consonant': 0.004451, 'loss_word': 0.013828}\n",
      "   80 | 0.000009 | 160640/160735 | 2.3450 | 8.8601 |||\n",
      "val: {'recall': 0.997899, 'recall_grapheme': 0.996805, 'recall_vowel': 0.998877, 'recall_consonant': 0.999109, 'recall_word': 0.996164, 'acc_grapheme': 0.996559, 'acc_vowel': 0.998803, 'acc_consonant': 0.998953, 'acc_word': 0.996085, 'loss_grapheme': 0.054379, 'loss_vowel': 0.039566, 'loss_consonant': 0.028069, 'loss_word': 0.031889}\n",
      "   81 | 0.000008 | 160640/160735 | 1.9835 | 8.6459 |||\n",
      "val: {'recall': 0.997901, 'recall_grapheme': 0.996782, 'recall_vowel': 0.998808, 'recall_consonant': 0.999233, 'recall_word': 0.99619, 'acc_grapheme': 0.996634, 'acc_vowel': 0.998803, 'acc_consonant': 0.999077, 'acc_word': 0.996135, 'loss_grapheme': 0.040842, 'loss_vowel': 0.027611, 'loss_consonant': 0.020288, 'loss_word': 0.026552}\n",
      "   82 | 0.000007 | 160640/160735 | 1.8516 | 8.7672 ||\n",
      "val: {'recall': 0.996834, 'recall_grapheme': 0.995352, 'recall_vowel': 0.998754, 'recall_consonant': 0.997879, 'recall_word': 0.994888, 'acc_grapheme': 0.995362, 'acc_vowel': 0.998604, 'acc_consonant': 0.998504, 'acc_word': 0.994739, 'loss_grapheme': 0.083443, 'loss_vowel': 0.050922, 'loss_consonant': 0.038978, 'loss_word': 0.054421}\n",
      "   83 | 0.000006 | 160640/160735 | 2.3070 | 8.6041 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997848, 'recall_grapheme': 0.996644, 'recall_vowel': 0.998916, 'recall_consonant': 0.999187, 'recall_word': 0.996059, 'acc_grapheme': 0.996484, 'acc_vowel': 0.998878, 'acc_consonant': 0.999052, 'acc_word': 0.995986, 'loss_grapheme': 0.025879, 'loss_vowel': 0.017047, 'loss_consonant': 0.013309, 'loss_word': 0.019901}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997948, 'recall_grapheme': 0.997028, 'recall_vowel': 0.998671, 'recall_consonant': 0.999064, 'recall_word': 0.996607, 'acc_grapheme': 0.997157, 'acc_vowel': 0.998778, 'acc_consonant': 0.999028, 'acc_word': 0.996584, 'loss_grapheme': 0.011929, 'loss_vowel': 0.005588, 'loss_consonant': 0.004468, 'loss_word': 0.013834}\n",
      "   84 | 0.000005 | 160640/160735 | 16.1408 | 9.0102 ||\n",
      "val: {'recall': 0.997673, 'recall_grapheme': 0.996392, 'recall_vowel': 0.998874, 'recall_consonant': 0.999035, 'recall_word': 0.995477, 'acc_grapheme': 0.99606, 'acc_vowel': 0.998678, 'acc_consonant': 0.998828, 'acc_word': 0.995387, 'loss_grapheme': 0.042132, 'loss_vowel': 0.024127, 'loss_consonant': 0.019311, 'loss_word': 0.032291}\n",
      "   85 | 0.000005 | 160640/160735 | 19.9550 | 8.9163 ||\n",
      "val: {'recall': 0.997968, 'recall_grapheme': 0.996921, 'recall_vowel': 0.998807, 'recall_consonant': 0.99922, 'recall_word': 0.996111, 'acc_grapheme': 0.996634, 'acc_vowel': 0.998753, 'acc_consonant': 0.999052, 'acc_word': 0.996035, 'loss_grapheme': 0.044552, 'loss_vowel': 0.029784, 'loss_consonant': 0.021825, 'loss_word': 0.029211}\n",
      "   86 | 0.000004 | 160640/160735 | 8.5420 | 9.5426 |||\n",
      "val: {'recall': 0.996969, 'recall_grapheme': 0.995546, 'recall_vowel': 0.998732, 'recall_consonant': 0.998052, 'recall_word': 0.994914, 'acc_grapheme': 0.995412, 'acc_vowel': 0.998579, 'acc_consonant': 0.998579, 'acc_word': 0.994789, 'loss_grapheme': 0.06677, 'loss_vowel': 0.0396, 'loss_consonant': 0.030913, 'loss_word': 0.044593}\n",
      "   87 | 0.000004 | 160640/160735 | 19.2979 | 9.2974 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996942, 'recall_grapheme': 0.995337, 'recall_vowel': 0.99868, 'recall_consonant': 0.998414, 'recall_word': 0.995118, 'acc_grapheme': 0.995537, 'acc_vowel': 0.998629, 'acc_consonant': 0.998604, 'acc_word': 0.995038, 'loss_grapheme': 0.066001, 'loss_vowel': 0.044753, 'loss_consonant': 0.033921, 'loss_word': 0.041416}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997927, 'recall_grapheme': 0.997059, 'recall_vowel': 0.998627, 'recall_consonant': 0.998962, 'recall_word': 0.996657, 'acc_grapheme': 0.997182, 'acc_vowel': 0.998753, 'acc_consonant': 0.998978, 'acc_word': 0.996634, 'loss_grapheme': 0.011901, 'loss_vowel': 0.005614, 'loss_consonant': 0.004458, 'loss_word': 0.013799}\n",
      "   88 | 0.000003 | 160640/160735 | 19.2199 | 8.5160 ||\n",
      "val: {'recall': 0.998046, 'recall_grapheme': 0.99711, 'recall_vowel': 0.998797, 'recall_consonant': 0.999167, 'recall_word': 0.996344, 'acc_grapheme': 0.996883, 'acc_vowel': 0.998778, 'acc_consonant': 0.999077, 'acc_word': 0.99631, 'loss_grapheme': 0.037586, 'loss_vowel': 0.028347, 'loss_consonant': 0.020161, 'loss_word': 0.023736}\n",
      "   89 | 0.000002 | 160640/160735 | 18.0060 | 8.6625 |\n",
      "val: {'recall': 0.997872, 'recall_grapheme': 0.996743, 'recall_vowel': 0.998886, 'recall_consonant': 0.999116, 'recall_word': 0.996147, 'acc_grapheme': 0.996584, 'acc_vowel': 0.998803, 'acc_consonant': 0.998978, 'acc_word': 0.996085, 'loss_grapheme': 0.04489, 'loss_vowel': 0.030936, 'loss_consonant': 0.023228, 'loss_word': 0.027972}\n",
      "   90 | 0.000002 | 160640/160735 | 9.8619 | 9.1502 |||\n",
      "val: {'recall': 0.996906, 'recall_grapheme': 0.995403, 'recall_vowel': 0.998873, 'recall_consonant': 0.997945, 'recall_word': 0.994816, 'acc_grapheme': 0.995262, 'acc_vowel': 0.998629, 'acc_consonant': 0.998454, 'acc_word': 0.994689, 'loss_grapheme': 0.067034, 'loss_vowel': 0.039414, 'loss_consonant': 0.030584, 'loss_word': 0.046119}\n",
      "   91 | 0.000002 | 160640/160735 | 2.1033 | 7.8890 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997911, 'recall_grapheme': 0.996754, 'recall_vowel': 0.998926, 'recall_consonant': 0.999211, 'recall_word': 0.996026, 'acc_grapheme': 0.996559, 'acc_vowel': 0.998903, 'acc_consonant': 0.999003, 'acc_word': 0.995936, 'loss_grapheme': 0.032284, 'loss_vowel': 0.021595, 'loss_consonant': 0.01666, 'loss_word': 0.022384}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997988, 'recall_grapheme': 0.997049, 'recall_vowel': 0.998791, 'recall_consonant': 0.999064, 'recall_word': 0.996647, 'acc_grapheme': 0.997232, 'acc_vowel': 0.998828, 'acc_consonant': 0.999028, 'acc_word': 0.996634, 'loss_grapheme': 0.01191, 'loss_vowel': 0.005572, 'loss_consonant': 0.004438, 'loss_word': 0.013755}\n",
      "   92 | 0.000001 | 160640/160735 | 1.9749 | 8.6161 |||\n",
      "val: {'recall': 0.997185, 'recall_grapheme': 0.995699, 'recall_vowel': 0.998799, 'recall_consonant': 0.998542, 'recall_word': 0.994931, 'acc_grapheme': 0.995636, 'acc_vowel': 0.998678, 'acc_consonant': 0.998703, 'acc_word': 0.994789, 'loss_grapheme': 0.056269, 'loss_vowel': 0.035707, 'loss_consonant': 0.02702, 'loss_word': 0.037141}\n",
      "   93 | 0.000001 | 160640/160735 | 1.8694 | 8.2980 |||\n",
      "val: {'recall': 0.997616, 'recall_grapheme': 0.996274, 'recall_vowel': 0.998866, 'recall_consonant': 0.999048, 'recall_word': 0.995651, 'acc_grapheme': 0.99631, 'acc_vowel': 0.998828, 'acc_consonant': 0.998928, 'acc_word': 0.995562, 'loss_grapheme': 0.019701, 'loss_vowel': 0.010698, 'loss_consonant': 0.009311, 'loss_word': 0.01828}\n",
      "   94 | 0.000001 | 160640/160735 | 3.1445 | 8.2975 |||\n",
      "val: {'recall': 0.997706, 'recall_grapheme': 0.996612, 'recall_vowel': 0.99874, 'recall_consonant': 0.998861, 'recall_word': 0.995938, 'acc_grapheme': 0.996509, 'acc_vowel': 0.998728, 'acc_consonant': 0.998828, 'acc_word': 0.995886, 'loss_grapheme': 0.059546, 'loss_vowel': 0.043825, 'loss_consonant': 0.030605, 'loss_word': 0.034156}\n",
      "   95 | 0.000000 | 160640/160735 | 2.0680 | 9.0446 |||\n",
      "val: {'recall': 0.998075, 'recall_grapheme': 0.997116, 'recall_vowel': 0.99888, 'recall_consonant': 0.999186, 'recall_word': 0.996332, 'acc_grapheme': 0.996858, 'acc_vowel': 0.998828, 'acc_consonant': 0.999052, 'acc_word': 0.996285, 'loss_grapheme': 0.036512, 'loss_vowel': 0.024296, 'loss_consonant': 0.017471, 'loss_word': 0.024723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224.pth\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997943, 'recall_grapheme': 0.997016, 'recall_vowel': 0.998685, 'recall_consonant': 0.999053, 'recall_word': 0.996635, 'acc_grapheme': 0.997133, 'acc_vowel': 0.998828, 'acc_consonant': 0.998978, 'acc_word': 0.996609, 'loss_grapheme': 0.011976, 'loss_vowel': 0.005607, 'loss_consonant': 0.004486, 'loss_word': 0.013822}\n",
      "   96 | 0.000000 | 160640/160735 | 9.8643 | 9.0044 |||\n",
      "val: {'recall': 0.997682, 'recall_grapheme': 0.996641, 'recall_vowel': 0.998941, 'recall_consonant': 0.998506, 'recall_word': 0.995735, 'acc_grapheme': 0.99636, 'acc_vowel': 0.998778, 'acc_consonant': 0.998803, 'acc_word': 0.995661, 'loss_grapheme': 0.059761, 'loss_vowel': 0.039104, 'loss_consonant': 0.029299, 'loss_word': 0.038818}\n",
      "   97 | 0.000000 | 160640/160735 | 19.9404 | 8.4928 |\n",
      "val: {'recall': 0.997563, 'recall_grapheme': 0.996465, 'recall_vowel': 0.998837, 'recall_consonant': 0.998485, 'recall_word': 0.995742, 'acc_grapheme': 0.996135, 'acc_vowel': 0.998778, 'acc_consonant': 0.998828, 'acc_word': 0.995661, 'loss_grapheme': 0.055361, 'loss_vowel': 0.03997, 'loss_consonant': 0.028606, 'loss_word': 0.032515}\n",
      "   98 | 0.000000 | 160640/160735 | 11.5351 | 8.4553 ||\n",
      "val: {'recall': 0.997489, 'recall_grapheme': 0.996153, 'recall_vowel': 0.998661, 'recall_consonant': 0.998988, 'recall_word': 0.995201, 'acc_grapheme': 0.995786, 'acc_vowel': 0.998629, 'acc_consonant': 0.998728, 'acc_word': 0.995113, 'loss_grapheme': 0.049526, 'loss_vowel': 0.029056, 'loss_consonant': 0.02308, 'loss_word': 0.03469}\n",
      "   99 | 0.000000 | 160640/160735 | 2.2293 | 8.5496 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997499, 'recall_grapheme': 0.99629, 'recall_vowel': 0.998846, 'recall_consonant': 0.998568, 'recall_word': 0.995497, 'acc_grapheme': 0.995911, 'acc_vowel': 0.998753, 'acc_consonant': 0.998828, 'acc_word': 0.995387, 'loss_grapheme': 0.047245, 'loss_vowel': 0.028728, 'loss_consonant': 0.022107, 'loss_word': 0.035053}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998023, 'recall_grapheme': 0.997158, 'recall_vowel': 0.998808, 'recall_consonant': 0.998968, 'recall_word': 0.996716, 'acc_grapheme': 0.997282, 'acc_vowel': 0.998853, 'acc_consonant': 0.999003, 'acc_word': 0.996709, 'loss_grapheme': 0.011901, 'loss_vowel': 0.005588, 'loss_consonant': 0.004438, 'loss_word': 0.01375}\n",
      "CYCLE: 2\n",
      "    0 | 0.000020 | 160640/160735 | 1.3444 | 7.8680 |||\n",
      "val: {'recall': 0.997816, 'recall_grapheme': 0.996632, 'recall_vowel': 0.998872, 'recall_consonant': 0.999127, 'recall_word': 0.995885, 'acc_grapheme': 0.996409, 'acc_vowel': 0.998853, 'acc_consonant': 0.998878, 'acc_word': 0.995786, 'loss_grapheme': 0.056062, 'loss_vowel': 0.040345, 'loss_consonant': 0.029166, 'loss_word': 0.033006}\n",
      "    1 | 0.000040 | 160640/160735 | 10.3740 | 8.8890 ||\n",
      "val: {'recall': 0.99692, 'recall_grapheme': 0.995254, 'recall_vowel': 0.998737, 'recall_consonant': 0.998434, 'recall_word': 0.995173, 'acc_grapheme': 0.995711, 'acc_vowel': 0.998604, 'acc_consonant': 0.998728, 'acc_word': 0.995113, 'loss_grapheme': 0.073826, 'loss_vowel': 0.047549, 'loss_consonant': 0.03393, 'loss_word': 0.043367}\n",
      "    2 | 0.000060 | 160640/160735 | 7.9529 | 7.9951 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-b2c1bf117c1f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_start\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-b2c1bf117c1f>\u001b[0m in \u001b[0;36mvalidate_and_save\u001b[0;34m(model, model_file, val_loader, save)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbest_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbest_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-d19374fd65cb>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpreds2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpreds3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
