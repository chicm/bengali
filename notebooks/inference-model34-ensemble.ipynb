{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: timm\r\n",
      "Version: 0.1.16\r\n",
      "Summary: (Unofficial) PyTorch Image Models\r\n",
      "Home-page: https://github.com/rwightman/pytorch-image-models\r\n",
      "Author: Ross Wightman\r\n",
      "Author-email: hello@rwightman.com\r\n",
      "License: UNKNOWN\r\n",
      "Location: /mnt/chicm/anaconda3/lib/python3.7/site-packages\r\n",
      "Requires: torchvision, torch\r\n",
      "Required-by: cvcore\r\n"
     ]
    }
   ],
   "source": [
    "!pip show timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_APEX = False\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "if ENABLE_APEX:\n",
    "    !cd /kaggle/input/nvidia-apex &&  pip install --no-cache-dir --global-option=\"--cpp_ext\" \\\n",
    "        --global-option=\"--cuda_ext\" .\n",
    "    from apex import amp\n",
    "    BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR = '/kaggle/input/bengaliai-cv19'\n",
    "#MODEL_DIR = '/kaggle/input/model3-weights'\n",
    "\n",
    "DATA_DIR = '/mnt/chicm/data/bengali'\n",
    "#MODEL_DIR = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "#test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "#class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "#sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, img_df):\n",
    "        self.img_df = img_df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = 255 - self.img_df.iloc[idx].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loader(batch_size=4, idx=0):\n",
    "    img_df = pd.read_parquet(f'{DATA_DIR}/test_image_data_{idx}.parquet').set_index('image_id')\n",
    "\n",
    "    ds = BengaliDataset(img_df)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
    "    loader.num = len(ds)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet3(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet3, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_name(self.backbone_name, override_params={'num_classes': 1000})\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained=None)\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.size())\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliResNet(nn.Module):\n",
    "    def __init__(self, backbone_name='se_resnext50_32x4d'):\n",
    "        super(BengaliResNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.n_word = 1295\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant + self.n_word\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained=None)\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        self.num_p2_features = self.backbone.layer2[-1].se_module.fc2.out_channels\n",
    "        self.num_p3_features = self.backbone.layer3[-1].se_module.fc2.out_channels\n",
    "        self.p2_head = nn.Conv2d(self.num_p2_features, self.num_p2_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.p3_head = nn.Conv2d(self.num_p3_features, self.num_p3_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_p2_features * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_p3_features * 4)\n",
    "        self.act2 = Swish()\n",
    "        self.act3 = Swish()\n",
    "        \n",
    "        self.fc_aux1 = nn.Linear(self.num_p3_features * 4, self.num_classes)\n",
    "        self.fc_aux2 = nn.Linear(self.num_p2_features * 4, self.num_classes)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        for fc in [self.fc, self.fc_aux1, self.fc_aux2]:\n",
    "            nn.init.zeros_(fc.bias.data)\n",
    "\n",
    "        print('init model4')\n",
    "        \n",
    "    def features(self, x):\n",
    "        x = self.backbone.layer0(x); #print(x.size())\n",
    "        x = self.backbone.layer1(x); #print(x.size())\n",
    "        x = self.backbone.layer2(x); p2 = x; p2 = self.p2_head(p2); p2 = self.bn2(p2); p2 = self.act2(p2) #print(x.size())\n",
    "        x = self.backbone.layer3(x); p3 = x; p3 = self.p3_head(p3); p3 = self.bn3(p3); p3 = self.act3(p3) #print(x.size())\n",
    "        x = self.backbone.layer4(x); #print(x.size())\n",
    "        return x, p2, p3\n",
    "        \n",
    "    def logits(self, x, p2, p3):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        p2 = self.avg_pool(p2)\n",
    "        p2 = torch.flatten(p2, 1)\n",
    "        \n",
    "        p3 = self.avg_pool(p3)\n",
    "        p3 = torch.flatten(p3, 1)\n",
    "        return self.fc(x), self.fc_aux1(p3), self.fc_aux2(p2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x, p2, p3 = self.features(x)\n",
    "        x, logits_aux1, logits_aux2 = self.logits(x, p2, p3)\n",
    "\n",
    "        return x #, logits_aux1, logits_aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cfg = Namespace()\n",
    "cfg.MODEL_NAME = 'tf_efficientnet_b4'\n",
    "cfg.PRETRAINED = True\n",
    "cfg.IN_CHANNELS = 1\n",
    "cfg.POOL_TYPE = 'avg'\n",
    "cfg.CLS_HEAD = 'linear'\n",
    "cfg.MODEL_ACTIVATION = 'swish'\n",
    "cfg.DROP_CONNECT = 0.2\n",
    "cfg.DROPOUT= 0.\n",
    "cfg.NUM_WORD_CLASSES = 1295\n",
    "cfg.NUM_GRAPHEME_CLASSES = 168\n",
    "cfg.NUM_VOWEL_CLASSES = 11\n",
    "cfg.NUM_CONSONANT_CLASSES = 7\n",
    "cfg.CKP_NAME = 'model4_eb4_fold1.pth'\n",
    "'''\n",
    "class BengaliEfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNet B0-B8.\n",
    "    Args:\n",
    "        cfg (CfgNode): configs\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliEfficientNet, self).__init__()\n",
    "        #model_name = cfg.MODEL_NAME\n",
    "        pretrained = False\n",
    "        input_channels = 1\n",
    "        pool_type = 'avg'\n",
    "        drop_connect_rate = 0.2\n",
    "        self.drop_rate = 0.\n",
    "        cls_head = 'linear'\n",
    "        num_total_classes = 168+11+7+1295\n",
    "\n",
    "        backbone = timm.create_model(\n",
    "            model_name=backbone_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=input_channels,\n",
    "            drop_connect_rate=drop_connect_rate,\n",
    "        )\n",
    "        self.conv_stem = backbone.conv_stem\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.act1 = backbone.act1\n",
    "        ### Original blocks ###\n",
    "        for i in range(len((backbone.blocks))):\n",
    "            setattr(self, \"block{}\".format(str(i)), backbone.blocks[i])\n",
    "        self.conv_head = backbone.conv_head\n",
    "        self.bn2 = backbone.bn2\n",
    "        self.act2 = backbone.act2\n",
    "        self.aux_block5 = backbone.blocks[5]\n",
    "        self.aux_num_features = self.block5[-1].bn3.num_features\n",
    "        self.aux_head4 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act4 = Swish()\n",
    "        self.aux_head5 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act5 = Swish()\n",
    "        self.global_pool = SelectAdaptivePool2d(pool_type=pool_type)\n",
    "        self.num_features = backbone.num_features * self.global_pool.feat_mult()\n",
    "        assert cls_head == 'linear'\n",
    "        if cls_head == \"linear\":\n",
    "            ### Baseline head ###\n",
    "            self.fc = nn.Linear(self.num_features, num_total_classes)            \n",
    "            self.aux_fc1 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            self.aux_fc2 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            \n",
    "            for fc in [self.fc, self.aux_fc1, self.aux_fc2]:\n",
    "                nn.init.zeros_(fc.bias.data)\n",
    "        #elif cls_head == \"norm_softmax\":\n",
    "            ### NormSoftmax ###\n",
    "            #self.grapheme_fc = NormSoftmax(self.num_features, num_grapheme_classes)\n",
    "            #self.consonant_fc = NormSoftmax(self.num_features, num_consonant_classes)\n",
    "            #self.vowel_fc = NormSoftmax(self.num_features, num_vowel_classes)\n",
    "        # Replace with Mish activation\n",
    "        #if cfg.MODEL_ACTIVATION == \"mish\":\n",
    "        #    convert_swish_to_mish(self)\n",
    "        #del backbone\n",
    "\n",
    "    def _features(self, x):\n",
    "        x = self.conv_stem(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x); b4 = x\n",
    "        x = self.block5(x); b4 = self.aux_block5(b4); b5 = x\n",
    "        x = self.block6(x)\n",
    "        x = self.conv_head(x); b4 = self.aux_head4(b4); b5 = self.aux_head5(b5)\n",
    "        x = self.bn2(x); b4 = self.bn4(b4); b5 = self.bn5(b5)\n",
    "        x = self.act2(x); b4 = self.act4(b4); b5 = self.act5(b5)\n",
    "        return b4, b5, x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.clone()\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "\n",
    "        # _, _, x = self._features(x)\n",
    "        b4, b5, x = self._features(x)\n",
    "        x = self.global_pool(x); b4 = self.global_pool(b4); b5 = self.global_pool(b5)\n",
    "        x = torch.flatten(x, 1); b4 = torch.flatten(b4, 1); b5 = torch.flatten(b5, 1)\n",
    "        if self.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.drop_rate, training=self.training)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        aux_logits1 = self.aux_fc1(b4)\n",
    "        aux_logits2 = self.aux_fc2(b5)\n",
    "        \n",
    "        return logits #, aux_logits1, aux_logits2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, model_file, model_type):\n",
    "    if model_type == 'BengaliNet3':\n",
    "        model = BengaliNet3(backbone_name=backbone)\n",
    "    elif model_type == 'BengaliEfficientNet':\n",
    "        model = BengaliEfficientNet(backbone_name=backbone)\n",
    "    elif model_type == 'BengaliResNet':\n",
    "        model = BengaliResNet(backbone_name=backbone)\n",
    "    else:\n",
    "        raise ValueError('wrong model type')\n",
    "    #model_file = os.path.join(MODEL_DIR, ckp_name)\n",
    "\n",
    "    assert os.path.exists(model_file)\n",
    "    print('loading {}...'.format(model_file))\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    models = []\n",
    "    for backbone, model_file, model_type in ckp_list:\n",
    "        model = create_model(backbone, model_file, model_type).cuda()\n",
    "        if ENABLE_APEX:\n",
    "            model = amp.initialize(model, None, opt_level=\"O1\",verbosity=0)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se_resnext50_32x4d  tf_efficientnet_b4\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./model4-ckps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model4_eb4_fold1_cv997705.pth\t   model4_se_resnext50_fold0_224_cv9976.pth\r\n",
      "model4_eb4_fold1_cv998144.pth\t   model4_se_resnext50_fold0_224_cv9977.pth\r\n",
      "model4_eb4_fold2_cv9976.pth\t   model4_se_resnext50_fold0_224_cv9978.pth\r\n",
      "model4_eb4_fold3_cv9971.pth\t   model4_se_resnext50_fold0_224_cv998106.pth\r\n",
      "model4_eb4_fold3_cv998185_swa.pth  model4_se_resnext50_fold4_224_cv997979.pth\r\n",
      "model4_eb4_fold3_cv998307_swa.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/model4-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3_se_resnext50_fold0_mixup_cutmix_224_gridmask_cv9974.pth\r\n",
      "model3_se_resnext50_fold0_mixup_cutmix_224_gridmask_cv9976.pth\r\n",
      "model3_se_resnext50_fold1_mixup_cutmix_224_gridmask_cv9965.pth\r\n",
      "model3_se_resnext50_fold1_mixup_cutmix_224_gridmask_cv9970.pth\r\n",
      "model3_se_resnext50_fold4_mixup_cutmix_224_gridmask_cv9974.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/model3-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_list = [\n",
    "    ('se_resnext50_32x4d', './model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold0_224_cv998106.pth', 'BengaliResNet'), # lb 9886\n",
    "    ('tf_efficientnet_b4', './model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_cv998144.pth', 'BengaliEfficientNet'),  # lb9881\n",
    "    ('tf_efficientnet_b4', './model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_cv998185_swa.pth', 'BengaliEfficientNet'),  # lb9891\n",
    "    ('tf_efficientnet_b4', './model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_cv9976.pth', 'BengaliEfficientNet'),  # lb9889\n",
    "    ('se_resnext50_32x4d', './model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224_cv997979.pth', 'BengaliResNet') # lb 9882\n",
    "    #('se_resnext50_32x4d', '/kaggle/input/model4-weights/model4_se_resnext50_fold0_224_cv9977.pth', 'BengaliResNet'), # lb 9884\n",
    "    #('se_resnext50_32x4d', '/kaggle/input/model3-weights/model3_se_resnext50_fold4_mixup_cutmix_224_gridmask_cv9974.pth', 'BengaliNet3'), # lb 9877\n",
    "    #('tf_efficientnet_b4', './model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_cv998307_swa.pth', 'BengaliEfficientNet')  # lb9892\n",
    "]\n",
    "#model_weights = [0.3, 0.3, 0.4]\n",
    "#model_weights = [0.5, 0.5]\n",
    "#model_weights = [1.]\n",
    "model_weights = [0.2, 0.15, 0.25, 0.25, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, test_loader):\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x in test_loader:\n",
    "            x = x.cuda()\n",
    "            outputs0, outputs1, outputs2 = [], [], []\n",
    "            for i, model in enumerate(models):\n",
    "                output = model(x.clone())\n",
    "                print(i, output.cpu().numpy())\n",
    "                output = torch.split(output[:, :186], [168, 11, 7], dim=1)\n",
    "                outputs0.append(torch.softmax(output[0], dim=1).cpu().numpy())\n",
    "                outputs1.append(torch.softmax(output[1], dim=1).cpu().numpy())\n",
    "                outputs2.append(torch.softmax(output[2], dim=1).cpu().numpy())\n",
    "            outputs0 = np.average(outputs0, 0, weights=model_weights)\n",
    "            outputs1 = np.average(outputs1, 0, weights=model_weights)\n",
    "            outputs2 = np.average(outputs2, 0, weights=model_weights)\n",
    "            \n",
    "            preds0.append(np.argmax(outputs0, 1))\n",
    "            preds1.append(np.argmax(outputs1, 1))\n",
    "            preds2.append(np.argmax(outputs2, 1))\n",
    "            #preds = get_predictions(outputs0, outputs1, outputs2)\n",
    "            #preds0.append(preds[0])\n",
    "            #preds1.append(preds[1])\n",
    "            #preds2.append(preds[2])\n",
    "            \n",
    "            \n",
    "    preds0 = np.concatenate(preds0, 0)\n",
    "    preds1 = np.concatenate(preds1, 0)\n",
    "    preds2 = np.concatenate(preds2, 0)\n",
    "    \n",
    "    return preds0, preds1, preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model4\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold0_224_cv998106.pth...\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold1_cv998144.pth...\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_cv998185_swa.pth...\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_cv9976.pth...\n",
      "init model4\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold4_224_cv997979.pth...\n"
     ]
    }
   ],
   "source": [
    "models = create_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ -7.1862817   -7.810594    -4.8198237  ...  -0.8179925   -0.19777063\n",
      "   -1.4713253 ]\n",
      " [-10.734917   -11.806205    -9.45489    ...  -1.3461176   -1.3830768\n",
      "   -2.1137755 ]\n",
      " [ -6.3235493   -7.6116095   -6.1489162  ...  -0.04808476  -0.15125619\n",
      "   -0.95830286]]\n",
      "1 [[-2.6705704  -2.517937    1.3185531  ... -0.9167047  -0.52865475\n",
      "  -1.770554  ]\n",
      " [-3.2127757  -3.5128353  -2.142935   ... -0.4858613  -1.6771361\n",
      "  -1.5057656 ]\n",
      " [-1.9421563  -2.1973522  -1.5409075  ...  0.7223144  -0.49772972\n",
      "  -0.83899623]]\n",
      "2 [[-1.9815211  -2.3962836   1.8050307  ...  0.41863483 -0.03356555\n",
      "  -1.1492089 ]\n",
      " [-3.0018673  -3.3024516  -2.4305837  ... -0.40422902 -0.93963295\n",
      "  -0.61511666]\n",
      " [-1.7645657  -2.323179   -1.6421713  ...  0.4624252  -0.86281157\n",
      "  -0.55969614]]\n",
      "3 [[-2.8739367  -1.683599    1.6972646  ...  0.10131954  0.1774449\n",
      "  -0.8141838 ]\n",
      " [-3.6307256  -2.5702085  -2.1647127  ... -0.4519977  -0.83477646\n",
      "  -1.1875901 ]\n",
      " [-1.7564092  -1.4671712  -0.9772157  ...  0.57132506 -0.07662015\n",
      "  -1.2050614 ]]\n",
      "4 [[-5.551262  -5.785081  -4.0948625 ... -1.5669893 -1.2182308 -2.5189176]\n",
      " [-5.777696  -6.0676913 -4.96182   ... -1.4195246 -1.8490022 -2.2009003]\n",
      " [-6.5306387 -5.1900597 -4.015188  ... -1.1841973 -1.9502436 -2.0830255]]\n",
      "0 [[-8.059809   -7.86163    -4.588019   ... -0.28205454 -1.8065289\n",
      "  -2.202515  ]\n",
      " [-6.401383   -7.571383   -7.42809    ... -0.39378995 -1.7965508\n",
      "  -2.6123462 ]\n",
      " [-6.699834   -6.668283   -5.612072   ... -0.49784404 -0.8903008\n",
      "  -2.3487523 ]]\n",
      "1 [[-3.2611306  -3.6755974   0.15533485 ...  0.17834634 -1.6347324\n",
      "  -2.96749   ]\n",
      " [-1.6300013  -1.2327821  -2.7795794  ... -0.13245663 -1.1140065\n",
      "  -1.1354824 ]\n",
      " [-3.3921218  -3.1252527  -1.3248788  ...  0.5028636  -1.2045035\n",
      "  -1.9073625 ]]\n",
      "2 [[-4.1630816  -3.6187284   0.17257023 ... -1.2305492  -2.069665\n",
      "  -2.4557526 ]\n",
      " [-2.6643453  -3.1623561  -1.7414362  ... -0.4931431  -0.7689832\n",
      "  -1.1394364 ]\n",
      " [-3.10076    -3.202427   -1.6731133  ... -0.31856272 -1.120518\n",
      "  -1.7250777 ]]\n",
      "3 [[-3.599402   -2.3611097   0.18198377 ...  0.6890877  -1.0891328\n",
      "  -2.8407648 ]\n",
      " [-1.1345098  -1.221085   -2.1812642  ...  0.10280535 -0.9225764\n",
      "  -0.7418132 ]\n",
      " [-3.4843976  -2.7565088  -2.2552967  ... -0.06568424 -1.5142089\n",
      "  -2.015525  ]]\n",
      "4 [[-6.374789   -7.311377   -1.7511898  ... -0.10254803 -1.8670219\n",
      "  -3.0400796 ]\n",
      " [-3.9997904  -5.563684   -6.1535316  ... -1.6642867  -2.2904618\n",
      "  -3.0252404 ]\n",
      " [-6.2733665  -6.585283   -5.6185803  ... -1.553297   -1.9448736\n",
      "  -3.2956383 ]]\n",
      "0 [[-7.6205444  -7.1578755  -6.435188   ... -0.6233      1.8118263\n",
      "  -2.1573842 ]\n",
      " [-7.841884   -8.444308   -5.9389844  ...  1.2010179  -1.070295\n",
      "  -1.7561125 ]\n",
      " [-7.8731084  -8.802391   -6.76936    ...  0.02021349  2.205983\n",
      "  -1.0170838 ]]\n",
      "1 [[-3.136212   -3.0786097  -1.6358032  ... -0.515283    1.1381434\n",
      "  -1.7093414 ]\n",
      " [-3.116718   -2.2679043  -2.1944911  ...  0.5219466  -0.70555794\n",
      "  -1.1833876 ]\n",
      " [-2.7618997  -3.0357182  -2.0263894  ...  0.98101866  2.257431\n",
      "  -0.947987  ]]\n",
      "2 [[-3.584045   -3.5256333  -2.3599143  ... -0.5943073   0.32120028\n",
      "  -0.10669224]\n",
      " [-2.1545324  -3.073289   -1.950397   ...  0.63448155 -0.33607846\n",
      "  -0.72417825]\n",
      " [-2.5658965  -3.059737   -1.3301737  ...  0.04588587  2.2594516\n",
      "  -1.2172878 ]]\n",
      "3 [[-1.8734746  -2.8732915  -0.7773968  ...  0.49059683  1.9874496\n",
      "  -0.41183412]\n",
      " [-2.6842942  -2.7795134  -1.7300556  ...  0.9316405  -0.663863\n",
      "  -0.82204324]\n",
      " [-2.8197932  -2.6598098  -1.4742347  ...  1.1284032   3.1524918\n",
      "  -0.7613689 ]]\n",
      "4 [[-6.5613723 -5.335522  -5.5337124 ... -1.9614574  2.1875026 -2.0515795]\n",
      " [-5.3124943 -5.6355166 -5.0362077 ...  2.5112627 -0.7794585 -1.7754916]\n",
      " [-5.8702555 -5.973474  -5.975915  ... -1.3604523  3.311223  -2.3363817]]\n",
      "0 [[-7.4465446 -7.598721  -7.5197463 ... -0.3495463 -0.7670226 -1.9803432]\n",
      " [-9.648492  -9.031142  -7.9966025 ... -1.5587182 -1.2686116  3.4094312]\n",
      " [-8.091598  -7.8953094 -6.54081   ... -1.0621816 -0.9115544 -1.7945088]]\n",
      "1 [[-3.4892685  -4.288116   -2.0380101  ...  0.52261    -0.26366994\n",
      "  -0.47987977]\n",
      " [-2.3554623  -3.292238   -2.1479983  ... -0.80427974 -0.66702956\n",
      "   3.641059  ]\n",
      " [-3.7339096  -3.9576027  -0.4219153  ...  0.38416222 -0.82011455\n",
      "  -0.79580146]]\n",
      "2 [[-1.1741327  -2.6963952  -1.2545342  ... -0.1334528  -0.43743262\n",
      "  -1.0867112 ]\n",
      " [-3.4942737  -3.3348353  -0.83675057 ... -0.29198718 -0.00458399\n",
      "   1.2165972 ]\n",
      " [-2.3303752  -3.152591   -1.2400956  ... -0.07229826 -0.74317056\n",
      "  -0.65666854]]\n",
      "3 [[-2.9233952  -3.909344   -1.8719174  ... -1.3790128  -0.7894496\n",
      "  -2.395862  ]\n",
      " [-2.4501138  -2.974061   -2.4754174  ... -0.73111653 -0.94749844\n",
      "   3.2835867 ]\n",
      " [-3.427409   -4.8262725  -2.586266   ... -1.0050374  -2.1204722\n",
      "  -2.352977  ]]\n",
      "4 [[-4.976813   -4.4282846  -4.770301   ... -1.3815757  -0.09538471\n",
      "  -2.6101835 ]\n",
      " [-6.278336   -5.4690747  -4.585597   ... -2.095321   -2.4579782\n",
      "   4.6383505 ]\n",
      " [-6.892337   -7.2748146  -5.7027454  ... -2.3150787  -1.5939736\n",
      "  -2.0493402 ]]\n"
     ]
    }
   ],
   "source": [
    "# outputs for  model2, model1\n",
    "import gc\n",
    "\n",
    "preds0, preds1, preds2 = [], [], []\n",
    "\n",
    "for i in range(4):\n",
    "    test_loader = get_test_loader(batch_size=BATCH_SIZE, idx=i)\n",
    "    p0, p1, p2 = predict(models, test_loader)\n",
    "    preds0.append(p0)\n",
    "    preds1.append(p1)\n",
    "    preds2.append(p2)\n",
    "    del test_loader\n",
    "    gc.collect()\n",
    "    \n",
    "preds0 = np.concatenate(preds0, 0)\n",
    "preds1 = np.concatenate(preds1, 0)\n",
    "preds2 = np.concatenate(preds2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[-1.9815211  -2.3962836   1.8050307  ...  0.41863483 -0.03356555\n",
      "  -1.1492089 ]\n",
      " [-3.0018673  -3.3024516  -2.4305837  ... -0.40422902 -0.93963295\n",
      "  -0.61511666]\n",
      " [-1.7645657  -2.323179   -1.6421713  ...  0.4624252  -0.86281157\n",
      "  -0.55969614]]\n",
      "0 [[-4.1630816  -3.6187284   0.17257023 ... -1.2305492  -2.069665\n",
      "  -2.4557526 ]\n",
      " [-2.6643453  -3.1623561  -1.7414362  ... -0.4931431  -0.7689832\n",
      "  -1.1394364 ]\n",
      " [-3.10076    -3.202427   -1.6731133  ... -0.31856272 -1.120518\n",
      "  -1.7250777 ]]\n",
      "0 [[-3.584045   -3.5256333  -2.3599143  ... -0.5943073   0.32120028\n",
      "  -0.10669224]\n",
      " [-2.1545324  -3.073289   -1.950397   ...  0.63448155 -0.33607846\n",
      "  -0.72417825]\n",
      " [-2.5658965  -3.059737   -1.3301737  ...  0.04588587  2.2594516\n",
      "  -1.2172878 ]]\n",
      "0 [[-1.1741327  -2.6963952  -1.2545342  ... -0.1334528  -0.43743262\n",
      "  -1.0867112 ]\n",
      " [-3.4942737  -3.3348353  -0.83675057 ... -0.29198718 -0.00458399\n",
      "   1.2165972 ]\n",
      " [-2.3303752  -3.152591   -1.2400956  ... -0.07229826 -0.74317056\n",
      "  -0.65666854]]\n"
     ]
    }
   ],
   "source": [
    "# outputs for  model2\n",
    "import gc\n",
    "\n",
    "preds0, preds1, preds2 = [], [], []\n",
    "\n",
    "for i in range(4):\n",
    "    test_loader = get_test_loader(batch_size=BATCH_SIZE, idx=i)\n",
    "    p0, p1, p2 = predict(models, test_loader)\n",
    "    preds0.append(p0)\n",
    "    preds1.append(p1)\n",
    "    preds2.append(p2)\n",
    "    del test_loader\n",
    "    gc.collect()\n",
    "    \n",
    "preds0 = np.concatenate(preds0, 0)\n",
    "preds1 = np.concatenate(preds1, 0)\n",
    "preds2 = np.concatenate(preds2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[-2.8739367  -1.683599    1.6972646  ...  0.10131954  0.1774449\n",
      "  -0.8141838 ]\n",
      " [-3.6307256  -2.5702085  -2.1647127  ... -0.4519977  -0.83477646\n",
      "  -1.1875901 ]\n",
      " [-1.7564092  -1.4671712  -0.9772157  ...  0.57132506 -0.07662015\n",
      "  -1.2050614 ]]\n",
      "0 [[-3.599402   -2.3611097   0.18198377 ...  0.6890877  -1.0891328\n",
      "  -2.8407648 ]\n",
      " [-1.1345098  -1.221085   -2.1812642  ...  0.10280535 -0.9225764\n",
      "  -0.7418132 ]\n",
      " [-3.4843976  -2.7565088  -2.2552967  ... -0.06568424 -1.5142089\n",
      "  -2.015525  ]]\n",
      "0 [[-1.8734746  -2.8732915  -0.7773968  ...  0.49059683  1.9874496\n",
      "  -0.41183412]\n",
      " [-2.6842942  -2.7795134  -1.7300556  ...  0.9316405  -0.663863\n",
      "  -0.82204324]\n",
      " [-2.8197932  -2.6598098  -1.4742347  ...  1.1284032   3.1524918\n",
      "  -0.7613689 ]]\n",
      "0 [[-2.9233952  -3.909344   -1.8719174  ... -1.3790128  -0.7894496\n",
      "  -2.395862  ]\n",
      " [-2.4501138  -2.974061   -2.4754174  ... -0.73111653 -0.94749844\n",
      "   3.2835867 ]\n",
      " [-3.427409   -4.8262725  -2.586266   ... -1.0050374  -2.1204722\n",
      "  -2.352977  ]]\n"
     ]
    }
   ],
   "source": [
    "# outputs for  model1\n",
    "import gc\n",
    "\n",
    "preds0, preds1, preds2 = [], [], []\n",
    "\n",
    "for i in range(4):\n",
    "    test_loader = get_test_loader(batch_size=BATCH_SIZE, idx=i)\n",
    "    p0, p1, p2 = predict(models, test_loader)\n",
    "    preds0.append(p0)\n",
    "    preds1.append(p1)\n",
    "    preds2.append(p2)\n",
    "    del test_loader\n",
    "    gc.collect()\n",
    "    \n",
    "preds0 = np.concatenate(preds0, 0)\n",
    "preds1 = np.concatenate(preds1, 0)\n",
    "preds2 = np.concatenate(preds2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[-2.8739367  -1.683599    1.6972646  ...  0.10131954  0.1774449\n",
      "  -0.8141838 ]\n",
      " [-3.6307256  -2.5702085  -2.1647127  ... -0.4519977  -0.83477646\n",
      "  -1.1875901 ]\n",
      " [-1.7564092  -1.4671712  -0.9772157  ...  0.57132506 -0.07662015\n",
      "  -1.2050614 ]]\n",
      "1 [[-1138.3181    -1200.3625     -637.5423    ...  -443.79025\n",
      "   -169.7639     -324.2416   ]\n",
      " [ -417.66345    -511.23328    -278.062     ...   -86.338554\n",
      "    -67.46889       2.6422465]\n",
      " [ -857.3012    -1186.0989     -561.0034    ...   -76.796364\n",
      "   -310.8326     -187.83319  ]]\n",
      "0 [[-3.599402   -2.3611097   0.18198377 ...  0.6890877  -1.0891328\n",
      "  -2.8407648 ]\n",
      " [-1.1345098  -1.221085   -2.1812642  ...  0.10280535 -0.9225764\n",
      "  -0.7418132 ]\n",
      " [-3.4843976  -2.7565088  -2.2552967  ... -0.06568424 -1.5142089\n",
      "  -2.015525  ]]\n",
      "1 [[ -966.835    -1082.6678    -423.4504   ...  -558.5766    -586.00464\n",
      "   -331.2461  ]\n",
      " [ -237.67717   -386.17957   -189.19699  ...   -34.76139    -51.678402\n",
      "    -30.83259 ]\n",
      " [ -113.84788   -155.35092    -84.28233  ...   -22.731848   -18.968098\n",
      "      4.566693]]\n",
      "0 [[-1.8734746  -2.8732915  -0.7773968  ...  0.49059683  1.9874496\n",
      "  -0.41183412]\n",
      " [-2.6842942  -2.7795134  -1.7300556  ...  0.9316405  -0.663863\n",
      "  -0.82204324]\n",
      " [-2.8197932  -2.6598098  -1.4742347  ...  1.1284032   3.1524918\n",
      "  -0.7613689 ]]\n",
      "1 [[-241.73068   -315.53937   -251.28331   ...  -45.60047   -129.73186\n",
      "   -52.22321  ]\n",
      " [ -80.019806  -106.57856    -56.88007   ...  -27.005728   -27.724176\n",
      "    -4.4800744]\n",
      " [ -24.912333   -33.09412    -16.444202  ...   -8.702986   -10.49335\n",
      "    -2.8794963]]\n",
      "0 [[-2.9233952  -3.909344   -1.8719174  ... -1.3790128  -0.7894496\n",
      "  -2.395862  ]\n",
      " [-2.4501138  -2.974061   -2.4754174  ... -0.73111653 -0.94749844\n",
      "   3.2835867 ]\n",
      " [-3.427409   -4.8262725  -2.586266   ... -1.0050374  -2.1204722\n",
      "  -2.352977  ]]\n",
      "1 [[ -25.072083   -31.358143   -15.016762  ...   -9.771925   -15.1083145\n",
      "    -6.377562 ]\n",
      " [-101.62849   -125.56024    -60.722412  ...   -4.4332604   12.668281\n",
      "    36.585903 ]\n",
      " [ -19.103073   -28.074745   -13.542072  ...  -13.8088255  -12.185351\n",
      "    -7.966365 ]]\n"
     ]
    }
   ],
   "source": [
    "# outputs for 2 models\n",
    "import gc\n",
    "\n",
    "preds0, preds1, preds2 = [], [], []\n",
    "\n",
    "for i in range(4):\n",
    "    test_loader = get_test_loader(batch_size=BATCH_SIZE, idx=i)\n",
    "    p0, p1, p2 = predict(models, test_loader)\n",
    "    preds0.append(p0)\n",
    "    preds1.append(p1)\n",
    "    preds2.append(p2)\n",
    "    del test_loader\n",
    "    gc.collect()\n",
    "    \n",
    "preds0 = np.concatenate(preds0, 0)\n",
    "preds1 = np.concatenate(preds1, 0)\n",
    "preds2 = np.concatenate(preds2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 66225.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id  target\n",
       "0        Test_0_grapheme_root       3\n",
       "1      Test_0_vowel_diacritic       0\n",
       "2  Test_0_consonant_diacritic       0\n",
       "3        Test_1_grapheme_root      93\n",
       "4      Test_1_vowel_diacritic       2"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_id = []\n",
    "target = []\n",
    "for i in tqdm(range(len(preds0))):\n",
    "    row_id += [f'Test_{i}_grapheme_root', f'Test_{i}_vowel_diacritic',\n",
    "               f'Test_{i}_consonant_diacritic']\n",
    "    target += [preds0[i], preds1[i], preds2[i]]\n",
    "submission_df = pd.DataFrame({'row_id': row_id, 'target': target})\n",
    "#submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Test_2_grapheme_root</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Test_2_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Test_2_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Test_3_grapheme_root</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Test_3_vowel_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Test_3_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Test_4_grapheme_root</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Test_4_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Test_4_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Test_5_grapheme_root</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Test_5_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Test_5_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Test_6_grapheme_root</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Test_6_vowel_diacritic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Test_6_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Test_7_grapheme_root</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Test_7_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Test_7_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Test_8_grapheme_root</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Test_8_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Test_8_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Test_9_grapheme_root</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Test_9_vowel_diacritic</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Test_9_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Test_10_grapheme_root</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Test_10_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Test_10_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Test_11_grapheme_root</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Test_11_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Test_11_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id  target\n",
       "0          Test_0_grapheme_root     148\n",
       "1        Test_0_vowel_diacritic       0\n",
       "2    Test_0_consonant_diacritic       0\n",
       "3          Test_1_grapheme_root     107\n",
       "4        Test_1_vowel_diacritic       1\n",
       "5    Test_1_consonant_diacritic       0\n",
       "6          Test_2_grapheme_root     107\n",
       "7        Test_2_vowel_diacritic       1\n",
       "8    Test_2_consonant_diacritic       0\n",
       "9          Test_3_grapheme_root      89\n",
       "10       Test_3_vowel_diacritic       4\n",
       "11   Test_3_consonant_diacritic       0\n",
       "12         Test_4_grapheme_root     107\n",
       "13       Test_4_vowel_diacritic       1\n",
       "14   Test_4_consonant_diacritic       0\n",
       "15         Test_5_grapheme_root     107\n",
       "16       Test_5_vowel_diacritic       1\n",
       "17   Test_5_consonant_diacritic       0\n",
       "18         Test_6_grapheme_root      71\n",
       "19       Test_6_vowel_diacritic       7\n",
       "20   Test_6_consonant_diacritic       0\n",
       "21         Test_7_grapheme_root     137\n",
       "22       Test_7_vowel_diacritic       1\n",
       "23   Test_7_consonant_diacritic       0\n",
       "24         Test_8_grapheme_root     119\n",
       "25       Test_8_vowel_diacritic       9\n",
       "26   Test_8_consonant_diacritic       0\n",
       "27         Test_9_grapheme_root     133\n",
       "28       Test_9_vowel_diacritic      10\n",
       "29   Test_9_consonant_diacritic       0\n",
       "30        Test_10_grapheme_root      13\n",
       "31      Test_10_vowel_diacritic       1\n",
       "32  Test_10_consonant_diacritic       0\n",
       "33        Test_11_grapheme_root      21\n",
       "34      Test_11_vowel_diacritic       2\n",
       "35  Test_11_consonant_diacritic       0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
