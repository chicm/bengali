{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image\n",
    "from utils import bn_update, moving_average, copy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.data.auto_augment import Invert, RandAugment, AugmentAndMix\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from augmix import RandomAugMix\n",
    "import albumentations as albu\n",
    "\n",
    "class RandAug(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=False, p=1.):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.aug = RandAugment(n=2, m=27)\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        return np.asarray(self.aug(Image.fromarray(image))).astype(np.uint8)\n",
    "\n",
    "train_aug = albu.Compose([\n",
    "    RandAug(p=1.),\n",
    "    #RandomAugMix(severity=3, width=3, alpha=1., p=1.)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augs():\n",
    "    #return RandAugment(n=2, m=27)\n",
    "    return train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arange(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image'].astype(np.uint8)\n",
    "            #img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in train_loader:\n",
    "#    print(x)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "class BengaliNet4(nn.Module):\n",
    "    def __init__(self, backbone_name='se_resnext50_32x4d'):\n",
    "        super(BengaliNet4, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.n_word = 1295\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant + self.n_word\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        self.num_p2_features = self.backbone.layer2[-1].se_module.fc2.out_channels\n",
    "        self.num_p3_features = self.backbone.layer3[-1].se_module.fc2.out_channels\n",
    "        self.p2_head = nn.Conv2d(self.num_p2_features, self.num_p2_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.p3_head = nn.Conv2d(self.num_p3_features, self.num_p3_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_p2_features * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_p3_features * 4)\n",
    "        self.act2 = Swish()\n",
    "        self.act3 = Swish()\n",
    "        \n",
    "        self.fc_aux1 = nn.Linear(self.num_p3_features * 4, self.num_classes)\n",
    "        self.fc_aux2 = nn.Linear(self.num_p2_features * 4, self.num_classes)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        for fc in [self.fc, self.fc_aux1, self.fc_aux2]:\n",
    "            nn.init.zeros_(fc.bias.data)\n",
    "\n",
    "        print('init model4')\n",
    "        \n",
    "    def features(self, x):\n",
    "        x = self.backbone.layer0(x); #print(x.size())\n",
    "        x = self.backbone.layer1(x); #print(x.size())\n",
    "        x = self.backbone.layer2(x); p2 = x; p2 = self.p2_head(p2); p2 = self.bn2(p2); p2 = self.act2(p2) #print(x.size())\n",
    "        x = self.backbone.layer3(x); p3 = x; p3 = self.p3_head(p3); p3 = self.bn3(p3); p3 = self.act3(p3) #print(x.size())\n",
    "        x = self.backbone.layer4(x); #print(x.size())\n",
    "        return x, p2, p3\n",
    "        \n",
    "    def logits(self, x, p2, p3):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        p2 = self.avg_pool(p2)\n",
    "        p2 = torch.flatten(p2, 1)\n",
    "        \n",
    "        p3 = self.avg_pool(p3)\n",
    "        p3 = torch.flatten(p3, 1)\n",
    "        return self.fc(x), self.fc_aux1(p3), self.fc_aux2(p2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x, p2, p3 = self.features(x)\n",
    "        x, logits_aux1, logits_aux2 = self.logits(x, p2, p3)\n",
    "\n",
    "        return x, logits_aux1, logits_aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model4-ckps'\n",
    "def create_model(args):\n",
    "    model = BengaliNet4(args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, preds3, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2) == len(preds3)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    recall_word = sklearn.metrics.recall_score(preds3, y[:, 3], average='macro')\n",
    "    \n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    metrics['recall_word'] = round(recall_word, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    metrics['acc_word'] = round((preds3 == y[:, 3]).sum() / len(y), 6)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    loss3 = F.cross_entropy(outputs[3], y_true[:, 3], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 + loss3 #, loss0.item(), loss1.item(), loss2.item()\n",
    "    #return loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2, loss3 = 0., 0., 0., 0.\n",
    "    preds0, preds1, preds2, preds3 = [], [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(x)\n",
    "            #avg_outputs = torch.mean(torch.stack([outputs, outputs_aux1, outputs_aux2], 0), 0)\n",
    "            outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            preds3.append(torch.max(outputs[3], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            loss3 += F.cross_entropy(outputs[3], y[:, 3], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    preds3 = torch.cat(preds3, 0).cpu().numpy()\n",
    "    \n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, preds3, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    metrics['loss_word'] = round(loss3 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4172528007108527"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "        img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "        batch_size = img.size(0)\n",
    "        r = np.random.rand()\n",
    "\n",
    "        if r < 0.5:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            #img[:, :, bby1:bby2, bbx1:bbx2] = img[rand_index, :, bby1:bby2, bbx1:bbx2] #for new cutmix\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "            loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r > 1.9: # normal train\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, targets)\n",
    "            loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r > 1.7: # grid mask\n",
    "            img = grid(img)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, targets)\n",
    "            loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        else: # mixup\n",
    "            orig_img, targets = mixup(orig_img, targets)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "            loss_primary = mixup_criterion(outputs, targets)\n",
    "            loss_aux1 = mixup_criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = mixup_criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "            #loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        lr_scheduler(optimizer, batch_idx, epoch)\n",
    "        optimizer.step()            \n",
    "        \n",
    "        current_lr = get_lrs(optimizer)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "            epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "            loss.item(), train_loss/(batch_idx+1)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = 0.\n",
    "\n",
    "def validate_and_save(model, model_file, val_loader, save=False):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        best_metrics = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "def train(args):\n",
    "    model, model_file = create_model(args)\n",
    "    model = model.cuda()\n",
    "\n",
    "    swa_model, _ = create_model(args)\n",
    "    swa_model = swa_model.cuda()\n",
    "    swa_model_file = model_file\n",
    "\n",
    "    optimizer = make_optimizer(model)\n",
    "    lr_scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    [model, swa_model], optimizer = amp.initialize([model, swa_model], optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        swa_model = nn.DataParallel(swa_model)\n",
    "    \n",
    "    validate_and_save(model, model_file, val_loader, save=False)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "        if os.path.exists(model_file):\n",
    "            print(f'loading {model_file}...')\n",
    "            model.module.load_state_dict(torch.load(model_file))\n",
    "\n",
    "        for epoch in range(args.start_epoch, args.num_epochs):\n",
    "            grid.set_prob(epoch, args.st_epochs)\n",
    "            train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\n",
    "            validate_and_save(model, model_file, val_loader, save=True)\n",
    "            \n",
    "            if (epoch+1) == args.swa_start and cycle == 1:\n",
    "                copy_model(swa_model, model)\n",
    "                swa_n = 0\n",
    "            if (epoch+1) >= args.swa_start and (epoch+1) % args.swa_freq == 0:\n",
    "                print('SWA>>>:')\n",
    "                moving_average(swa_model, model, 1.0 / (swa_n + 1))\n",
    "                swa_n += 1\n",
    "                bn_update(train_loader, swa_model)\n",
    "                validate_and_save(swa_model, swa_model_file, val_loader, save=True)\n",
    "\n",
    "        #args.base_lr = 1.5e-4\n",
    "        #args.num_epochs = 80\n",
    "        #args.warmup_epochs = 10\n",
    "        # reset scheduler at each cycle\n",
    "        lr_scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model4_se_resnext50_fold3_224.pth'\n",
    "\n",
    "args.base_lr = 4e-5\n",
    "args.num_epochs = 60\n",
    "args.start_epoch = 0\n",
    "args.warmup_epochs = 0\n",
    "\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 640\n",
    "args.val_batch_size = 1024\n",
    "args.st_epochs = 10\n",
    "\n",
    "args.swa_start = 0\n",
    "args.swa_freq = 3\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160716, 6) (40124, 6)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth...\n",
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth...\n",
      "\n",
      "val: {'recall': 0.990901, 'recall_grapheme': 0.986626, 'recall_vowel': 0.994607, 'recall_consonant': 0.995745, 'recall_word': 0.983622, 'acc_grapheme': 0.985445, 'acc_vowel': 0.995265, 'acc_consonant': 0.995863, 'acc_word': 0.983601, 'loss_grapheme': 0.066175, 'loss_vowel': 0.028702, 'loss_consonant': 0.022095, 'loss_word': 0.070521}\n",
      "CYCLE: 1\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth...\n",
      "    0 | 0.000040 | 160640/160716 | 7.8883 | 11.1346 ||\n",
      "val: {'recall': 0.988418, 'recall_grapheme': 0.982352, 'recall_vowel': 0.993159, 'recall_consonant': 0.99581, 'recall_word': 0.980183, 'acc_grapheme': 0.981507, 'acc_vowel': 0.994343, 'acc_consonant': 0.994791, 'acc_word': 0.979887, 'loss_grapheme': 0.184769, 'loss_vowel': 0.151576, 'loss_consonant': 0.105095, 'loss_word': 0.163724}\n",
      "    1 | 0.000040 | 160640/160716 | 9.0945 | 11.1592 ||\n",
      "val: {'recall': 0.987688, 'recall_grapheme': 0.981154, 'recall_vowel': 0.992815, 'recall_consonant': 0.995628, 'recall_word': 0.980465, 'acc_grapheme': 0.980959, 'acc_vowel': 0.994318, 'acc_consonant': 0.994716, 'acc_word': 0.980261, 'loss_grapheme': 0.190109, 'loss_vowel': 0.142075, 'loss_consonant': 0.10001, 'loss_word': 0.161461}\n",
      "    2 | 0.000040 | 013440/160716 | 8.9949 | 10.4935 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b03a8b8d0225>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-37d565e9b96c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# mixup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_aux1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_aux2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mloss_primary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss_aux1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_aux1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.backbone.parameters():\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate(nn.DataParallel(model), val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth...\n",
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth...\n",
      "\n",
      "val: {'recall': 0.973574, 'recall_grapheme': 0.958259, 'recall_vowel': 0.986701, 'recall_consonant': 0.991078, 'recall_word': 0.946792, 'acc_grapheme': 0.955563, 'acc_vowel': 0.986916, 'acc_consonant': 0.982853, 'acc_word': 0.940609, 'loss_grapheme': 0.505266, 'loss_vowel': 0.242785, 'loss_consonant': 0.176852, 'loss_word': 0.689013}\n",
      "CYCLE: 1\n",
      "    0 | 0.000040 | 160640/160716 | 10.7314 | 13.5860 |\n",
      "val: {'recall': 0.983047, 'recall_grapheme': 0.975177, 'recall_vowel': 0.990518, 'recall_consonant': 0.991315, 'recall_word': 0.974583, 'acc_grapheme': 0.974554, 'acc_vowel': 0.992025, 'acc_consonant': 0.991825, 'acc_word': 0.974355, 'loss_grapheme': 0.243174, 'loss_vowel': 0.149139, 'loss_consonant': 0.11224, 'loss_word': 0.219538}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "    1 | 0.000080 | 160640/160716 | 20.3251 | 12.0757 |\n",
      "val: {'recall': 0.985197, 'recall_grapheme': 0.978017, 'recall_vowel': 0.991304, 'recall_consonant': 0.993452, 'recall_word': 0.976877, 'acc_grapheme': 0.976897, 'acc_vowel': 0.992847, 'acc_consonant': 0.992847, 'acc_word': 0.976647, 'loss_grapheme': 0.263074, 'loss_vowel': 0.195254, 'loss_consonant': 0.128039, 'loss_word': 0.242482}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "    2 | 0.000119 | 160640/160716 | 20.3389 | 11.8871 |\n",
      "val: {'recall': 0.985738, 'recall_grapheme': 0.978242, 'recall_vowel': 0.991344, 'recall_consonant': 0.995124, 'recall_word': 0.977394, 'acc_grapheme': 0.977096, 'acc_vowel': 0.993047, 'acc_consonant': 0.993371, 'acc_word': 0.977246, 'loss_grapheme': 0.273971, 'loss_vowel': 0.205731, 'loss_consonant': 0.136208, 'loss_word': 0.25712}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "    3 | 0.000158 | 160640/160716 | 10.9299 | 12.6330 |\n",
      "val: {'recall': 0.984687, 'recall_grapheme': 0.976979, 'recall_vowel': 0.991388, 'recall_consonant': 0.993401, 'recall_word': 0.97524, 'acc_grapheme': 0.97585, 'acc_vowel': 0.992997, 'acc_consonant': 0.992723, 'acc_word': 0.974928, 'loss_grapheme': 0.19853, 'loss_vowel': 0.140225, 'loss_consonant': 0.096217, 'loss_word': 0.198851}\n",
      "    4 | 0.000196 | 160640/160716 | 2.4145 | 12.4837 ||\n",
      "val: {'recall': 0.98511, 'recall_grapheme': 0.977431, 'recall_vowel': 0.991227, 'recall_consonant': 0.994352, 'recall_word': 0.975989, 'acc_grapheme': 0.975974, 'acc_vowel': 0.993146, 'acc_consonant': 0.993321, 'acc_word': 0.975551, 'loss_grapheme': 0.231769, 'loss_vowel': 0.16371, 'loss_consonant': 0.106878, 'loss_word': 0.222833}\n",
      "    5 | 0.000195 | 160640/160716 | 6.6184 | 12.4135 ||\n",
      "val: {'recall': 0.985096, 'recall_grapheme': 0.977382, 'recall_vowel': 0.992368, 'recall_consonant': 0.993253, 'recall_word': 0.976726, 'acc_grapheme': 0.976647, 'acc_vowel': 0.993022, 'acc_consonant': 0.992099, 'acc_word': 0.976523, 'loss_grapheme': 0.20078, 'loss_vowel': 0.151911, 'loss_consonant': 0.104196, 'loss_word': 0.185285}\n",
      "    6 | 0.000193 | 160640/160716 | 23.1164 | 11.8408 |\n",
      "val: {'recall': 0.985643, 'recall_grapheme': 0.9784, 'recall_vowel': 0.990708, 'recall_consonant': 0.995067, 'recall_word': 0.97758, 'acc_grapheme': 0.977694, 'acc_vowel': 0.992847, 'acc_consonant': 0.993371, 'acc_word': 0.977395, 'loss_grapheme': 0.205847, 'loss_vowel': 0.149446, 'loss_consonant': 0.105708, 'loss_word': 0.193445}\n",
      "    7 | 0.000191 | 160640/160716 | 5.5429 | 11.9763 ||\n",
      "val: {'recall': 0.986584, 'recall_grapheme': 0.980005, 'recall_vowel': 0.99227, 'recall_consonant': 0.994056, 'recall_word': 0.978215, 'acc_grapheme': 0.977619, 'acc_vowel': 0.99357, 'acc_consonant': 0.993271, 'acc_word': 0.977869, 'loss_grapheme': 0.206428, 'loss_vowel': 0.156184, 'loss_consonant': 0.103418, 'loss_word': 0.190326}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "    8 | 0.000189 | 160640/160716 | 9.6732 | 12.5788 ||\n",
      "val: {'recall': 0.985676, 'recall_grapheme': 0.978389, 'recall_vowel': 0.991213, 'recall_consonant': 0.994711, 'recall_word': 0.977532, 'acc_grapheme': 0.977644, 'acc_vowel': 0.993121, 'acc_consonant': 0.992997, 'acc_word': 0.977221, 'loss_grapheme': 0.200518, 'loss_vowel': 0.140105, 'loss_consonant': 0.104722, 'loss_word': 0.181194}\n",
      "    9 | 0.000187 | 160640/160716 | 9.1718 | 12.1510 ||\n",
      "val: {'recall': 0.98547, 'recall_grapheme': 0.977955, 'recall_vowel': 0.991626, 'recall_consonant': 0.994345, 'recall_word': 0.976631, 'acc_grapheme': 0.976946, 'acc_vowel': 0.993022, 'acc_consonant': 0.992747, 'acc_word': 0.976348, 'loss_grapheme': 0.185565, 'loss_vowel': 0.101258, 'loss_consonant': 0.09012, 'loss_word': 0.156744}\n",
      "   10 | 0.000184 | 160640/160716 | 3.2783 | 11.7525 ||\n",
      "val: {'recall': 0.98588, 'recall_grapheme': 0.979558, 'recall_vowel': 0.99143, 'recall_consonant': 0.992971, 'recall_word': 0.976809, 'acc_grapheme': 0.97742, 'acc_vowel': 0.993296, 'acc_consonant': 0.993395, 'acc_word': 0.976249, 'loss_grapheme': 0.218964, 'loss_vowel': 0.162207, 'loss_consonant': 0.108413, 'loss_word': 0.214014}\n",
      "   11 | 0.000181 | 160640/160716 | 11.4839 | 11.6881 |\n",
      "val: {'recall': 0.987197, 'recall_grapheme': 0.980986, 'recall_vowel': 0.991877, 'recall_consonant': 0.994938, 'recall_word': 0.978974, 'acc_grapheme': 0.978915, 'acc_vowel': 0.99342, 'acc_consonant': 0.99342, 'acc_word': 0.978566, 'loss_grapheme': 0.21415, 'loss_vowel': 0.159762, 'loss_consonant': 0.109256, 'loss_word': 0.197294}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   12 | 0.000178 | 160640/160716 | 5.6147 | 11.7363 ||\n",
      "val: {'recall': 0.986784, 'recall_grapheme': 0.979512, 'recall_vowel': 0.993236, 'recall_consonant': 0.994873, 'recall_word': 0.977872, 'acc_grapheme': 0.978367, 'acc_vowel': 0.99362, 'acc_consonant': 0.993047, 'acc_word': 0.97757, 'loss_grapheme': 0.198252, 'loss_vowel': 0.145334, 'loss_consonant': 0.098674, 'loss_word': 0.1842}\n",
      "   13 | 0.000174 | 160640/160716 | 12.9508 | 11.8600 |\n",
      "val: {'recall': 0.985849, 'recall_grapheme': 0.979754, 'recall_vowel': 0.991543, 'recall_consonant': 0.992345, 'recall_word': 0.977745, 'acc_grapheme': 0.978168, 'acc_vowel': 0.993246, 'acc_consonant': 0.99352, 'acc_word': 0.977445, 'loss_grapheme': 0.175233, 'loss_vowel': 0.130458, 'loss_consonant': 0.091098, 'loss_word': 0.166843}\n",
      "   14 | 0.000171 | 160640/160716 | 17.2279 | 11.7241 |\n",
      "val: {'recall': 0.987697, 'recall_grapheme': 0.981219, 'recall_vowel': 0.993458, 'recall_consonant': 0.994892, 'recall_word': 0.979625, 'acc_grapheme': 0.979165, 'acc_vowel': 0.994118, 'acc_consonant': 0.993919, 'acc_word': 0.979264, 'loss_grapheme': 0.237654, 'loss_vowel': 0.183833, 'loss_consonant': 0.120208, 'loss_word': 0.210377}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988702, 'recall_grapheme': 0.983408, 'recall_vowel': 0.994278, 'recall_consonant': 0.993713, 'recall_word': 0.981235, 'acc_grapheme': 0.981981, 'acc_vowel': 0.994467, 'acc_consonant': 0.994367, 'acc_word': 0.981158, 'loss_grapheme': 0.084338, 'loss_vowel': 0.036426, 'loss_consonant': 0.030505, 'loss_word': 0.084398}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   15 | 0.000167 | 160640/160716 | 10.2000 | 12.1626 |\n",
      "val: {'recall': 0.986645, 'recall_grapheme': 0.980716, 'recall_vowel': 0.991359, 'recall_consonant': 0.993791, 'recall_word': 0.977962, 'acc_grapheme': 0.978517, 'acc_vowel': 0.993595, 'acc_consonant': 0.993545, 'acc_word': 0.97752, 'loss_grapheme': 0.193478, 'loss_vowel': 0.129462, 'loss_consonant': 0.094164, 'loss_word': 0.178724}\n",
      "   16 | 0.000163 | 160640/160716 | 8.9220 | 11.8400 ||\n",
      "val: {'recall': 0.98634, 'recall_grapheme': 0.9793, 'recall_vowel': 0.992438, 'recall_consonant': 0.994322, 'recall_word': 0.978441, 'acc_grapheme': 0.979414, 'acc_vowel': 0.993819, 'acc_consonant': 0.992872, 'acc_word': 0.978168, 'loss_grapheme': 0.181449, 'loss_vowel': 0.134186, 'loss_consonant': 0.09182, 'loss_word': 0.174638}\n",
      "   17 | 0.000159 | 160640/160716 | 8.9946 | 11.4488 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.987666, 'recall_grapheme': 0.981507, 'recall_vowel': 0.99235, 'recall_consonant': 0.995301, 'recall_word': 0.979606, 'acc_grapheme': 0.979987, 'acc_vowel': 0.993495, 'acc_consonant': 0.993346, 'acc_word': 0.979214, 'loss_grapheme': 0.226765, 'loss_vowel': 0.170005, 'loss_consonant': 0.120342, 'loss_word': 0.211435}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:25<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988941, 'recall_grapheme': 0.983948, 'recall_vowel': 0.99339, 'recall_consonant': 0.994479, 'recall_word': 0.981403, 'acc_grapheme': 0.982579, 'acc_vowel': 0.994318, 'acc_consonant': 0.994766, 'acc_word': 0.981308, 'loss_grapheme': 0.08397, 'loss_vowel': 0.037254, 'loss_consonant': 0.030794, 'loss_word': 0.083673}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   18 | 0.000154 | 160640/160716 | 9.3672 | 11.1293 ||\n",
      "val: {'recall': 0.987044, 'recall_grapheme': 0.980198, 'recall_vowel': 0.99238, 'recall_consonant': 0.9954, 'recall_word': 0.9777, 'acc_grapheme': 0.978292, 'acc_vowel': 0.99342, 'acc_consonant': 0.993794, 'acc_word': 0.97732, 'loss_grapheme': 0.172029, 'loss_vowel': 0.133502, 'loss_consonant': 0.089886, 'loss_word': 0.17217}\n",
      "   19 | 0.000150 | 160640/160716 | 19.4221 | 11.9090 |\n",
      "val: {'recall': 0.986956, 'recall_grapheme': 0.980921, 'recall_vowel': 0.992808, 'recall_consonant': 0.993172, 'recall_word': 0.979373, 'acc_grapheme': 0.979912, 'acc_vowel': 0.994068, 'acc_consonant': 0.994019, 'acc_word': 0.979214, 'loss_grapheme': 0.144702, 'loss_vowel': 0.103402, 'loss_consonant': 0.075012, 'loss_word': 0.135317}\n",
      "   20 | 0.000145 | 160640/160716 | 8.4768 | 11.9136 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.987042, 'recall_grapheme': 0.981626, 'recall_vowel': 0.992164, 'recall_consonant': 0.992751, 'recall_word': 0.97859, 'acc_grapheme': 0.979364, 'acc_vowel': 0.993919, 'acc_consonant': 0.99357, 'acc_word': 0.978442, 'loss_grapheme': 0.187271, 'loss_vowel': 0.142829, 'loss_consonant': 0.100332, 'loss_word': 0.178249}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989488, 'recall_grapheme': 0.98468, 'recall_vowel': 0.993293, 'recall_consonant': 0.995299, 'recall_word': 0.981651, 'acc_grapheme': 0.983576, 'acc_vowel': 0.994492, 'acc_consonant': 0.995115, 'acc_word': 0.981682, 'loss_grapheme': 0.083424, 'loss_vowel': 0.038647, 'loss_consonant': 0.031227, 'loss_word': 0.083663}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   21 | 0.000141 | 160640/160716 | 11.5016 | 12.0601 |\n",
      "val: {'recall': 0.987622, 'recall_grapheme': 0.980897, 'recall_vowel': 0.993378, 'recall_consonant': 0.995315, 'recall_word': 0.979716, 'acc_grapheme': 0.979788, 'acc_vowel': 0.993944, 'acc_consonant': 0.993695, 'acc_word': 0.979538, 'loss_grapheme': 0.193942, 'loss_vowel': 0.147146, 'loss_consonant': 0.101736, 'loss_word': 0.166479}\n",
      "   22 | 0.000136 | 160640/160716 | 8.4757 | 11.1659 ||\n",
      "val: {'recall': 0.987305, 'recall_grapheme': 0.981354, 'recall_vowel': 0.992829, 'recall_consonant': 0.993681, 'recall_word': 0.979449, 'acc_grapheme': 0.980161, 'acc_vowel': 0.993819, 'acc_consonant': 0.993769, 'acc_word': 0.979364, 'loss_grapheme': 0.197938, 'loss_vowel': 0.145741, 'loss_consonant': 0.100574, 'loss_word': 0.1834}\n",
      "   23 | 0.000131 | 160640/160716 | 14.0578 | 11.5005 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.987401, 'recall_grapheme': 0.980943, 'recall_vowel': 0.993101, 'recall_consonant': 0.994615, 'recall_word': 0.978159, 'acc_grapheme': 0.980112, 'acc_vowel': 0.993794, 'acc_consonant': 0.993595, 'acc_word': 0.977769, 'loss_grapheme': 0.20616, 'loss_vowel': 0.157129, 'loss_consonant': 0.104625, 'loss_word': 0.20009}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989533, 'recall_grapheme': 0.984659, 'recall_vowel': 0.993426, 'recall_consonant': 0.995389, 'recall_word': 0.981813, 'acc_grapheme': 0.983676, 'acc_vowel': 0.994567, 'acc_consonant': 0.995165, 'acc_word': 0.981806, 'loss_grapheme': 0.080192, 'loss_vowel': 0.03664, 'loss_consonant': 0.029374, 'loss_word': 0.081544}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   24 | 0.000126 | 160640/160716 | 1.3440 | 11.6876 ||\n",
      "val: {'recall': 0.987081, 'recall_grapheme': 0.981256, 'recall_vowel': 0.99237, 'recall_consonant': 0.993443, 'recall_word': 0.979072, 'acc_grapheme': 0.979987, 'acc_vowel': 0.993744, 'acc_consonant': 0.994143, 'acc_word': 0.978816, 'loss_grapheme': 0.209714, 'loss_vowel': 0.169065, 'loss_consonant': 0.111517, 'loss_word': 0.185963}\n",
      "   25 | 0.000121 | 160640/160716 | 5.7105 | 11.2164 ||\n",
      "val: {'recall': 0.987001, 'recall_grapheme': 0.980176, 'recall_vowel': 0.992903, 'recall_consonant': 0.994749, 'recall_word': 0.978634, 'acc_grapheme': 0.979214, 'acc_vowel': 0.99362, 'acc_consonant': 0.993919, 'acc_word': 0.978342, 'loss_grapheme': 0.141609, 'loss_vowel': 0.079241, 'loss_consonant': 0.066526, 'loss_word': 0.129148}\n",
      "   26 | 0.000116 | 160640/160716 | 10.7360 | 11.8691 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988747, 'recall_grapheme': 0.982562, 'recall_vowel': 0.993919, 'recall_consonant': 0.995946, 'recall_word': 0.981162, 'acc_grapheme': 0.98071, 'acc_vowel': 0.994567, 'acc_consonant': 0.994268, 'acc_word': 0.980884, 'loss_grapheme': 0.202331, 'loss_vowel': 0.155643, 'loss_consonant': 0.110006, 'loss_word': 0.17642}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989769, 'recall_grapheme': 0.984897, 'recall_vowel': 0.993836, 'recall_consonant': 0.995448, 'recall_word': 0.982083, 'acc_grapheme': 0.984025, 'acc_vowel': 0.994667, 'acc_consonant': 0.99524, 'acc_word': 0.982081, 'loss_grapheme': 0.077732, 'loss_vowel': 0.035082, 'loss_consonant': 0.028382, 'loss_word': 0.079198}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   27 | 0.000110 | 160640/160716 | 13.9549 | 11.5440 |\n",
      "val: {'recall': 0.988423, 'recall_grapheme': 0.982369, 'recall_vowel': 0.993573, 'recall_consonant': 0.995382, 'recall_word': 0.980861, 'acc_grapheme': 0.981507, 'acc_vowel': 0.994268, 'acc_consonant': 0.994193, 'acc_word': 0.980585, 'loss_grapheme': 0.197424, 'loss_vowel': 0.152369, 'loss_consonant': 0.100128, 'loss_word': 0.178919}\n",
      "   28 | 0.000105 | 160640/160716 | 20.4562 | 11.3414 |\n",
      "val: {'recall': 0.988235, 'recall_grapheme': 0.98197, 'recall_vowel': 0.993417, 'recall_consonant': 0.995585, 'recall_word': 0.981385, 'acc_grapheme': 0.981333, 'acc_vowel': 0.994467, 'acc_consonant': 0.994318, 'acc_word': 0.981158, 'loss_grapheme': 0.1935, 'loss_vowel': 0.15216, 'loss_consonant': 0.106843, 'loss_word': 0.177317}\n",
      "   29 | 0.000100 | 160640/160716 | 18.9177 | 11.2596 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988566, 'recall_grapheme': 0.98248, 'recall_vowel': 0.993836, 'recall_consonant': 0.995471, 'recall_word': 0.980743, 'acc_grapheme': 0.980785, 'acc_vowel': 0.994492, 'acc_consonant': 0.994268, 'acc_word': 0.980535, 'loss_grapheme': 0.186972, 'loss_vowel': 0.146232, 'loss_consonant': 0.097226, 'loss_word': 0.168711}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989917, 'recall_grapheme': 0.985231, 'recall_vowel': 0.993873, 'recall_consonant': 0.995331, 'recall_word': 0.982335, 'acc_grapheme': 0.984274, 'acc_vowel': 0.994691, 'acc_consonant': 0.995265, 'acc_word': 0.982355, 'loss_grapheme': 0.076335, 'loss_vowel': 0.034215, 'loss_consonant': 0.027626, 'loss_word': 0.078268}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   30 | 0.000095 | 160640/160716 | 3.6900 | 11.2939 ||\n",
      "val: {'recall': 0.988657, 'recall_grapheme': 0.983051, 'recall_vowel': 0.99339, 'recall_consonant': 0.995139, 'recall_word': 0.980883, 'acc_grapheme': 0.981133, 'acc_vowel': 0.994318, 'acc_consonant': 0.994293, 'acc_word': 0.980685, 'loss_grapheme': 0.142875, 'loss_vowel': 0.104821, 'loss_consonant': 0.072496, 'loss_word': 0.137048}\n",
      "   31 | 0.000090 | 160640/160716 | 17.6985 | 11.2147 |\n",
      "val: {'recall': 0.987797, 'recall_grapheme': 0.981575, 'recall_vowel': 0.993086, 'recall_consonant': 0.994951, 'recall_word': 0.979301, 'acc_grapheme': 0.980635, 'acc_vowel': 0.994068, 'acc_consonant': 0.994268, 'acc_word': 0.979115, 'loss_grapheme': 0.19573, 'loss_vowel': 0.16604, 'loss_consonant': 0.110021, 'loss_word': 0.176689}\n",
      "   32 | 0.000084 | 160640/160716 | 21.7751 | 11.4639 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988051, 'recall_grapheme': 0.982093, 'recall_vowel': 0.992837, 'recall_consonant': 0.995181, 'recall_word': 0.979827, 'acc_grapheme': 0.981009, 'acc_vowel': 0.994243, 'acc_consonant': 0.993944, 'acc_word': 0.979613, 'loss_grapheme': 0.220939, 'loss_vowel': 0.18059, 'loss_consonant': 0.120906, 'loss_word': 0.200075}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989954, 'recall_grapheme': 0.985208, 'recall_vowel': 0.994006, 'recall_consonant': 0.995393, 'recall_word': 0.982438, 'acc_grapheme': 0.984299, 'acc_vowel': 0.994816, 'acc_consonant': 0.99529, 'acc_word': 0.982429, 'loss_grapheme': 0.0757, 'loss_vowel': 0.033963, 'loss_consonant': 0.027405, 'loss_word': 0.077937}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   33 | 0.000079 | 160640/160716 | 5.3657 | 11.6975 ||\n",
      "val: {'recall': 0.988564, 'recall_grapheme': 0.98276, 'recall_vowel': 0.992763, 'recall_consonant': 0.995973, 'recall_word': 0.980879, 'acc_grapheme': 0.981183, 'acc_vowel': 0.993944, 'acc_consonant': 0.994417, 'acc_word': 0.980735, 'loss_grapheme': 0.188327, 'loss_vowel': 0.146538, 'loss_consonant': 0.099563, 'loss_word': 0.165623}\n",
      "   34 | 0.000074 | 160640/160716 | 6.5991 | 10.9271 ||\n",
      "val: {'recall': 0.988398, 'recall_grapheme': 0.982649, 'recall_vowel': 0.992656, 'recall_consonant': 0.995638, 'recall_word': 0.980327, 'acc_grapheme': 0.981109, 'acc_vowel': 0.994318, 'acc_consonant': 0.994143, 'acc_word': 0.980087, 'loss_grapheme': 0.171407, 'loss_vowel': 0.13786, 'loss_consonant': 0.093282, 'loss_word': 0.158777}\n",
      "   35 | 0.000069 | 160640/160716 | 9.6308 | 11.5925 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988036, 'recall_grapheme': 0.981939, 'recall_vowel': 0.992927, 'recall_consonant': 0.99534, 'recall_word': 0.98008, 'acc_grapheme': 0.980685, 'acc_vowel': 0.994318, 'acc_consonant': 0.994268, 'acc_word': 0.979838, 'loss_grapheme': 0.208376, 'loss_vowel': 0.168702, 'loss_consonant': 0.11342, 'loss_word': 0.185382}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:27<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989919, 'recall_grapheme': 0.985153, 'recall_vowel': 0.993906, 'recall_consonant': 0.995465, 'recall_word': 0.982492, 'acc_grapheme': 0.984299, 'acc_vowel': 0.994791, 'acc_consonant': 0.995364, 'acc_word': 0.982504, 'loss_grapheme': 0.07535, 'loss_vowel': 0.033715, 'loss_consonant': 0.02714, 'loss_word': 0.077525}\n",
      "   36 | 0.000064 | 160640/160716 | 4.6623 | 11.4520 ||\n",
      "val: {'recall': 0.988473, 'recall_grapheme': 0.982256, 'recall_vowel': 0.993444, 'recall_consonant': 0.995936, 'recall_word': 0.98095, 'acc_grapheme': 0.980934, 'acc_vowel': 0.994392, 'acc_consonant': 0.994367, 'acc_word': 0.980635, 'loss_grapheme': 0.180546, 'loss_vowel': 0.145638, 'loss_consonant': 0.101986, 'loss_word': 0.158224}\n",
      "   37 | 0.000059 | 160640/160716 | 4.6603 | 11.2763 ||\n",
      "val: {'recall': 0.988536, 'recall_grapheme': 0.982693, 'recall_vowel': 0.993071, 'recall_consonant': 0.995688, 'recall_word': 0.981279, 'acc_grapheme': 0.981408, 'acc_vowel': 0.994143, 'acc_consonant': 0.994642, 'acc_word': 0.980984, 'loss_grapheme': 0.154992, 'loss_vowel': 0.10527, 'loss_consonant': 0.081717, 'loss_word': 0.134835}\n",
      "   38 | 0.000055 | 160640/160716 | 19.5125 | 11.2694 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988748, 'recall_grapheme': 0.982727, 'recall_vowel': 0.993556, 'recall_consonant': 0.995982, 'recall_word': 0.981044, 'acc_grapheme': 0.981781, 'acc_vowel': 0.994417, 'acc_consonant': 0.994816, 'acc_word': 0.980735, 'loss_grapheme': 0.153797, 'loss_vowel': 0.118704, 'loss_consonant': 0.081906, 'loss_word': 0.142304}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:27<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990037, 'recall_grapheme': 0.985245, 'recall_vowel': 0.994203, 'recall_consonant': 0.995457, 'recall_word': 0.982489, 'acc_grapheme': 0.984349, 'acc_vowel': 0.994891, 'acc_consonant': 0.995364, 'acc_word': 0.982504, 'loss_grapheme': 0.074544, 'loss_vowel': 0.033431, 'loss_consonant': 0.02678, 'loss_word': 0.077013}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   39 | 0.000050 | 160640/160716 | 15.5516 | 11.1378 |\n",
      "val: {'recall': 0.989298, 'recall_grapheme': 0.984011, 'recall_vowel': 0.99347, 'recall_consonant': 0.995698, 'recall_word': 0.981245, 'acc_grapheme': 0.982479, 'acc_vowel': 0.994392, 'acc_consonant': 0.994791, 'acc_word': 0.981109, 'loss_grapheme': 0.169957, 'loss_vowel': 0.133094, 'loss_consonant': 0.091798, 'loss_word': 0.155294}\n",
      "   40 | 0.000046 | 160640/160716 | 18.1405 | 11.0269 |\n",
      "val: {'recall': 0.988268, 'recall_grapheme': 0.981918, 'recall_vowel': 0.993566, 'recall_consonant': 0.995669, 'recall_word': 0.980974, 'acc_grapheme': 0.981781, 'acc_vowel': 0.994517, 'acc_consonant': 0.994841, 'acc_word': 0.980785, 'loss_grapheme': 0.172316, 'loss_vowel': 0.135151, 'loss_consonant': 0.089351, 'loss_word': 0.157338}\n",
      "   41 | 0.000041 | 160640/160716 | 19.9769 | 11.9203 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.98816, 'recall_grapheme': 0.98163, 'recall_vowel': 0.993367, 'recall_consonant': 0.996014, 'recall_word': 0.980551, 'acc_grapheme': 0.980809, 'acc_vowel': 0.994392, 'acc_consonant': 0.994243, 'acc_word': 0.980336, 'loss_grapheme': 0.216032, 'loss_vowel': 0.174316, 'loss_consonant': 0.122033, 'loss_word': 0.184103}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:25<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990037, 'recall_grapheme': 0.98529, 'recall_vowel': 0.994094, 'recall_consonant': 0.995473, 'recall_word': 0.982472, 'acc_grapheme': 0.984523, 'acc_vowel': 0.994941, 'acc_consonant': 0.995339, 'acc_word': 0.982504, 'loss_grapheme': 0.073891, 'loss_vowel': 0.033046, 'loss_consonant': 0.026433, 'loss_word': 0.076386}\n",
      "   42 | 0.000037 | 160640/160716 | 8.3027 | 11.6499 ||\n",
      "val: {'recall': 0.989279, 'recall_grapheme': 0.983732, 'recall_vowel': 0.994, 'recall_consonant': 0.99565, 'recall_word': 0.981178, 'acc_grapheme': 0.982255, 'acc_vowel': 0.994442, 'acc_consonant': 0.994716, 'acc_word': 0.980884, 'loss_grapheme': 0.147552, 'loss_vowel': 0.112711, 'loss_consonant': 0.078095, 'loss_word': 0.138999}\n",
      "   43 | 0.000033 | 160640/160716 | 7.7823 | 10.9490 ||\n",
      "val: {'recall': 0.988428, 'recall_grapheme': 0.982686, 'recall_vowel': 0.993042, 'recall_consonant': 0.995298, 'recall_word': 0.980028, 'acc_grapheme': 0.981482, 'acc_vowel': 0.994093, 'acc_consonant': 0.994567, 'acc_word': 0.979838, 'loss_grapheme': 0.139374, 'loss_vowel': 0.090503, 'loss_consonant': 0.066086, 'loss_word': 0.128329}\n",
      "   44 | 0.000029 | 160640/160716 | 1.8049 | 11.3105 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989457, 'recall_grapheme': 0.983712, 'recall_vowel': 0.99417, 'recall_consonant': 0.996234, 'recall_word': 0.981621, 'acc_grapheme': 0.982255, 'acc_vowel': 0.994866, 'acc_consonant': 0.994916, 'acc_word': 0.981457, 'loss_grapheme': 0.162869, 'loss_vowel': 0.128537, 'loss_consonant': 0.090099, 'loss_word': 0.14853}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:27<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990064, 'recall_grapheme': 0.985282, 'recall_vowel': 0.994185, 'recall_consonant': 0.995507, 'recall_word': 0.982694, 'acc_grapheme': 0.984548, 'acc_vowel': 0.994941, 'acc_consonant': 0.995364, 'acc_word': 0.982704, 'loss_grapheme': 0.073237, 'loss_vowel': 0.03261, 'loss_consonant': 0.026092, 'loss_word': 0.075892}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   45 | 0.000026 | 160640/160716 | 18.1091 | 10.9010 |\n",
      "val: {'recall': 0.989306, 'recall_grapheme': 0.983393, 'recall_vowel': 0.994337, 'recall_consonant': 0.9961, 'recall_word': 0.980645, 'acc_grapheme': 0.982031, 'acc_vowel': 0.994791, 'acc_consonant': 0.994816, 'acc_word': 0.980436, 'loss_grapheme': 0.160365, 'loss_vowel': 0.12994, 'loss_consonant': 0.089442, 'loss_word': 0.150955}\n",
      "   46 | 0.000022 | 160640/160716 | 9.4556 | 11.4316 ||\n",
      "val: {'recall': 0.988405, 'recall_grapheme': 0.982151, 'recall_vowel': 0.993451, 'recall_consonant': 0.995866, 'recall_word': 0.980932, 'acc_grapheme': 0.981283, 'acc_vowel': 0.994392, 'acc_consonant': 0.994592, 'acc_word': 0.98076, 'loss_grapheme': 0.171332, 'loss_vowel': 0.126569, 'loss_consonant': 0.092705, 'loss_word': 0.15128}\n",
      "   47 | 0.000019 | 160640/160716 | 4.7184 | 11.0383 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989321, 'recall_grapheme': 0.983827, 'recall_vowel': 0.993377, 'recall_consonant': 0.996253, 'recall_word': 0.980846, 'acc_grapheme': 0.98223, 'acc_vowel': 0.994691, 'acc_consonant': 0.995015, 'acc_word': 0.980685, 'loss_grapheme': 0.155728, 'loss_vowel': 0.120962, 'loss_consonant': 0.0844, 'loss_word': 0.146366}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:26<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990093, 'recall_grapheme': 0.985322, 'recall_vowel': 0.994208, 'recall_consonant': 0.995519, 'recall_word': 0.982676, 'acc_grapheme': 0.984573, 'acc_vowel': 0.994991, 'acc_consonant': 0.995414, 'acc_word': 0.982704, 'loss_grapheme': 0.072534, 'loss_vowel': 0.032184, 'loss_consonant': 0.025704, 'loss_word': 0.075393}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3_224.pth\n",
      "   48 | 0.000016 | 160640/160716 | 18.6086 | 11.9723 |\n",
      "val: {'recall': 0.989311, 'recall_grapheme': 0.98359, 'recall_vowel': 0.994177, 'recall_consonant': 0.995887, 'recall_word': 0.981754, 'acc_grapheme': 0.981831, 'acc_vowel': 0.994841, 'acc_consonant': 0.994891, 'acc_word': 0.981557, 'loss_grapheme': 0.192972, 'loss_vowel': 0.158029, 'loss_consonant': 0.107754, 'loss_word': 0.16852}\n",
      "   49 | 0.000015 | 054400/160716 | 8.3042 | 12.6752 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-3645aae0edb1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-37d565e9b96c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3.pth...\n",
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3.pth...\n",
      "\n",
      "val: {'recall': 0.987867, 'recall_grapheme': 0.981981, 'recall_vowel': 0.993514, 'recall_consonant': 0.993993, 'recall_word': 0.979095, 'acc_grapheme': 0.981009, 'acc_vowel': 0.994492, 'acc_consonant': 0.99362, 'acc_word': 0.97899, 'loss_grapheme': 0.084801, 'loss_vowel': 0.034225, 'loss_consonant': 0.030225, 'loss_word': 0.086658}\n",
      "CYCLE: 1\n",
      "    0 | 0.000030 | 160160/160716 | 17.3765 | 12.9856 |\n",
      "val: {'recall': 0.987116, 'recall_grapheme': 0.98068, 'recall_vowel': 0.992119, 'recall_consonant': 0.994983, 'recall_word': 0.97957, 'acc_grapheme': 0.97909, 'acc_vowel': 0.993744, 'acc_consonant': 0.99367, 'acc_word': 0.979364, 'loss_grapheme': 0.296987, 'loss_vowel': 0.230309, 'loss_consonant': 0.148434, 'loss_word': 0.270692}\n",
      "    1 | 0.000060 | 160160/160716 | 6.6518 | 12.4337 ||\n",
      "val: {'recall': 0.986982, 'recall_grapheme': 0.980663, 'recall_vowel': 0.992058, 'recall_consonant': 0.994546, 'recall_word': 0.978796, 'acc_grapheme': 0.97904, 'acc_vowel': 0.99352, 'acc_consonant': 0.993595, 'acc_word': 0.978367, 'loss_grapheme': 0.187402, 'loss_vowel': 0.136419, 'loss_consonant': 0.092953, 'loss_word': 0.172307}\n",
      "    2 | 0.000089 | 160160/160716 | 10.1081 | 11.8471 |\n",
      "val: {'recall': 0.986305, 'recall_grapheme': 0.979403, 'recall_vowel': 0.991816, 'recall_consonant': 0.994598, 'recall_word': 0.977709, 'acc_grapheme': 0.977694, 'acc_vowel': 0.993371, 'acc_consonant': 0.993371, 'acc_word': 0.97737, 'loss_grapheme': 0.247712, 'loss_vowel': 0.183204, 'loss_consonant': 0.121642, 'loss_word': 0.233127}\n",
      "    3 | 0.000119 | 160160/160716 | 10.1239 | 11.8035 |\n",
      "val: {'recall': 0.987323, 'recall_grapheme': 0.981099, 'recall_vowel': 0.992292, 'recall_consonant': 0.9948, 'recall_word': 0.978288, 'acc_grapheme': 0.978691, 'acc_vowel': 0.993919, 'acc_consonant': 0.993395, 'acc_word': 0.978093, 'loss_grapheme': 0.195586, 'loss_vowel': 0.136561, 'loss_consonant': 0.091789, 'loss_word': 0.176149}\n",
      "    4 | 0.000147 | 160160/160716 | 1.0380 | 12.1912 ||\n",
      "val: {'recall': 0.986783, 'recall_grapheme': 0.979782, 'recall_vowel': 0.992552, 'recall_consonant': 0.995015, 'recall_word': 0.978092, 'acc_grapheme': 0.978741, 'acc_vowel': 0.993794, 'acc_consonant': 0.992822, 'acc_word': 0.977744, 'loss_grapheme': 0.170419, 'loss_vowel': 0.11303, 'loss_consonant': 0.079328, 'loss_word': 0.158437}\n",
      "    5 | 0.000146 | 160160/160716 | 9.6948 | 12.9670 ||\n",
      "val: {'recall': 0.98598, 'recall_grapheme': 0.978762, 'recall_vowel': 0.99222, 'recall_consonant': 0.994177, 'recall_word': 0.977714, 'acc_grapheme': 0.977744, 'acc_vowel': 0.993395, 'acc_consonant': 0.993071, 'acc_word': 0.977345, 'loss_grapheme': 0.20681, 'loss_vowel': 0.137466, 'loss_consonant': 0.094725, 'loss_word': 0.184453}\n",
      "    6 | 0.000145 | 160160/160716 | 22.3737 | 12.5459 |\n",
      "val: {'recall': 0.986898, 'recall_grapheme': 0.979604, 'recall_vowel': 0.992885, 'recall_consonant': 0.995501, 'recall_word': 0.979295, 'acc_grapheme': 0.978442, 'acc_vowel': 0.993744, 'acc_consonant': 0.993171, 'acc_word': 0.978741, 'loss_grapheme': 0.297158, 'loss_vowel': 0.235015, 'loss_consonant': 0.150996, 'loss_word': 0.26695}\n",
      "    7 | 0.000144 | 160160/160716 | 21.6332 | 11.7979 |\n",
      "val: {'recall': 0.986764, 'recall_grapheme': 0.979627, 'recall_vowel': 0.992926, 'recall_consonant': 0.994878, 'recall_word': 0.978593, 'acc_grapheme': 0.978666, 'acc_vowel': 0.993695, 'acc_consonant': 0.993346, 'acc_word': 0.978242, 'loss_grapheme': 0.291204, 'loss_vowel': 0.225457, 'loss_consonant': 0.147016, 'loss_word': 0.267789}\n",
      "    8 | 0.000142 | 160160/160716 | 8.0661 | 12.4633 ||\n",
      "val: {'recall': 0.986438, 'recall_grapheme': 0.979036, 'recall_vowel': 0.992626, 'recall_consonant': 0.995055, 'recall_word': 0.977598, 'acc_grapheme': 0.977669, 'acc_vowel': 0.99342, 'acc_consonant': 0.993071, 'acc_word': 0.977221, 'loss_grapheme': 0.220956, 'loss_vowel': 0.167981, 'loss_consonant': 0.112175, 'loss_word': 0.202}\n",
      "    9 | 0.000140 | 160160/160716 | 20.0034 | 12.1568 |\n",
      "val: {'recall': 0.985895, 'recall_grapheme': 0.978452, 'recall_vowel': 0.992657, 'recall_consonant': 0.99402, 'recall_word': 0.978261, 'acc_grapheme': 0.977943, 'acc_vowel': 0.993545, 'acc_consonant': 0.993645, 'acc_word': 0.978018, 'loss_grapheme': 0.240949, 'loss_vowel': 0.179187, 'loss_consonant': 0.118441, 'loss_word': 0.221711}\n",
      "   10 | 0.000138 | 160160/160716 | 8.2060 | 11.7478 ||\n",
      "val: {'recall': 0.986037, 'recall_grapheme': 0.978314, 'recall_vowel': 0.992943, 'recall_consonant': 0.994578, 'recall_word': 0.976883, 'acc_grapheme': 0.977644, 'acc_vowel': 0.993495, 'acc_consonant': 0.993395, 'acc_word': 0.976473, 'loss_grapheme': 0.20587, 'loss_vowel': 0.140295, 'loss_consonant': 0.0957, 'loss_word': 0.196201}\n",
      "   11 | 0.000136 | 160160/160716 | 10.9800 | 11.5039 |\n",
      "val: {'recall': 0.986506, 'recall_grapheme': 0.979271, 'recall_vowel': 0.992784, 'recall_consonant': 0.994698, 'recall_word': 0.977004, 'acc_grapheme': 0.978068, 'acc_vowel': 0.993495, 'acc_consonant': 0.993545, 'acc_word': 0.976747, 'loss_grapheme': 0.20836, 'loss_vowel': 0.151727, 'loss_consonant': 0.100376, 'loss_word': 0.203408}\n",
      "   12 | 0.000133 | 160160/160716 | 8.9601 | 12.2451 ||\n",
      "val: {'recall': 0.986271, 'recall_grapheme': 0.978758, 'recall_vowel': 0.992684, 'recall_consonant': 0.994882, 'recall_word': 0.977498, 'acc_grapheme': 0.977769, 'acc_vowel': 0.993794, 'acc_consonant': 0.993719, 'acc_word': 0.97727, 'loss_grapheme': 0.190036, 'loss_vowel': 0.138571, 'loss_consonant': 0.094456, 'loss_word': 0.180325}\n",
      "   13 | 0.000131 | 160160/160716 | 14.2565 | 11.1526 |\n",
      "val: {'recall': 0.986809, 'recall_grapheme': 0.980042, 'recall_vowel': 0.992539, 'recall_consonant': 0.994613, 'recall_word': 0.977975, 'acc_grapheme': 0.978218, 'acc_vowel': 0.993894, 'acc_consonant': 0.993744, 'acc_word': 0.977669, 'loss_grapheme': 0.195572, 'loss_vowel': 0.14072, 'loss_consonant': 0.092757, 'loss_word': 0.185921}\n",
      "   14 | 0.000128 | 160160/160716 | 2.1135 | 11.8724 ||\n",
      "val: {'recall': 0.986406, 'recall_grapheme': 0.979323, 'recall_vowel': 0.992117, 'recall_consonant': 0.994858, 'recall_word': 0.978008, 'acc_grapheme': 0.978367, 'acc_vowel': 0.993545, 'acc_consonant': 0.993121, 'acc_word': 0.977819, 'loss_grapheme': 0.170642, 'loss_vowel': 0.120327, 'loss_consonant': 0.08109, 'loss_word': 0.160455}\n",
      "   15 | 0.000125 | 160160/160716 | 19.8580 | 11.7954 |\n",
      "val: {'recall': 0.987333, 'recall_grapheme': 0.981186, 'recall_vowel': 0.992184, 'recall_consonant': 0.994774, 'recall_word': 0.978869, 'acc_grapheme': 0.979339, 'acc_vowel': 0.99357, 'acc_consonant': 0.99367, 'acc_word': 0.978591, 'loss_grapheme': 0.221042, 'loss_vowel': 0.167495, 'loss_consonant': 0.111452, 'loss_word': 0.204371}\n",
      "   16 | 0.000122 | 160160/160716 | 5.7603 | 12.0602 ||\n",
      "val: {'recall': 0.985954, 'recall_grapheme': 0.979276, 'recall_vowel': 0.992132, 'recall_consonant': 0.993134, 'recall_word': 0.978683, 'acc_grapheme': 0.97899, 'acc_vowel': 0.993719, 'acc_consonant': 0.99347, 'acc_word': 0.978417, 'loss_grapheme': 0.198739, 'loss_vowel': 0.144586, 'loss_consonant': 0.099297, 'loss_word': 0.18567}\n",
      "   17 | 0.000119 | 160160/160716 | 21.9950 | 12.4155 |\n",
      "val: {'recall': 0.987726, 'recall_grapheme': 0.981668, 'recall_vowel': 0.992582, 'recall_consonant': 0.994988, 'recall_word': 0.978982, 'acc_grapheme': 0.979489, 'acc_vowel': 0.993869, 'acc_consonant': 0.993794, 'acc_word': 0.978616, 'loss_grapheme': 0.211273, 'loss_vowel': 0.158214, 'loss_consonant': 0.102964, 'loss_word': 0.193483}\n",
      "   18 | 0.000116 | 160160/160716 | 4.8397 | 11.3516 ||\n",
      "val: {'recall': 0.986819, 'recall_grapheme': 0.979927, 'recall_vowel': 0.992634, 'recall_consonant': 0.994788, 'recall_word': 0.978442, 'acc_grapheme': 0.979538, 'acc_vowel': 0.993645, 'acc_consonant': 0.993869, 'acc_word': 0.978267, 'loss_grapheme': 0.194774, 'loss_vowel': 0.140165, 'loss_consonant': 0.092054, 'loss_word': 0.185029}\n",
      "   19 | 0.000113 | 160160/160716 | 20.2565 | 11.6480 |\n",
      "val: {'recall': 0.986786, 'recall_grapheme': 0.979659, 'recall_vowel': 0.992417, 'recall_consonant': 0.99541, 'recall_word': 0.978137, 'acc_grapheme': 0.978616, 'acc_vowel': 0.993794, 'acc_consonant': 0.993744, 'acc_word': 0.977744, 'loss_grapheme': 0.231821, 'loss_vowel': 0.171579, 'loss_consonant': 0.116029, 'loss_word': 0.216041}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 0.000109 | 160160/160716 | 12.5166 | 11.4550 |\n",
      "val: {'recall': 0.987425, 'recall_grapheme': 0.980741, 'recall_vowel': 0.992662, 'recall_consonant': 0.995554, 'recall_word': 0.978316, 'acc_grapheme': 0.979264, 'acc_vowel': 0.994168, 'acc_consonant': 0.993869, 'acc_word': 0.977819, 'loss_grapheme': 0.180255, 'loss_vowel': 0.132443, 'loss_consonant': 0.090824, 'loss_word': 0.165787}\n",
      "   21 | 0.000106 | 160160/160716 | 6.8766 | 11.3363 ||\n",
      "val: {'recall': 0.987269, 'recall_grapheme': 0.980304, 'recall_vowel': 0.99329, 'recall_consonant': 0.995176, 'recall_word': 0.97823, 'acc_grapheme': 0.979289, 'acc_vowel': 0.994168, 'acc_consonant': 0.993445, 'acc_word': 0.977943, 'loss_grapheme': 0.169548, 'loss_vowel': 0.111923, 'loss_consonant': 0.080026, 'loss_word': 0.160665}\n",
      "   22 | 0.000102 | 160160/160716 | 11.1981 | 11.7928 |\n",
      "val: {'recall': 0.987309, 'recall_grapheme': 0.980512, 'recall_vowel': 0.992872, 'recall_consonant': 0.99534, 'recall_word': 0.979068, 'acc_grapheme': 0.978965, 'acc_vowel': 0.993719, 'acc_consonant': 0.994068, 'acc_word': 0.978766, 'loss_grapheme': 0.213235, 'loss_vowel': 0.150594, 'loss_consonant': 0.103631, 'loss_word': 0.191395}\n",
      "   23 | 0.000098 | 160160/160716 | 21.9850 | 11.6488 |\n",
      "val: {'recall': 0.987299, 'recall_grapheme': 0.980989, 'recall_vowel': 0.992852, 'recall_consonant': 0.994366, 'recall_word': 0.97924, 'acc_grapheme': 0.979489, 'acc_vowel': 0.993769, 'acc_consonant': 0.993744, 'acc_word': 0.978965, 'loss_grapheme': 0.277364, 'loss_vowel': 0.215998, 'loss_consonant': 0.139203, 'loss_word': 0.265638}\n",
      "   24 | 0.000094 | 160160/160716 | 5.2763 | 11.9064 ||\n",
      "val: {'recall': 0.987814, 'recall_grapheme': 0.981985, 'recall_vowel': 0.992351, 'recall_consonant': 0.994933, 'recall_word': 0.979138, 'acc_grapheme': 0.979763, 'acc_vowel': 0.99352, 'acc_consonant': 0.993719, 'acc_word': 0.97889, 'loss_grapheme': 0.202947, 'loss_vowel': 0.130772, 'loss_consonant': 0.089626, 'loss_word': 0.178624}\n",
      "   25 | 0.000091 | 160160/160716 | 8.0964 | 11.3871 ||\n",
      "val: {'recall': 0.986453, 'recall_grapheme': 0.979946, 'recall_vowel': 0.99274, 'recall_consonant': 0.993179, 'recall_word': 0.978818, 'acc_grapheme': 0.979538, 'acc_vowel': 0.994019, 'acc_consonant': 0.993744, 'acc_word': 0.978517, 'loss_grapheme': 0.19712, 'loss_vowel': 0.149002, 'loss_consonant': 0.099983, 'loss_word': 0.184652}\n",
      "   26 | 0.000087 | 160160/160716 | 2.7467 | 12.2997 ||\n",
      "val: {'recall': 0.9869, 'recall_grapheme': 0.980108, 'recall_vowel': 0.992578, 'recall_consonant': 0.994807, 'recall_word': 0.978352, 'acc_grapheme': 0.979713, 'acc_vowel': 0.993894, 'acc_consonant': 0.993969, 'acc_word': 0.978218, 'loss_grapheme': 0.182109, 'loss_vowel': 0.133805, 'loss_consonant': 0.08994, 'loss_word': 0.170709}\n",
      "   27 | 0.000083 | 160160/160716 | 11.3421 | 12.3596 |\n",
      "val: {'recall': 0.987576, 'recall_grapheme': 0.980946, 'recall_vowel': 0.992955, 'recall_consonant': 0.995458, 'recall_word': 0.980312, 'acc_grapheme': 0.980112, 'acc_vowel': 0.994293, 'acc_consonant': 0.993944, 'acc_word': 0.979987, 'loss_grapheme': 0.262039, 'loss_vowel': 0.196647, 'loss_consonant': 0.128663, 'loss_word': 0.225797}\n",
      "   28 | 0.000079 | 160160/160716 | 21.4531 | 12.1340 |\n",
      "val: {'recall': 0.987332, 'recall_grapheme': 0.980417, 'recall_vowel': 0.992866, 'recall_consonant': 0.995625, 'recall_word': 0.9792, 'acc_grapheme': 0.979389, 'acc_vowel': 0.994019, 'acc_consonant': 0.993495, 'acc_word': 0.978915, 'loss_grapheme': 0.226532, 'loss_vowel': 0.169822, 'loss_consonant': 0.11518, 'loss_word': 0.202788}\n",
      "   29 | 0.000075 | 160160/160716 | 12.3102 | 11.8980 |\n",
      "val: {'recall': 0.987269, 'recall_grapheme': 0.981361, 'recall_vowel': 0.992368, 'recall_consonant': 0.993985, 'recall_word': 0.979017, 'acc_grapheme': 0.979887, 'acc_vowel': 0.994068, 'acc_consonant': 0.99367, 'acc_word': 0.978716, 'loss_grapheme': 0.181258, 'loss_vowel': 0.132154, 'loss_consonant': 0.092274, 'loss_word': 0.170884}\n",
      "   30 | 0.000071 | 160160/160716 | 4.5539 | 11.1348 ||\n",
      "val: {'recall': 0.987379, 'recall_grapheme': 0.980613, 'recall_vowel': 0.992916, 'recall_consonant': 0.995374, 'recall_word': 0.978936, 'acc_grapheme': 0.979489, 'acc_vowel': 0.993994, 'acc_consonant': 0.993844, 'acc_word': 0.978666, 'loss_grapheme': 0.199965, 'loss_vowel': 0.150082, 'loss_consonant': 0.102014, 'loss_word': 0.182988}\n",
      "   31 | 0.000067 | 160160/160716 | 15.4486 | 11.6520 |\n",
      "val: {'recall': 0.988323, 'recall_grapheme': 0.982419, 'recall_vowel': 0.993021, 'recall_consonant': 0.995431, 'recall_word': 0.979204, 'acc_grapheme': 0.980161, 'acc_vowel': 0.994068, 'acc_consonant': 0.994068, 'acc_word': 0.978791, 'loss_grapheme': 0.163535, 'loss_vowel': 0.117619, 'loss_consonant': 0.07837, 'loss_word': 0.149876}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3.pth\n",
      "   32 | 0.000063 | 160160/160716 | 8.1662 | 11.8822 ||\n",
      "val: {'recall': 0.987596, 'recall_grapheme': 0.981309, 'recall_vowel': 0.99321, 'recall_consonant': 0.994557, 'recall_word': 0.979312, 'acc_grapheme': 0.980286, 'acc_vowel': 0.994043, 'acc_consonant': 0.994268, 'acc_word': 0.979115, 'loss_grapheme': 0.156427, 'loss_vowel': 0.114415, 'loss_consonant': 0.075413, 'loss_word': 0.144861}\n",
      "   33 | 0.000059 | 160160/160716 | 8.3683 | 11.9623 ||\n",
      "val: {'recall': 0.9872, 'recall_grapheme': 0.980506, 'recall_vowel': 0.992885, 'recall_consonant': 0.994904, 'recall_word': 0.978929, 'acc_grapheme': 0.979713, 'acc_vowel': 0.993794, 'acc_consonant': 0.993994, 'acc_word': 0.978591, 'loss_grapheme': 0.183056, 'loss_vowel': 0.131399, 'loss_consonant': 0.090947, 'loss_word': 0.165581}\n",
      "   34 | 0.000056 | 160160/160716 | 15.5551 | 12.1469 |\n",
      "val: {'recall': 0.987475, 'recall_grapheme': 0.981216, 'recall_vowel': 0.992597, 'recall_consonant': 0.994872, 'recall_word': 0.97922, 'acc_grapheme': 0.979613, 'acc_vowel': 0.993819, 'acc_consonant': 0.993894, 'acc_word': 0.978965, 'loss_grapheme': 0.213901, 'loss_vowel': 0.163947, 'loss_consonant': 0.110908, 'loss_word': 0.186047}\n",
      "   35 | 0.000052 | 160160/160716 | 21.2405 | 11.8537 |\n",
      "val: {'recall': 0.987691, 'recall_grapheme': 0.98165, 'recall_vowel': 0.99273, 'recall_consonant': 0.994732, 'recall_word': 0.979274, 'acc_grapheme': 0.980236, 'acc_vowel': 0.993869, 'acc_consonant': 0.993894, 'acc_word': 0.979065, 'loss_grapheme': 0.172791, 'loss_vowel': 0.12566, 'loss_consonant': 0.085, 'loss_word': 0.161771}\n",
      "   36 | 0.000048 | 160160/160716 | 18.6622 | 11.6774 |\n",
      "val: {'recall': 0.987416, 'recall_grapheme': 0.981162, 'recall_vowel': 0.992601, 'recall_consonant': 0.994739, 'recall_word': 0.979891, 'acc_grapheme': 0.980386, 'acc_vowel': 0.994019, 'acc_consonant': 0.994019, 'acc_word': 0.979713, 'loss_grapheme': 0.202923, 'loss_vowel': 0.154547, 'loss_consonant': 0.102562, 'loss_word': 0.182259}\n",
      "   37 | 0.000045 | 160160/160716 | 16.6444 | 12.0816 |\n",
      "val: {'recall': 0.987708, 'recall_grapheme': 0.981211, 'recall_vowel': 0.993008, 'recall_consonant': 0.9954, 'recall_word': 0.980022, 'acc_grapheme': 0.98056, 'acc_vowel': 0.994143, 'acc_consonant': 0.993944, 'acc_word': 0.979813, 'loss_grapheme': 0.222288, 'loss_vowel': 0.173977, 'loss_consonant': 0.113026, 'loss_word': 0.196709}\n",
      "   38 | 0.000041 | 160160/160716 | 8.0603 | 11.6702 ||\n",
      "val: {'recall': 0.988079, 'recall_grapheme': 0.982005, 'recall_vowel': 0.993152, 'recall_consonant': 0.995154, 'recall_word': 0.980076, 'acc_grapheme': 0.980585, 'acc_vowel': 0.994193, 'acc_consonant': 0.994143, 'acc_word': 0.979937, 'loss_grapheme': 0.240227, 'loss_vowel': 0.183411, 'loss_consonant': 0.119698, 'loss_word': 0.208044}\n",
      "   39 | 0.000038 | 160160/160716 | 9.4918 | 11.9352 ||\n",
      "val: {'recall': 0.986933, 'recall_grapheme': 0.980619, 'recall_vowel': 0.992528, 'recall_consonant': 0.993968, 'recall_word': 0.978692, 'acc_grapheme': 0.97909, 'acc_vowel': 0.99362, 'acc_consonant': 0.993445, 'acc_word': 0.978392, 'loss_grapheme': 0.176375, 'loss_vowel': 0.10858, 'loss_consonant': 0.081116, 'loss_word': 0.149692}\n",
      "   40 | 0.000034 | 160160/160716 | 10.8003 | 11.5982 |\n",
      "val: {'recall': 0.987665, 'recall_grapheme': 0.981416, 'recall_vowel': 0.992676, 'recall_consonant': 0.995152, 'recall_word': 0.979793, 'acc_grapheme': 0.979912, 'acc_vowel': 0.993894, 'acc_consonant': 0.994118, 'acc_word': 0.979588, 'loss_grapheme': 0.230109, 'loss_vowel': 0.178679, 'loss_consonant': 0.119588, 'loss_word': 0.200049}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 | 0.000031 | 160160/160716 | 1.3689 | 11.4202 ||\n",
      "val: {'recall': 0.988204, 'recall_grapheme': 0.981947, 'recall_vowel': 0.993381, 'recall_consonant': 0.995541, 'recall_word': 0.979776, 'acc_grapheme': 0.980685, 'acc_vowel': 0.994268, 'acc_consonant': 0.994343, 'acc_word': 0.979588, 'loss_grapheme': 0.183105, 'loss_vowel': 0.137544, 'loss_consonant': 0.090824, 'loss_word': 0.165487}\n",
      "   42 | 0.000028 | 160160/160716 | 9.3395 | 11.8952 ||\n",
      "val: {'recall': 0.988001, 'recall_grapheme': 0.981648, 'recall_vowel': 0.993227, 'recall_consonant': 0.995481, 'recall_word': 0.97985, 'acc_grapheme': 0.980585, 'acc_vowel': 0.994243, 'acc_consonant': 0.994068, 'acc_word': 0.979638, 'loss_grapheme': 0.220798, 'loss_vowel': 0.170995, 'loss_consonant': 0.112872, 'loss_word': 0.198475}\n",
      "   43 | 0.000025 | 160160/160716 | 23.0140 | 11.3666 |\n",
      "val: {'recall': 0.987604, 'recall_grapheme': 0.981609, 'recall_vowel': 0.993538, 'recall_consonant': 0.99366, 'recall_word': 0.979535, 'acc_grapheme': 0.980585, 'acc_vowel': 0.994392, 'acc_consonant': 0.994118, 'acc_word': 0.979339, 'loss_grapheme': 0.176072, 'loss_vowel': 0.131075, 'loss_consonant': 0.089056, 'loss_word': 0.159231}\n",
      "   44 | 0.000022 | 160160/160716 | 5.8701 | 11.8910 ||\n",
      "val: {'recall': 0.98777, 'recall_grapheme': 0.981602, 'recall_vowel': 0.993108, 'recall_consonant': 0.994769, 'recall_word': 0.979808, 'acc_grapheme': 0.980635, 'acc_vowel': 0.994093, 'acc_consonant': 0.993994, 'acc_word': 0.979538, 'loss_grapheme': 0.180979, 'loss_vowel': 0.134144, 'loss_consonant': 0.090823, 'loss_word': 0.164735}\n",
      "   45 | 0.000019 | 160160/160716 | 13.6890 | 11.4628 |\n",
      "val: {'recall': 0.987954, 'recall_grapheme': 0.981457, 'recall_vowel': 0.993164, 'recall_consonant': 0.99574, 'recall_word': 0.979988, 'acc_grapheme': 0.980261, 'acc_vowel': 0.994118, 'acc_consonant': 0.994118, 'acc_word': 0.979788, 'loss_grapheme': 0.245452, 'loss_vowel': 0.191995, 'loss_consonant': 0.125073, 'loss_word': 0.209063}\n",
      "   46 | 0.000017 | 160160/160716 | 4.5490 | 11.4065 ||\n",
      "val: {'recall': 0.988257, 'recall_grapheme': 0.982209, 'recall_vowel': 0.993037, 'recall_consonant': 0.995576, 'recall_word': 0.98012, 'acc_grapheme': 0.980809, 'acc_vowel': 0.994168, 'acc_consonant': 0.994318, 'acc_word': 0.979887, 'loss_grapheme': 0.180055, 'loss_vowel': 0.133326, 'loss_consonant': 0.089271, 'loss_word': 0.167045}\n",
      "   47 | 0.000014 | 160160/160716 | 2.6592 | 12.0598 ||\n",
      "val: {'recall': 0.988185, 'recall_grapheme': 0.981943, 'recall_vowel': 0.993576, 'recall_consonant': 0.995277, 'recall_word': 0.980093, 'acc_grapheme': 0.980735, 'acc_vowel': 0.994417, 'acc_consonant': 0.994268, 'acc_word': 0.979912, 'loss_grapheme': 0.174089, 'loss_vowel': 0.130308, 'loss_consonant': 0.085667, 'loss_word': 0.159154}\n",
      "   48 | 0.000012 | 160160/160716 | 14.1735 | 11.8086 |\n",
      "val: {'recall': 0.987385, 'recall_grapheme': 0.98088, 'recall_vowel': 0.992833, 'recall_consonant': 0.994945, 'recall_word': 0.979374, 'acc_grapheme': 0.980112, 'acc_vowel': 0.993944, 'acc_consonant': 0.994093, 'acc_word': 0.979214, 'loss_grapheme': 0.206671, 'loss_vowel': 0.156672, 'loss_consonant': 0.105403, 'loss_word': 0.184615}\n",
      "   49 | 0.000010 | 160160/160716 | 6.6767 | 10.6577 ||\n",
      "val: {'recall': 0.987027, 'recall_grapheme': 0.980679, 'recall_vowel': 0.992653, 'recall_consonant': 0.994096, 'recall_word': 0.978899, 'acc_grapheme': 0.979538, 'acc_vowel': 0.993595, 'acc_consonant': 0.99352, 'acc_word': 0.978666, 'loss_grapheme': 0.166916, 'loss_vowel': 0.101232, 'loss_consonant': 0.078438, 'loss_word': 0.141893}\n",
      "   50 | 0.000008 | 160160/160716 | 7.3084 | 11.3043 ||\n",
      "val: {'recall': 0.987884, 'recall_grapheme': 0.981619, 'recall_vowel': 0.99293, 'recall_consonant': 0.995368, 'recall_word': 0.979813, 'acc_grapheme': 0.98056, 'acc_vowel': 0.994218, 'acc_consonant': 0.994318, 'acc_word': 0.979588, 'loss_grapheme': 0.183215, 'loss_vowel': 0.134549, 'loss_consonant': 0.090213, 'loss_word': 0.165196}\n",
      "   51 | 0.000006 | 160160/160716 | 11.4759 | 12.6164 |\n",
      "val: {'recall': 0.988062, 'recall_grapheme': 0.98181, 'recall_vowel': 0.993243, 'recall_consonant': 0.995387, 'recall_word': 0.98024, 'acc_grapheme': 0.980809, 'acc_vowel': 0.994367, 'acc_consonant': 0.994392, 'acc_word': 0.980087, 'loss_grapheme': 0.23098, 'loss_vowel': 0.175539, 'loss_consonant': 0.116544, 'loss_word': 0.207186}\n",
      "   52 | 0.000005 | 160160/160716 | 22.0898 | 12.1506 |\n",
      "val: {'recall': 0.988411, 'recall_grapheme': 0.982404, 'recall_vowel': 0.993299, 'recall_consonant': 0.995536, 'recall_word': 0.980347, 'acc_grapheme': 0.981009, 'acc_vowel': 0.994343, 'acc_consonant': 0.994492, 'acc_word': 0.980186, 'loss_grapheme': 0.194234, 'loss_vowel': 0.146476, 'loss_consonant': 0.097591, 'loss_word': 0.170535}\n",
      "###>>>>> saved ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold3.pth\n",
      "   53 | 0.000004 | 160160/160716 | 10.9201 | 11.6520 |\n",
      "val: {'recall': 0.988235, 'recall_grapheme': 0.982049, 'recall_vowel': 0.99331, 'recall_consonant': 0.995532, 'recall_word': 0.980223, 'acc_grapheme': 0.98076, 'acc_vowel': 0.994343, 'acc_consonant': 0.994467, 'acc_word': 0.980087, 'loss_grapheme': 0.205258, 'loss_vowel': 0.157492, 'loss_consonant': 0.104375, 'loss_word': 0.179529}\n",
      "   54 | 0.000003 | 160160/160716 | 4.4895 | 12.6386 ||\n",
      "val: {'recall': 0.988301, 'recall_grapheme': 0.982232, 'recall_vowel': 0.992973, 'recall_consonant': 0.99577, 'recall_word': 0.980609, 'acc_grapheme': 0.980884, 'acc_vowel': 0.994168, 'acc_consonant': 0.994392, 'acc_word': 0.980411, 'loss_grapheme': 0.248141, 'loss_vowel': 0.190913, 'loss_consonant': 0.1238, 'loss_word': 0.216185}\n",
      "   55 | 0.000002 | 160160/160716 | 9.2356 | 11.2792 ||\n",
      "val: {'recall': 0.987016, 'recall_grapheme': 0.980651, 'recall_vowel': 0.992456, 'recall_consonant': 0.994306, 'recall_word': 0.979146, 'acc_grapheme': 0.979638, 'acc_vowel': 0.99362, 'acc_consonant': 0.993645, 'acc_word': 0.978965, 'loss_grapheme': 0.213885, 'loss_vowel': 0.139041, 'loss_consonant': 0.100142, 'loss_word': 0.176718}\n",
      "   56 | 0.000001 | 160160/160716 | 9.3198 | 10.8297 ||\n",
      "val: {'recall': 0.988117, 'recall_grapheme': 0.982041, 'recall_vowel': 0.99301, 'recall_consonant': 0.995375, 'recall_word': 0.979896, 'acc_grapheme': 0.98066, 'acc_vowel': 0.994193, 'acc_consonant': 0.994293, 'acc_word': 0.979663, 'loss_grapheme': 0.18359, 'loss_vowel': 0.132683, 'loss_consonant': 0.089302, 'loss_word': 0.165703}\n",
      "   57 | 0.000000 | 160160/160716 | 15.1286 | 11.4896 |\n",
      "val: {'recall': 0.987786, 'recall_grapheme': 0.981518, 'recall_vowel': 0.992779, 'recall_consonant': 0.995329, 'recall_word': 0.979361, 'acc_grapheme': 0.980386, 'acc_vowel': 0.994043, 'acc_consonant': 0.994318, 'acc_word': 0.97914, 'loss_grapheme': 0.1713, 'loss_vowel': 0.123921, 'loss_consonant': 0.08361, 'loss_word': 0.1564}\n",
      "   58 | 0.000000 | 160160/160716 | 7.6388 | 11.1155 ||\n",
      "val: {'recall': 0.987872, 'recall_grapheme': 0.981935, 'recall_vowel': 0.992838, 'recall_consonant': 0.99478, 'recall_word': 0.97976, 'acc_grapheme': 0.980485, 'acc_vowel': 0.994068, 'acc_consonant': 0.994118, 'acc_word': 0.979538, 'loss_grapheme': 0.184583, 'loss_vowel': 0.134422, 'loss_consonant': 0.08848, 'loss_word': 0.166867}\n",
      "   59 | 0.000000 | 160160/160716 | 5.0750 | 10.4057 ||\n",
      "val: {'recall': 0.987807, 'recall_grapheme': 0.981663, 'recall_vowel': 0.992982, 'recall_consonant': 0.994922, 'recall_word': 0.980003, 'acc_grapheme': 0.980535, 'acc_vowel': 0.994168, 'acc_consonant': 0.994143, 'acc_word': 0.979788, 'loss_grapheme': 0.213469, 'loss_vowel': 0.16359, 'loss_consonant': 0.107972, 'loss_word': 0.193912}\n",
      "CYCLE: 2\n",
      "    0 | 0.000030 | 160160/160716 | 4.3987 | 12.2186 ||\n",
      "val: {'recall': 0.987965, 'recall_grapheme': 0.981906, 'recall_vowel': 0.992891, 'recall_consonant': 0.995158, 'recall_word': 0.979495, 'acc_grapheme': 0.980311, 'acc_vowel': 0.994043, 'acc_consonant': 0.994068, 'acc_word': 0.979264, 'loss_grapheme': 0.178102, 'loss_vowel': 0.128605, 'loss_consonant': 0.085901, 'loss_word': 0.163055}\n",
      "    1 | 0.000060 | 160160/160716 | 8.1571 | 12.0850 ||\n",
      "val: {'recall': 0.987681, 'recall_grapheme': 0.98152, 'recall_vowel': 0.993185, 'recall_consonant': 0.994499, 'recall_word': 0.979257, 'acc_grapheme': 0.980286, 'acc_vowel': 0.994293, 'acc_consonant': 0.994218, 'acc_word': 0.97904, 'loss_grapheme': 0.160697, 'loss_vowel': 0.11519, 'loss_consonant': 0.078219, 'loss_word': 0.146208}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000064 | 022880/160716 | 10.0757 | 10.2515 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-02d2e1a4c9fc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-37d565e9b96c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# mixup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_aux1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_aux2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mloss_primary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss_aux1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_aux1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
