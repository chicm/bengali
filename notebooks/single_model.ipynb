{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install opencv-python\\n!pip install fastparquet\\n!pip install pyarrow\\n!pip install snappy\\n!conda install python-snappy -y\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install opencv-python\n",
    "!pip install fastparquet\n",
    "!pip install pyarrow\n",
    "!pip install snappy\n",
    "!conda install python-snappy -y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengaliai-cv19.zip\t   test_image_data_3.parquet\r\n",
      "class_map.csv\t\t   train.csv\r\n",
      "sample_submission.csv\t   train_image_data_0.parquet\r\n",
      "test.csv\t\t   train_image_data_1.parquet\r\n",
      "test_image_data_0.parquet  train_image_data_2.parquet\r\n",
      "test_image_data_1.parquet  train_image_data_3.parquet\r\n",
      "test_image_data_2.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/chicm/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200840, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.image_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72     5736\n",
       "64     5596\n",
       "13     5420\n",
       "107    5321\n",
       "23     5149\n",
       "       ... \n",
       "130     144\n",
       "158     143\n",
       "102     141\n",
       "33      136\n",
       "73      130\n",
       "Name: grapheme_root, Length: 168, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.grapheme_root.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>32322</th>\n",
       "      <th>32323</th>\n",
       "      <th>32324</th>\n",
       "      <th>32325</th>\n",
       "      <th>32326</th>\n",
       "      <th>32327</th>\n",
       "      <th>32328</th>\n",
       "      <th>32329</th>\n",
       "      <th>32330</th>\n",
       "      <th>32331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>251</td>\n",
       "      <td>244</td>\n",
       "      <td>238</td>\n",
       "      <td>245</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>248</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
       "0  Train_0  254  253  252  253  251  252  253  251  251  ...    253    253   \n",
       "1  Train_1  251  244  238  245  248  246  246  247  251  ...    255    255   \n",
       "2  Train_2  251  250  249  250  249  245  247  252  252  ...    254    253   \n",
       "3  Train_3  247  247  249  253  253  252  251  251  250  ...    254    254   \n",
       "4  Train_4  249  248  246  246  248  244  242  242  229  ...    255    255   \n",
       "\n",
       "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
       "0    253    253    253    253    253    253    253    251  \n",
       "1    255    255    255    255    255    255    255    254  \n",
       "2    252    252    253    253    253    253    251    249  \n",
       "3    254    254    254    253    253    252    251    252  \n",
       "4    255    255    255    255    255    255    255    255  \n",
       "\n",
       "[5 rows x 32333 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50210, 32333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32322</th>\n",
       "      <th>32323</th>\n",
       "      <th>32324</th>\n",
       "      <th>32325</th>\n",
       "      <th>32326</th>\n",
       "      <th>32327</th>\n",
       "      <th>32328</th>\n",
       "      <th>32329</th>\n",
       "      <th>32330</th>\n",
       "      <th>32331</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Train_0</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_1</td>\n",
       "      <td>251</td>\n",
       "      <td>244</td>\n",
       "      <td>238</td>\n",
       "      <td>245</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_2</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_3</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_4</td>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>248</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>229</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9  ...  32322  32323  \\\n",
       "image_id                                                    ...                 \n",
       "Train_0   254  253  252  253  251  252  253  251  251  253  ...    253    253   \n",
       "Train_1   251  244  238  245  248  246  246  247  251  252  ...    255    255   \n",
       "Train_2   251  250  249  250  249  245  247  252  252  252  ...    254    253   \n",
       "Train_3   247  247  249  253  253  252  251  251  250  250  ...    254    254   \n",
       "Train_4   249  248  246  246  248  244  242  242  229  225  ...    255    255   \n",
       "\n",
       "          32324  32325  32326  32327  32328  32329  32330  32331  \n",
       "image_id                                                          \n",
       "Train_0     253    253    253    253    253    253    253    251  \n",
       "Train_1     255    255    255    255    255    255    255    254  \n",
       "Train_2     252    252    253    253    253    253    251    249  \n",
       "Train_3     254    254    254    253    253    252    251    252  \n",
       "Train_4     255    255    255    255    255    255    255    255  \n",
       "\n",
       "[5 rows x 32332 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Train_0', 'Train_1', 'Train_2', 'Train_3', 'Train_4', 'Train_5',\n",
       "       'Train_6', 'Train_7', 'Train_8', 'Train_9',\n",
       "       ...\n",
       "       'Train_50200', 'Train_50201', 'Train_50202', 'Train_50203',\n",
       "       'Train_50204', 'Train_50205', 'Train_50206', 'Train_50207',\n",
       "       'Train_50208', 'Train_50209'],\n",
       "      dtype='object', name='image_id', length=50210)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = 255 - df.iloc[10, 1:].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img2 = cv2.resize(img, (256, 128))\n",
    "#plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = get_train_augs(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-32ad6cb7aa56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=augs(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    train = train_df.iloc[:split_index]\n",
    "    val = train_df.iloc[split_index:]\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor img, y in train_loader:\\n    print(img.size(), y.size())\\n    print(y)\\n    #print(img)\\n    #plt.imshow(img.squeeze()[0].numpy())\\n    break\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for img, y in train_loader:\n",
    "    print(img.size(), y.size())\n",
    "    print(y)\n",
    "    #print(img)\n",
    "    #plt.imshow(img.squeeze()[0].numpy())\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048, 5, 8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nargs = Namespace()\\nargs.backbone = 'se_resnext50_32x4d'\\nargs.ckp_name = 'best_model.pth'\\nargs.predict = False\\n\\nbnet = create_model(args)[0].cuda()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "\n",
    "bnet = create_model(args)[0].cuda()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 137, 236])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 186])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum().item()\n",
    "        res.append(correct_k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(batch_size=32, val_batch_size=128, dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(180756, 5) (20084, 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/best_model.pth, exist: False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400341889163127"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler.step(best_metrics)\n",
    "    else:\n",
    "        lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            if do_mixup:\n",
    "                img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            outputs = model(img)\n",
    "            \n",
    "            if do_mixup:\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100\n",
    "args.batch_size = 640\n",
    "args.val_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(180756, 5) (20084, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/best_model.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/best_model.pth...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e646c3d4b64b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#if torch.cuda.device_count() > 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#    model = nn.DataParallel(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-6dfe0967f147>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.982995, 'recall_grapheme': 0.976186, 'recall_vowel': 0.98771, 'recall_consonant': 0.991897, 'acc_grapheme': 0.974358, 'acc_vowel': 0.990689, 'acc_consonant': 0.991735, 'loss_grapheme': 0.110631, 'loss_vowel': 0.044344, 'loss_consonant': 0.033979}\n",
      "    0 | 0.000020 | 080000/180756 | 0.0313 | 0.0261 |\n",
      "val: {'recall': 0.979963, 'recall_grapheme': 0.973543, 'recall_vowel': 0.9868, 'recall_consonant': 0.985965, 'acc_grapheme': 0.972217, 'acc_vowel': 0.989494, 'acc_consonant': 0.991187, 'loss_grapheme': 0.119936, 'loss_vowel': 0.049913, 'loss_consonant': 0.037856}\n",
      "    0 | 0.000019 | 160000/180756 | 0.0173 | 0.0259 |\n",
      "val: {'recall': 0.982137, 'recall_grapheme': 0.975451, 'recall_vowel': 0.987014, 'recall_consonant': 0.990632, 'acc_grapheme': 0.973063, 'acc_vowel': 0.99054, 'acc_consonant': 0.991436, 'loss_grapheme': 0.116544, 'loss_vowel': 0.046634, 'loss_consonant': 0.037774}\n",
      "    1 | 0.000017 | 059600/180756 | 0.0142 | 0.0207 |\n",
      "val: {'recall': 0.981425, 'recall_grapheme': 0.974275, 'recall_vowel': 0.985239, 'recall_consonant': 0.991909, 'acc_grapheme': 0.972764, 'acc_vowel': 0.989892, 'acc_consonant': 0.991735, 'loss_grapheme': 0.118442, 'loss_vowel': 0.047641, 'loss_consonant': 0.037206}\n",
      "    1 | 0.000015 | 065600/180756 | 0.0288 | 0.0207 |"
     ]
    }
   ],
   "source": [
    "train(args) # 224 apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.982824, 'recall_grapheme': 0.974935, 'recall_vowel': 0.988783, 'recall_consonant': 0.992641, 'acc_grapheme': 0.972764, 'acc_vowel': 0.991038, 'acc_consonant': 0.992083, 'loss_grapheme': 0.125657, 'loss_vowel': 0.048525, 'loss_consonant': 0.038285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.000048 | 102400/180756 | 3.2615 | 1.4118 |\n",
      "val: {'recall': 0.97843, 'recall_grapheme': 0.969373, 'recall_vowel': 0.985765, 'recall_consonant': 0.98921, 'acc_grapheme': 0.968731, 'acc_vowel': 0.989743, 'acc_consonant': 0.990988, 'loss_grapheme': 0.13156, 'loss_vowel': 0.051558, 'loss_consonant': 0.039783}\n",
      "    1 | 0.000043 | 024064/180756 | 0.0343 | 1.7944 |\n",
      "val: {'recall': 0.977958, 'recall_grapheme': 0.967824, 'recall_vowel': 0.986971, 'recall_consonant': 0.989212, 'acc_grapheme': 0.966391, 'acc_vowel': 0.989544, 'acc_consonant': 0.990938, 'loss_grapheme': 0.147742, 'loss_vowel': 0.061956, 'loss_consonant': 0.049779}\n",
      "    1 | 0.000035 | 126464/180756 | 3.8145 | 1.3723 |\n",
      "val: {'recall': 0.977738, 'recall_grapheme': 0.967739, 'recall_vowel': 0.985267, 'recall_consonant': 0.990207, 'acc_grapheme': 0.967935, 'acc_vowel': 0.989544, 'acc_consonant': 0.991137, 'loss_grapheme': 0.131048, 'loss_vowel': 0.053109, 'loss_consonant': 0.040805}\n",
      "    2 | 0.000026 | 048128/180756 | 0.0428 | 0.9521 |\n",
      "val: {'recall': 0.978504, 'recall_grapheme': 0.968809, 'recall_vowel': 0.985889, 'recall_consonant': 0.990509, 'acc_grapheme': 0.968731, 'acc_vowel': 0.989544, 'acc_consonant': 0.991735, 'loss_grapheme': 0.131776, 'loss_vowel': 0.053143, 'loss_consonant': 0.040148}\n",
      "    2 | 0.000016 | 150528/180756 | 0.0537 | 1.0677 |\n",
      "val: {'recall': 0.979426, 'recall_grapheme': 0.970213, 'recall_vowel': 0.985162, 'recall_consonant': 0.992117, 'acc_grapheme': 0.970723, 'acc_vowel': 0.989843, 'acc_consonant': 0.991287, 'loss_grapheme': 0.122407, 'loss_vowel': 0.048146, 'loss_consonant': 0.036979}\n",
      "    3 | 0.000008 | 072192/180756 | 3.0074 | 1.3269 |\n",
      "val: {'recall': 0.979504, 'recall_grapheme': 0.970912, 'recall_vowel': 0.986391, 'recall_consonant': 0.989802, 'acc_grapheme': 0.970325, 'acc_vowel': 0.990241, 'acc_consonant': 0.991287, 'loss_grapheme': 0.123653, 'loss_vowel': 0.052083, 'loss_consonant': 0.039023}\n",
      "    3 | 0.000003 | 174592/180756 | 3.2038 | 1.3032 |\n",
      "val: {'recall': 0.979406, 'recall_grapheme': 0.970726, 'recall_vowel': 0.986394, 'recall_consonant': 0.989777, 'acc_grapheme': 0.970275, 'acc_vowel': 0.990191, 'acc_consonant': 0.991336, 'loss_grapheme': 0.126168, 'loss_vowel': 0.05435, 'loss_consonant': 0.040519}\n",
      "    4 | 0.000001 | 096256/180756 | 0.0112 | 1.2217 |\n",
      "val: {'recall': 0.979963, 'recall_grapheme': 0.971852, 'recall_vowel': 0.986904, 'recall_consonant': 0.989243, 'acc_grapheme': 0.971818, 'acc_vowel': 0.990938, 'acc_consonant': 0.991237, 'loss_grapheme': 0.117167, 'loss_vowel': 0.042985, 'loss_consonant': 0.034284}\n",
      "    5 | 0.000003 | 017920/180756 | 0.0343 | 0.9202 |\n",
      "val: {'recall': 0.980083, 'recall_grapheme': 0.971706, 'recall_vowel': 0.987419, 'recall_consonant': 0.9895, 'acc_grapheme': 0.971221, 'acc_vowel': 0.990838, 'acc_consonant': 0.991087, 'loss_grapheme': 0.117512, 'loss_vowel': 0.044529, 'loss_consonant': 0.03519}\n",
      "    5 | 0.000008 | 120320/180756 | 0.0210 | 1.0818 |\n",
      "val: {'recall': 0.980026, 'recall_grapheme': 0.971601, 'recall_vowel': 0.986929, 'recall_consonant': 0.989971, 'acc_grapheme': 0.971121, 'acc_vowel': 0.990191, 'acc_consonant': 0.991287, 'loss_grapheme': 0.11767, 'loss_vowel': 0.047255, 'loss_consonant': 0.037227}\n",
      "    6 | 0.000016 | 041984/180756 | 0.0294 | 1.1499 |\n",
      "val: {'recall': 0.97901, 'recall_grapheme': 0.970235, 'recall_vowel': 0.985993, 'recall_consonant': 0.989577, 'acc_grapheme': 0.970424, 'acc_vowel': 0.990141, 'acc_consonant': 0.991336, 'loss_grapheme': 0.121495, 'loss_vowel': 0.04911, 'loss_consonant': 0.038406}\n",
      "    6 | 0.000025 | 144384/180756 | 0.0297 | 1.0883 |\n",
      "val: {'recall': 0.979541, 'recall_grapheme': 0.970372, 'recall_vowel': 0.987486, 'recall_consonant': 0.989936, 'acc_grapheme': 0.971221, 'acc_vowel': 0.99049, 'acc_consonant': 0.991486, 'loss_grapheme': 0.119076, 'loss_vowel': 0.043769, 'loss_consonant': 0.034371}\n",
      "    7 | 0.000035 | 066048/180756 | 0.0284 | 1.0096 |\n",
      "val: {'recall': 0.979221, 'recall_grapheme': 0.970211, 'recall_vowel': 0.986487, 'recall_consonant': 0.989974, 'acc_grapheme': 0.970773, 'acc_vowel': 0.990141, 'acc_consonant': 0.991486, 'loss_grapheme': 0.12117, 'loss_vowel': 0.044289, 'loss_consonant': 0.034565}\n",
      "    7 | 0.000043 | 168448/180756 | 0.0355 | 1.2341 |\n",
      "val: {'recall': 0.977572, 'recall_grapheme': 0.967929, 'recall_vowel': 0.986525, 'recall_consonant': 0.987903, 'acc_grapheme': 0.96898, 'acc_vowel': 0.990042, 'acc_consonant': 0.991386, 'loss_grapheme': 0.128014, 'loss_vowel': 0.046328, 'loss_consonant': 0.036559}\n",
      "    8 | 0.000048 | 090112/180756 | 1.6038 | 1.0088 |\n",
      "val: {'recall': 0.97708, 'recall_grapheme': 0.965326, 'recall_vowel': 0.984176, 'recall_consonant': 0.99349, 'acc_grapheme': 0.965196, 'acc_vowel': 0.989195, 'acc_consonant': 0.991436, 'loss_grapheme': 0.139971, 'loss_vowel': 0.051981, 'loss_consonant': 0.040047}\n",
      "    9 | 0.000050 | 011776/180756 | 0.0486 | 0.7297 |\n",
      "val: {'recall': 0.977263, 'recall_grapheme': 0.968348, 'recall_vowel': 0.986567, 'recall_consonant': 0.98579, 'acc_grapheme': 0.968383, 'acc_vowel': 0.989793, 'acc_consonant': 0.991436, 'loss_grapheme': 0.124326, 'loss_vowel': 0.04562, 'loss_consonant': 0.034891}\n",
      "    9 | 0.000048 | 114176/180756 | 0.0444 | 1.2430 |\n",
      "val: {'recall': 0.976662, 'recall_grapheme': 0.965875, 'recall_vowel': 0.986564, 'recall_consonant': 0.988334, 'acc_grapheme': 0.967138, 'acc_vowel': 0.989942, 'acc_consonant': 0.991237, 'loss_grapheme': 0.130486, 'loss_vowel': 0.050042, 'loss_consonant': 0.039658}\n",
      "   10 | 0.000043 | 035840/180756 | 0.0241 | 1.1594 |\n",
      "val: {'recall': 0.979004, 'recall_grapheme': 0.969186, 'recall_vowel': 0.986071, 'recall_consonant': 0.991574, 'acc_grapheme': 0.967785, 'acc_vowel': 0.989793, 'acc_consonant': 0.991436, 'loss_grapheme': 0.132684, 'loss_vowel': 0.050396, 'loss_consonant': 0.03906}\n",
      "   10 | 0.000035 | 138240/180756 | 0.0221 | 1.1128 |\n",
      "val: {'recall': 0.979807, 'recall_grapheme': 0.970596, 'recall_vowel': 0.987028, 'recall_consonant': 0.991008, 'acc_grapheme': 0.969379, 'acc_vowel': 0.990141, 'acc_consonant': 0.991486, 'loss_grapheme': 0.118134, 'loss_vowel': 0.045732, 'loss_consonant': 0.03615}\n",
      "   11 | 0.000026 | 059904/180756 | 0.0247 | 0.9352 |\n",
      "val: {'recall': 0.980067, 'recall_grapheme': 0.970993, 'recall_vowel': 0.987256, 'recall_consonant': 0.991026, 'acc_grapheme': 0.971619, 'acc_vowel': 0.990739, 'acc_consonant': 0.991536, 'loss_grapheme': 0.11478, 'loss_vowel': 0.043576, 'loss_consonant': 0.035137}\n",
      "   11 | 0.000016 | 162304/180756 | 0.0221 | 1.1646 |\n",
      "val: {'recall': 0.979465, 'recall_grapheme': 0.971202, 'recall_vowel': 0.986738, 'recall_consonant': 0.988717, 'acc_grapheme': 0.970574, 'acc_vowel': 0.990341, 'acc_consonant': 0.991287, 'loss_grapheme': 0.118368, 'loss_vowel': 0.047988, 'loss_consonant': 0.036679}\n",
      "   12 | 0.000008 | 083968/180756 | 0.0162 | 1.2469 |\n",
      "val: {'recall': 0.979654, 'recall_grapheme': 0.969791, 'recall_vowel': 0.986728, 'recall_consonant': 0.992306, 'acc_grapheme': 0.970325, 'acc_vowel': 0.99039, 'acc_consonant': 0.991984, 'loss_grapheme': 0.118978, 'loss_vowel': 0.049392, 'loss_consonant': 0.038175}\n",
      "   13 | 0.000003 | 005632/180756 | 1.9448 | 0.3992 |\n",
      "val: {'recall': 0.981475, 'recall_grapheme': 0.973469, 'recall_vowel': 0.987369, 'recall_consonant': 0.991595, 'acc_grapheme': 0.972366, 'acc_vowel': 0.990689, 'acc_consonant': 0.991536, 'loss_grapheme': 0.11463, 'loss_vowel': 0.043635, 'loss_consonant': 0.033781}\n",
      "   13 | 0.000001 | 108032/180756 | 2.6903 | 0.9922 |\n",
      "val: {'recall': 0.979573, 'recall_grapheme': 0.970953, 'recall_vowel': 0.98682, 'recall_consonant': 0.989566, 'acc_grapheme': 0.971121, 'acc_vowel': 0.99054, 'acc_consonant': 0.991834, 'loss_grapheme': 0.115588, 'loss_vowel': 0.046927, 'loss_consonant': 0.036493}\n",
      "   14 | 0.000003 | 029696/180756 | 0.0090 | 1.2113 |\n",
      "val: {'recall': 0.980434, 'recall_grapheme': 0.972864, 'recall_vowel': 0.987125, 'recall_consonant': 0.988884, 'acc_grapheme': 0.972466, 'acc_vowel': 0.990639, 'acc_consonant': 0.991685, 'loss_grapheme': 0.113122, 'loss_vowel': 0.045125, 'loss_consonant': 0.034597}\n",
      "   14 | 0.000008 | 132096/180756 | 0.0424 | 1.0160 |\n",
      "val: {'recall': 0.979018, 'recall_grapheme': 0.969623, 'recall_vowel': 0.987273, 'recall_consonant': 0.989555, 'acc_grapheme': 0.970773, 'acc_vowel': 0.99059, 'acc_consonant': 0.991635, 'loss_grapheme': 0.113624, 'loss_vowel': 0.045994, 'loss_consonant': 0.035212}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 0.000016 | 053760/180756 | 1.0664 | 0.8372 |\n",
      "val: {'recall': 0.981438, 'recall_grapheme': 0.973326, 'recall_vowel': 0.987532, 'recall_consonant': 0.991566, 'acc_grapheme': 0.972117, 'acc_vowel': 0.990639, 'acc_consonant': 0.991536, 'loss_grapheme': 0.114547, 'loss_vowel': 0.044488, 'loss_consonant': 0.034962}\n",
      "   15 | 0.000025 | 156160/180756 | 0.0222 | 1.0311 |\n",
      "val: {'recall': 0.978847, 'recall_grapheme': 0.969373, 'recall_vowel': 0.986988, 'recall_consonant': 0.989652, 'acc_grapheme': 0.969578, 'acc_vowel': 0.99059, 'acc_consonant': 0.991336, 'loss_grapheme': 0.120258, 'loss_vowel': 0.051157, 'loss_consonant': 0.038007}\n",
      "   16 | 0.000035 | 077824/180756 | 3.9964 | 0.9425 |\n",
      "val: {'recall': 0.979803, 'recall_grapheme': 0.970898, 'recall_vowel': 0.988269, 'recall_consonant': 0.989147, 'acc_grapheme': 0.970225, 'acc_vowel': 0.990092, 'acc_consonant': 0.991685, 'loss_grapheme': 0.122257, 'loss_vowel': 0.047853, 'loss_consonant': 0.035619}\n",
      "   16 | 0.000043 | 180224/180756 | 2.7492 | 0.9488 |\n",
      "val: {'recall': 0.978141, 'recall_grapheme': 0.968454, 'recall_vowel': 0.984517, 'recall_consonant': 0.991137, 'acc_grapheme': 0.968881, 'acc_vowel': 0.988847, 'acc_consonant': 0.990739, 'loss_grapheme': 0.127942, 'loss_vowel': 0.065396, 'loss_consonant': 0.044429}\n",
      "   17 | 0.000048 | 101888/180756 | 0.0344 | 1.1351 |\n",
      "val: {'recall': 0.978684, 'recall_grapheme': 0.967182, 'recall_vowel': 0.98806, 'recall_consonant': 0.992313, 'acc_grapheme': 0.968482, 'acc_vowel': 0.990042, 'acc_consonant': 0.991386, 'loss_grapheme': 0.130032, 'loss_vowel': 0.053612, 'loss_consonant': 0.040752}\n",
      "   18 | 0.000050 | 023552/180756 | 0.0334 | 0.8727 |\n",
      "val: {'recall': 0.979746, 'recall_grapheme': 0.969427, 'recall_vowel': 0.987967, 'recall_consonant': 0.992164, 'acc_grapheme': 0.967885, 'acc_vowel': 0.989992, 'acc_consonant': 0.99054, 'loss_grapheme': 0.126886, 'loss_vowel': 0.044125, 'loss_consonant': 0.037162}\n",
      "   18 | 0.000048 | 125952/180756 | 2.7252 | 1.0436 |\n",
      "val: {'recall': 0.977643, 'recall_grapheme': 0.966846, 'recall_vowel': 0.986962, 'recall_consonant': 0.989921, 'acc_grapheme': 0.965595, 'acc_vowel': 0.988897, 'acc_consonant': 0.990141, 'loss_grapheme': 0.143913, 'loss_vowel': 0.064202, 'loss_consonant': 0.053869}\n",
      "   19 | 0.000043 | 047616/180756 | 2.2452 | 1.4868 |\n",
      "val: {'recall': 0.977716, 'recall_grapheme': 0.967844, 'recall_vowel': 0.986679, 'recall_consonant': 0.988498, 'acc_grapheme': 0.968283, 'acc_vowel': 0.989992, 'acc_consonant': 0.99059, 'loss_grapheme': 0.134908, 'loss_vowel': 0.05703, 'loss_consonant': 0.043534}\n",
      "   19 | 0.000035 | 150016/180756 | 0.0206 | 1.1687 |\n",
      "val: {'recall': 0.979314, 'recall_grapheme': 0.96965, 'recall_vowel': 0.986456, 'recall_consonant': 0.9915, 'acc_grapheme': 0.970723, 'acc_vowel': 0.989942, 'acc_consonant': 0.991087, 'loss_grapheme': 0.119547, 'loss_vowel': 0.043618, 'loss_consonant': 0.037265}\n",
      "   20 | 0.000026 | 071680/180756 | 0.0211 | 0.8821 |\n",
      "val: {'recall': 0.979248, 'recall_grapheme': 0.971998, 'recall_vowel': 0.985589, 'recall_consonant': 0.987405, 'acc_grapheme': 0.970574, 'acc_vowel': 0.990341, 'acc_consonant': 0.991137, 'loss_grapheme': 0.124405, 'loss_vowel': 0.043812, 'loss_consonant': 0.038545}\n",
      "   20 | 0.000016 | 174080/180756 | 0.0126 | 1.0136 |\n",
      "val: {'recall': 0.978539, 'recall_grapheme': 0.968182, 'recall_vowel': 0.986069, 'recall_consonant': 0.991722, 'acc_grapheme': 0.969578, 'acc_vowel': 0.990341, 'acc_consonant': 0.991436, 'loss_grapheme': 0.120309, 'loss_vowel': 0.046865, 'loss_consonant': 0.03681}\n",
      "   21 | 0.000008 | 095744/180756 | 1.0214 | 1.1689 |\n",
      "val: {'recall': 0.979713, 'recall_grapheme': 0.970109, 'recall_vowel': 0.986714, 'recall_consonant': 0.991922, 'acc_grapheme': 0.970574, 'acc_vowel': 0.99039, 'acc_consonant': 0.991536, 'loss_grapheme': 0.118615, 'loss_vowel': 0.045223, 'loss_consonant': 0.035866}\n",
      "   22 | 0.000003 | 017408/180756 | 1.6081 | 1.3094 |\n",
      "val: {'recall': 0.979416, 'recall_grapheme': 0.969576, 'recall_vowel': 0.986727, 'recall_consonant': 0.991783, 'acc_grapheme': 0.970275, 'acc_vowel': 0.990191, 'acc_consonant': 0.991685, 'loss_grapheme': 0.119531, 'loss_vowel': 0.049847, 'loss_consonant': 0.038453}\n",
      "   22 | 0.000001 | 119808/180756 | 0.0136 | 0.9960 |\n",
      "val: {'recall': 0.979563, 'recall_grapheme': 0.969619, 'recall_vowel': 0.987027, 'recall_consonant': 0.991987, 'acc_grapheme': 0.970623, 'acc_vowel': 0.99054, 'acc_consonant': 0.991685, 'loss_grapheme': 0.117546, 'loss_vowel': 0.047164, 'loss_consonant': 0.037636}\n",
      "   23 | 0.000003 | 041472/180756 | 0.0344 | 1.0532 |\n",
      "val: {'recall': 0.980217, 'recall_grapheme': 0.970541, 'recall_vowel': 0.987818, 'recall_consonant': 0.991967, 'acc_grapheme': 0.971121, 'acc_vowel': 0.990739, 'acc_consonant': 0.991834, 'loss_grapheme': 0.117017, 'loss_vowel': 0.044369, 'loss_consonant': 0.035628}\n",
      "   23 | 0.000008 | 143872/180756 | 0.0181 | 1.0333 |\n",
      "val: {'recall': 0.980116, 'recall_grapheme': 0.970945, 'recall_vowel': 0.986733, 'recall_consonant': 0.991843, 'acc_grapheme': 0.971121, 'acc_vowel': 0.99059, 'acc_consonant': 0.991884, 'loss_grapheme': 0.117348, 'loss_vowel': 0.0432, 'loss_consonant': 0.034512}\n",
      "   24 | 0.000016 | 065536/180756 | 2.5180 | 0.9776 |\n",
      "val: {'recall': 0.979551, 'recall_grapheme': 0.969915, 'recall_vowel': 0.985692, 'recall_consonant': 0.992682, 'acc_grapheme': 0.971121, 'acc_vowel': 0.989892, 'acc_consonant': 0.991834, 'loss_grapheme': 0.116221, 'loss_vowel': 0.049378, 'loss_consonant': 0.038724}\n",
      "   24 | 0.000025 | 167936/180756 | 2.9772 | 1.0618 |\n",
      "val: {'recall': 0.978959, 'recall_grapheme': 0.968859, 'recall_vowel': 0.986664, 'recall_consonant': 0.991453, 'acc_grapheme': 0.96903, 'acc_vowel': 0.989693, 'acc_consonant': 0.991237, 'loss_grapheme': 0.124547, 'loss_vowel': 0.047598, 'loss_consonant': 0.036191}\n",
      "   25 | 0.000035 | 089600/180756 | 0.0476 | 0.8789 |\n",
      "val: {'recall': 0.979047, 'recall_grapheme': 0.967729, 'recall_vowel': 0.989075, 'recall_consonant': 0.991655, 'acc_grapheme': 0.968532, 'acc_vowel': 0.990341, 'acc_consonant': 0.990988, 'loss_grapheme': 0.124941, 'loss_vowel': 0.047933, 'loss_consonant': 0.036454}\n",
      "   26 | 0.000043 | 011264/180756 | 1.8816 | 0.8579 |\n",
      "val: {'recall': 0.978203, 'recall_grapheme': 0.96879, 'recall_vowel': 0.985807, 'recall_consonant': 0.989426, 'acc_grapheme': 0.969478, 'acc_vowel': 0.989594, 'acc_consonant': 0.991287, 'loss_grapheme': 0.125247, 'loss_vowel': 0.045158, 'loss_consonant': 0.03657}\n",
      "   26 | 0.000048 | 113664/180756 | 2.0988 | 1.2542 |\n",
      "val: {'recall': 0.976663, 'recall_grapheme': 0.965946, 'recall_vowel': 0.985332, 'recall_consonant': 0.989427, 'acc_grapheme': 0.965445, 'acc_vowel': 0.988897, 'acc_consonant': 0.99054, 'loss_grapheme': 0.135513, 'loss_vowel': 0.05853, 'loss_consonant': 0.04382}\n",
      "   27 | 0.000050 | 035328/180756 | 0.0527 | 1.0524 |\n",
      "val: {'recall': 0.977602, 'recall_grapheme': 0.967624, 'recall_vowel': 0.984656, 'recall_consonant': 0.990502, 'acc_grapheme': 0.967437, 'acc_vowel': 0.989146, 'acc_consonant': 0.991137, 'loss_grapheme': 0.134211, 'loss_vowel': 0.054718, 'loss_consonant': 0.04061}\n",
      "   27 | 0.000048 | 137728/180756 | 3.1837 | 1.0096 |\n",
      "val: {'recall': 0.978157, 'recall_grapheme': 0.969082, 'recall_vowel': 0.986491, 'recall_consonant': 0.987973, 'acc_grapheme': 0.969229, 'acc_vowel': 0.990141, 'acc_consonant': 0.991486, 'loss_grapheme': 0.125292, 'loss_vowel': 0.04949, 'loss_consonant': 0.038597}\n",
      "   28 | 0.000043 | 059392/180756 | 2.4531 | 1.2059 |\n",
      "val: {'recall': 0.9783, 'recall_grapheme': 0.969156, 'recall_vowel': 0.986569, 'recall_consonant': 0.988317, 'acc_grapheme': 0.968333, 'acc_vowel': 0.990042, 'acc_consonant': 0.991137, 'loss_grapheme': 0.126607, 'loss_vowel': 0.054053, 'loss_consonant': 0.041103}\n",
      "   28 | 0.000035 | 161792/180756 | 3.2937 | 0.9286 |\n",
      "val: {'recall': 0.978845, 'recall_grapheme': 0.969671, 'recall_vowel': 0.987553, 'recall_consonant': 0.988485, 'acc_grapheme': 0.969628, 'acc_vowel': 0.990888, 'acc_consonant': 0.991436, 'loss_grapheme': 0.125147, 'loss_vowel': 0.042884, 'loss_consonant': 0.034714}\n",
      "   29 | 0.000025 | 083456/180756 | 2.7769 | 1.0717 |\n",
      "val: {'recall': 0.979883, 'recall_grapheme': 0.971237, 'recall_vowel': 0.988252, 'recall_consonant': 0.988806, 'acc_grapheme': 0.970823, 'acc_vowel': 0.990988, 'acc_consonant': 0.992183, 'loss_grapheme': 0.116673, 'loss_vowel': 0.044598, 'loss_consonant': 0.034716}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 0.000016 | 005120/180756 | 0.0101 | 1.5130 |\n",
      "val: {'recall': 0.980206, 'recall_grapheme': 0.970435, 'recall_vowel': 0.98742, 'recall_consonant': 0.992535, 'acc_grapheme': 0.970125, 'acc_vowel': 0.990241, 'acc_consonant': 0.992033, 'loss_grapheme': 0.118664, 'loss_vowel': 0.047526, 'loss_consonant': 0.035762}\n",
      "   30 | 0.000008 | 107520/180756 | 0.0141 | 1.1993 |\n",
      "val: {'recall': 0.9795, 'recall_grapheme': 0.970165, 'recall_vowel': 0.987713, 'recall_consonant': 0.989957, 'acc_grapheme': 0.97147, 'acc_vowel': 0.99049, 'acc_consonant': 0.992183, 'loss_grapheme': 0.11555, 'loss_vowel': 0.043591, 'loss_consonant': 0.033442}\n",
      "   31 | 0.000003 | 029184/180756 | 0.0130 | 0.8759 |\n",
      "val: {'recall': 0.980991, 'recall_grapheme': 0.971537, 'recall_vowel': 0.988508, 'recall_consonant': 0.992381, 'acc_grapheme': 0.972615, 'acc_vowel': 0.990988, 'acc_consonant': 0.992382, 'loss_grapheme': 0.114167, 'loss_vowel': 0.042793, 'loss_consonant': 0.03382}\n",
      "   31 | 0.000001 | 131584/180756 | 0.0087 | 1.0126 |\n",
      "val: {'recall': 0.979702, 'recall_grapheme': 0.970735, 'recall_vowel': 0.986954, 'recall_consonant': 0.990382, 'acc_grapheme': 0.97147, 'acc_vowel': 0.99059, 'acc_consonant': 0.992432, 'loss_grapheme': 0.115179, 'loss_vowel': 0.04474, 'loss_consonant': 0.034882}\n",
      "   32 | 0.000003 | 053248/180756 | 0.0112 | 0.7515 |\n",
      "val: {'recall': 0.981266, 'recall_grapheme': 0.972351, 'recall_vowel': 0.987936, 'recall_consonant': 0.992428, 'acc_grapheme': 0.972416, 'acc_vowel': 0.990689, 'acc_consonant': 0.992382, 'loss_grapheme': 0.114928, 'loss_vowel': 0.04389, 'loss_consonant': 0.034089}\n",
      "   32 | 0.000008 | 155648/180756 | 0.0078 | 0.9291 |\n",
      "val: {'recall': 0.979502, 'recall_grapheme': 0.97011, 'recall_vowel': 0.987646, 'recall_consonant': 0.990142, 'acc_grapheme': 0.97152, 'acc_vowel': 0.99049, 'acc_consonant': 0.991884, 'loss_grapheme': 0.114335, 'loss_vowel': 0.045964, 'loss_consonant': 0.035269}\n",
      "   33 | 0.000016 | 077312/180756 | 3.2593 | 0.9885 |\n",
      "val: {'recall': 0.978775, 'recall_grapheme': 0.968827, 'recall_vowel': 0.985215, 'recall_consonant': 0.992232, 'acc_grapheme': 0.970524, 'acc_vowel': 0.989942, 'acc_consonant': 0.991685, 'loss_grapheme': 0.120425, 'loss_vowel': 0.047811, 'loss_consonant': 0.037311}\n",
      "   33 | 0.000025 | 179712/180756 | 0.0147 | 0.9589 |\n",
      "val: {'recall': 0.979618, 'recall_grapheme': 0.970592, 'recall_vowel': 0.98719, 'recall_consonant': 0.990097, 'acc_grapheme': 0.970723, 'acc_vowel': 0.990241, 'acc_consonant': 0.991785, 'loss_grapheme': 0.121185, 'loss_vowel': 0.044872, 'loss_consonant': 0.034193}\n",
      "   34 | 0.000035 | 101376/180756 | 0.0203 | 0.9503 |\n",
      "val: {'recall': 0.979611, 'recall_grapheme': 0.970011, 'recall_vowel': 0.986795, 'recall_consonant': 0.991627, 'acc_grapheme': 0.969578, 'acc_vowel': 0.990241, 'acc_consonant': 0.991436, 'loss_grapheme': 0.129983, 'loss_vowel': 0.045386, 'loss_consonant': 0.03609}\n",
      "   35 | 0.000043 | 023040/180756 | 3.4578 | 1.0300 |\n",
      "val: {'recall': 0.978235, 'recall_grapheme': 0.968248, 'recall_vowel': 0.987067, 'recall_consonant': 0.989378, 'acc_grapheme': 0.968781, 'acc_vowel': 0.989992, 'acc_consonant': 0.991287, 'loss_grapheme': 0.124452, 'loss_vowel': 0.048969, 'loss_consonant': 0.03911}\n",
      "   35 | 0.000048 | 125440/180756 | 0.0500 | 1.0947 |\n",
      "val: {'recall': 0.979564, 'recall_grapheme': 0.971067, 'recall_vowel': 0.984912, 'recall_consonant': 0.991211, 'acc_grapheme': 0.967636, 'acc_vowel': 0.989992, 'acc_consonant': 0.991486, 'loss_grapheme': 0.135642, 'loss_vowel': 0.046493, 'loss_consonant': 0.035895}\n",
      "   36 | 0.000050 | 047104/180756 | 0.0149 | 0.9798 |\n",
      "val: {'recall': 0.977778, 'recall_grapheme': 0.969504, 'recall_vowel': 0.987061, 'recall_consonant': 0.985045, 'acc_grapheme': 0.969727, 'acc_vowel': 0.990639, 'acc_consonant': 0.991187, 'loss_grapheme': 0.121945, 'loss_vowel': 0.04654, 'loss_consonant': 0.037043}\n",
      "   36 | 0.000048 | 149504/180756 | 0.0298 | 0.8667 |\n",
      "val: {'recall': 0.979937, 'recall_grapheme': 0.970307, 'recall_vowel': 0.987935, 'recall_consonant': 0.9912, 'acc_grapheme': 0.969379, 'acc_vowel': 0.989693, 'acc_consonant': 0.991038, 'loss_grapheme': 0.128766, 'loss_vowel': 0.047987, 'loss_consonant': 0.03615}\n",
      "   37 | 0.000043 | 071168/180756 | 0.0218 | 0.7648 |\n",
      "val: {'recall': 0.978581, 'recall_grapheme': 0.969896, 'recall_vowel': 0.984035, 'recall_consonant': 0.990496, 'acc_grapheme': 0.968482, 'acc_vowel': 0.989444, 'acc_consonant': 0.991386, 'loss_grapheme': 0.130627, 'loss_vowel': 0.055538, 'loss_consonant': 0.039351}\n",
      "   37 | 0.000035 | 173568/180756 | 0.1676 | 0.9226 |\n",
      "val: {'recall': 0.97886, 'recall_grapheme': 0.968582, 'recall_vowel': 0.986867, 'recall_consonant': 0.991409, 'acc_grapheme': 0.969279, 'acc_vowel': 0.989843, 'acc_consonant': 0.991187, 'loss_grapheme': 0.125236, 'loss_vowel': 0.052916, 'loss_consonant': 0.039721}\n",
      "   38 | 0.000025 | 095232/180756 | 0.0183 | 1.0223 |\n",
      "val: {'recall': 0.981452, 'recall_grapheme': 0.972888, 'recall_vowel': 0.987934, 'recall_consonant': 0.992098, 'acc_grapheme': 0.972316, 'acc_vowel': 0.990888, 'acc_consonant': 0.991934, 'loss_grapheme': 0.111981, 'loss_vowel': 0.043469, 'loss_consonant': 0.034413}\n",
      "   39 | 0.000016 | 016896/180756 | 3.1507 | 1.1928 |\n",
      "val: {'recall': 0.980142, 'recall_grapheme': 0.970571, 'recall_vowel': 0.987193, 'recall_consonant': 0.992232, 'acc_grapheme': 0.971022, 'acc_vowel': 0.99049, 'acc_consonant': 0.991785, 'loss_grapheme': 0.11813, 'loss_vowel': 0.045231, 'loss_consonant': 0.036104}\n",
      "   39 | 0.000008 | 119296/180756 | 0.0049 | 0.9644 |\n",
      "val: {'recall': 0.98052, 'recall_grapheme': 0.970887, 'recall_vowel': 0.987786, 'recall_consonant': 0.992518, 'acc_grapheme': 0.971968, 'acc_vowel': 0.990739, 'acc_consonant': 0.991984, 'loss_grapheme': 0.115219, 'loss_vowel': 0.046819, 'loss_consonant': 0.03594}\n",
      "   40 | 0.000003 | 040960/180756 | 0.0110 | 1.0367 |\n",
      "val: {'recall': 0.979736, 'recall_grapheme': 0.969832, 'recall_vowel': 0.987291, 'recall_consonant': 0.991989, 'acc_grapheme': 0.970275, 'acc_vowel': 0.99054, 'acc_consonant': 0.991785, 'loss_grapheme': 0.121117, 'loss_vowel': 0.053765, 'loss_consonant': 0.040515}\n",
      "   40 | 0.000001 | 143360/180756 | 0.0054 | 0.9818 |\n",
      "val: {'recall': 0.980807, 'recall_grapheme': 0.971824, 'recall_vowel': 0.987437, 'recall_consonant': 0.992142, 'acc_grapheme': 0.972565, 'acc_vowel': 0.990639, 'acc_consonant': 0.991984, 'loss_grapheme': 0.113445, 'loss_vowel': 0.043985, 'loss_consonant': 0.034477}\n",
      "   41 | 0.000003 | 065024/180756 | 2.7141 | 0.9156 |\n",
      "val: {'recall': 0.980956, 'recall_grapheme': 0.971815, 'recall_vowel': 0.987697, 'recall_consonant': 0.992496, 'acc_grapheme': 0.972316, 'acc_vowel': 0.990689, 'acc_consonant': 0.992332, 'loss_grapheme': 0.114756, 'loss_vowel': 0.044885, 'loss_consonant': 0.035103}\n",
      "   41 | 0.000008 | 167424/180756 | 0.0308 | 0.8904 |\n",
      "val: {'recall': 0.98213, 'recall_grapheme': 0.973366, 'recall_vowel': 0.989465, 'recall_consonant': 0.992324, 'acc_grapheme': 0.972914, 'acc_vowel': 0.991287, 'acc_consonant': 0.992033, 'loss_grapheme': 0.114682, 'loss_vowel': 0.042221, 'loss_consonant': 0.034536}\n",
      "   42 | 0.000016 | 089088/180756 | 0.0069 | 1.0878 |\n",
      "val: {'recall': 0.980953, 'recall_grapheme': 0.972086, 'recall_vowel': 0.98777, 'recall_consonant': 0.991872, 'acc_grapheme': 0.971818, 'acc_vowel': 0.990888, 'acc_consonant': 0.991785, 'loss_grapheme': 0.118306, 'loss_vowel': 0.043134, 'loss_consonant': 0.034481}\n",
      "   43 | 0.000025 | 010752/180756 | 2.5973 | 1.2401 |\n",
      "val: {'recall': 0.978916, 'recall_grapheme': 0.969665, 'recall_vowel': 0.986399, 'recall_consonant': 0.989934, 'acc_grapheme': 0.970325, 'acc_vowel': 0.990092, 'acc_consonant': 0.991137, 'loss_grapheme': 0.123184, 'loss_vowel': 0.053605, 'loss_consonant': 0.041329}\n",
      "   43 | 0.000035 | 113152/180756 | 3.2087 | 1.0720 |\n",
      "val: {'recall': 0.978596, 'recall_grapheme': 0.967745, 'recall_vowel': 0.986026, 'recall_consonant': 0.992869, 'acc_grapheme': 0.968781, 'acc_vowel': 0.989843, 'acc_consonant': 0.991635, 'loss_grapheme': 0.123913, 'loss_vowel': 0.051545, 'loss_consonant': 0.038892}\n",
      "   44 | 0.000043 | 034816/180756 | 0.0430 | 0.9456 |\n",
      "val: {'recall': 0.978838, 'recall_grapheme': 0.969317, 'recall_vowel': 0.987986, 'recall_consonant': 0.988731, 'acc_grapheme': 0.969279, 'acc_vowel': 0.990191, 'acc_consonant': 0.991785, 'loss_grapheme': 0.129308, 'loss_vowel': 0.045245, 'loss_consonant': 0.038007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 0.000048 | 137216/180756 | 2.2247 | 0.9645 |\n",
      "val: {'recall': 0.977953, 'recall_grapheme': 0.968739, 'recall_vowel': 0.986895, 'recall_consonant': 0.987438, 'acc_grapheme': 0.96908, 'acc_vowel': 0.990639, 'acc_consonant': 0.990838, 'loss_grapheme': 0.129933, 'loss_vowel': 0.046, 'loss_consonant': 0.038408}\n",
      "   45 | 0.000050 | 058880/180756 | 1.7077 | 1.2178 |\n",
      "val: {'recall': 0.978723, 'recall_grapheme': 0.967689, 'recall_vowel': 0.988455, 'recall_consonant': 0.99106, 'acc_grapheme': 0.967785, 'acc_vowel': 0.989395, 'acc_consonant': 0.991087, 'loss_grapheme': 0.134903, 'loss_vowel': 0.055969, 'loss_consonant': 0.040302}\n",
      "   45 | 0.000048 | 161280/180756 | 0.0165 | 0.9858 |\n",
      "val: {'recall': 0.980273, 'recall_grapheme': 0.971704, 'recall_vowel': 0.988712, 'recall_consonant': 0.988971, 'acc_grapheme': 0.970574, 'acc_vowel': 0.991685, 'acc_consonant': 0.99044, 'loss_grapheme': 0.121489, 'loss_vowel': 0.041971, 'loss_consonant': 0.037099}\n",
      "   46 | 0.000043 | 082944/180756 | 0.0093 | 1.1007 |\n",
      "val: {'recall': 0.979688, 'recall_grapheme': 0.969141, 'recall_vowel': 0.988794, 'recall_consonant': 0.991675, 'acc_grapheme': 0.969179, 'acc_vowel': 0.991137, 'acc_consonant': 0.990838, 'loss_grapheme': 0.126923, 'loss_vowel': 0.044288, 'loss_consonant': 0.037819}\n",
      "   47 | 0.000035 | 004608/180756 | 0.0102 | 1.2781 |\n",
      "val: {'recall': 0.978288, 'recall_grapheme': 0.967661, 'recall_vowel': 0.987705, 'recall_consonant': 0.990125, 'acc_grapheme': 0.969926, 'acc_vowel': 0.990888, 'acc_consonant': 0.991834, 'loss_grapheme': 0.119752, 'loss_vowel': 0.048195, 'loss_consonant': 0.037465}\n",
      "   47 | 0.000025 | 107008/180756 | 0.4650 | 1.1628 |\n",
      "val: {'recall': 0.978222, 'recall_grapheme': 0.968848, 'recall_vowel': 0.98649, 'recall_consonant': 0.988701, 'acc_grapheme': 0.969578, 'acc_vowel': 0.990341, 'acc_consonant': 0.991137, 'loss_grapheme': 0.127968, 'loss_vowel': 0.05752, 'loss_consonant': 0.040578}\n",
      "   48 | 0.000016 | 028672/180756 | 0.0186 | 1.0874 |\n",
      "val: {'recall': 0.980649, 'recall_grapheme': 0.971493, 'recall_vowel': 0.988567, 'recall_consonant': 0.991041, 'acc_grapheme': 0.972217, 'acc_vowel': 0.991237, 'acc_consonant': 0.991585, 'loss_grapheme': 0.119617, 'loss_vowel': 0.042607, 'loss_consonant': 0.035374}\n",
      "   48 | 0.000008 | 131072/180756 | 2.8168 | 0.9978 |\n",
      "val: {'recall': 0.980054, 'recall_grapheme': 0.970361, 'recall_vowel': 0.98754, 'recall_consonant': 0.991955, 'acc_grapheme': 0.971271, 'acc_vowel': 0.991137, 'acc_consonant': 0.991735, 'loss_grapheme': 0.117216, 'loss_vowel': 0.044697, 'loss_consonant': 0.03512}\n",
      "   49 | 0.000003 | 052736/180756 | 3.1699 | 1.0767 |\n",
      "val: {'recall': 0.978871, 'recall_grapheme': 0.969702, 'recall_vowel': 0.986928, 'recall_consonant': 0.98915, 'acc_grapheme': 0.97137, 'acc_vowel': 0.990838, 'acc_consonant': 0.991536, 'loss_grapheme': 0.116105, 'loss_vowel': 0.048661, 'loss_consonant': 0.036498}\n",
      "   49 | 0.000001 | 155136/180756 | 0.0237 | 0.9834 |\n",
      "val: {'recall': 0.981349, 'recall_grapheme': 0.972639, 'recall_vowel': 0.988682, 'recall_consonant': 0.991434, 'acc_grapheme': 0.972715, 'acc_vowel': 0.991386, 'acc_consonant': 0.991685, 'loss_grapheme': 0.115472, 'loss_vowel': 0.042812, 'loss_consonant': 0.035104}\n",
      "   50 | 0.000003 | 076800/180756 | 2.6076 | 0.9626 |\n",
      "val: {'recall': 0.979923, 'recall_grapheme': 0.970557, 'recall_vowel': 0.987139, 'recall_consonant': 0.991438, 'acc_grapheme': 0.971868, 'acc_vowel': 0.990938, 'acc_consonant': 0.991386, 'loss_grapheme': 0.114958, 'loss_vowel': 0.047494, 'loss_consonant': 0.037168}\n",
      "   50 | 0.000008 | 179200/180756 | 0.0085 | 0.9546 |\n",
      "val: {'recall': 0.979596, 'recall_grapheme': 0.970572, 'recall_vowel': 0.987897, 'recall_consonant': 0.989345, 'acc_grapheme': 0.972167, 'acc_vowel': 0.991237, 'acc_consonant': 0.991785, 'loss_grapheme': 0.113346, 'loss_vowel': 0.043621, 'loss_consonant': 0.034763}\n",
      "   51 | 0.000016 | 100864/180756 | 3.1559 | 0.8030 |\n",
      "val: {'recall': 0.978887, 'recall_grapheme': 0.969907, 'recall_vowel': 0.987358, 'recall_consonant': 0.988375, 'acc_grapheme': 0.970823, 'acc_vowel': 0.990888, 'acc_consonant': 0.991237, 'loss_grapheme': 0.117649, 'loss_vowel': 0.044871, 'loss_consonant': 0.03539}\n",
      "   52 | 0.000025 | 022528/180756 | 0.3264 | 1.1015 |\n",
      "val: {'recall': 0.979329, 'recall_grapheme': 0.96923, 'recall_vowel': 0.987761, 'recall_consonant': 0.991096, 'acc_grapheme': 0.971022, 'acc_vowel': 0.990838, 'acc_consonant': 0.991536, 'loss_grapheme': 0.127665, 'loss_vowel': 0.044925, 'loss_consonant': 0.037831}\n",
      "   52 | 0.000035 | 124928/180756 | 0.0302 | 0.8976 |\n",
      "val: {'recall': 0.979918, 'recall_grapheme': 0.969987, 'recall_vowel': 0.988624, 'recall_consonant': 0.991073, 'acc_grapheme': 0.971918, 'acc_vowel': 0.990838, 'acc_consonant': 0.991486, 'loss_grapheme': 0.123058, 'loss_vowel': 0.04508, 'loss_consonant': 0.036303}\n",
      "   53 | 0.000043 | 046592/180756 | 0.0141 | 0.9674 |\n",
      "val: {'recall': 0.980517, 'recall_grapheme': 0.971325, 'recall_vowel': 0.98779, 'recall_consonant': 0.991627, 'acc_grapheme': 0.971171, 'acc_vowel': 0.99059, 'acc_consonant': 0.991685, 'loss_grapheme': 0.123846, 'loss_vowel': 0.044483, 'loss_consonant': 0.035219}\n",
      "   53 | 0.000048 | 148992/180756 | 3.0974 | 1.0521 |\n",
      "val: {'recall': 0.978951, 'recall_grapheme': 0.96931, 'recall_vowel': 0.986864, 'recall_consonant': 0.990319, 'acc_grapheme': 0.969677, 'acc_vowel': 0.990888, 'acc_consonant': 0.990838, 'loss_grapheme': 0.127135, 'loss_vowel': 0.046039, 'loss_consonant': 0.03983}\n",
      "   54 | 0.000050 | 070656/180756 | 0.0327 | 1.1106 |\n",
      "val: {'recall': 0.978694, 'recall_grapheme': 0.969372, 'recall_vowel': 0.986312, 'recall_consonant': 0.98972, 'acc_grapheme': 0.969926, 'acc_vowel': 0.990639, 'acc_consonant': 0.990341, 'loss_grapheme': 0.121966, 'loss_vowel': 0.046148, 'loss_consonant': 0.040645}\n",
      "   54 | 0.000048 | 173056/180756 | 1.9055 | 1.0396 |\n",
      "val: {'recall': 0.979463, 'recall_grapheme': 0.970405, 'recall_vowel': 0.986587, 'recall_consonant': 0.990456, 'acc_grapheme': 0.968433, 'acc_vowel': 0.989494, 'acc_consonant': 0.990739, 'loss_grapheme': 0.129875, 'loss_vowel': 0.049585, 'loss_consonant': 0.03856}\n",
      "   55 | 0.000043 | 094720/180756 | 3.0979 | 1.0719 |\n",
      "val: {'recall': 0.978452, 'recall_grapheme': 0.969199, 'recall_vowel': 0.985155, 'recall_consonant': 0.990253, 'acc_grapheme': 0.969578, 'acc_vowel': 0.989793, 'acc_consonant': 0.99054, 'loss_grapheme': 0.122124, 'loss_vowel': 0.050066, 'loss_consonant': 0.041061}\n",
      "   56 | 0.000035 | 016384/180756 | 0.0057 | 0.4972 |\n",
      "val: {'recall': 0.980569, 'recall_grapheme': 0.970824, 'recall_vowel': 0.988532, 'recall_consonant': 0.992095, 'acc_grapheme': 0.970723, 'acc_vowel': 0.990988, 'acc_consonant': 0.991984, 'loss_grapheme': 0.125002, 'loss_vowel': 0.043423, 'loss_consonant': 0.03602}\n",
      "   56 | 0.000025 | 118784/180756 | 2.7232 | 0.9077 |\n",
      "val: {'recall': 0.980082, 'recall_grapheme': 0.971506, 'recall_vowel': 0.987963, 'recall_consonant': 0.989354, 'acc_grapheme': 0.970524, 'acc_vowel': 0.990689, 'acc_consonant': 0.991585, 'loss_grapheme': 0.117685, 'loss_vowel': 0.049284, 'loss_consonant': 0.037265}\n",
      "   57 | 0.000016 | 040448/180756 | 3.2048 | 0.8199 |\n",
      "val: {'recall': 0.979987, 'recall_grapheme': 0.969818, 'recall_vowel': 0.987016, 'recall_consonant': 0.993295, 'acc_grapheme': 0.970922, 'acc_vowel': 0.99049, 'acc_consonant': 0.992083, 'loss_grapheme': 0.11795, 'loss_vowel': 0.049404, 'loss_consonant': 0.036222}\n",
      "   57 | 0.000008 | 142848/180756 | 0.0111 | 0.8427 |\n",
      "val: {'recall': 0.980582, 'recall_grapheme': 0.9719, 'recall_vowel': 0.987006, 'recall_consonant': 0.991522, 'acc_grapheme': 0.972466, 'acc_vowel': 0.99044, 'acc_consonant': 0.991934, 'loss_grapheme': 0.115711, 'loss_vowel': 0.046054, 'loss_consonant': 0.035376}\n",
      "   58 | 0.000003 | 064512/180756 | 0.0039 | 0.8627 |\n",
      "val: {'recall': 0.981152, 'recall_grapheme': 0.97234, 'recall_vowel': 0.988099, 'recall_consonant': 0.991831, 'acc_grapheme': 0.973213, 'acc_vowel': 0.990988, 'acc_consonant': 0.992033, 'loss_grapheme': 0.11497, 'loss_vowel': 0.044266, 'loss_consonant': 0.034948}\n",
      "   58 | 0.000001 | 166912/180756 | 0.0056 | 0.8735 |\n",
      "val: {'recall': 0.981323, 'recall_grapheme': 0.973209, 'recall_vowel': 0.987465, 'recall_consonant': 0.991409, 'acc_grapheme': 0.973262, 'acc_vowel': 0.990789, 'acc_consonant': 0.992033, 'loss_grapheme': 0.114854, 'loss_vowel': 0.04484, 'loss_consonant': 0.035018}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 0.000003 | 088576/180756 | 0.0051 | 0.8949 |\n",
      "val: {'recall': 0.981509, 'recall_grapheme': 0.973493, 'recall_vowel': 0.988221, 'recall_consonant': 0.99083, 'acc_grapheme': 0.973412, 'acc_vowel': 0.991038, 'acc_consonant': 0.991735, 'loss_grapheme': 0.118964, 'loss_vowel': 0.044002, 'loss_consonant': 0.036207}\n",
      "   60 | 0.000008 | 010240/180756 | 0.0063 | 1.1942 |\n",
      "val: {'recall': 0.980636, 'recall_grapheme': 0.971855, 'recall_vowel': 0.987712, 'recall_consonant': 0.991122, 'acc_grapheme': 0.972366, 'acc_vowel': 0.990888, 'acc_consonant': 0.991984, 'loss_grapheme': 0.115274, 'loss_vowel': 0.045318, 'loss_consonant': 0.035217}\n",
      "   60 | 0.000016 | 112640/180756 | 2.3177 | 0.9899 |\n",
      "val: {'recall': 0.981393, 'recall_grapheme': 0.972551, 'recall_vowel': 0.987616, 'recall_consonant': 0.992856, 'acc_grapheme': 0.97132, 'acc_vowel': 0.991287, 'acc_consonant': 0.991884, 'loss_grapheme': 0.123325, 'loss_vowel': 0.044148, 'loss_consonant': 0.036621}\n",
      "   61 | 0.000025 | 034304/180756 | 1.9889 | 0.7889 |\n",
      "val: {'recall': 0.980558, 'recall_grapheme': 0.971597, 'recall_vowel': 0.98794, 'recall_consonant': 0.991097, 'acc_grapheme': 0.970623, 'acc_vowel': 0.990291, 'acc_consonant': 0.991336, 'loss_grapheme': 0.129181, 'loss_vowel': 0.048175, 'loss_consonant': 0.036872}\n",
      "   61 | 0.000035 | 136704/180756 | 3.6757 | 1.0686 |\n",
      "val: {'recall': 0.978664, 'recall_grapheme': 0.970618, 'recall_vowel': 0.986063, 'recall_consonant': 0.987355, 'acc_grapheme': 0.969677, 'acc_vowel': 0.989942, 'acc_consonant': 0.991336, 'loss_grapheme': 0.131628, 'loss_vowel': 0.055638, 'loss_consonant': 0.041728}\n",
      "   62 | 0.000043 | 058368/180756 | 0.0276 | 1.0946 |\n",
      "val: {'recall': 0.978893, 'recall_grapheme': 0.968448, 'recall_vowel': 0.9887, 'recall_consonant': 0.989977, 'acc_grapheme': 0.968283, 'acc_vowel': 0.991087, 'acc_consonant': 0.99039, 'loss_grapheme': 0.135086, 'loss_vowel': 0.046112, 'loss_consonant': 0.040023}\n",
      "   62 | 0.000048 | 160768/180756 | 0.0124 | 1.0842 |\n",
      "val: {'recall': 0.977309, 'recall_grapheme': 0.967771, 'recall_vowel': 0.987445, 'recall_consonant': 0.986248, 'acc_grapheme': 0.968831, 'acc_vowel': 0.990291, 'acc_consonant': 0.990938, 'loss_grapheme': 0.128863, 'loss_vowel': 0.052135, 'loss_consonant': 0.039574}\n",
      "   63 | 0.000050 | 082432/180756 | 2.1876 | 1.0312 |\n",
      "val: {'recall': 0.979432, 'recall_grapheme': 0.969977, 'recall_vowel': 0.985644, 'recall_consonant': 0.992129, 'acc_grapheme': 0.968831, 'acc_vowel': 0.989992, 'acc_consonant': 0.991336, 'loss_grapheme': 0.131756, 'loss_vowel': 0.052821, 'loss_consonant': 0.039681}\n",
      "   64 | 0.000048 | 004096/180756 | 0.0152 | 0.5194 |\n",
      "val: {'recall': 0.979991, 'recall_grapheme': 0.969776, 'recall_vowel': 0.989106, 'recall_consonant': 0.991305, 'acc_grapheme': 0.968134, 'acc_vowel': 0.989942, 'acc_consonant': 0.990789, 'loss_grapheme': 0.134762, 'loss_vowel': 0.048586, 'loss_consonant': 0.039117}\n",
      "   64 | 0.000043 | 106496/180756 | 0.0290 | 0.9457 |\n",
      "val: {'recall': 0.978333, 'recall_grapheme': 0.968965, 'recall_vowel': 0.987501, 'recall_consonant': 0.987903, 'acc_grapheme': 0.970922, 'acc_vowel': 0.990341, 'acc_consonant': 0.991187, 'loss_grapheme': 0.124664, 'loss_vowel': 0.04706, 'loss_consonant': 0.036309}\n",
      "   65 | 0.000035 | 028160/180756 | 0.0177 | 1.0128 |\n",
      "val: {'recall': 0.978617, 'recall_grapheme': 0.969945, 'recall_vowel': 0.986721, 'recall_consonant': 0.987858, 'acc_grapheme': 0.969827, 'acc_vowel': 0.99049, 'acc_consonant': 0.991486, 'loss_grapheme': 0.122906, 'loss_vowel': 0.050938, 'loss_consonant': 0.037094}\n",
      "   65 | 0.000026 | 130560/180756 | 0.0142 | 1.0184 |\n",
      "val: {'recall': 0.979395, 'recall_grapheme': 0.970259, 'recall_vowel': 0.98774, 'recall_consonant': 0.989323, 'acc_grapheme': 0.97147, 'acc_vowel': 0.99054, 'acc_consonant': 0.991685, 'loss_grapheme': 0.118654, 'loss_vowel': 0.047962, 'loss_consonant': 0.036783}\n",
      "   66 | 0.000016 | 052224/180756 | 0.0044 | 1.0791 |\n",
      "val: {'recall': 0.981098, 'recall_grapheme': 0.97366, 'recall_vowel': 0.987952, 'recall_consonant': 0.989121, 'acc_grapheme': 0.972914, 'acc_vowel': 0.991137, 'acc_consonant': 0.991536, 'loss_grapheme': 0.118209, 'loss_vowel': 0.045542, 'loss_consonant': 0.034422}\n",
      "   66 | 0.000008 | 154624/180756 | 0.0150 | 1.0771 |\n",
      "val: {'recall': 0.978935, 'recall_grapheme': 0.970109, 'recall_vowel': 0.985287, 'recall_consonant': 0.990233, 'acc_grapheme': 0.971221, 'acc_vowel': 0.989942, 'acc_consonant': 0.991984, 'loss_grapheme': 0.118414, 'loss_vowel': 0.049458, 'loss_consonant': 0.036065}\n",
      "   67 | 0.000003 | 076288/180756 | 1.4938 | 0.9792 |\n",
      "val: {'recall': 0.9793, 'recall_grapheme': 0.970762, 'recall_vowel': 0.985257, 'recall_consonant': 0.990416, 'acc_grapheme': 0.971669, 'acc_vowel': 0.989992, 'acc_consonant': 0.992133, 'loss_grapheme': 0.120045, 'loss_vowel': 0.051776, 'loss_consonant': 0.037623}\n",
      "   67 | 0.000001 | 178688/180756 | 0.0055 | 0.9052 |\n",
      "val: {'recall': 0.979827, 'recall_grapheme': 0.971436, 'recall_vowel': 0.985983, 'recall_consonant': 0.990453, 'acc_grapheme': 0.972266, 'acc_vowel': 0.990241, 'acc_consonant': 0.992083, 'loss_grapheme': 0.116799, 'loss_vowel': 0.04731, 'loss_consonant': 0.035281}\n",
      "   68 | 0.000003 | 100352/180756 | 0.0072 | 0.9126 |\n",
      "val: {'recall': 0.980692, 'recall_grapheme': 0.972492, 'recall_vowel': 0.987368, 'recall_consonant': 0.990418, 'acc_grapheme': 0.972764, 'acc_vowel': 0.991038, 'acc_consonant': 0.992183, 'loss_grapheme': 0.117897, 'loss_vowel': 0.044555, 'loss_consonant': 0.034141}\n",
      "   69 | 0.000008 | 022016/180756 | 0.0038 | 1.0942 |\n",
      "val: {'recall': 0.98077, 'recall_grapheme': 0.973456, 'recall_vowel': 0.987484, 'recall_consonant': 0.988683, 'acc_grapheme': 0.973312, 'acc_vowel': 0.990739, 'acc_consonant': 0.991785, 'loss_grapheme': 0.116432, 'loss_vowel': 0.04544, 'loss_consonant': 0.034654}\n",
      "   69 | 0.000016 | 124416/180756 | 0.0069 | 0.8747 |\n",
      "val: {'recall': 0.981535, 'recall_grapheme': 0.973011, 'recall_vowel': 0.987704, 'recall_consonant': 0.992413, 'acc_grapheme': 0.973063, 'acc_vowel': 0.991087, 'acc_consonant': 0.991735, 'loss_grapheme': 0.125882, 'loss_vowel': 0.045434, 'loss_consonant': 0.035208}\n",
      "   70 | 0.000025 | 046080/180756 | 0.0215 | 0.9828 |\n",
      "val: {'recall': 0.979616, 'recall_grapheme': 0.972359, 'recall_vowel': 0.986644, 'recall_consonant': 0.987101, 'acc_grapheme': 0.971818, 'acc_vowel': 0.99044, 'acc_consonant': 0.991785, 'loss_grapheme': 0.118596, 'loss_vowel': 0.04811, 'loss_consonant': 0.034335}\n",
      "   70 | 0.000035 | 148480/180756 | 0.0067 | 0.9134 |\n",
      "val: {'recall': 0.979433, 'recall_grapheme': 0.970353, 'recall_vowel': 0.987229, 'recall_consonant': 0.989796, 'acc_grapheme': 0.96903, 'acc_vowel': 0.990241, 'acc_consonant': 0.991386, 'loss_grapheme': 0.130497, 'loss_vowel': 0.047117, 'loss_consonant': 0.035952}\n",
      "   71 | 0.000043 | 070144/180756 | 0.0182 | 1.0112 |\n",
      "val: {'recall': 0.98007, 'recall_grapheme': 0.970774, 'recall_vowel': 0.987471, 'recall_consonant': 0.99126, 'acc_grapheme': 0.970275, 'acc_vowel': 0.990092, 'acc_consonant': 0.990838, 'loss_grapheme': 0.13253, 'loss_vowel': 0.048585, 'loss_consonant': 0.037193}\n",
      "   71 | 0.000048 | 172544/180756 | 0.0230 | 0.8180 |\n",
      "val: {'recall': 0.977394, 'recall_grapheme': 0.968107, 'recall_vowel': 0.986413, 'recall_consonant': 0.98695, 'acc_grapheme': 0.968433, 'acc_vowel': 0.989245, 'acc_consonant': 0.991386, 'loss_grapheme': 0.131066, 'loss_vowel': 0.057608, 'loss_consonant': 0.038919}\n",
      "   72 | 0.000050 | 094208/180756 | 0.0358 | 1.0878 |\n",
      "val: {'recall': 0.979176, 'recall_grapheme': 0.968761, 'recall_vowel': 0.986681, 'recall_consonant': 0.992502, 'acc_grapheme': 0.967736, 'acc_vowel': 0.989892, 'acc_consonant': 0.99039, 'loss_grapheme': 0.134521, 'loss_vowel': 0.05513, 'loss_consonant': 0.043706}\n",
      "   73 | 0.000048 | 015872/180756 | 0.0455 | 0.9228 |\n",
      "val: {'recall': 0.980881, 'recall_grapheme': 0.970863, 'recall_vowel': 0.989292, 'recall_consonant': 0.992506, 'acc_grapheme': 0.970076, 'acc_vowel': 0.990938, 'acc_consonant': 0.991237, 'loss_grapheme': 0.122898, 'loss_vowel': 0.049074, 'loss_consonant': 0.038684}\n",
      "   73 | 0.000043 | 118272/180756 | 0.0202 | 0.9872 |\n",
      "val: {'recall': 0.978151, 'recall_grapheme': 0.971015, 'recall_vowel': 0.987406, 'recall_consonant': 0.98317, 'acc_grapheme': 0.969727, 'acc_vowel': 0.989843, 'acc_consonant': 0.990938, 'loss_grapheme': 0.123523, 'loss_vowel': 0.050587, 'loss_consonant': 0.03846}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 0.000035 | 039936/180756 | 0.0100 | 0.9802 |\n",
      "val: {'recall': 0.980261, 'recall_grapheme': 0.971742, 'recall_vowel': 0.989404, 'recall_consonant': 0.988158, 'acc_grapheme': 0.970823, 'acc_vowel': 0.991585, 'acc_consonant': 0.991536, 'loss_grapheme': 0.129563, 'loss_vowel': 0.043731, 'loss_consonant': 0.037285}\n",
      "   74 | 0.000026 | 142336/180756 | 0.0122 | 0.9536 |\n",
      "val: {'recall': 0.979643, 'recall_grapheme': 0.970194, 'recall_vowel': 0.987694, 'recall_consonant': 0.99049, 'acc_grapheme': 0.970773, 'acc_vowel': 0.990888, 'acc_consonant': 0.991785, 'loss_grapheme': 0.121123, 'loss_vowel': 0.045172, 'loss_consonant': 0.034577}\n",
      "   75 | 0.000016 | 064000/180756 | 2.7650 | 1.0248 |\n",
      "val: {'recall': 0.980379, 'recall_grapheme': 0.971754, 'recall_vowel': 0.987807, 'recall_consonant': 0.9902, 'acc_grapheme': 0.971769, 'acc_vowel': 0.991137, 'acc_consonant': 0.992033, 'loss_grapheme': 0.118837, 'loss_vowel': 0.045385, 'loss_consonant': 0.034522}\n",
      "   75 | 0.000008 | 166400/180756 | 2.9181 | 1.0398 |\n",
      "val: {'recall': 0.980265, 'recall_grapheme': 0.972505, 'recall_vowel': 0.988169, 'recall_consonant': 0.98788, 'acc_grapheme': 0.972316, 'acc_vowel': 0.990938, 'acc_consonant': 0.992133, 'loss_grapheme': 0.117548, 'loss_vowel': 0.049439, 'loss_consonant': 0.036558}\n",
      "   76 | 0.000003 | 088064/180756 | 0.0141 | 0.8725 |\n",
      "val: {'recall': 0.981335, 'recall_grapheme': 0.973465, 'recall_vowel': 0.98823, 'recall_consonant': 0.990179, 'acc_grapheme': 0.973063, 'acc_vowel': 0.991087, 'acc_consonant': 0.992133, 'loss_grapheme': 0.116922, 'loss_vowel': 0.044927, 'loss_consonant': 0.034286}\n",
      "   77 | 0.000001 | 009728/180756 | 0.0116 | 0.9048 |\n",
      "val: {'recall': 0.981549, 'recall_grapheme': 0.972876, 'recall_vowel': 0.988107, 'recall_consonant': 0.992335, 'acc_grapheme': 0.972416, 'acc_vowel': 0.991038, 'acc_consonant': 0.992083, 'loss_grapheme': 0.116692, 'loss_vowel': 0.045256, 'loss_consonant': 0.035046}\n",
      "   77 | 0.000003 | 112128/180756 | 3.1637 | 1.0291 |\n",
      "val: {'recall': 0.979924, 'recall_grapheme': 0.970811, 'recall_vowel': 0.988139, 'recall_consonant': 0.989936, 'acc_grapheme': 0.971121, 'acc_vowel': 0.991038, 'acc_consonant': 0.991884, 'loss_grapheme': 0.11993, 'loss_vowel': 0.050921, 'loss_consonant': 0.036927}\n",
      "   78 | 0.000008 | 033792/180756 | 0.0284 | 0.7197 |\n",
      "val: {'recall': 0.982184, 'recall_grapheme': 0.973911, 'recall_vowel': 0.988551, 'recall_consonant': 0.992362, 'acc_grapheme': 0.973013, 'acc_vowel': 0.991237, 'acc_consonant': 0.991934, 'loss_grapheme': 0.118644, 'loss_vowel': 0.044144, 'loss_consonant': 0.034655}\n",
      "   78 | 0.000016 | 136192/180756 | 1.8916 | 1.0101 |\n",
      "val: {'recall': 0.980244, 'recall_grapheme': 0.972113, 'recall_vowel': 0.988353, 'recall_consonant': 0.988397, 'acc_grapheme': 0.97152, 'acc_vowel': 0.990739, 'acc_consonant': 0.992282, 'loss_grapheme': 0.118318, 'loss_vowel': 0.049122, 'loss_consonant': 0.035484}\n",
      "   79 | 0.000025 | 057856/180756 | 0.0137 | 0.9548 |\n",
      "val: {'recall': 0.979433, 'recall_grapheme': 0.970116, 'recall_vowel': 0.98809, 'recall_consonant': 0.989407, 'acc_grapheme': 0.971271, 'acc_vowel': 0.991237, 'acc_consonant': 0.991287, 'loss_grapheme': 0.125323, 'loss_vowel': 0.045325, 'loss_consonant': 0.036303}\n",
      "   79 | 0.000035 | 160256/180756 | 0.0236 | 0.9130 |\n",
      "val: {'recall': 0.981265, 'recall_grapheme': 0.972452, 'recall_vowel': 0.98837, 'recall_consonant': 0.991785, 'acc_grapheme': 0.971022, 'acc_vowel': 0.991187, 'acc_consonant': 0.991287, 'loss_grapheme': 0.129366, 'loss_vowel': 0.04359, 'loss_consonant': 0.038576}\n",
      "   80 | 0.000043 | 081920/180756 | 0.0083 | 1.0438 |\n",
      "val: {'recall': 0.978939, 'recall_grapheme': 0.969461, 'recall_vowel': 0.987247, 'recall_consonant': 0.989586, 'acc_grapheme': 0.968532, 'acc_vowel': 0.99049, 'acc_consonant': 0.991635, 'loss_grapheme': 0.133957, 'loss_vowel': 0.046436, 'loss_consonant': 0.036913}\n",
      "   81 | 0.000048 | 003584/180756 | 0.0224 | 1.3511 |\n",
      "val: {'recall': 0.979068, 'recall_grapheme': 0.969202, 'recall_vowel': 0.985432, 'recall_consonant': 0.992436, 'acc_grapheme': 0.969379, 'acc_vowel': 0.989942, 'acc_consonant': 0.990938, 'loss_grapheme': 0.129128, 'loss_vowel': 0.050909, 'loss_consonant': 0.04043}\n",
      "   81 | 0.000050 | 105984/180756 | 2.2723 | 1.1320 |\n",
      "val: {'recall': 0.977834, 'recall_grapheme': 0.967246, 'recall_vowel': 0.987119, 'recall_consonant': 0.989724, 'acc_grapheme': 0.967088, 'acc_vowel': 0.99039, 'acc_consonant': 0.991187, 'loss_grapheme': 0.135772, 'loss_vowel': 0.055316, 'loss_consonant': 0.041684}\n",
      "   82 | 0.000048 | 027648/180756 | 0.0167 | 0.8240 |\n",
      "val: {'recall': 0.978916, 'recall_grapheme': 0.969435, 'recall_vowel': 0.987909, 'recall_consonant': 0.988884, 'acc_grapheme': 0.969428, 'acc_vowel': 0.990291, 'acc_consonant': 0.991834, 'loss_grapheme': 0.125792, 'loss_vowel': 0.047128, 'loss_consonant': 0.035209}\n",
      "   82 | 0.000043 | 130048/180756 | 0.0096 | 1.0107 |\n",
      "val: {'recall': 0.979351, 'recall_grapheme': 0.969993, 'recall_vowel': 0.985798, 'recall_consonant': 0.991622, 'acc_grapheme': 0.969877, 'acc_vowel': 0.990042, 'acc_consonant': 0.991187, 'loss_grapheme': 0.12638, 'loss_vowel': 0.048615, 'loss_consonant': 0.039898}\n",
      "   83 | 0.000035 | 051712/180756 | 3.0408 | 0.8544 |\n",
      "val: {'recall': 0.979713, 'recall_grapheme': 0.969876, 'recall_vowel': 0.987319, 'recall_consonant': 0.991781, 'acc_grapheme': 0.96898, 'acc_vowel': 0.99054, 'acc_consonant': 0.991536, 'loss_grapheme': 0.126185, 'loss_vowel': 0.049874, 'loss_consonant': 0.03791}\n",
      "   83 | 0.000026 | 154112/180756 | 1.1766 | 0.9786 |\n",
      "val: {'recall': 0.979989, 'recall_grapheme': 0.969897, 'recall_vowel': 0.988051, 'recall_consonant': 0.99211, 'acc_grapheme': 0.971022, 'acc_vowel': 0.991237, 'acc_consonant': 0.991934, 'loss_grapheme': 0.120967, 'loss_vowel': 0.049997, 'loss_consonant': 0.036657}\n",
      "   84 | 0.000016 | 075776/180756 | 0.0097 | 0.9595 |\n",
      "val: {'recall': 0.979844, 'recall_grapheme': 0.970712, 'recall_vowel': 0.987467, 'recall_consonant': 0.990485, 'acc_grapheme': 0.971569, 'acc_vowel': 0.990888, 'acc_consonant': 0.991984, 'loss_grapheme': 0.118065, 'loss_vowel': 0.046289, 'loss_consonant': 0.036053}\n",
      "   84 | 0.000008 | 178176/180756 | 0.0048 | 0.9490 |\n",
      "val: {'recall': 0.980936, 'recall_grapheme': 0.972277, 'recall_vowel': 0.989057, 'recall_consonant': 0.990135, 'acc_grapheme': 0.972117, 'acc_vowel': 0.991187, 'acc_consonant': 0.991735, 'loss_grapheme': 0.11743, 'loss_vowel': 0.046327, 'loss_consonant': 0.036052}\n",
      "   85 | 0.000003 | 099840/180756 | 0.0038 | 1.0217 |\n",
      "val: {'recall': 0.980337, 'recall_grapheme': 0.971033, 'recall_vowel': 0.988817, 'recall_consonant': 0.990467, 'acc_grapheme': 0.97142, 'acc_vowel': 0.991187, 'acc_consonant': 0.991834, 'loss_grapheme': 0.118253, 'loss_vowel': 0.045828, 'loss_consonant': 0.036549}\n",
      "   86 | 0.000001 | 021504/180756 | 2.4762 | 1.0387 |\n",
      "val: {'recall': 0.979497, 'recall_grapheme': 0.969803, 'recall_vowel': 0.988092, 'recall_consonant': 0.990292, 'acc_grapheme': 0.971022, 'acc_vowel': 0.990838, 'acc_consonant': 0.991884, 'loss_grapheme': 0.122705, 'loss_vowel': 0.053018, 'loss_consonant': 0.039388}\n",
      "   86 | 0.000003 | 123904/180756 | 2.6221 | 1.0262 |\n",
      "val: {'recall': 0.98018, 'recall_grapheme': 0.970105, 'recall_vowel': 0.987868, 'recall_consonant': 0.992641, 'acc_grapheme': 0.971071, 'acc_vowel': 0.990838, 'acc_consonant': 0.991934, 'loss_grapheme': 0.118362, 'loss_vowel': 0.048739, 'loss_consonant': 0.03675}\n",
      "   87 | 0.000008 | 045568/180756 | 2.5739 | 0.8565 |\n",
      "val: {'recall': 0.980834, 'recall_grapheme': 0.971129, 'recall_vowel': 0.988949, 'recall_consonant': 0.992131, 'acc_grapheme': 0.971769, 'acc_vowel': 0.991486, 'acc_consonant': 0.991536, 'loss_grapheme': 0.118009, 'loss_vowel': 0.045271, 'loss_consonant': 0.035394}\n",
      "   87 | 0.000016 | 147968/180756 | 0.0052 | 0.9282 |\n",
      "val: {'recall': 0.979186, 'recall_grapheme': 0.970656, 'recall_vowel': 0.987307, 'recall_consonant': 0.988126, 'acc_grapheme': 0.971619, 'acc_vowel': 0.990739, 'acc_consonant': 0.991735, 'loss_grapheme': 0.117234, 'loss_vowel': 0.048445, 'loss_consonant': 0.036107}\n",
      "   88 | 0.000025 | 069632/180756 | 0.0395 | 0.9294 |\n",
      "val: {'recall': 0.979491, 'recall_grapheme': 0.969758, 'recall_vowel': 0.985852, 'recall_consonant': 0.992594, 'acc_grapheme': 0.970773, 'acc_vowel': 0.990291, 'acc_consonant': 0.991735, 'loss_grapheme': 0.122026, 'loss_vowel': 0.046094, 'loss_consonant': 0.035394}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88 | 0.000035 | 172032/180756 | 0.0125 | 0.8470 |\n",
      "val: {'recall': 0.979817, 'recall_grapheme': 0.970339, 'recall_vowel': 0.987451, 'recall_consonant': 0.991137, 'acc_grapheme': 0.970524, 'acc_vowel': 0.990988, 'acc_consonant': 0.99044, 'loss_grapheme': 0.132758, 'loss_vowel': 0.046578, 'loss_consonant': 0.040624}\n",
      "   89 | 0.000043 | 093696/180756 | 0.0127 | 1.0265 |\n",
      "val: {'recall': 0.978685, 'recall_grapheme': 0.96823, 'recall_vowel': 0.988799, 'recall_consonant': 0.98948, 'acc_grapheme': 0.969677, 'acc_vowel': 0.990988, 'acc_consonant': 0.991087, 'loss_grapheme': 0.12766, 'loss_vowel': 0.047853, 'loss_consonant': 0.03898}\n",
      "   90 | 0.000048 | 015360/180756 | 0.0164 | 1.1609 |\n",
      "val: {'recall': 0.977315, 'recall_grapheme': 0.966645, 'recall_vowel': 0.987395, 'recall_consonant': 0.988576, 'acc_grapheme': 0.967736, 'acc_vowel': 0.989743, 'acc_consonant': 0.990191, 'loss_grapheme': 0.13509, 'loss_vowel': 0.050962, 'loss_consonant': 0.041461}\n",
      "   90 | 0.000050 | 117760/180756 | 0.0068 | 0.8705 |\n",
      "val: {'recall': 0.979009, 'recall_grapheme': 0.97018, 'recall_vowel': 0.987572, 'recall_consonant': 0.988104, 'acc_grapheme': 0.968283, 'acc_vowel': 0.990341, 'acc_consonant': 0.99049, 'loss_grapheme': 0.145287, 'loss_vowel': 0.048244, 'loss_consonant': 0.041224}\n",
      "   91 | 0.000048 | 039424/180756 | 0.5755 | 1.2351 |\n",
      "val: {'recall': 0.978691, 'recall_grapheme': 0.967242, 'recall_vowel': 0.988036, 'recall_consonant': 0.992246, 'acc_grapheme': 0.968084, 'acc_vowel': 0.990341, 'acc_consonant': 0.990789, 'loss_grapheme': 0.139319, 'loss_vowel': 0.057205, 'loss_consonant': 0.048415}\n",
      "   91 | 0.000043 | 122880/180756 | 0.9938 | 1.0356 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8501fff2442a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# augmentation with 0.4 prob mixup, loss weight 2.0 on grapheme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-b7bd0e5b60ac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdo_mixup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) # augmentation with 0.4 prob mixup, loss weight 2.0 on grapheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./models/se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
