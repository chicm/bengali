{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image\n",
    "from utils import bn_update, moving_average, copy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport albumentations as albu\\n\\ndef get_train_augs(p=1.):\\n    return albu.Compose([\\n        #albu.HorizontalFlip(.5),\\n        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\\n        albu.Blur(blur_limit=3, p=0.3),\\n        albu.OpticalDistortion(p=0.3),\\n        albu.GaussNoise(p=0.3)\\n        #albu.GridDistortion(p=.33),\\n        #albu.HueSaturationValue(p=.33) # not for grey scale\\n    ], p=p)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(256, 512), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F.interpolate(torch.randn(2,1,224,224), size=(256, 512), mode='bilinear', align_corners=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './new-model3-ckps'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7971996704567992"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "        img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "        batch_size = img.size(0)\n",
    "        r = np.random.rand()\n",
    "\n",
    "        if r < 0.3:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs = model(img)\n",
    "            loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "        elif r > 0.7: # grid mask\n",
    "            img = grid(img)\n",
    "            outputs = model(img)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            orig_img, targets = mixup(orig_img, targets)\n",
    "            outputs = model(orig_img)\n",
    "            loss = mixup_criterion(outputs, targets)\n",
    "            #loss = criterion(outputs, targets)\n",
    "        '''\n",
    "        #if True:\n",
    "        if r < 0.3:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            #img[:, :, bby1:bby2, bbx1:bbx2] = img[rand_index, :, bby1:bby2, bbx1:bbx2] #for new cutmix\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "            loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r > 0.7:\n",
    "            img = grid(img)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, targets)\n",
    "            loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        else:\n",
    "            orig_img, targets = mixup(orig_img, targets)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "            loss_primary = mixup_criterion(outputs, targets)\n",
    "            loss_aux1 = mixup_criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = mixup_criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "            #loss = criterion(outputs, targets)\n",
    "        '''\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        lr_scheduler(optimizer, batch_idx, epoch)\n",
    "        optimizer.step()            \n",
    "        \n",
    "        current_lr = get_lrs(optimizer)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "            epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "            loss.item(), train_loss/(batch_idx+1)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "best_metrics = 0.\n",
    "best_metrics_swa = 0.\n",
    "\n",
    "\n",
    "def validate_and_save(model, model_file, val_loader, save=False):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        best_metrics = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "\n",
    "def validate_and_save_swa(model, model_file, val_loader, save=False):\n",
    "    global best_metrics_swa\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics_swa:\n",
    "        best_metrics_swa = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    model, model_file = create_model(args)\n",
    "    model = model.cuda()\n",
    "\n",
    "    swa_args = copy.deepcopy(args)\n",
    "    swa_args.ckp_name = args.ckp_name + '_swa'\n",
    "    swa_model, swa_model_file = create_model(swa_args)\n",
    "    swa_model = swa_model.cuda()\n",
    "\n",
    "    optimizer = make_optimizer(model)\n",
    "    lr_scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    [model, swa_model], optimizer = amp.initialize([model, swa_model], optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    #[model, swa_model], optimizer = amp.initialize(\n",
    "    #    [model, swa_model], optimizer, opt_level=\"O2\",verbosity=0, keep_batchnorm_fp32=True)\n",
    "    \n",
    "    #opt_level=\"O2\", keep_batchnorm_fp32=True\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        swa_model = nn.DataParallel(swa_model)\n",
    "    \n",
    "    validate_and_save(model, model_file, val_loader, save=False)\n",
    "\n",
    "    swa_model_loaded = False\n",
    "    if os.path.exists(swa_model_file):\n",
    "        swa_model_loaded = True\n",
    "        validate_and_save_swa(swa_model, swa_model_file, val_loader, save=False)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "        for epoch in range(args.start_epoch, args.num_epochs):\n",
    "            grid.set_prob(epoch, args.st_epochs)\n",
    "            train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\n",
    "            validate_and_save(model, model_file, val_loader, save=True)\n",
    "            \n",
    "            if (epoch+1) == args.swa_start and cycle == 1:\n",
    "                if not swa_model_loaded:\n",
    "                    copy_model(swa_model, model)\n",
    "                #swa_n = 0\n",
    "                swa_n = args.swa_n\n",
    "            if (epoch+1) >= args.swa_start and (epoch+1) % args.swa_freq == 0:\n",
    "                print('SWA>>>:')\n",
    "                moving_average(swa_model, model, 1.0 / (swa_n + 1))\n",
    "                swa_n += 1\n",
    "                bn_update(train_loader, swa_model)\n",
    "                validate_and_save_swa(swa_model, swa_model_file, val_loader, save=True)\n",
    "\n",
    "        #args.base_lr = 1e-4\n",
    "        #args.num_epochs = 60\n",
    "        #args.warmup_epochs = 5\n",
    "        #args.swa_start = 15\n",
    "        #args.swa_freq = 3\n",
    "\n",
    "        # reset scheduler at each cycle\n",
    "        lr_scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model3_res50_fold4_256_512.pth'\n",
    "\n",
    "args.base_lr = 8e-5\n",
    "args.num_epochs = 60\n",
    "args.start_epoch = 10\n",
    "args.warmup_epochs = 5\n",
    "\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 280\n",
    "args.val_batch_size = 512\n",
    "args.st_epochs = 5\n",
    "\n",
    "args.swa_start = 15\n",
    "args.swa_freq = 3\n",
    "args.swa_n = 5\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160735, 6) (40105, 6)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth, exist: True\n",
      "loading ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth...\n",
      "model file: ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth_swa, exist: True\n",
      "loading ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth_swa...\n",
      "\n",
      "val: {'recall': 0.998326, 'recall_grapheme': 0.997742, 'recall_vowel': 0.99917, 'recall_consonant': 0.99865, 'acc_grapheme': 0.997432, 'acc_vowel': 0.999052, 'acc_consonant': 0.999052, 'loss_grapheme': 0.019324, 'loss_vowel': 0.015373, 'loss_consonant': 0.011769}\n",
      "\n",
      "val: {'recall': 0.998566, 'recall_grapheme': 0.998129, 'recall_vowel': 0.999308, 'recall_consonant': 0.998697, 'acc_grapheme': 0.997905, 'acc_vowel': 0.999127, 'acc_consonant': 0.999127, 'loss_grapheme': 0.009049, 'loss_vowel': 0.004092, 'loss_consonant': 0.003665}\n",
      "CYCLE: 1\n",
      "   10 | 0.000074 | 160720/160735 | 1.7604 | 1.3775 |\n",
      "val: {'recall': 0.997881, 'recall_grapheme': 0.997178, 'recall_vowel': 0.99899, 'recall_consonant': 0.998178, 'acc_grapheme': 0.996783, 'acc_vowel': 0.998753, 'acc_consonant': 0.998654, 'loss_grapheme': 0.017455, 'loss_vowel': 0.011695, 'loss_consonant': 0.009666}\n",
      "   11 | 0.000072 | 160720/160735 | 1.2243 | 1.2826 |\n",
      "val: {'recall': 0.997461, 'recall_grapheme': 0.996866, 'recall_vowel': 0.998915, 'recall_consonant': 0.997195, 'acc_grapheme': 0.996559, 'acc_vowel': 0.998703, 'acc_consonant': 0.998678, 'loss_grapheme': 0.017624, 'loss_vowel': 0.011134, 'loss_consonant': 0.008892}\n",
      "   12 | 0.000071 | 160720/160735 | 1.0564 | 1.3651 |\n",
      "val: {'recall': 0.997054, 'recall_grapheme': 0.996137, 'recall_vowel': 0.998427, 'recall_consonant': 0.997516, 'acc_grapheme': 0.995836, 'acc_vowel': 0.998354, 'acc_consonant': 0.99808, 'loss_grapheme': 0.016635, 'loss_vowel': 0.009296, 'loss_consonant': 0.008003}\n",
      "   13 | 0.000070 | 160720/160735 | 1.4174 | 1.4424 |\n",
      "val: {'recall': 0.997088, 'recall_grapheme': 0.996448, 'recall_vowel': 0.998596, 'recall_consonant': 0.996859, 'acc_grapheme': 0.996035, 'acc_vowel': 0.998504, 'acc_consonant': 0.998354, 'loss_grapheme': 0.030988, 'loss_vowel': 0.021807, 'loss_consonant': 0.016798}\n",
      "   14 | 0.000068 | 160720/160735 | 2.3525 | 1.4268 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997315, 'recall_grapheme': 0.996745, 'recall_vowel': 0.99874, 'recall_consonant': 0.99703, 'acc_grapheme': 0.996559, 'acc_vowel': 0.998654, 'acc_consonant': 0.998504, 'loss_grapheme': 0.018523, 'loss_vowel': 0.011894, 'loss_consonant': 0.010104}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [02:11<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998404, 'recall_grapheme': 0.997821, 'recall_vowel': 0.999278, 'recall_consonant': 0.998697, 'acc_grapheme': 0.997955, 'acc_vowel': 0.999077, 'acc_consonant': 0.999127, 'loss_grapheme': 0.008967, 'loss_vowel': 0.004131, 'loss_consonant': 0.003661}\n",
      "   15 | 0.000067 | 160720/160735 | 2.1835 | 1.4455 |\n",
      "val: {'recall': 0.997394, 'recall_grapheme': 0.996461, 'recall_vowel': 0.998589, 'recall_consonant': 0.998067, 'acc_grapheme': 0.996285, 'acc_vowel': 0.998479, 'acc_consonant': 0.998579, 'loss_grapheme': 0.022371, 'loss_vowel': 0.015577, 'loss_consonant': 0.012056}\n",
      "   16 | 0.000065 | 160720/160735 | 0.1762 | 1.4121 |\n",
      "val: {'recall': 0.997679, 'recall_grapheme': 0.99667, 'recall_vowel': 0.998597, 'recall_consonant': 0.998778, 'acc_grapheme': 0.996808, 'acc_vowel': 0.998654, 'acc_consonant': 0.998579, 'loss_grapheme': 0.015938, 'loss_vowel': 0.010189, 'loss_consonant': 0.008488}\n",
      "   17 | 0.000064 | 160720/160735 | 1.5925 | 1.4009 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.99789, 'recall_grapheme': 0.997011, 'recall_vowel': 0.998952, 'recall_consonant': 0.998585, 'acc_grapheme': 0.996858, 'acc_vowel': 0.998878, 'acc_consonant': 0.998828, 'loss_grapheme': 0.02234, 'loss_vowel': 0.017368, 'loss_consonant': 0.013063}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [02:11<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998428, 'recall_grapheme': 0.997865, 'recall_vowel': 0.999278, 'recall_consonant': 0.998703, 'acc_grapheme': 0.99793, 'acc_vowel': 0.999077, 'acc_consonant': 0.999152, 'loss_grapheme': 0.008893, 'loss_vowel': 0.004094, 'loss_consonant': 0.003636}\n",
      "   18 | 0.000062 | 160720/160735 | 3.1201 | 1.3766 |\n",
      "val: {'recall': 0.997281, 'recall_grapheme': 0.996374, 'recall_vowel': 0.998527, 'recall_consonant': 0.99785, 'acc_grapheme': 0.995836, 'acc_vowel': 0.998329, 'acc_consonant': 0.998304, 'loss_grapheme': 0.017309, 'loss_vowel': 0.009962, 'loss_consonant': 0.008406}\n",
      "   19 | 0.000060 | 160720/160735 | 1.1534 | 1.4050 |\n",
      "val: {'recall': 0.995825, 'recall_grapheme': 0.995496, 'recall_vowel': 0.998441, 'recall_consonant': 0.993867, 'acc_grapheme': 0.994415, 'acc_vowel': 0.99813, 'acc_consonant': 0.995686, 'loss_grapheme': 0.022521, 'loss_vowel': 0.009307, 'loss_consonant': 0.016431}\n",
      "   20 | 0.000058 | 160720/160735 | 2.5372 | 1.4057 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996349, 'recall_grapheme': 0.996183, 'recall_vowel': 0.998538, 'recall_consonant': 0.994491, 'acc_grapheme': 0.995587, 'acc_vowel': 0.99828, 'acc_consonant': 0.996135, 'loss_grapheme': 0.018005, 'loss_vowel': 0.008804, 'loss_consonant': 0.013801}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [02:10<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998434, 'recall_grapheme': 0.997883, 'recall_vowel': 0.999278, 'recall_consonant': 0.998692, 'acc_grapheme': 0.997955, 'acc_vowel': 0.999077, 'acc_consonant': 0.999102, 'loss_grapheme': 0.008915, 'loss_vowel': 0.004129, 'loss_consonant': 0.00362}\n",
      "   21 | 0.000056 | 160720/160735 | 0.7384 | 1.4176 |\n",
      "val: {'recall': 0.997564, 'recall_grapheme': 0.996543, 'recall_vowel': 0.999089, 'recall_consonant': 0.998082, 'acc_grapheme': 0.996584, 'acc_vowel': 0.998953, 'acc_consonant': 0.998504, 'loss_grapheme': 0.020586, 'loss_vowel': 0.014321, 'loss_consonant': 0.01136}\n",
      "   22 | 0.000054 | 160720/160735 | 0.8256 | 1.3718 |\n",
      "val: {'recall': 0.9951, 'recall_grapheme': 0.995567, 'recall_vowel': 0.998273, 'recall_consonant': 0.99099, 'acc_grapheme': 0.995213, 'acc_vowel': 0.998055, 'acc_consonant': 0.993293, 'loss_grapheme': 0.019454, 'loss_vowel': 0.00987, 'loss_consonant': 0.021837}\n",
      "   23 | 0.000052 | 160720/160735 | 0.0971 | 1.5003 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997128, 'recall_grapheme': 0.996122, 'recall_vowel': 0.998384, 'recall_consonant': 0.997885, 'acc_grapheme': 0.99611, 'acc_vowel': 0.998554, 'acc_consonant': 0.998329, 'loss_grapheme': 0.020543, 'loss_vowel': 0.013576, 'loss_consonant': 0.01216}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [02:11<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998433, 'recall_grapheme': 0.99787, 'recall_vowel': 0.999293, 'recall_consonant': 0.998697, 'acc_grapheme': 0.997905, 'acc_vowel': 0.999102, 'acc_consonant': 0.999127, 'loss_grapheme': 0.008952, 'loss_vowel': 0.004144, 'loss_consonant': 0.003633}\n",
      "   24 | 0.000050 | 160720/160735 | 0.1306 | 1.3305 |\n",
      "val: {'recall': 0.997895, 'recall_grapheme': 0.997182, 'recall_vowel': 0.998842, 'recall_consonant': 0.998375, 'acc_grapheme': 0.996858, 'acc_vowel': 0.998753, 'acc_consonant': 0.998703, 'loss_grapheme': 0.017344, 'loss_vowel': 0.012411, 'loss_consonant': 0.009205}\n",
      "   25 | 0.000048 | 160720/160735 | 1.0223 | 1.4663 |\n",
      "val: {'recall': 0.995599, 'recall_grapheme': 0.996075, 'recall_vowel': 0.998453, 'recall_consonant': 0.991793, 'acc_grapheme': 0.995636, 'acc_vowel': 0.998205, 'acc_consonant': 0.995038, 'loss_grapheme': 0.017952, 'loss_vowel': 0.008977, 'loss_consonant': 0.017277}\n",
      "   26 | 0.000046 | 160720/160735 | 0.0413 | 1.3641 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.996972, 'recall_grapheme': 0.99565, 'recall_vowel': 0.99845, 'recall_consonant': 0.998139, 'acc_grapheme': 0.995661, 'acc_vowel': 0.998304, 'acc_consonant': 0.998504, 'loss_grapheme': 0.016935, 'loss_vowel': 0.009717, 'loss_consonant': 0.007878}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [02:11<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998418, 'recall_grapheme': 0.997837, 'recall_vowel': 0.999293, 'recall_consonant': 0.998703, 'acc_grapheme': 0.997881, 'acc_vowel': 0.999102, 'acc_consonant': 0.999152, 'loss_grapheme': 0.008959, 'loss_vowel': 0.004119, 'loss_consonant': 0.003574}\n",
      "   27 | 0.000044 | 160720/160735 | 0.0732 | 1.3413 |\n",
      "val: {'recall': 0.99736, 'recall_grapheme': 0.996534, 'recall_vowel': 0.998606, 'recall_consonant': 0.997766, 'acc_grapheme': 0.995836, 'acc_vowel': 0.998454, 'acc_consonant': 0.99823, 'loss_grapheme': 0.019473, 'loss_vowel': 0.012077, 'loss_consonant': 0.010996}\n",
      "   28 | 0.000042 | 160720/160735 | 3.3739 | 1.3072 |\n",
      "val: {'recall': 0.997646, 'recall_grapheme': 0.996685, 'recall_vowel': 0.998936, 'recall_consonant': 0.998277, 'acc_grapheme': 0.996384, 'acc_vowel': 0.998778, 'acc_consonant': 0.998629, 'loss_grapheme': 0.022842, 'loss_vowel': 0.018021, 'loss_consonant': 0.012886}\n",
      "   29 | 0.000040 | 160720/160735 | 2.6277 | 1.3237 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997299, 'recall_grapheme': 0.996195, 'recall_vowel': 0.998489, 'recall_consonant': 0.998315, 'acc_grapheme': 0.995861, 'acc_vowel': 0.998479, 'acc_consonant': 0.998329, 'loss_grapheme': 0.019989, 'loss_vowel': 0.011532, 'loss_consonant': 0.010559}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [02:12<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998446, 'recall_grapheme': 0.997889, 'recall_vowel': 0.999304, 'recall_consonant': 0.998703, 'acc_grapheme': 0.997856, 'acc_vowel': 0.999127, 'acc_consonant': 0.999152, 'loss_grapheme': 0.008947, 'loss_vowel': 0.004103, 'loss_consonant': 0.003559}\n",
      "   30 | 0.000038 | 160720/160735 | 2.2773 | 1.3233 |\n",
      "val: {'recall': 0.996512, 'recall_grapheme': 0.995664, 'recall_vowel': 0.998166, 'recall_consonant': 0.996554, 'acc_grapheme': 0.995462, 'acc_vowel': 0.998005, 'acc_consonant': 0.997357, 'loss_grapheme': 0.017756, 'loss_vowel': 0.009567, 'loss_consonant': 0.010789}\n",
      "   31 | 0.000036 | 160720/160735 | 0.1188 | 1.2947 |\n",
      "val: {'recall': 0.997565, 'recall_grapheme': 0.996707, 'recall_vowel': 0.998698, 'recall_consonant': 0.998149, 'acc_grapheme': 0.996484, 'acc_vowel': 0.998629, 'acc_consonant': 0.998604, 'loss_grapheme': 0.017034, 'loss_vowel': 0.010864, 'loss_consonant': 0.008605}\n",
      "   32 | 0.000034 | 160720/160735 | 0.1340 | 1.3819 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.997694, 'recall_grapheme': 0.996801, 'recall_vowel': 0.998896, 'recall_consonant': 0.998277, 'acc_grapheme': 0.996783, 'acc_vowel': 0.998753, 'acc_consonant': 0.998554, 'loss_grapheme': 0.016086, 'loss_vowel': 0.010713, 'loss_consonant': 0.008164}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [02:11<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.998468, 'recall_grapheme': 0.99792, 'recall_vowel': 0.999322, 'recall_consonant': 0.998709, 'acc_grapheme': 0.99793, 'acc_vowel': 0.999152, 'acc_consonant': 0.999177, 'loss_grapheme': 0.008977, 'loss_vowel': 0.004089, 'loss_consonant': 0.003533}\n",
      "   33 | 0.000032 | 160720/160735 | 0.5514 | 1.4002 |\n",
      "val: {'recall': 0.994198, 'recall_grapheme': 0.995598, 'recall_vowel': 0.997433, 'recall_consonant': 0.988165, 'acc_grapheme': 0.995238, 'acc_vowel': 0.997531, 'acc_consonant': 0.990325, 'loss_grapheme': 0.022824, 'loss_vowel': 0.013254, 'loss_consonant': 0.029641}\n",
      "   34 | 0.000030 | 160720/160735 | 0.0562 | 1.3230 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-bd527aca1785>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_start\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-bd527aca1785>\u001b[0m in \u001b[0;36mvalidate_and_save\u001b[0;34m(model, model_file, val_loader, save)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbest_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-0e344cb1f778>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth, exist: True\n",
      "loading ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth...\n",
      "model file: ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.993159, 'recall_grapheme': 0.990407, 'recall_vowel': 0.995688, 'recall_consonant': 0.996137, 'acc_grapheme': 0.990849, 'acc_vowel': 0.99626, 'acc_consonant': 0.996434, 'loss_grapheme': 0.07707, 'loss_vowel': 0.065005, 'loss_consonant': 0.044777}\n",
      "CYCLE: 1\n",
      "    0 | 0.000195 | 160720/160735 | 1.9432 | 1.6098 |\n",
      "val: {'recall': 0.995326, 'recall_grapheme': 0.993633, 'recall_vowel': 0.997483, 'recall_consonant': 0.996555, 'acc_grapheme': 0.99237, 'acc_vowel': 0.997182, 'acc_consonant': 0.997307, 'loss_grapheme': 0.050218, 'loss_vowel': 0.039879, 'loss_consonant': 0.032145}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "    1 | 0.000362 | 160720/160735 | 1.9828 | 1.5628 |\n",
      "val: {'recall': 0.994286, 'recall_grapheme': 0.992043, 'recall_vowel': 0.996688, 'recall_consonant': 0.996371, 'acc_grapheme': 0.989976, 'acc_vowel': 0.996235, 'acc_consonant': 0.995961, 'loss_grapheme': 0.041682, 'loss_vowel': 0.019773, 'loss_consonant': 0.023214}\n",
      "    2 | 0.000318 | 160720/160735 | 3.0473 | 1.5191 |\n",
      "val: {'recall': 0.995014, 'recall_grapheme': 0.992926, 'recall_vowel': 0.997056, 'recall_consonant': 0.997147, 'acc_grapheme': 0.99242, 'acc_vowel': 0.997083, 'acc_consonant': 0.997357, 'loss_grapheme': 0.064415, 'loss_vowel': 0.04684, 'loss_consonant': 0.037221}\n",
      "    3 | 0.000262 | 160720/160735 | 0.3098 | 1.4846 |\n",
      "val: {'recall': 0.99573, 'recall_grapheme': 0.994081, 'recall_vowel': 0.997491, 'recall_consonant': 0.997267, 'acc_grapheme': 0.993617, 'acc_vowel': 0.997058, 'acc_consonant': 0.997108, 'loss_grapheme': 0.043473, 'loss_vowel': 0.033815, 'loss_consonant': 0.026094}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "    4 | 0.000200 | 160720/160735 | 0.2348 | 1.5230 |\n",
      "val: {'recall': 0.996261, 'recall_grapheme': 0.994821, 'recall_vowel': 0.99799, 'recall_consonant': 0.99741, 'acc_grapheme': 0.994764, 'acc_vowel': 0.997656, 'acc_consonant': 0.997656, 'loss_grapheme': 0.033573, 'loss_vowel': 0.02695, 'loss_consonant': 0.020894}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "    5 | 0.000138 | 160720/160735 | 0.7247 | 1.4576 |\n",
      "val: {'recall': 0.996151, 'recall_grapheme': 0.994116, 'recall_vowel': 0.998398, 'recall_consonant': 0.997972, 'acc_grapheme': 0.994091, 'acc_vowel': 0.998005, 'acc_consonant': 0.99803, 'loss_grapheme': 0.034129, 'loss_vowel': 0.027055, 'loss_consonant': 0.021891}\n",
      "    6 | 0.000083 | 160720/160735 | 1.2711 | 1.5255 |\n",
      "val: {'recall': 0.99729, 'recall_grapheme': 0.996218, 'recall_vowel': 0.998701, 'recall_consonant': 0.998023, 'acc_grapheme': 0.995786, 'acc_vowel': 0.998379, 'acc_consonant': 0.998329, 'loss_grapheme': 0.030406, 'loss_vowel': 0.024451, 'loss_consonant': 0.018626}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "    7 | 0.000038 | 160720/160735 | 0.1771 | 1.4867 |\n",
      "val: {'recall': 0.997232, 'recall_grapheme': 0.996173, 'recall_vowel': 0.998757, 'recall_consonant': 0.997824, 'acc_grapheme': 0.995861, 'acc_vowel': 0.998354, 'acc_consonant': 0.99818, 'loss_grapheme': 0.02511, 'loss_vowel': 0.018633, 'loss_consonant': 0.015666}\n",
      "    8 | 0.000010 | 160720/160735 | 0.8192 | 1.4497 |\n",
      "val: {'recall': 0.997259, 'recall_grapheme': 0.996158, 'recall_vowel': 0.998769, 'recall_consonant': 0.997951, 'acc_grapheme': 0.995886, 'acc_vowel': 0.998329, 'acc_consonant': 0.998379, 'loss_grapheme': 0.025357, 'loss_vowel': 0.01961, 'loss_consonant': 0.015251}\n",
      "    9 | 0.000000 | 160720/160735 | 1.0850 | 1.4286 |\n",
      "val: {'recall': 0.996408, 'recall_grapheme': 0.995813, 'recall_vowel': 0.998479, 'recall_consonant': 0.995528, 'acc_grapheme': 0.995238, 'acc_vowel': 0.997856, 'acc_consonant': 0.996609, 'loss_grapheme': 0.020392, 'loss_vowel': 0.01063, 'loss_consonant': 0.01585}\n",
      "CYCLE: 2\n",
      "    0 | 0.000020 | 160720/160735 | 0.5661 | 1.3609 |\n",
      "val: {'recall': 0.996709, 'recall_grapheme': 0.995713, 'recall_vowel': 0.998505, 'recall_consonant': 0.996903, 'acc_grapheme': 0.995038, 'acc_vowel': 0.99798, 'acc_consonant': 0.997232, 'loss_grapheme': 0.021638, 'loss_vowel': 0.010197, 'loss_consonant': 0.014595}\n",
      "    1 | 0.000040 | 160720/160735 | 0.8895 | 1.4249 |\n",
      "val: {'recall': 0.99699, 'recall_grapheme': 0.99578, 'recall_vowel': 0.998585, 'recall_consonant': 0.997814, 'acc_grapheme': 0.995287, 'acc_vowel': 0.998205, 'acc_consonant': 0.99828, 'loss_grapheme': 0.023717, 'loss_vowel': 0.01595, 'loss_consonant': 0.014141}\n",
      "    2 | 0.000059 | 160720/160735 | 3.5752 | 1.4116 |\n",
      "val: {'recall': 0.995743, 'recall_grapheme': 0.994821, 'recall_vowel': 0.998217, 'recall_consonant': 0.995113, 'acc_grapheme': 0.994165, 'acc_vowel': 0.997881, 'acc_consonant': 0.996135, 'loss_grapheme': 0.030875, 'loss_vowel': 0.018241, 'loss_consonant': 0.023396}\n",
      "    3 | 0.000079 | 160720/160735 | 1.1727 | 1.4967 |\n",
      "val: {'recall': 0.996919, 'recall_grapheme': 0.995754, 'recall_vowel': 0.998343, 'recall_consonant': 0.997826, 'acc_grapheme': 0.995537, 'acc_vowel': 0.998205, 'acc_consonant': 0.998205, 'loss_grapheme': 0.023195, 'loss_vowel': 0.014802, 'loss_consonant': 0.012968}\n",
      "    4 | 0.000098 | 160720/160735 | 1.4820 | 1.3324 |\n",
      "val: {'recall': 0.996332, 'recall_grapheme': 0.995535, 'recall_vowel': 0.998137, 'recall_consonant': 0.996121, 'acc_grapheme': 0.995088, 'acc_vowel': 0.997905, 'acc_consonant': 0.997232, 'loss_grapheme': 0.025972, 'loss_vowel': 0.016379, 'loss_consonant': 0.017572}\n",
      "    5 | 0.000096 | 160720/160735 | 0.8108 | 1.5466 |\n",
      "val: {'recall': 0.996737, 'recall_grapheme': 0.995566, 'recall_vowel': 0.998275, 'recall_consonant': 0.997542, 'acc_grapheme': 0.995487, 'acc_vowel': 0.998105, 'acc_consonant': 0.998155, 'loss_grapheme': 0.020603, 'loss_vowel': 0.012791, 'loss_consonant': 0.010845}\n",
      "    6 | 0.000095 | 160720/160735 | 2.5663 | 1.4114 |\n",
      "val: {'recall': 0.996788, 'recall_grapheme': 0.995547, 'recall_vowel': 0.998237, 'recall_consonant': 0.997822, 'acc_grapheme': 0.995038, 'acc_vowel': 0.998055, 'acc_consonant': 0.99813, 'loss_grapheme': 0.03093, 'loss_vowel': 0.023664, 'loss_consonant': 0.018894}\n",
      "    7 | 0.000094 | 160720/160735 | 1.6386 | 1.4608 |\n",
      "val: {'recall': 0.996998, 'recall_grapheme': 0.995868, 'recall_vowel': 0.998334, 'recall_consonant': 0.997921, 'acc_grapheme': 0.995761, 'acc_vowel': 0.998205, 'acc_consonant': 0.99828, 'loss_grapheme': 0.018969, 'loss_vowel': 0.010849, 'loss_consonant': 0.009342}\n",
      "    8 | 0.000092 | 160720/160735 | 0.1550 | 1.4201 |\n",
      "val: {'recall': 0.997684, 'recall_grapheme': 0.996922, 'recall_vowel': 0.998673, 'recall_consonant': 0.99822, 'acc_grapheme': 0.996808, 'acc_vowel': 0.998329, 'acc_consonant': 0.998678, 'loss_grapheme': 0.028277, 'loss_vowel': 0.024393, 'loss_consonant': 0.017866}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "    9 | 0.000090 | 160720/160735 | 1.8004 | 1.4574 |\n",
      "val: {'recall': 0.996828, 'recall_grapheme': 0.995889, 'recall_vowel': 0.998165, 'recall_consonant': 0.997368, 'acc_grapheme': 0.995238, 'acc_vowel': 0.997781, 'acc_consonant': 0.99798, 'loss_grapheme': 0.023449, 'loss_vowel': 0.016127, 'loss_consonant': 0.012935}\n",
      "   10 | 0.000089 | 160720/160735 | 1.4633 | 1.5538 |\n",
      "val: {'recall': 0.997535, 'recall_grapheme': 0.99663, 'recall_vowel': 0.998763, 'recall_consonant': 0.998118, 'acc_grapheme': 0.996335, 'acc_vowel': 0.998429, 'acc_consonant': 0.998304, 'loss_grapheme': 0.026273, 'loss_vowel': 0.019256, 'loss_consonant': 0.014467}\n",
      "   11 | 0.000086 | 160720/160735 | 0.0893 | 1.4526 |\n",
      "val: {'recall': 0.996927, 'recall_grapheme': 0.9958, 'recall_vowel': 0.998442, 'recall_consonant': 0.997665, 'acc_grapheme': 0.995612, 'acc_vowel': 0.998304, 'acc_consonant': 0.99823, 'loss_grapheme': 0.027493, 'loss_vowel': 0.019617, 'loss_consonant': 0.015787}\n",
      "   12 | 0.000084 | 160720/160735 | 0.3196 | 1.4712 |\n",
      "val: {'recall': 0.996483, 'recall_grapheme': 0.995265, 'recall_vowel': 0.99817, 'recall_consonant': 0.997231, 'acc_grapheme': 0.994564, 'acc_vowel': 0.99808, 'acc_consonant': 0.997706, 'loss_grapheme': 0.025409, 'loss_vowel': 0.012818, 'loss_consonant': 0.013742}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 0.000082 | 160720/160735 | 0.1083 | 1.4509 |\n",
      "val: {'recall': 0.997592, 'recall_grapheme': 0.99663, 'recall_vowel': 0.998967, 'recall_consonant': 0.998139, 'acc_grapheme': 0.996285, 'acc_vowel': 0.998629, 'acc_consonant': 0.998354, 'loss_grapheme': 0.022873, 'loss_vowel': 0.016748, 'loss_consonant': 0.01383}\n",
      "   14 | 0.000079 | 160720/160735 | 0.1230 | 1.4195 |\n",
      "val: {'recall': 0.997375, 'recall_grapheme': 0.996603, 'recall_vowel': 0.998253, 'recall_consonant': 0.998043, 'acc_grapheme': 0.99616, 'acc_vowel': 0.99813, 'acc_consonant': 0.998404, 'loss_grapheme': 0.018192, 'loss_vowel': 0.011561, 'loss_consonant': 0.009797}\n",
      "   15 | 0.000077 | 160720/160735 | 0.1504 | 1.3703 |\n",
      "val: {'recall': 0.997769, 'recall_grapheme': 0.997123, 'recall_vowel': 0.998774, 'recall_consonant': 0.998057, 'acc_grapheme': 0.996833, 'acc_vowel': 0.998728, 'acc_consonant': 0.998554, 'loss_grapheme': 0.024975, 'loss_vowel': 0.018703, 'loss_consonant': 0.014175}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "   16 | 0.000074 | 160720/160735 | 2.1991 | 1.3398 |\n",
      "val: {'recall': 0.997026, 'recall_grapheme': 0.996053, 'recall_vowel': 0.998315, 'recall_consonant': 0.997682, 'acc_grapheme': 0.995562, 'acc_vowel': 0.998005, 'acc_consonant': 0.99823, 'loss_grapheme': 0.02247, 'loss_vowel': 0.013721, 'loss_consonant': 0.01328}\n",
      "   17 | 0.000071 | 160720/160735 | 0.4542 | 1.3759 |\n",
      "val: {'recall': 0.997285, 'recall_grapheme': 0.996696, 'recall_vowel': 0.998238, 'recall_consonant': 0.997511, 'acc_grapheme': 0.995886, 'acc_vowel': 0.99823, 'acc_consonant': 0.99813, 'loss_grapheme': 0.018058, 'loss_vowel': 0.0101, 'loss_consonant': 0.010379}\n",
      "   18 | 0.000068 | 160720/160735 | 0.1348 | 1.4688 |\n",
      "val: {'recall': 0.996341, 'recall_grapheme': 0.995542, 'recall_vowel': 0.998237, 'recall_consonant': 0.996043, 'acc_grapheme': 0.994938, 'acc_vowel': 0.99793, 'acc_consonant': 0.997182, 'loss_grapheme': 0.02108, 'loss_vowel': 0.009978, 'loss_consonant': 0.012876}\n",
      "   19 | 0.000065 | 160720/160735 | 3.2192 | 1.3824 |\n",
      "val: {'recall': 0.996853, 'recall_grapheme': 0.995765, 'recall_vowel': 0.998639, 'recall_consonant': 0.997241, 'acc_grapheme': 0.995362, 'acc_vowel': 0.998255, 'acc_consonant': 0.998005, 'loss_grapheme': 0.022881, 'loss_vowel': 0.013048, 'loss_consonant': 0.013327}\n",
      "   20 | 0.000062 | 160720/160735 | 1.3658 | 1.4720 |\n",
      "val: {'recall': 0.993598, 'recall_grapheme': 0.99508, 'recall_vowel': 0.997775, 'recall_consonant': 0.986456, 'acc_grapheme': 0.993642, 'acc_vowel': 0.997656, 'acc_consonant': 0.989129, 'loss_grapheme': 0.03426, 'loss_vowel': 0.013069, 'loss_consonant': 0.038607}\n",
      "   21 | 0.000059 | 160720/160735 | 3.4471 | 1.4036 |\n",
      "val: {'recall': 0.998035, 'recall_grapheme': 0.997402, 'recall_vowel': 0.998859, 'recall_consonant': 0.998477, 'acc_grapheme': 0.997382, 'acc_vowel': 0.998853, 'acc_consonant': 0.998853, 'loss_grapheme': 0.016266, 'loss_vowel': 0.012419, 'loss_consonant': 0.009512}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "   22 | 0.000056 | 160720/160735 | 1.9572 | 1.3651 |\n",
      "val: {'recall': 0.997156, 'recall_grapheme': 0.996068, 'recall_vowel': 0.998691, 'recall_consonant': 0.997796, 'acc_grapheme': 0.995761, 'acc_vowel': 0.998479, 'acc_consonant': 0.998329, 'loss_grapheme': 0.023073, 'loss_vowel': 0.014949, 'loss_consonant': 0.013134}\n",
      "   23 | 0.000053 | 160720/160735 | 0.1211 | 1.4050 |\n",
      "val: {'recall': 0.996919, 'recall_grapheme': 0.995621, 'recall_vowel': 0.998599, 'recall_consonant': 0.997837, 'acc_grapheme': 0.995686, 'acc_vowel': 0.998504, 'acc_consonant': 0.998454, 'loss_grapheme': 0.017594, 'loss_vowel': 0.009695, 'loss_consonant': 0.008863}\n",
      "   24 | 0.000050 | 160720/160735 | 3.0670 | 1.3490 |\n",
      "val: {'recall': 0.997688, 'recall_grapheme': 0.99676, 'recall_vowel': 0.998917, 'recall_consonant': 0.998313, 'acc_grapheme': 0.996759, 'acc_vowel': 0.998728, 'acc_consonant': 0.998629, 'loss_grapheme': 0.018092, 'loss_vowel': 0.012153, 'loss_consonant': 0.0097}\n",
      "   25 | 0.000047 | 160720/160735 | 1.7302 | 1.3883 |\n",
      "val: {'recall': 0.996875, 'recall_grapheme': 0.996173, 'recall_vowel': 0.998466, 'recall_consonant': 0.996688, 'acc_grapheme': 0.995636, 'acc_vowel': 0.998205, 'acc_consonant': 0.998155, 'loss_grapheme': 0.017929, 'loss_vowel': 0.009144, 'loss_consonant': 0.008903}\n",
      "   26 | 0.000044 | 160720/160735 | 0.1168 | 1.4045 |\n",
      "val: {'recall': 0.997481, 'recall_grapheme': 0.996498, 'recall_vowel': 0.998737, 'recall_consonant': 0.998191, 'acc_grapheme': 0.996185, 'acc_vowel': 0.998654, 'acc_consonant': 0.998479, 'loss_grapheme': 0.0151, 'loss_vowel': 0.008294, 'loss_consonant': 0.007498}\n",
      "   27 | 0.000041 | 160720/160735 | 2.6875 | 1.3837 |\n",
      "val: {'recall': 0.99748, 'recall_grapheme': 0.996625, 'recall_vowel': 0.998494, 'recall_consonant': 0.998175, 'acc_grapheme': 0.99616, 'acc_vowel': 0.998479, 'acc_consonant': 0.998504, 'loss_grapheme': 0.017485, 'loss_vowel': 0.010499, 'loss_consonant': 0.008987}\n",
      "   28 | 0.000038 | 160720/160735 | 1.4215 | 1.3904 |\n",
      "val: {'recall': 0.997683, 'recall_grapheme': 0.997034, 'recall_vowel': 0.998648, 'recall_consonant': 0.998017, 'acc_grapheme': 0.996459, 'acc_vowel': 0.998529, 'acc_consonant': 0.998554, 'loss_grapheme': 0.015418, 'loss_vowel': 0.00903, 'loss_consonant': 0.007596}\n",
      "   29 | 0.000035 | 160720/160735 | 0.7893 | 1.3502 |\n",
      "val: {'recall': 0.997346, 'recall_grapheme': 0.99673, 'recall_vowel': 0.998494, 'recall_consonant': 0.997431, 'acc_grapheme': 0.99626, 'acc_vowel': 0.998479, 'acc_consonant': 0.998055, 'loss_grapheme': 0.016604, 'loss_vowel': 0.008929, 'loss_consonant': 0.008264}\n",
      "   30 | 0.000032 | 160720/160735 | 0.0966 | 1.4298 |\n",
      "val: {'recall': 0.997791, 'recall_grapheme': 0.996999, 'recall_vowel': 0.998786, 'recall_consonant': 0.998379, 'acc_grapheme': 0.996908, 'acc_vowel': 0.998753, 'acc_consonant': 0.998753, 'loss_grapheme': 0.018529, 'loss_vowel': 0.014923, 'loss_consonant': 0.011197}\n",
      "   31 | 0.000029 | 160720/160735 | 0.1007 | 1.3129 |\n",
      "val: {'recall': 0.997911, 'recall_grapheme': 0.997123, 'recall_vowel': 0.999084, 'recall_consonant': 0.998313, 'acc_grapheme': 0.997033, 'acc_vowel': 0.998903, 'acc_consonant': 0.998678, 'loss_grapheme': 0.017388, 'loss_vowel': 0.012832, 'loss_consonant': 0.00981}\n",
      "   32 | 0.000026 | 160720/160735 | 0.1275 | 1.4630 |\n",
      "val: {'recall': 0.997821, 'recall_grapheme': 0.997118, 'recall_vowel': 0.998754, 'recall_consonant': 0.998293, 'acc_grapheme': 0.997133, 'acc_vowel': 0.998678, 'acc_consonant': 0.998629, 'loss_grapheme': 0.020021, 'loss_vowel': 0.01553, 'loss_consonant': 0.011584}\n",
      "   33 | 0.000023 | 160720/160735 | 0.5509 | 1.3350 |\n",
      "val: {'recall': 0.997303, 'recall_grapheme': 0.996823, 'recall_vowel': 0.998689, 'recall_consonant': 0.996878, 'acc_grapheme': 0.996534, 'acc_vowel': 0.998579, 'acc_consonant': 0.998504, 'loss_grapheme': 0.017138, 'loss_vowel': 0.010718, 'loss_consonant': 0.008846}\n",
      "   34 | 0.000021 | 160720/160735 | 0.5162 | 1.4222 |\n",
      "val: {'recall': 0.997617, 'recall_grapheme': 0.997278, 'recall_vowel': 0.998695, 'recall_consonant': 0.997217, 'acc_grapheme': 0.996883, 'acc_vowel': 0.998678, 'acc_consonant': 0.998604, 'loss_grapheme': 0.018467, 'loss_vowel': 0.012713, 'loss_consonant': 0.009722}\n",
      "   35 | 0.000018 | 160720/160735 | 3.3824 | 1.3672 |\n",
      "val: {'recall': 0.996796, 'recall_grapheme': 0.996004, 'recall_vowel': 0.998537, 'recall_consonant': 0.996638, 'acc_grapheme': 0.995437, 'acc_vowel': 0.99828, 'acc_consonant': 0.99828, 'loss_grapheme': 0.020895, 'loss_vowel': 0.012932, 'loss_consonant': 0.01105}\n",
      "   36 | 0.000016 | 160720/160735 | 0.0827 | 1.4026 |\n",
      "val: {'recall': 0.997928, 'recall_grapheme': 0.99761, 'recall_vowel': 0.998955, 'recall_consonant': 0.997537, 'acc_grapheme': 0.997432, 'acc_vowel': 0.999028, 'acc_consonant': 0.998978, 'loss_grapheme': 0.015433, 'loss_vowel': 0.010894, 'loss_consonant': 0.008275}\n",
      "   37 | 0.000014 | 160720/160735 | 0.1303 | 1.3267 |\n",
      "val: {'recall': 0.997444, 'recall_grapheme': 0.99695, 'recall_vowel': 0.998642, 'recall_consonant': 0.997235, 'acc_grapheme': 0.996559, 'acc_vowel': 0.998678, 'acc_consonant': 0.998703, 'loss_grapheme': 0.015576, 'loss_vowel': 0.009862, 'loss_consonant': 0.007724}\n",
      "   38 | 0.000011 | 160720/160735 | 3.5650 | 1.3332 |\n",
      "val: {'recall': 0.997671, 'recall_grapheme': 0.997254, 'recall_vowel': 0.99876, 'recall_consonant': 0.997415, 'acc_grapheme': 0.996908, 'acc_vowel': 0.998753, 'acc_consonant': 0.998803, 'loss_grapheme': 0.015264, 'loss_vowel': 0.009636, 'loss_consonant': 0.007741}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 | 0.000010 | 160720/160735 | 1.5646 | 1.4261 |\n",
      "val: {'recall': 0.997367, 'recall_grapheme': 0.996963, 'recall_vowel': 0.998625, 'recall_consonant': 0.996917, 'acc_grapheme': 0.996434, 'acc_vowel': 0.998504, 'acc_consonant': 0.998479, 'loss_grapheme': 0.016916, 'loss_vowel': 0.011102, 'loss_consonant': 0.008791}\n",
      "   40 | 0.000008 | 160720/160735 | 0.1237 | 1.4017 |\n",
      "val: {'recall': 0.998326, 'recall_grapheme': 0.997742, 'recall_vowel': 0.99917, 'recall_consonant': 0.99865, 'acc_grapheme': 0.997432, 'acc_vowel': 0.999052, 'acc_consonant': 0.999052, 'loss_grapheme': 0.019324, 'loss_vowel': 0.015373, 'loss_consonant': 0.011769}\n",
      "###>>>>> saved ./new-model3-ckps/se_resnext50_32x4d/model3_res50_fold4_256_512.pth\n",
      "   41 | 0.000006 | 160720/160735 | 0.0901 | 1.3473 |\n",
      "val: {'recall': 0.997868, 'recall_grapheme': 0.997142, 'recall_vowel': 0.998767, 'recall_consonant': 0.998421, 'acc_grapheme': 0.996759, 'acc_vowel': 0.998778, 'acc_consonant': 0.998753, 'loss_grapheme': 0.017633, 'loss_vowel': 0.01258, 'loss_consonant': 0.009785}\n",
      "   42 | 0.000005 | 160720/160735 | 2.9363 | 1.3907 |\n",
      "val: {'recall': 0.99706, 'recall_grapheme': 0.996279, 'recall_vowel': 0.998539, 'recall_consonant': 0.997145, 'acc_grapheme': 0.995711, 'acc_vowel': 0.998329, 'acc_consonant': 0.997831, 'loss_grapheme': 0.018377, 'loss_vowel': 0.00997, 'loss_consonant': 0.010635}\n",
      "   43 | 0.000004 | 160720/160735 | 1.6234 | 1.3431 |\n",
      "val: {'recall': 0.975789, 'recall_grapheme': 0.986542, 'recall_vowel': 0.962146, 'recall_consonant': 0.967925, 'acc_grapheme': 0.97903, 'acc_vowel': 0.959382, 'acc_consonant': 0.969355, 'loss_grapheme': 0.105797, 'loss_vowel': 0.138298, 'loss_consonant': 0.085303}\n",
      "   44 | 0.000002 | 160720/160735 | 1.1248 | 1.4152 |\n",
      "val: {'recall': 0.997482, 'recall_grapheme': 0.997072, 'recall_vowel': 0.998704, 'recall_consonant': 0.997078, 'acc_grapheme': 0.996609, 'acc_vowel': 0.998579, 'acc_consonant': 0.998604, 'loss_grapheme': 0.015933, 'loss_vowel': 0.010453, 'loss_consonant': 0.008092}\n",
      "   45 | 0.000002 | 160720/160735 | 2.6361 | 1.3063 |\n",
      "val: {'recall': 0.996406, 'recall_grapheme': 0.995875, 'recall_vowel': 0.997851, 'recall_consonant': 0.996023, 'acc_grapheme': 0.995088, 'acc_vowel': 0.997756, 'acc_consonant': 0.997058, 'loss_grapheme': 0.021897, 'loss_vowel': 0.012165, 'loss_consonant': 0.013294}\n",
      "   46 | 0.000002 | 012040/160735 | 0.6802 | 1.4418 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-60640ec4a914>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-fb7c2b763f8a>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
