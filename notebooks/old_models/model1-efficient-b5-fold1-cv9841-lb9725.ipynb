{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class PlainRAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "        super(PlainRAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PlainRAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                beta2_t = beta2 ** state['step']\n",
    "                N_sma_max = 2 / (1 - beta2) - 1\n",
    "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:                    \n",
    "                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, warmup = warmup)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AdamW, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                \n",
    "                if group['warmup'] > state['step']:\n",
    "                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n",
    "                else:\n",
    "                    scheduled_lr = group['lr']\n",
    "\n",
    "                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n",
    "                \n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n",
    "\n",
    "                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install opencv-python\\n!pip install fastparquet\\n!pip install pyarrow\\n!pip install snappy\\n!conda install python-snappy -y\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install opencv-python\n",
    "!pip install fastparquet\n",
    "!pip install pyarrow\n",
    "!pip install snappy\n",
    "!conda install python-snappy -y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/mnt/chicm/data/bengali': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor img, y in train_loader:\\n    print(img.size(), y.size())\\n    print(y)\\n    #print(img)\\n    #plt.imshow(img.squeeze()[0].numpy())\\n    break\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for img, y in train_loader:\n",
    "    print(img.size(), y.size())\n",
    "    print(y)\n",
    "    #print(img)\n",
    "    #plt.imshow(img.squeeze()[0].numpy())\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nargs = Namespace()\\nargs.backbone = 'se_resnext50_32x4d'\\nargs.ckp_name = 'best_model.pth'\\nargs.predict = False\\n\\nbnet = create_model(args)[0].cuda()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "\n",
    "bnet = create_model(args)[0].cuda()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum().item()\n",
    "        res.append(correct_k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36119972638146136"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                #img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                #loss = mixup_criterion(outputs, targets)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'efficientnet-b5'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "args.optim = 'RAdam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 512\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160635, 5) (40205, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "model file: ./models/efficientnet-b5/best_model.pth, exist: True\n",
      "loading ./models/efficientnet-b5/best_model.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.980026, 'recall_grapheme': 0.97021, 'recall_vowel': 0.990607, 'recall_consonant': 0.989076, 'acc_grapheme': 0.970327, 'acc_vowel': 0.991867, 'acc_consonant': 0.99122, 'loss_grapheme': 0.132579, 'loss_vowel': 0.063698, 'loss_consonant': 0.053269}\n",
      "    0 | 0.000020 | 102400/160635 | 1.4216 | 1.5926 |\n",
      "val: {'recall': 0.979428, 'recall_grapheme': 0.969732, 'recall_vowel': 0.99021, 'recall_consonant': 0.988036, 'acc_grapheme': 0.970327, 'acc_vowel': 0.991668, 'acc_consonant': 0.991419, 'loss_grapheme': 0.123832, 'loss_vowel': 0.0538, 'loss_consonant': 0.046213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000020 | 044544/160635 | 0.0343 | 1.7214 |\n",
      "val: {'recall': 0.978853, 'recall_grapheme': 0.969097, 'recall_vowel': 0.989925, 'recall_consonant': 0.987291, 'acc_grapheme': 0.970526, 'acc_vowel': 0.991668, 'acc_consonant': 0.991369, 'loss_grapheme': 0.125642, 'loss_vowel': 0.054729, 'loss_consonant': 0.046928}\n",
      "    1 | 0.000019 | 146944/160635 | 0.0254 | 1.7357 |\n",
      "val: {'recall': 0.979415, 'recall_grapheme': 0.969339, 'recall_vowel': 0.989935, 'recall_consonant': 0.98905, 'acc_grapheme': 0.970551, 'acc_vowel': 0.991668, 'acc_consonant': 0.99127, 'loss_grapheme': 0.129955, 'loss_vowel': 0.062203, 'loss_consonant': 0.051282}\n",
      "    2 | 0.000017 | 089088/160635 | 4.6678 | 1.8437 |\n",
      "val: {'recall': 0.980222, 'recall_grapheme': 0.970599, 'recall_vowel': 0.99002, 'recall_consonant': 0.989671, 'acc_grapheme': 0.970775, 'acc_vowel': 0.991668, 'acc_consonant': 0.990922, 'loss_grapheme': 0.145251, 'loss_vowel': 0.073869, 'loss_consonant': 0.061182}\n",
      "** saved\n",
      "    3 | 0.000015 | 031232/160635 | 0.0189 | 1.8733 |\n",
      "val: {'recall': 0.979772, 'recall_grapheme': 0.969404, 'recall_vowel': 0.989862, 'recall_consonant': 0.990418, 'acc_grapheme': 0.970526, 'acc_vowel': 0.991792, 'acc_consonant': 0.991444, 'loss_grapheme': 0.138542, 'loss_vowel': 0.068664, 'loss_consonant': 0.056757}\n",
      "    3 | 0.000013 | 133632/160635 | 1.2337 | 1.8120 |\n",
      "val: {'recall': 0.979884, 'recall_grapheme': 0.969592, 'recall_vowel': 0.990521, 'recall_consonant': 0.989829, 'acc_grapheme': 0.970451, 'acc_vowel': 0.991717, 'acc_consonant': 0.991394, 'loss_grapheme': 0.13762, 'loss_vowel': 0.068821, 'loss_consonant': 0.056969}\n",
      "    4 | 0.000011 | 075776/160635 | 3.4430 | 1.9235 |\n",
      "val: {'recall': 0.979357, 'recall_grapheme': 0.969431, 'recall_vowel': 0.990472, 'recall_consonant': 0.988094, 'acc_grapheme': 0.970103, 'acc_vowel': 0.991742, 'acc_consonant': 0.991071, 'loss_grapheme': 0.141735, 'loss_vowel': 0.072633, 'loss_consonant': 0.059161}\n",
      "    5 | 0.000008 | 017920/160635 | 1.1211 | 1.3511 |\n",
      "val: {'recall': 0.979639, 'recall_grapheme': 0.96956, 'recall_vowel': 0.990492, 'recall_consonant': 0.988943, 'acc_grapheme': 0.970874, 'acc_vowel': 0.991792, 'acc_consonant': 0.991444, 'loss_grapheme': 0.12414, 'loss_vowel': 0.056409, 'loss_consonant': 0.047351}\n",
      "    5 | 0.000006 | 120320/160635 | 0.0391 | 1.7811 |\n",
      "val: {'recall': 0.979844, 'recall_grapheme': 0.970099, 'recall_vowel': 0.9903, 'recall_consonant': 0.988878, 'acc_grapheme': 0.970949, 'acc_vowel': 0.991792, 'acc_consonant': 0.991543, 'loss_grapheme': 0.126431, 'loss_vowel': 0.0578, 'loss_consonant': 0.049956}\n",
      "    6 | 0.000004 | 062464/160635 | 0.0186 | 1.6210 |\n",
      "val: {'recall': 0.979626, 'recall_grapheme': 0.969655, 'recall_vowel': 0.990102, 'recall_consonant': 0.989093, 'acc_grapheme': 0.9708, 'acc_vowel': 0.991842, 'acc_consonant': 0.991344, 'loss_grapheme': 0.122764, 'loss_vowel': 0.054617, 'loss_consonant': 0.047026}\n",
      "    7 | 0.000002 | 004608/160635 | 0.0139 | 0.9415 |\n",
      "val: {'recall': 0.979815, 'recall_grapheme': 0.96998, 'recall_vowel': 0.990278, 'recall_consonant': 0.98902, 'acc_grapheme': 0.970974, 'acc_vowel': 0.991767, 'acc_consonant': 0.991394, 'loss_grapheme': 0.123971, 'loss_vowel': 0.055824, 'loss_consonant': 0.047381}\n",
      "    7 | 0.000001 | 107008/160635 | 3.3147 | 1.5404 |\n",
      "val: {'recall': 0.979688, 'recall_grapheme': 0.969645, 'recall_vowel': 0.990358, 'recall_consonant': 0.989105, 'acc_grapheme': 0.970899, 'acc_vowel': 0.991842, 'acc_consonant': 0.991394, 'loss_grapheme': 0.122806, 'loss_vowel': 0.054004, 'loss_consonant': 0.046076}\n",
      "    8 | 0.000001 | 049152/160635 | 4.4008 | 1.6029 |\n",
      "val: {'recall': 0.979781, 'recall_grapheme': 0.970116, 'recall_vowel': 0.990387, 'recall_consonant': 0.988507, 'acc_grapheme': 0.970974, 'acc_vowel': 0.991892, 'acc_consonant': 0.991245, 'loss_grapheme': 0.126436, 'loss_vowel': 0.057895, 'loss_consonant': 0.048981}\n",
      "    8 | 0.000001 | 151552/160635 | 4.9208 | 1.7241 |\n",
      "val: {'recall': 0.97999, 'recall_grapheme': 0.97018, 'recall_vowel': 0.990195, 'recall_consonant': 0.989403, 'acc_grapheme': 0.971173, 'acc_vowel': 0.991643, 'acc_consonant': 0.991469, 'loss_grapheme': 0.133634, 'loss_vowel': 0.0657, 'loss_consonant': 0.054609}\n",
      "    9 | 0.000002 | 093696/160635 | 0.0359 | 1.4959 |\n",
      "val: {'recall': 0.979463, 'recall_grapheme': 0.970047, 'recall_vowel': 0.990207, 'recall_consonant': 0.987553, 'acc_grapheme': 0.971024, 'acc_vowel': 0.991792, 'acc_consonant': 0.991394, 'loss_grapheme': 0.118881, 'loss_vowel': 0.050138, 'loss_consonant': 0.04315}\n",
      "   10 | 0.000004 | 035840/160635 | 0.0270 | 1.5320 |\n",
      "val: {'recall': 0.979364, 'recall_grapheme': 0.969828, 'recall_vowel': 0.990357, 'recall_consonant': 0.987441, 'acc_grapheme': 0.970874, 'acc_vowel': 0.991767, 'acc_consonant': 0.99127, 'loss_grapheme': 0.122153, 'loss_vowel': 0.05258, 'loss_consonant': 0.044646}\n",
      "   10 | 0.000006 | 138240/160635 | 0.0167 | 1.8501 |\n",
      "val: {'recall': 0.979475, 'recall_grapheme': 0.969942, 'recall_vowel': 0.990363, 'recall_consonant': 0.987652, 'acc_grapheme': 0.970675, 'acc_vowel': 0.991693, 'acc_consonant': 0.991394, 'loss_grapheme': 0.135043, 'loss_vowel': 0.065746, 'loss_consonant': 0.054949}\n",
      "   11 | 0.000008 | 080384/160635 | 3.8484 | 1.9434 |\n",
      "val: {'recall': 0.979726, 'recall_grapheme': 0.970012, 'recall_vowel': 0.990344, 'recall_consonant': 0.988535, 'acc_grapheme': 0.970825, 'acc_vowel': 0.991717, 'acc_consonant': 0.991245, 'loss_grapheme': 0.138257, 'loss_vowel': 0.069271, 'loss_consonant': 0.057458}\n",
      "   12 | 0.000010 | 022528/160635 | 4.3213 | 1.6064 |\n",
      "val: {'recall': 0.979523, 'recall_grapheme': 0.969576, 'recall_vowel': 0.989946, 'recall_consonant': 0.988994, 'acc_grapheme': 0.970899, 'acc_vowel': 0.991593, 'acc_consonant': 0.991245, 'loss_grapheme': 0.122044, 'loss_vowel': 0.054329, 'loss_consonant': 0.045814}\n",
      "   12 | 0.000013 | 124928/160635 | 0.0529 | 1.8070 |\n",
      "val: {'recall': 0.979584, 'recall_grapheme': 0.969361, 'recall_vowel': 0.98986, 'recall_consonant': 0.989755, 'acc_grapheme': 0.970352, 'acc_vowel': 0.991444, 'acc_consonant': 0.991046, 'loss_grapheme': 0.132199, 'loss_vowel': 0.063792, 'loss_consonant': 0.052299}\n",
      "   13 | 0.000015 | 067072/160635 | 0.0137 | 1.6088 |\n",
      "val: {'recall': 0.979664, 'recall_grapheme': 0.969678, 'recall_vowel': 0.990283, 'recall_consonant': 0.989018, 'acc_grapheme': 0.97075, 'acc_vowel': 0.991668, 'acc_consonant': 0.991319, 'loss_grapheme': 0.125679, 'loss_vowel': 0.056192, 'loss_consonant': 0.047499}\n",
      "   14 | 0.000017 | 009216/160635 | 3.1461 | 2.2730 |\n",
      "val: {'recall': 0.979177, 'recall_grapheme': 0.968887, 'recall_vowel': 0.990417, 'recall_consonant': 0.988518, 'acc_grapheme': 0.970103, 'acc_vowel': 0.991593, 'acc_consonant': 0.99127, 'loss_grapheme': 0.140132, 'loss_vowel': 0.070627, 'loss_consonant': 0.057151}\n",
      "   14 | 0.000019 | 111616/160635 | 3.8132 | 1.9417 |\n",
      "val: {'recall': 0.97879, 'recall_grapheme': 0.968969, 'recall_vowel': 0.989524, 'recall_consonant': 0.987698, 'acc_grapheme': 0.970377, 'acc_vowel': 0.991469, 'acc_consonant': 0.99117, 'loss_grapheme': 0.137272, 'loss_vowel': 0.066642, 'loss_consonant': 0.056365}\n",
      "   15 | 0.000020 | 053760/160635 | 3.7255 | 1.7354 |\n",
      "val: {'recall': 0.979004, 'recall_grapheme': 0.969241, 'recall_vowel': 0.989776, 'recall_consonant': 0.987755, 'acc_grapheme': 0.970029, 'acc_vowel': 0.991792, 'acc_consonant': 0.99117, 'loss_grapheme': 0.12754, 'loss_vowel': 0.057827, 'loss_consonant': 0.049819}\n",
      "   15 | 0.000020 | 156160/160635 | 4.4883 | 1.7212 |\n",
      "val: {'recall': 0.97837, 'recall_grapheme': 0.968567, 'recall_vowel': 0.98952, 'recall_consonant': 0.986825, 'acc_grapheme': 0.969805, 'acc_vowel': 0.991767, 'acc_consonant': 0.991369, 'loss_grapheme': 0.128258, 'loss_vowel': 0.057586, 'loss_consonant': 0.05022}\n",
      "   16 | 0.000020 | 098304/160635 | 0.0269 | 1.6181 |\n",
      "val: {'recall': 0.978803, 'recall_grapheme': 0.969248, 'recall_vowel': 0.989677, 'recall_consonant': 0.987042, 'acc_grapheme': 0.970476, 'acc_vowel': 0.991568, 'acc_consonant': 0.991121, 'loss_grapheme': 0.122976, 'loss_vowel': 0.053031, 'loss_consonant': 0.046185}\n",
      "   17 | 0.000019 | 040448/160635 | 0.6447 | 1.7619 |\n",
      "val: {'recall': 0.979019, 'recall_grapheme': 0.969071, 'recall_vowel': 0.989951, 'recall_consonant': 0.987984, 'acc_grapheme': 0.970675, 'acc_vowel': 0.991742, 'acc_consonant': 0.990922, 'loss_grapheme': 0.128662, 'loss_vowel': 0.057689, 'loss_consonant': 0.049109}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 0.000017 | 142848/160635 | 0.0232 | 1.6166 |\n",
      "val: {'recall': 0.978898, 'recall_grapheme': 0.969306, 'recall_vowel': 0.988991, 'recall_consonant': 0.987989, 'acc_grapheme': 0.970501, 'acc_vowel': 0.991643, 'acc_consonant': 0.990996, 'loss_grapheme': 0.123555, 'loss_vowel': 0.050833, 'loss_consonant': 0.044785}\n",
      "   18 | 0.000015 | 084992/160635 | 1.9702 | 1.7859 |\n",
      "val: {'recall': 0.979288, 'recall_grapheme': 0.969932, 'recall_vowel': 0.990072, 'recall_consonant': 0.987215, 'acc_grapheme': 0.971073, 'acc_vowel': 0.991643, 'acc_consonant': 0.991245, 'loss_grapheme': 0.129075, 'loss_vowel': 0.061248, 'loss_consonant': 0.051546}\n",
      "   19 | 0.000013 | 027136/160635 | 4.8899 | 1.9568 |\n",
      "val: {'recall': 0.979606, 'recall_grapheme': 0.970542, 'recall_vowel': 0.989461, 'recall_consonant': 0.987878, 'acc_grapheme': 0.971372, 'acc_vowel': 0.991593, 'acc_consonant': 0.991145, 'loss_grapheme': 0.127272, 'loss_vowel': 0.05641, 'loss_consonant': 0.050583}\n",
      "   19 | 0.000011 | 129536/160635 | 3.9684 | 1.8220 |\n",
      "val: {'recall': 0.979449, 'recall_grapheme': 0.969733, 'recall_vowel': 0.989963, 'recall_consonant': 0.988365, 'acc_grapheme': 0.970725, 'acc_vowel': 0.991742, 'acc_consonant': 0.991394, 'loss_grapheme': 0.126889, 'loss_vowel': 0.057826, 'loss_consonant': 0.049491}\n",
      "   20 | 0.000008 | 071680/160635 | 3.5534 | 1.6749 |\n",
      "val: {'recall': 0.979495, 'recall_grapheme': 0.970323, 'recall_vowel': 0.989795, 'recall_consonant': 0.98754, 'acc_grapheme': 0.97075, 'acc_vowel': 0.991693, 'acc_consonant': 0.991369, 'loss_grapheme': 0.126591, 'loss_vowel': 0.056583, 'loss_consonant': 0.048715}\n",
      "   21 | 0.000006 | 013824/160635 | 0.0273 | 2.1457 |\n",
      "val: {'recall': 0.979592, 'recall_grapheme': 0.969892, 'recall_vowel': 0.990059, 'recall_consonant': 0.988524, 'acc_grapheme': 0.970825, 'acc_vowel': 0.991842, 'acc_consonant': 0.991319, 'loss_grapheme': 0.127188, 'loss_vowel': 0.059206, 'loss_consonant': 0.0496}\n",
      "   21 | 0.000004 | 116224/160635 | 0.0399 | 1.8475 |\n",
      "val: {'recall': 0.97981, 'recall_grapheme': 0.969617, 'recall_vowel': 0.990112, 'recall_consonant': 0.989893, 'acc_grapheme': 0.971198, 'acc_vowel': 0.991867, 'acc_consonant': 0.991344, 'loss_grapheme': 0.126541, 'loss_vowel': 0.057945, 'loss_consonant': 0.049194}\n",
      "   22 | 0.000002 | 058368/160635 | 0.0173 | 1.6919 |\n",
      "val: {'recall': 0.98018, 'recall_grapheme': 0.971024, 'recall_vowel': 0.990419, 'recall_consonant': 0.988253, 'acc_grapheme': 0.971372, 'acc_vowel': 0.991966, 'acc_consonant': 0.99122, 'loss_grapheme': 0.131102, 'loss_vowel': 0.063505, 'loss_consonant': 0.052434}\n",
      "   23 | 0.000001 | 000512/160635 | 4.2312 | 4.2312 |\n",
      "val: {'recall': 0.979735, 'recall_grapheme': 0.970351, 'recall_vowel': 0.990006, 'recall_consonant': 0.988231, 'acc_grapheme': 0.971272, 'acc_vowel': 0.991892, 'acc_consonant': 0.991394, 'loss_grapheme': 0.123816, 'loss_vowel': 0.056301, 'loss_consonant': 0.047775}\n",
      "   23 | 0.000001 | 102912/160635 | 0.0157 | 1.4678 |\n",
      "val: {'recall': 0.979798, 'recall_grapheme': 0.970559, 'recall_vowel': 0.990234, 'recall_consonant': 0.987841, 'acc_grapheme': 0.971521, 'acc_vowel': 0.991941, 'acc_consonant': 0.991543, 'loss_grapheme': 0.12324, 'loss_vowel': 0.055246, 'loss_consonant': 0.046753}\n",
      "   24 | 0.000001 | 045056/160635 | 4.9479 | 1.5995 |\n",
      "val: {'recall': 0.979617, 'recall_grapheme': 0.970371, 'recall_vowel': 0.990017, 'recall_consonant': 0.987709, 'acc_grapheme': 0.971496, 'acc_vowel': 0.991916, 'acc_consonant': 0.991494, 'loss_grapheme': 0.12148, 'loss_vowel': 0.053855, 'loss_consonant': 0.045696}\n",
      "   24 | 0.000002 | 147456/160635 | 4.0725 | 1.6091 |\n",
      "val: {'recall': 0.979796, 'recall_grapheme': 0.970735, 'recall_vowel': 0.99042, 'recall_consonant': 0.987295, 'acc_grapheme': 0.971322, 'acc_vowel': 0.991916, 'acc_consonant': 0.991518, 'loss_grapheme': 0.124909, 'loss_vowel': 0.057004, 'loss_consonant': 0.048109}\n",
      "   25 | 0.000004 | 089600/160635 | 0.0254 | 1.5822 |\n",
      "val: {'recall': 0.97974, 'recall_grapheme': 0.970674, 'recall_vowel': 0.99025, 'recall_consonant': 0.98736, 'acc_grapheme': 0.97162, 'acc_vowel': 0.992016, 'acc_consonant': 0.991518, 'loss_grapheme': 0.123048, 'loss_vowel': 0.055308, 'loss_consonant': 0.046889}\n",
      "   26 | 0.000006 | 031744/160635 | 4.5416 | 1.6868 |\n",
      "val: {'recall': 0.979638, 'recall_grapheme': 0.969688, 'recall_vowel': 0.990287, 'recall_consonant': 0.988889, 'acc_grapheme': 0.970999, 'acc_vowel': 0.991842, 'acc_consonant': 0.991469, 'loss_grapheme': 0.12656, 'loss_vowel': 0.058352, 'loss_consonant': 0.049602}\n",
      "   26 | 0.000008 | 134144/160635 | 0.0187 | 1.7672 |\n",
      "val: {'recall': 0.979671, 'recall_grapheme': 0.970165, 'recall_vowel': 0.99042, 'recall_consonant': 0.987934, 'acc_grapheme': 0.971347, 'acc_vowel': 0.991892, 'acc_consonant': 0.991518, 'loss_grapheme': 0.122377, 'loss_vowel': 0.054365, 'loss_consonant': 0.046428}\n",
      "   27 | 0.000010 | 076288/160635 | 2.9571 | 1.5370 |\n",
      "val: {'recall': 0.979002, 'recall_grapheme': 0.969084, 'recall_vowel': 0.98995, 'recall_consonant': 0.987888, 'acc_grapheme': 0.970974, 'acc_vowel': 0.991643, 'acc_consonant': 0.991469, 'loss_grapheme': 0.121293, 'loss_vowel': 0.052492, 'loss_consonant': 0.04577}\n",
      "   28 | 0.000013 | 018432/160635 | 0.0265 | 1.5385 |\n",
      "val: {'recall': 0.97963, 'recall_grapheme': 0.97037, 'recall_vowel': 0.990107, 'recall_consonant': 0.987673, 'acc_grapheme': 0.970924, 'acc_vowel': 0.991966, 'acc_consonant': 0.991444, 'loss_grapheme': 0.122373, 'loss_vowel': 0.05276, 'loss_consonant': 0.045485}\n",
      "   28 | 0.000015 | 120832/160635 | 4.1840 | 1.6868 |\n",
      "val: {'recall': 0.979031, 'recall_grapheme': 0.969161, 'recall_vowel': 0.989542, 'recall_consonant': 0.988261, 'acc_grapheme': 0.9708, 'acc_vowel': 0.991817, 'acc_consonant': 0.991295, 'loss_grapheme': 0.130301, 'loss_vowel': 0.06149, 'loss_consonant': 0.052002}\n",
      "   29 | 0.000017 | 062976/160635 | 3.0169 | 2.1772 |\n",
      "val: {'recall': 0.979212, 'recall_grapheme': 0.969056, 'recall_vowel': 0.989871, 'recall_consonant': 0.988865, 'acc_grapheme': 0.970899, 'acc_vowel': 0.991593, 'acc_consonant': 0.991469, 'loss_grapheme': 0.140195, 'loss_vowel': 0.074504, 'loss_consonant': 0.061384}\n",
      "   30 | 0.000019 | 005120/160635 | 4.0314 | 2.0489 |\n",
      "val: {'recall': 0.979767, 'recall_grapheme': 0.970404, 'recall_vowel': 0.989501, 'recall_consonant': 0.988758, 'acc_grapheme': 0.971745, 'acc_vowel': 0.991668, 'acc_consonant': 0.991295, 'loss_grapheme': 0.127252, 'loss_vowel': 0.059654, 'loss_consonant': 0.050544}\n",
      "   30 | 0.000020 | 107520/160635 | 0.0358 | 1.6896 |\n",
      "val: {'recall': 0.978823, 'recall_grapheme': 0.968779, 'recall_vowel': 0.98994, 'recall_consonant': 0.987796, 'acc_grapheme': 0.970874, 'acc_vowel': 0.991792, 'acc_consonant': 0.991419, 'loss_grapheme': 0.126915, 'loss_vowel': 0.056919, 'loss_consonant': 0.04874}\n",
      "   31 | 0.000020 | 049664/160635 | 4.7865 | 1.7119 |\n",
      "val: {'recall': 0.979702, 'recall_grapheme': 0.970998, 'recall_vowel': 0.989544, 'recall_consonant': 0.987266, 'acc_grapheme': 0.97075, 'acc_vowel': 0.991668, 'acc_consonant': 0.991145, 'loss_grapheme': 0.129445, 'loss_vowel': 0.060169, 'loss_consonant': 0.049863}\n",
      "   31 | 0.000020 | 152064/160635 | 3.7741 | 1.8795 |\n",
      "val: {'recall': 0.978217, 'recall_grapheme': 0.967823, 'recall_vowel': 0.989615, 'recall_consonant': 0.987607, 'acc_grapheme': 0.970427, 'acc_vowel': 0.991842, 'acc_consonant': 0.991494, 'loss_grapheme': 0.132115, 'loss_vowel': 0.06287, 'loss_consonant': 0.053111}\n",
      "   32 | 0.000019 | 094208/160635 | 4.6810 | 1.7930 |\n",
      "val: {'recall': 0.979324, 'recall_grapheme': 0.969565, 'recall_vowel': 0.989926, 'recall_consonant': 0.98824, 'acc_grapheme': 0.971247, 'acc_vowel': 0.991742, 'acc_consonant': 0.991693, 'loss_grapheme': 0.125897, 'loss_vowel': 0.056744, 'loss_consonant': 0.048915}\n",
      "   33 | 0.000017 | 036352/160635 | 0.0221 | 1.6451 |\n",
      "val: {'recall': 0.979282, 'recall_grapheme': 0.970069, 'recall_vowel': 0.989818, 'recall_consonant': 0.987174, 'acc_grapheme': 0.970849, 'acc_vowel': 0.991693, 'acc_consonant': 0.991444, 'loss_grapheme': 0.127003, 'loss_vowel': 0.058352, 'loss_consonant': 0.049513}\n",
      "   33 | 0.000015 | 138752/160635 | 0.6934 | 1.6962 |\n",
      "val: {'recall': 0.98062, 'recall_grapheme': 0.971556, 'recall_vowel': 0.990379, 'recall_consonant': 0.988988, 'acc_grapheme': 0.971919, 'acc_vowel': 0.991941, 'acc_consonant': 0.991693, 'loss_grapheme': 0.122765, 'loss_vowel': 0.054713, 'loss_consonant': 0.046667}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   34 | 0.000013 | 080896/160635 | 4.4634 | 1.6296 |\n",
      "val: {'recall': 0.979439, 'recall_grapheme': 0.969324, 'recall_vowel': 0.990212, 'recall_consonant': 0.988896, 'acc_grapheme': 0.9707, 'acc_vowel': 0.991867, 'acc_consonant': 0.991344, 'loss_grapheme': 0.127543, 'loss_vowel': 0.056723, 'loss_consonant': 0.049874}\n",
      "   35 | 0.000011 | 023040/160635 | 0.0159 | 0.8954 |\n",
      "val: {'recall': 0.980082, 'recall_grapheme': 0.970736, 'recall_vowel': 0.990228, 'recall_consonant': 0.988629, 'acc_grapheme': 0.971297, 'acc_vowel': 0.992066, 'acc_consonant': 0.991518, 'loss_grapheme': 0.118208, 'loss_vowel': 0.048186, 'loss_consonant': 0.042618}\n",
      "   35 | 0.000008 | 125440/160635 | 4.3193 | 1.5558 |\n",
      "val: {'recall': 0.98018, 'recall_grapheme': 0.97096, 'recall_vowel': 0.990596, 'recall_consonant': 0.988203, 'acc_grapheme': 0.971645, 'acc_vowel': 0.992066, 'acc_consonant': 0.991444, 'loss_grapheme': 0.120369, 'loss_vowel': 0.052064, 'loss_consonant': 0.045449}\n",
      "   36 | 0.000006 | 067584/160635 | 0.0333 | 1.6036 |\n",
      "val: {'recall': 0.980081, 'recall_grapheme': 0.970371, 'recall_vowel': 0.990515, 'recall_consonant': 0.989068, 'acc_grapheme': 0.97177, 'acc_vowel': 0.992115, 'acc_consonant': 0.991394, 'loss_grapheme': 0.11843, 'loss_vowel': 0.051489, 'loss_consonant': 0.044739}\n",
      "   37 | 0.000004 | 009728/160635 | 0.4734 | 1.6324 |\n",
      "val: {'recall': 0.979875, 'recall_grapheme': 0.97011, 'recall_vowel': 0.990389, 'recall_consonant': 0.988892, 'acc_grapheme': 0.971596, 'acc_vowel': 0.992165, 'acc_consonant': 0.991593, 'loss_grapheme': 0.118553, 'loss_vowel': 0.050712, 'loss_consonant': 0.044329}\n",
      "   37 | 0.000002 | 112128/160635 | 0.0263 | 1.6897 |\n",
      "val: {'recall': 0.98003, 'recall_grapheme': 0.970412, 'recall_vowel': 0.990552, 'recall_consonant': 0.988745, 'acc_grapheme': 0.971645, 'acc_vowel': 0.992091, 'acc_consonant': 0.991494, 'loss_grapheme': 0.122855, 'loss_vowel': 0.055181, 'loss_consonant': 0.047232}\n",
      "   38 | 0.000001 | 054272/160635 | 2.5441 | 1.6287 |\n",
      "val: {'recall': 0.980163, 'recall_grapheme': 0.97082, 'recall_vowel': 0.990762, 'recall_consonant': 0.988249, 'acc_grapheme': 0.971919, 'acc_vowel': 0.992165, 'acc_consonant': 0.991568, 'loss_grapheme': 0.123515, 'loss_vowel': 0.056183, 'loss_consonant': 0.048734}\n",
      "   38 | 0.000001 | 156672/160635 | 1.7121 | 1.6349 |\n",
      "val: {'recall': 0.979995, 'recall_grapheme': 0.970622, 'recall_vowel': 0.990543, 'recall_consonant': 0.988194, 'acc_grapheme': 0.971869, 'acc_vowel': 0.992165, 'acc_consonant': 0.991593, 'loss_grapheme': 0.1212, 'loss_vowel': 0.054282, 'loss_consonant': 0.046832}\n",
      "   39 | 0.000001 | 098816/160635 | 0.0169 | 1.7800 |\n",
      "val: {'recall': 0.98007, 'recall_grapheme': 0.970261, 'recall_vowel': 0.990773, 'recall_consonant': 0.988987, 'acc_grapheme': 0.971521, 'acc_vowel': 0.99214, 'acc_consonant': 0.991518, 'loss_grapheme': 0.126232, 'loss_vowel': 0.058916, 'loss_consonant': 0.050541}\n",
      "   40 | 0.000002 | 040960/160635 | 4.3028 | 1.6938 |\n",
      "val: {'recall': 0.980042, 'recall_grapheme': 0.970577, 'recall_vowel': 0.990457, 'recall_consonant': 0.988558, 'acc_grapheme': 0.971819, 'acc_vowel': 0.992091, 'acc_consonant': 0.991693, 'loss_grapheme': 0.121028, 'loss_vowel': 0.053842, 'loss_consonant': 0.046716}\n",
      "   40 | 0.000004 | 143360/160635 | 4.0741 | 1.8389 |\n",
      "val: {'recall': 0.979863, 'recall_grapheme': 0.970312, 'recall_vowel': 0.990463, 'recall_consonant': 0.988363, 'acc_grapheme': 0.97172, 'acc_vowel': 0.992066, 'acc_consonant': 0.991717, 'loss_grapheme': 0.12199, 'loss_vowel': 0.055237, 'loss_consonant': 0.047451}\n",
      "   41 | 0.000006 | 085504/160635 | 3.0809 | 1.5996 |\n",
      "val: {'recall': 0.97982, 'recall_grapheme': 0.969997, 'recall_vowel': 0.9903, 'recall_consonant': 0.988983, 'acc_grapheme': 0.971869, 'acc_vowel': 0.991966, 'acc_consonant': 0.991717, 'loss_grapheme': 0.12189, 'loss_vowel': 0.054399, 'loss_consonant': 0.046974}\n",
      "   42 | 0.000008 | 027648/160635 | 3.3682 | 1.9302 |\n",
      "val: {'recall': 0.979784, 'recall_grapheme': 0.97023, 'recall_vowel': 0.990005, 'recall_consonant': 0.988672, 'acc_grapheme': 0.97167, 'acc_vowel': 0.991892, 'acc_consonant': 0.991593, 'loss_grapheme': 0.122632, 'loss_vowel': 0.055339, 'loss_consonant': 0.047247}\n",
      "   42 | 0.000011 | 130048/160635 | 0.0188 | 1.6324 |\n",
      "val: {'recall': 0.979489, 'recall_grapheme': 0.970169, 'recall_vowel': 0.989886, 'recall_consonant': 0.987731, 'acc_grapheme': 0.971446, 'acc_vowel': 0.991941, 'acc_consonant': 0.991742, 'loss_grapheme': 0.119031, 'loss_vowel': 0.051233, 'loss_consonant': 0.044238}\n",
      "   43 | 0.000013 | 072192/160635 | 0.0171 | 1.5791 |\n",
      "val: {'recall': 0.979579, 'recall_grapheme': 0.970025, 'recall_vowel': 0.990256, 'recall_consonant': 0.988008, 'acc_grapheme': 0.971198, 'acc_vowel': 0.991842, 'acc_consonant': 0.991319, 'loss_grapheme': 0.121263, 'loss_vowel': 0.052937, 'loss_consonant': 0.046251}\n",
      "   44 | 0.000015 | 014336/160635 | 0.0224 | 1.4805 |\n",
      "val: {'recall': 0.978996, 'recall_grapheme': 0.969363, 'recall_vowel': 0.989654, 'recall_consonant': 0.987603, 'acc_grapheme': 0.971471, 'acc_vowel': 0.991941, 'acc_consonant': 0.991245, 'loss_grapheme': 0.120816, 'loss_vowel': 0.052447, 'loss_consonant': 0.045437}\n",
      "   44 | 0.000017 | 116736/160635 | 5.0657 | 1.7054 |\n",
      "val: {'recall': 0.980709, 'recall_grapheme': 0.97178, 'recall_vowel': 0.990091, 'recall_consonant': 0.989186, 'acc_grapheme': 0.971819, 'acc_vowel': 0.991867, 'acc_consonant': 0.991469, 'loss_grapheme': 0.122954, 'loss_vowel': 0.053827, 'loss_consonant': 0.04731}\n",
      "** saved\n",
      "   45 | 0.000019 | 058880/160635 | 2.1239 | 1.7350 |\n",
      "val: {'recall': 0.980048, 'recall_grapheme': 0.970778, 'recall_vowel': 0.989782, 'recall_consonant': 0.988853, 'acc_grapheme': 0.971695, 'acc_vowel': 0.991892, 'acc_consonant': 0.991444, 'loss_grapheme': 0.122774, 'loss_vowel': 0.056319, 'loss_consonant': 0.047933}\n",
      "   46 | 0.000020 | 001024/160635 | 4.1487 | 2.0903 |\n",
      "val: {'recall': 0.979917, 'recall_grapheme': 0.970547, 'recall_vowel': 0.990111, 'recall_consonant': 0.988462, 'acc_grapheme': 0.971819, 'acc_vowel': 0.991991, 'acc_consonant': 0.991319, 'loss_grapheme': 0.115754, 'loss_vowel': 0.048297, 'loss_consonant': 0.041204}\n",
      "   46 | 0.000020 | 103424/160635 | 0.0220 | 1.6039 |\n",
      "val: {'recall': 0.979357, 'recall_grapheme': 0.969526, 'recall_vowel': 0.989007, 'recall_consonant': 0.989367, 'acc_grapheme': 0.970974, 'acc_vowel': 0.991842, 'acc_consonant': 0.991593, 'loss_grapheme': 0.124182, 'loss_vowel': 0.052396, 'loss_consonant': 0.045638}\n",
      "   47 | 0.000020 | 045568/160635 | 0.0214 | 1.7491 |\n",
      "val: {'recall': 0.97942, 'recall_grapheme': 0.970245, 'recall_vowel': 0.990091, 'recall_consonant': 0.987098, 'acc_grapheme': 0.971397, 'acc_vowel': 0.991892, 'acc_consonant': 0.991444, 'loss_grapheme': 0.123584, 'loss_vowel': 0.05586, 'loss_consonant': 0.048263}\n",
      "   47 | 0.000019 | 147968/160635 | 3.3277 | 1.8876 |\n",
      "val: {'recall': 0.980891, 'recall_grapheme': 0.972475, 'recall_vowel': 0.989762, 'recall_consonant': 0.988853, 'acc_grapheme': 0.971969, 'acc_vowel': 0.991693, 'acc_consonant': 0.991518, 'loss_grapheme': 0.131689, 'loss_vowel': 0.065888, 'loss_consonant': 0.053452}\n",
      "** saved\n",
      "   48 | 0.000017 | 090112/160635 | 0.0326 | 1.6351 |\n",
      "val: {'recall': 0.979542, 'recall_grapheme': 0.969947, 'recall_vowel': 0.989496, 'recall_consonant': 0.988779, 'acc_grapheme': 0.971521, 'acc_vowel': 0.991767, 'acc_consonant': 0.991643, 'loss_grapheme': 0.120347, 'loss_vowel': 0.051281, 'loss_consonant': 0.045502}\n",
      "   49 | 0.000015 | 032256/160635 | 0.0207 | 1.3505 |\n",
      "val: {'recall': 0.980157, 'recall_grapheme': 0.97091, 'recall_vowel': 0.989945, 'recall_consonant': 0.988864, 'acc_grapheme': 0.971596, 'acc_vowel': 0.991916, 'acc_consonant': 0.991419, 'loss_grapheme': 0.121552, 'loss_vowel': 0.054036, 'loss_consonant': 0.047166}\n",
      "   49 | 0.000013 | 134656/160635 | 4.9117 | 1.5890 |\n",
      "val: {'recall': 0.980394, 'recall_grapheme': 0.970526, 'recall_vowel': 0.990429, 'recall_consonant': 0.990094, 'acc_grapheme': 0.971222, 'acc_vowel': 0.99219, 'acc_consonant': 0.991593, 'loss_grapheme': 0.123683, 'loss_vowel': 0.053851, 'loss_consonant': 0.047232}\n",
      "   50 | 0.000011 | 076800/160635 | 0.0241 | 1.5441 |\n",
      "val: {'recall': 0.979947, 'recall_grapheme': 0.9704, 'recall_vowel': 0.990625, 'recall_consonant': 0.988362, 'acc_grapheme': 0.971795, 'acc_vowel': 0.99219, 'acc_consonant': 0.991842, 'loss_grapheme': 0.117677, 'loss_vowel': 0.049169, 'loss_consonant': 0.042872}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 0.000008 | 018944/160635 | 4.5109 | 1.5164 |\n",
      "val: {'recall': 0.980208, 'recall_grapheme': 0.970824, 'recall_vowel': 0.990362, 'recall_consonant': 0.98882, 'acc_grapheme': 0.971869, 'acc_vowel': 0.991991, 'acc_consonant': 0.991494, 'loss_grapheme': 0.122238, 'loss_vowel': 0.056858, 'loss_consonant': 0.04733}\n",
      "   51 | 0.000006 | 121344/160635 | 4.2205 | 1.7131 |\n",
      "val: {'recall': 0.980451, 'recall_grapheme': 0.971231, 'recall_vowel': 0.990262, 'recall_consonant': 0.989078, 'acc_grapheme': 0.972018, 'acc_vowel': 0.99214, 'acc_consonant': 0.991643, 'loss_grapheme': 0.120716, 'loss_vowel': 0.054275, 'loss_consonant': 0.047123}\n",
      "   52 | 0.000004 | 063488/160635 | 0.0196 | 1.3440 |\n",
      "val: {'recall': 0.979845, 'recall_grapheme': 0.970467, 'recall_vowel': 0.990706, 'recall_consonant': 0.987741, 'acc_grapheme': 0.972193, 'acc_vowel': 0.992265, 'acc_consonant': 0.991717, 'loss_grapheme': 0.113592, 'loss_vowel': 0.046023, 'loss_consonant': 0.040173}\n",
      "   53 | 0.000002 | 005632/160635 | 4.9897 | 1.8129 |\n",
      "val: {'recall': 0.980171, 'recall_grapheme': 0.970884, 'recall_vowel': 0.990589, 'recall_consonant': 0.988329, 'acc_grapheme': 0.972267, 'acc_vowel': 0.992165, 'acc_consonant': 0.991767, 'loss_grapheme': 0.118144, 'loss_vowel': 0.051578, 'loss_consonant': 0.044091}\n",
      "   53 | 0.000001 | 108032/160635 | 0.0215 | 1.7075 |\n",
      "val: {'recall': 0.97994, 'recall_grapheme': 0.970676, 'recall_vowel': 0.990184, 'recall_consonant': 0.988226, 'acc_grapheme': 0.972143, 'acc_vowel': 0.992041, 'acc_consonant': 0.991742, 'loss_grapheme': 0.123934, 'loss_vowel': 0.057616, 'loss_consonant': 0.048987}\n",
      "   54 | 0.000001 | 050176/160635 | 0.0155 | 1.6605 |\n",
      "val: {'recall': 0.98019, 'recall_grapheme': 0.970925, 'recall_vowel': 0.990226, 'recall_consonant': 0.988683, 'acc_grapheme': 0.972292, 'acc_vowel': 0.992016, 'acc_consonant': 0.991792, 'loss_grapheme': 0.122253, 'loss_vowel': 0.05578, 'loss_consonant': 0.047512}\n",
      "   54 | 0.000001 | 152576/160635 | 3.3243 | 1.5561 |\n",
      "val: {'recall': 0.980123, 'recall_grapheme': 0.970679, 'recall_vowel': 0.990433, 'recall_consonant': 0.988702, 'acc_grapheme': 0.972242, 'acc_vowel': 0.99214, 'acc_consonant': 0.991867, 'loss_grapheme': 0.119318, 'loss_vowel': 0.051993, 'loss_consonant': 0.044844}\n",
      "   55 | 0.000002 | 094720/160635 | 3.9840 | 1.8712 |\n",
      "val: {'recall': 0.980551, 'recall_grapheme': 0.970812, 'recall_vowel': 0.990257, 'recall_consonant': 0.990322, 'acc_grapheme': 0.972118, 'acc_vowel': 0.992066, 'acc_consonant': 0.991792, 'loss_grapheme': 0.127248, 'loss_vowel': 0.061808, 'loss_consonant': 0.052437}\n",
      "   56 | 0.000004 | 036864/160635 | 0.2873 | 2.0533 |\n",
      "val: {'recall': 0.98033, 'recall_grapheme': 0.970718, 'recall_vowel': 0.990209, 'recall_consonant': 0.989677, 'acc_grapheme': 0.971994, 'acc_vowel': 0.992066, 'acc_consonant': 0.991717, 'loss_grapheme': 0.127405, 'loss_vowel': 0.062821, 'loss_consonant': 0.052268}\n",
      "   56 | 0.000006 | 139264/160635 | 4.1270 | 1.7957 |\n",
      "val: {'recall': 0.980272, 'recall_grapheme': 0.970677, 'recall_vowel': 0.990324, 'recall_consonant': 0.989409, 'acc_grapheme': 0.972516, 'acc_vowel': 0.99214, 'acc_consonant': 0.991817, 'loss_grapheme': 0.125775, 'loss_vowel': 0.059183, 'loss_consonant': 0.050095}\n",
      "   57 | 0.000008 | 081408/160635 | 0.0154 | 1.5413 |\n",
      "val: {'recall': 0.980623, 'recall_grapheme': 0.971631, 'recall_vowel': 0.990315, 'recall_consonant': 0.988917, 'acc_grapheme': 0.972143, 'acc_vowel': 0.99219, 'acc_consonant': 0.991867, 'loss_grapheme': 0.119063, 'loss_vowel': 0.052096, 'loss_consonant': 0.044523}\n",
      "   58 | 0.000011 | 023552/160635 | 0.0143 | 1.7380 |\n",
      "val: {'recall': 0.980391, 'recall_grapheme': 0.971102, 'recall_vowel': 0.990067, 'recall_consonant': 0.989291, 'acc_grapheme': 0.972292, 'acc_vowel': 0.992066, 'acc_consonant': 0.991717, 'loss_grapheme': 0.117782, 'loss_vowel': 0.050312, 'loss_consonant': 0.043441}\n",
      "   58 | 0.000013 | 125952/160635 | 0.0281 | 1.7129 |\n",
      "val: {'recall': 0.980205, 'recall_grapheme': 0.971284, 'recall_vowel': 0.989727, 'recall_consonant': 0.988527, 'acc_grapheme': 0.972217, 'acc_vowel': 0.991817, 'acc_consonant': 0.991568, 'loss_grapheme': 0.119455, 'loss_vowel': 0.053321, 'loss_consonant': 0.046184}\n",
      "   59 | 0.000015 | 068096/160635 | 0.0109 | 1.6748 |\n",
      "val: {'recall': 0.98065, 'recall_grapheme': 0.971947, 'recall_vowel': 0.989884, 'recall_consonant': 0.98882, 'acc_grapheme': 0.972267, 'acc_vowel': 0.991892, 'acc_consonant': 0.991444, 'loss_grapheme': 0.121002, 'loss_vowel': 0.052438, 'loss_consonant': 0.045165}\n",
      "   60 | 0.000017 | 010240/160635 | 4.1057 | 2.2253 |\n",
      "val: {'recall': 0.980304, 'recall_grapheme': 0.970858, 'recall_vowel': 0.990323, 'recall_consonant': 0.989176, 'acc_grapheme': 0.971944, 'acc_vowel': 0.992215, 'acc_consonant': 0.991817, 'loss_grapheme': 0.12029, 'loss_vowel': 0.053644, 'loss_consonant': 0.045378}\n",
      "   60 | 0.000019 | 112640/160635 | 0.0142 | 1.5707 |\n",
      "val: {'recall': 0.980528, 'recall_grapheme': 0.971245, 'recall_vowel': 0.990197, 'recall_consonant': 0.989426, 'acc_grapheme': 0.971894, 'acc_vowel': 0.992016, 'acc_consonant': 0.991668, 'loss_grapheme': 0.116668, 'loss_vowel': 0.04701, 'loss_consonant': 0.041084}\n",
      "   61 | 0.000020 | 054784/160635 | 0.0161 | 1.6521 |\n",
      "val: {'recall': 0.979878, 'recall_grapheme': 0.969682, 'recall_vowel': 0.990274, 'recall_consonant': 0.989874, 'acc_grapheme': 0.971919, 'acc_vowel': 0.99214, 'acc_consonant': 0.991369, 'loss_grapheme': 0.117737, 'loss_vowel': 0.050073, 'loss_consonant': 0.044479}\n",
      "   61 | 0.000020 | 157184/160635 | 0.0139 | 1.5366 |\n",
      "val: {'recall': 0.980066, 'recall_grapheme': 0.970742, 'recall_vowel': 0.990895, 'recall_consonant': 0.987885, 'acc_grapheme': 0.972118, 'acc_vowel': 0.992265, 'acc_consonant': 0.991195, 'loss_grapheme': 0.118922, 'loss_vowel': 0.050732, 'loss_consonant': 0.044123}\n",
      "   62 | 0.000020 | 099328/160635 | 0.0194 | 1.7731 |\n",
      "val: {'recall': 0.980192, 'recall_grapheme': 0.9708, 'recall_vowel': 0.990519, 'recall_consonant': 0.988649, 'acc_grapheme': 0.972118, 'acc_vowel': 0.99229, 'acc_consonant': 0.991518, 'loss_grapheme': 0.122086, 'loss_vowel': 0.054813, 'loss_consonant': 0.046867}\n",
      "   63 | 0.000019 | 041472/160635 | 0.0202 | 1.4123 |\n",
      "val: {'recall': 0.980071, 'recall_grapheme': 0.970952, 'recall_vowel': 0.990258, 'recall_consonant': 0.988121, 'acc_grapheme': 0.972416, 'acc_vowel': 0.992091, 'acc_consonant': 0.991469, 'loss_grapheme': 0.116077, 'loss_vowel': 0.047538, 'loss_consonant': 0.042345}\n",
      "   63 | 0.000017 | 143872/160635 | 4.5919 | 1.6433 |\n",
      "val: {'recall': 0.980066, 'recall_grapheme': 0.970943, 'recall_vowel': 0.989972, 'recall_consonant': 0.988407, 'acc_grapheme': 0.972267, 'acc_vowel': 0.991693, 'acc_consonant': 0.990996, 'loss_grapheme': 0.12173, 'loss_vowel': 0.055089, 'loss_consonant': 0.047461}\n",
      "   64 | 0.000015 | 086016/160635 | 1.9388 | 1.4193 |\n",
      "val: {'recall': 0.980903, 'recall_grapheme': 0.972536, 'recall_vowel': 0.990328, 'recall_consonant': 0.988213, 'acc_grapheme': 0.972914, 'acc_vowel': 0.992165, 'acc_consonant': 0.991369, 'loss_grapheme': 0.11223, 'loss_vowel': 0.04555, 'loss_consonant': 0.040123}\n",
      "** saved\n",
      "   65 | 0.000013 | 028160/160635 | 0.0191 | 2.1642 |\n",
      "val: {'recall': 0.980505, 'recall_grapheme': 0.971463, 'recall_vowel': 0.99038, 'recall_consonant': 0.988713, 'acc_grapheme': 0.972566, 'acc_vowel': 0.99214, 'acc_consonant': 0.991543, 'loss_grapheme': 0.129617, 'loss_vowel': 0.062675, 'loss_consonant': 0.053146}\n",
      "   65 | 0.000011 | 130560/160635 | 0.0185 | 1.9171 |\n",
      "val: {'recall': 0.98079, 'recall_grapheme': 0.972219, 'recall_vowel': 0.990224, 'recall_consonant': 0.9885, 'acc_grapheme': 0.973013, 'acc_vowel': 0.991991, 'acc_consonant': 0.991344, 'loss_grapheme': 0.127152, 'loss_vowel': 0.062949, 'loss_consonant': 0.054336}\n",
      "   66 | 0.000008 | 072704/160635 | 0.0162 | 1.4761 |\n",
      "val: {'recall': 0.980577, 'recall_grapheme': 0.972132, 'recall_vowel': 0.990108, 'recall_consonant': 0.987935, 'acc_grapheme': 0.973013, 'acc_vowel': 0.992265, 'acc_consonant': 0.991494, 'loss_grapheme': 0.114721, 'loss_vowel': 0.048622, 'loss_consonant': 0.042191}\n",
      "   67 | 0.000006 | 014848/160635 | 4.4494 | 2.5169 |\n",
      "val: {'recall': 0.980165, 'recall_grapheme': 0.971235, 'recall_vowel': 0.990493, 'recall_consonant': 0.987697, 'acc_grapheme': 0.97264, 'acc_vowel': 0.992339, 'acc_consonant': 0.991518, 'loss_grapheme': 0.119104, 'loss_vowel': 0.054421, 'loss_consonant': 0.046607}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 0.000004 | 117248/160635 | 2.5359 | 1.7289 |\n",
      "val: {'recall': 0.980698, 'recall_grapheme': 0.971658, 'recall_vowel': 0.990834, 'recall_consonant': 0.988643, 'acc_grapheme': 0.97274, 'acc_vowel': 0.992389, 'acc_consonant': 0.991593, 'loss_grapheme': 0.118685, 'loss_vowel': 0.052678, 'loss_consonant': 0.04529}\n",
      "   68 | 0.000002 | 059392/160635 | 3.0239 | 1.9479 |\n",
      "val: {'recall': 0.980653, 'recall_grapheme': 0.971558, 'recall_vowel': 0.990775, 'recall_consonant': 0.988722, 'acc_grapheme': 0.972765, 'acc_vowel': 0.99229, 'acc_consonant': 0.991543, 'loss_grapheme': 0.122499, 'loss_vowel': 0.057941, 'loss_consonant': 0.049276}\n",
      "   69 | 0.000001 | 001536/160635 | 0.0231 | 1.2142 |\n",
      "val: {'recall': 0.980585, 'recall_grapheme': 0.971565, 'recall_vowel': 0.990576, 'recall_consonant': 0.988634, 'acc_grapheme': 0.972939, 'acc_vowel': 0.992314, 'acc_consonant': 0.991543, 'loss_grapheme': 0.116843, 'loss_vowel': 0.051443, 'loss_consonant': 0.044679}\n",
      "   69 | 0.000001 | 103936/160635 | 1.1283 | 1.4625 |\n",
      "val: {'recall': 0.98075, 'recall_grapheme': 0.971976, 'recall_vowel': 0.990305, 'recall_consonant': 0.988741, 'acc_grapheme': 0.973237, 'acc_vowel': 0.992314, 'acc_consonant': 0.991717, 'loss_grapheme': 0.113893, 'loss_vowel': 0.048132, 'loss_consonant': 0.042203}\n",
      "   70 | 0.000001 | 046080/160635 | 1.9155 | 1.6607 |\n",
      "val: {'recall': 0.9808, 'recall_grapheme': 0.971785, 'recall_vowel': 0.99076, 'recall_consonant': 0.98887, 'acc_grapheme': 0.973113, 'acc_vowel': 0.992439, 'acc_consonant': 0.991668, 'loss_grapheme': 0.117034, 'loss_vowel': 0.051738, 'loss_consonant': 0.045279}\n",
      "   70 | 0.000002 | 148480/160635 | 0.0114 | 1.5117 |\n",
      "val: {'recall': 0.980871, 'recall_grapheme': 0.971937, 'recall_vowel': 0.990782, 'recall_consonant': 0.988828, 'acc_grapheme': 0.973237, 'acc_vowel': 0.99224, 'acc_consonant': 0.991742, 'loss_grapheme': 0.114576, 'loss_vowel': 0.048199, 'loss_consonant': 0.042422}\n",
      "   71 | 0.000004 | 090624/160635 | 0.0206 | 1.6436 |\n",
      "val: {'recall': 0.980736, 'recall_grapheme': 0.971892, 'recall_vowel': 0.990673, 'recall_consonant': 0.988486, 'acc_grapheme': 0.973088, 'acc_vowel': 0.99229, 'acc_consonant': 0.991593, 'loss_grapheme': 0.11631, 'loss_vowel': 0.050936, 'loss_consonant': 0.044013}\n",
      "   72 | 0.000006 | 032768/160635 | 0.0196 | 1.9628 |\n",
      "val: {'recall': 0.980791, 'recall_grapheme': 0.971843, 'recall_vowel': 0.990882, 'recall_consonant': 0.988594, 'acc_grapheme': 0.972765, 'acc_vowel': 0.992215, 'acc_consonant': 0.991618, 'loss_grapheme': 0.120253, 'loss_vowel': 0.055633, 'loss_consonant': 0.047675}\n",
      "   72 | 0.000008 | 135168/160635 | 0.0116 | 1.6433 |\n",
      "val: {'recall': 0.980422, 'recall_grapheme': 0.972073, 'recall_vowel': 0.990738, 'recall_consonant': 0.986803, 'acc_grapheme': 0.972765, 'acc_vowel': 0.992314, 'acc_consonant': 0.991643, 'loss_grapheme': 0.115156, 'loss_vowel': 0.049035, 'loss_consonant': 0.043117}\n",
      "   73 | 0.000010 | 077312/160635 | 2.5004 | 1.5016 |\n",
      "val: {'recall': 0.981012, 'recall_grapheme': 0.972578, 'recall_vowel': 0.989995, 'recall_consonant': 0.988895, 'acc_grapheme': 0.972665, 'acc_vowel': 0.991916, 'acc_consonant': 0.991643, 'loss_grapheme': 0.114537, 'loss_vowel': 0.047741, 'loss_consonant': 0.041666}\n",
      "** saved\n",
      "   74 | 0.000013 | 019456/160635 | 0.0163 | 1.5450 |\n",
      "val: {'recall': 0.979959, 'recall_grapheme': 0.970755, 'recall_vowel': 0.990255, 'recall_consonant': 0.988072, 'acc_grapheme': 0.972391, 'acc_vowel': 0.992041, 'acc_consonant': 0.991518, 'loss_grapheme': 0.120695, 'loss_vowel': 0.054176, 'loss_consonant': 0.046799}\n",
      "   74 | 0.000015 | 121856/160635 | 3.5099 | 1.7584 |\n",
      "val: {'recall': 0.980076, 'recall_grapheme': 0.971791, 'recall_vowel': 0.9898, 'recall_consonant': 0.986921, 'acc_grapheme': 0.972367, 'acc_vowel': 0.992041, 'acc_consonant': 0.991568, 'loss_grapheme': 0.124088, 'loss_vowel': 0.057065, 'loss_consonant': 0.049192}\n",
      "   75 | 0.000017 | 064000/160635 | 0.3559 | 1.5595 |\n",
      "val: {'recall': 0.981227, 'recall_grapheme': 0.972242, 'recall_vowel': 0.990581, 'recall_consonant': 0.989842, 'acc_grapheme': 0.972541, 'acc_vowel': 0.992265, 'acc_consonant': 0.991941, 'loss_grapheme': 0.119891, 'loss_vowel': 0.051588, 'loss_consonant': 0.04488}\n",
      "** saved\n",
      "   76 | 0.000019 | 006144/160635 | 0.0186 | 1.9860 |\n",
      "val: {'recall': 0.980651, 'recall_grapheme': 0.9716, 'recall_vowel': 0.990935, 'recall_consonant': 0.988469, 'acc_grapheme': 0.971894, 'acc_vowel': 0.991892, 'acc_consonant': 0.991817, 'loss_grapheme': 0.118779, 'loss_vowel': 0.052591, 'loss_consonant': 0.044735}\n",
      "   76 | 0.000020 | 108544/160635 | 3.6732 | 1.8416 |\n",
      "val: {'recall': 0.980408, 'recall_grapheme': 0.970927, 'recall_vowel': 0.990387, 'recall_consonant': 0.989393, 'acc_grapheme': 0.971571, 'acc_vowel': 0.991717, 'acc_consonant': 0.991867, 'loss_grapheme': 0.128612, 'loss_vowel': 0.059525, 'loss_consonant': 0.051244}\n",
      "   77 | 0.000020 | 050688/160635 | 0.0121 | 1.5546 |\n",
      "val: {'recall': 0.980382, 'recall_grapheme': 0.97143, 'recall_vowel': 0.990239, 'recall_consonant': 0.988429, 'acc_grapheme': 0.97259, 'acc_vowel': 0.992041, 'acc_consonant': 0.991494, 'loss_grapheme': 0.116547, 'loss_vowel': 0.051329, 'loss_consonant': 0.043368}\n",
      "   77 | 0.000020 | 153088/160635 | 2.1450 | 1.5315 |\n",
      "val: {'recall': 0.980589, 'recall_grapheme': 0.971323, 'recall_vowel': 0.990882, 'recall_consonant': 0.988828, 'acc_grapheme': 0.972441, 'acc_vowel': 0.99224, 'acc_consonant': 0.99127, 'loss_grapheme': 0.117329, 'loss_vowel': 0.047793, 'loss_consonant': 0.043455}\n",
      "   78 | 0.000019 | 095232/160635 | 0.0114 | 1.6146 |\n",
      "val: {'recall': 0.980281, 'recall_grapheme': 0.971836, 'recall_vowel': 0.990923, 'recall_consonant': 0.986526, 'acc_grapheme': 0.972541, 'acc_vowel': 0.992115, 'acc_consonant': 0.991494, 'loss_grapheme': 0.119097, 'loss_vowel': 0.050657, 'loss_consonant': 0.044467}\n",
      "   79 | 0.000017 | 037376/160635 | 4.6022 | 2.1138 |\n",
      "val: {'recall': 0.980205, 'recall_grapheme': 0.9712, 'recall_vowel': 0.99018, 'recall_consonant': 0.988241, 'acc_grapheme': 0.971869, 'acc_vowel': 0.992066, 'acc_consonant': 0.991295, 'loss_grapheme': 0.134433, 'loss_vowel': 0.06652, 'loss_consonant': 0.056372}\n",
      "   79 | 0.000015 | 139776/160635 | 4.6939 | 1.8049 |\n",
      "val: {'recall': 0.981025, 'recall_grapheme': 0.972811, 'recall_vowel': 0.990649, 'recall_consonant': 0.98783, 'acc_grapheme': 0.972466, 'acc_vowel': 0.992091, 'acc_consonant': 0.991419, 'loss_grapheme': 0.125017, 'loss_vowel': 0.058113, 'loss_consonant': 0.050817}\n",
      "   80 | 0.000013 | 081920/160635 | 1.3100 | 1.6067 |\n",
      "val: {'recall': 0.980618, 'recall_grapheme': 0.971071, 'recall_vowel': 0.990712, 'recall_consonant': 0.98962, 'acc_grapheme': 0.972441, 'acc_vowel': 0.991966, 'acc_consonant': 0.991742, 'loss_grapheme': 0.118485, 'loss_vowel': 0.053353, 'loss_consonant': 0.046439}\n",
      "   81 | 0.000010 | 024064/160635 | 0.0244 | 1.7588 |\n",
      "val: {'recall': 0.980761, 'recall_grapheme': 0.971579, 'recall_vowel': 0.990363, 'recall_consonant': 0.989522, 'acc_grapheme': 0.972715, 'acc_vowel': 0.99224, 'acc_consonant': 0.991568, 'loss_grapheme': 0.118685, 'loss_vowel': 0.054157, 'loss_consonant': 0.04694}\n",
      "   81 | 0.000008 | 126464/160635 | 0.0106 | 1.5171 |\n",
      "val: {'recall': 0.980778, 'recall_grapheme': 0.972084, 'recall_vowel': 0.990516, 'recall_consonant': 0.98843, 'acc_grapheme': 0.972491, 'acc_vowel': 0.992115, 'acc_consonant': 0.991842, 'loss_grapheme': 0.114914, 'loss_vowel': 0.048049, 'loss_consonant': 0.041729}\n",
      "   82 | 0.000006 | 068608/160635 | 3.8097 | 1.7774 |\n",
      "val: {'recall': 0.980361, 'recall_grapheme': 0.971711, 'recall_vowel': 0.990066, 'recall_consonant': 0.987955, 'acc_grapheme': 0.973013, 'acc_vowel': 0.99214, 'acc_consonant': 0.991817, 'loss_grapheme': 0.11982, 'loss_vowel': 0.056708, 'loss_consonant': 0.047635}\n",
      "   83 | 0.000004 | 010752/160635 | 1.3356 | 1.5357 |\n",
      "val: {'recall': 0.979938, 'recall_grapheme': 0.97106, 'recall_vowel': 0.990284, 'recall_consonant': 0.987347, 'acc_grapheme': 0.972541, 'acc_vowel': 0.992215, 'acc_consonant': 0.991867, 'loss_grapheme': 0.113579, 'loss_vowel': 0.048286, 'loss_consonant': 0.041898}\n",
      "   83 | 0.000002 | 113152/160635 | 0.0150 | 1.5479 |\n",
      "val: {'recall': 0.980806, 'recall_grapheme': 0.971533, 'recall_vowel': 0.990655, 'recall_consonant': 0.989504, 'acc_grapheme': 0.972914, 'acc_vowel': 0.992314, 'acc_consonant': 0.991941, 'loss_grapheme': 0.112364, 'loss_vowel': 0.046967, 'loss_consonant': 0.040641}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84 | 0.000001 | 055296/160635 | 3.8815 | 1.8673 |\n",
      "val: {'recall': 0.980875, 'recall_grapheme': 0.971626, 'recall_vowel': 0.990759, 'recall_consonant': 0.98949, 'acc_grapheme': 0.972789, 'acc_vowel': 0.992464, 'acc_consonant': 0.991916, 'loss_grapheme': 0.119631, 'loss_vowel': 0.055689, 'loss_consonant': 0.047219}\n",
      "   84 | 0.000001 | 157696/160635 | 0.0120 | 1.5200 |\n",
      "val: {'recall': 0.980784, 'recall_grapheme': 0.971435, 'recall_vowel': 0.990852, 'recall_consonant': 0.989412, 'acc_grapheme': 0.972814, 'acc_vowel': 0.992439, 'acc_consonant': 0.991892, 'loss_grapheme': 0.111761, 'loss_vowel': 0.04615, 'loss_consonant': 0.039822}\n",
      "   85 | 0.000001 | 099840/160635 | 3.3682 | 1.3286 |\n",
      "val: {'recall': 0.98053, 'recall_grapheme': 0.971524, 'recall_vowel': 0.990739, 'recall_consonant': 0.988332, 'acc_grapheme': 0.972864, 'acc_vowel': 0.992414, 'acc_consonant': 0.991817, 'loss_grapheme': 0.110627, 'loss_vowel': 0.044428, 'loss_consonant': 0.038691}\n",
      "   86 | 0.000002 | 041984/160635 | 4.1985 | 1.6260 |\n",
      "val: {'recall': 0.980164, 'recall_grapheme': 0.971368, 'recall_vowel': 0.990704, 'recall_consonant': 0.987215, 'acc_grapheme': 0.972765, 'acc_vowel': 0.992364, 'acc_consonant': 0.991742, 'loss_grapheme': 0.112217, 'loss_vowel': 0.046971, 'loss_consonant': 0.04079}\n",
      "   86 | 0.000004 | 144384/160635 | 0.0094 | 1.6691 |\n",
      "val: {'recall': 0.980437, 'recall_grapheme': 0.972117, 'recall_vowel': 0.990331, 'recall_consonant': 0.987185, 'acc_grapheme': 0.973187, 'acc_vowel': 0.992265, 'acc_consonant': 0.991668, 'loss_grapheme': 0.11519, 'loss_vowel': 0.050267, 'loss_consonant': 0.043004}\n",
      "   87 | 0.000006 | 086528/160635 | 0.0087 | 1.7307 |\n",
      "val: {'recall': 0.980895, 'recall_grapheme': 0.971631, 'recall_vowel': 0.990892, 'recall_consonant': 0.989426, 'acc_grapheme': 0.97269, 'acc_vowel': 0.992439, 'acc_consonant': 0.991767, 'loss_grapheme': 0.116286, 'loss_vowel': 0.050484, 'loss_consonant': 0.043605}\n",
      "   88 | 0.000008 | 028672/160635 | 0.0172 | 1.7638 |\n",
      "val: {'recall': 0.980062, 'recall_grapheme': 0.971087, 'recall_vowel': 0.990538, 'recall_consonant': 0.987538, 'acc_grapheme': 0.972665, 'acc_vowel': 0.992115, 'acc_consonant': 0.991543, 'loss_grapheme': 0.11352, 'loss_vowel': 0.047626, 'loss_consonant': 0.041239}\n",
      "   88 | 0.000010 | 131072/160635 | 2.4974 | 1.5634 |\n",
      "val: {'recall': 0.97981, 'recall_grapheme': 0.970689, 'recall_vowel': 0.990533, 'recall_consonant': 0.987331, 'acc_grapheme': 0.973088, 'acc_vowel': 0.992165, 'acc_consonant': 0.991593, 'loss_grapheme': 0.1129, 'loss_vowel': 0.0457, 'loss_consonant': 0.040194}\n",
      "   89 | 0.000013 | 073216/160635 | 0.0154 | 1.8690 |\n",
      "val: {'recall': 0.980146, 'recall_grapheme': 0.970744, 'recall_vowel': 0.991165, 'recall_consonant': 0.98793, 'acc_grapheme': 0.97274, 'acc_vowel': 0.99229, 'acc_consonant': 0.991792, 'loss_grapheme': 0.116497, 'loss_vowel': 0.052003, 'loss_consonant': 0.044589}\n",
      "   90 | 0.000015 | 015360/160635 | 4.7812 | 2.0641 |\n",
      "val: {'recall': 0.979969, 'recall_grapheme': 0.970289, 'recall_vowel': 0.990343, 'recall_consonant': 0.988955, 'acc_grapheme': 0.972342, 'acc_vowel': 0.991867, 'acc_consonant': 0.991568, 'loss_grapheme': 0.123178, 'loss_vowel': 0.058118, 'loss_consonant': 0.04923}\n",
      "   90 | 0.000017 | 117760/160635 | 2.6625 | 1.8843 |\n",
      "val: {'recall': 0.98049, 'recall_grapheme': 0.971617, 'recall_vowel': 0.990825, 'recall_consonant': 0.9879, 'acc_grapheme': 0.972715, 'acc_vowel': 0.992115, 'acc_consonant': 0.991643, 'loss_grapheme': 0.117921, 'loss_vowel': 0.05254, 'loss_consonant': 0.045448}\n",
      "   91 | 0.000019 | 059904/160635 | 0.0131 | 1.3915 |\n",
      "val: {'recall': 0.981116, 'recall_grapheme': 0.972912, 'recall_vowel': 0.991037, 'recall_consonant': 0.987603, 'acc_grapheme': 0.973262, 'acc_vowel': 0.992265, 'acc_consonant': 0.991295, 'loss_grapheme': 0.113444, 'loss_vowel': 0.046951, 'loss_consonant': 0.041742}\n",
      "   92 | 0.000020 | 002048/160635 | 0.0187 | 2.2094 |\n",
      "val: {'recall': 0.981204, 'recall_grapheme': 0.972397, 'recall_vowel': 0.990912, 'recall_consonant': 0.989111, 'acc_grapheme': 0.973212, 'acc_vowel': 0.992389, 'acc_consonant': 0.991693, 'loss_grapheme': 0.113847, 'loss_vowel': 0.048646, 'loss_consonant': 0.042861}\n",
      "   92 | 0.000020 | 104448/160635 | 3.0092 | 1.5707 |\n",
      "val: {'recall': 0.980239, 'recall_grapheme': 0.97122, 'recall_vowel': 0.990933, 'recall_consonant': 0.987584, 'acc_grapheme': 0.972118, 'acc_vowel': 0.991842, 'acc_consonant': 0.991593, 'loss_grapheme': 0.117016, 'loss_vowel': 0.050748, 'loss_consonant': 0.043534}\n",
      "   93 | 0.000020 | 046592/160635 | 0.0281 | 1.5362 |\n",
      "val: {'recall': 0.980438, 'recall_grapheme': 0.971535, 'recall_vowel': 0.990548, 'recall_consonant': 0.988131, 'acc_grapheme': 0.972143, 'acc_vowel': 0.991966, 'acc_consonant': 0.991693, 'loss_grapheme': 0.118721, 'loss_vowel': 0.048872, 'loss_consonant': 0.041921}\n",
      "   93 | 0.000019 | 148992/160635 | 0.0159 | 1.6904 |\n",
      "val: {'recall': 0.98115, 'recall_grapheme': 0.972477, 'recall_vowel': 0.990486, 'recall_consonant': 0.989158, 'acc_grapheme': 0.972143, 'acc_vowel': 0.992041, 'acc_consonant': 0.991369, 'loss_grapheme': 0.123326, 'loss_vowel': 0.054993, 'loss_consonant': 0.04729}\n",
      "   94 | 0.000017 | 091136/160635 | 1.1620 | 1.6218 |\n",
      "val: {'recall': 0.979868, 'recall_grapheme': 0.971704, 'recall_vowel': 0.989704, 'recall_consonant': 0.98636, 'acc_grapheme': 0.972665, 'acc_vowel': 0.992165, 'acc_consonant': 0.991046, 'loss_grapheme': 0.115072, 'loss_vowel': 0.050236, 'loss_consonant': 0.045909}\n",
      "   95 | 0.000015 | 033280/160635 | 4.2882 | 1.8837 |\n",
      "val: {'recall': 0.979704, 'recall_grapheme': 0.970731, 'recall_vowel': 0.990221, 'recall_consonant': 0.987135, 'acc_grapheme': 0.972939, 'acc_vowel': 0.992165, 'acc_consonant': 0.991593, 'loss_grapheme': 0.11565, 'loss_vowel': 0.051604, 'loss_consonant': 0.045184}\n",
      "   95 | 0.000013 | 135680/160635 | 3.9370 | 1.7509 |\n",
      "val: {'recall': 0.980298, 'recall_grapheme': 0.971492, 'recall_vowel': 0.99027, 'recall_consonant': 0.987939, 'acc_grapheme': 0.972839, 'acc_vowel': 0.99214, 'acc_consonant': 0.991543, 'loss_grapheme': 0.116058, 'loss_vowel': 0.052331, 'loss_consonant': 0.044932}\n",
      "   96 | 0.000010 | 077824/160635 | 0.0161 | 1.5224 |\n",
      "val: {'recall': 0.980786, 'recall_grapheme': 0.972753, 'recall_vowel': 0.99034, 'recall_consonant': 0.987299, 'acc_grapheme': 0.973386, 'acc_vowel': 0.991966, 'acc_consonant': 0.991518, 'loss_grapheme': 0.113395, 'loss_vowel': 0.047063, 'loss_consonant': 0.041816}\n",
      "   97 | 0.000008 | 019968/160635 | 0.0121 | 1.1501 |\n",
      "val: {'recall': 0.980794, 'recall_grapheme': 0.972652, 'recall_vowel': 0.989767, 'recall_consonant': 0.988105, 'acc_grapheme': 0.973386, 'acc_vowel': 0.992041, 'acc_consonant': 0.991543, 'loss_grapheme': 0.109555, 'loss_vowel': 0.044218, 'loss_consonant': 0.03848}\n",
      "   97 | 0.000006 | 122368/160635 | 3.2007 | 1.5235 |\n",
      "val: {'recall': 0.980507, 'recall_grapheme': 0.971883, 'recall_vowel': 0.990097, 'recall_consonant': 0.988166, 'acc_grapheme': 0.973038, 'acc_vowel': 0.992041, 'acc_consonant': 0.991693, 'loss_grapheme': 0.113769, 'loss_vowel': 0.047739, 'loss_consonant': 0.041571}\n",
      "   98 | 0.000004 | 064512/160635 | 0.0230 | 1.7124 |\n",
      "val: {'recall': 0.980579, 'recall_grapheme': 0.972091, 'recall_vowel': 0.989854, 'recall_consonant': 0.98828, 'acc_grapheme': 0.973386, 'acc_vowel': 0.992041, 'acc_consonant': 0.991593, 'loss_grapheme': 0.11305, 'loss_vowel': 0.048607, 'loss_consonant': 0.042425}\n",
      "   99 | 0.000002 | 006656/160635 | 0.0211 | 1.2441 |\n",
      "val: {'recall': 0.9806, 'recall_grapheme': 0.972322, 'recall_vowel': 0.990065, 'recall_consonant': 0.987692, 'acc_grapheme': 0.973585, 'acc_vowel': 0.992066, 'acc_consonant': 0.991568, 'loss_grapheme': 0.111236, 'loss_vowel': 0.046294, 'loss_consonant': 0.040593}\n",
      "   99 | 0.000001 | 109056/160635 | 0.0593 | 1.6765 |\n",
      "val: {'recall': 0.980531, 'recall_grapheme': 0.971761, 'recall_vowel': 0.990073, 'recall_consonant': 0.98853, 'acc_grapheme': 0.973362, 'acc_vowel': 0.992091, 'acc_consonant': 0.991817, 'loss_grapheme': 0.113106, 'loss_vowel': 0.048916, 'loss_consonant': 0.042676}\n",
      "  100 | 0.000001 | 051200/160635 | 0.0108 | 1.6599 |\n",
      "val: {'recall': 0.980634, 'recall_grapheme': 0.972044, 'recall_vowel': 0.989997, 'recall_consonant': 0.988451, 'acc_grapheme': 0.973411, 'acc_vowel': 0.992115, 'acc_consonant': 0.991767, 'loss_grapheme': 0.114525, 'loss_vowel': 0.050214, 'loss_consonant': 0.043677}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 | 0.000001 | 153600/160635 | 0.0179 | 1.4934 |\n",
      "val: {'recall': 0.980618, 'recall_grapheme': 0.972174, 'recall_vowel': 0.990123, 'recall_consonant': 0.988, 'acc_grapheme': 0.973362, 'acc_vowel': 0.99214, 'acc_consonant': 0.991618, 'loss_grapheme': 0.108189, 'loss_vowel': 0.042693, 'loss_consonant': 0.037559}\n",
      "  101 | 0.000002 | 095744/160635 | 3.1684 | 1.3000 |\n",
      "val: {'recall': 0.980557, 'recall_grapheme': 0.972062, 'recall_vowel': 0.990217, 'recall_consonant': 0.987885, 'acc_grapheme': 0.973362, 'acc_vowel': 0.992314, 'acc_consonant': 0.991767, 'loss_grapheme': 0.109544, 'loss_vowel': 0.043751, 'loss_consonant': 0.038437}\n",
      "  102 | 0.000004 | 037888/160635 | 0.0232 | 1.5840 |\n",
      "val: {'recall': 0.980632, 'recall_grapheme': 0.971876, 'recall_vowel': 0.990335, 'recall_consonant': 0.988439, 'acc_grapheme': 0.973337, 'acc_vowel': 0.99229, 'acc_consonant': 0.991643, 'loss_grapheme': 0.111907, 'loss_vowel': 0.047088, 'loss_consonant': 0.041137}\n",
      "  102 | 0.000006 | 140288/160635 | 0.0125 | 1.7528 |\n",
      "val: {'recall': 0.980907, 'recall_grapheme': 0.972767, 'recall_vowel': 0.990026, 'recall_consonant': 0.988068, 'acc_grapheme': 0.973386, 'acc_vowel': 0.992091, 'acc_consonant': 0.991842, 'loss_grapheme': 0.11722, 'loss_vowel': 0.053337, 'loss_consonant': 0.045628}\n",
      "  103 | 0.000008 | 082432/160635 | 4.4445 | 1.5368 |\n",
      "val: {'recall': 0.980676, 'recall_grapheme': 0.972001, 'recall_vowel': 0.990295, 'recall_consonant': 0.988409, 'acc_grapheme': 0.97361, 'acc_vowel': 0.992215, 'acc_consonant': 0.991742, 'loss_grapheme': 0.112783, 'loss_vowel': 0.04913, 'loss_consonant': 0.042052}\n",
      "  104 | 0.000010 | 024576/160635 | 4.5127 | 1.5268 |\n",
      "val: {'recall': 0.980561, 'recall_grapheme': 0.972024, 'recall_vowel': 0.99034, 'recall_consonant': 0.987857, 'acc_grapheme': 0.973262, 'acc_vowel': 0.991966, 'acc_consonant': 0.991618, 'loss_grapheme': 0.11415, 'loss_vowel': 0.049389, 'loss_consonant': 0.04245}\n",
      "  104 | 0.000013 | 126976/160635 | 4.7435 | 1.8250 |\n",
      "val: {'recall': 0.980988, 'recall_grapheme': 0.971899, 'recall_vowel': 0.990381, 'recall_consonant': 0.989773, 'acc_grapheme': 0.973038, 'acc_vowel': 0.992215, 'acc_consonant': 0.991792, 'loss_grapheme': 0.120524, 'loss_vowel': 0.056931, 'loss_consonant': 0.048318}\n",
      "  105 | 0.000015 | 069120/160635 | 0.0177 | 1.6249 |\n",
      "val: {'recall': 0.980831, 'recall_grapheme': 0.972617, 'recall_vowel': 0.989499, 'recall_consonant': 0.988589, 'acc_grapheme': 0.973088, 'acc_vowel': 0.991867, 'acc_consonant': 0.991892, 'loss_grapheme': 0.116987, 'loss_vowel': 0.051198, 'loss_consonant': 0.044199}\n",
      "  106 | 0.000017 | 011264/160635 | 0.0148 | 1.6874 |\n",
      "val: {'recall': 0.981124, 'recall_grapheme': 0.972893, 'recall_vowel': 0.990518, 'recall_consonant': 0.988194, 'acc_grapheme': 0.973486, 'acc_vowel': 0.992265, 'acc_consonant': 0.991593, 'loss_grapheme': 0.119493, 'loss_vowel': 0.052782, 'loss_consonant': 0.046055}\n",
      "  106 | 0.000019 | 113664/160635 | 1.8458 | 1.5229 |\n",
      "val: {'recall': 0.981236, 'recall_grapheme': 0.9729, 'recall_vowel': 0.99061, 'recall_consonant': 0.988535, 'acc_grapheme': 0.972964, 'acc_vowel': 0.992215, 'acc_consonant': 0.991792, 'loss_grapheme': 0.114771, 'loss_vowel': 0.047198, 'loss_consonant': 0.040839}\n",
      "** saved\n",
      "  107 | 0.000020 | 055808/160635 | 1.1528 | 1.5803 |\n",
      "val: {'recall': 0.980898, 'recall_grapheme': 0.97205, 'recall_vowel': 0.989777, 'recall_consonant': 0.989714, 'acc_grapheme': 0.973138, 'acc_vowel': 0.991892, 'acc_consonant': 0.991717, 'loss_grapheme': 0.11329, 'loss_vowel': 0.046965, 'loss_consonant': 0.04161}\n",
      "  107 | 0.000020 | 158208/160635 | 0.0126 | 1.7459 |\n",
      "val: {'recall': 0.980999, 'recall_grapheme': 0.973254, 'recall_vowel': 0.989744, 'recall_consonant': 0.987742, 'acc_grapheme': 0.973461, 'acc_vowel': 0.992165, 'acc_consonant': 0.991817, 'loss_grapheme': 0.116397, 'loss_vowel': 0.053544, 'loss_consonant': 0.045199}\n",
      "  108 | 0.000020 | 100352/160635 | 0.0233 | 1.5224 |\n",
      "val: {'recall': 0.980708, 'recall_grapheme': 0.972637, 'recall_vowel': 0.989842, 'recall_consonant': 0.987715, 'acc_grapheme': 0.972541, 'acc_vowel': 0.992016, 'acc_consonant': 0.991518, 'loss_grapheme': 0.117065, 'loss_vowel': 0.05147, 'loss_consonant': 0.043473}\n",
      "  109 | 0.000019 | 042496/160635 | 1.7919 | 1.8002 |\n",
      "val: {'recall': 0.981369, 'recall_grapheme': 0.973473, 'recall_vowel': 0.989845, 'recall_consonant': 0.988685, 'acc_grapheme': 0.973585, 'acc_vowel': 0.992115, 'acc_consonant': 0.991693, 'loss_grapheme': 0.120868, 'loss_vowel': 0.056008, 'loss_consonant': 0.047989}\n",
      "** saved\n",
      "  109 | 0.000017 | 144896/160635 | 4.3273 | 1.6110 |\n",
      "val: {'recall': 0.980523, 'recall_grapheme': 0.971565, 'recall_vowel': 0.990384, 'recall_consonant': 0.988581, 'acc_grapheme': 0.973013, 'acc_vowel': 0.992091, 'acc_consonant': 0.991717, 'loss_grapheme': 0.1141, 'loss_vowel': 0.04793, 'loss_consonant': 0.041127}\n",
      "  110 | 0.000015 | 087040/160635 | 3.9777 | 1.6365 |\n",
      "val: {'recall': 0.98064, 'recall_grapheme': 0.97251, 'recall_vowel': 0.990089, 'recall_consonant': 0.987451, 'acc_grapheme': 0.973187, 'acc_vowel': 0.992215, 'acc_consonant': 0.991842, 'loss_grapheme': 0.109499, 'loss_vowel': 0.043436, 'loss_consonant': 0.038246}\n",
      "  111 | 0.000013 | 029184/160635 | 0.0082 | 1.6838 |\n",
      "val: {'recall': 0.980322, 'recall_grapheme': 0.971045, 'recall_vowel': 0.990674, 'recall_consonant': 0.988524, 'acc_grapheme': 0.973113, 'acc_vowel': 0.992165, 'acc_consonant': 0.991693, 'loss_grapheme': 0.113265, 'loss_vowel': 0.048896, 'loss_consonant': 0.042524}\n",
      "  111 | 0.000011 | 131584/160635 | 3.0858 | 1.6658 |\n",
      "val: {'recall': 0.981038, 'recall_grapheme': 0.972534, 'recall_vowel': 0.990623, 'recall_consonant': 0.988462, 'acc_grapheme': 0.972964, 'acc_vowel': 0.992265, 'acc_consonant': 0.991842, 'loss_grapheme': 0.117721, 'loss_vowel': 0.053807, 'loss_consonant': 0.045876}\n",
      "  112 | 0.000008 | 073728/160635 | 4.9479 | 1.9616 |\n",
      "val: {'recall': 0.981077, 'recall_grapheme': 0.972587, 'recall_vowel': 0.990531, 'recall_consonant': 0.988603, 'acc_grapheme': 0.973312, 'acc_vowel': 0.99219, 'acc_consonant': 0.991792, 'loss_grapheme': 0.126696, 'loss_vowel': 0.062487, 'loss_consonant': 0.053401}\n",
      "  113 | 0.000006 | 015872/160635 | 0.0193 | 1.1314 |\n",
      "val: {'recall': 0.98114, 'recall_grapheme': 0.972612, 'recall_vowel': 0.991046, 'recall_consonant': 0.988292, 'acc_grapheme': 0.973859, 'acc_vowel': 0.992265, 'acc_consonant': 0.991966, 'loss_grapheme': 0.107417, 'loss_vowel': 0.042453, 'loss_consonant': 0.036869}\n",
      "  113 | 0.000004 | 118272/160635 | 0.0244 | 1.6918 |\n",
      "val: {'recall': 0.981184, 'recall_grapheme': 0.972884, 'recall_vowel': 0.990466, 'recall_consonant': 0.988505, 'acc_grapheme': 0.973685, 'acc_vowel': 0.99224, 'acc_consonant': 0.991892, 'loss_grapheme': 0.111782, 'loss_vowel': 0.048932, 'loss_consonant': 0.042026}\n",
      "  114 | 0.000002 | 060416/160635 | 0.0093 | 1.3944 |\n",
      "val: {'recall': 0.981021, 'recall_grapheme': 0.972362, 'recall_vowel': 0.990702, 'recall_consonant': 0.988656, 'acc_grapheme': 0.973759, 'acc_vowel': 0.992389, 'acc_consonant': 0.991842, 'loss_grapheme': 0.110776, 'loss_vowel': 0.048288, 'loss_consonant': 0.041616}\n",
      "  115 | 0.000001 | 002560/160635 | 0.0086 | 0.0122 |\n",
      "val: {'recall': 0.981163, 'recall_grapheme': 0.972544, 'recall_vowel': 0.990785, 'recall_consonant': 0.988777, 'acc_grapheme': 0.973859, 'acc_vowel': 0.992439, 'acc_consonant': 0.991991, 'loss_grapheme': 0.107576, 'loss_vowel': 0.043924, 'loss_consonant': 0.03823}\n",
      "  115 | 0.000001 | 104960/160635 | 0.0060 | 1.3759 |\n",
      "val: {'recall': 0.981171, 'recall_grapheme': 0.972728, 'recall_vowel': 0.990752, 'recall_consonant': 0.988478, 'acc_grapheme': 0.973934, 'acc_vowel': 0.992364, 'acc_consonant': 0.991867, 'loss_grapheme': 0.107738, 'loss_vowel': 0.043494, 'loss_consonant': 0.037774}\n",
      "  116 | 0.000001 | 047104/160635 | 0.0078 | 1.6678 |\n",
      "val: {'recall': 0.981484, 'recall_grapheme': 0.973215, 'recall_vowel': 0.990946, 'recall_consonant': 0.988561, 'acc_grapheme': 0.973784, 'acc_vowel': 0.992414, 'acc_consonant': 0.991966, 'loss_grapheme': 0.111849, 'loss_vowel': 0.048772, 'loss_consonant': 0.041997}\n",
      "** saved\n",
      "  116 | 0.000002 | 149504/160635 | 3.0235 | 1.6091 |\n",
      "val: {'recall': 0.981132, 'recall_grapheme': 0.972543, 'recall_vowel': 0.990882, 'recall_consonant': 0.98856, 'acc_grapheme': 0.973759, 'acc_vowel': 0.992439, 'acc_consonant': 0.991966, 'loss_grapheme': 0.110904, 'loss_vowel': 0.047965, 'loss_consonant': 0.041227}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  117 | 0.000004 | 091648/160635 | 0.0078 | 1.3309 |\n",
      "val: {'recall': 0.980901, 'recall_grapheme': 0.972229, 'recall_vowel': 0.990812, 'recall_consonant': 0.988336, 'acc_grapheme': 0.97366, 'acc_vowel': 0.992513, 'acc_consonant': 0.991767, 'loss_grapheme': 0.106444, 'loss_vowel': 0.041722, 'loss_consonant': 0.036412}\n",
      "  118 | 0.000006 | 033792/160635 | 0.0128 | 1.6388 |\n",
      "val: {'recall': 0.981212, 'recall_grapheme': 0.972761, 'recall_vowel': 0.990839, 'recall_consonant': 0.988489, 'acc_grapheme': 0.973536, 'acc_vowel': 0.992488, 'acc_consonant': 0.991817, 'loss_grapheme': 0.112221, 'loss_vowel': 0.047989, 'loss_consonant': 0.041165}\n",
      "  118 | 0.000008 | 136192/160635 | 0.0110 | 1.5780 |\n",
      "val: {'recall': 0.980909, 'recall_grapheme': 0.972353, 'recall_vowel': 0.99073, 'recall_consonant': 0.988202, 'acc_grapheme': 0.973685, 'acc_vowel': 0.992488, 'acc_consonant': 0.991916, 'loss_grapheme': 0.110169, 'loss_vowel': 0.045832, 'loss_consonant': 0.039647}\n",
      "  119 | 0.000010 | 078336/160635 | 0.6342 | 1.4478 |\n",
      "val: {'recall': 0.980666, 'recall_grapheme': 0.972309, 'recall_vowel': 0.990227, 'recall_consonant': 0.987819, 'acc_grapheme': 0.97371, 'acc_vowel': 0.992215, 'acc_consonant': 0.991717, 'loss_grapheme': 0.108503, 'loss_vowel': 0.043616, 'loss_consonant': 0.03903}\n",
      "  120 | 0.000013 | 020480/160635 | 4.0926 | 1.9492 |\n",
      "val: {'recall': 0.98106, 'recall_grapheme': 0.972933, 'recall_vowel': 0.99054, 'recall_consonant': 0.987834, 'acc_grapheme': 0.973561, 'acc_vowel': 0.992314, 'acc_consonant': 0.991717, 'loss_grapheme': 0.118745, 'loss_vowel': 0.053704, 'loss_consonant': 0.046646}\n",
      "  120 | 0.000015 | 122880/160635 | 0.0169 | 1.7349 |\n",
      "val: {'recall': 0.981683, 'recall_grapheme': 0.97393, 'recall_vowel': 0.990457, 'recall_consonant': 0.988416, 'acc_grapheme': 0.973809, 'acc_vowel': 0.99219, 'acc_consonant': 0.991693, 'loss_grapheme': 0.119676, 'loss_vowel': 0.056909, 'loss_consonant': 0.049192}\n",
      "** saved\n",
      "  121 | 0.000017 | 065024/160635 | 4.3861 | 1.9941 |\n",
      "val: {'recall': 0.980473, 'recall_grapheme': 0.971348, 'recall_vowel': 0.990521, 'recall_consonant': 0.988677, 'acc_grapheme': 0.973138, 'acc_vowel': 0.99224, 'acc_consonant': 0.991916, 'loss_grapheme': 0.126262, 'loss_vowel': 0.062714, 'loss_consonant': 0.053761}\n",
      "  122 | 0.000019 | 007168/160635 | 0.0122 | 1.6950 |\n",
      "val: {'recall': 0.98079, 'recall_grapheme': 0.971859, 'recall_vowel': 0.991104, 'recall_consonant': 0.988336, 'acc_grapheme': 0.972814, 'acc_vowel': 0.992439, 'acc_consonant': 0.991916, 'loss_grapheme': 0.116173, 'loss_vowel': 0.0513, 'loss_consonant': 0.044254}\n",
      "  122 | 0.000020 | 109568/160635 | 4.0409 | 1.5151 |\n",
      "val: {'recall': 0.980964, 'recall_grapheme': 0.972437, 'recall_vowel': 0.99049, 'recall_consonant': 0.988493, 'acc_grapheme': 0.973362, 'acc_vowel': 0.992364, 'acc_consonant': 0.991543, 'loss_grapheme': 0.114687, 'loss_vowel': 0.047783, 'loss_consonant': 0.043065}\n",
      "  123 | 0.000020 | 051712/160635 | 3.8640 | 1.5920 |\n",
      "val: {'recall': 0.981561, 'recall_grapheme': 0.973038, 'recall_vowel': 0.991172, 'recall_consonant': 0.988998, 'acc_grapheme': 0.973138, 'acc_vowel': 0.992513, 'acc_consonant': 0.991792, 'loss_grapheme': 0.117366, 'loss_vowel': 0.049868, 'loss_consonant': 0.04405}\n",
      "  123 | 0.000020 | 154112/160635 | 0.0151 | 1.6479 |\n",
      "val: {'recall': 0.980382, 'recall_grapheme': 0.970895, 'recall_vowel': 0.990929, 'recall_consonant': 0.988808, 'acc_grapheme': 0.97259, 'acc_vowel': 0.992314, 'acc_consonant': 0.991717, 'loss_grapheme': 0.112137, 'loss_vowel': 0.04599, 'loss_consonant': 0.040085}\n",
      "  124 | 0.000019 | 096256/160635 | 2.2403 | 1.6823 |\n",
      "val: {'recall': 0.981151, 'recall_grapheme': 0.972335, 'recall_vowel': 0.991218, 'recall_consonant': 0.988716, 'acc_grapheme': 0.973386, 'acc_vowel': 0.992488, 'acc_consonant': 0.991593, 'loss_grapheme': 0.114634, 'loss_vowel': 0.050547, 'loss_consonant': 0.043511}\n",
      "  125 | 0.000017 | 038400/160635 | 3.2551 | 1.9035 |\n",
      "val: {'recall': 0.981694, 'recall_grapheme': 0.97298, 'recall_vowel': 0.990614, 'recall_consonant': 0.990201, 'acc_grapheme': 0.973958, 'acc_vowel': 0.992314, 'acc_consonant': 0.992389, 'loss_grapheme': 0.115695, 'loss_vowel': 0.055197, 'loss_consonant': 0.04697}\n",
      "** saved\n",
      "  125 | 0.000015 | 140800/160635 | 3.5243 | 1.6689 |\n",
      "val: {'recall': 0.981455, 'recall_grapheme': 0.973026, 'recall_vowel': 0.990794, 'recall_consonant': 0.988972, 'acc_grapheme': 0.973511, 'acc_vowel': 0.992389, 'acc_consonant': 0.992066, 'loss_grapheme': 0.113357, 'loss_vowel': 0.049012, 'loss_consonant': 0.043237}\n",
      "  126 | 0.000013 | 082944/160635 | 0.0227 | 1.5573 |\n",
      "val: {'recall': 0.981495, 'recall_grapheme': 0.973053, 'recall_vowel': 0.9907, 'recall_consonant': 0.989176, 'acc_grapheme': 0.974157, 'acc_vowel': 0.992687, 'acc_consonant': 0.991966, 'loss_grapheme': 0.110398, 'loss_vowel': 0.045705, 'loss_consonant': 0.040196}\n",
      "  127 | 0.000011 | 025088/160635 | 0.5194 | 1.2619 |\n",
      "val: {'recall': 0.981285, 'recall_grapheme': 0.972566, 'recall_vowel': 0.990997, 'recall_consonant': 0.98901, 'acc_grapheme': 0.973461, 'acc_vowel': 0.992414, 'acc_consonant': 0.99219, 'loss_grapheme': 0.111456, 'loss_vowel': 0.046691, 'loss_consonant': 0.040318}\n",
      "  127 | 0.000008 | 127488/160635 | 0.0129 | 1.3761 |\n",
      "val: {'recall': 0.981172, 'recall_grapheme': 0.972648, 'recall_vowel': 0.990815, 'recall_consonant': 0.988575, 'acc_grapheme': 0.974033, 'acc_vowel': 0.992364, 'acc_consonant': 0.992016, 'loss_grapheme': 0.107273, 'loss_vowel': 0.042462, 'loss_consonant': 0.037345}\n",
      "  128 | 0.000006 | 069632/160635 | 0.0257 | 1.7091 |\n",
      "val: {'recall': 0.981415, 'recall_grapheme': 0.973101, 'recall_vowel': 0.990843, 'recall_consonant': 0.988614, 'acc_grapheme': 0.973759, 'acc_vowel': 0.992265, 'acc_consonant': 0.992115, 'loss_grapheme': 0.111694, 'loss_vowel': 0.048178, 'loss_consonant': 0.04156}\n",
      "  129 | 0.000004 | 011776/160635 | 3.0477 | 1.2600 |\n",
      "val: {'recall': 0.981143, 'recall_grapheme': 0.972682, 'recall_vowel': 0.990764, 'recall_consonant': 0.988445, 'acc_grapheme': 0.974506, 'acc_vowel': 0.992339, 'acc_consonant': 0.992091, 'loss_grapheme': 0.108995, 'loss_vowel': 0.045112, 'loss_consonant': 0.039321}\n",
      "  129 | 0.000002 | 114176/160635 | 0.0227 | 1.6391 |\n",
      "val: {'recall': 0.981467, 'recall_grapheme': 0.973232, 'recall_vowel': 0.990797, 'recall_consonant': 0.988606, 'acc_grapheme': 0.974257, 'acc_vowel': 0.992314, 'acc_consonant': 0.992115, 'loss_grapheme': 0.109638, 'loss_vowel': 0.046829, 'loss_consonant': 0.040742}\n",
      "  130 | 0.000001 | 056320/160635 | 0.0065 | 1.5869 |\n",
      "val: {'recall': 0.981532, 'recall_grapheme': 0.973391, 'recall_vowel': 0.990996, 'recall_consonant': 0.988352, 'acc_grapheme': 0.974133, 'acc_vowel': 0.992339, 'acc_consonant': 0.992115, 'loss_grapheme': 0.108656, 'loss_vowel': 0.045341, 'loss_consonant': 0.039883}\n",
      "  130 | 0.000001 | 158720/160635 | 3.5409 | 1.7086 |\n",
      "val: {'recall': 0.981652, 'recall_grapheme': 0.973567, 'recall_vowel': 0.990897, 'recall_consonant': 0.988578, 'acc_grapheme': 0.974207, 'acc_vowel': 0.992339, 'acc_consonant': 0.992215, 'loss_grapheme': 0.109805, 'loss_vowel': 0.047301, 'loss_consonant': 0.041504}\n",
      "  131 | 0.000001 | 100864/160635 | 2.4746 | 1.6507 |\n",
      "val: {'recall': 0.981544, 'recall_grapheme': 0.973433, 'recall_vowel': 0.990731, 'recall_consonant': 0.98858, 'acc_grapheme': 0.974332, 'acc_vowel': 0.992414, 'acc_consonant': 0.99224, 'loss_grapheme': 0.109052, 'loss_vowel': 0.046261, 'loss_consonant': 0.040537}\n",
      "  132 | 0.000002 | 043008/160635 | 0.0075 | 1.4772 |\n",
      "val: {'recall': 0.981587, 'recall_grapheme': 0.973526, 'recall_vowel': 0.990928, 'recall_consonant': 0.98837, 'acc_grapheme': 0.974282, 'acc_vowel': 0.992364, 'acc_consonant': 0.99214, 'loss_grapheme': 0.111085, 'loss_vowel': 0.048219, 'loss_consonant': 0.042322}\n",
      "  132 | 0.000004 | 145408/160635 | 0.0182 | 1.5070 |\n",
      "val: {'recall': 0.981335, 'recall_grapheme': 0.973003, 'recall_vowel': 0.990865, 'recall_consonant': 0.988471, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992364, 'acc_consonant': 0.992115, 'loss_grapheme': 0.108064, 'loss_vowel': 0.044106, 'loss_consonant': 0.038674}\n",
      "  133 | 0.000006 | 087552/160635 | 4.2806 | 1.4472 |\n",
      "val: {'recall': 0.981494, 'recall_grapheme': 0.973231, 'recall_vowel': 0.990987, 'recall_consonant': 0.988525, 'acc_grapheme': 0.974282, 'acc_vowel': 0.992439, 'acc_consonant': 0.992115, 'loss_grapheme': 0.107176, 'loss_vowel': 0.04281, 'loss_consonant': 0.037495}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  134 | 0.000008 | 029696/160635 | 2.2756 | 1.7758 |\n",
      "val: {'recall': 0.981082, 'recall_grapheme': 0.972354, 'recall_vowel': 0.991327, 'recall_consonant': 0.988292, 'acc_grapheme': 0.974182, 'acc_vowel': 0.992613, 'acc_consonant': 0.991991, 'loss_grapheme': 0.112565, 'loss_vowel': 0.049069, 'loss_consonant': 0.042238}\n",
      "  134 | 0.000011 | 132096/160635 | 3.4873 | 1.5254 |\n",
      "val: {'recall': 0.98168, 'recall_grapheme': 0.97266, 'recall_vowel': 0.991128, 'recall_consonant': 0.990275, 'acc_grapheme': 0.973735, 'acc_vowel': 0.992538, 'acc_consonant': 0.99219, 'loss_grapheme': 0.112222, 'loss_vowel': 0.048133, 'loss_consonant': 0.041725}\n",
      "  135 | 0.000013 | 074240/160635 | 2.7795 | 1.5630 |\n",
      "val: {'recall': 0.981251, 'recall_grapheme': 0.972865, 'recall_vowel': 0.990845, 'recall_consonant': 0.988428, 'acc_grapheme': 0.973934, 'acc_vowel': 0.992339, 'acc_consonant': 0.99214, 'loss_grapheme': 0.110001, 'loss_vowel': 0.045562, 'loss_consonant': 0.039639}\n",
      "  136 | 0.000015 | 016384/160635 | 0.0058 | 1.3258 |\n",
      "val: {'recall': 0.981185, 'recall_grapheme': 0.973397, 'recall_vowel': 0.990567, 'recall_consonant': 0.98738, 'acc_grapheme': 0.973809, 'acc_vowel': 0.992663, 'acc_consonant': 0.991767, 'loss_grapheme': 0.11108, 'loss_vowel': 0.045217, 'loss_consonant': 0.040395}\n",
      "  136 | 0.000017 | 118784/160635 | 3.2170 | 1.5212 |\n",
      "val: {'recall': 0.981166, 'recall_grapheme': 0.972201, 'recall_vowel': 0.990832, 'recall_consonant': 0.989427, 'acc_grapheme': 0.973212, 'acc_vowel': 0.992339, 'acc_consonant': 0.991892, 'loss_grapheme': 0.11515, 'loss_vowel': 0.049494, 'loss_consonant': 0.043984}\n",
      "  137 | 0.000019 | 060928/160635 | 0.0092 | 1.6209 |\n",
      "val: {'recall': 0.981651, 'recall_grapheme': 0.973591, 'recall_vowel': 0.990474, 'recall_consonant': 0.988949, 'acc_grapheme': 0.973934, 'acc_vowel': 0.992389, 'acc_consonant': 0.991867, 'loss_grapheme': 0.111143, 'loss_vowel': 0.047548, 'loss_consonant': 0.039952}\n",
      "  138 | 0.000020 | 003072/160635 | 0.2278 | 2.7532 |\n",
      "val: {'recall': 0.980385, 'recall_grapheme': 0.971764, 'recall_vowel': 0.990227, 'recall_consonant': 0.987785, 'acc_grapheme': 0.973461, 'acc_vowel': 0.992165, 'acc_consonant': 0.991842, 'loss_grapheme': 0.11465, 'loss_vowel': 0.050873, 'loss_consonant': 0.043456}\n",
      "  138 | 0.000020 | 105472/160635 | 0.0122 | 1.6054 |\n",
      "val: {'recall': 0.981061, 'recall_grapheme': 0.972274, 'recall_vowel': 0.990923, 'recall_consonant': 0.988775, 'acc_grapheme': 0.973834, 'acc_vowel': 0.992588, 'acc_consonant': 0.992091, 'loss_grapheme': 0.109683, 'loss_vowel': 0.046695, 'loss_consonant': 0.040158}\n",
      "  139 | 0.000020 | 047616/160635 | 0.0139 | 1.5742 |\n",
      "val: {'recall': 0.981218, 'recall_grapheme': 0.972943, 'recall_vowel': 0.990122, 'recall_consonant': 0.988867, 'acc_grapheme': 0.973287, 'acc_vowel': 0.99219, 'acc_consonant': 0.991941, 'loss_grapheme': 0.111589, 'loss_vowel': 0.045501, 'loss_consonant': 0.039527}\n",
      "  139 | 0.000019 | 150016/160635 | 3.3710 | 1.4776 |\n",
      "val: {'recall': 0.980133, 'recall_grapheme': 0.971618, 'recall_vowel': 0.990665, 'recall_consonant': 0.986631, 'acc_grapheme': 0.973287, 'acc_vowel': 0.992439, 'acc_consonant': 0.991817, 'loss_grapheme': 0.112082, 'loss_vowel': 0.043904, 'loss_consonant': 0.039225}\n",
      "  140 | 0.000017 | 092160/160635 | 3.9449 | 1.5466 |\n",
      "val: {'recall': 0.981341, 'recall_grapheme': 0.972767, 'recall_vowel': 0.991158, 'recall_consonant': 0.988672, 'acc_grapheme': 0.973859, 'acc_vowel': 0.992339, 'acc_consonant': 0.992215, 'loss_grapheme': 0.112069, 'loss_vowel': 0.047492, 'loss_consonant': 0.041346}\n",
      "  141 | 0.000015 | 034304/160635 | 0.0125 | 1.2983 |\n",
      "val: {'recall': 0.980806, 'recall_grapheme': 0.972009, 'recall_vowel': 0.990072, 'recall_consonant': 0.989132, 'acc_grapheme': 0.973163, 'acc_vowel': 0.992464, 'acc_consonant': 0.991518, 'loss_grapheme': 0.110315, 'loss_vowel': 0.045131, 'loss_consonant': 0.039633}\n",
      "  141 | 0.000013 | 136704/160635 | 0.1938 | 1.4330 |\n",
      "val: {'recall': 0.980716, 'recall_grapheme': 0.971374, 'recall_vowel': 0.990797, 'recall_consonant': 0.98932, 'acc_grapheme': 0.973511, 'acc_vowel': 0.992339, 'acc_consonant': 0.991991, 'loss_grapheme': 0.109849, 'loss_vowel': 0.044333, 'loss_consonant': 0.039602}\n",
      "  142 | 0.000011 | 078848/160635 | 0.0090 | 1.4101 |\n",
      "val: {'recall': 0.981116, 'recall_grapheme': 0.972732, 'recall_vowel': 0.990714, 'recall_consonant': 0.988285, 'acc_grapheme': 0.973909, 'acc_vowel': 0.992414, 'acc_consonant': 0.992041, 'loss_grapheme': 0.109674, 'loss_vowel': 0.044188, 'loss_consonant': 0.039061}\n",
      "  143 | 0.000008 | 020992/160635 | 4.5770 | 1.8683 |\n",
      "val: {'recall': 0.982063, 'recall_grapheme': 0.973677, 'recall_vowel': 0.991137, 'recall_consonant': 0.98976, 'acc_grapheme': 0.974332, 'acc_vowel': 0.992414, 'acc_consonant': 0.992339, 'loss_grapheme': 0.111199, 'loss_vowel': 0.046916, 'loss_consonant': 0.040738}\n",
      "** saved\n",
      "  143 | 0.000006 | 123392/160635 | 0.0109 | 1.6748 |\n",
      "val: {'recall': 0.981418, 'recall_grapheme': 0.973001, 'recall_vowel': 0.990697, 'recall_consonant': 0.988974, 'acc_grapheme': 0.973958, 'acc_vowel': 0.992314, 'acc_consonant': 0.992041, 'loss_grapheme': 0.108086, 'loss_vowel': 0.043974, 'loss_consonant': 0.038845}\n",
      "  144 | 0.000004 | 065536/160635 | 0.0080 | 1.6936 |\n",
      "val: {'recall': 0.98189, 'recall_grapheme': 0.973205, 'recall_vowel': 0.99074, 'recall_consonant': 0.99041, 'acc_grapheme': 0.974506, 'acc_vowel': 0.992364, 'acc_consonant': 0.992215, 'loss_grapheme': 0.111059, 'loss_vowel': 0.048746, 'loss_consonant': 0.042496}\n",
      "  145 | 0.000002 | 007680/160635 | 4.2320 | 1.7372 |\n",
      "val: {'recall': 0.982051, 'recall_grapheme': 0.973644, 'recall_vowel': 0.990633, 'recall_consonant': 0.990282, 'acc_grapheme': 0.974431, 'acc_vowel': 0.992339, 'acc_consonant': 0.992265, 'loss_grapheme': 0.110183, 'loss_vowel': 0.047852, 'loss_consonant': 0.041355}\n",
      "  145 | 0.000001 | 110080/160635 | 2.5972 | 1.3989 |\n",
      "val: {'recall': 0.98184, 'recall_grapheme': 0.973061, 'recall_vowel': 0.990731, 'recall_consonant': 0.990509, 'acc_grapheme': 0.974356, 'acc_vowel': 0.992314, 'acc_consonant': 0.99224, 'loss_grapheme': 0.106579, 'loss_vowel': 0.043537, 'loss_consonant': 0.037781}\n",
      "  146 | 0.000001 | 052224/160635 | 0.0048 | 1.4307 |\n",
      "val: {'recall': 0.98217, 'recall_grapheme': 0.973709, 'recall_vowel': 0.990837, 'recall_consonant': 0.990427, 'acc_grapheme': 0.974555, 'acc_vowel': 0.992339, 'acc_consonant': 0.992215, 'loss_grapheme': 0.107413, 'loss_vowel': 0.044162, 'loss_consonant': 0.038645}\n",
      "** saved\n",
      "  146 | 0.000001 | 154624/160635 | 4.1533 | 1.5883 |\n",
      "val: {'recall': 0.981809, 'recall_grapheme': 0.973376, 'recall_vowel': 0.990705, 'recall_consonant': 0.989781, 'acc_grapheme': 0.974332, 'acc_vowel': 0.99229, 'acc_consonant': 0.992215, 'loss_grapheme': 0.10957, 'loss_vowel': 0.047136, 'loss_consonant': 0.041126}\n",
      "  147 | 0.000002 | 096768/160635 | 0.0095 | 1.7148 |\n",
      "val: {'recall': 0.98157, 'recall_grapheme': 0.973734, 'recall_vowel': 0.990833, 'recall_consonant': 0.987978, 'acc_grapheme': 0.974356, 'acc_vowel': 0.992488, 'acc_consonant': 0.992165, 'loss_grapheme': 0.109569, 'loss_vowel': 0.047168, 'loss_consonant': 0.04093}\n",
      "  148 | 0.000004 | 038912/160635 | 0.0055 | 1.4205 |\n",
      "val: {'recall': 0.981388, 'recall_grapheme': 0.972963, 'recall_vowel': 0.990995, 'recall_consonant': 0.988631, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992488, 'acc_consonant': 0.99229, 'loss_grapheme': 0.105972, 'loss_vowel': 0.04169, 'loss_consonant': 0.036062}\n",
      "  148 | 0.000006 | 141312/160635 | 0.0058 | 1.5532 |\n",
      "val: {'recall': 0.981376, 'recall_grapheme': 0.973406, 'recall_vowel': 0.990712, 'recall_consonant': 0.987978, 'acc_grapheme': 0.974332, 'acc_vowel': 0.992513, 'acc_consonant': 0.991991, 'loss_grapheme': 0.108568, 'loss_vowel': 0.045485, 'loss_consonant': 0.039939}\n",
      "  149 | 0.000008 | 083456/160635 | 3.0550 | 1.6206 |\n",
      "val: {'recall': 0.981998, 'recall_grapheme': 0.974255, 'recall_vowel': 0.99092, 'recall_consonant': 0.988561, 'acc_grapheme': 0.974531, 'acc_vowel': 0.992638, 'acc_consonant': 0.99224, 'loss_grapheme': 0.108298, 'loss_vowel': 0.044493, 'loss_consonant': 0.038477}\n",
      "  150 | 0.000010 | 025600/160635 | 0.5509 | 1.3502 |\n",
      "val: {'recall': 0.981134, 'recall_grapheme': 0.972719, 'recall_vowel': 0.990649, 'recall_consonant': 0.98845, 'acc_grapheme': 0.973685, 'acc_vowel': 0.992364, 'acc_consonant': 0.992165, 'loss_grapheme': 0.108898, 'loss_vowel': 0.043411, 'loss_consonant': 0.037381}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  150 | 0.000013 | 128000/160635 | 0.0150 | 1.5541 |\n",
      "val: {'recall': 0.981937, 'recall_grapheme': 0.973063, 'recall_vowel': 0.991392, 'recall_consonant': 0.990229, 'acc_grapheme': 0.974332, 'acc_vowel': 0.992588, 'acc_consonant': 0.992165, 'loss_grapheme': 0.110053, 'loss_vowel': 0.045717, 'loss_consonant': 0.039054}\n",
      "  151 | 0.000015 | 070144/160635 | 0.0066 | 1.6842 |\n",
      "val: {'recall': 0.981275, 'recall_grapheme': 0.972765, 'recall_vowel': 0.990983, 'recall_consonant': 0.988586, 'acc_grapheme': 0.973884, 'acc_vowel': 0.992464, 'acc_consonant': 0.992265, 'loss_grapheme': 0.10977, 'loss_vowel': 0.046896, 'loss_consonant': 0.040131}\n",
      "  152 | 0.000017 | 012288/160635 | 3.6739 | 1.2945 |\n",
      "val: {'recall': 0.981226, 'recall_grapheme': 0.973124, 'recall_vowel': 0.990411, 'recall_consonant': 0.988243, 'acc_grapheme': 0.973834, 'acc_vowel': 0.992314, 'acc_consonant': 0.991916, 'loss_grapheme': 0.111941, 'loss_vowel': 0.045437, 'loss_consonant': 0.039176}\n",
      "  152 | 0.000019 | 114688/160635 | 0.0106 | 1.7403 |\n",
      "val: {'recall': 0.981534, 'recall_grapheme': 0.973002, 'recall_vowel': 0.991103, 'recall_consonant': 0.98903, 'acc_grapheme': 0.974307, 'acc_vowel': 0.992513, 'acc_consonant': 0.992314, 'loss_grapheme': 0.113221, 'loss_vowel': 0.049081, 'loss_consonant': 0.043345}\n",
      "  153 | 0.000020 | 056832/160635 | 0.0100 | 1.7043 |\n",
      "val: {'recall': 0.981386, 'recall_grapheme': 0.97361, 'recall_vowel': 0.9895, 'recall_consonant': 0.988824, 'acc_grapheme': 0.974133, 'acc_vowel': 0.99229, 'acc_consonant': 0.992115, 'loss_grapheme': 0.112582, 'loss_vowel': 0.048217, 'loss_consonant': 0.042387}\n",
      "  153 | 0.000020 | 159232/160635 | 0.0089 | 1.5894 |\n",
      "val: {'recall': 0.981528, 'recall_grapheme': 0.97306, 'recall_vowel': 0.99131, 'recall_consonant': 0.988683, 'acc_grapheme': 0.973536, 'acc_vowel': 0.992364, 'acc_consonant': 0.992215, 'loss_grapheme': 0.112977, 'loss_vowel': 0.04759, 'loss_consonant': 0.041155}\n",
      "  154 | 0.000020 | 101376/160635 | 0.0123 | 1.5631 |\n",
      "val: {'recall': 0.981231, 'recall_grapheme': 0.973529, 'recall_vowel': 0.991055, 'recall_consonant': 0.986811, 'acc_grapheme': 0.973262, 'acc_vowel': 0.99219, 'acc_consonant': 0.992215, 'loss_grapheme': 0.110995, 'loss_vowel': 0.045578, 'loss_consonant': 0.039649}\n",
      "  155 | 0.000019 | 043520/160635 | 0.0186 | 1.4426 |\n",
      "val: {'recall': 0.981028, 'recall_grapheme': 0.973264, 'recall_vowel': 0.990238, 'recall_consonant': 0.987346, 'acc_grapheme': 0.974307, 'acc_vowel': 0.992439, 'acc_consonant': 0.991991, 'loss_grapheme': 0.110878, 'loss_vowel': 0.046524, 'loss_consonant': 0.04026}\n",
      "  155 | 0.000017 | 145920/160635 | 3.4052 | 1.4913 |\n",
      "val: {'recall': 0.980945, 'recall_grapheme': 0.973065, 'recall_vowel': 0.990457, 'recall_consonant': 0.987195, 'acc_grapheme': 0.973735, 'acc_vowel': 0.992513, 'acc_consonant': 0.992364, 'loss_grapheme': 0.111447, 'loss_vowel': 0.046207, 'loss_consonant': 0.039307}\n",
      "  156 | 0.000015 | 088064/160635 | 3.4280 | 1.4991 |\n",
      "val: {'recall': 0.981708, 'recall_grapheme': 0.973471, 'recall_vowel': 0.990604, 'recall_consonant': 0.989285, 'acc_grapheme': 0.974157, 'acc_vowel': 0.992414, 'acc_consonant': 0.992041, 'loss_grapheme': 0.111226, 'loss_vowel': 0.046119, 'loss_consonant': 0.040365}\n",
      "  157 | 0.000013 | 030208/160635 | 4.5894 | 1.5943 |\n",
      "val: {'recall': 0.981563, 'recall_grapheme': 0.973008, 'recall_vowel': 0.991218, 'recall_consonant': 0.989019, 'acc_grapheme': 0.974083, 'acc_vowel': 0.992663, 'acc_consonant': 0.99214, 'loss_grapheme': 0.107952, 'loss_vowel': 0.044291, 'loss_consonant': 0.037817}\n",
      "  157 | 0.000011 | 132608/160635 | 0.0142 | 1.6593 |\n",
      "val: {'recall': 0.981917, 'recall_grapheme': 0.974097, 'recall_vowel': 0.990857, 'recall_consonant': 0.988617, 'acc_grapheme': 0.974332, 'acc_vowel': 0.992464, 'acc_consonant': 0.992364, 'loss_grapheme': 0.109173, 'loss_vowel': 0.04559, 'loss_consonant': 0.039629}\n",
      "  158 | 0.000008 | 074752/160635 | 3.0979 | 1.7128 |\n",
      "val: {'recall': 0.982232, 'recall_grapheme': 0.97433, 'recall_vowel': 0.990867, 'recall_consonant': 0.9894, 'acc_grapheme': 0.974605, 'acc_vowel': 0.992538, 'acc_consonant': 0.992389, 'loss_grapheme': 0.111794, 'loss_vowel': 0.049756, 'loss_consonant': 0.043226}\n",
      "** saved\n",
      "  159 | 0.000006 | 016896/160635 | 3.6197 | 2.0494 |\n",
      "val: {'recall': 0.981971, 'recall_grapheme': 0.973222, 'recall_vowel': 0.990969, 'recall_consonant': 0.990468, 'acc_grapheme': 0.97458, 'acc_vowel': 0.992613, 'acc_consonant': 0.992314, 'loss_grapheme': 0.110212, 'loss_vowel': 0.048279, 'loss_consonant': 0.041746}\n",
      "  159 | 0.000004 | 119296/160635 | 3.8125 | 1.5181 |\n",
      "val: {'recall': 0.981917, 'recall_grapheme': 0.973654, 'recall_vowel': 0.990873, 'recall_consonant': 0.989489, 'acc_grapheme': 0.974531, 'acc_vowel': 0.992538, 'acc_consonant': 0.99229, 'loss_grapheme': 0.105892, 'loss_vowel': 0.042134, 'loss_consonant': 0.036557}\n",
      "  160 | 0.000002 | 061440/160635 | 0.0057 | 1.4707 |\n",
      "val: {'recall': 0.981931, 'recall_grapheme': 0.973674, 'recall_vowel': 0.991043, 'recall_consonant': 0.989333, 'acc_grapheme': 0.974555, 'acc_vowel': 0.992513, 'acc_consonant': 0.992414, 'loss_grapheme': 0.106605, 'loss_vowel': 0.043181, 'loss_consonant': 0.037155}\n",
      "  161 | 0.000001 | 003584/160635 | 0.0136 | 1.4278 |\n",
      "val: {'recall': 0.98221, 'recall_grapheme': 0.97377, 'recall_vowel': 0.990929, 'recall_consonant': 0.990371, 'acc_grapheme': 0.974804, 'acc_vowel': 0.992488, 'acc_consonant': 0.992389, 'loss_grapheme': 0.112667, 'loss_vowel': 0.051214, 'loss_consonant': 0.043809}\n",
      "  161 | 0.000001 | 105984/160635 | 0.0071 | 1.6397 |\n",
      "val: {'recall': 0.982026, 'recall_grapheme': 0.973509, 'recall_vowel': 0.990674, 'recall_consonant': 0.990413, 'acc_grapheme': 0.97473, 'acc_vowel': 0.992439, 'acc_consonant': 0.992563, 'loss_grapheme': 0.108379, 'loss_vowel': 0.046676, 'loss_consonant': 0.040045}\n",
      "  162 | 0.000001 | 048128/160635 | 0.2409 | 1.5840 |\n",
      "val: {'recall': 0.982199, 'recall_grapheme': 0.974257, 'recall_vowel': 0.990845, 'recall_consonant': 0.989437, 'acc_grapheme': 0.975028, 'acc_vowel': 0.992389, 'acc_consonant': 0.992563, 'loss_grapheme': 0.109864, 'loss_vowel': 0.047964, 'loss_consonant': 0.041426}\n",
      "  162 | 0.000002 | 150528/160635 | 1.4875 | 1.6323 |\n",
      "val: {'recall': 0.981884, 'recall_grapheme': 0.973455, 'recall_vowel': 0.991161, 'recall_consonant': 0.989467, 'acc_grapheme': 0.974481, 'acc_vowel': 0.992488, 'acc_consonant': 0.992538, 'loss_grapheme': 0.11006, 'loss_vowel': 0.047829, 'loss_consonant': 0.041013}\n",
      "  163 | 0.000004 | 092672/160635 | 3.5851 | 1.5697 |\n",
      "val: {'recall': 0.981686, 'recall_grapheme': 0.973504, 'recall_vowel': 0.991001, 'recall_consonant': 0.988735, 'acc_grapheme': 0.974381, 'acc_vowel': 0.992588, 'acc_consonant': 0.992488, 'loss_grapheme': 0.109499, 'loss_vowel': 0.046711, 'loss_consonant': 0.039525}\n",
      "  164 | 0.000006 | 034816/160635 | 3.5311 | 1.5842 |\n",
      "val: {'recall': 0.981752, 'recall_grapheme': 0.973363, 'recall_vowel': 0.990968, 'recall_consonant': 0.989314, 'acc_grapheme': 0.974406, 'acc_vowel': 0.992588, 'acc_consonant': 0.992364, 'loss_grapheme': 0.107905, 'loss_vowel': 0.045609, 'loss_consonant': 0.039168}\n",
      "  164 | 0.000008 | 137216/160635 | 0.0129 | 1.6941 |\n",
      "val: {'recall': 0.981649, 'recall_grapheme': 0.973718, 'recall_vowel': 0.990391, 'recall_consonant': 0.988768, 'acc_grapheme': 0.974779, 'acc_vowel': 0.992389, 'acc_consonant': 0.992265, 'loss_grapheme': 0.109787, 'loss_vowel': 0.047173, 'loss_consonant': 0.040728}\n",
      "  165 | 0.000010 | 079360/160635 | 3.4165 | 1.5625 |\n",
      "val: {'recall': 0.981739, 'recall_grapheme': 0.973638, 'recall_vowel': 0.99114, 'recall_consonant': 0.98854, 'acc_grapheme': 0.974804, 'acc_vowel': 0.992513, 'acc_consonant': 0.992314, 'loss_grapheme': 0.107753, 'loss_vowel': 0.04432, 'loss_consonant': 0.038834}\n",
      "  166 | 0.000013 | 021504/160635 | 0.0063 | 1.4723 |\n",
      "val: {'recall': 0.981421, 'recall_grapheme': 0.973653, 'recall_vowel': 0.990792, 'recall_consonant': 0.987587, 'acc_grapheme': 0.974356, 'acc_vowel': 0.992613, 'acc_consonant': 0.992066, 'loss_grapheme': 0.107978, 'loss_vowel': 0.043898, 'loss_consonant': 0.038209}\n",
      "  166 | 0.000015 | 123904/160635 | 3.4622 | 1.4165 |\n",
      "val: {'recall': 0.981857, 'recall_grapheme': 0.974149, 'recall_vowel': 0.990672, 'recall_consonant': 0.988458, 'acc_grapheme': 0.974108, 'acc_vowel': 0.992638, 'acc_consonant': 0.992091, 'loss_grapheme': 0.108012, 'loss_vowel': 0.041872, 'loss_consonant': 0.037266}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  167 | 0.000017 | 066048/160635 | 0.0137 | 1.7025 |\n",
      "val: {'recall': 0.981609, 'recall_grapheme': 0.972657, 'recall_vowel': 0.991256, 'recall_consonant': 0.989867, 'acc_grapheme': 0.974406, 'acc_vowel': 0.992389, 'acc_consonant': 0.991892, 'loss_grapheme': 0.109996, 'loss_vowel': 0.047313, 'loss_consonant': 0.041982}\n",
      "  168 | 0.000019 | 008192/160635 | 3.8557 | 2.3393 |\n",
      "val: {'recall': 0.981583, 'recall_grapheme': 0.972423, 'recall_vowel': 0.990601, 'recall_consonant': 0.990884, 'acc_grapheme': 0.973934, 'acc_vowel': 0.992265, 'acc_consonant': 0.992041, 'loss_grapheme': 0.121634, 'loss_vowel': 0.055141, 'loss_consonant': 0.046839}\n",
      "  168 | 0.000020 | 110592/160635 | 0.0077 | 1.7213 |\n",
      "val: {'recall': 0.98183, 'recall_grapheme': 0.972978, 'recall_vowel': 0.990772, 'recall_consonant': 0.990591, 'acc_grapheme': 0.974008, 'acc_vowel': 0.992439, 'acc_consonant': 0.992016, 'loss_grapheme': 0.115241, 'loss_vowel': 0.051163, 'loss_consonant': 0.044902}\n",
      "  169 | 0.000020 | 052736/160635 | 3.3491 | 1.4197 |\n",
      "val: {'recall': 0.981412, 'recall_grapheme': 0.972647, 'recall_vowel': 0.990887, 'recall_consonant': 0.989464, 'acc_grapheme': 0.97371, 'acc_vowel': 0.992488, 'acc_consonant': 0.991916, 'loss_grapheme': 0.110329, 'loss_vowel': 0.044111, 'loss_consonant': 0.038958}\n",
      "  169 | 0.000020 | 155136/160635 | 2.1579 | 1.4607 |\n",
      "val: {'recall': 0.981532, 'recall_grapheme': 0.972647, 'recall_vowel': 0.990781, 'recall_consonant': 0.990052, 'acc_grapheme': 0.974257, 'acc_vowel': 0.992439, 'acc_consonant': 0.991792, 'loss_grapheme': 0.109483, 'loss_vowel': 0.045221, 'loss_consonant': 0.038965}\n",
      "  170 | 0.000019 | 097280/160635 | 0.0259 | 1.5848 |\n",
      "val: {'recall': 0.981697, 'recall_grapheme': 0.972567, 'recall_vowel': 0.990693, 'recall_consonant': 0.990961, 'acc_grapheme': 0.974307, 'acc_vowel': 0.99224, 'acc_consonant': 0.992165, 'loss_grapheme': 0.109978, 'loss_vowel': 0.044954, 'loss_consonant': 0.039411}\n",
      "  171 | 0.000017 | 039424/160635 | 0.0072 | 1.7349 |\n",
      "val: {'recall': 0.982019, 'recall_grapheme': 0.973631, 'recall_vowel': 0.990924, 'recall_consonant': 0.98989, 'acc_grapheme': 0.97468, 'acc_vowel': 0.992414, 'acc_consonant': 0.992115, 'loss_grapheme': 0.110849, 'loss_vowel': 0.050742, 'loss_consonant': 0.043799}\n",
      "  171 | 0.000015 | 141824/160635 | 4.7778 | 1.7027 |\n",
      "val: {'recall': 0.981875, 'recall_grapheme': 0.973894, 'recall_vowel': 0.991113, 'recall_consonant': 0.988596, 'acc_grapheme': 0.974555, 'acc_vowel': 0.992389, 'acc_consonant': 0.992041, 'loss_grapheme': 0.110911, 'loss_vowel': 0.051043, 'loss_consonant': 0.041963}\n",
      "  172 | 0.000013 | 083968/160635 | 0.0135 | 1.6800 |\n",
      "val: {'recall': 0.981959, 'recall_grapheme': 0.974208, 'recall_vowel': 0.991111, 'recall_consonant': 0.98831, 'acc_grapheme': 0.974804, 'acc_vowel': 0.992563, 'acc_consonant': 0.99214, 'loss_grapheme': 0.109477, 'loss_vowel': 0.047707, 'loss_consonant': 0.041466}\n",
      "  173 | 0.000011 | 026112/160635 | 3.6399 | 1.4340 |\n",
      "val: {'recall': 0.982165, 'recall_grapheme': 0.973428, 'recall_vowel': 0.991097, 'recall_consonant': 0.990709, 'acc_grapheme': 0.974406, 'acc_vowel': 0.992563, 'acc_consonant': 0.992339, 'loss_grapheme': 0.106835, 'loss_vowel': 0.044158, 'loss_consonant': 0.038448}\n",
      "  173 | 0.000008 | 128512/160635 | 0.0090 | 1.3449 |\n",
      "val: {'recall': 0.98227, 'recall_grapheme': 0.974813, 'recall_vowel': 0.990897, 'recall_consonant': 0.988557, 'acc_grapheme': 0.974854, 'acc_vowel': 0.992712, 'acc_consonant': 0.99224, 'loss_grapheme': 0.105742, 'loss_vowel': 0.041594, 'loss_consonant': 0.036512}\n",
      "** saved\n",
      "  174 | 0.000006 | 070656/160635 | 2.9362 | 1.7883 |\n",
      "val: {'recall': 0.982061, 'recall_grapheme': 0.974485, 'recall_vowel': 0.990693, 'recall_consonant': 0.988582, 'acc_grapheme': 0.974854, 'acc_vowel': 0.992314, 'acc_consonant': 0.992215, 'loss_grapheme': 0.10869, 'loss_vowel': 0.048554, 'loss_consonant': 0.041008}\n",
      "  175 | 0.000004 | 012800/160635 | 3.3549 | 1.7395 |\n",
      "val: {'recall': 0.982155, 'recall_grapheme': 0.97447, 'recall_vowel': 0.990764, 'recall_consonant': 0.988916, 'acc_grapheme': 0.975202, 'acc_vowel': 0.992563, 'acc_consonant': 0.99224, 'loss_grapheme': 0.105609, 'loss_vowel': 0.044402, 'loss_consonant': 0.037959}\n",
      "  175 | 0.000002 | 115200/160635 | 4.0312 | 1.4636 |\n",
      "val: {'recall': 0.982179, 'recall_grapheme': 0.974568, 'recall_vowel': 0.991029, 'recall_consonant': 0.988553, 'acc_grapheme': 0.975103, 'acc_vowel': 0.992613, 'acc_consonant': 0.992265, 'loss_grapheme': 0.105678, 'loss_vowel': 0.043887, 'loss_consonant': 0.038186}\n",
      "  176 | 0.000001 | 057344/160635 | 0.0126 | 1.5617 |\n",
      "val: {'recall': 0.981956, 'recall_grapheme': 0.974004, 'recall_vowel': 0.990963, 'recall_consonant': 0.988852, 'acc_grapheme': 0.975152, 'acc_vowel': 0.992563, 'acc_consonant': 0.992389, 'loss_grapheme': 0.10525, 'loss_vowel': 0.04375, 'loss_consonant': 0.037769}\n",
      "  176 | 0.000001 | 159744/160635 | 4.6823 | 1.4751 |\n",
      "val: {'recall': 0.9821, 'recall_grapheme': 0.974294, 'recall_vowel': 0.990971, 'recall_consonant': 0.988843, 'acc_grapheme': 0.975152, 'acc_vowel': 0.992613, 'acc_consonant': 0.992339, 'loss_grapheme': 0.104654, 'loss_vowel': 0.043173, 'loss_consonant': 0.037251}\n",
      "  177 | 0.000001 | 101888/160635 | 0.0084 | 1.4033 |\n",
      "val: {'recall': 0.981899, 'recall_grapheme': 0.973974, 'recall_vowel': 0.99094, 'recall_consonant': 0.988707, 'acc_grapheme': 0.975152, 'acc_vowel': 0.992538, 'acc_consonant': 0.992215, 'loss_grapheme': 0.104105, 'loss_vowel': 0.042277, 'loss_consonant': 0.036538}\n",
      "  178 | 0.000002 | 044032/160635 | 0.0031 | 1.5193 |\n",
      "val: {'recall': 0.982053, 'recall_grapheme': 0.974324, 'recall_vowel': 0.990834, 'recall_consonant': 0.988729, 'acc_grapheme': 0.975277, 'acc_vowel': 0.992439, 'acc_consonant': 0.992265, 'loss_grapheme': 0.10609, 'loss_vowel': 0.044649, 'loss_consonant': 0.038542}\n",
      "  178 | 0.000004 | 146432/160635 | 0.0111 | 1.5145 |\n",
      "val: {'recall': 0.982075, 'recall_grapheme': 0.974519, 'recall_vowel': 0.990573, 'recall_consonant': 0.988689, 'acc_grapheme': 0.975302, 'acc_vowel': 0.992414, 'acc_consonant': 0.992115, 'loss_grapheme': 0.105569, 'loss_vowel': 0.0449, 'loss_consonant': 0.03879}\n",
      "  179 | 0.000006 | 088576/160635 | 3.6372 | 1.3655 |\n",
      "val: {'recall': 0.982116, 'recall_grapheme': 0.973692, 'recall_vowel': 0.990956, 'recall_consonant': 0.990126, 'acc_grapheme': 0.97468, 'acc_vowel': 0.992538, 'acc_consonant': 0.99219, 'loss_grapheme': 0.103563, 'loss_vowel': 0.039263, 'loss_consonant': 0.033975}\n",
      "  180 | 0.000008 | 030720/160635 | 3.5712 | 1.8153 |\n",
      "val: {'recall': 0.98201, 'recall_grapheme': 0.974404, 'recall_vowel': 0.99087, 'recall_consonant': 0.988361, 'acc_grapheme': 0.975326, 'acc_vowel': 0.992538, 'acc_consonant': 0.992314, 'loss_grapheme': 0.105859, 'loss_vowel': 0.044341, 'loss_consonant': 0.038674}\n",
      "  180 | 0.000010 | 133120/160635 | 0.0065 | 1.7484 |\n",
      "val: {'recall': 0.982578, 'recall_grapheme': 0.974833, 'recall_vowel': 0.990695, 'recall_consonant': 0.989952, 'acc_grapheme': 0.974829, 'acc_vowel': 0.992588, 'acc_consonant': 0.99214, 'loss_grapheme': 0.111795, 'loss_vowel': 0.051206, 'loss_consonant': 0.042862}\n",
      "** saved\n",
      "  181 | 0.000013 | 075264/160635 | 4.0120 | 1.5503 |\n",
      "val: {'recall': 0.982123, 'recall_grapheme': 0.97425, 'recall_vowel': 0.990958, 'recall_consonant': 0.989034, 'acc_grapheme': 0.97473, 'acc_vowel': 0.992563, 'acc_consonant': 0.992165, 'loss_grapheme': 0.10695, 'loss_vowel': 0.045844, 'loss_consonant': 0.03935}\n",
      "  182 | 0.000015 | 017408/160635 | 4.4998 | 1.2752 |\n",
      "val: {'recall': 0.982068, 'recall_grapheme': 0.974023, 'recall_vowel': 0.991168, 'recall_consonant': 0.989056, 'acc_grapheme': 0.974506, 'acc_vowel': 0.992464, 'acc_consonant': 0.99224, 'loss_grapheme': 0.108928, 'loss_vowel': 0.046615, 'loss_consonant': 0.039634}\n",
      "  182 | 0.000017 | 119808/160635 | 0.0061 | 1.4419 |\n",
      "val: {'recall': 0.982198, 'recall_grapheme': 0.974223, 'recall_vowel': 0.990853, 'recall_consonant': 0.989492, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992588, 'acc_consonant': 0.991892, 'loss_grapheme': 0.106985, 'loss_vowel': 0.044434, 'loss_consonant': 0.038573}\n",
      "  183 | 0.000019 | 061952/160635 | 0.0080 | 1.5258 |\n",
      "val: {'recall': 0.982064, 'recall_grapheme': 0.974408, 'recall_vowel': 0.990902, 'recall_consonant': 0.988538, 'acc_grapheme': 0.97458, 'acc_vowel': 0.992414, 'acc_consonant': 0.992165, 'loss_grapheme': 0.107763, 'loss_vowel': 0.043516, 'loss_consonant': 0.037462}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  184 | 0.000020 | 004096/160635 | 0.0081 | 1.3402 |\n",
      "val: {'recall': 0.981692, 'recall_grapheme': 0.972997, 'recall_vowel': 0.990519, 'recall_consonant': 0.990257, 'acc_grapheme': 0.973486, 'acc_vowel': 0.992488, 'acc_consonant': 0.992016, 'loss_grapheme': 0.111887, 'loss_vowel': 0.045742, 'loss_consonant': 0.040582}\n",
      "  184 | 0.000020 | 106496/160635 | 0.0093 | 1.5738 |\n",
      "val: {'recall': 0.981323, 'recall_grapheme': 0.97232, 'recall_vowel': 0.991046, 'recall_consonant': 0.989604, 'acc_grapheme': 0.973436, 'acc_vowel': 0.992165, 'acc_consonant': 0.991892, 'loss_grapheme': 0.112551, 'loss_vowel': 0.048577, 'loss_consonant': 0.043324}\n",
      "  185 | 0.000020 | 048640/160635 | 0.0152 | 1.7806 |\n",
      "val: {'recall': 0.98159, 'recall_grapheme': 0.972686, 'recall_vowel': 0.990576, 'recall_consonant': 0.990413, 'acc_grapheme': 0.974257, 'acc_vowel': 0.992339, 'acc_consonant': 0.992091, 'loss_grapheme': 0.11141, 'loss_vowel': 0.0487, 'loss_consonant': 0.041596}\n",
      "  185 | 0.000019 | 151040/160635 | 4.7143 | 1.6166 |\n",
      "val: {'recall': 0.981959, 'recall_grapheme': 0.973838, 'recall_vowel': 0.990861, 'recall_consonant': 0.9893, 'acc_grapheme': 0.974182, 'acc_vowel': 0.992464, 'acc_consonant': 0.99219, 'loss_grapheme': 0.111988, 'loss_vowel': 0.047366, 'loss_consonant': 0.042161}\n",
      "  186 | 0.000017 | 093184/160635 | 3.8585 | 1.5162 |\n",
      "val: {'recall': 0.980927, 'recall_grapheme': 0.971987, 'recall_vowel': 0.990869, 'recall_consonant': 0.988864, 'acc_grapheme': 0.974232, 'acc_vowel': 0.992488, 'acc_consonant': 0.992115, 'loss_grapheme': 0.109025, 'loss_vowel': 0.044938, 'loss_consonant': 0.038909}\n",
      "  187 | 0.000015 | 035328/160635 | 2.9127 | 1.4145 |\n",
      "val: {'recall': 0.981742, 'recall_grapheme': 0.973702, 'recall_vowel': 0.990875, 'recall_consonant': 0.988688, 'acc_grapheme': 0.974531, 'acc_vowel': 0.992538, 'acc_consonant': 0.99224, 'loss_grapheme': 0.107409, 'loss_vowel': 0.04361, 'loss_consonant': 0.038246}\n",
      "  187 | 0.000013 | 137728/160635 | 0.1502 | 1.5392 |\n",
      "val: {'recall': 0.9822, 'recall_grapheme': 0.974347, 'recall_vowel': 0.991314, 'recall_consonant': 0.98879, 'acc_grapheme': 0.974829, 'acc_vowel': 0.992663, 'acc_consonant': 0.992265, 'loss_grapheme': 0.107847, 'loss_vowel': 0.046686, 'loss_consonant': 0.040219}\n",
      "  188 | 0.000010 | 079872/160635 | 4.2663 | 1.6351 |\n",
      "val: {'recall': 0.981947, 'recall_grapheme': 0.974009, 'recall_vowel': 0.991183, 'recall_consonant': 0.988585, 'acc_grapheme': 0.975227, 'acc_vowel': 0.992563, 'acc_consonant': 0.99219, 'loss_grapheme': 0.104564, 'loss_vowel': 0.04411, 'loss_consonant': 0.038245}\n",
      "  189 | 0.000008 | 022016/160635 | 0.0079 | 1.5265 |\n",
      "val: {'recall': 0.981764, 'recall_grapheme': 0.973168, 'recall_vowel': 0.991301, 'recall_consonant': 0.989419, 'acc_grapheme': 0.974829, 'acc_vowel': 0.992638, 'acc_consonant': 0.99214, 'loss_grapheme': 0.105322, 'loss_vowel': 0.044653, 'loss_consonant': 0.038706}\n",
      "  189 | 0.000006 | 124416/160635 | 0.0067 | 1.5181 |\n",
      "val: {'recall': 0.982172, 'recall_grapheme': 0.974407, 'recall_vowel': 0.991246, 'recall_consonant': 0.988628, 'acc_grapheme': 0.975152, 'acc_vowel': 0.992712, 'acc_consonant': 0.992215, 'loss_grapheme': 0.104603, 'loss_vowel': 0.043954, 'loss_consonant': 0.038134}\n",
      "  190 | 0.000004 | 066560/160635 | 1.6974 | 1.3418 |\n",
      "val: {'recall': 0.9822, 'recall_grapheme': 0.974326, 'recall_vowel': 0.991476, 'recall_consonant': 0.988672, 'acc_grapheme': 0.975302, 'acc_vowel': 0.992687, 'acc_consonant': 0.99214, 'loss_grapheme': 0.102888, 'loss_vowel': 0.041464, 'loss_consonant': 0.035887}\n",
      "  191 | 0.000002 | 008704/160635 | 0.0050 | 1.3042 |\n",
      "val: {'recall': 0.982188, 'recall_grapheme': 0.974239, 'recall_vowel': 0.991673, 'recall_consonant': 0.988602, 'acc_grapheme': 0.975252, 'acc_vowel': 0.992862, 'acc_consonant': 0.99214, 'loss_grapheme': 0.104714, 'loss_vowel': 0.044855, 'loss_consonant': 0.038549}\n",
      "  191 | 0.000001 | 111104/160635 | 2.6540 | 1.4665 |\n",
      "val: {'recall': 0.982612, 'recall_grapheme': 0.974633, 'recall_vowel': 0.991465, 'recall_consonant': 0.989716, 'acc_grapheme': 0.97555, 'acc_vowel': 0.992862, 'acc_consonant': 0.992165, 'loss_grapheme': 0.102137, 'loss_vowel': 0.040935, 'loss_consonant': 0.035634}\n",
      "** saved\n",
      "  192 | 0.000001 | 053248/160635 | 3.5302 | 2.0528 |\n",
      "val: {'recall': 0.982512, 'recall_grapheme': 0.974398, 'recall_vowel': 0.991418, 'recall_consonant': 0.989834, 'acc_grapheme': 0.975177, 'acc_vowel': 0.992886, 'acc_consonant': 0.992265, 'loss_grapheme': 0.111773, 'loss_vowel': 0.054026, 'loss_consonant': 0.046036}\n",
      "  192 | 0.000001 | 155648/160635 | 3.3237 | 1.7729 |\n",
      "val: {'recall': 0.982474, 'recall_grapheme': 0.974333, 'recall_vowel': 0.991476, 'recall_consonant': 0.989755, 'acc_grapheme': 0.975326, 'acc_vowel': 0.992837, 'acc_consonant': 0.992265, 'loss_grapheme': 0.104346, 'loss_vowel': 0.044525, 'loss_consonant': 0.038414}\n",
      "  193 | 0.000002 | 097792/160635 | 0.0056 | 1.3513 |\n",
      "val: {'recall': 0.98264, 'recall_grapheme': 0.974593, 'recall_vowel': 0.991547, 'recall_consonant': 0.989826, 'acc_grapheme': 0.975451, 'acc_vowel': 0.992837, 'acc_consonant': 0.992314, 'loss_grapheme': 0.103109, 'loss_vowel': 0.041692, 'loss_consonant': 0.035985}\n",
      "** saved\n",
      "  194 | 0.000004 | 039936/160635 | 0.0354 | 1.5387 |\n",
      "val: {'recall': 0.982177, 'recall_grapheme': 0.974337, 'recall_vowel': 0.991567, 'recall_consonant': 0.988465, 'acc_grapheme': 0.975003, 'acc_vowel': 0.992787, 'acc_consonant': 0.99224, 'loss_grapheme': 0.105363, 'loss_vowel': 0.043895, 'loss_consonant': 0.037606}\n",
      "  194 | 0.000006 | 142336/160635 | 0.0069 | 1.5544 |\n",
      "val: {'recall': 0.982028, 'recall_grapheme': 0.974184, 'recall_vowel': 0.991147, 'recall_consonant': 0.988597, 'acc_grapheme': 0.975326, 'acc_vowel': 0.992936, 'acc_consonant': 0.992165, 'loss_grapheme': 0.10406, 'loss_vowel': 0.043879, 'loss_consonant': 0.038169}\n",
      "  195 | 0.000008 | 084480/160635 | 0.0165 | 1.6490 |\n",
      "val: {'recall': 0.982838, 'recall_grapheme': 0.974898, 'recall_vowel': 0.991879, 'recall_consonant': 0.989677, 'acc_grapheme': 0.975426, 'acc_vowel': 0.992911, 'acc_consonant': 0.992314, 'loss_grapheme': 0.106818, 'loss_vowel': 0.04691, 'loss_consonant': 0.040788}\n",
      "** saved\n",
      "  196 | 0.000010 | 026624/160635 | 0.0057 | 1.4430 |\n",
      "val: {'recall': 0.982164, 'recall_grapheme': 0.973832, 'recall_vowel': 0.991602, 'recall_consonant': 0.989391, 'acc_grapheme': 0.97473, 'acc_vowel': 0.992687, 'acc_consonant': 0.992339, 'loss_grapheme': 0.1083, 'loss_vowel': 0.044188, 'loss_consonant': 0.037954}\n",
      "  196 | 0.000013 | 129024/160635 | 0.9273 | 1.4404 |\n",
      "val: {'recall': 0.981439, 'recall_grapheme': 0.973002, 'recall_vowel': 0.990853, 'recall_consonant': 0.988898, 'acc_grapheme': 0.974506, 'acc_vowel': 0.992787, 'acc_consonant': 0.992588, 'loss_grapheme': 0.106905, 'loss_vowel': 0.044091, 'loss_consonant': 0.037445}\n",
      "  197 | 0.000015 | 071168/160635 | 0.0129 | 1.4507 |\n",
      "val: {'recall': 0.982011, 'recall_grapheme': 0.974578, 'recall_vowel': 0.991227, 'recall_consonant': 0.987662, 'acc_grapheme': 0.974779, 'acc_vowel': 0.992886, 'acc_consonant': 0.99224, 'loss_grapheme': 0.105903, 'loss_vowel': 0.042052, 'loss_consonant': 0.036268}\n",
      "  198 | 0.000017 | 013312/160635 | 0.0133 | 1.9276 |\n",
      "val: {'recall': 0.981734, 'recall_grapheme': 0.973917, 'recall_vowel': 0.990845, 'recall_consonant': 0.988258, 'acc_grapheme': 0.974406, 'acc_vowel': 0.992638, 'acc_consonant': 0.992215, 'loss_grapheme': 0.106356, 'loss_vowel': 0.042573, 'loss_consonant': 0.036723}\n",
      "  198 | 0.000019 | 115712/160635 | 0.0106 | 1.3923 |\n",
      "val: {'recall': 0.981231, 'recall_grapheme': 0.973458, 'recall_vowel': 0.990911, 'recall_consonant': 0.987097, 'acc_grapheme': 0.975028, 'acc_vowel': 0.99224, 'acc_consonant': 0.992091, 'loss_grapheme': 0.104438, 'loss_vowel': 0.040738, 'loss_consonant': 0.035081}\n",
      "  199 | 0.000020 | 057856/160635 | 0.0060 | 1.7553 |\n",
      "val: {'recall': 0.982359, 'recall_grapheme': 0.974906, 'recall_vowel': 0.990954, 'recall_consonant': 0.98867, 'acc_grapheme': 0.975401, 'acc_vowel': 0.992663, 'acc_consonant': 0.992339, 'loss_grapheme': 0.106372, 'loss_vowel': 0.044674, 'loss_consonant': 0.039568}\n",
      "  199 | 0.000020 | 160256/160635 | 2.5080 | 1.6909 |\n",
      "val: {'recall': 0.981017, 'recall_grapheme': 0.972292, 'recall_vowel': 0.990531, 'recall_consonant': 0.988955, 'acc_grapheme': 0.974356, 'acc_vowel': 0.992538, 'acc_consonant': 0.99229, 'loss_grapheme': 0.107217, 'loss_vowel': 0.046883, 'loss_consonant': 0.040636}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200 | 0.000020 | 102400/160635 | 0.0191 | 1.3510 |\n",
      "val: {'recall': 0.982598, 'recall_grapheme': 0.975037, 'recall_vowel': 0.991331, 'recall_consonant': 0.988989, 'acc_grapheme': 0.975376, 'acc_vowel': 0.992687, 'acc_consonant': 0.992265, 'loss_grapheme': 0.10434, 'loss_vowel': 0.039555, 'loss_consonant': 0.035841}\n",
      "  201 | 0.000019 | 044544/160635 | 0.0260 | 1.7899 |\n",
      "val: {'recall': 0.981514, 'recall_grapheme': 0.973313, 'recall_vowel': 0.990558, 'recall_consonant': 0.988874, 'acc_grapheme': 0.974356, 'acc_vowel': 0.992439, 'acc_consonant': 0.992215, 'loss_grapheme': 0.10626, 'loss_vowel': 0.044002, 'loss_consonant': 0.039991}\n",
      "  201 | 0.000017 | 146944/160635 | 2.6176 | 1.7036 |\n",
      "val: {'recall': 0.981924, 'recall_grapheme': 0.974048, 'recall_vowel': 0.991024, 'recall_consonant': 0.988577, 'acc_grapheme': 0.974978, 'acc_vowel': 0.992588, 'acc_consonant': 0.992488, 'loss_grapheme': 0.108338, 'loss_vowel': 0.047723, 'loss_consonant': 0.041182}\n",
      "  202 | 0.000015 | 089088/160635 | 0.0084 | 1.4760 |\n",
      "val: {'recall': 0.981929, 'recall_grapheme': 0.973845, 'recall_vowel': 0.991103, 'recall_consonant': 0.988924, 'acc_grapheme': 0.975252, 'acc_vowel': 0.992638, 'acc_consonant': 0.992414, 'loss_grapheme': 0.104969, 'loss_vowel': 0.043898, 'loss_consonant': 0.037053}\n",
      "  203 | 0.000013 | 031232/160635 | 2.1973 | 1.6434 |\n",
      "val: {'recall': 0.982152, 'recall_grapheme': 0.974486, 'recall_vowel': 0.991353, 'recall_consonant': 0.988284, 'acc_grapheme': 0.975152, 'acc_vowel': 0.992886, 'acc_consonant': 0.992091, 'loss_grapheme': 0.10593, 'loss_vowel': 0.045445, 'loss_consonant': 0.039385}\n",
      "  203 | 0.000011 | 133632/160635 | 0.0035 | 1.7260 |\n",
      "val: {'recall': 0.98229, 'recall_grapheme': 0.974704, 'recall_vowel': 0.991259, 'recall_consonant': 0.988494, 'acc_grapheme': 0.975476, 'acc_vowel': 0.992936, 'acc_consonant': 0.992389, 'loss_grapheme': 0.107912, 'loss_vowel': 0.048634, 'loss_consonant': 0.041485}\n",
      "  204 | 0.000008 | 075776/160635 | 0.4698 | 1.4796 |\n",
      "val: {'recall': 0.981646, 'recall_grapheme': 0.973998, 'recall_vowel': 0.991219, 'recall_consonant': 0.987368, 'acc_grapheme': 0.975376, 'acc_vowel': 0.992737, 'acc_consonant': 0.992314, 'loss_grapheme': 0.103795, 'loss_vowel': 0.043451, 'loss_consonant': 0.037115}\n",
      "  205 | 0.000006 | 017920/160635 | 0.0056 | 1.6424 |\n",
      "val: {'recall': 0.982148, 'recall_grapheme': 0.974396, 'recall_vowel': 0.991629, 'recall_consonant': 0.988173, 'acc_grapheme': 0.975227, 'acc_vowel': 0.992862, 'acc_consonant': 0.99214, 'loss_grapheme': 0.104536, 'loss_vowel': 0.04562, 'loss_consonant': 0.038958}\n",
      "  205 | 0.000004 | 120320/160635 | 3.1598 | 1.6094 |\n",
      "val: {'recall': 0.982298, 'recall_grapheme': 0.974758, 'recall_vowel': 0.991263, 'recall_consonant': 0.988413, 'acc_grapheme': 0.975874, 'acc_vowel': 0.992687, 'acc_consonant': 0.99219, 'loss_grapheme': 0.103516, 'loss_vowel': 0.044902, 'loss_consonant': 0.038484}\n",
      "  206 | 0.000002 | 062464/160635 | 0.0095 | 1.3542 |\n",
      "val: {'recall': 0.982228, 'recall_grapheme': 0.974785, 'recall_vowel': 0.991165, 'recall_consonant': 0.988175, 'acc_grapheme': 0.975774, 'acc_vowel': 0.992663, 'acc_consonant': 0.992314, 'loss_grapheme': 0.101037, 'loss_vowel': 0.040178, 'loss_consonant': 0.034567}\n",
      "  207 | 0.000001 | 004608/160635 | 0.0730 | 1.0494 |\n",
      "val: {'recall': 0.982185, 'recall_grapheme': 0.974561, 'recall_vowel': 0.99131, 'recall_consonant': 0.988308, 'acc_grapheme': 0.975724, 'acc_vowel': 0.992737, 'acc_consonant': 0.992314, 'loss_grapheme': 0.102903, 'loss_vowel': 0.043868, 'loss_consonant': 0.037688}\n",
      "  207 | 0.000001 | 107008/160635 | 2.9868 | 1.5988 |\n",
      "val: {'recall': 0.982417, 'recall_grapheme': 0.975027, 'recall_vowel': 0.991149, 'recall_consonant': 0.988466, 'acc_grapheme': 0.9757, 'acc_vowel': 0.992762, 'acc_consonant': 0.992389, 'loss_grapheme': 0.105155, 'loss_vowel': 0.046467, 'loss_consonant': 0.039789}\n",
      "  208 | 0.000001 | 049152/160635 | 1.0813 | 1.4886 |\n",
      "val: {'recall': 0.982461, 'recall_grapheme': 0.97519, 'recall_vowel': 0.991192, 'recall_consonant': 0.988271, 'acc_grapheme': 0.976023, 'acc_vowel': 0.992712, 'acc_consonant': 0.99229, 'loss_grapheme': 0.102795, 'loss_vowel': 0.043187, 'loss_consonant': 0.037154}\n",
      "  208 | 0.000002 | 151552/160635 | 4.1671 | 1.5317 |\n",
      "val: {'recall': 0.982273, 'recall_grapheme': 0.974708, 'recall_vowel': 0.99139, 'recall_consonant': 0.988284, 'acc_grapheme': 0.975774, 'acc_vowel': 0.992862, 'acc_consonant': 0.992314, 'loss_grapheme': 0.101422, 'loss_vowel': 0.04153, 'loss_consonant': 0.035635}\n",
      "  209 | 0.000004 | 093696/160635 | 0.0128 | 1.6690 |\n",
      "val: {'recall': 0.982127, 'recall_grapheme': 0.974494, 'recall_vowel': 0.991206, 'recall_consonant': 0.988315, 'acc_grapheme': 0.9757, 'acc_vowel': 0.992687, 'acc_consonant': 0.992339, 'loss_grapheme': 0.103748, 'loss_vowel': 0.045449, 'loss_consonant': 0.039194}\n",
      "  210 | 0.000006 | 035840/160635 | 3.9373 | 1.7303 |\n",
      "val: {'recall': 0.982059, 'recall_grapheme': 0.974093, 'recall_vowel': 0.991133, 'recall_consonant': 0.988917, 'acc_grapheme': 0.975501, 'acc_vowel': 0.992563, 'acc_consonant': 0.992439, 'loss_grapheme': 0.105736, 'loss_vowel': 0.048339, 'loss_consonant': 0.041504}\n",
      "  210 | 0.000008 | 138240/160635 | 0.0114 | 1.5600 |\n",
      "val: {'recall': 0.982297, 'recall_grapheme': 0.973888, 'recall_vowel': 0.99126, 'recall_consonant': 0.990154, 'acc_grapheme': 0.975103, 'acc_vowel': 0.992812, 'acc_consonant': 0.992339, 'loss_grapheme': 0.106566, 'loss_vowel': 0.045752, 'loss_consonant': 0.039445}\n",
      "  211 | 0.000010 | 080384/160635 | 0.0030 | 1.5184 |\n",
      "val: {'recall': 0.982457, 'recall_grapheme': 0.974842, 'recall_vowel': 0.991254, 'recall_consonant': 0.988891, 'acc_grapheme': 0.975351, 'acc_vowel': 0.992712, 'acc_consonant': 0.992165, 'loss_grapheme': 0.104429, 'loss_vowel': 0.044155, 'loss_consonant': 0.038392}\n",
      "  212 | 0.000013 | 022528/160635 | 3.6085 | 1.3240 |\n",
      "val: {'recall': 0.981885, 'recall_grapheme': 0.974496, 'recall_vowel': 0.991133, 'recall_consonant': 0.987414, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992464, 'acc_consonant': 0.99219, 'loss_grapheme': 0.104928, 'loss_vowel': 0.045489, 'loss_consonant': 0.037901}\n",
      "  212 | 0.000015 | 124928/160635 | 0.0070 | 1.4037 |\n",
      "val: {'recall': 0.981141, 'recall_grapheme': 0.973566, 'recall_vowel': 0.990992, 'recall_consonant': 0.986442, 'acc_grapheme': 0.974779, 'acc_vowel': 0.992588, 'acc_consonant': 0.992115, 'loss_grapheme': 0.103472, 'loss_vowel': 0.041141, 'loss_consonant': 0.035556}\n",
      "  213 | 0.000017 | 067072/160635 | 0.0073 | 1.6446 |\n",
      "val: {'recall': 0.982148, 'recall_grapheme': 0.974186, 'recall_vowel': 0.991322, 'recall_consonant': 0.988897, 'acc_grapheme': 0.975252, 'acc_vowel': 0.992488, 'acc_consonant': 0.99229, 'loss_grapheme': 0.107441, 'loss_vowel': 0.046626, 'loss_consonant': 0.039585}\n",
      "  214 | 0.000019 | 009216/160635 | 0.0145 | 1.4413 |\n",
      "val: {'recall': 0.981434, 'recall_grapheme': 0.973159, 'recall_vowel': 0.991215, 'recall_consonant': 0.988202, 'acc_grapheme': 0.975078, 'acc_vowel': 0.992638, 'acc_consonant': 0.992339, 'loss_grapheme': 0.104931, 'loss_vowel': 0.04431, 'loss_consonant': 0.038326}\n",
      "  214 | 0.000020 | 111616/160635 | 0.0134 | 1.4459 |\n",
      "val: {'recall': 0.981758, 'recall_grapheme': 0.973961, 'recall_vowel': 0.991234, 'recall_consonant': 0.987876, 'acc_grapheme': 0.974555, 'acc_vowel': 0.992091, 'acc_consonant': 0.992115, 'loss_grapheme': 0.103894, 'loss_vowel': 0.04293, 'loss_consonant': 0.036401}\n",
      "  215 | 0.000020 | 053760/160635 | 0.0117 | 1.6670 |\n",
      "val: {'recall': 0.980723, 'recall_grapheme': 0.970823, 'recall_vowel': 0.991276, 'recall_consonant': 0.98997, 'acc_grapheme': 0.974307, 'acc_vowel': 0.992488, 'acc_consonant': 0.992464, 'loss_grapheme': 0.10703, 'loss_vowel': 0.0446, 'loss_consonant': 0.038469}\n",
      "  215 | 0.000020 | 156160/160635 | 0.3699 | 1.4787 |\n",
      "val: {'recall': 0.981939, 'recall_grapheme': 0.97421, 'recall_vowel': 0.991398, 'recall_consonant': 0.987938, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992613, 'acc_consonant': 0.992314, 'loss_grapheme': 0.103353, 'loss_vowel': 0.041045, 'loss_consonant': 0.035256}\n",
      "  216 | 0.000019 | 098304/160635 | 0.0254 | 1.5452 |\n",
      "val: {'recall': 0.981427, 'recall_grapheme': 0.973472, 'recall_vowel': 0.990982, 'recall_consonant': 0.98778, 'acc_grapheme': 0.975053, 'acc_vowel': 0.992215, 'acc_consonant': 0.992066, 'loss_grapheme': 0.103523, 'loss_vowel': 0.043276, 'loss_consonant': 0.037277}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217 | 0.000017 | 040448/160635 | 0.9370 | 1.4708 |\n",
      "val: {'recall': 0.981933, 'recall_grapheme': 0.973888, 'recall_vowel': 0.991377, 'recall_consonant': 0.98858, 'acc_grapheme': 0.974879, 'acc_vowel': 0.992638, 'acc_consonant': 0.992389, 'loss_grapheme': 0.105564, 'loss_vowel': 0.044916, 'loss_consonant': 0.039517}\n",
      "  217 | 0.000015 | 142848/160635 | 0.0036 | 1.5133 |\n",
      "val: {'recall': 0.982295, 'recall_grapheme': 0.975037, 'recall_vowel': 0.991254, 'recall_consonant': 0.987852, 'acc_grapheme': 0.975426, 'acc_vowel': 0.992563, 'acc_consonant': 0.992314, 'loss_grapheme': 0.103815, 'loss_vowel': 0.043973, 'loss_consonant': 0.037433}\n",
      "  218 | 0.000013 | 084992/160635 | 1.9744 | 1.6019 |\n",
      "val: {'recall': 0.98268, 'recall_grapheme': 0.975112, 'recall_vowel': 0.991298, 'recall_consonant': 0.989198, 'acc_grapheme': 0.975749, 'acc_vowel': 0.992737, 'acc_consonant': 0.992314, 'loss_grapheme': 0.104869, 'loss_vowel': 0.046332, 'loss_consonant': 0.039256}\n",
      "  219 | 0.000011 | 027136/160635 | 2.0712 | 1.2453 |\n",
      "val: {'recall': 0.98249, 'recall_grapheme': 0.974969, 'recall_vowel': 0.991334, 'recall_consonant': 0.988689, 'acc_grapheme': 0.976098, 'acc_vowel': 0.992687, 'acc_consonant': 0.992364, 'loss_grapheme': 0.100176, 'loss_vowel': 0.042212, 'loss_consonant': 0.036744}\n",
      "  219 | 0.000008 | 129536/160635 | 3.4778 | 1.5801 |\n",
      "val: {'recall': 0.982535, 'recall_grapheme': 0.975316, 'recall_vowel': 0.991608, 'recall_consonant': 0.987901, 'acc_grapheme': 0.975749, 'acc_vowel': 0.992862, 'acc_consonant': 0.992538, 'loss_grapheme': 0.102906, 'loss_vowel': 0.044883, 'loss_consonant': 0.038239}\n",
      "  220 | 0.000006 | 071680/160635 | 4.3715 | 1.5406 |\n",
      "val: {'recall': 0.982853, 'recall_grapheme': 0.975018, 'recall_vowel': 0.991868, 'recall_consonant': 0.989506, 'acc_grapheme': 0.975948, 'acc_vowel': 0.992762, 'acc_consonant': 0.992464, 'loss_grapheme': 0.103086, 'loss_vowel': 0.045361, 'loss_consonant': 0.038974}\n",
      "** saved\n",
      "  221 | 0.000004 | 013824/160635 | 0.9116 | 1.0446 |\n",
      "val: {'recall': 0.981991, 'recall_grapheme': 0.97429, 'recall_vowel': 0.991593, 'recall_consonant': 0.98779, 'acc_grapheme': 0.97565, 'acc_vowel': 0.992762, 'acc_consonant': 0.992563, 'loss_grapheme': 0.100213, 'loss_vowel': 0.042357, 'loss_consonant': 0.036064}\n",
      "  221 | 0.000002 | 116224/160635 | 3.8660 | 1.4755 |\n",
      "val: {'recall': 0.982373, 'recall_grapheme': 0.974437, 'recall_vowel': 0.991506, 'recall_consonant': 0.989114, 'acc_grapheme': 0.975899, 'acc_vowel': 0.992638, 'acc_consonant': 0.992638, 'loss_grapheme': 0.101386, 'loss_vowel': 0.043277, 'loss_consonant': 0.036947}\n",
      "  222 | 0.000001 | 058368/160635 | 4.1681 | 1.6027 |\n",
      "val: {'recall': 0.982462, 'recall_grapheme': 0.974749, 'recall_vowel': 0.991439, 'recall_consonant': 0.98891, 'acc_grapheme': 0.975899, 'acc_vowel': 0.992638, 'acc_consonant': 0.992613, 'loss_grapheme': 0.10203, 'loss_vowel': 0.044625, 'loss_consonant': 0.038211}\n",
      "  223 | 0.000001 | 000512/160635 | 3.0986 | 3.0986 |\n",
      "val: {'recall': 0.982297, 'recall_grapheme': 0.974358, 'recall_vowel': 0.991549, 'recall_consonant': 0.988923, 'acc_grapheme': 0.975874, 'acc_vowel': 0.992837, 'acc_consonant': 0.992663, 'loss_grapheme': 0.100589, 'loss_vowel': 0.042393, 'loss_consonant': 0.036474}\n",
      "  223 | 0.000001 | 102912/160635 | 0.0041 | 1.4292 |\n",
      "val: {'recall': 0.98237, 'recall_grapheme': 0.974313, 'recall_vowel': 0.991712, 'recall_consonant': 0.989143, 'acc_grapheme': 0.975948, 'acc_vowel': 0.992886, 'acc_consonant': 0.992712, 'loss_grapheme': 0.099532, 'loss_vowel': 0.040385, 'loss_consonant': 0.034914}\n",
      "  224 | 0.000002 | 045056/160635 | 3.0885 | 1.7051 |\n",
      "val: {'recall': 0.982407, 'recall_grapheme': 0.974539, 'recall_vowel': 0.991584, 'recall_consonant': 0.988965, 'acc_grapheme': 0.975998, 'acc_vowel': 0.992762, 'acc_consonant': 0.992712, 'loss_grapheme': 0.10221, 'loss_vowel': 0.044834, 'loss_consonant': 0.038258}\n",
      "  224 | 0.000004 | 147456/160635 | 3.4040 | 1.6622 |\n",
      "val: {'recall': 0.982594, 'recall_grapheme': 0.974852, 'recall_vowel': 0.991687, 'recall_consonant': 0.988985, 'acc_grapheme': 0.975973, 'acc_vowel': 0.992862, 'acc_consonant': 0.992638, 'loss_grapheme': 0.100381, 'loss_vowel': 0.041903, 'loss_consonant': 0.035875}\n",
      "  225 | 0.000006 | 089600/160635 | 3.1907 | 1.3883 |\n",
      "val: {'recall': 0.982471, 'recall_grapheme': 0.974914, 'recall_vowel': 0.991318, 'recall_consonant': 0.98874, 'acc_grapheme': 0.975824, 'acc_vowel': 0.992687, 'acc_consonant': 0.992613, 'loss_grapheme': 0.100735, 'loss_vowel': 0.04165, 'loss_consonant': 0.035438}\n",
      "  226 | 0.000008 | 031744/160635 | 3.4774 | 1.3049 |\n",
      "val: {'recall': 0.982128, 'recall_grapheme': 0.974237, 'recall_vowel': 0.991052, 'recall_consonant': 0.988983, 'acc_grapheme': 0.975899, 'acc_vowel': 0.992762, 'acc_consonant': 0.992687, 'loss_grapheme': 0.100204, 'loss_vowel': 0.040589, 'loss_consonant': 0.034897}\n",
      "  226 | 0.000011 | 134144/160635 | 0.0058 | 1.3785 |\n",
      "val: {'recall': 0.982268, 'recall_grapheme': 0.974635, 'recall_vowel': 0.99126, 'recall_consonant': 0.988544, 'acc_grapheme': 0.975625, 'acc_vowel': 0.992588, 'acc_consonant': 0.99214, 'loss_grapheme': 0.100884, 'loss_vowel': 0.041207, 'loss_consonant': 0.035251}\n",
      "  227 | 0.000013 | 076288/160635 | 4.3079 | 1.2900 |\n",
      "val: {'recall': 0.98221, 'recall_grapheme': 0.974562, 'recall_vowel': 0.991009, 'recall_consonant': 0.988708, 'acc_grapheme': 0.975401, 'acc_vowel': 0.992638, 'acc_consonant': 0.992389, 'loss_grapheme': 0.102501, 'loss_vowel': 0.040719, 'loss_consonant': 0.034863}\n",
      "  228 | 0.000015 | 018432/160635 | 0.0209 | 1.6967 |\n",
      "val: {'recall': 0.982482, 'recall_grapheme': 0.97492, 'recall_vowel': 0.990814, 'recall_consonant': 0.989273, 'acc_grapheme': 0.976023, 'acc_vowel': 0.992613, 'acc_consonant': 0.992389, 'loss_grapheme': 0.103835, 'loss_vowel': 0.043167, 'loss_consonant': 0.037194}\n",
      "  228 | 0.000017 | 120832/160635 | 4.2302 | 1.4389 |\n",
      "val: {'recall': 0.981748, 'recall_grapheme': 0.974476, 'recall_vowel': 0.991036, 'recall_consonant': 0.987005, 'acc_grapheme': 0.975277, 'acc_vowel': 0.992862, 'acc_consonant': 0.992364, 'loss_grapheme': 0.103208, 'loss_vowel': 0.041471, 'loss_consonant': 0.036378}\n",
      "  229 | 0.000019 | 062976/160635 | 2.3010 | 1.5186 |\n",
      "val: {'recall': 0.981607, 'recall_grapheme': 0.973258, 'recall_vowel': 0.991425, 'recall_consonant': 0.988486, 'acc_grapheme': 0.975252, 'acc_vowel': 0.992837, 'acc_consonant': 0.992538, 'loss_grapheme': 0.106745, 'loss_vowel': 0.044599, 'loss_consonant': 0.040205}\n",
      "  230 | 0.000020 | 005120/160635 | 0.0045 | 1.3966 |\n",
      "val: {'recall': 0.981532, 'recall_grapheme': 0.973096, 'recall_vowel': 0.99145, 'recall_consonant': 0.988486, 'acc_grapheme': 0.975426, 'acc_vowel': 0.992663, 'acc_consonant': 0.992364, 'loss_grapheme': 0.104208, 'loss_vowel': 0.044716, 'loss_consonant': 0.038732}\n",
      "  230 | 0.000020 | 107520/160635 | 1.4365 | 1.5754 |\n",
      "val: {'recall': 0.982802, 'recall_grapheme': 0.9754, 'recall_vowel': 0.991178, 'recall_consonant': 0.98923, 'acc_grapheme': 0.975575, 'acc_vowel': 0.992389, 'acc_consonant': 0.992464, 'loss_grapheme': 0.108446, 'loss_vowel': 0.049454, 'loss_consonant': 0.040954}\n",
      "  231 | 0.000020 | 049664/160635 | 4.6399 | 1.6627 |\n",
      "val: {'recall': 0.981993, 'recall_grapheme': 0.974372, 'recall_vowel': 0.990872, 'recall_consonant': 0.988355, 'acc_grapheme': 0.975426, 'acc_vowel': 0.992464, 'acc_consonant': 0.99219, 'loss_grapheme': 0.109068, 'loss_vowel': 0.049722, 'loss_consonant': 0.041922}\n",
      "  231 | 0.000019 | 152064/160635 | 3.2788 | 1.6435 |\n",
      "val: {'recall': 0.981818, 'recall_grapheme': 0.973832, 'recall_vowel': 0.991574, 'recall_consonant': 0.988033, 'acc_grapheme': 0.975774, 'acc_vowel': 0.992538, 'acc_consonant': 0.992538, 'loss_grapheme': 0.104214, 'loss_vowel': 0.045046, 'loss_consonant': 0.039144}\n",
      "  232 | 0.000017 | 094208/160635 | 0.0055 | 1.5735 |\n",
      "val: {'recall': 0.982473, 'recall_grapheme': 0.974741, 'recall_vowel': 0.991336, 'recall_consonant': 0.989077, 'acc_grapheme': 0.9757, 'acc_vowel': 0.992812, 'acc_consonant': 0.992563, 'loss_grapheme': 0.103991, 'loss_vowel': 0.044782, 'loss_consonant': 0.038238}\n",
      "  233 | 0.000015 | 036352/160635 | 3.6868 | 1.6252 |\n",
      "val: {'recall': 0.982029, 'recall_grapheme': 0.975035, 'recall_vowel': 0.99086, 'recall_consonant': 0.987186, 'acc_grapheme': 0.975675, 'acc_vowel': 0.992488, 'acc_consonant': 0.992663, 'loss_grapheme': 0.104526, 'loss_vowel': 0.046933, 'loss_consonant': 0.039717}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  233 | 0.000013 | 138752/160635 | 0.0054 | 1.4936 |\n",
      "val: {'recall': 0.982683, 'recall_grapheme': 0.975445, 'recall_vowel': 0.991516, 'recall_consonant': 0.988324, 'acc_grapheme': 0.976421, 'acc_vowel': 0.992862, 'acc_consonant': 0.992563, 'loss_grapheme': 0.101429, 'loss_vowel': 0.043679, 'loss_consonant': 0.037587}\n",
      "  234 | 0.000011 | 080896/160635 | 0.0063 | 1.4816 |\n",
      "val: {'recall': 0.982929, 'recall_grapheme': 0.976193, 'recall_vowel': 0.991511, 'recall_consonant': 0.987821, 'acc_grapheme': 0.976645, 'acc_vowel': 0.993011, 'acc_consonant': 0.992265, 'loss_grapheme': 0.10027, 'loss_vowel': 0.041647, 'loss_consonant': 0.036315}\n",
      "** saved\n",
      "  235 | 0.000008 | 023040/160635 | 0.0149 | 1.4852 |\n",
      "val: {'recall': 0.98258, 'recall_grapheme': 0.974906, 'recall_vowel': 0.991838, 'recall_consonant': 0.988671, 'acc_grapheme': 0.975824, 'acc_vowel': 0.99311, 'acc_consonant': 0.992389, 'loss_grapheme': 0.102224, 'loss_vowel': 0.044242, 'loss_consonant': 0.039015}\n",
      "  235 | 0.000006 | 125440/160635 | 1.9441 | 1.4860 |\n",
      "val: {'recall': 0.982061, 'recall_grapheme': 0.974575, 'recall_vowel': 0.991307, 'recall_consonant': 0.987786, 'acc_grapheme': 0.976197, 'acc_vowel': 0.992936, 'acc_consonant': 0.992364, 'loss_grapheme': 0.100962, 'loss_vowel': 0.044141, 'loss_consonant': 0.038242}\n",
      "  236 | 0.000004 | 067584/160635 | 0.0114 | 1.5109 |\n",
      "val: {'recall': 0.982708, 'recall_grapheme': 0.97517, 'recall_vowel': 0.991756, 'recall_consonant': 0.988738, 'acc_grapheme': 0.97652, 'acc_vowel': 0.993036, 'acc_consonant': 0.992488, 'loss_grapheme': 0.102471, 'loss_vowel': 0.045652, 'loss_consonant': 0.039226}\n",
      "  237 | 0.000002 | 009728/160635 | 0.0035 | 1.6157 |\n",
      "val: {'recall': 0.982694, 'recall_grapheme': 0.975759, 'recall_vowel': 0.991601, 'recall_consonant': 0.987655, 'acc_grapheme': 0.97657, 'acc_vowel': 0.993011, 'acc_consonant': 0.992513, 'loss_grapheme': 0.099339, 'loss_vowel': 0.041421, 'loss_consonant': 0.035766}\n",
      "  237 | 0.000001 | 112128/160635 | 0.0030 | 1.4504 |\n",
      "val: {'recall': 0.982558, 'recall_grapheme': 0.975585, 'recall_vowel': 0.991258, 'recall_consonant': 0.987804, 'acc_grapheme': 0.97652, 'acc_vowel': 0.993061, 'acc_consonant': 0.992563, 'loss_grapheme': 0.098675, 'loss_vowel': 0.040915, 'loss_consonant': 0.03538}\n",
      "  238 | 0.000001 | 054272/160635 | 3.8003 | 1.5040 |\n",
      "val: {'recall': 0.982475, 'recall_grapheme': 0.975424, 'recall_vowel': 0.991199, 'recall_consonant': 0.987855, 'acc_grapheme': 0.976446, 'acc_vowel': 0.992911, 'acc_consonant': 0.992588, 'loss_grapheme': 0.101001, 'loss_vowel': 0.043687, 'loss_consonant': 0.037505}\n",
      "  238 | 0.000001 | 156672/160635 | 4.6403 | 1.6619 |\n",
      "val: {'recall': 0.982522, 'recall_grapheme': 0.975384, 'recall_vowel': 0.99153, 'recall_consonant': 0.987792, 'acc_grapheme': 0.976296, 'acc_vowel': 0.993036, 'acc_consonant': 0.992513, 'loss_grapheme': 0.103213, 'loss_vowel': 0.047569, 'loss_consonant': 0.041187}\n",
      "  239 | 0.000002 | 098816/160635 | 0.0064 | 1.5846 |\n",
      "val: {'recall': 0.982485, 'recall_grapheme': 0.975168, 'recall_vowel': 0.991709, 'recall_consonant': 0.987896, 'acc_grapheme': 0.976545, 'acc_vowel': 0.99316, 'acc_consonant': 0.992687, 'loss_grapheme': 0.099313, 'loss_vowel': 0.042043, 'loss_consonant': 0.036462}\n",
      "  240 | 0.000004 | 040960/160635 | 3.0243 | 1.0640 |\n",
      "val: {'recall': 0.982624, 'recall_grapheme': 0.975123, 'recall_vowel': 0.991528, 'recall_consonant': 0.98872, 'acc_grapheme': 0.976719, 'acc_vowel': 0.993135, 'acc_consonant': 0.992538, 'loss_grapheme': 0.098125, 'loss_vowel': 0.039446, 'loss_consonant': 0.033974}\n",
      "  240 | 0.000006 | 143360/160635 | 0.0087 | 1.3688 |\n",
      "val: {'recall': 0.982338, 'recall_grapheme': 0.974615, 'recall_vowel': 0.991388, 'recall_consonant': 0.988732, 'acc_grapheme': 0.976048, 'acc_vowel': 0.992961, 'acc_consonant': 0.992439, 'loss_grapheme': 0.099285, 'loss_vowel': 0.041096, 'loss_consonant': 0.035663}\n",
      "  241 | 0.000008 | 085504/160635 | 0.7600 | 1.2560 |\n",
      "val: {'recall': 0.982334, 'recall_grapheme': 0.974894, 'recall_vowel': 0.991662, 'recall_consonant': 0.987887, 'acc_grapheme': 0.976098, 'acc_vowel': 0.992936, 'acc_consonant': 0.992414, 'loss_grapheme': 0.099633, 'loss_vowel': 0.038183, 'loss_consonant': 0.033233}\n",
      "  242 | 0.000011 | 027648/160635 | 3.2244 | 1.4749 |\n",
      "val: {'recall': 0.982336, 'recall_grapheme': 0.975178, 'recall_vowel': 0.99117, 'recall_consonant': 0.987819, 'acc_grapheme': 0.97657, 'acc_vowel': 0.992961, 'acc_consonant': 0.992663, 'loss_grapheme': 0.098941, 'loss_vowel': 0.039785, 'loss_consonant': 0.033789}\n",
      "  242 | 0.000013 | 130048/160635 | 4.5004 | 1.6381 |\n",
      "val: {'recall': 0.983045, 'recall_grapheme': 0.975786, 'recall_vowel': 0.992373, 'recall_consonant': 0.988236, 'acc_grapheme': 0.976023, 'acc_vowel': 0.99316, 'acc_consonant': 0.992513, 'loss_grapheme': 0.10248, 'loss_vowel': 0.044295, 'loss_consonant': 0.037761}\n",
      "** saved\n",
      "  243 | 0.000015 | 072192/160635 | 1.6795 | 1.6161 |\n",
      "val: {'recall': 0.982668, 'recall_grapheme': 0.976084, 'recall_vowel': 0.99217, 'recall_consonant': 0.986334, 'acc_grapheme': 0.976122, 'acc_vowel': 0.993036, 'acc_consonant': 0.992265, 'loss_grapheme': 0.10113, 'loss_vowel': 0.043778, 'loss_consonant': 0.037833}\n",
      "  244 | 0.000017 | 014336/160635 | 2.3852 | 1.8008 |\n",
      "val: {'recall': 0.982372, 'recall_grapheme': 0.974423, 'recall_vowel': 0.991937, 'recall_consonant': 0.988703, 'acc_grapheme': 0.9757, 'acc_vowel': 0.992936, 'acc_consonant': 0.992464, 'loss_grapheme': 0.103498, 'loss_vowel': 0.044847, 'loss_consonant': 0.037828}\n",
      "  244 | 0.000019 | 116736/160635 | 4.1451 | 1.5390 |\n",
      "val: {'recall': 0.983087, 'recall_grapheme': 0.976338, 'recall_vowel': 0.991585, 'recall_consonant': 0.988085, 'acc_grapheme': 0.976098, 'acc_vowel': 0.992911, 'acc_consonant': 0.992389, 'loss_grapheme': 0.103956, 'loss_vowel': 0.044522, 'loss_consonant': 0.037766}\n",
      "** saved\n",
      "  245 | 0.000020 | 058880/160635 | 4.4502 | 1.5671 |\n",
      "val: {'recall': 0.982866, 'recall_grapheme': 0.975517, 'recall_vowel': 0.990997, 'recall_consonant': 0.989431, 'acc_grapheme': 0.976272, 'acc_vowel': 0.992961, 'acc_consonant': 0.992314, 'loss_grapheme': 0.103866, 'loss_vowel': 0.044558, 'loss_consonant': 0.03875}\n",
      "  246 | 0.000020 | 001024/160635 | 0.0060 | 1.2164 |\n",
      "val: {'recall': 0.98217, 'recall_grapheme': 0.974353, 'recall_vowel': 0.992056, 'recall_consonant': 0.987917, 'acc_grapheme': 0.9757, 'acc_vowel': 0.993135, 'acc_consonant': 0.992265, 'loss_grapheme': 0.102221, 'loss_vowel': 0.041026, 'loss_consonant': 0.036315}\n",
      "  246 | 0.000020 | 103424/160635 | 3.8443 | 1.2373 |\n",
      "val: {'recall': 0.9831, 'recall_grapheme': 0.975848, 'recall_vowel': 0.991886, 'recall_consonant': 0.988817, 'acc_grapheme': 0.975923, 'acc_vowel': 0.993036, 'acc_consonant': 0.992663, 'loss_grapheme': 0.099843, 'loss_vowel': 0.03861, 'loss_consonant': 0.033592}\n",
      "** saved\n",
      "  247 | 0.000019 | 045568/160635 | 0.0090 | 1.5216 |\n",
      "val: {'recall': 0.982267, 'recall_grapheme': 0.975174, 'recall_vowel': 0.992068, 'recall_consonant': 0.98665, 'acc_grapheme': 0.976048, 'acc_vowel': 0.992712, 'acc_consonant': 0.992314, 'loss_grapheme': 0.102908, 'loss_vowel': 0.043835, 'loss_consonant': 0.037228}\n",
      "  247 | 0.000017 | 147968/160635 | 4.4764 | 1.6706 |\n",
      "val: {'recall': 0.983349, 'recall_grapheme': 0.975952, 'recall_vowel': 0.99184, 'recall_consonant': 0.98965, 'acc_grapheme': 0.976023, 'acc_vowel': 0.993085, 'acc_consonant': 0.992414, 'loss_grapheme': 0.103221, 'loss_vowel': 0.046091, 'loss_consonant': 0.040775}\n",
      "** saved\n",
      "  248 | 0.000015 | 090112/160635 | 3.8809 | 1.6275 |\n",
      "val: {'recall': 0.98267, 'recall_grapheme': 0.974919, 'recall_vowel': 0.991797, 'recall_consonant': 0.989047, 'acc_grapheme': 0.976147, 'acc_vowel': 0.992886, 'acc_consonant': 0.992414, 'loss_grapheme': 0.103153, 'loss_vowel': 0.046971, 'loss_consonant': 0.039948}\n",
      "  249 | 0.000013 | 032256/160635 | 0.0050 | 1.4445 |\n",
      "val: {'recall': 0.98259, 'recall_grapheme': 0.975128, 'recall_vowel': 0.991445, 'recall_consonant': 0.988659, 'acc_grapheme': 0.976396, 'acc_vowel': 0.992936, 'acc_consonant': 0.992389, 'loss_grapheme': 0.101769, 'loss_vowel': 0.0429, 'loss_consonant': 0.037198}\n",
      "  249 | 0.000011 | 134656/160635 | 0.0056 | 1.4044 |\n",
      "val: {'recall': 0.982676, 'recall_grapheme': 0.975877, 'recall_vowel': 0.991262, 'recall_consonant': 0.987687, 'acc_grapheme': 0.975899, 'acc_vowel': 0.992787, 'acc_consonant': 0.992215, 'loss_grapheme': 0.10261, 'loss_vowel': 0.041808, 'loss_consonant': 0.036467}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  250 | 0.000008 | 076800/160635 | 0.0096 | 1.5870 |\n",
      "val: {'recall': 0.982752, 'recall_grapheme': 0.975854, 'recall_vowel': 0.991829, 'recall_consonant': 0.98747, 'acc_grapheme': 0.976471, 'acc_vowel': 0.992936, 'acc_consonant': 0.99219, 'loss_grapheme': 0.103531, 'loss_vowel': 0.04737, 'loss_consonant': 0.040136}\n",
      "  251 | 0.000006 | 018944/160635 | 0.0075 | 1.5341 |\n",
      "val: {'recall': 0.982378, 'recall_grapheme': 0.975172, 'recall_vowel': 0.991565, 'recall_consonant': 0.987602, 'acc_grapheme': 0.976222, 'acc_vowel': 0.992663, 'acc_consonant': 0.99224, 'loss_grapheme': 0.100366, 'loss_vowel': 0.042755, 'loss_consonant': 0.036624}\n",
      "  251 | 0.000004 | 121344/160635 | 0.0020 | 1.4994 |\n",
      "val: {'recall': 0.982429, 'recall_grapheme': 0.975253, 'recall_vowel': 0.991836, 'recall_consonant': 0.987376, 'acc_grapheme': 0.976073, 'acc_vowel': 0.993011, 'acc_consonant': 0.99224, 'loss_grapheme': 0.100909, 'loss_vowel': 0.044397, 'loss_consonant': 0.037886}\n",
      "  252 | 0.000002 | 063488/160635 | 2.3039 | 1.7843 |\n",
      "val: {'recall': 0.982378, 'recall_grapheme': 0.97523, 'recall_vowel': 0.991585, 'recall_consonant': 0.987468, 'acc_grapheme': 0.975973, 'acc_vowel': 0.992812, 'acc_consonant': 0.992265, 'loss_grapheme': 0.104846, 'loss_vowel': 0.048962, 'loss_consonant': 0.042}\n",
      "  253 | 0.000001 | 005632/160635 | 3.6862 | 1.4858 |\n",
      "val: {'recall': 0.983015, 'recall_grapheme': 0.975817, 'recall_vowel': 0.991519, 'recall_consonant': 0.988906, 'acc_grapheme': 0.976421, 'acc_vowel': 0.992886, 'acc_consonant': 0.992364, 'loss_grapheme': 0.100574, 'loss_vowel': 0.042778, 'loss_consonant': 0.036911}\n",
      "  253 | 0.000001 | 108032/160635 | 0.0226 | 1.4429 |\n",
      "val: {'recall': 0.982846, 'recall_grapheme': 0.975328, 'recall_vowel': 0.991853, 'recall_consonant': 0.988876, 'acc_grapheme': 0.976371, 'acc_vowel': 0.993036, 'acc_consonant': 0.992389, 'loss_grapheme': 0.098501, 'loss_vowel': 0.040056, 'loss_consonant': 0.0345}\n",
      "  254 | 0.000001 | 050176/160635 | 2.8638 | 1.4202 |\n",
      "val: {'recall': 0.982734, 'recall_grapheme': 0.975812, 'recall_vowel': 0.991623, 'recall_consonant': 0.987691, 'acc_grapheme': 0.97662, 'acc_vowel': 0.992961, 'acc_consonant': 0.992439, 'loss_grapheme': 0.099136, 'loss_vowel': 0.041649, 'loss_consonant': 0.035691}\n",
      "  255 | 0.000004 | 094720/160635 | 3.6623 | 1.5543 |\n",
      "val: {'recall': 0.983118, 'recall_grapheme': 0.975993, 'recall_vowel': 0.991641, 'recall_consonant': 0.988844, 'acc_grapheme': 0.976371, 'acc_vowel': 0.992936, 'acc_consonant': 0.992439, 'loss_grapheme': 0.099258, 'loss_vowel': 0.040784, 'loss_consonant': 0.03534}\n",
      "  256 | 0.000006 | 036864/160635 | 0.0113 | 1.6366 |\n",
      "val: {'recall': 0.983148, 'recall_grapheme': 0.976471, 'recall_vowel': 0.991595, 'recall_consonant': 0.988055, 'acc_grapheme': 0.976694, 'acc_vowel': 0.992886, 'acc_consonant': 0.992414, 'loss_grapheme': 0.10189, 'loss_vowel': 0.045459, 'loss_consonant': 0.039247}\n",
      "  256 | 0.000008 | 139264/160635 | 0.0065 | 1.4849 |\n",
      "val: {'recall': 0.983098, 'recall_grapheme': 0.975915, 'recall_vowel': 0.99194, 'recall_consonant': 0.988623, 'acc_grapheme': 0.976844, 'acc_vowel': 0.99316, 'acc_consonant': 0.992265, 'loss_grapheme': 0.098029, 'loss_vowel': 0.040494, 'loss_consonant': 0.034809}\n",
      "  257 | 0.000010 | 081408/160635 | 0.0035 | 1.5277 |\n",
      "val: {'recall': 0.982924, 'recall_grapheme': 0.976087, 'recall_vowel': 0.991192, 'recall_consonant': 0.98833, 'acc_grapheme': 0.976222, 'acc_vowel': 0.993036, 'acc_consonant': 0.99224, 'loss_grapheme': 0.102322, 'loss_vowel': 0.044705, 'loss_consonant': 0.038169}\n",
      "  258 | 0.000013 | 023552/160635 | 0.0056 | 1.4264 |\n",
      "val: {'recall': 0.982745, 'recall_grapheme': 0.97512, 'recall_vowel': 0.991173, 'recall_consonant': 0.989569, 'acc_grapheme': 0.975998, 'acc_vowel': 0.992712, 'acc_consonant': 0.992414, 'loss_grapheme': 0.101586, 'loss_vowel': 0.042031, 'loss_consonant': 0.036069}\n",
      "  258 | 0.000015 | 125952/160635 | 0.0057 | 1.5304 |\n",
      "val: {'recall': 0.982774, 'recall_grapheme': 0.975119, 'recall_vowel': 0.991787, 'recall_consonant': 0.989071, 'acc_grapheme': 0.975675, 'acc_vowel': 0.99321, 'acc_consonant': 0.992265, 'loss_grapheme': 0.102257, 'loss_vowel': 0.042989, 'loss_consonant': 0.037196}\n",
      "  259 | 0.000017 | 068096/160635 | 1.2742 | 1.6571 |\n",
      "val: {'recall': 0.983254, 'recall_grapheme': 0.976393, 'recall_vowel': 0.991575, 'recall_consonant': 0.988656, 'acc_grapheme': 0.976048, 'acc_vowel': 0.992787, 'acc_consonant': 0.992464, 'loss_grapheme': 0.104346, 'loss_vowel': 0.04465, 'loss_consonant': 0.039456}\n",
      "  260 | 0.000019 | 010240/160635 | 0.0106 | 1.1001 |\n",
      "val: {'recall': 0.982544, 'recall_grapheme': 0.974971, 'recall_vowel': 0.991351, 'recall_consonant': 0.988883, 'acc_grapheme': 0.976098, 'acc_vowel': 0.992737, 'acc_consonant': 0.992389, 'loss_grapheme': 0.100926, 'loss_vowel': 0.040285, 'loss_consonant': 0.034943}\n",
      "  260 | 0.000020 | 112640/160635 | 0.0059 | 1.5089 |\n",
      "val: {'recall': 0.983053, 'recall_grapheme': 0.975764, 'recall_vowel': 0.991542, 'recall_consonant': 0.989142, 'acc_grapheme': 0.976023, 'acc_vowel': 0.993061, 'acc_consonant': 0.992364, 'loss_grapheme': 0.10394, 'loss_vowel': 0.043665, 'loss_consonant': 0.037357}\n",
      "  261 | 0.000020 | 054784/160635 | 1.8511 | 1.3315 |\n",
      "val: {'recall': 0.983194, 'recall_grapheme': 0.97558, 'recall_vowel': 0.990994, 'recall_consonant': 0.990621, 'acc_grapheme': 0.975824, 'acc_vowel': 0.992712, 'acc_consonant': 0.992538, 'loss_grapheme': 0.099938, 'loss_vowel': 0.038645, 'loss_consonant': 0.034356}\n",
      "  261 | 0.000020 | 157184/160635 | 0.0083 | 1.3724 |\n",
      "val: {'recall': 0.983834, 'recall_grapheme': 0.976572, 'recall_vowel': 0.991584, 'recall_consonant': 0.990609, 'acc_grapheme': 0.976247, 'acc_vowel': 0.992812, 'acc_consonant': 0.99229, 'loss_grapheme': 0.101871, 'loss_vowel': 0.042168, 'loss_consonant': 0.037754}\n",
      "** saved\n",
      "  262 | 0.000019 | 099328/160635 | 0.0175 | 1.8368 |\n",
      "val: {'recall': 0.983267, 'recall_grapheme': 0.976203, 'recall_vowel': 0.99206, 'recall_consonant': 0.988601, 'acc_grapheme': 0.976122, 'acc_vowel': 0.992936, 'acc_consonant': 0.992339, 'loss_grapheme': 0.10459, 'loss_vowel': 0.047738, 'loss_consonant': 0.0407}\n",
      "  263 | 0.000017 | 041472/160635 | 4.7160 | 1.5817 |\n",
      "val: {'recall': 0.982775, 'recall_grapheme': 0.975468, 'recall_vowel': 0.99168, 'recall_consonant': 0.988483, 'acc_grapheme': 0.975923, 'acc_vowel': 0.992812, 'acc_consonant': 0.992613, 'loss_grapheme': 0.10338, 'loss_vowel': 0.044901, 'loss_consonant': 0.03817}\n",
      "  263 | 0.000015 | 143872/160635 | 0.0055 | 1.5903 |\n",
      "val: {'recall': 0.9825, 'recall_grapheme': 0.975145, 'recall_vowel': 0.991976, 'recall_consonant': 0.987734, 'acc_grapheme': 0.976371, 'acc_vowel': 0.992911, 'acc_consonant': 0.992389, 'loss_grapheme': 0.100463, 'loss_vowel': 0.042975, 'loss_consonant': 0.037412}\n",
      "  264 | 0.000013 | 086016/160635 | 0.0070 | 1.6821 |\n",
      "val: {'recall': 0.983091, 'recall_grapheme': 0.975304, 'recall_vowel': 0.991953, 'recall_consonant': 0.989803, 'acc_grapheme': 0.976172, 'acc_vowel': 0.992986, 'acc_consonant': 0.992837, 'loss_grapheme': 0.101826, 'loss_vowel': 0.044086, 'loss_consonant': 0.037876}\n",
      "  265 | 0.000011 | 028160/160635 | 4.0928 | 1.7707 |\n",
      "val: {'recall': 0.983057, 'recall_grapheme': 0.975881, 'recall_vowel': 0.990863, 'recall_consonant': 0.989604, 'acc_grapheme': 0.976769, 'acc_vowel': 0.992613, 'acc_consonant': 0.992364, 'loss_grapheme': 0.100789, 'loss_vowel': 0.045414, 'loss_consonant': 0.03789}\n",
      "  265 | 0.000008 | 130560/160635 | 0.0070 | 1.5388 |\n",
      "val: {'recall': 0.98295, 'recall_grapheme': 0.97555, 'recall_vowel': 0.99143, 'recall_consonant': 0.989272, 'acc_grapheme': 0.976545, 'acc_vowel': 0.992886, 'acc_consonant': 0.992712, 'loss_grapheme': 0.101022, 'loss_vowel': 0.043448, 'loss_consonant': 0.036641}\n",
      "  266 | 0.000006 | 072704/160635 | 4.1589 | 1.7852 |\n",
      "val: {'recall': 0.983617, 'recall_grapheme': 0.976744, 'recall_vowel': 0.991694, 'recall_consonant': 0.989288, 'acc_grapheme': 0.976794, 'acc_vowel': 0.992986, 'acc_consonant': 0.992687, 'loss_grapheme': 0.103224, 'loss_vowel': 0.047017, 'loss_consonant': 0.04032}\n",
      "  267 | 0.000004 | 014848/160635 | 1.8077 | 1.8624 |\n",
      "val: {'recall': 0.983409, 'recall_grapheme': 0.97657, 'recall_vowel': 0.991631, 'recall_consonant': 0.988867, 'acc_grapheme': 0.976869, 'acc_vowel': 0.992961, 'acc_consonant': 0.992513, 'loss_grapheme': 0.102431, 'loss_vowel': 0.046701, 'loss_consonant': 0.039915}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  267 | 0.000002 | 117248/160635 | 0.0036 | 1.5686 |\n",
      "val: {'recall': 0.983411, 'recall_grapheme': 0.976256, 'recall_vowel': 0.991908, 'recall_consonant': 0.989225, 'acc_grapheme': 0.977267, 'acc_vowel': 0.99316, 'acc_consonant': 0.992737, 'loss_grapheme': 0.099384, 'loss_vowel': 0.043489, 'loss_consonant': 0.037253}\n",
      "  268 | 0.000001 | 059392/160635 | 3.4335 | 1.2917 |\n",
      "val: {'recall': 0.983488, 'recall_grapheme': 0.976608, 'recall_vowel': 0.991655, 'recall_consonant': 0.989082, 'acc_grapheme': 0.977068, 'acc_vowel': 0.993011, 'acc_consonant': 0.992687, 'loss_grapheme': 0.098433, 'loss_vowel': 0.04109, 'loss_consonant': 0.034987}\n",
      "  269 | 0.000001 | 001536/160635 | 4.6920 | 2.9598 |\n",
      "val: {'recall': 0.983355, 'recall_grapheme': 0.976281, 'recall_vowel': 0.991823, 'recall_consonant': 0.989036, 'acc_grapheme': 0.976893, 'acc_vowel': 0.993036, 'acc_consonant': 0.992663, 'loss_grapheme': 0.100298, 'loss_vowel': 0.044452, 'loss_consonant': 0.037617}\n",
      "  269 | 0.000001 | 103936/160635 | 2.3586 | 1.6609 |\n",
      "val: {'recall': 0.983336, 'recall_grapheme': 0.976284, 'recall_vowel': 0.991805, 'recall_consonant': 0.988969, 'acc_grapheme': 0.976918, 'acc_vowel': 0.992986, 'acc_consonant': 0.992563, 'loss_grapheme': 0.101217, 'loss_vowel': 0.045676, 'loss_consonant': 0.038626}\n",
      "  270 | 0.000002 | 046080/160635 | 3.2148 | 1.6702 |\n",
      "val: {'recall': 0.983495, 'recall_grapheme': 0.976272, 'recall_vowel': 0.991897, 'recall_consonant': 0.98954, 'acc_grapheme': 0.976943, 'acc_vowel': 0.99311, 'acc_consonant': 0.992812, 'loss_grapheme': 0.100036, 'loss_vowel': 0.044046, 'loss_consonant': 0.037832}\n",
      "  270 | 0.000004 | 148480/160635 | 0.0039 | 1.5141 |\n",
      "val: {'recall': 0.983602, 'recall_grapheme': 0.976468, 'recall_vowel': 0.9923, 'recall_consonant': 0.989173, 'acc_grapheme': 0.977117, 'acc_vowel': 0.993185, 'acc_consonant': 0.992613, 'loss_grapheme': 0.099577, 'loss_vowel': 0.043826, 'loss_consonant': 0.037295}\n",
      "  271 | 0.000006 | 090624/160635 | 3.9994 | 1.7674 |\n",
      "val: {'recall': 0.983101, 'recall_grapheme': 0.975803, 'recall_vowel': 0.991595, 'recall_consonant': 0.989203, 'acc_grapheme': 0.976446, 'acc_vowel': 0.992886, 'acc_consonant': 0.992663, 'loss_grapheme': 0.103425, 'loss_vowel': 0.047961, 'loss_consonant': 0.040319}\n",
      "  272 | 0.000008 | 032768/160635 | 0.0053 | 1.5723 |\n",
      "val: {'recall': 0.983082, 'recall_grapheme': 0.976216, 'recall_vowel': 0.991699, 'recall_consonant': 0.988196, 'acc_grapheme': 0.976844, 'acc_vowel': 0.992961, 'acc_consonant': 0.992563, 'loss_grapheme': 0.100292, 'loss_vowel': 0.044138, 'loss_consonant': 0.037577}\n",
      "  272 | 0.000011 | 135168/160635 | 2.6954 | 1.4851 |\n",
      "val: {'recall': 0.982543, 'recall_grapheme': 0.975312, 'recall_vowel': 0.991746, 'recall_consonant': 0.987801, 'acc_grapheme': 0.976694, 'acc_vowel': 0.992961, 'acc_consonant': 0.992638, 'loss_grapheme': 0.098865, 'loss_vowel': 0.043084, 'loss_consonant': 0.036987}\n",
      "  273 | 0.000013 | 077312/160635 | 3.7711 | 1.7283 |\n",
      "val: {'recall': 0.983173, 'recall_grapheme': 0.976282, 'recall_vowel': 0.991146, 'recall_consonant': 0.988982, 'acc_grapheme': 0.976744, 'acc_vowel': 0.992936, 'acc_consonant': 0.992588, 'loss_grapheme': 0.103861, 'loss_vowel': 0.048096, 'loss_consonant': 0.04118}\n",
      "  274 | 0.000015 | 019456/160635 | 0.0081 | 1.5630 |\n",
      "val: {'recall': 0.982837, 'recall_grapheme': 0.975418, 'recall_vowel': 0.991296, 'recall_consonant': 0.989215, 'acc_grapheme': 0.976446, 'acc_vowel': 0.992787, 'acc_consonant': 0.992414, 'loss_grapheme': 0.100868, 'loss_vowel': 0.043089, 'loss_consonant': 0.037619}\n",
      "  274 | 0.000017 | 121856/160635 | 0.0043 | 1.5030 |\n",
      "val: {'recall': 0.982368, 'recall_grapheme': 0.975903, 'recall_vowel': 0.991016, 'recall_consonant': 0.986649, 'acc_grapheme': 0.976296, 'acc_vowel': 0.992787, 'acc_consonant': 0.992115, 'loss_grapheme': 0.101027, 'loss_vowel': 0.042237, 'loss_consonant': 0.036755}\n",
      "  275 | 0.000019 | 064000/160635 | 2.7402 | 1.3438 |\n",
      "val: {'recall': 0.982565, 'recall_grapheme': 0.975269, 'recall_vowel': 0.991229, 'recall_consonant': 0.988495, 'acc_grapheme': 0.975973, 'acc_vowel': 0.992936, 'acc_consonant': 0.991941, 'loss_grapheme': 0.102173, 'loss_vowel': 0.043209, 'loss_consonant': 0.03738}\n",
      "  276 | 0.000020 | 006144/160635 | 3.7251 | 1.9873 |\n",
      "val: {'recall': 0.983175, 'recall_grapheme': 0.976596, 'recall_vowel': 0.992388, 'recall_consonant': 0.987121, 'acc_grapheme': 0.976545, 'acc_vowel': 0.993061, 'acc_consonant': 0.99214, 'loss_grapheme': 0.102779, 'loss_vowel': 0.044023, 'loss_consonant': 0.038926}\n",
      "  276 | 0.000020 | 108544/160635 | 3.2035 | 1.5907 |\n",
      "val: {'recall': 0.982817, 'recall_grapheme': 0.97564, 'recall_vowel': 0.991394, 'recall_consonant': 0.988595, 'acc_grapheme': 0.976645, 'acc_vowel': 0.992911, 'acc_consonant': 0.992339, 'loss_grapheme': 0.100599, 'loss_vowel': 0.042981, 'loss_consonant': 0.039415}\n",
      "  277 | 0.000020 | 050688/160635 | 0.6360 | 1.4965 |\n",
      "val: {'recall': 0.982899, 'recall_grapheme': 0.975402, 'recall_vowel': 0.991793, 'recall_consonant': 0.989, 'acc_grapheme': 0.976595, 'acc_vowel': 0.992986, 'acc_consonant': 0.992439, 'loss_grapheme': 0.099124, 'loss_vowel': 0.042519, 'loss_consonant': 0.036778}\n",
      "  277 | 0.000019 | 153088/160635 | 0.0213 | 1.7384 |\n",
      "val: {'recall': 0.983197, 'recall_grapheme': 0.976756, 'recall_vowel': 0.991218, 'recall_consonant': 0.988058, 'acc_grapheme': 0.976794, 'acc_vowel': 0.992812, 'acc_consonant': 0.99229, 'loss_grapheme': 0.103594, 'loss_vowel': 0.047021, 'loss_consonant': 0.041676}\n",
      "  278 | 0.000017 | 095232/160635 | 0.0118 | 1.4617 |\n",
      "val: {'recall': 0.98321, 'recall_grapheme': 0.976759, 'recall_vowel': 0.9915, 'recall_consonant': 0.987822, 'acc_grapheme': 0.977192, 'acc_vowel': 0.993011, 'acc_consonant': 0.992339, 'loss_grapheme': 0.099289, 'loss_vowel': 0.042268, 'loss_consonant': 0.03641}\n",
      "  279 | 0.000015 | 037376/160635 | 2.1422 | 1.9748 |\n",
      "val: {'recall': 0.983605, 'recall_grapheme': 0.977103, 'recall_vowel': 0.992019, 'recall_consonant': 0.988195, 'acc_grapheme': 0.976893, 'acc_vowel': 0.993185, 'acc_consonant': 0.992513, 'loss_grapheme': 0.105828, 'loss_vowel': 0.050185, 'loss_consonant': 0.043719}\n",
      "  279 | 0.000013 | 139776/160635 | 2.4083 | 1.5993 |\n",
      "val: {'recall': 0.983564, 'recall_grapheme': 0.976676, 'recall_vowel': 0.992188, 'recall_consonant': 0.988715, 'acc_grapheme': 0.976943, 'acc_vowel': 0.99321, 'acc_consonant': 0.992464, 'loss_grapheme': 0.100326, 'loss_vowel': 0.04343, 'loss_consonant': 0.037884}\n",
      "  280 | 0.000010 | 081920/160635 | 0.4595 | 1.3605 |\n",
      "val: {'recall': 0.983431, 'recall_grapheme': 0.976773, 'recall_vowel': 0.991611, 'recall_consonant': 0.988568, 'acc_grapheme': 0.977018, 'acc_vowel': 0.992986, 'acc_consonant': 0.992538, 'loss_grapheme': 0.098849, 'loss_vowel': 0.041381, 'loss_consonant': 0.03601}\n",
      "  281 | 0.000008 | 024064/160635 | 3.5789 | 1.7152 |\n",
      "val: {'recall': 0.983228, 'recall_grapheme': 0.976389, 'recall_vowel': 0.991199, 'recall_consonant': 0.988937, 'acc_grapheme': 0.977018, 'acc_vowel': 0.992911, 'acc_consonant': 0.992339, 'loss_grapheme': 0.098972, 'loss_vowel': 0.042915, 'loss_consonant': 0.036817}\n",
      "  281 | 0.000006 | 126464/160635 | 0.0052 | 1.6136 |\n",
      "val: {'recall': 0.983308, 'recall_grapheme': 0.976834, 'recall_vowel': 0.991409, 'recall_consonant': 0.988156, 'acc_grapheme': 0.977366, 'acc_vowel': 0.993036, 'acc_consonant': 0.992339, 'loss_grapheme': 0.098929, 'loss_vowel': 0.0435, 'loss_consonant': 0.0372}\n",
      "  282 | 0.000004 | 068608/160635 | 1.8277 | 1.6629 |\n",
      "val: {'recall': 0.983493, 'recall_grapheme': 0.97673, 'recall_vowel': 0.991708, 'recall_consonant': 0.988803, 'acc_grapheme': 0.977316, 'acc_vowel': 0.993085, 'acc_consonant': 0.992663, 'loss_grapheme': 0.100574, 'loss_vowel': 0.045809, 'loss_consonant': 0.039228}\n",
      "  283 | 0.000002 | 010752/160635 | 4.1444 | 1.6838 |\n",
      "val: {'recall': 0.983942, 'recall_grapheme': 0.97735, 'recall_vowel': 0.991739, 'recall_consonant': 0.989329, 'acc_grapheme': 0.97749, 'acc_vowel': 0.99311, 'acc_consonant': 0.992787, 'loss_grapheme': 0.098949, 'loss_vowel': 0.043835, 'loss_consonant': 0.037579}\n",
      "** saved\n",
      "  283 | 0.000001 | 113152/160635 | 0.0090 | 1.7166 |\n",
      "val: {'recall': 0.983669, 'recall_grapheme': 0.977049, 'recall_vowel': 0.992018, 'recall_consonant': 0.988562, 'acc_grapheme': 0.977565, 'acc_vowel': 0.993061, 'acc_consonant': 0.992663, 'loss_grapheme': 0.100551, 'loss_vowel': 0.046077, 'loss_consonant': 0.039169}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  284 | 0.000001 | 055296/160635 | 4.1632 | 1.6100 |\n",
      "val: {'recall': 0.983841, 'recall_grapheme': 0.977095, 'recall_vowel': 0.991965, 'recall_consonant': 0.989211, 'acc_grapheme': 0.977515, 'acc_vowel': 0.993135, 'acc_consonant': 0.992638, 'loss_grapheme': 0.09847, 'loss_vowel': 0.043345, 'loss_consonant': 0.037137}\n",
      "  284 | 0.000001 | 157696/160635 | 1.2566 | 1.5645 |\n",
      "val: {'recall': 0.98372, 'recall_grapheme': 0.977202, 'recall_vowel': 0.991818, 'recall_consonant': 0.988658, 'acc_grapheme': 0.977739, 'acc_vowel': 0.99311, 'acc_consonant': 0.992588, 'loss_grapheme': 0.096045, 'loss_vowel': 0.039928, 'loss_consonant': 0.034286}\n",
      "  285 | 0.000002 | 099840/160635 | 3.3976 | 1.9436 |\n",
      "val: {'recall': 0.983417, 'recall_grapheme': 0.976715, 'recall_vowel': 0.99191, 'recall_consonant': 0.988329, 'acc_grapheme': 0.977341, 'acc_vowel': 0.993036, 'acc_consonant': 0.992488, 'loss_grapheme': 0.101625, 'loss_vowel': 0.047453, 'loss_consonant': 0.041207}\n",
      "  286 | 0.000004 | 041984/160635 | 1.9936 | 1.3521 |\n",
      "val: {'recall': 0.983515, 'recall_grapheme': 0.976733, 'recall_vowel': 0.991758, 'recall_consonant': 0.988836, 'acc_grapheme': 0.977441, 'acc_vowel': 0.992936, 'acc_consonant': 0.992488, 'loss_grapheme': 0.098203, 'loss_vowel': 0.042788, 'loss_consonant': 0.036736}\n",
      "  286 | 0.000006 | 144384/160635 | 0.0063 | 1.5839 |\n",
      "val: {'recall': 0.983858, 'recall_grapheme': 0.977182, 'recall_vowel': 0.992062, 'recall_consonant': 0.989005, 'acc_grapheme': 0.97749, 'acc_vowel': 0.993185, 'acc_consonant': 0.992613, 'loss_grapheme': 0.098651, 'loss_vowel': 0.043803, 'loss_consonant': 0.037575}\n",
      "  287 | 0.000008 | 086528/160635 | 0.0034 | 1.5105 |\n",
      "val: {'recall': 0.983631, 'recall_grapheme': 0.97671, 'recall_vowel': 0.991779, 'recall_consonant': 0.989324, 'acc_grapheme': 0.977117, 'acc_vowel': 0.993061, 'acc_consonant': 0.992613, 'loss_grapheme': 0.09717, 'loss_vowel': 0.040191, 'loss_consonant': 0.034593}\n",
      "  288 | 0.000010 | 028672/160635 | 0.0048 | 0.9296 |\n",
      "val: {'recall': 0.983874, 'recall_grapheme': 0.977153, 'recall_vowel': 0.99176, 'recall_consonant': 0.989431, 'acc_grapheme': 0.97759, 'acc_vowel': 0.992961, 'acc_consonant': 0.992538, 'loss_grapheme': 0.096643, 'loss_vowel': 0.038437, 'loss_consonant': 0.032927}\n",
      "  288 | 0.000013 | 131072/160635 | 4.1660 | 1.4638 |\n",
      "val: {'recall': 0.982988, 'recall_grapheme': 0.976148, 'recall_vowel': 0.991782, 'recall_consonant': 0.987873, 'acc_grapheme': 0.97662, 'acc_vowel': 0.993061, 'acc_consonant': 0.992265, 'loss_grapheme': 0.09797, 'loss_vowel': 0.040039, 'loss_consonant': 0.034811}\n",
      "  289 | 0.000015 | 073216/160635 | 0.0066 | 1.6223 |\n",
      "val: {'recall': 0.983104, 'recall_grapheme': 0.97548, 'recall_vowel': 0.991307, 'recall_consonant': 0.990149, 'acc_grapheme': 0.976769, 'acc_vowel': 0.992812, 'acc_consonant': 0.992687, 'loss_grapheme': 0.098762, 'loss_vowel': 0.043799, 'loss_consonant': 0.037646}\n",
      "  290 | 0.000017 | 015360/160635 | 1.8186 | 1.3279 |\n",
      "val: {'recall': 0.983355, 'recall_grapheme': 0.976663, 'recall_vowel': 0.991069, 'recall_consonant': 0.989026, 'acc_grapheme': 0.976968, 'acc_vowel': 0.993135, 'acc_consonant': 0.992563, 'loss_grapheme': 0.099862, 'loss_vowel': 0.044223, 'loss_consonant': 0.03838}\n",
      "  290 | 0.000019 | 117760/160635 | 0.0060 | 1.5647 |\n",
      "val: {'recall': 0.98344, 'recall_grapheme': 0.975663, 'recall_vowel': 0.992065, 'recall_consonant': 0.99037, 'acc_grapheme': 0.97652, 'acc_vowel': 0.993135, 'acc_consonant': 0.992513, 'loss_grapheme': 0.101864, 'loss_vowel': 0.045872, 'loss_consonant': 0.038502}\n",
      "  291 | 0.000020 | 059904/160635 | 0.0059 | 1.5640 |\n",
      "val: {'recall': 0.98299, 'recall_grapheme': 0.976405, 'recall_vowel': 0.991277, 'recall_consonant': 0.987874, 'acc_grapheme': 0.976396, 'acc_vowel': 0.992936, 'acc_consonant': 0.99214, 'loss_grapheme': 0.101852, 'loss_vowel': 0.042776, 'loss_consonant': 0.036975}\n",
      "  292 | 0.000020 | 002048/160635 | 3.4919 | 2.6218 |\n",
      "val: {'recall': 0.982847, 'recall_grapheme': 0.975174, 'recall_vowel': 0.991364, 'recall_consonant': 0.989676, 'acc_grapheme': 0.976918, 'acc_vowel': 0.993011, 'acc_consonant': 0.992613, 'loss_grapheme': 0.098667, 'loss_vowel': 0.042436, 'loss_consonant': 0.03658}\n",
      "  292 | 0.000020 | 104448/160635 | 0.0082 | 1.3908 |\n",
      "val: {'recall': 0.983023, 'recall_grapheme': 0.975609, 'recall_vowel': 0.992376, 'recall_consonant': 0.988498, 'acc_grapheme': 0.975998, 'acc_vowel': 0.99321, 'acc_consonant': 0.992215, 'loss_grapheme': 0.099034, 'loss_vowel': 0.039228, 'loss_consonant': 0.034542}\n",
      "  293 | 0.000019 | 046592/160635 | 3.9306 | 1.3518 |\n",
      "val: {'recall': 0.983089, 'recall_grapheme': 0.975456, 'recall_vowel': 0.991932, 'recall_consonant': 0.989512, 'acc_grapheme': 0.976993, 'acc_vowel': 0.993135, 'acc_consonant': 0.992513, 'loss_grapheme': 0.097086, 'loss_vowel': 0.04038, 'loss_consonant': 0.035403}\n",
      "  293 | 0.000017 | 148992/160635 | 3.8128 | 1.5231 |\n",
      "val: {'recall': 0.98369, 'recall_grapheme': 0.976531, 'recall_vowel': 0.992131, 'recall_consonant': 0.989565, 'acc_grapheme': 0.977142, 'acc_vowel': 0.993085, 'acc_consonant': 0.992513, 'loss_grapheme': 0.098171, 'loss_vowel': 0.041542, 'loss_consonant': 0.035599}\n",
      "  294 | 0.000015 | 091136/160635 | 0.0030 | 1.6988 |\n",
      "val: {'recall': 0.982731, 'recall_grapheme': 0.975424, 'recall_vowel': 0.991973, 'recall_consonant': 0.988101, 'acc_grapheme': 0.976794, 'acc_vowel': 0.992911, 'acc_consonant': 0.992464, 'loss_grapheme': 0.099457, 'loss_vowel': 0.043197, 'loss_consonant': 0.038398}\n",
      "  295 | 0.000013 | 033280/160635 | 4.1617 | 1.4605 |\n",
      "val: {'recall': 0.9833, 'recall_grapheme': 0.976761, 'recall_vowel': 0.992086, 'recall_consonant': 0.987593, 'acc_grapheme': 0.977242, 'acc_vowel': 0.99311, 'acc_consonant': 0.992464, 'loss_grapheme': 0.098042, 'loss_vowel': 0.0433, 'loss_consonant': 0.036794}\n",
      "  295 | 0.000011 | 135680/160635 | 0.0109 | 1.5580 |\n",
      "val: {'recall': 0.983599, 'recall_grapheme': 0.976699, 'recall_vowel': 0.9914, 'recall_consonant': 0.989597, 'acc_grapheme': 0.977092, 'acc_vowel': 0.992961, 'acc_consonant': 0.992638, 'loss_grapheme': 0.097553, 'loss_vowel': 0.040524, 'loss_consonant': 0.034797}\n",
      "  296 | 0.000008 | 077824/160635 | 0.0046 | 1.4011 |\n",
      "val: {'recall': 0.983614, 'recall_grapheme': 0.976527, 'recall_vowel': 0.991682, 'recall_consonant': 0.98972, 'acc_grapheme': 0.977689, 'acc_vowel': 0.993011, 'acc_consonant': 0.992762, 'loss_grapheme': 0.09615, 'loss_vowel': 0.040159, 'loss_consonant': 0.035185}\n",
      "  297 | 0.000006 | 019968/160635 | 1.6889 | 1.4983 |\n",
      "val: {'recall': 0.983701, 'recall_grapheme': 0.976991, 'recall_vowel': 0.991586, 'recall_consonant': 0.989235, 'acc_grapheme': 0.97754, 'acc_vowel': 0.992911, 'acc_consonant': 0.992663, 'loss_grapheme': 0.097144, 'loss_vowel': 0.041772, 'loss_consonant': 0.035694}\n",
      "  297 | 0.000004 | 122368/160635 | 3.8872 | 1.5853 |\n",
      "val: {'recall': 0.983553, 'recall_grapheme': 0.976539, 'recall_vowel': 0.991956, 'recall_consonant': 0.989176, 'acc_grapheme': 0.97764, 'acc_vowel': 0.993061, 'acc_consonant': 0.992712, 'loss_grapheme': 0.095497, 'loss_vowel': 0.040102, 'loss_consonant': 0.034685}\n",
      "  298 | 0.000002 | 064512/160635 | 0.7545 | 1.4791 |\n",
      "val: {'recall': 0.98366, 'recall_grapheme': 0.976602, 'recall_vowel': 0.992053, 'recall_consonant': 0.989382, 'acc_grapheme': 0.977664, 'acc_vowel': 0.993135, 'acc_consonant': 0.992613, 'loss_grapheme': 0.095746, 'loss_vowel': 0.039994, 'loss_consonant': 0.034256}\n",
      "  299 | 0.000001 | 006656/160635 | 0.6012 | 0.9195 |\n",
      "val: {'recall': 0.983676, 'recall_grapheme': 0.9766, 'recall_vowel': 0.991931, 'recall_consonant': 0.989573, 'acc_grapheme': 0.977888, 'acc_vowel': 0.99316, 'acc_consonant': 0.992762, 'loss_grapheme': 0.094583, 'loss_vowel': 0.037685, 'loss_consonant': 0.031861}\n",
      "  299 | 0.000001 | 109056/160635 | 0.0024 | 1.5431 |\n",
      "val: {'recall': 0.983488, 'recall_grapheme': 0.976448, 'recall_vowel': 0.991957, 'recall_consonant': 0.989101, 'acc_grapheme': 0.977615, 'acc_vowel': 0.993185, 'acc_consonant': 0.992712, 'loss_grapheme': 0.0969, 'loss_vowel': 0.042924, 'loss_consonant': 0.036544}\n",
      "  300 | 0.000002 | 153600/160635 | 0.0031 | 1.5657 |\n",
      "val: {'recall': 0.983364, 'recall_grapheme': 0.9762, 'recall_vowel': 0.992066, 'recall_consonant': 0.988989, 'acc_grapheme': 0.977465, 'acc_vowel': 0.993185, 'acc_consonant': 0.992613, 'loss_grapheme': 0.097349, 'loss_vowel': 0.042379, 'loss_consonant': 0.036178}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  301 | 0.000004 | 095744/160635 | 3.7193 | 1.5397 |\n",
      "val: {'recall': 0.983512, 'recall_grapheme': 0.976575, 'recall_vowel': 0.991984, 'recall_consonant': 0.988915, 'acc_grapheme': 0.977839, 'acc_vowel': 0.99316, 'acc_consonant': 0.992613, 'loss_grapheme': 0.095014, 'loss_vowel': 0.040648, 'loss_consonant': 0.034716}\n",
      "  302 | 0.000006 | 037888/160635 | 2.1015 | 1.7126 |\n",
      "val: {'recall': 0.983325, 'recall_grapheme': 0.976459, 'recall_vowel': 0.992177, 'recall_consonant': 0.988204, 'acc_grapheme': 0.97759, 'acc_vowel': 0.99321, 'acc_consonant': 0.992812, 'loss_grapheme': 0.095966, 'loss_vowel': 0.040384, 'loss_consonant': 0.034576}\n",
      "  302 | 0.000008 | 140288/160635 | 0.0091 | 1.5529 |\n",
      "val: {'recall': 0.983329, 'recall_grapheme': 0.976208, 'recall_vowel': 0.991523, 'recall_consonant': 0.989374, 'acc_grapheme': 0.977565, 'acc_vowel': 0.993085, 'acc_consonant': 0.992638, 'loss_grapheme': 0.098111, 'loss_vowel': 0.043101, 'loss_consonant': 0.037025}\n",
      "  303 | 0.000010 | 082432/160635 | 0.0037 | 1.6703 |\n",
      "val: {'recall': 0.983271, 'recall_grapheme': 0.976487, 'recall_vowel': 0.991501, 'recall_consonant': 0.988609, 'acc_grapheme': 0.97764, 'acc_vowel': 0.992812, 'acc_consonant': 0.992911, 'loss_grapheme': 0.097224, 'loss_vowel': 0.041467, 'loss_consonant': 0.035136}\n",
      "  304 | 0.000013 | 024576/160635 | 0.0099 | 1.2473 |\n",
      "val: {'recall': 0.983205, 'recall_grapheme': 0.976758, 'recall_vowel': 0.991806, 'recall_consonant': 0.987497, 'acc_grapheme': 0.977341, 'acc_vowel': 0.993235, 'acc_consonant': 0.992712, 'loss_grapheme': 0.095911, 'loss_vowel': 0.037981, 'loss_consonant': 0.032385}\n",
      "  304 | 0.000015 | 126976/160635 | 0.0066 | 1.5244 |\n",
      "val: {'recall': 0.983218, 'recall_grapheme': 0.976771, 'recall_vowel': 0.991427, 'recall_consonant': 0.987904, 'acc_grapheme': 0.977242, 'acc_vowel': 0.992911, 'acc_consonant': 0.992513, 'loss_grapheme': 0.098807, 'loss_vowel': 0.041268, 'loss_consonant': 0.036183}\n",
      "  305 | 0.000017 | 069120/160635 | 1.0434 | 1.6572 |\n",
      "val: {'recall': 0.983098, 'recall_grapheme': 0.976593, 'recall_vowel': 0.991932, 'recall_consonant': 0.987274, 'acc_grapheme': 0.976794, 'acc_vowel': 0.992986, 'acc_consonant': 0.992389, 'loss_grapheme': 0.098268, 'loss_vowel': 0.042622, 'loss_consonant': 0.035718}\n",
      "  306 | 0.000019 | 011264/160635 | 1.3840 | 1.8586 |\n",
      "val: {'recall': 0.983422, 'recall_grapheme': 0.977063, 'recall_vowel': 0.991477, 'recall_consonant': 0.988086, 'acc_grapheme': 0.977515, 'acc_vowel': 0.993036, 'acc_consonant': 0.992762, 'loss_grapheme': 0.105776, 'loss_vowel': 0.049958, 'loss_consonant': 0.041948}\n",
      "  306 | 0.000020 | 113664/160635 | 2.0875 | 1.4652 |\n",
      "val: {'recall': 0.98419, 'recall_grapheme': 0.9775, 'recall_vowel': 0.991594, 'recall_consonant': 0.990166, 'acc_grapheme': 0.977615, 'acc_vowel': 0.993011, 'acc_consonant': 0.992862, 'loss_grapheme': 0.098645, 'loss_vowel': 0.042012, 'loss_consonant': 0.03659}\n",
      "** saved\n",
      "  307 | 0.000020 | 055808/160635 | 4.1380 | 1.2814 |\n",
      "val: {'recall': 0.983788, 'recall_grapheme': 0.977071, 'recall_vowel': 0.991539, 'recall_consonant': 0.989472, 'acc_grapheme': 0.977167, 'acc_vowel': 0.992886, 'acc_consonant': 0.992712, 'loss_grapheme': 0.09603, 'loss_vowel': 0.040277, 'loss_consonant': 0.033726}\n",
      "  307 | 0.000020 | 158208/160635 | 0.0079 | 1.3383 |\n",
      "val: {'recall': 0.983591, 'recall_grapheme': 0.976117, 'recall_vowel': 0.991866, 'recall_consonant': 0.990262, 'acc_grapheme': 0.977043, 'acc_vowel': 0.993011, 'acc_consonant': 0.992513, 'loss_grapheme': 0.097871, 'loss_vowel': 0.040102, 'loss_consonant': 0.033848}\n",
      "  308 | 0.000019 | 100352/160635 | 3.8593 | 1.4483 |\n",
      "val: {'recall': 0.984006, 'recall_grapheme': 0.97752, 'recall_vowel': 0.991265, 'recall_consonant': 0.989721, 'acc_grapheme': 0.977515, 'acc_vowel': 0.992961, 'acc_consonant': 0.992737, 'loss_grapheme': 0.099847, 'loss_vowel': 0.043099, 'loss_consonant': 0.036156}\n",
      "  309 | 0.000017 | 042496/160635 | 0.0122 | 1.7723 |\n",
      "val: {'recall': 0.9834, 'recall_grapheme': 0.976572, 'recall_vowel': 0.99122, 'recall_consonant': 0.989238, 'acc_grapheme': 0.977515, 'acc_vowel': 0.993061, 'acc_consonant': 0.992986, 'loss_grapheme': 0.09898, 'loss_vowel': 0.041918, 'loss_consonant': 0.035542}\n",
      "  309 | 0.000015 | 144896/160635 | 2.0957 | 1.5753 |\n",
      "val: {'recall': 0.98395, 'recall_grapheme': 0.977276, 'recall_vowel': 0.99142, 'recall_consonant': 0.989828, 'acc_grapheme': 0.977068, 'acc_vowel': 0.993061, 'acc_consonant': 0.992464, 'loss_grapheme': 0.100105, 'loss_vowel': 0.041458, 'loss_consonant': 0.035781}\n",
      "  310 | 0.000013 | 087040/160635 | 0.8285 | 1.4100 |\n",
      "val: {'recall': 0.983508, 'recall_grapheme': 0.976703, 'recall_vowel': 0.991207, 'recall_consonant': 0.989419, 'acc_grapheme': 0.977839, 'acc_vowel': 0.992986, 'acc_consonant': 0.992638, 'loss_grapheme': 0.094624, 'loss_vowel': 0.038902, 'loss_consonant': 0.033715}\n",
      "  311 | 0.000010 | 029184/160635 | 0.0058 | 1.2542 |\n",
      "val: {'recall': 0.98417, 'recall_grapheme': 0.977555, 'recall_vowel': 0.992139, 'recall_consonant': 0.989433, 'acc_grapheme': 0.977615, 'acc_vowel': 0.993135, 'acc_consonant': 0.992886, 'loss_grapheme': 0.098119, 'loss_vowel': 0.039469, 'loss_consonant': 0.034182}\n",
      "  311 | 0.000008 | 131584/160635 | 0.0084 | 1.6038 |\n",
      "val: {'recall': 0.984184, 'recall_grapheme': 0.977466, 'recall_vowel': 0.991886, 'recall_consonant': 0.989918, 'acc_grapheme': 0.97759, 'acc_vowel': 0.992837, 'acc_consonant': 0.992886, 'loss_grapheme': 0.098918, 'loss_vowel': 0.043879, 'loss_consonant': 0.037258}\n",
      "  312 | 0.000006 | 073728/160635 | 4.6181 | 1.6363 |\n",
      "val: {'recall': 0.984039, 'recall_grapheme': 0.977407, 'recall_vowel': 0.992271, 'recall_consonant': 0.989071, 'acc_grapheme': 0.977963, 'acc_vowel': 0.993135, 'acc_consonant': 0.992762, 'loss_grapheme': 0.098486, 'loss_vowel': 0.044047, 'loss_consonant': 0.03682}\n",
      "  313 | 0.000004 | 015872/160635 | 4.1071 | 1.3145 |\n",
      "val: {'recall': 0.983786, 'recall_grapheme': 0.977105, 'recall_vowel': 0.991625, 'recall_consonant': 0.98931, 'acc_grapheme': 0.977913, 'acc_vowel': 0.993011, 'acc_consonant': 0.992911, 'loss_grapheme': 0.097355, 'loss_vowel': 0.042102, 'loss_consonant': 0.035713}\n",
      "  313 | 0.000002 | 118272/160635 | 0.0052 | 1.2489 |\n",
      "val: {'recall': 0.983803, 'recall_grapheme': 0.977038, 'recall_vowel': 0.991715, 'recall_consonant': 0.98942, 'acc_grapheme': 0.977863, 'acc_vowel': 0.99311, 'acc_consonant': 0.992936, 'loss_grapheme': 0.094768, 'loss_vowel': 0.037239, 'loss_consonant': 0.031871}\n",
      "  314 | 0.000001 | 060416/160635 | 2.9016 | 1.4827 |\n",
      "val: {'recall': 0.983905, 'recall_grapheme': 0.977175, 'recall_vowel': 0.991917, 'recall_consonant': 0.98935, 'acc_grapheme': 0.978038, 'acc_vowel': 0.993085, 'acc_consonant': 0.992936, 'loss_grapheme': 0.094277, 'loss_vowel': 0.038041, 'loss_consonant': 0.032512}\n",
      "  315 | 0.000001 | 002560/160635 | 0.0109 | 1.7751 |\n",
      "val: {'recall': 0.984011, 'recall_grapheme': 0.977381, 'recall_vowel': 0.991912, 'recall_consonant': 0.989371, 'acc_grapheme': 0.978087, 'acc_vowel': 0.993085, 'acc_consonant': 0.992936, 'loss_grapheme': 0.094237, 'loss_vowel': 0.03884, 'loss_consonant': 0.03334}\n",
      "  315 | 0.000001 | 104960/160635 | 4.3128 | 1.6108 |\n",
      "val: {'recall': 0.983856, 'recall_grapheme': 0.977061, 'recall_vowel': 0.991901, 'recall_consonant': 0.989401, 'acc_grapheme': 0.977963, 'acc_vowel': 0.993061, 'acc_consonant': 0.992936, 'loss_grapheme': 0.09721, 'loss_vowel': 0.042623, 'loss_consonant': 0.036182}\n",
      "  316 | 0.000002 | 047104/160635 | 2.7303 | 1.7966 |\n",
      "val: {'recall': 0.984105, 'recall_grapheme': 0.977595, 'recall_vowel': 0.992358, 'recall_consonant': 0.988873, 'acc_grapheme': 0.978261, 'acc_vowel': 0.993284, 'acc_consonant': 0.992862, 'loss_grapheme': 0.098006, 'loss_vowel': 0.044766, 'loss_consonant': 0.037694}\n",
      "  316 | 0.000004 | 149504/160635 | 2.5524 | 1.6071 |\n",
      "val: {'recall': 0.984155, 'recall_grapheme': 0.977232, 'recall_vowel': 0.992188, 'recall_consonant': 0.989967, 'acc_grapheme': 0.978087, 'acc_vowel': 0.99311, 'acc_consonant': 0.993011, 'loss_grapheme': 0.095368, 'loss_vowel': 0.041034, 'loss_consonant': 0.034541}\n",
      "  317 | 0.000006 | 091648/160635 | 3.9712 | 1.4046 |\n",
      "val: {'recall': 0.983847, 'recall_grapheme': 0.977301, 'recall_vowel': 0.991846, 'recall_consonant': 0.988941, 'acc_grapheme': 0.978311, 'acc_vowel': 0.992862, 'acc_consonant': 0.992812, 'loss_grapheme': 0.09511, 'loss_vowel': 0.040099, 'loss_consonant': 0.0336}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  318 | 0.000008 | 033792/160635 | 0.0050 | 1.8017 |\n",
      "val: {'recall': 0.983994, 'recall_grapheme': 0.97747, 'recall_vowel': 0.992259, 'recall_consonant': 0.988777, 'acc_grapheme': 0.978062, 'acc_vowel': 0.993284, 'acc_consonant': 0.992886, 'loss_grapheme': 0.09685, 'loss_vowel': 0.04277, 'loss_consonant': 0.036739}\n",
      "  318 | 0.000010 | 136192/160635 | 3.7779 | 1.6133 |\n",
      "val: {'recall': 0.983665, 'recall_grapheme': 0.977096, 'recall_vowel': 0.991746, 'recall_consonant': 0.988723, 'acc_grapheme': 0.977565, 'acc_vowel': 0.992787, 'acc_consonant': 0.992812, 'loss_grapheme': 0.09708, 'loss_vowel': 0.04262, 'loss_consonant': 0.03578}\n",
      "  319 | 0.000013 | 078336/160635 | 0.0146 | 1.3104 |\n",
      "val: {'recall': 0.983448, 'recall_grapheme': 0.976634, 'recall_vowel': 0.992005, 'recall_consonant': 0.988519, 'acc_grapheme': 0.977764, 'acc_vowel': 0.993085, 'acc_consonant': 0.992762, 'loss_grapheme': 0.095862, 'loss_vowel': 0.039059, 'loss_consonant': 0.033053}\n",
      "  320 | 0.000015 | 020480/160635 | 3.1414 | 1.9767 |\n",
      "val: {'recall': 0.983364, 'recall_grapheme': 0.977085, 'recall_vowel': 0.991927, 'recall_consonant': 0.987358, 'acc_grapheme': 0.977689, 'acc_vowel': 0.992936, 'acc_consonant': 0.992538, 'loss_grapheme': 0.10216, 'loss_vowel': 0.048711, 'loss_consonant': 0.040424}\n",
      "  320 | 0.000017 | 122880/160635 | 3.4279 | 1.4797 |\n",
      "val: {'recall': 0.983512, 'recall_grapheme': 0.977178, 'recall_vowel': 0.991942, 'recall_consonant': 0.987749, 'acc_grapheme': 0.977341, 'acc_vowel': 0.992862, 'acc_consonant': 0.992687, 'loss_grapheme': 0.097983, 'loss_vowel': 0.041574, 'loss_consonant': 0.035924}\n",
      "  321 | 0.000019 | 065024/160635 | 0.0053 | 1.2929 |\n",
      "val: {'recall': 0.983582, 'recall_grapheme': 0.976678, 'recall_vowel': 0.991781, 'recall_consonant': 0.989189, 'acc_grapheme': 0.977565, 'acc_vowel': 0.993011, 'acc_consonant': 0.992712, 'loss_grapheme': 0.094898, 'loss_vowel': 0.03885, 'loss_consonant': 0.032991}\n",
      "  322 | 0.000020 | 007168/160635 | 3.4662 | 1.6435 |\n",
      "val: {'recall': 0.983452, 'recall_grapheme': 0.977548, 'recall_vowel': 0.992071, 'recall_consonant': 0.98664, 'acc_grapheme': 0.977465, 'acc_vowel': 0.99326, 'acc_consonant': 0.992638, 'loss_grapheme': 0.099351, 'loss_vowel': 0.042694, 'loss_consonant': 0.037154}\n",
      "  322 | 0.000020 | 109568/160635 | 0.0084 | 1.5393 |\n",
      "val: {'recall': 0.983646, 'recall_grapheme': 0.976988, 'recall_vowel': 0.992025, 'recall_consonant': 0.988583, 'acc_grapheme': 0.977242, 'acc_vowel': 0.99311, 'acc_consonant': 0.992513, 'loss_grapheme': 0.101107, 'loss_vowel': 0.042542, 'loss_consonant': 0.036496}\n",
      "  323 | 0.000020 | 051712/160635 | 0.0020 | 1.0811 |\n",
      "val: {'recall': 0.983242, 'recall_grapheme': 0.977046, 'recall_vowel': 0.992078, 'recall_consonant': 0.986797, 'acc_grapheme': 0.976918, 'acc_vowel': 0.993085, 'acc_consonant': 0.992364, 'loss_grapheme': 0.09938, 'loss_vowel': 0.037173, 'loss_consonant': 0.032932}\n",
      "  323 | 0.000019 | 096256/160635 | 0.0041 | 1.2945 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-54080d9d42c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-2329e2f97030>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_no_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpost_backward_models_are_masters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_models_are_masters\u001b[0;34m(scaler, params, stashed_grads, scale_override)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mstashed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mgrads_needing_unscale_with_stash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Clear the stash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[1;32m    176\u001b[0m                                  \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# 1./scale,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                                  \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstashed_have_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 1.0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                  0) # check only arg 0, aka the incoming model grads, for infs\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             self.unscale_with_stashed_python(model_grads,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, op, noop_flag_buffer, tensor_lists, *args)\u001b[0m\n\u001b[1;32m     28\u001b[0m                   \u001b[0mnoop_flag_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                   \u001b[0mtensor_lists\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                   *args)\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
