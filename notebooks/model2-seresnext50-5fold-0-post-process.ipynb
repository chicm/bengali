{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengaliai-cv19.zip\t   test_image_data_3.parquet\r\n",
      "class_map.csv\t\t   train.csv\r\n",
      "sample_submission.csv\t   train_image_data_0.parquet\r\n",
      "test.csv\t\t   train_image_data_1.parquet\r\n",
      "test_image_data_0.parquet  train_image_data_2.parquet\r\n",
      "test_image_data_1.parquet  train_image_data_3.parquet\r\n",
      "test_image_data_2.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/chicm/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet_1(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengali-ensemble.ipynb\r\n",
      "bengali-inference.ipynb\r\n",
      "eda.ipynb\r\n",
      "efficient-net.ipynb\r\n",
      "Inference.ipynb\r\n",
      "model1-efficient-b5-fold1-cv9841-lb9725.ipynb\r\n",
      "model1-efficient-b5-fold1-focal_loss.ipynb\r\n",
      "model1-se_resnext50-5fold-0.ipynb\r\n",
      "model2-efficientnet-b5-5fold-1.ipynb\r\n",
      "model2-seresnext50-5fold-0.ipynb\r\n",
      "model2-seresnext50-5fold-0-post-process.ipynb\r\n",
      "model2-seresnext50-5fold-2.ipynb\r\n",
      "models\r\n",
      "over9000\r\n",
      "post_process.pth\r\n",
      "single-model-apex-cutmix-5fold-0-se154.ipynb\r\n",
      "single-model-apex-cutmix-5fold-1-efficient-b6.ipynb\r\n",
      "single-model-apex-cutmix-5fold-4-seresnext101.ipynb\r\n",
      "single-model-apex-cutmix-efficient-densenet.ipynb\r\n",
      "single-model-apex-cutmix-lb9699-cv9848-224-mixup.ipynb\r\n",
      "single-model-apex-cutmix-lb9699-cv9848.ipynb\r\n",
      "single_model.ipynb\r\n",
      "single_model_lb9680_cv9828.ipynb\r\n",
      "tmpx\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_dict = torch.load('post_process.pth')\n",
    "vowel_dict = post_process_dict['vowel_dict']\n",
    "consonant_dict = post_process_dict['consonant_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: tensor([], dtype=torch.int64),\n",
       " 1: tensor([  0,   1,   2,   5,   7,   8,  10,  11,  12,  14,  15,  16,  17,  18,\n",
       "          19,  20,  21,  24,  25,  26,  27,  28,  30,  31,  32,  33,  34,  35,\n",
       "          36,  37,  39,  40,  41,  43,  44,  45,  46,  47,  49,  50,  51,  52,\n",
       "          53,  54,  56,  57,  58,  59,  60,  61,  62,  63,  65,  66,  67,  68,\n",
       "          69,  70,  71,  73,  74,  75,  76,  77,  78,  80,  81,  82,  83,  84,\n",
       "          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  97,  98,  99,\n",
       "         100, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "         146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161,\n",
       "         162, 163, 164, 165, 166, 167]),\n",
       " 2: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,\n",
       "          15,  16,  17,  18,  19,  20,  24,  25,  26,  27,  28,  30,  31,  32,\n",
       "          33,  34,  35,  36,  37,  39,  40,  41,  44,  45,  46,  47,  49,  50,\n",
       "          51,  52,  54,  55,  57,  58,  60,  61,  62,  63,  66,  67,  68,  69,\n",
       "          70,  73,  77,  78,  82,  83,  84,  85,  87,  88,  89,  90,  91,  92,\n",
       "          93,  94,  95,  97,  98,  99, 100, 101, 102, 104, 105, 106, 108, 109,\n",
       "         110, 112, 114, 116, 117, 118, 119, 121, 123, 125, 126, 127, 129, 130,\n",
       "         131, 132, 134, 135, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148,\n",
       "         150, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165,\n",
       "         166, 167]),\n",
       " 3: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "          44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "          58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  72,\n",
       "          73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
       "          87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "         101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167]),\n",
       " 4: tensor([  0,   1,   3,   4,   5,   6,   7,   8,  10,  11,  12,  14,  15,  16,\n",
       "          17,  19,  20,  21,  24,  26,  27,  30,  31,  32,  33,  34,  35,  36,\n",
       "          37,  39,  40,  41,  44,  45,  46,  47,  48,  49,  50,  51,  52,  54,\n",
       "          57,  60,  61,  62,  63,  66,  67,  68,  69,  73,  74,  75,  77,  78,\n",
       "          80,  82,  83,  84,  85,  87,  88,  90,  93,  94,  95,  97,  98,  99,\n",
       "         100, 102, 104, 105, 108, 109, 110, 111, 114, 116, 117, 118, 119, 120,\n",
       "         121, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138,\n",
       "         140, 143, 144, 145, 146, 150, 152, 154, 155, 156, 157, 158, 160, 161,\n",
       "         162, 163, 164, 165, 166]),\n",
       " 5: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,\n",
       "          16,  17,  18,  19,  20,  21,  24,  25,  26,  27,  28,  30,  31,  32,\n",
       "          33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  44,  45,  46,  47,\n",
       "          48,  49,  50,  51,  52,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
       "          65,  66,  67,  68,  69,  70,  73,  74,  75,  76,  78,  80,  81,  82,\n",
       "          84,  87,  88,  90,  92,  93,  94,  95,  97,  98,  99, 100, 101, 102,\n",
       "         104, 105, 106, 108, 109, 110, 111, 112, 114, 116, 118, 120, 121, 122,\n",
       "         123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137,\n",
       "         138, 139, 142, 143, 145, 146, 151, 152, 154, 155, 156, 157, 158, 160,\n",
       "         161, 162, 163, 164, 165, 166, 167]),\n",
       " 6: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  14,\n",
       "          15,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,\n",
       "          30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
       "          44,  45,  46,  47,  48,  49,  50,  51,  52,  54,  55,  56,  57,  58,\n",
       "          59,  60,  61,  62,  63,  65,  66,  67,  68,  69,  70,  71,  73,  74,\n",
       "          75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
       "          89,  90,  91,  92,  93,  94,  95,  97,  98,  99, 100, 101, 102, 104,\n",
       "         105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
       "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "         134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
       "         148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
       "         163, 164, 165, 166, 167])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consonant_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(output0, output1, output2):\n",
    "    #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    output1 = torch.softmax(output1, dim=1)   \n",
    "    output2 = torch.softmax(output2, dim=1)        \n",
    "    \n",
    "    score_vowel, preds_vowel = torch.max(output1, dim=1)\n",
    "    score_consonant, preds_consonant = torch.max(output2, dim=1)\n",
    "    \n",
    "    for i in range(output0.size(0)):\n",
    "        #if preds_vowel[i].item() != 0:\n",
    "        if score_vowel[i].item() > 0.3:\n",
    "            output0[i, vowel_dict[preds_vowel[i].item()]] = -100000.\n",
    "        #if preds_consonant[i].item() != 0:\n",
    "        if score_consonant[i].item() > 0.3:\n",
    "            output0[i, consonant_dict[preds_consonant[i].item()]] = -100000.\n",
    "    preds_grapheme = torch.max(output0, dim=1)[1]\n",
    "    \n",
    "    return preds_grapheme, preds_vowel, preds_consonant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader):\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds = get_predictions(outputs[0], outputs[1], outputs[2])\n",
    "            preds0.append(preds[0])\n",
    "            preds1.append(preds[1])\n",
    "            preds2.append(preds[2])\n",
    "            \n",
    "            #preds0.append(torch.max(split_outputs[0], dim=1)[1])\n",
    "            #preds1.append(torch.max(split_outputs[1], dim=1)[1])\n",
    "            #preds2.append(torch.max(split_outputs[2], dim=1)[1])\n",
    "\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.985201, 'recall_grapheme': 0.977361, 'recall_vowel': 0.992751, 'recall_consonant': 0.993332, 'acc_grapheme': 0.977736, 'acc_vowel': 0.993713, 'acc_consonant': 0.993042, 'loss_grapheme': 201.399638, 'loss_vowel': 0.08522, 'loss_consonant': 0.065171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(validate(model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.985201, 'recall_grapheme': 0.977361, 'recall_vowel': 0.992751, 'recall_consonant': 0.993332, 'acc_grapheme': 0.977736, 'acc_vowel': 0.993713, 'acc_consonant': 0.993042, 'loss_grapheme': 201.399638, 'loss_vowel': 0.08522, 'loss_consonant': 0.065171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(validate(model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.985159, 'recall_grapheme': 0.977276, 'recall_vowel': 0.992751, 'recall_consonant': 0.993332, 'acc_grapheme': 0.977711, 'acc_vowel': 0.993713, 'acc_consonant': 0.993042, 'loss_grapheme': 198.914883, 'loss_vowel': 0.08522, 'loss_consonant': 0.065171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(validate(model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29251408144274393"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.9:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                #img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                #loss = mixup_criterion(outputs, targets)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model2_se_resnext50_fold0.pth'\n",
    "args.predict = False\n",
    "args.optim = 'RAdam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 15\n",
    "args.factor = 0.6\n",
    "args.patience = 0\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160596, 5) (40244, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model2_se_resnext50_fold0.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model2_se_resnext50_fold0.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.984116, 'recall_grapheme': 0.97519, 'recall_vowel': 0.992751, 'recall_consonant': 0.993332, 'acc_grapheme': 0.977313, 'acc_vowel': 0.993713, 'acc_consonant': 0.993042, 'loss_grapheme': 0.142988, 'loss_vowel': 0.08522, 'loss_consonant': 0.065171}\n"
     ]
    }
   ],
   "source": [
    "print(validate(model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.983745, 'recall_grapheme': 0.974981, 'recall_vowel': 0.992261, 'recall_consonant': 0.992757, 'acc_grapheme': 0.976046, 'acc_vowel': 0.993167, 'acc_consonant': 0.992297, 'loss_grapheme': 0.103041, 'loss_vowel': 0.042857, 'loss_consonant': 0.038426}\n",
      "    1 | 0.000020 | 045056/160596 | 2.0154 | 2.4724 |\n",
      "val: {'recall': 0.982875, 'recall_grapheme': 0.973581, 'recall_vowel': 0.991425, 'recall_consonant': 0.992913, 'acc_grapheme': 0.975375, 'acc_vowel': 0.992769, 'acc_consonant': 0.991676, 'loss_grapheme': 0.185012, 'loss_vowel': 0.117962, 'loss_consonant': 0.087933}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000020 | 090112/160596 | 4.5338 | 2.7222 |\n",
      "val: {'recall': 0.98232, 'recall_grapheme': 0.972734, 'recall_vowel': 0.990797, 'recall_consonant': 0.993016, 'acc_grapheme': 0.974679, 'acc_vowel': 0.992396, 'acc_consonant': 0.991527, 'loss_grapheme': 0.230635, 'loss_vowel': 0.156667, 'loss_consonant': 0.114001}\n",
      "    3 | 0.000019 | 135168/160596 | 4.5807 | 2.9073 |\n",
      "val: {'recall': 0.981842, 'recall_grapheme': 0.971744, 'recall_vowel': 0.991033, 'recall_consonant': 0.992845, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992446, 'acc_consonant': 0.991328, 'loss_grapheme': 0.296629, 'loss_vowel': 0.20651, 'loss_consonant': 0.144226}\n",
      "    5 | 0.000018 | 020480/160596 | 0.0051 | 1.9522 |\n",
      "val: {'recall': 0.983169, 'recall_grapheme': 0.974084, 'recall_vowel': 0.991507, 'recall_consonant': 0.993001, 'acc_grapheme': 0.975499, 'acc_vowel': 0.992695, 'acc_consonant': 0.991899, 'loss_grapheme': 0.12782, 'loss_vowel': 0.07325, 'loss_consonant': 0.057126}\n",
      "    6 | 0.000017 | 065536/160596 | 4.3425 | 2.9459 |\n",
      "val: {'recall': 0.981912, 'recall_grapheme': 0.971611, 'recall_vowel': 0.991097, 'recall_consonant': 0.993328, 'acc_grapheme': 0.974232, 'acc_vowel': 0.992471, 'acc_consonant': 0.991502, 'loss_grapheme': 0.325465, 'loss_vowel': 0.231891, 'loss_consonant': 0.158164}\n",
      "    7 | 0.000015 | 110592/160596 | 3.8064 | 2.6722 |\n",
      "val: {'recall': 0.981989, 'recall_grapheme': 0.972007, 'recall_vowel': 0.991183, 'recall_consonant': 0.992761, 'acc_grapheme': 0.974853, 'acc_vowel': 0.992446, 'acc_consonant': 0.991229, 'loss_grapheme': 0.297209, 'loss_vowel': 0.199946, 'loss_consonant': 0.13838}\n",
      "    8 | 0.000013 | 155648/160596 | 4.7564 | 2.8763 |\n",
      "val: {'recall': 0.982595, 'recall_grapheme': 0.972928, 'recall_vowel': 0.99147, 'recall_consonant': 0.993054, 'acc_grapheme': 0.974754, 'acc_vowel': 0.992521, 'acc_consonant': 0.991601, 'loss_grapheme': 0.212442, 'loss_vowel': 0.147427, 'loss_consonant': 0.106137}\n",
      "   10 | 0.000011 | 040960/160596 | 3.8731 | 2.5407 |\n",
      "val: {'recall': 0.983322, 'recall_grapheme': 0.974281, 'recall_vowel': 0.991763, 'recall_consonant': 0.992965, 'acc_grapheme': 0.975723, 'acc_vowel': 0.992819, 'acc_consonant': 0.992049, 'loss_grapheme': 0.14051, 'loss_vowel': 0.0844, 'loss_consonant': 0.064183}\n",
      "   11 | 0.000010 | 086016/160596 | 4.6670 | 2.7121 |\n",
      "val: {'recall': 0.982616, 'recall_grapheme': 0.972827, 'recall_vowel': 0.991607, 'recall_consonant': 0.993205, 'acc_grapheme': 0.975176, 'acc_vowel': 0.992819, 'acc_consonant': 0.991899, 'loss_grapheme': 0.139941, 'loss_vowel': 0.086368, 'loss_consonant': 0.067576}\n",
      "   12 | 0.000008 | 131072/160596 | 1.6786 | 2.9275 |\n",
      "val: {'recall': 0.982403, 'recall_grapheme': 0.97264, 'recall_vowel': 0.991165, 'recall_consonant': 0.993169, 'acc_grapheme': 0.974853, 'acc_vowel': 0.992347, 'acc_consonant': 0.9918, 'loss_grapheme': 0.243412, 'loss_vowel': 0.16315, 'loss_consonant': 0.116526}\n",
      "   14 | 0.000006 | 016384/160596 | 3.6581 | 2.8431 |\n",
      "val: {'recall': 0.982512, 'recall_grapheme': 0.972955, 'recall_vowel': 0.991159, 'recall_consonant': 0.992976, 'acc_grapheme': 0.974655, 'acc_vowel': 0.992521, 'acc_consonant': 0.991576, 'loss_grapheme': 0.292667, 'loss_vowel': 0.200109, 'loss_consonant': 0.138021}\n",
      "   15 | 0.000004 | 061440/160596 | 3.8215 | 2.8782 |\n",
      "val: {'recall': 0.982565, 'recall_grapheme': 0.973073, 'recall_vowel': 0.991055, 'recall_consonant': 0.993059, 'acc_grapheme': 0.974878, 'acc_vowel': 0.992396, 'acc_consonant': 0.991676, 'loss_grapheme': 0.247855, 'loss_vowel': 0.170587, 'loss_consonant': 0.120528}\n",
      "   16 | 0.000003 | 106496/160596 | 2.8516 | 2.7281 |\n",
      "val: {'recall': 0.982544, 'recall_grapheme': 0.972933, 'recall_vowel': 0.991294, 'recall_consonant': 0.993015, 'acc_grapheme': 0.974555, 'acc_vowel': 0.992595, 'acc_consonant': 0.991725, 'loss_grapheme': 0.286211, 'loss_vowel': 0.198196, 'loss_consonant': 0.136845}\n",
      "   17 | 0.000002 | 151552/160596 | 0.0071 | 2.8827 |\n",
      "val: {'recall': 0.982593, 'recall_grapheme': 0.973121, 'recall_vowel': 0.991244, 'recall_consonant': 0.992886, 'acc_grapheme': 0.974804, 'acc_vowel': 0.99262, 'acc_consonant': 0.991626, 'loss_grapheme': 0.212364, 'loss_vowel': 0.147493, 'loss_consonant': 0.106365}\n",
      "   19 | 0.000001 | 036864/160596 | 3.3755 | 2.7169 |\n",
      "val: {'recall': 0.982328, 'recall_grapheme': 0.972487, 'recall_vowel': 0.991317, 'recall_consonant': 0.99302, 'acc_grapheme': 0.974679, 'acc_vowel': 0.992421, 'acc_consonant': 0.99175, 'loss_grapheme': 0.263914, 'loss_vowel': 0.180191, 'loss_consonant': 0.127584}\n",
      "   20 | 0.000001 | 081920/160596 | 3.2394 | 2.7715 |\n",
      "val: {'recall': 0.982591, 'recall_grapheme': 0.972964, 'recall_vowel': 0.991172, 'recall_consonant': 0.993265, 'acc_grapheme': 0.974829, 'acc_vowel': 0.992545, 'acc_consonant': 0.99175, 'loss_grapheme': 0.302302, 'loss_vowel': 0.200621, 'loss_consonant': 0.137868}\n",
      "   21 | 0.000001 | 126976/160596 | 2.3086 | 2.5832 |\n",
      "val: {'recall': 0.98279, 'recall_grapheme': 0.973361, 'recall_vowel': 0.991255, 'recall_consonant': 0.993181, 'acc_grapheme': 0.974928, 'acc_vowel': 0.992719, 'acc_consonant': 0.991775, 'loss_grapheme': 0.24922, 'loss_vowel': 0.174276, 'loss_consonant': 0.120981}\n",
      "   23 | 0.000002 | 012288/160596 | 0.0079 | 1.8341 |\n",
      "val: {'recall': 0.983222, 'recall_grapheme': 0.974075, 'recall_vowel': 0.991743, 'recall_consonant': 0.992994, 'acc_grapheme': 0.975425, 'acc_vowel': 0.992844, 'acc_consonant': 0.992272, 'loss_grapheme': 0.139633, 'loss_vowel': 0.081953, 'loss_consonant': 0.063724}\n",
      "   24 | 0.000003 | 057344/160596 | 4.4478 | 2.6079 |\n",
      "val: {'recall': 0.983092, 'recall_grapheme': 0.973813, 'recall_vowel': 0.991653, 'recall_consonant': 0.993087, 'acc_grapheme': 0.975301, 'acc_vowel': 0.992943, 'acc_consonant': 0.992123, 'loss_grapheme': 0.154262, 'loss_vowel': 0.097282, 'loss_consonant': 0.073595}\n",
      "   25 | 0.000004 | 102400/160596 | 2.6795 | 2.2730 |\n",
      "val: {'recall': 0.983228, 'recall_grapheme': 0.973998, 'recall_vowel': 0.991856, 'recall_consonant': 0.993061, 'acc_grapheme': 0.975599, 'acc_vowel': 0.992968, 'acc_consonant': 0.992123, 'loss_grapheme': 0.16163, 'loss_vowel': 0.098067, 'loss_consonant': 0.073963}\n",
      "   26 | 0.000006 | 147456/160596 | 3.0530 | 2.7303 |\n",
      "val: {'recall': 0.982829, 'recall_grapheme': 0.973671, 'recall_vowel': 0.990853, 'recall_consonant': 0.993122, 'acc_grapheme': 0.9754, 'acc_vowel': 0.992496, 'acc_consonant': 0.991725, 'loss_grapheme': 0.246421, 'loss_vowel': 0.168959, 'loss_consonant': 0.117966}\n",
      "   28 | 0.000008 | 032768/160596 | 4.3620 | 2.9802 |\n",
      "val: {'recall': 0.982609, 'recall_grapheme': 0.973234, 'recall_vowel': 0.990976, 'recall_consonant': 0.992991, 'acc_grapheme': 0.974978, 'acc_vowel': 0.992421, 'acc_consonant': 0.991576, 'loss_grapheme': 0.241484, 'loss_vowel': 0.161914, 'loss_consonant': 0.115172}\n",
      "   29 | 0.000010 | 077824/160596 | 1.5517 | 2.8744 |\n",
      "val: {'recall': 0.982463, 'recall_grapheme': 0.972646, 'recall_vowel': 0.991455, 'recall_consonant': 0.993106, 'acc_grapheme': 0.97463, 'acc_vowel': 0.992645, 'acc_consonant': 0.991725, 'loss_grapheme': 0.260555, 'loss_vowel': 0.173415, 'loss_consonant': 0.121757}\n",
      "   30 | 0.000011 | 122880/160596 | 0.0117 | 2.2974 |\n",
      "val: {'recall': 0.98322, 'recall_grapheme': 0.974186, 'recall_vowel': 0.991554, 'recall_consonant': 0.992953, 'acc_grapheme': 0.975649, 'acc_vowel': 0.992893, 'acc_consonant': 0.992173, 'loss_grapheme': 0.123197, 'loss_vowel': 0.068061, 'loss_consonant': 0.054348}\n",
      "   32 | 0.000013 | 008192/160596 | 3.3757 | 2.2591 |\n",
      "val: {'recall': 0.982775, 'recall_grapheme': 0.97341, 'recall_vowel': 0.991331, 'recall_consonant': 0.992951, 'acc_grapheme': 0.975276, 'acc_vowel': 0.992744, 'acc_consonant': 0.992024, 'loss_grapheme': 0.19153, 'loss_vowel': 0.124381, 'loss_consonant': 0.093097}\n",
      "   33 | 0.000015 | 053248/160596 | 3.5293 | 2.7026 |\n",
      "val: {'recall': 0.982851, 'recall_grapheme': 0.973383, 'recall_vowel': 0.991558, 'recall_consonant': 0.993079, 'acc_grapheme': 0.974779, 'acc_vowel': 0.99267, 'acc_consonant': 0.991775, 'loss_grapheme': 0.250469, 'loss_vowel': 0.168782, 'loss_consonant': 0.117949}\n",
      "   34 | 0.000017 | 098304/160596 | 3.2128 | 2.6389 |\n",
      "val: {'recall': 0.982797, 'recall_grapheme': 0.973379, 'recall_vowel': 0.991418, 'recall_consonant': 0.993013, 'acc_grapheme': 0.974829, 'acc_vowel': 0.992844, 'acc_consonant': 0.991725, 'loss_grapheme': 0.179721, 'loss_vowel': 0.118541, 'loss_consonant': 0.088106}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000018 | 143360/160596 | 3.1996 | 2.6377 |\n",
      "val: {'recall': 0.982709, 'recall_grapheme': 0.973953, 'recall_vowel': 0.991048, 'recall_consonant': 0.991884, 'acc_grapheme': 0.975226, 'acc_vowel': 0.992869, 'acc_consonant': 0.991502, 'loss_grapheme': 0.230154, 'loss_vowel': 0.15357, 'loss_consonant': 0.111495}\n",
      "   37 | 0.000019 | 028672/160596 | 3.2622 | 3.1381 |\n",
      "val: {'recall': 0.982646, 'recall_grapheme': 0.973213, 'recall_vowel': 0.991256, 'recall_consonant': 0.992902, 'acc_grapheme': 0.974754, 'acc_vowel': 0.992695, 'acc_consonant': 0.991701, 'loss_grapheme': 0.22379, 'loss_vowel': 0.153706, 'loss_consonant': 0.108864}\n",
      "   38 | 0.000020 | 073728/160596 | 0.0069 | 2.6257 |\n",
      "val: {'recall': 0.983266, 'recall_grapheme': 0.97406, 'recall_vowel': 0.991862, 'recall_consonant': 0.993083, 'acc_grapheme': 0.975673, 'acc_vowel': 0.992968, 'acc_consonant': 0.992173, 'loss_grapheme': 0.149001, 'loss_vowel': 0.090988, 'loss_consonant': 0.069694}\n",
      "   39 | 0.000020 | 118784/160596 | 4.1178 | 2.5157 |\n",
      "val: {'recall': 0.983133, 'recall_grapheme': 0.973966, 'recall_vowel': 0.991457, 'recall_consonant': 0.993141, 'acc_grapheme': 0.975649, 'acc_vowel': 0.993067, 'acc_consonant': 0.991949, 'loss_grapheme': 0.16007, 'loss_vowel': 0.104717, 'loss_consonant': 0.077806}\n",
      "   41 | 0.000020 | 004096/160596 | 3.4632 | 2.8456 |\n",
      "val: {'recall': 0.982472, 'recall_grapheme': 0.973475, 'recall_vowel': 0.991383, 'recall_consonant': 0.991556, 'acc_grapheme': 0.975301, 'acc_vowel': 0.992297, 'acc_consonant': 0.991825, 'loss_grapheme': 0.269324, 'loss_vowel': 0.182684, 'loss_consonant': 0.129039}\n",
      "   42 | 0.000019 | 049152/160596 | 1.7764 | 2.8794 |\n",
      "val: {'recall': 0.982523, 'recall_grapheme': 0.972813, 'recall_vowel': 0.991517, 'recall_consonant': 0.99295, 'acc_grapheme': 0.974456, 'acc_vowel': 0.992645, 'acc_consonant': 0.991452, 'loss_grapheme': 0.303195, 'loss_vowel': 0.21043, 'loss_consonant': 0.149067}\n",
      "   43 | 0.000018 | 094208/160596 | 2.7352 | 2.8203 |\n",
      "val: {'recall': 0.982903, 'recall_grapheme': 0.973959, 'recall_vowel': 0.991935, 'recall_consonant': 0.991758, 'acc_grapheme': 0.9754, 'acc_vowel': 0.992844, 'acc_consonant': 0.99185, 'loss_grapheme': 0.20978, 'loss_vowel': 0.140823, 'loss_consonant': 0.10345}\n",
      "   44 | 0.000017 | 139264/160596 | 2.8988 | 2.7259 |\n",
      "val: {'recall': 0.983127, 'recall_grapheme': 0.974313, 'recall_vowel': 0.991043, 'recall_consonant': 0.992838, 'acc_grapheme': 0.975499, 'acc_vowel': 0.992595, 'acc_consonant': 0.991651, 'loss_grapheme': 0.274604, 'loss_vowel': 0.185743, 'loss_consonant': 0.133487}\n",
      "   46 | 0.000015 | 024576/160596 | 0.9410 | 3.1395 |\n",
      "val: {'recall': 0.982601, 'recall_grapheme': 0.973638, 'recall_vowel': 0.99141, 'recall_consonant': 0.991718, 'acc_grapheme': 0.975574, 'acc_vowel': 0.992496, 'acc_consonant': 0.99175, 'loss_grapheme': 0.263929, 'loss_vowel': 0.180974, 'loss_consonant': 0.127864}\n",
      "   47 | 0.000013 | 069632/160596 | 4.0169 | 2.6626 |\n",
      "val: {'recall': 0.982292, 'recall_grapheme': 0.972951, 'recall_vowel': 0.991593, 'recall_consonant': 0.991671, 'acc_grapheme': 0.975276, 'acc_vowel': 0.992769, 'acc_consonant': 0.99185, 'loss_grapheme': 0.200308, 'loss_vowel': 0.134142, 'loss_consonant': 0.097628}\n",
      "   48 | 0.000011 | 114688/160596 | 3.4237 | 2.9113 |\n",
      "val: {'recall': 0.982287, 'recall_grapheme': 0.972956, 'recall_vowel': 0.991285, 'recall_consonant': 0.991953, 'acc_grapheme': 0.974953, 'acc_vowel': 0.99267, 'acc_consonant': 0.991626, 'loss_grapheme': 0.283356, 'loss_vowel': 0.19988, 'loss_consonant': 0.142115}\n",
      "   49 | 0.000010 | 159744/160596 | 3.2890 | 2.9804 |\n",
      "val: {'recall': 0.982508, 'recall_grapheme': 0.973567, 'recall_vowel': 0.991215, 'recall_consonant': 0.991682, 'acc_grapheme': 0.975301, 'acc_vowel': 0.992446, 'acc_consonant': 0.991974, 'loss_grapheme': 0.211501, 'loss_vowel': 0.141674, 'loss_consonant': 0.101777}\n",
      "   51 | 0.000008 | 045056/160596 | 4.2580 | 2.8448 |\n",
      "val: {'recall': 0.982329, 'recall_grapheme': 0.972985, 'recall_vowel': 0.991698, 'recall_consonant': 0.991646, 'acc_grapheme': 0.975127, 'acc_vowel': 0.99267, 'acc_consonant': 0.991775, 'loss_grapheme': 0.227741, 'loss_vowel': 0.152033, 'loss_consonant': 0.109507}\n",
      "   52 | 0.000006 | 090112/160596 | 2.4662 | 2.4658 |\n",
      "val: {'recall': 0.983304, 'recall_grapheme': 0.974148, 'recall_vowel': 0.991883, 'recall_consonant': 0.993036, 'acc_grapheme': 0.975847, 'acc_vowel': 0.992943, 'acc_consonant': 0.992049, 'loss_grapheme': 0.185148, 'loss_vowel': 0.12162, 'loss_consonant': 0.088326}\n",
      "   53 | 0.000004 | 135168/160596 | 3.4370 | 2.6945 |\n",
      "val: {'recall': 0.982565, 'recall_grapheme': 0.97313, 'recall_vowel': 0.991031, 'recall_consonant': 0.992966, 'acc_grapheme': 0.975176, 'acc_vowel': 0.992322, 'acc_consonant': 0.991875, 'loss_grapheme': 0.28195, 'loss_vowel': 0.195329, 'loss_consonant': 0.134185}\n",
      "   55 | 0.000003 | 020480/160596 | 4.0377 | 3.2808 |\n",
      "val: {'recall': 0.982677, 'recall_grapheme': 0.973138, 'recall_vowel': 0.991275, 'recall_consonant': 0.993157, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992521, 'acc_consonant': 0.991651, 'loss_grapheme': 0.298965, 'loss_vowel': 0.206409, 'loss_consonant': 0.140451}\n",
      "   56 | 0.000002 | 065536/160596 | 0.0075 | 2.6591 |\n",
      "val: {'recall': 0.983304, 'recall_grapheme': 0.974226, 'recall_vowel': 0.99175, 'recall_consonant': 0.993016, 'acc_grapheme': 0.976121, 'acc_vowel': 0.992943, 'acc_consonant': 0.992049, 'loss_grapheme': 0.182353, 'loss_vowel': 0.120503, 'loss_consonant': 0.088171}\n",
      "   57 | 0.000001 | 110592/160596 | 0.0051 | 2.6680 |\n",
      "val: {'recall': 0.983029, 'recall_grapheme': 0.974256, 'recall_vowel': 0.991803, 'recall_consonant': 0.991802, 'acc_grapheme': 0.97617, 'acc_vowel': 0.992844, 'acc_consonant': 0.992024, 'loss_grapheme': 0.181199, 'loss_vowel': 0.117432, 'loss_consonant': 0.085826}\n",
      "   58 | 0.000001 | 155648/160596 | 4.4105 | 2.7797 |\n",
      "val: {'recall': 0.982206, 'recall_grapheme': 0.97231, 'recall_vowel': 0.991023, 'recall_consonant': 0.993179, 'acc_grapheme': 0.974804, 'acc_vowel': 0.992347, 'acc_consonant': 0.991502, 'loss_grapheme': 0.365356, 'loss_vowel': 0.253576, 'loss_consonant': 0.169759}\n",
      "   60 | 0.000001 | 040960/160596 | 2.1021 | 2.9065 |\n",
      "val: {'recall': 0.982947, 'recall_grapheme': 0.97355, 'recall_vowel': 0.991623, 'recall_consonant': 0.993065, 'acc_grapheme': 0.975624, 'acc_vowel': 0.992869, 'acc_consonant': 0.991676, 'loss_grapheme': 0.250548, 'loss_vowel': 0.170263, 'loss_consonant': 0.120228}\n",
      "   61 | 0.000002 | 086016/160596 | 0.0044 | 2.6948 |\n",
      "val: {'recall': 0.983041, 'recall_grapheme': 0.974152, 'recall_vowel': 0.992059, 'recall_consonant': 0.991803, 'acc_grapheme': 0.975996, 'acc_vowel': 0.992869, 'acc_consonant': 0.992148, 'loss_grapheme': 0.162414, 'loss_vowel': 0.101562, 'loss_consonant': 0.075796}\n",
      "   62 | 0.000003 | 131072/160596 | 0.0091 | 2.8974 |\n",
      "val: {'recall': 0.98324, 'recall_grapheme': 0.974106, 'recall_vowel': 0.991745, 'recall_consonant': 0.993005, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992918, 'acc_consonant': 0.992148, 'loss_grapheme': 0.163978, 'loss_vowel': 0.106115, 'loss_consonant': 0.080958}\n",
      "   64 | 0.000004 | 016384/160596 | 2.1703 | 2.2902 |\n",
      "val: {'recall': 0.983367, 'recall_grapheme': 0.974298, 'recall_vowel': 0.991884, 'recall_consonant': 0.992986, 'acc_grapheme': 0.975922, 'acc_vowel': 0.992918, 'acc_consonant': 0.992024, 'loss_grapheme': 0.188415, 'loss_vowel': 0.126158, 'loss_consonant': 0.093616}\n",
      "   65 | 0.000006 | 061440/160596 | 0.0075 | 2.4178 |\n",
      "val: {'recall': 0.98347, 'recall_grapheme': 0.974462, 'recall_vowel': 0.992107, 'recall_consonant': 0.992848, 'acc_grapheme': 0.976146, 'acc_vowel': 0.993117, 'acc_consonant': 0.992247, 'loss_grapheme': 0.137731, 'loss_vowel': 0.082188, 'loss_consonant': 0.063336}\n",
      "   66 | 0.000008 | 106496/160596 | 3.5354 | 2.6806 |\n",
      "val: {'recall': 0.982185, 'recall_grapheme': 0.972821, 'recall_vowel': 0.991408, 'recall_consonant': 0.991687, 'acc_grapheme': 0.975102, 'acc_vowel': 0.992769, 'acc_consonant': 0.992272, 'loss_grapheme': 0.203185, 'loss_vowel': 0.138657, 'loss_consonant': 0.10269}\n",
      "   67 | 0.000010 | 151552/160596 | 3.4183 | 2.9506 |\n",
      "val: {'recall': 0.982352, 'recall_grapheme': 0.973236, 'recall_vowel': 0.99113, 'recall_consonant': 0.991805, 'acc_grapheme': 0.97535, 'acc_vowel': 0.992247, 'acc_consonant': 0.991875, 'loss_grapheme': 0.236961, 'loss_vowel': 0.164262, 'loss_consonant': 0.115295}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 0.000011 | 036864/160596 | 3.1474 | 3.0666 |\n",
      "val: {'recall': 0.982213, 'recall_grapheme': 0.973034, 'recall_vowel': 0.991179, 'recall_consonant': 0.991604, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992521, 'acc_consonant': 0.9918, 'loss_grapheme': 0.213629, 'loss_vowel': 0.144392, 'loss_consonant': 0.103826}\n",
      "   70 | 0.000013 | 081920/160596 | 2.9054 | 2.7230 |\n",
      "val: {'recall': 0.982278, 'recall_grapheme': 0.972957, 'recall_vowel': 0.991503, 'recall_consonant': 0.991695, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992695, 'acc_consonant': 0.991825, 'loss_grapheme': 0.208335, 'loss_vowel': 0.140419, 'loss_consonant': 0.101167}\n",
      "   71 | 0.000015 | 126976/160596 | 2.8766 | 2.5745 |\n",
      "val: {'recall': 0.982132, 'recall_grapheme': 0.972578, 'recall_vowel': 0.991637, 'recall_consonant': 0.991734, 'acc_grapheme': 0.974754, 'acc_vowel': 0.992645, 'acc_consonant': 0.991353, 'loss_grapheme': 0.305234, 'loss_vowel': 0.209053, 'loss_consonant': 0.146568}\n",
      "   73 | 0.000017 | 012288/160596 | 4.4477 | 3.5002 |\n",
      "val: {'recall': 0.982274, 'recall_grapheme': 0.972232, 'recall_vowel': 0.9917, 'recall_consonant': 0.992931, 'acc_grapheme': 0.974853, 'acc_vowel': 0.992744, 'acc_consonant': 0.991502, 'loss_grapheme': 0.289601, 'loss_vowel': 0.204528, 'loss_consonant': 0.142761}\n",
      "   74 | 0.000018 | 057344/160596 | 3.1653 | 2.6860 |\n",
      "val: {'recall': 0.982285, 'recall_grapheme': 0.972651, 'recall_vowel': 0.991158, 'recall_consonant': 0.99268, 'acc_grapheme': 0.974729, 'acc_vowel': 0.992471, 'acc_consonant': 0.991875, 'loss_grapheme': 0.275928, 'loss_vowel': 0.191171, 'loss_consonant': 0.130847}\n",
      "   75 | 0.000019 | 102400/160596 | 2.8918 | 2.5257 |\n",
      "val: {'recall': 0.98261, 'recall_grapheme': 0.973249, 'recall_vowel': 0.992306, 'recall_consonant': 0.991638, 'acc_grapheme': 0.975425, 'acc_vowel': 0.992968, 'acc_consonant': 0.991949, 'loss_grapheme': 0.185823, 'loss_vowel': 0.125434, 'loss_consonant': 0.092889}\n",
      "   76 | 0.000020 | 147456/160596 | 0.0059 | 2.6636 |\n",
      "val: {'recall': 0.982263, 'recall_grapheme': 0.972887, 'recall_vowel': 0.991562, 'recall_consonant': 0.991716, 'acc_grapheme': 0.975251, 'acc_vowel': 0.992844, 'acc_consonant': 0.991899, 'loss_grapheme': 0.212724, 'loss_vowel': 0.14618, 'loss_consonant': 0.105803}\n",
      "   78 | 0.000020 | 032768/160596 | 2.7792 | 2.9122 |\n",
      "val: {'recall': 0.982772, 'recall_grapheme': 0.973726, 'recall_vowel': 0.992157, 'recall_consonant': 0.991478, 'acc_grapheme': 0.975748, 'acc_vowel': 0.993117, 'acc_consonant': 0.991875, 'loss_grapheme': 0.261821, 'loss_vowel': 0.170838, 'loss_consonant': 0.119263}\n",
      "   79 | 0.000020 | 077824/160596 | 3.4340 | 2.8693 |\n",
      "val: {'recall': 0.982237, 'recall_grapheme': 0.972877, 'recall_vowel': 0.991489, 'recall_consonant': 0.991704, 'acc_grapheme': 0.975201, 'acc_vowel': 0.992993, 'acc_consonant': 0.991974, 'loss_grapheme': 0.224041, 'loss_vowel': 0.155767, 'loss_consonant': 0.110782}\n",
      "   80 | 0.000019 | 122880/160596 | 2.5506 | 2.5979 |\n",
      "val: {'recall': 0.982917, 'recall_grapheme': 0.973374, 'recall_vowel': 0.991969, 'recall_consonant': 0.99295, 'acc_grapheme': 0.975947, 'acc_vowel': 0.993266, 'acc_consonant': 0.991949, 'loss_grapheme': 0.172871, 'loss_vowel': 0.115861, 'loss_consonant': 0.087226}\n",
      "   82 | 0.000018 | 008192/160596 | 2.8357 | 2.9145 |\n",
      "val: {'recall': 0.982588, 'recall_grapheme': 0.973546, 'recall_vowel': 0.991719, 'recall_consonant': 0.991541, 'acc_grapheme': 0.975574, 'acc_vowel': 0.992819, 'acc_consonant': 0.99175, 'loss_grapheme': 0.258158, 'loss_vowel': 0.17304, 'loss_consonant': 0.122067}\n",
      "   83 | 0.000017 | 053248/160596 | 2.1920 | 2.6531 |\n",
      "val: {'recall': 0.982329, 'recall_grapheme': 0.973149, 'recall_vowel': 0.99112, 'recall_consonant': 0.9919, 'acc_grapheme': 0.976046, 'acc_vowel': 0.993067, 'acc_consonant': 0.991999, 'loss_grapheme': 0.2017, 'loss_vowel': 0.133628, 'loss_consonant': 0.097777}\n",
      "   84 | 0.000015 | 098304/160596 | 3.7482 | 2.7032 |\n",
      "val: {'recall': 0.982412, 'recall_grapheme': 0.973272, 'recall_vowel': 0.991239, 'recall_consonant': 0.991864, 'acc_grapheme': 0.975897, 'acc_vowel': 0.992794, 'acc_consonant': 0.991924, 'loss_grapheme': 0.249464, 'loss_vowel': 0.169788, 'loss_consonant': 0.119502}\n",
      "   85 | 0.000013 | 143360/160596 | 3.5438 | 2.7324 |\n",
      "val: {'recall': 0.982285, 'recall_grapheme': 0.973027, 'recall_vowel': 0.991376, 'recall_consonant': 0.991709, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992819, 'acc_consonant': 0.991924, 'loss_grapheme': 0.18627, 'loss_vowel': 0.130932, 'loss_consonant': 0.094474}\n",
      "   87 | 0.000011 | 028672/160596 | 0.0107 | 2.3123 |\n",
      "val: {'recall': 0.983038, 'recall_grapheme': 0.97402, 'recall_vowel': 0.992369, 'recall_consonant': 0.991742, 'acc_grapheme': 0.976444, 'acc_vowel': 0.993316, 'acc_consonant': 0.992173, 'loss_grapheme': 0.141611, 'loss_vowel': 0.085102, 'loss_consonant': 0.066231}\n",
      "   88 | 0.000010 | 073728/160596 | 3.9915 | 2.6899 |\n",
      "val: {'recall': 0.982428, 'recall_grapheme': 0.973394, 'recall_vowel': 0.990995, 'recall_consonant': 0.99193, 'acc_grapheme': 0.975822, 'acc_vowel': 0.99257, 'acc_consonant': 0.991949, 'loss_grapheme': 0.243142, 'loss_vowel': 0.171071, 'loss_consonant': 0.118419}\n",
      "   89 | 0.000008 | 118784/160596 | 2.9710 | 2.8005 |\n",
      "val: {'recall': 0.982613, 'recall_grapheme': 0.973716, 'recall_vowel': 0.991155, 'recall_consonant': 0.991863, 'acc_grapheme': 0.976295, 'acc_vowel': 0.992769, 'acc_consonant': 0.991924, 'loss_grapheme': 0.189455, 'loss_vowel': 0.125135, 'loss_consonant': 0.091668}\n",
      "   91 | 0.000006 | 004096/160596 | 2.6978 | 1.9619 |\n",
      "val: {'recall': 0.982291, 'recall_grapheme': 0.97321, 'recall_vowel': 0.990947, 'recall_consonant': 0.991797, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992744, 'acc_consonant': 0.991875, 'loss_grapheme': 0.187121, 'loss_vowel': 0.125168, 'loss_consonant': 0.092094}\n",
      "   92 | 0.000004 | 049152/160596 | 0.6277 | 3.2132 |\n",
      "val: {'recall': 0.982352, 'recall_grapheme': 0.973229, 'recall_vowel': 0.990923, 'recall_consonant': 0.992027, 'acc_grapheme': 0.975475, 'acc_vowel': 0.992595, 'acc_consonant': 0.991676, 'loss_grapheme': 0.272474, 'loss_vowel': 0.191169, 'loss_consonant': 0.13329}\n",
      "   93 | 0.000003 | 094208/160596 | 4.2391 | 2.7708 |\n",
      "val: {'recall': 0.982291, 'recall_grapheme': 0.973129, 'recall_vowel': 0.99101, 'recall_consonant': 0.991896, 'acc_grapheme': 0.975599, 'acc_vowel': 0.992744, 'acc_consonant': 0.991924, 'loss_grapheme': 0.206055, 'loss_vowel': 0.137836, 'loss_consonant': 0.100388}\n",
      "   94 | 0.000002 | 139264/160596 | 4.3663 | 2.7564 |\n",
      "val: {'recall': 0.982429, 'recall_grapheme': 0.973346, 'recall_vowel': 0.991044, 'recall_consonant': 0.991978, 'acc_grapheme': 0.975748, 'acc_vowel': 0.992769, 'acc_consonant': 0.992024, 'loss_grapheme': 0.210264, 'loss_vowel': 0.146399, 'loss_consonant': 0.103472}\n",
      "   96 | 0.000001 | 024576/160596 | 3.6129 | 2.9549 |\n",
      "val: {'recall': 0.982756, 'recall_grapheme': 0.973973, 'recall_vowel': 0.991145, 'recall_consonant': 0.991934, 'acc_grapheme': 0.975897, 'acc_vowel': 0.992819, 'acc_consonant': 0.992073, 'loss_grapheme': 0.243267, 'loss_vowel': 0.163069, 'loss_consonant': 0.116133}\n",
      "   97 | 0.000001 | 069632/160596 | 2.8425 | 2.4240 |\n",
      "val: {'recall': 0.982994, 'recall_grapheme': 0.974193, 'recall_vowel': 0.991698, 'recall_consonant': 0.991893, 'acc_grapheme': 0.976568, 'acc_vowel': 0.993216, 'acc_consonant': 0.992372, 'loss_grapheme': 0.158258, 'loss_vowel': 0.098782, 'loss_consonant': 0.075224}\n",
      "   98 | 0.000001 | 114688/160596 | 4.1705 | 2.7283 |\n",
      "val: {'recall': 0.98247, 'recall_grapheme': 0.973475, 'recall_vowel': 0.991125, 'recall_consonant': 0.991804, 'acc_grapheme': 0.975996, 'acc_vowel': 0.992819, 'acc_consonant': 0.992148, 'loss_grapheme': 0.163122, 'loss_vowel': 0.108508, 'loss_consonant': 0.081072}\n",
      "   99 | 0.000002 | 159744/160596 | 2.8112 | 2.6375 |\n",
      "val: {'recall': 0.982617, 'recall_grapheme': 0.973727, 'recall_vowel': 0.99086, 'recall_consonant': 0.992154, 'acc_grapheme': 0.975574, 'acc_vowel': 0.992446, 'acc_consonant': 0.991974, 'loss_grapheme': 0.276661, 'loss_vowel': 0.189045, 'loss_consonant': 0.129923}\n",
      "  101 | 0.000003 | 045056/160596 | 0.3714 | 2.3231 |\n",
      "val: {'recall': 0.983192, 'recall_grapheme': 0.974594, 'recall_vowel': 0.991793, 'recall_consonant': 0.991788, 'acc_grapheme': 0.976742, 'acc_vowel': 0.993142, 'acc_consonant': 0.992272, 'loss_grapheme': 0.162187, 'loss_vowel': 0.101793, 'loss_consonant': 0.076954}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 0.000004 | 090112/160596 | 0.1357 | 2.3549 |\n",
      "val: {'recall': 0.982639, 'recall_grapheme': 0.973928, 'recall_vowel': 0.991036, 'recall_consonant': 0.991661, 'acc_grapheme': 0.976021, 'acc_vowel': 0.992719, 'acc_consonant': 0.992049, 'loss_grapheme': 0.191546, 'loss_vowel': 0.127376, 'loss_consonant': 0.092514}\n",
      "  103 | 0.000006 | 135168/160596 | 0.2224 | 2.8519 |\n",
      "val: {'recall': 0.982627, 'recall_grapheme': 0.973305, 'recall_vowel': 0.991825, 'recall_consonant': 0.992074, 'acc_grapheme': 0.975748, 'acc_vowel': 0.993067, 'acc_consonant': 0.992098, 'loss_grapheme': 0.204663, 'loss_vowel': 0.142699, 'loss_consonant': 0.101941}\n",
      "  105 | 0.000008 | 020480/160596 | 0.4235 | 2.6806 |\n",
      "val: {'recall': 0.982826, 'recall_grapheme': 0.973917, 'recall_vowel': 0.991522, 'recall_consonant': 0.991948, 'acc_grapheme': 0.975922, 'acc_vowel': 0.992993, 'acc_consonant': 0.991949, 'loss_grapheme': 0.228592, 'loss_vowel': 0.152386, 'loss_consonant': 0.111011}\n",
      "  106 | 0.000010 | 065536/160596 | 3.0622 | 2.6644 |\n",
      "val: {'recall': 0.982529, 'recall_grapheme': 0.97345, 'recall_vowel': 0.991324, 'recall_consonant': 0.991892, 'acc_grapheme': 0.975996, 'acc_vowel': 0.992918, 'acc_consonant': 0.992123, 'loss_grapheme': 0.189056, 'loss_vowel': 0.129666, 'loss_consonant': 0.096687}\n",
      "  107 | 0.000011 | 110592/160596 | 4.2946 | 2.4782 |\n",
      "val: {'recall': 0.98296, 'recall_grapheme': 0.974189, 'recall_vowel': 0.991608, 'recall_consonant': 0.991856, 'acc_grapheme': 0.976543, 'acc_vowel': 0.993018, 'acc_consonant': 0.992098, 'loss_grapheme': 0.15234, 'loss_vowel': 0.095199, 'loss_consonant': 0.072885}\n",
      "  108 | 0.000013 | 155648/160596 | 3.1158 | 2.7337 |\n",
      "val: {'recall': 0.982322, 'recall_grapheme': 0.972939, 'recall_vowel': 0.991383, 'recall_consonant': 0.992029, 'acc_grapheme': 0.975574, 'acc_vowel': 0.992869, 'acc_consonant': 0.992198, 'loss_grapheme': 0.221354, 'loss_vowel': 0.152329, 'loss_consonant': 0.10851}\n",
      "  110 | 0.000015 | 040960/160596 | 3.7716 | 2.6030 |\n",
      "val: {'recall': 0.982762, 'recall_grapheme': 0.973195, 'recall_vowel': 0.991528, 'recall_consonant': 0.993131, 'acc_grapheme': 0.975822, 'acc_vowel': 0.993042, 'acc_consonant': 0.991899, 'loss_grapheme': 0.172091, 'loss_vowel': 0.116709, 'loss_consonant': 0.088872}\n",
      "  111 | 0.000017 | 086016/160596 | 1.1671 | 2.8280 |\n",
      "val: {'recall': 0.982502, 'recall_grapheme': 0.97319, 'recall_vowel': 0.991541, 'recall_consonant': 0.992085, 'acc_grapheme': 0.975822, 'acc_vowel': 0.993117, 'acc_consonant': 0.991875, 'loss_grapheme': 0.243638, 'loss_vowel': 0.167253, 'loss_consonant': 0.118439}\n",
      "  112 | 0.000018 | 131072/160596 | 1.2521 | 2.6996 |\n",
      "val: {'recall': 0.982701, 'recall_grapheme': 0.973064, 'recall_vowel': 0.991243, 'recall_consonant': 0.993433, 'acc_grapheme': 0.976071, 'acc_vowel': 0.993042, 'acc_consonant': 0.991949, 'loss_grapheme': 0.213983, 'loss_vowel': 0.142561, 'loss_consonant': 0.105298}\n",
      "  114 | 0.000019 | 016384/160596 | 0.0614 | 2.0430 |\n",
      "val: {'recall': 0.982616, 'recall_grapheme': 0.973746, 'recall_vowel': 0.992143, 'recall_consonant': 0.99083, 'acc_grapheme': 0.976394, 'acc_vowel': 0.993216, 'acc_consonant': 0.992247, 'loss_grapheme': 0.145699, 'loss_vowel': 0.089744, 'loss_consonant': 0.068921}\n",
      "  115 | 0.000020 | 061440/160596 | 3.4349 | 2.3298 |\n",
      "val: {'recall': 0.982721, 'recall_grapheme': 0.97379, 'recall_vowel': 0.991242, 'recall_consonant': 0.992061, 'acc_grapheme': 0.976071, 'acc_vowel': 0.992844, 'acc_consonant': 0.991899, 'loss_grapheme': 0.209448, 'loss_vowel': 0.140151, 'loss_consonant': 0.101297}\n",
      "  116 | 0.000020 | 106496/160596 | 3.0199 | 2.6461 |\n",
      "val: {'recall': 0.982681, 'recall_grapheme': 0.973634, 'recall_vowel': 0.991844, 'recall_consonant': 0.99161, 'acc_grapheme': 0.975947, 'acc_vowel': 0.992918, 'acc_consonant': 0.991899, 'loss_grapheme': 0.182291, 'loss_vowel': 0.117176, 'loss_consonant': 0.088848}\n",
      "  117 | 0.000020 | 151552/160596 | 3.7213 | 2.8532 |\n",
      "val: {'recall': 0.982482, 'recall_grapheme': 0.973369, 'recall_vowel': 0.991593, 'recall_consonant': 0.991598, 'acc_grapheme': 0.975425, 'acc_vowel': 0.992769, 'acc_consonant': 0.991924, 'loss_grapheme': 0.201962, 'loss_vowel': 0.134386, 'loss_consonant': 0.100013}\n",
      "  119 | 0.000019 | 036864/160596 | 0.0056 | 2.7604 |\n",
      "val: {'recall': 0.983083, 'recall_grapheme': 0.974538, 'recall_vowel': 0.99149, 'recall_consonant': 0.991763, 'acc_grapheme': 0.976195, 'acc_vowel': 0.992869, 'acc_consonant': 0.992123, 'loss_grapheme': 0.197035, 'loss_vowel': 0.129176, 'loss_consonant': 0.095274}\n",
      "  120 | 0.000018 | 081920/160596 | 2.7906 | 2.8663 |\n",
      "val: {'recall': 0.98204, 'recall_grapheme': 0.972682, 'recall_vowel': 0.991184, 'recall_consonant': 0.991613, 'acc_grapheme': 0.975027, 'acc_vowel': 0.992496, 'acc_consonant': 0.991601, 'loss_grapheme': 0.293359, 'loss_vowel': 0.195892, 'loss_consonant': 0.136999}\n",
      "  121 | 0.000017 | 126976/160596 | 3.8323 | 2.7896 |\n",
      "val: {'recall': 0.982616, 'recall_grapheme': 0.973249, 'recall_vowel': 0.990991, 'recall_consonant': 0.992975, 'acc_grapheme': 0.975176, 'acc_vowel': 0.992695, 'acc_consonant': 0.992024, 'loss_grapheme': 0.265337, 'loss_vowel': 0.183181, 'loss_consonant': 0.128409}\n",
      "  123 | 0.000015 | 012288/160596 | 1.9050 | 2.0202 |\n",
      "val: {'recall': 0.982704, 'recall_grapheme': 0.973733, 'recall_vowel': 0.991608, 'recall_consonant': 0.991743, 'acc_grapheme': 0.976245, 'acc_vowel': 0.993192, 'acc_consonant': 0.992272, 'loss_grapheme': 0.159433, 'loss_vowel': 0.100667, 'loss_consonant': 0.076362}\n",
      "  124 | 0.000013 | 057344/160596 | 3.6764 | 2.6971 |\n",
      "val: {'recall': 0.983058, 'recall_grapheme': 0.974289, 'recall_vowel': 0.991831, 'recall_consonant': 0.991822, 'acc_grapheme': 0.976021, 'acc_vowel': 0.993067, 'acc_consonant': 0.99185, 'loss_grapheme': 0.246456, 'loss_vowel': 0.164786, 'loss_consonant': 0.117139}\n",
      "  125 | 0.000011 | 102400/160596 | 4.4586 | 2.7833 |\n",
      "val: {'recall': 0.982711, 'recall_grapheme': 0.973125, 'recall_vowel': 0.991545, 'recall_consonant': 0.99305, 'acc_grapheme': 0.975798, 'acc_vowel': 0.993067, 'acc_consonant': 0.991825, 'loss_grapheme': 0.178697, 'loss_vowel': 0.120144, 'loss_consonant': 0.090784}\n",
      "  126 | 0.000010 | 147456/160596 | 4.6113 | 2.7065 |\n",
      "val: {'recall': 0.982494, 'recall_grapheme': 0.973109, 'recall_vowel': 0.992016, 'recall_consonant': 0.991742, 'acc_grapheme': 0.975847, 'acc_vowel': 0.993266, 'acc_consonant': 0.992123, 'loss_grapheme': 0.182745, 'loss_vowel': 0.120998, 'loss_consonant': 0.089546}\n",
      "  128 | 0.000008 | 032768/160596 | 0.0039 | 2.2872 |\n",
      "val: {'recall': 0.983367, 'recall_grapheme': 0.97472, 'recall_vowel': 0.992312, 'recall_consonant': 0.991715, 'acc_grapheme': 0.976692, 'acc_vowel': 0.99339, 'acc_consonant': 0.992471, 'loss_grapheme': 0.120017, 'loss_vowel': 0.067023, 'loss_consonant': 0.053739}\n",
      "  129 | 0.000006 | 077824/160596 | 0.0100 | 2.5874 |\n",
      "val: {'recall': 0.982461, 'recall_grapheme': 0.973307, 'recall_vowel': 0.991587, 'recall_consonant': 0.991641, 'acc_grapheme': 0.975947, 'acc_vowel': 0.992968, 'acc_consonant': 0.992247, 'loss_grapheme': 0.173618, 'loss_vowel': 0.113366, 'loss_consonant': 0.082601}\n",
      "  130 | 0.000004 | 122880/160596 | 1.6450 | 2.7037 |\n",
      "val: {'recall': 0.982777, 'recall_grapheme': 0.97394, 'recall_vowel': 0.991308, 'recall_consonant': 0.991919, 'acc_grapheme': 0.976394, 'acc_vowel': 0.993042, 'acc_consonant': 0.992222, 'loss_grapheme': 0.16836, 'loss_vowel': 0.108688, 'loss_consonant': 0.081504}\n",
      "  132 | 0.000003 | 008192/160596 | 4.1889 | 2.9341 |\n",
      "val: {'recall': 0.982766, 'recall_grapheme': 0.973964, 'recall_vowel': 0.991111, 'recall_consonant': 0.992025, 'acc_grapheme': 0.976121, 'acc_vowel': 0.992893, 'acc_consonant': 0.992049, 'loss_grapheme': 0.199732, 'loss_vowel': 0.134856, 'loss_consonant': 0.097519}\n",
      "  133 | 0.000002 | 053248/160596 | 4.1121 | 2.6486 |\n",
      "val: {'recall': 0.982289, 'recall_grapheme': 0.97292, 'recall_vowel': 0.991266, 'recall_consonant': 0.992051, 'acc_grapheme': 0.975599, 'acc_vowel': 0.993042, 'acc_consonant': 0.991999, 'loss_grapheme': 0.220333, 'loss_vowel': 0.152478, 'loss_consonant': 0.110387}\n",
      "  134 | 0.000001 | 098304/160596 | 3.9934 | 2.3210 |\n",
      "val: {'recall': 0.982387, 'recall_grapheme': 0.973277, 'recall_vowel': 0.991183, 'recall_consonant': 0.991813, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992769, 'acc_consonant': 0.992049, 'loss_grapheme': 0.210286, 'loss_vowel': 0.138146, 'loss_consonant': 0.09986}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  135 | 0.000001 | 143360/160596 | 3.2907 | 2.5674 |\n",
      "val: {'recall': 0.98284, 'recall_grapheme': 0.97405, 'recall_vowel': 0.991278, 'recall_consonant': 0.991981, 'acc_grapheme': 0.976543, 'acc_vowel': 0.992893, 'acc_consonant': 0.992322, 'loss_grapheme': 0.206174, 'loss_vowel': 0.138541, 'loss_consonant': 0.098892}\n",
      "  137 | 0.000001 | 028672/160596 | 4.4734 | 2.7133 |\n",
      "val: {'recall': 0.982423, 'recall_grapheme': 0.973162, 'recall_vowel': 0.991304, 'recall_consonant': 0.992065, 'acc_grapheme': 0.975922, 'acc_vowel': 0.992893, 'acc_consonant': 0.992049, 'loss_grapheme': 0.252126, 'loss_vowel': 0.168241, 'loss_consonant': 0.118903}\n",
      "  138 | 0.000002 | 073728/160596 | 3.8734 | 2.6939 |\n",
      "val: {'recall': 0.98244, 'recall_grapheme': 0.973352, 'recall_vowel': 0.991124, 'recall_consonant': 0.99193, 'acc_grapheme': 0.975798, 'acc_vowel': 0.992695, 'acc_consonant': 0.99185, 'loss_grapheme': 0.285952, 'loss_vowel': 0.196876, 'loss_consonant': 0.134718}\n",
      "  139 | 0.000003 | 118784/160596 | 1.7805 | 2.5980 |\n",
      "val: {'recall': 0.982975, 'recall_grapheme': 0.974253, 'recall_vowel': 0.991558, 'recall_consonant': 0.991837, 'acc_grapheme': 0.976319, 'acc_vowel': 0.993018, 'acc_consonant': 0.992148, 'loss_grapheme': 0.202369, 'loss_vowel': 0.134603, 'loss_consonant': 0.096656}\n",
      "  141 | 0.000004 | 004096/160596 | 3.4157 | 2.3416 |\n",
      "val: {'recall': 0.98257, 'recall_grapheme': 0.973247, 'recall_vowel': 0.991844, 'recall_consonant': 0.991944, 'acc_grapheme': 0.976319, 'acc_vowel': 0.993216, 'acc_consonant': 0.992148, 'loss_grapheme': 0.184653, 'loss_vowel': 0.11877, 'loss_consonant': 0.089967}\n",
      "  142 | 0.000006 | 049152/160596 | 0.5428 | 2.5875 |\n",
      "val: {'recall': 0.982611, 'recall_grapheme': 0.973683, 'recall_vowel': 0.991342, 'recall_consonant': 0.991736, 'acc_grapheme': 0.976146, 'acc_vowel': 0.992968, 'acc_consonant': 0.992123, 'loss_grapheme': 0.219099, 'loss_vowel': 0.143566, 'loss_consonant': 0.104735}\n",
      "  143 | 0.000008 | 094208/160596 | 2.5958 | 2.4979 |\n",
      "val: {'recall': 0.982648, 'recall_grapheme': 0.973692, 'recall_vowel': 0.99142, 'recall_consonant': 0.991787, 'acc_grapheme': 0.976021, 'acc_vowel': 0.993067, 'acc_consonant': 0.992247, 'loss_grapheme': 0.177722, 'loss_vowel': 0.114449, 'loss_consonant': 0.084268}\n",
      "  144 | 0.000010 | 139264/160596 | 3.4669 | 2.6670 |\n",
      "val: {'recall': 0.982675, 'recall_grapheme': 0.973661, 'recall_vowel': 0.991507, 'recall_consonant': 0.991873, 'acc_grapheme': 0.976121, 'acc_vowel': 0.993067, 'acc_consonant': 0.992049, 'loss_grapheme': 0.163976, 'loss_vowel': 0.105305, 'loss_consonant': 0.079653}\n",
      "  146 | 0.000011 | 024576/160596 | 4.3839 | 3.2604 |\n",
      "val: {'recall': 0.982476, 'recall_grapheme': 0.97359, 'recall_vowel': 0.991083, 'recall_consonant': 0.991643, 'acc_grapheme': 0.975748, 'acc_vowel': 0.99262, 'acc_consonant': 0.991527, 'loss_grapheme': 0.31287, 'loss_vowel': 0.214367, 'loss_consonant': 0.151595}\n",
      "  147 | 0.000013 | 069632/160596 | 2.3476 | 2.5104 |\n",
      "val: {'recall': 0.982381, 'recall_grapheme': 0.972961, 'recall_vowel': 0.991752, 'recall_consonant': 0.99185, 'acc_grapheme': 0.976121, 'acc_vowel': 0.992968, 'acc_consonant': 0.991949, 'loss_grapheme': 0.193463, 'loss_vowel': 0.128914, 'loss_consonant': 0.094566}\n",
      "  148 | 0.000015 | 114688/160596 | 0.6162 | 2.8550 |\n",
      "val: {'recall': 0.982852, 'recall_grapheme': 0.97356, 'recall_vowel': 0.991214, 'recall_consonant': 0.993075, 'acc_grapheme': 0.976121, 'acc_vowel': 0.993018, 'acc_consonant': 0.992347, 'loss_grapheme': 0.172353, 'loss_vowel': 0.110856, 'loss_consonant': 0.084683}\n",
      "  149 | 0.000017 | 159744/160596 | 1.5939 | 2.5242 |\n",
      "val: {'recall': 0.9837, 'recall_grapheme': 0.974834, 'recall_vowel': 0.992152, 'recall_consonant': 0.992981, 'acc_grapheme': 0.97627, 'acc_vowel': 0.993316, 'acc_consonant': 0.992421, 'loss_grapheme': 0.150535, 'loss_vowel': 0.094913, 'loss_consonant': 0.072552}\n",
      "  151 | 0.000018 | 045056/160596 | 3.5759 | 2.9773 |\n",
      "val: {'recall': 0.982119, 'recall_grapheme': 0.972343, 'recall_vowel': 0.991829, 'recall_consonant': 0.991959, 'acc_grapheme': 0.975375, 'acc_vowel': 0.993067, 'acc_consonant': 0.992297, 'loss_grapheme': 0.234252, 'loss_vowel': 0.154225, 'loss_consonant': 0.110208}\n",
      "  152 | 0.000019 | 090112/160596 | 0.4506 | 2.4989 |\n",
      "val: {'recall': 0.982974, 'recall_grapheme': 0.973808, 'recall_vowel': 0.99226, 'recall_consonant': 0.992019, 'acc_grapheme': 0.976419, 'acc_vowel': 0.993564, 'acc_consonant': 0.99257, 'loss_grapheme': 0.133854, 'loss_vowel': 0.076463, 'loss_consonant': 0.05948}\n",
      "  153 | 0.000020 | 135168/160596 | 4.1230 | 2.6862 |\n",
      "val: {'recall': 0.983316, 'recall_grapheme': 0.974237, 'recall_vowel': 0.991882, 'recall_consonant': 0.99291, 'acc_grapheme': 0.976618, 'acc_vowel': 0.993142, 'acc_consonant': 0.992148, 'loss_grapheme': 0.198253, 'loss_vowel': 0.130944, 'loss_consonant': 0.097245}\n",
      "  155 | 0.000020 | 020480/160596 | 2.7459 | 2.8136 |\n",
      "val: {'recall': 0.982901, 'recall_grapheme': 0.973409, 'recall_vowel': 0.991627, 'recall_consonant': 0.99316, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992943, 'acc_consonant': 0.992372, 'loss_grapheme': 0.216681, 'loss_vowel': 0.144104, 'loss_consonant': 0.106117}\n",
      "  156 | 0.000020 | 065536/160596 | 3.2929 | 2.7466 |\n",
      "val: {'recall': 0.983493, 'recall_grapheme': 0.975245, 'recall_vowel': 0.991676, 'recall_consonant': 0.991805, 'acc_grapheme': 0.976717, 'acc_vowel': 0.993241, 'acc_consonant': 0.992521, 'loss_grapheme': 0.160241, 'loss_vowel': 0.105601, 'loss_consonant': 0.077209}\n",
      "  157 | 0.000019 | 110592/160596 | 2.3667 | 2.5729 |\n",
      "val: {'recall': 0.982907, 'recall_grapheme': 0.974176, 'recall_vowel': 0.991548, 'recall_consonant': 0.991726, 'acc_grapheme': 0.976195, 'acc_vowel': 0.992869, 'acc_consonant': 0.992049, 'loss_grapheme': 0.222628, 'loss_vowel': 0.147512, 'loss_consonant': 0.106201}\n",
      "  158 | 0.000018 | 155648/160596 | 4.1960 | 2.7530 |\n",
      "val: {'recall': 0.982585, 'recall_grapheme': 0.973159, 'recall_vowel': 0.991724, 'recall_consonant': 0.992299, 'acc_grapheme': 0.975673, 'acc_vowel': 0.993142, 'acc_consonant': 0.991999, 'loss_grapheme': 0.198293, 'loss_vowel': 0.129415, 'loss_consonant': 0.098874}\n",
      "  160 | 0.000017 | 040960/160596 | 3.8709 | 2.7353 |\n",
      "val: {'recall': 0.982969, 'recall_grapheme': 0.974312, 'recall_vowel': 0.991736, 'recall_consonant': 0.991517, 'acc_grapheme': 0.97627, 'acc_vowel': 0.993266, 'acc_consonant': 0.992123, 'loss_grapheme': 0.204172, 'loss_vowel': 0.135493, 'loss_consonant': 0.098439}\n",
      "  161 | 0.000015 | 086016/160596 | 2.6545 | 2.5255 |\n",
      "val: {'recall': 0.98286, 'recall_grapheme': 0.974156, 'recall_vowel': 0.991706, 'recall_consonant': 0.991422, 'acc_grapheme': 0.976071, 'acc_vowel': 0.993067, 'acc_consonant': 0.992347, 'loss_grapheme': 0.17746, 'loss_vowel': 0.116487, 'loss_consonant': 0.085321}\n",
      "  162 | 0.000013 | 131072/160596 | 0.0055 | 2.7243 |\n",
      "val: {'recall': 0.982951, 'recall_grapheme': 0.974278, 'recall_vowel': 0.991849, 'recall_consonant': 0.991397, 'acc_grapheme': 0.976593, 'acc_vowel': 0.993341, 'acc_consonant': 0.992521, 'loss_grapheme': 0.168314, 'loss_vowel': 0.108745, 'loss_consonant': 0.081541}\n",
      "  164 | 0.000011 | 016384/160596 | 0.0058 | 2.1365 |\n",
      "val: {'recall': 0.982754, 'recall_grapheme': 0.973652, 'recall_vowel': 0.991691, 'recall_consonant': 0.992019, 'acc_grapheme': 0.976295, 'acc_vowel': 0.993291, 'acc_consonant': 0.992347, 'loss_grapheme': 0.148564, 'loss_vowel': 0.091282, 'loss_consonant': 0.070197}\n",
      "  165 | 0.000010 | 061440/160596 | 3.5788 | 2.6634 |\n",
      "val: {'recall': 0.983368, 'recall_grapheme': 0.974243, 'recall_vowel': 0.991643, 'recall_consonant': 0.993345, 'acc_grapheme': 0.976469, 'acc_vowel': 0.993266, 'acc_consonant': 0.992297, 'loss_grapheme': 0.199296, 'loss_vowel': 0.130977, 'loss_consonant': 0.093214}\n",
      "  166 | 0.000008 | 106496/160596 | 0.0052 | 2.5429 |\n",
      "val: {'recall': 0.983014, 'recall_grapheme': 0.974158, 'recall_vowel': 0.991822, 'recall_consonant': 0.991921, 'acc_grapheme': 0.976543, 'acc_vowel': 0.993316, 'acc_consonant': 0.992545, 'loss_grapheme': 0.154826, 'loss_vowel': 0.095192, 'loss_consonant': 0.073205}\n",
      "  167 | 0.000006 | 151552/160596 | 3.2414 | 2.6348 |\n",
      "val: {'recall': 0.982508, 'recall_grapheme': 0.973475, 'recall_vowel': 0.991288, 'recall_consonant': 0.991794, 'acc_grapheme': 0.975972, 'acc_vowel': 0.992968, 'acc_consonant': 0.992123, 'loss_grapheme': 0.19515, 'loss_vowel': 0.12977, 'loss_consonant': 0.097056}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  169 | 0.000004 | 036864/160596 | 3.2229 | 2.4405 |\n",
      "val: {'recall': 0.982978, 'recall_grapheme': 0.9741, 'recall_vowel': 0.991696, 'recall_consonant': 0.992018, 'acc_grapheme': 0.976642, 'acc_vowel': 0.993365, 'acc_consonant': 0.992595, 'loss_grapheme': 0.130097, 'loss_vowel': 0.075256, 'loss_consonant': 0.059096}\n",
      "  170 | 0.000003 | 081920/160596 | 2.7316 | 3.0466 |\n",
      "val: {'recall': 0.982551, 'recall_grapheme': 0.973436, 'recall_vowel': 0.991226, 'recall_consonant': 0.992106, 'acc_grapheme': 0.976071, 'acc_vowel': 0.993042, 'acc_consonant': 0.992098, 'loss_grapheme': 0.235771, 'loss_vowel': 0.153329, 'loss_consonant': 0.11236}\n",
      "  171 | 0.000002 | 126976/160596 | 3.0746 | 2.7222 |\n",
      "val: {'recall': 0.983051, 'recall_grapheme': 0.97413, 'recall_vowel': 0.991744, 'recall_consonant': 0.992199, 'acc_grapheme': 0.976493, 'acc_vowel': 0.993216, 'acc_consonant': 0.992521, 'loss_grapheme': 0.174377, 'loss_vowel': 0.110486, 'loss_consonant': 0.082632}\n",
      "  173 | 0.000001 | 012288/160596 | 0.0064 | 2.1070 |\n",
      "val: {'recall': 0.982937, 'recall_grapheme': 0.974039, 'recall_vowel': 0.991761, 'recall_consonant': 0.991911, 'acc_grapheme': 0.976568, 'acc_vowel': 0.993266, 'acc_consonant': 0.992769, 'loss_grapheme': 0.154075, 'loss_vowel': 0.096681, 'loss_consonant': 0.072756}\n",
      "  174 | 0.000001 | 057344/160596 | 2.8381 | 2.8250 |\n",
      "val: {'recall': 0.982835, 'recall_grapheme': 0.97382, 'recall_vowel': 0.991546, 'recall_consonant': 0.992154, 'acc_grapheme': 0.976195, 'acc_vowel': 0.993042, 'acc_consonant': 0.99262, 'loss_grapheme': 0.172705, 'loss_vowel': 0.114649, 'loss_consonant': 0.084708}\n",
      "  175 | 0.000001 | 102400/160596 | 3.1444 | 2.4578 |\n",
      "val: {'recall': 0.983049, 'recall_grapheme': 0.973985, 'recall_vowel': 0.992112, 'recall_consonant': 0.992113, 'acc_grapheme': 0.976319, 'acc_vowel': 0.993316, 'acc_consonant': 0.992222, 'loss_grapheme': 0.174141, 'loss_vowel': 0.113267, 'loss_consonant': 0.085193}\n",
      "  176 | 0.000002 | 147456/160596 | 0.0069 | 2.6511 |\n",
      "val: {'recall': 0.98324, 'recall_grapheme': 0.974359, 'recall_vowel': 0.992042, 'recall_consonant': 0.992199, 'acc_grapheme': 0.976667, 'acc_vowel': 0.993465, 'acc_consonant': 0.992446, 'loss_grapheme': 0.164926, 'loss_vowel': 0.104998, 'loss_consonant': 0.079034}\n",
      "  178 | 0.000003 | 032768/160596 | 1.8579 | 2.3481 |\n",
      "val: {'recall': 0.98332, 'recall_grapheme': 0.974561, 'recall_vowel': 0.991898, 'recall_consonant': 0.992263, 'acc_grapheme': 0.976742, 'acc_vowel': 0.99344, 'acc_consonant': 0.992819, 'loss_grapheme': 0.149244, 'loss_vowel': 0.093332, 'loss_consonant': 0.069397}\n",
      "  179 | 0.000004 | 077824/160596 | 2.5335 | 2.6482 |\n",
      "val: {'recall': 0.983136, 'recall_grapheme': 0.974615, 'recall_vowel': 0.991378, 'recall_consonant': 0.991934, 'acc_grapheme': 0.976891, 'acc_vowel': 0.993092, 'acc_consonant': 0.992421, 'loss_grapheme': 0.226196, 'loss_vowel': 0.149968, 'loss_consonant': 0.106397}\n",
      "  180 | 0.000006 | 122880/160596 | 2.9534 | 2.7598 |\n",
      "val: {'recall': 0.983204, 'recall_grapheme': 0.974498, 'recall_vowel': 0.991879, 'recall_consonant': 0.991942, 'acc_grapheme': 0.976618, 'acc_vowel': 0.993316, 'acc_consonant': 0.992471, 'loss_grapheme': 0.184082, 'loss_vowel': 0.115767, 'loss_consonant': 0.086563}\n",
      "  182 | 0.000008 | 008192/160596 | 3.5951 | 3.2165 |\n",
      "val: {'recall': 0.982892, 'recall_grapheme': 0.974115, 'recall_vowel': 0.991389, 'recall_consonant': 0.991949, 'acc_grapheme': 0.976245, 'acc_vowel': 0.993192, 'acc_consonant': 0.992123, 'loss_grapheme': 0.206049, 'loss_vowel': 0.138466, 'loss_consonant': 0.101154}\n",
      "  183 | 0.000010 | 053248/160596 | 3.7817 | 2.4467 |\n",
      "val: {'recall': 0.983109, 'recall_grapheme': 0.974597, 'recall_vowel': 0.991499, 'recall_consonant': 0.991743, 'acc_grapheme': 0.976916, 'acc_vowel': 0.993341, 'acc_consonant': 0.992421, 'loss_grapheme': 0.147164, 'loss_vowel': 0.090978, 'loss_consonant': 0.069905}\n",
      "  184 | 0.000011 | 098304/160596 | 4.1267 | 2.7887 |\n",
      "val: {'recall': 0.983108, 'recall_grapheme': 0.97437, 'recall_vowel': 0.991558, 'recall_consonant': 0.992135, 'acc_grapheme': 0.976767, 'acc_vowel': 0.993241, 'acc_consonant': 0.992446, 'loss_grapheme': 0.177105, 'loss_vowel': 0.116393, 'loss_consonant': 0.085759}\n",
      "  185 | 0.000013 | 143360/160596 | 3.0311 | 2.7738 |\n",
      "val: {'recall': 0.982552, 'recall_grapheme': 0.973369, 'recall_vowel': 0.991357, 'recall_consonant': 0.992113, 'acc_grapheme': 0.976195, 'acc_vowel': 0.993042, 'acc_consonant': 0.992372, 'loss_grapheme': 0.2091, 'loss_vowel': 0.135033, 'loss_consonant': 0.098348}\n",
      "  187 | 0.000015 | 028672/160596 | 2.8107 | 2.0997 |\n",
      "val: {'recall': 0.983531, 'recall_grapheme': 0.974792, 'recall_vowel': 0.9918, 'recall_consonant': 0.992743, 'acc_grapheme': 0.976841, 'acc_vowel': 0.993341, 'acc_consonant': 0.992446, 'loss_grapheme': 0.125588, 'loss_vowel': 0.071278, 'loss_consonant': 0.056243}\n",
      "  188 | 0.000017 | 073728/160596 | 2.3861 | 2.5669 |\n",
      "val: {'recall': 0.983187, 'recall_grapheme': 0.974462, 'recall_vowel': 0.992, 'recall_consonant': 0.991824, 'acc_grapheme': 0.976941, 'acc_vowel': 0.993365, 'acc_consonant': 0.992297, 'loss_grapheme': 0.168717, 'loss_vowel': 0.105459, 'loss_consonant': 0.079618}\n",
      "  189 | 0.000018 | 118784/160596 | 1.8610 | 2.6704 |\n",
      "val: {'recall': 0.983001, 'recall_grapheme': 0.973797, 'recall_vowel': 0.992059, 'recall_consonant': 0.99235, 'acc_grapheme': 0.976618, 'acc_vowel': 0.993241, 'acc_consonant': 0.992794, 'loss_grapheme': 0.203269, 'loss_vowel': 0.131854, 'loss_consonant': 0.097041}\n",
      "  191 | 0.000019 | 004096/160596 | 4.2655 | 2.3670 |\n",
      "val: {'recall': 0.982878, 'recall_grapheme': 0.974506, 'recall_vowel': 0.992256, 'recall_consonant': 0.990244, 'acc_grapheme': 0.976642, 'acc_vowel': 0.99349, 'acc_consonant': 0.992297, 'loss_grapheme': 0.138211, 'loss_vowel': 0.080374, 'loss_consonant': 0.064962}\n",
      "  192 | 0.000020 | 049152/160596 | 2.9828 | 2.3914 |\n",
      "val: {'recall': 0.983209, 'recall_grapheme': 0.974338, 'recall_vowel': 0.991559, 'recall_consonant': 0.992603, 'acc_grapheme': 0.976792, 'acc_vowel': 0.99344, 'acc_consonant': 0.992272, 'loss_grapheme': 0.181503, 'loss_vowel': 0.115382, 'loss_consonant': 0.086614}\n",
      "  193 | 0.000020 | 094208/160596 | 0.0246 | 2.5538 |\n",
      "val: {'recall': 0.982752, 'recall_grapheme': 0.973287, 'recall_vowel': 0.991902, 'recall_consonant': 0.992532, 'acc_grapheme': 0.97617, 'acc_vowel': 0.993365, 'acc_consonant': 0.99262, 'loss_grapheme': 0.171535, 'loss_vowel': 0.110779, 'loss_consonant': 0.081863}\n",
      "  194 | 0.000020 | 139264/160596 | 4.5040 | 2.6946 |\n",
      "val: {'recall': 0.982957, 'recall_grapheme': 0.973619, 'recall_vowel': 0.991509, 'recall_consonant': 0.993079, 'acc_grapheme': 0.976121, 'acc_vowel': 0.993117, 'acc_consonant': 0.992595, 'loss_grapheme': 0.212659, 'loss_vowel': 0.137744, 'loss_consonant': 0.099235}\n",
      "  196 | 0.000019 | 024576/160596 | 0.9869 | 2.1934 |\n",
      "val: {'recall': 0.983807, 'recall_grapheme': 0.975073, 'recall_vowel': 0.992321, 'recall_consonant': 0.992762, 'acc_grapheme': 0.97699, 'acc_vowel': 0.993664, 'acc_consonant': 0.992719, 'loss_grapheme': 0.179168, 'loss_vowel': 0.110338, 'loss_consonant': 0.081284}\n",
      "** saved\n",
      "  197 | 0.000018 | 069632/160596 | 2.5390 | 2.5120 |\n",
      "val: {'recall': 0.983433, 'recall_grapheme': 0.974719, 'recall_vowel': 0.992063, 'recall_consonant': 0.992233, 'acc_grapheme': 0.976593, 'acc_vowel': 0.993365, 'acc_consonant': 0.992645, 'loss_grapheme': 0.214956, 'loss_vowel': 0.139448, 'loss_consonant': 0.102982}\n",
      "  198 | 0.000017 | 114688/160596 | 3.2355 | 2.6485 |\n",
      "val: {'recall': 0.982398, 'recall_grapheme': 0.973276, 'recall_vowel': 0.991294, 'recall_consonant': 0.991745, 'acc_grapheme': 0.975996, 'acc_vowel': 0.992794, 'acc_consonant': 0.99175, 'loss_grapheme': 0.27326, 'loss_vowel': 0.179103, 'loss_consonant': 0.130442}\n",
      "  199 | 0.000015 | 159744/160596 | 3.2429 | 2.6606 |\n",
      "val: {'recall': 0.983145, 'recall_grapheme': 0.974838, 'recall_vowel': 0.991022, 'recall_consonant': 0.991883, 'acc_grapheme': 0.976916, 'acc_vowel': 0.993067, 'acc_consonant': 0.992769, 'loss_grapheme': 0.20421, 'loss_vowel': 0.132701, 'loss_consonant': 0.095312}\n",
      "  201 | 0.000013 | 045056/160596 | 3.9079 | 2.3094 |\n",
      "val: {'recall': 0.983065, 'recall_grapheme': 0.973749, 'recall_vowel': 0.991374, 'recall_consonant': 0.993389, 'acc_grapheme': 0.976742, 'acc_vowel': 0.993291, 'acc_consonant': 0.992471, 'loss_grapheme': 0.224972, 'loss_vowel': 0.148323, 'loss_consonant': 0.10829}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  202 | 0.000011 | 090112/160596 | 3.6882 | 2.7306 |\n",
      "val: {'recall': 0.983333, 'recall_grapheme': 0.974253, 'recall_vowel': 0.99157, 'recall_consonant': 0.993255, 'acc_grapheme': 0.976642, 'acc_vowel': 0.992993, 'acc_consonant': 0.992322, 'loss_grapheme': 0.210327, 'loss_vowel': 0.139612, 'loss_consonant': 0.10247}\n",
      "  203 | 0.000010 | 135168/160596 | 4.1768 | 2.4707 |\n",
      "val: {'recall': 0.983521, 'recall_grapheme': 0.974365, 'recall_vowel': 0.992202, 'recall_consonant': 0.993152, 'acc_grapheme': 0.976941, 'acc_vowel': 0.993515, 'acc_consonant': 0.992695, 'loss_grapheme': 0.153233, 'loss_vowel': 0.094962, 'loss_consonant': 0.07231}\n",
      "  205 | 0.000008 | 020480/160596 | 2.6844 | 2.6417 |\n",
      "val: {'recall': 0.983164, 'recall_grapheme': 0.973737, 'recall_vowel': 0.991782, 'recall_consonant': 0.9934, 'acc_grapheme': 0.976593, 'acc_vowel': 0.993067, 'acc_consonant': 0.992421, 'loss_grapheme': 0.173772, 'loss_vowel': 0.113096, 'loss_consonant': 0.084655}\n",
      "  206 | 0.000006 | 065536/160596 | 3.0368 | 2.6797 |\n",
      "val: {'recall': 0.983022, 'recall_grapheme': 0.973414, 'recall_vowel': 0.991805, 'recall_consonant': 0.993454, 'acc_grapheme': 0.976096, 'acc_vowel': 0.993241, 'acc_consonant': 0.992421, 'loss_grapheme': 0.210339, 'loss_vowel': 0.136743, 'loss_consonant': 0.099593}\n",
      "  207 | 0.000004 | 110592/160596 | 4.0789 | 2.6177 |\n",
      "val: {'recall': 0.983082, 'recall_grapheme': 0.973639, 'recall_vowel': 0.991663, 'recall_consonant': 0.993387, 'acc_grapheme': 0.976369, 'acc_vowel': 0.993365, 'acc_consonant': 0.99262, 'loss_grapheme': 0.202505, 'loss_vowel': 0.137079, 'loss_consonant': 0.099758}\n",
      "  208 | 0.000003 | 155648/160596 | 4.2297 | 2.5265 |\n",
      "val: {'recall': 0.983411, 'recall_grapheme': 0.974126, 'recall_vowel': 0.992266, 'recall_consonant': 0.993126, 'acc_grapheme': 0.97699, 'acc_vowel': 0.993415, 'acc_consonant': 0.992794, 'loss_grapheme': 0.154986, 'loss_vowel': 0.09956, 'loss_consonant': 0.075845}\n",
      "  210 | 0.000002 | 040960/160596 | 2.8263 | 2.4306 |\n",
      "val: {'recall': 0.98326, 'recall_grapheme': 0.97404, 'recall_vowel': 0.991624, 'recall_consonant': 0.993334, 'acc_grapheme': 0.976792, 'acc_vowel': 0.993266, 'acc_consonant': 0.992719, 'loss_grapheme': 0.173249, 'loss_vowel': 0.109617, 'loss_consonant': 0.082558}\n",
      "  211 | 0.000001 | 086016/160596 | 0.3195 | 2.7957 |\n",
      "val: {'recall': 0.983228, 'recall_grapheme': 0.973993, 'recall_vowel': 0.99172, 'recall_consonant': 0.993207, 'acc_grapheme': 0.976742, 'acc_vowel': 0.993216, 'acc_consonant': 0.992545, 'loss_grapheme': 0.199402, 'loss_vowel': 0.131476, 'loss_consonant': 0.09575}\n",
      "  212 | 0.000001 | 131072/160596 | 2.0187 | 2.5056 |\n",
      "val: {'recall': 0.983249, 'recall_grapheme': 0.974022, 'recall_vowel': 0.991435, 'recall_consonant': 0.993518, 'acc_grapheme': 0.976866, 'acc_vowel': 0.993291, 'acc_consonant': 0.992421, 'loss_grapheme': 0.191138, 'loss_vowel': 0.121149, 'loss_consonant': 0.090098}\n",
      "  214 | 0.000001 | 016384/160596 | 4.1683 | 3.0898 |\n",
      "val: {'recall': 0.982837, 'recall_grapheme': 0.973258, 'recall_vowel': 0.99155, 'recall_consonant': 0.993281, 'acc_grapheme': 0.976146, 'acc_vowel': 0.993067, 'acc_consonant': 0.992173, 'loss_grapheme': 0.244582, 'loss_vowel': 0.159742, 'loss_consonant': 0.114737}\n",
      "  215 | 0.000002 | 061440/160596 | 0.0045 | 2.7857 |\n",
      "val: {'recall': 0.983559, 'recall_grapheme': 0.974448, 'recall_vowel': 0.992002, 'recall_consonant': 0.993338, 'acc_grapheme': 0.976891, 'acc_vowel': 0.993365, 'acc_consonant': 0.992695, 'loss_grapheme': 0.152285, 'loss_vowel': 0.098294, 'loss_consonant': 0.072691}\n",
      "  216 | 0.000003 | 106496/160596 | 1.9785 | 2.4781 |\n",
      "val: {'recall': 0.983697, 'recall_grapheme': 0.974696, 'recall_vowel': 0.992243, 'recall_consonant': 0.993152, 'acc_grapheme': 0.977139, 'acc_vowel': 0.993515, 'acc_consonant': 0.992844, 'loss_grapheme': 0.136251, 'loss_vowel': 0.081004, 'loss_consonant': 0.062391}\n",
      "  217 | 0.000004 | 151552/160596 | 1.7952 | 2.6555 |\n",
      "val: {'recall': 0.983419, 'recall_grapheme': 0.974198, 'recall_vowel': 0.991826, 'recall_consonant': 0.993457, 'acc_grapheme': 0.976841, 'acc_vowel': 0.993365, 'acc_consonant': 0.992645, 'loss_grapheme': 0.164372, 'loss_vowel': 0.103884, 'loss_consonant': 0.077102}\n",
      "  219 | 0.000006 | 036864/160596 | 3.8158 | 2.8693 |\n",
      "val: {'recall': 0.983445, 'recall_grapheme': 0.974382, 'recall_vowel': 0.991415, 'recall_consonant': 0.993601, 'acc_grapheme': 0.976966, 'acc_vowel': 0.993167, 'acc_consonant': 0.992744, 'loss_grapheme': 0.210876, 'loss_vowel': 0.142655, 'loss_consonant': 0.101577}\n",
      "  220 | 0.000008 | 081920/160596 | 1.0271 | 2.8277 |\n",
      "val: {'recall': 0.983185, 'recall_grapheme': 0.974129, 'recall_vowel': 0.99125, 'recall_consonant': 0.993232, 'acc_grapheme': 0.976642, 'acc_vowel': 0.993092, 'acc_consonant': 0.992471, 'loss_grapheme': 0.234174, 'loss_vowel': 0.154384, 'loss_consonant': 0.112791}\n",
      "  221 | 0.000010 | 126976/160596 | 2.4618 | 2.3522 |\n",
      "val: {'recall': 0.983455, 'recall_grapheme': 0.974313, 'recall_vowel': 0.992006, 'recall_consonant': 0.993189, 'acc_grapheme': 0.976816, 'acc_vowel': 0.99344, 'acc_consonant': 0.992595, 'loss_grapheme': 0.146878, 'loss_vowel': 0.091093, 'loss_consonant': 0.069716}\n",
      "  223 | 0.000011 | 012288/160596 | 4.1128 | 3.3767 |\n",
      "val: {'recall': 0.982989, 'recall_grapheme': 0.974089, 'recall_vowel': 0.991586, 'recall_consonant': 0.992191, 'acc_grapheme': 0.976444, 'acc_vowel': 0.993167, 'acc_consonant': 0.992446, 'loss_grapheme': 0.243563, 'loss_vowel': 0.161453, 'loss_consonant': 0.116324}\n",
      "  224 | 0.000013 | 057344/160596 | 0.0057 | 2.5589 |\n",
      "val: {'recall': 0.984023, 'recall_grapheme': 0.975166, 'recall_vowel': 0.992345, 'recall_consonant': 0.993415, 'acc_grapheme': 0.977363, 'acc_vowel': 0.993614, 'acc_consonant': 0.993018, 'loss_grapheme': 0.134893, 'loss_vowel': 0.0801, 'loss_consonant': 0.061919}\n",
      "** saved\n",
      "  225 | 0.000015 | 102400/160596 | 2.2098 | 2.9238 |\n",
      "val: {'recall': 0.98339, 'recall_grapheme': 0.974908, 'recall_vowel': 0.991781, 'recall_consonant': 0.991962, 'acc_grapheme': 0.977015, 'acc_vowel': 0.993291, 'acc_consonant': 0.992918, 'loss_grapheme': 0.147875, 'loss_vowel': 0.085897, 'loss_consonant': 0.067179}\n",
      "  226 | 0.000017 | 147456/160596 | 3.9314 | 2.6118 |\n",
      "val: {'recall': 0.983455, 'recall_grapheme': 0.97399, 'recall_vowel': 0.992184, 'recall_consonant': 0.993657, 'acc_grapheme': 0.976394, 'acc_vowel': 0.993316, 'acc_consonant': 0.992869, 'loss_grapheme': 0.260603, 'loss_vowel': 0.174768, 'loss_consonant': 0.122946}\n",
      "  228 | 0.000018 | 032768/160596 | 1.3321 | 2.7465 |\n",
      "val: {'recall': 0.983324, 'recall_grapheme': 0.974321, 'recall_vowel': 0.992513, 'recall_consonant': 0.992142, 'acc_grapheme': 0.976618, 'acc_vowel': 0.993639, 'acc_consonant': 0.992496, 'loss_grapheme': 0.191847, 'loss_vowel': 0.123191, 'loss_consonant': 0.09136}\n",
      "  229 | 0.000019 | 077824/160596 | 4.0169 | 2.7678 |\n",
      "val: {'recall': 0.982983, 'recall_grapheme': 0.973085, 'recall_vowel': 0.9923, 'recall_consonant': 0.993461, 'acc_grapheme': 0.975872, 'acc_vowel': 0.99349, 'acc_consonant': 0.992198, 'loss_grapheme': 0.194358, 'loss_vowel': 0.126801, 'loss_consonant': 0.093851}\n",
      "  230 | 0.000020 | 122880/160596 | 3.0279 | 2.3887 |\n",
      "val: {'recall': 0.982975, 'recall_grapheme': 0.973733, 'recall_vowel': 0.991182, 'recall_consonant': 0.993254, 'acc_grapheme': 0.976444, 'acc_vowel': 0.993316, 'acc_consonant': 0.992322, 'loss_grapheme': 0.188965, 'loss_vowel': 0.119475, 'loss_consonant': 0.088967}\n",
      "  232 | 0.000020 | 008192/160596 | 1.3673 | 2.3447 |\n",
      "val: {'recall': 0.983567, 'recall_grapheme': 0.974325, 'recall_vowel': 0.992037, 'recall_consonant': 0.993582, 'acc_grapheme': 0.977164, 'acc_vowel': 0.993689, 'acc_consonant': 0.99257, 'loss_grapheme': 0.16634, 'loss_vowel': 0.102809, 'loss_consonant': 0.079551}\n",
      "  233 | 0.000020 | 053248/160596 | 2.5198 | 2.3772 |\n",
      "val: {'recall': 0.983185, 'recall_grapheme': 0.974386, 'recall_vowel': 0.991627, 'recall_consonant': 0.992339, 'acc_grapheme': 0.976816, 'acc_vowel': 0.993316, 'acc_consonant': 0.992943, 'loss_grapheme': 0.15648, 'loss_vowel': 0.097652, 'loss_consonant': 0.074042}\n",
      "  234 | 0.000019 | 098304/160596 | 3.5815 | 2.1953 |\n",
      "val: {'recall': 0.983326, 'recall_grapheme': 0.97442, 'recall_vowel': 0.992246, 'recall_consonant': 0.992218, 'acc_grapheme': 0.976593, 'acc_vowel': 0.993689, 'acc_consonant': 0.992695, 'loss_grapheme': 0.159203, 'loss_vowel': 0.097359, 'loss_consonant': 0.074248}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  235 | 0.000018 | 143360/160596 | 0.0074 | 2.5929 |\n",
      "val: {'recall': 0.9839, 'recall_grapheme': 0.975784, 'recall_vowel': 0.992169, 'recall_consonant': 0.991862, 'acc_grapheme': 0.977388, 'acc_vowel': 0.993713, 'acc_consonant': 0.992794, 'loss_grapheme': 0.149174, 'loss_vowel': 0.088149, 'loss_consonant': 0.067614}\n",
      "  237 | 0.000017 | 028672/160596 | 3.4314 | 2.5235 |\n",
      "val: {'recall': 0.983003, 'recall_grapheme': 0.974027, 'recall_vowel': 0.992122, 'recall_consonant': 0.991835, 'acc_grapheme': 0.976245, 'acc_vowel': 0.993515, 'acc_consonant': 0.99257, 'loss_grapheme': 0.184502, 'loss_vowel': 0.119877, 'loss_consonant': 0.088966}\n",
      "  238 | 0.000015 | 073728/160596 | 3.7852 | 2.2145 |\n",
      "val: {'recall': 0.983339, 'recall_grapheme': 0.97454, 'recall_vowel': 0.992508, 'recall_consonant': 0.991768, 'acc_grapheme': 0.97699, 'acc_vowel': 0.993862, 'acc_consonant': 0.992869, 'loss_grapheme': 0.142637, 'loss_vowel': 0.086487, 'loss_consonant': 0.066051}\n",
      "  239 | 0.000013 | 118784/160596 | 4.4240 | 2.7789 |\n",
      "val: {'recall': 0.983067, 'recall_grapheme': 0.973545, 'recall_vowel': 0.991851, 'recall_consonant': 0.993326, 'acc_grapheme': 0.976295, 'acc_vowel': 0.993241, 'acc_consonant': 0.992198, 'loss_grapheme': 0.231481, 'loss_vowel': 0.155137, 'loss_consonant': 0.11392}\n",
      "  241 | 0.000011 | 004096/160596 | 2.7760 | 3.1845 |\n",
      "val: {'recall': 0.98287, 'recall_grapheme': 0.973667, 'recall_vowel': 0.992561, 'recall_consonant': 0.991583, 'acc_grapheme': 0.976295, 'acc_vowel': 0.993614, 'acc_consonant': 0.992322, 'loss_grapheme': 0.188045, 'loss_vowel': 0.11707, 'loss_consonant': 0.088642}\n",
      "  242 | 0.000010 | 049152/160596 | 4.0174 | 2.6996 |\n",
      "val: {'recall': 0.982844, 'recall_grapheme': 0.973511, 'recall_vowel': 0.992204, 'recall_consonant': 0.99215, 'acc_grapheme': 0.976419, 'acc_vowel': 0.993341, 'acc_consonant': 0.992471, 'loss_grapheme': 0.174799, 'loss_vowel': 0.111783, 'loss_consonant': 0.084823}\n",
      "  243 | 0.000008 | 094208/160596 | 2.0731 | 2.5219 |\n",
      "val: {'recall': 0.983496, 'recall_grapheme': 0.974168, 'recall_vowel': 0.992081, 'recall_consonant': 0.993569, 'acc_grapheme': 0.976667, 'acc_vowel': 0.993539, 'acc_consonant': 0.99257, 'loss_grapheme': 0.183628, 'loss_vowel': 0.120617, 'loss_consonant': 0.089785}\n",
      "  244 | 0.000006 | 139264/160596 | 3.5674 | 2.5420 |\n",
      "val: {'recall': 0.982916, 'recall_grapheme': 0.973863, 'recall_vowel': 0.992081, 'recall_consonant': 0.991856, 'acc_grapheme': 0.976319, 'acc_vowel': 0.993241, 'acc_consonant': 0.992123, 'loss_grapheme': 0.219685, 'loss_vowel': 0.143135, 'loss_consonant': 0.106833}\n",
      "  246 | 0.000004 | 024576/160596 | 2.4969 | 3.2206 |\n",
      "val: {'recall': 0.98295, 'recall_grapheme': 0.973905, 'recall_vowel': 0.991997, 'recall_consonant': 0.991991, 'acc_grapheme': 0.976369, 'acc_vowel': 0.993092, 'acc_consonant': 0.991974, 'loss_grapheme': 0.230262, 'loss_vowel': 0.150324, 'loss_consonant': 0.111247}\n",
      "  247 | 0.000003 | 069632/160596 | 1.6345 | 2.5205 |\n",
      "val: {'recall': 0.982989, 'recall_grapheme': 0.973875, 'recall_vowel': 0.992191, 'recall_consonant': 0.992015, 'acc_grapheme': 0.976518, 'acc_vowel': 0.993266, 'acc_consonant': 0.992645, 'loss_grapheme': 0.200442, 'loss_vowel': 0.129797, 'loss_consonant': 0.097889}\n",
      "  248 | 0.000002 | 114688/160596 | 2.5539 | 2.5102 |\n",
      "val: {'recall': 0.983493, 'recall_grapheme': 0.97474, 'recall_vowel': 0.992465, 'recall_consonant': 0.99203, 'acc_grapheme': 0.976941, 'acc_vowel': 0.993664, 'acc_consonant': 0.992918, 'loss_grapheme': 0.179586, 'loss_vowel': 0.10961, 'loss_consonant': 0.082677}\n",
      "  249 | 0.000001 | 159744/160596 | 2.6443 | 2.5315 |\n",
      "val: {'recall': 0.983436, 'recall_grapheme': 0.974607, 'recall_vowel': 0.99243, 'recall_consonant': 0.992102, 'acc_grapheme': 0.976916, 'acc_vowel': 0.993465, 'acc_consonant': 0.992769, 'loss_grapheme': 0.188485, 'loss_vowel': 0.119684, 'loss_consonant': 0.090774}\n",
      "  251 | 0.000001 | 045056/160596 | 2.8241 | 2.8005 |\n",
      "val: {'recall': 0.983, 'recall_grapheme': 0.973887, 'recall_vowel': 0.992226, 'recall_consonant': 0.991999, 'acc_grapheme': 0.976394, 'acc_vowel': 0.993241, 'acc_consonant': 0.992372, 'loss_grapheme': 0.193364, 'loss_vowel': 0.124109, 'loss_consonant': 0.094963}\n",
      "  252 | 0.000001 | 090112/160596 | 0.9801 | 2.5991 |\n",
      "val: {'recall': 0.983197, 'recall_grapheme': 0.97417, 'recall_vowel': 0.992384, 'recall_consonant': 0.992063, 'acc_grapheme': 0.976767, 'acc_vowel': 0.993539, 'acc_consonant': 0.992744, 'loss_grapheme': 0.167457, 'loss_vowel': 0.105402, 'loss_consonant': 0.079776}\n",
      "  253 | 0.000002 | 135168/160596 | 0.0089 | 2.4857 |\n",
      "val: {'recall': 0.983901, 'recall_grapheme': 0.975459, 'recall_vowel': 0.992881, 'recall_consonant': 0.991804, 'acc_grapheme': 0.977462, 'acc_vowel': 0.993838, 'acc_consonant': 0.993067, 'loss_grapheme': 0.112268, 'loss_vowel': 0.057844, 'loss_consonant': 0.04831}\n",
      "  255 | 0.000003 | 020480/160596 | 3.6621 | 2.1601 |\n",
      "val: {'recall': 0.983556, 'recall_grapheme': 0.974777, 'recall_vowel': 0.992439, 'recall_consonant': 0.99223, 'acc_grapheme': 0.977164, 'acc_vowel': 0.993614, 'acc_consonant': 0.993042, 'loss_grapheme': 0.142003, 'loss_vowel': 0.084221, 'loss_consonant': 0.065667}\n",
      "  256 | 0.000004 | 065536/160596 | 3.8424 | 2.6652 |\n",
      "val: {'recall': 0.983055, 'recall_grapheme': 0.974105, 'recall_vowel': 0.991851, 'recall_consonant': 0.992159, 'acc_grapheme': 0.976543, 'acc_vowel': 0.993266, 'acc_consonant': 0.992521, 'loss_grapheme': 0.222557, 'loss_vowel': 0.143145, 'loss_consonant': 0.105317}\n",
      "  257 | 0.000006 | 110592/160596 | 2.7567 | 2.5264 |\n",
      "val: {'recall': 0.982558, 'recall_grapheme': 0.973091, 'recall_vowel': 0.992129, 'recall_consonant': 0.991922, 'acc_grapheme': 0.97617, 'acc_vowel': 0.993266, 'acc_consonant': 0.992272, 'loss_grapheme': 0.23535, 'loss_vowel': 0.150783, 'loss_consonant': 0.110826}\n",
      "  258 | 0.000008 | 155648/160596 | 4.0552 | 2.6098 |\n",
      "val: {'recall': 0.98289, 'recall_grapheme': 0.973666, 'recall_vowel': 0.992327, 'recall_consonant': 0.991901, 'acc_grapheme': 0.976469, 'acc_vowel': 0.993539, 'acc_consonant': 0.992421, 'loss_grapheme': 0.171161, 'loss_vowel': 0.106859, 'loss_consonant': 0.082241}\n",
      "  260 | 0.000010 | 040960/160596 | 4.4962 | 2.7511 |\n",
      "val: {'recall': 0.982691, 'recall_grapheme': 0.973402, 'recall_vowel': 0.992016, 'recall_consonant': 0.991942, 'acc_grapheme': 0.97622, 'acc_vowel': 0.993241, 'acc_consonant': 0.992446, 'loss_grapheme': 0.190314, 'loss_vowel': 0.123355, 'loss_consonant': 0.093166}\n",
      "  261 | 0.000011 | 086016/160596 | 3.2324 | 2.6127 |\n",
      "val: {'recall': 0.982943, 'recall_grapheme': 0.973984, 'recall_vowel': 0.991934, 'recall_consonant': 0.991872, 'acc_grapheme': 0.976121, 'acc_vowel': 0.993241, 'acc_consonant': 0.992446, 'loss_grapheme': 0.233026, 'loss_vowel': 0.152916, 'loss_consonant': 0.109368}\n",
      "  262 | 0.000013 | 131072/160596 | 2.2610 | 2.3783 |\n",
      "val: {'recall': 0.984127, 'recall_grapheme': 0.975222, 'recall_vowel': 0.992739, 'recall_consonant': 0.993325, 'acc_grapheme': 0.977338, 'acc_vowel': 0.993689, 'acc_consonant': 0.993018, 'loss_grapheme': 0.143043, 'loss_vowel': 0.085241, 'loss_consonant': 0.065172}\n",
      "** saved\n",
      "  264 | 0.000015 | 016384/160596 | 3.4905 | 2.3073 |\n",
      "val: {'recall': 0.983692, 'recall_grapheme': 0.974377, 'recall_vowel': 0.992621, 'recall_consonant': 0.993392, 'acc_grapheme': 0.976742, 'acc_vowel': 0.993614, 'acc_consonant': 0.992968, 'loss_grapheme': 0.162081, 'loss_vowel': 0.098358, 'loss_consonant': 0.074243}\n",
      "  265 | 0.000017 | 061440/160596 | 3.8722 | 2.4571 |\n",
      "val: {'recall': 0.983318, 'recall_grapheme': 0.97483, 'recall_vowel': 0.991775, 'recall_consonant': 0.991837, 'acc_grapheme': 0.976419, 'acc_vowel': 0.993365, 'acc_consonant': 0.992769, 'loss_grapheme': 0.168318, 'loss_vowel': 0.099701, 'loss_consonant': 0.077362}\n",
      "  266 | 0.000018 | 106496/160596 | 2.7249 | 2.5576 |\n",
      "val: {'recall': 0.983375, 'recall_grapheme': 0.973773, 'recall_vowel': 0.992275, 'recall_consonant': 0.99368, 'acc_grapheme': 0.976667, 'acc_vowel': 0.993564, 'acc_consonant': 0.992719, 'loss_grapheme': 0.189813, 'loss_vowel': 0.122276, 'loss_consonant': 0.091238}\n",
      "  267 | 0.000019 | 151552/160596 | 3.2054 | 2.5550 |\n",
      "val: {'recall': 0.983434, 'recall_grapheme': 0.974464, 'recall_vowel': 0.99257, 'recall_consonant': 0.992239, 'acc_grapheme': 0.976916, 'acc_vowel': 0.993614, 'acc_consonant': 0.992719, 'loss_grapheme': 0.134067, 'loss_vowel': 0.079105, 'loss_consonant': 0.062608}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  269 | 0.000020 | 036864/160596 | 3.3534 | 2.2221 |\n",
      "val: {'recall': 0.98411, 'recall_grapheme': 0.975018, 'recall_vowel': 0.993078, 'recall_consonant': 0.993327, 'acc_grapheme': 0.977065, 'acc_vowel': 0.993912, 'acc_consonant': 0.992943, 'loss_grapheme': 0.135213, 'loss_vowel': 0.076796, 'loss_consonant': 0.061474}\n",
      "  270 | 0.000020 | 081920/160596 | 3.8405 | 2.5556 |\n",
      "val: {'recall': 0.98337, 'recall_grapheme': 0.97443, 'recall_vowel': 0.992546, 'recall_consonant': 0.992074, 'acc_grapheme': 0.976518, 'acc_vowel': 0.99349, 'acc_consonant': 0.992595, 'loss_grapheme': 0.177909, 'loss_vowel': 0.11266, 'loss_consonant': 0.086049}\n",
      "  271 | 0.000020 | 126976/160596 | 0.0054 | 2.4768 |\n",
      "val: {'recall': 0.983062, 'recall_grapheme': 0.973783, 'recall_vowel': 0.993131, 'recall_consonant': 0.991551, 'acc_grapheme': 0.976618, 'acc_vowel': 0.993838, 'acc_consonant': 0.992794, 'loss_grapheme': 0.145273, 'loss_vowel': 0.086979, 'loss_consonant': 0.06694}\n",
      "  273 | 0.000019 | 012288/160596 | 3.2754 | 2.7515 |\n",
      "val: {'recall': 0.983808, 'recall_grapheme': 0.974786, 'recall_vowel': 0.99258, 'recall_consonant': 0.993078, 'acc_grapheme': 0.976642, 'acc_vowel': 0.993539, 'acc_consonant': 0.992446, 'loss_grapheme': 0.149451, 'loss_vowel': 0.093398, 'loss_consonant': 0.072008}\n",
      "  274 | 0.000018 | 057344/160596 | 3.7851 | 2.5544 |\n",
      "val: {'recall': 0.983512, 'recall_grapheme': 0.974143, 'recall_vowel': 0.992292, 'recall_consonant': 0.993472, 'acc_grapheme': 0.976121, 'acc_vowel': 0.99349, 'acc_consonant': 0.992645, 'loss_grapheme': 0.170201, 'loss_vowel': 0.102279, 'loss_consonant': 0.080068}\n",
      "  275 | 0.000017 | 102400/160596 | 4.1934 | 2.8920 |\n",
      "val: {'recall': 0.98329, 'recall_grapheme': 0.974271, 'recall_vowel': 0.992469, 'recall_consonant': 0.992151, 'acc_grapheme': 0.976568, 'acc_vowel': 0.99349, 'acc_consonant': 0.992372, 'loss_grapheme': 0.193747, 'loss_vowel': 0.131908, 'loss_consonant': 0.099109}\n",
      "  276 | 0.000015 | 147456/160596 | 3.2433 | 2.6647 |\n",
      "val: {'recall': 0.982795, 'recall_grapheme': 0.973836, 'recall_vowel': 0.991368, 'recall_consonant': 0.99214, 'acc_grapheme': 0.976021, 'acc_vowel': 0.993142, 'acc_consonant': 0.992446, 'loss_grapheme': 0.190177, 'loss_vowel': 0.123197, 'loss_consonant': 0.094497}\n",
      "  278 | 0.000013 | 032768/160596 | 2.7856 | 2.5016 |\n",
      "val: {'recall': 0.983537, 'recall_grapheme': 0.974584, 'recall_vowel': 0.992829, 'recall_consonant': 0.99215, 'acc_grapheme': 0.97699, 'acc_vowel': 0.993589, 'acc_consonant': 0.992695, 'loss_grapheme': 0.169272, 'loss_vowel': 0.106805, 'loss_consonant': 0.080295}\n",
      "  279 | 0.000011 | 077824/160596 | 2.3961 | 2.6281 |\n",
      "val: {'recall': 0.983302, 'recall_grapheme': 0.97443, 'recall_vowel': 0.992076, 'recall_consonant': 0.992274, 'acc_grapheme': 0.976369, 'acc_vowel': 0.993365, 'acc_consonant': 0.992844, 'loss_grapheme': 0.195327, 'loss_vowel': 0.127969, 'loss_consonant': 0.091597}\n",
      "  280 | 0.000010 | 122880/160596 | 2.5240 | 2.5291 |\n",
      "val: {'recall': 0.983308, 'recall_grapheme': 0.974488, 'recall_vowel': 0.992285, 'recall_consonant': 0.99197, 'acc_grapheme': 0.976568, 'acc_vowel': 0.993365, 'acc_consonant': 0.992719, 'loss_grapheme': 0.172937, 'loss_vowel': 0.110631, 'loss_consonant': 0.082459}\n",
      "  282 | 0.000008 | 008192/160596 | 3.7098 | 2.0686 |\n",
      "val: {'recall': 0.98354, 'recall_grapheme': 0.974827, 'recall_vowel': 0.992401, 'recall_consonant': 0.992106, 'acc_grapheme': 0.976916, 'acc_vowel': 0.993564, 'acc_consonant': 0.992769, 'loss_grapheme': 0.153836, 'loss_vowel': 0.089815, 'loss_consonant': 0.068901}\n",
      "  283 | 0.000006 | 053248/160596 | 4.3869 | 2.4580 |\n",
      "val: {'recall': 0.983394, 'recall_grapheme': 0.97423, 'recall_vowel': 0.992612, 'recall_consonant': 0.992504, 'acc_grapheme': 0.976866, 'acc_vowel': 0.993564, 'acc_consonant': 0.992993, 'loss_grapheme': 0.171545, 'loss_vowel': 0.106012, 'loss_consonant': 0.08031}\n",
      "  284 | 0.000004 | 098304/160596 | 0.0048 | 2.5454 |\n",
      "val: {'recall': 0.983757, 'recall_grapheme': 0.975042, 'recall_vowel': 0.993031, 'recall_consonant': 0.991913, 'acc_grapheme': 0.97709, 'acc_vowel': 0.993813, 'acc_consonant': 0.992893, 'loss_grapheme': 0.13936, 'loss_vowel': 0.081417, 'loss_consonant': 0.063211}\n",
      "  285 | 0.000003 | 143360/160596 | 4.1055 | 2.5224 |\n",
      "val: {'recall': 0.983722, 'recall_grapheme': 0.975257, 'recall_vowel': 0.992439, 'recall_consonant': 0.991935, 'acc_grapheme': 0.97699, 'acc_vowel': 0.993539, 'acc_consonant': 0.992645, 'loss_grapheme': 0.174784, 'loss_vowel': 0.11213, 'loss_consonant': 0.085006}\n",
      "  287 | 0.000002 | 028672/160596 | 0.0103 | 2.2860 |\n",
      "val: {'recall': 0.984126, 'recall_grapheme': 0.975616, 'recall_vowel': 0.992937, 'recall_consonant': 0.992338, 'acc_grapheme': 0.977686, 'acc_vowel': 0.993838, 'acc_consonant': 0.992993, 'loss_grapheme': 0.115143, 'loss_vowel': 0.062195, 'loss_consonant': 0.050545}\n",
      "  288 | 0.000001 | 073728/160596 | 2.3913 | 2.2926 |\n",
      "val: {'recall': 0.983601, 'recall_grapheme': 0.974818, 'recall_vowel': 0.992798, 'recall_consonant': 0.991969, 'acc_grapheme': 0.977065, 'acc_vowel': 0.993515, 'acc_consonant': 0.992869, 'loss_grapheme': 0.149875, 'loss_vowel': 0.084847, 'loss_consonant': 0.06616}\n",
      "  289 | 0.000001 | 118784/160596 | 0.9708 | 2.8445 |\n",
      "val: {'recall': 0.983662, 'recall_grapheme': 0.975048, 'recall_vowel': 0.992283, 'recall_consonant': 0.992267, 'acc_grapheme': 0.977139, 'acc_vowel': 0.99349, 'acc_consonant': 0.992918, 'loss_grapheme': 0.189927, 'loss_vowel': 0.119331, 'loss_consonant': 0.089019}\n",
      "  291 | 0.000001 | 004096/160596 | 2.4721 | 2.1648 |\n",
      "val: {'recall': 0.98332, 'recall_grapheme': 0.974329, 'recall_vowel': 0.992532, 'recall_consonant': 0.992088, 'acc_grapheme': 0.976692, 'acc_vowel': 0.993465, 'acc_consonant': 0.992794, 'loss_grapheme': 0.157491, 'loss_vowel': 0.096176, 'loss_consonant': 0.074049}\n",
      "  292 | 0.000002 | 049152/160596 | 2.6300 | 2.8051 |\n",
      "val: {'recall': 0.983565, 'recall_grapheme': 0.974808, 'recall_vowel': 0.992669, 'recall_consonant': 0.991974, 'acc_grapheme': 0.977139, 'acc_vowel': 0.993664, 'acc_consonant': 0.992993, 'loss_grapheme': 0.170905, 'loss_vowel': 0.105015, 'loss_consonant': 0.080189}\n",
      "  293 | 0.000003 | 094208/160596 | 3.9769 | 2.5116 |\n",
      "val: {'recall': 0.983673, 'recall_grapheme': 0.974857, 'recall_vowel': 0.992798, 'recall_consonant': 0.99218, 'acc_grapheme': 0.977015, 'acc_vowel': 0.993713, 'acc_consonant': 0.992869, 'loss_grapheme': 0.188153, 'loss_vowel': 0.122731, 'loss_consonant': 0.091493}\n",
      "  294 | 0.000004 | 139264/160596 | 3.2321 | 2.6135 |\n",
      "val: {'recall': 0.983341, 'recall_grapheme': 0.974478, 'recall_vowel': 0.992291, 'recall_consonant': 0.992119, 'acc_grapheme': 0.976717, 'acc_vowel': 0.993589, 'acc_consonant': 0.993042, 'loss_grapheme': 0.158887, 'loss_vowel': 0.101571, 'loss_consonant': 0.076616}\n",
      "  296 | 0.000006 | 024576/160596 | 3.4685 | 2.5231 |\n",
      "val: {'recall': 0.98366, 'recall_grapheme': 0.975023, 'recall_vowel': 0.992412, 'recall_consonant': 0.992182, 'acc_grapheme': 0.977239, 'acc_vowel': 0.993738, 'acc_consonant': 0.992893, 'loss_grapheme': 0.143843, 'loss_vowel': 0.086554, 'loss_consonant': 0.067077}\n",
      "  297 | 0.000008 | 069632/160596 | 3.5874 | 2.2814 |\n",
      "val: {'recall': 0.983333, 'recall_grapheme': 0.974431, 'recall_vowel': 0.992141, 'recall_consonant': 0.992328, 'acc_grapheme': 0.976816, 'acc_vowel': 0.99344, 'acc_consonant': 0.992769, 'loss_grapheme': 0.162493, 'loss_vowel': 0.099395, 'loss_consonant': 0.076328}\n",
      "  298 | 0.000010 | 114688/160596 | 2.7955 | 2.4470 |\n",
      "val: {'recall': 0.982711, 'recall_grapheme': 0.973192, 'recall_vowel': 0.992334, 'recall_consonant': 0.992127, 'acc_grapheme': 0.976096, 'acc_vowel': 0.993316, 'acc_consonant': 0.992844, 'loss_grapheme': 0.148653, 'loss_vowel': 0.087982, 'loss_consonant': 0.069542}\n",
      "  299 | 0.000011 | 159744/160596 | 0.0035 | 2.5661 |\n",
      "val: {'recall': 0.983257, 'recall_grapheme': 0.974118, 'recall_vowel': 0.992581, 'recall_consonant': 0.992211, 'acc_grapheme': 0.976518, 'acc_vowel': 0.993465, 'acc_consonant': 0.992372, 'loss_grapheme': 0.184033, 'loss_vowel': 0.119224, 'loss_consonant': 0.091121}\n",
      "  301 | 0.000013 | 045056/160596 | 0.0053 | 2.3409 |\n",
      "val: {'recall': 0.983525, 'recall_grapheme': 0.974854, 'recall_vowel': 0.992763, 'recall_consonant': 0.991627, 'acc_grapheme': 0.977214, 'acc_vowel': 0.993689, 'acc_consonant': 0.992844, 'loss_grapheme': 0.119894, 'loss_vowel': 0.06264, 'loss_consonant': 0.051792}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  302 | 0.000015 | 090112/160596 | 2.6312 | 2.7341 |\n",
      "val: {'recall': 0.98289, 'recall_grapheme': 0.973678, 'recall_vowel': 0.992302, 'recall_consonant': 0.991904, 'acc_grapheme': 0.976493, 'acc_vowel': 0.993266, 'acc_consonant': 0.992446, 'loss_grapheme': 0.178524, 'loss_vowel': 0.109209, 'loss_consonant': 0.086438}\n",
      "  303 | 0.000017 | 135168/160596 | 1.2320 | 2.5044 |\n",
      "val: {'recall': 0.983363, 'recall_grapheme': 0.97375, 'recall_vowel': 0.992526, 'recall_consonant': 0.993426, 'acc_grapheme': 0.976444, 'acc_vowel': 0.993689, 'acc_consonant': 0.992496, 'loss_grapheme': 0.216388, 'loss_vowel': 0.137286, 'loss_consonant': 0.099744}\n",
      "  305 | 0.000018 | 020480/160596 | 0.9559 | 2.8179 |\n",
      "val: {'recall': 0.983209, 'recall_grapheme': 0.973712, 'recall_vowel': 0.992287, 'recall_consonant': 0.993125, 'acc_grapheme': 0.976469, 'acc_vowel': 0.993539, 'acc_consonant': 0.992695, 'loss_grapheme': 0.159226, 'loss_vowel': 0.097191, 'loss_consonant': 0.074482}\n",
      "  306 | 0.000019 | 065536/160596 | 0.9294 | 2.3533 |\n",
      "val: {'recall': 0.983968, 'recall_grapheme': 0.975195, 'recall_vowel': 0.992575, 'recall_consonant': 0.992907, 'acc_grapheme': 0.977164, 'acc_vowel': 0.993788, 'acc_consonant': 0.992695, 'loss_grapheme': 0.165393, 'loss_vowel': 0.09809, 'loss_consonant': 0.075028}\n",
      "  307 | 0.000020 | 110592/160596 | 3.5728 | 2.6467 |\n",
      "val: {'recall': 0.983517, 'recall_grapheme': 0.974712, 'recall_vowel': 0.992707, 'recall_consonant': 0.991936, 'acc_grapheme': 0.976966, 'acc_vowel': 0.993639, 'acc_consonant': 0.993042, 'loss_grapheme': 0.151054, 'loss_vowel': 0.092533, 'loss_consonant': 0.069468}\n",
      "  308 | 0.000020 | 155648/160596 | 0.0071 | 2.5830 |\n",
      "val: {'recall': 0.982848, 'recall_grapheme': 0.973893, 'recall_vowel': 0.992229, 'recall_consonant': 0.991377, 'acc_grapheme': 0.976692, 'acc_vowel': 0.993341, 'acc_consonant': 0.992421, 'loss_grapheme': 0.16332, 'loss_vowel': 0.102053, 'loss_consonant': 0.076552}\n",
      "  310 | 0.000020 | 040960/160596 | 2.3435 | 2.3747 |\n",
      "val: {'recall': 0.983626, 'recall_grapheme': 0.974487, 'recall_vowel': 0.992488, 'recall_consonant': 0.993042, 'acc_grapheme': 0.976717, 'acc_vowel': 0.993813, 'acc_consonant': 0.992943, 'loss_grapheme': 0.134018, 'loss_vowel': 0.074481, 'loss_consonant': 0.058651}\n",
      "  311 | 0.000019 | 086016/160596 | 3.6884 | 2.4105 |\n",
      "val: {'recall': 0.983464, 'recall_grapheme': 0.974128, 'recall_vowel': 0.992545, 'recall_consonant': 0.993056, 'acc_grapheme': 0.976593, 'acc_vowel': 0.993589, 'acc_consonant': 0.992396, 'loss_grapheme': 0.183188, 'loss_vowel': 0.115597, 'loss_consonant': 0.088079}\n",
      "  312 | 0.000018 | 131072/160596 | 2.9927 | 2.5608 |\n",
      "val: {'recall': 0.983793, 'recall_grapheme': 0.974676, 'recall_vowel': 0.992501, 'recall_consonant': 0.993317, 'acc_grapheme': 0.976816, 'acc_vowel': 0.99349, 'acc_consonant': 0.992595, 'loss_grapheme': 0.183928, 'loss_vowel': 0.112994, 'loss_consonant': 0.087036}\n",
      "  314 | 0.000017 | 016384/160596 | 1.1622 | 2.7682 |\n",
      "val: {'recall': 0.98328, 'recall_grapheme': 0.974052, 'recall_vowel': 0.992592, 'recall_consonant': 0.992424, 'acc_grapheme': 0.976841, 'acc_vowel': 0.99344, 'acc_consonant': 0.992744, 'loss_grapheme': 0.214839, 'loss_vowel': 0.133402, 'loss_consonant': 0.09705}\n",
      "  315 | 0.000015 | 061440/160596 | 1.6955 | 2.3953 |\n",
      "val: {'recall': 0.984018, 'recall_grapheme': 0.974969, 'recall_vowel': 0.992902, 'recall_consonant': 0.993231, 'acc_grapheme': 0.97709, 'acc_vowel': 0.993788, 'acc_consonant': 0.992968, 'loss_grapheme': 0.166796, 'loss_vowel': 0.100017, 'loss_consonant': 0.076547}\n",
      "  316 | 0.000013 | 106496/160596 | 3.1856 | 2.5732 |\n",
      "val: {'recall': 0.983871, 'recall_grapheme': 0.974742, 'recall_vowel': 0.993018, 'recall_consonant': 0.992983, 'acc_grapheme': 0.976816, 'acc_vowel': 0.993862, 'acc_consonant': 0.992968, 'loss_grapheme': 0.15585, 'loss_vowel': 0.093598, 'loss_consonant': 0.071877}\n",
      "  317 | 0.000011 | 151552/160596 | 4.1523 | 2.4634 |\n",
      "val: {'recall': 0.983742, 'recall_grapheme': 0.974304, 'recall_vowel': 0.992773, 'recall_consonant': 0.993585, 'acc_grapheme': 0.976692, 'acc_vowel': 0.993465, 'acc_consonant': 0.992744, 'loss_grapheme': 0.202234, 'loss_vowel': 0.125173, 'loss_consonant': 0.095506}\n",
      "  319 | 0.000010 | 036864/160596 | 3.0623 | 2.2848 |\n",
      "val: {'recall': 0.983558, 'recall_grapheme': 0.974382, 'recall_vowel': 0.992742, 'recall_consonant': 0.992726, 'acc_grapheme': 0.976792, 'acc_vowel': 0.993838, 'acc_consonant': 0.992819, 'loss_grapheme': 0.161835, 'loss_vowel': 0.097446, 'loss_consonant': 0.0741}\n",
      "  320 | 0.000008 | 081920/160596 | 3.2847 | 2.5420 |\n",
      "val: {'recall': 0.984105, 'recall_grapheme': 0.975112, 'recall_vowel': 0.993112, 'recall_consonant': 0.993084, 'acc_grapheme': 0.977388, 'acc_vowel': 0.993887, 'acc_consonant': 0.993018, 'loss_grapheme': 0.147351, 'loss_vowel': 0.084841, 'loss_consonant': 0.066973}\n",
      "  321 | 0.000006 | 126976/160596 | 1.6752 | 2.5882 |\n",
      "val: {'recall': 0.983814, 'recall_grapheme': 0.974332, 'recall_vowel': 0.993124, 'recall_consonant': 0.993469, 'acc_grapheme': 0.977065, 'acc_vowel': 0.993862, 'acc_consonant': 0.992719, 'loss_grapheme': 0.179615, 'loss_vowel': 0.11161, 'loss_consonant': 0.085933}\n",
      "  323 | 0.000004 | 012288/160596 | 3.7324 | 2.7321 |\n",
      "val: {'recall': 0.98288, 'recall_grapheme': 0.973663, 'recall_vowel': 0.992293, 'recall_consonant': 0.991902, 'acc_grapheme': 0.976469, 'acc_vowel': 0.99344, 'acc_consonant': 0.99257, 'loss_grapheme': 0.152456, 'loss_vowel': 0.092624, 'loss_consonant': 0.071488}\n",
      "  324 | 0.000003 | 057344/160596 | 3.7979 | 2.7868 |\n",
      "val: {'recall': 0.983286, 'recall_grapheme': 0.973683, 'recall_vowel': 0.992331, 'recall_consonant': 0.993448, 'acc_grapheme': 0.976568, 'acc_vowel': 0.99339, 'acc_consonant': 0.99262, 'loss_grapheme': 0.167126, 'loss_vowel': 0.101594, 'loss_consonant': 0.078658}\n",
      "  325 | 0.000002 | 102400/160596 | 0.0064 | 2.5986 |\n",
      "val: {'recall': 0.983464, 'recall_grapheme': 0.974681, 'recall_vowel': 0.992923, 'recall_consonant': 0.99157, 'acc_grapheme': 0.977313, 'acc_vowel': 0.993912, 'acc_consonant': 0.993092, 'loss_grapheme': 0.125861, 'loss_vowel': 0.070427, 'loss_consonant': 0.05664}\n",
      "  326 | 0.000001 | 147456/160596 | 2.8912 | 2.4693 |\n",
      "val: {'recall': 0.983151, 'recall_grapheme': 0.973982, 'recall_vowel': 0.992845, 'recall_consonant': 0.991796, 'acc_grapheme': 0.977015, 'acc_vowel': 0.993614, 'acc_consonant': 0.992893, 'loss_grapheme': 0.194875, 'loss_vowel': 0.123249, 'loss_consonant': 0.093122}\n",
      "  328 | 0.000001 | 032768/160596 | 3.0790 | 2.6525 |\n",
      "val: {'recall': 0.983242, 'recall_grapheme': 0.973582, 'recall_vowel': 0.992532, 'recall_consonant': 0.993274, 'acc_grapheme': 0.976717, 'acc_vowel': 0.99344, 'acc_consonant': 0.992695, 'loss_grapheme': 0.204823, 'loss_vowel': 0.127185, 'loss_consonant': 0.096621}\n",
      "  329 | 0.000001 | 077824/160596 | 4.4759 | 2.5123 |\n",
      "val: {'recall': 0.982689, 'recall_grapheme': 0.973038, 'recall_vowel': 0.992511, 'recall_consonant': 0.992169, 'acc_grapheme': 0.976593, 'acc_vowel': 0.993316, 'acc_consonant': 0.99257, 'loss_grapheme': 0.158129, 'loss_vowel': 0.093105, 'loss_consonant': 0.073841}\n",
      "  330 | 0.000002 | 122880/160596 | 2.6630 | 2.4423 |\n",
      "val: {'recall': 0.983758, 'recall_grapheme': 0.974772, 'recall_vowel': 0.992899, 'recall_consonant': 0.992588, 'acc_grapheme': 0.977214, 'acc_vowel': 0.993937, 'acc_consonant': 0.993067, 'loss_grapheme': 0.131281, 'loss_vowel': 0.072477, 'loss_consonant': 0.057034}\n",
      "  332 | 0.000003 | 008192/160596 | 2.8158 | 2.7075 |\n",
      "val: {'recall': 0.983405, 'recall_grapheme': 0.974297, 'recall_vowel': 0.992928, 'recall_consonant': 0.992095, 'acc_grapheme': 0.976891, 'acc_vowel': 0.993713, 'acc_consonant': 0.992719, 'loss_grapheme': 0.175042, 'loss_vowel': 0.110833, 'loss_consonant': 0.083531}\n",
      "  333 | 0.000004 | 053248/160596 | 4.2008 | 2.7392 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-323af2dc3716>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;31m#print('train:', train_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;31m#save_model(model, model_file+'_latest')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-0e344cb1f778>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mparam_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mparam_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_coalesced_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Use the autograd function to broadcast if not detach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mbroadcast_coalesced\u001b[0;34m(tensors, devices, buffer_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
