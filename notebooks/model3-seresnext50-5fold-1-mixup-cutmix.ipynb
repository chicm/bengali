{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        #if self.train_mode:\n",
    "        #    augs = get_train_augs()\n",
    "        #    img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        #for i in range(len(x)):\n",
    "        #    transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        #x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44358804003528074"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from over9000.lookahead import Lookahead\n",
    "def LookaheadSGD(params, alpha=0.5, k=6, *args, **kwargs):\n",
    "     sgd = optim.SGD(params, *args, **kwargs)\n",
    "     return Lookahead(sgd, alpha, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        #optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "        optimizer = optim.Adam([{'params': model.parameters(), 'initial_lr': args.lr }], lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-5)\n",
    "        optimizer = LookaheadSGD(\n",
    "            [{'params': model.parameters(), 'initial_lr': args.lr }],\n",
    "            lr=args.lr, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, args.t_max, eta_min=args.min_lr, last_epoch=args.t_max)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model3_se_resnext50_fold1_mixup_cutmix.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 1e-4\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.1\n",
    "args.patience = 10\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160635, 5) (40205, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model3_se_resnext50_fold1_mixup_cutmix.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model3_se_resnext50_fold1_mixup_cutmix.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(backbone='se_resnext50_32x4d', batch_size=1024, beta=1.0, ckp_name='model3_se_resnext50_fold1_mixup_cutmix.pth', cutmix_prob=0.5, factor=0.1, iter_val=200, lr=0.0001, lrs='cosine', min_lr=1e-06, num_epochs=100000, optim='Adam', patience=10, predict=False, t_max=12, val_batch_size=1024)\n",
      "{'recall': 0.983677, 'recall_grapheme': 0.976234, 'recall_vowel': 0.98942, 'recall_consonant': 0.992822, 'acc_grapheme': 0.974008, 'acc_vowel': 0.991071, 'acc_consonant': 0.990747, 'loss_grapheme': 0.260177, 'loss_vowel': 0.170087, 'loss_consonant': 0.123249}\n",
      "    1 | 0.000001 | 045056/160635 | 2.0904 | 2.3344 |\n",
      "val: {'recall': 0.983608, 'recall_grapheme': 0.975824, 'recall_vowel': 0.990264, 'recall_consonant': 0.992522, 'acc_grapheme': 0.974779, 'acc_vowel': 0.991593, 'acc_consonant': 0.990922, 'loss_grapheme': 0.237221, 'loss_vowel': 0.158403, 'loss_consonant': 0.116476}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000003 | 090112/160635 | 3.8444 | 2.4709 |\n",
      "val: {'recall': 0.983178, 'recall_grapheme': 0.976542, 'recall_vowel': 0.989967, 'recall_consonant': 0.989662, 'acc_grapheme': 0.974879, 'acc_vowel': 0.991543, 'acc_consonant': 0.991046, 'loss_grapheme': 0.333962, 'loss_vowel': 0.22906, 'loss_consonant': 0.156294}\n",
      "    3 | 0.000008 | 135168/160635 | 2.2165 | 2.1780 |\n",
      "val: {'recall': 0.983076, 'recall_grapheme': 0.97625, 'recall_vowel': 0.990412, 'recall_consonant': 0.989393, 'acc_grapheme': 0.975028, 'acc_vowel': 0.991469, 'acc_consonant': 0.990474, 'loss_grapheme': 0.190356, 'loss_vowel': 0.100459, 'loss_consonant': 0.084499}\n",
      "    5 | 0.000015 | 020480/160635 | 3.8531 | 2.4569 |\n",
      "val: {'recall': 0.982217, 'recall_grapheme': 0.974871, 'recall_vowel': 0.989584, 'recall_consonant': 0.989543, 'acc_grapheme': 0.974207, 'acc_vowel': 0.99122, 'acc_consonant': 0.990747, 'loss_grapheme': 0.309306, 'loss_vowel': 0.219908, 'loss_consonant': 0.150654}\n",
      "    6 | 0.000026 | 065536/160635 | 3.8297 | 2.1877 |\n",
      "val: {'recall': 0.982621, 'recall_grapheme': 0.975598, 'recall_vowel': 0.989808, 'recall_consonant': 0.98948, 'acc_grapheme': 0.974332, 'acc_vowel': 0.991494, 'acc_consonant': 0.990374, 'loss_grapheme': 0.23287, 'loss_vowel': 0.149141, 'loss_consonant': 0.110343}\n",
      "    7 | 0.000038 | 110592/160635 | 0.8084 | 2.3556 |\n",
      "val: {'recall': 0.982628, 'recall_grapheme': 0.976194, 'recall_vowel': 0.98922, 'recall_consonant': 0.988905, 'acc_grapheme': 0.973958, 'acc_vowel': 0.991121, 'acc_consonant': 0.990499, 'loss_grapheme': 0.258638, 'loss_vowel': 0.169353, 'loss_consonant': 0.126721}\n",
      "    8 | 0.000050 | 155648/160635 | 4.3361 | 2.3788 |\n",
      "val: {'recall': 0.982748, 'recall_grapheme': 0.97545, 'recall_vowel': 0.989618, 'recall_consonant': 0.990475, 'acc_grapheme': 0.973958, 'acc_vowel': 0.991245, 'acc_consonant': 0.990648, 'loss_grapheme': 0.328228, 'loss_vowel': 0.22793, 'loss_consonant': 0.148804}\n",
      "   10 | 0.000063 | 040960/160635 | 3.3621 | 2.0712 |\n",
      "val: {'recall': 0.981319, 'recall_grapheme': 0.974701, 'recall_vowel': 0.989346, 'recall_consonant': 0.986527, 'acc_grapheme': 0.973212, 'acc_vowel': 0.990723, 'acc_consonant': 0.990101, 'loss_grapheme': 0.265197, 'loss_vowel': 0.158857, 'loss_consonant': 0.1184}\n",
      "   11 | 0.000075 | 086016/160635 | 3.4987 | 2.3963 |\n",
      "val: {'recall': 0.981748, 'recall_grapheme': 0.975133, 'recall_vowel': 0.989594, 'recall_consonant': 0.987133, 'acc_grapheme': 0.974307, 'acc_vowel': 0.991145, 'acc_consonant': 0.990126, 'loss_grapheme': 0.298883, 'loss_vowel': 0.204936, 'loss_consonant': 0.128871}\n",
      "   12 | 0.000086 | 131072/160635 | 1.5146 | 2.4509 |\n",
      "val: {'recall': 0.982194, 'recall_grapheme': 0.97357, 'recall_vowel': 0.988958, 'recall_consonant': 0.992677, 'acc_grapheme': 0.971596, 'acc_vowel': 0.990474, 'acc_consonant': 0.988981, 'loss_grapheme': 0.292718, 'loss_vowel': 0.164038, 'loss_consonant': 0.123132}\n",
      "   14 | 0.000093 | 016384/160635 | 2.9702 | 2.0205 |\n",
      "val: {'recall': 0.981318, 'recall_grapheme': 0.973691, 'recall_vowel': 0.98778, 'recall_consonant': 0.990111, 'acc_grapheme': 0.972491, 'acc_vowel': 0.99025, 'acc_consonant': 0.990175, 'loss_grapheme': 0.190314, 'loss_vowel': 0.134385, 'loss_consonant': 0.090402}\n",
      "   15 | 0.000098 | 061440/160635 | 0.6324 | 2.2238 |\n",
      "val: {'recall': 0.980432, 'recall_grapheme': 0.973147, 'recall_vowel': 0.988271, 'recall_consonant': 0.987163, 'acc_grapheme': 0.972043, 'acc_vowel': 0.990772, 'acc_consonant': 0.9902, 'loss_grapheme': 0.236377, 'loss_vowel': 0.134244, 'loss_consonant': 0.107328}\n",
      "   16 | 0.000100 | 106496/160635 | 1.9907 | 2.5348 |\n",
      "val: {'recall': 0.980867, 'recall_grapheme': 0.972064, 'recall_vowel': 0.988335, 'recall_consonant': 0.991005, 'acc_grapheme': 0.971372, 'acc_vowel': 0.990772, 'acc_consonant': 0.989554, 'loss_grapheme': 0.337994, 'loss_vowel': 0.216886, 'loss_consonant': 0.163334}\n",
      "   17 | 0.000098 | 151552/160635 | 3.6867 | 2.3381 |\n",
      "val: {'recall': 0.982697, 'recall_grapheme': 0.974374, 'recall_vowel': 0.989925, 'recall_consonant': 0.992116, 'acc_grapheme': 0.971969, 'acc_vowel': 0.99122, 'acc_consonant': 0.989852, 'loss_grapheme': 0.247561, 'loss_vowel': 0.193827, 'loss_consonant': 0.126153}\n",
      "   19 | 0.000093 | 036864/160635 | 0.8013 | 2.3825 |\n",
      "val: {'recall': 0.982459, 'recall_grapheme': 0.974535, 'recall_vowel': 0.989934, 'recall_consonant': 0.990833, 'acc_grapheme': 0.971596, 'acc_vowel': 0.990772, 'acc_consonant': 0.99025, 'loss_grapheme': 0.236627, 'loss_vowel': 0.15658, 'loss_consonant': 0.113139}\n",
      "   20 | 0.000086 | 081920/160635 | 2.0170 | 2.2414 |\n",
      "val: {'recall': 0.983051, 'recall_grapheme': 0.975305, 'recall_vowel': 0.990443, 'recall_consonant': 0.99115, 'acc_grapheme': 0.973436, 'acc_vowel': 0.991494, 'acc_consonant': 0.990847, 'loss_grapheme': 0.195493, 'loss_vowel': 0.130947, 'loss_consonant': 0.100554}\n",
      "   21 | 0.000075 | 126976/160635 | 1.8182 | 2.3540 |\n",
      "val: {'recall': 0.983322, 'recall_grapheme': 0.975015, 'recall_vowel': 0.991861, 'recall_consonant': 0.991398, 'acc_grapheme': 0.974157, 'acc_vowel': 0.992265, 'acc_consonant': 0.990648, 'loss_grapheme': 0.220687, 'loss_vowel': 0.143551, 'loss_consonant': 0.101206}\n",
      "   23 | 0.000063 | 012288/160635 | 2.2450 | 2.3768 |\n",
      "val: {'recall': 0.984206, 'recall_grapheme': 0.977544, 'recall_vowel': 0.991176, 'recall_consonant': 0.990562, 'acc_grapheme': 0.975177, 'acc_vowel': 0.992215, 'acc_consonant': 0.99122, 'loss_grapheme': 0.269725, 'loss_vowel': 0.170327, 'loss_consonant': 0.12693}\n",
      "** saved\n",
      "   24 | 0.000051 | 057344/160635 | 0.7717 | 2.2950 |\n",
      "val: {'recall': 0.982982, 'recall_grapheme': 0.974627, 'recall_vowel': 0.990959, 'recall_consonant': 0.991713, 'acc_grapheme': 0.974431, 'acc_vowel': 0.991842, 'acc_consonant': 0.992066, 'loss_grapheme': 0.243578, 'loss_vowel': 0.169116, 'loss_consonant': 0.120256}\n",
      "   25 | 0.000038 | 102400/160635 | 1.9879 | 2.2406 |\n",
      "val: {'recall': 0.983778, 'recall_grapheme': 0.976604, 'recall_vowel': 0.989572, 'recall_consonant': 0.992332, 'acc_grapheme': 0.97565, 'acc_vowel': 0.991941, 'acc_consonant': 0.991643, 'loss_grapheme': 0.221563, 'loss_vowel': 0.155191, 'loss_consonant': 0.10667}\n",
      "   26 | 0.000026 | 147456/160635 | 0.5722 | 2.1116 |\n",
      "val: {'recall': 0.984168, 'recall_grapheme': 0.976852, 'recall_vowel': 0.990106, 'recall_consonant': 0.992861, 'acc_grapheme': 0.975849, 'acc_vowel': 0.992066, 'acc_consonant': 0.991941, 'loss_grapheme': 0.212963, 'loss_vowel': 0.155551, 'loss_consonant': 0.104498}\n",
      "   28 | 0.000015 | 032768/160635 | 1.7695 | 2.0071 |\n",
      "val: {'recall': 0.984645, 'recall_grapheme': 0.97806, 'recall_vowel': 0.991, 'recall_consonant': 0.991461, 'acc_grapheme': 0.976794, 'acc_vowel': 0.992339, 'acc_consonant': 0.991494, 'loss_grapheme': 0.191613, 'loss_vowel': 0.116696, 'loss_consonant': 0.08584}\n",
      "** saved\n",
      "   29 | 0.000008 | 077824/160635 | 3.5717 | 2.2001 |\n",
      "val: {'recall': 0.985021, 'recall_grapheme': 0.978248, 'recall_vowel': 0.990513, 'recall_consonant': 0.993076, 'acc_grapheme': 0.976645, 'acc_vowel': 0.992339, 'acc_consonant': 0.992041, 'loss_grapheme': 0.235908, 'loss_vowel': 0.176284, 'loss_consonant': 0.121743}\n",
      "** saved\n",
      "   30 | 0.000003 | 122880/160635 | 4.3678 | 2.1901 |\n",
      "val: {'recall': 0.984865, 'recall_grapheme': 0.9779, 'recall_vowel': 0.990852, 'recall_consonant': 0.992807, 'acc_grapheme': 0.976197, 'acc_vowel': 0.992414, 'acc_consonant': 0.991867, 'loss_grapheme': 0.21761, 'loss_vowel': 0.147035, 'loss_consonant': 0.105371}\n",
      "   32 | 0.000001 | 008192/160635 | 1.0745 | 2.5013 |\n",
      "val: {'recall': 0.985275, 'recall_grapheme': 0.978473, 'recall_vowel': 0.991202, 'recall_consonant': 0.992951, 'acc_grapheme': 0.97667, 'acc_vowel': 0.992638, 'acc_consonant': 0.992115, 'loss_grapheme': 0.243088, 'loss_vowel': 0.173878, 'loss_consonant': 0.119502}\n",
      "** saved\n",
      "   33 | 0.000003 | 053248/160635 | 1.9845 | 2.1110 |\n",
      "val: {'recall': 0.985149, 'recall_grapheme': 0.978833, 'recall_vowel': 0.990439, 'recall_consonant': 0.99249, 'acc_grapheme': 0.976869, 'acc_vowel': 0.992314, 'acc_consonant': 0.991817, 'loss_grapheme': 0.234981, 'loss_vowel': 0.16268, 'loss_consonant': 0.120753}\n",
      "   34 | 0.000008 | 098304/160635 | 1.9988 | 2.1572 |\n",
      "val: {'recall': 0.984782, 'recall_grapheme': 0.978087, 'recall_vowel': 0.990974, 'recall_consonant': 0.991979, 'acc_grapheme': 0.976222, 'acc_vowel': 0.992414, 'acc_consonant': 0.991693, 'loss_grapheme': 0.205886, 'loss_vowel': 0.136243, 'loss_consonant': 0.10084}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000015 | 143360/160635 | 2.2455 | 2.2200 |\n",
      "val: {'recall': 0.984993, 'recall_grapheme': 0.97823, 'recall_vowel': 0.990737, 'recall_consonant': 0.992777, 'acc_grapheme': 0.976073, 'acc_vowel': 0.992513, 'acc_consonant': 0.992091, 'loss_grapheme': 0.247657, 'loss_vowel': 0.18098, 'loss_consonant': 0.126431}\n",
      "   37 | 0.000026 | 028672/160635 | 3.7019 | 2.3401 |\n",
      "val: {'recall': 0.984241, 'recall_grapheme': 0.977432, 'recall_vowel': 0.990938, 'recall_consonant': 0.991163, 'acc_grapheme': 0.975476, 'acc_vowel': 0.992364, 'acc_consonant': 0.991742, 'loss_grapheme': 0.250919, 'loss_vowel': 0.175898, 'loss_consonant': 0.120783}\n",
      "   38 | 0.000038 | 073728/160635 | 3.6996 | 2.3324 |\n",
      "val: {'recall': 0.983927, 'recall_grapheme': 0.977136, 'recall_vowel': 0.990032, 'recall_consonant': 0.991406, 'acc_grapheme': 0.974978, 'acc_vowel': 0.992339, 'acc_consonant': 0.990897, 'loss_grapheme': 0.269713, 'loss_vowel': 0.184357, 'loss_consonant': 0.125567}\n",
      "   39 | 0.000050 | 118784/160635 | 3.0159 | 2.0852 |\n",
      "val: {'recall': 0.983175, 'recall_grapheme': 0.975971, 'recall_vowel': 0.990048, 'recall_consonant': 0.990709, 'acc_grapheme': 0.975401, 'acc_vowel': 0.991643, 'acc_consonant': 0.991444, 'loss_grapheme': 0.2185, 'loss_vowel': 0.16541, 'loss_consonant': 0.122773}\n",
      "   41 | 0.000063 | 004096/160635 | 3.6587 | 2.5087 |\n",
      "val: {'recall': 0.984286, 'recall_grapheme': 0.977554, 'recall_vowel': 0.990602, 'recall_consonant': 0.991434, 'acc_grapheme': 0.975202, 'acc_vowel': 0.992215, 'acc_consonant': 0.990822, 'loss_grapheme': 0.232492, 'loss_vowel': 0.15701, 'loss_consonant': 0.105291}\n",
      "   42 | 0.000075 | 049152/160635 | 2.0007 | 2.3091 |\n",
      "val: {'recall': 0.983175, 'recall_grapheme': 0.975948, 'recall_vowel': 0.990864, 'recall_consonant': 0.98994, 'acc_grapheme': 0.974207, 'acc_vowel': 0.991892, 'acc_consonant': 0.991693, 'loss_grapheme': 0.250867, 'loss_vowel': 0.187425, 'loss_consonant': 0.132212}\n",
      "   43 | 0.000086 | 094208/160635 | 2.0034 | 2.2818 |\n",
      "val: {'recall': 0.982923, 'recall_grapheme': 0.976052, 'recall_vowel': 0.988668, 'recall_consonant': 0.99092, 'acc_grapheme': 0.975451, 'acc_vowel': 0.991394, 'acc_consonant': 0.990275, 'loss_grapheme': 0.214655, 'loss_vowel': 0.14388, 'loss_consonant': 0.124111}\n",
      "   44 | 0.000093 | 139264/160635 | 1.8533 | 2.2680 |\n",
      "val: {'recall': 0.983258, 'recall_grapheme': 0.976928, 'recall_vowel': 0.989479, 'recall_consonant': 0.989699, 'acc_grapheme': 0.975302, 'acc_vowel': 0.991991, 'acc_consonant': 0.990847, 'loss_grapheme': 0.225499, 'loss_vowel': 0.166031, 'loss_consonant': 0.113983}\n",
      "   46 | 0.000098 | 024576/160635 | 3.1237 | 2.4275 |\n",
      "val: {'recall': 0.984234, 'recall_grapheme': 0.97796, 'recall_vowel': 0.99115, 'recall_consonant': 0.989865, 'acc_grapheme': 0.975899, 'acc_vowel': 0.992165, 'acc_consonant': 0.991245, 'loss_grapheme': 0.277788, 'loss_vowel': 0.188018, 'loss_consonant': 0.123185}\n",
      "   47 | 0.000100 | 069632/160635 | 1.2105 | 2.3189 |\n",
      "val: {'recall': 0.982555, 'recall_grapheme': 0.975948, 'recall_vowel': 0.990993, 'recall_consonant': 0.987331, 'acc_grapheme': 0.974108, 'acc_vowel': 0.992215, 'acc_consonant': 0.990101, 'loss_grapheme': 0.214077, 'loss_vowel': 0.13407, 'loss_consonant': 0.098292}\n",
      "   48 | 0.000098 | 114688/160635 | 4.5762 | 2.2702 |\n",
      "val: {'recall': 0.983403, 'recall_grapheme': 0.977032, 'recall_vowel': 0.990326, 'recall_consonant': 0.989221, 'acc_grapheme': 0.974978, 'acc_vowel': 0.991892, 'acc_consonant': 0.990772, 'loss_grapheme': 0.210682, 'loss_vowel': 0.144986, 'loss_consonant': 0.104272}\n",
      "   49 | 0.000093 | 159744/160635 | 0.2953 | 2.1526 |\n",
      "val: {'recall': 0.983699, 'recall_grapheme': 0.977205, 'recall_vowel': 0.990539, 'recall_consonant': 0.989846, 'acc_grapheme': 0.976147, 'acc_vowel': 0.991494, 'acc_consonant': 0.990946, 'loss_grapheme': 0.218722, 'loss_vowel': 0.130266, 'loss_consonant': 0.098796}\n",
      "   51 | 0.000086 | 045056/160635 | 2.3938 | 2.2992 |\n",
      "val: {'recall': 0.985193, 'recall_grapheme': 0.979417, 'recall_vowel': 0.990318, 'recall_consonant': 0.99162, 'acc_grapheme': 0.977068, 'acc_vowel': 0.992091, 'acc_consonant': 0.991668, 'loss_grapheme': 0.246844, 'loss_vowel': 0.193449, 'loss_consonant': 0.120171}\n",
      "   52 | 0.000075 | 090112/160635 | 1.7719 | 2.2034 |\n",
      "val: {'recall': 0.983869, 'recall_grapheme': 0.977639, 'recall_vowel': 0.990211, 'recall_consonant': 0.989986, 'acc_grapheme': 0.975575, 'acc_vowel': 0.991991, 'acc_consonant': 0.992165, 'loss_grapheme': 0.197621, 'loss_vowel': 0.145955, 'loss_consonant': 0.097651}\n",
      "   53 | 0.000063 | 135168/160635 | 1.8424 | 2.2588 |\n",
      "val: {'recall': 0.985112, 'recall_grapheme': 0.979328, 'recall_vowel': 0.99058, 'recall_consonant': 0.991212, 'acc_grapheme': 0.977291, 'acc_vowel': 0.992439, 'acc_consonant': 0.992339, 'loss_grapheme': 0.264934, 'loss_vowel': 0.201853, 'loss_consonant': 0.138122}\n",
      "   55 | 0.000051 | 020480/160635 | 2.9245 | 2.1460 |\n",
      "val: {'recall': 0.985002, 'recall_grapheme': 0.978847, 'recall_vowel': 0.991369, 'recall_consonant': 0.990945, 'acc_grapheme': 0.977441, 'acc_vowel': 0.992488, 'acc_consonant': 0.991593, 'loss_grapheme': 0.2314, 'loss_vowel': 0.169382, 'loss_consonant': 0.12118}\n",
      "   56 | 0.000038 | 065536/160635 | 3.3000 | 2.4192 |\n",
      "val: {'recall': 0.985781, 'recall_grapheme': 0.980748, 'recall_vowel': 0.990415, 'recall_consonant': 0.991211, 'acc_grapheme': 0.978734, 'acc_vowel': 0.99229, 'acc_consonant': 0.991792, 'loss_grapheme': 0.217322, 'loss_vowel': 0.148495, 'loss_consonant': 0.110458}\n",
      "** saved\n",
      "   57 | 0.000026 | 110592/160635 | 1.9608 | 2.2993 |\n",
      "val: {'recall': 0.985686, 'recall_grapheme': 0.980665, 'recall_vowel': 0.991049, 'recall_consonant': 0.990364, 'acc_grapheme': 0.977988, 'acc_vowel': 0.992787, 'acc_consonant': 0.991543, 'loss_grapheme': 0.199497, 'loss_vowel': 0.118394, 'loss_consonant': 0.097738}\n",
      "   58 | 0.000015 | 155648/160635 | 2.0654 | 2.1409 |\n",
      "val: {'recall': 0.985049, 'recall_grapheme': 0.979097, 'recall_vowel': 0.99081, 'recall_consonant': 0.991193, 'acc_grapheme': 0.977888, 'acc_vowel': 0.992488, 'acc_consonant': 0.991842, 'loss_grapheme': 0.227383, 'loss_vowel': 0.160636, 'loss_consonant': 0.117119}\n",
      "   60 | 0.000008 | 040960/160635 | 1.5529 | 2.0761 |\n",
      "val: {'recall': 0.985633, 'recall_grapheme': 0.979862, 'recall_vowel': 0.991186, 'recall_consonant': 0.99162, 'acc_grapheme': 0.977839, 'acc_vowel': 0.992762, 'acc_consonant': 0.992115, 'loss_grapheme': 0.226249, 'loss_vowel': 0.161238, 'loss_consonant': 0.112364}\n",
      "   61 | 0.000003 | 086016/160635 | 1.3528 | 2.0209 |\n",
      "val: {'recall': 0.986149, 'recall_grapheme': 0.980948, 'recall_vowel': 0.991594, 'recall_consonant': 0.991106, 'acc_grapheme': 0.978809, 'acc_vowel': 0.992837, 'acc_consonant': 0.991867, 'loss_grapheme': 0.16956, 'loss_vowel': 0.098055, 'loss_consonant': 0.081416}\n",
      "** saved\n",
      "   62 | 0.000001 | 131072/160635 | 1.6218 | 2.1132 |\n",
      "val: {'recall': 0.985648, 'recall_grapheme': 0.980048, 'recall_vowel': 0.991365, 'recall_consonant': 0.991132, 'acc_grapheme': 0.978062, 'acc_vowel': 0.992886, 'acc_consonant': 0.992265, 'loss_grapheme': 0.181687, 'loss_vowel': 0.116632, 'loss_consonant': 0.08922}\n",
      "   64 | 0.000003 | 016384/160635 | 1.7650 | 1.6101 |\n",
      "val: {'recall': 0.986262, 'recall_grapheme': 0.981073, 'recall_vowel': 0.991434, 'recall_consonant': 0.991468, 'acc_grapheme': 0.978485, 'acc_vowel': 0.992911, 'acc_consonant': 0.992464, 'loss_grapheme': 0.188233, 'loss_vowel': 0.122525, 'loss_consonant': 0.091764}\n",
      "** saved\n",
      "   65 | 0.000008 | 061440/160635 | 2.1407 | 2.3428 |\n",
      "val: {'recall': 0.985894, 'recall_grapheme': 0.980491, 'recall_vowel': 0.991202, 'recall_consonant': 0.991392, 'acc_grapheme': 0.978162, 'acc_vowel': 0.992687, 'acc_consonant': 0.992041, 'loss_grapheme': 0.226089, 'loss_vowel': 0.164073, 'loss_consonant': 0.117547}\n",
      "   66 | 0.000015 | 106496/160635 | 2.0660 | 2.0573 |\n",
      "val: {'recall': 0.985557, 'recall_grapheme': 0.980221, 'recall_vowel': 0.99132, 'recall_consonant': 0.990464, 'acc_grapheme': 0.977814, 'acc_vowel': 0.992936, 'acc_consonant': 0.991867, 'loss_grapheme': 0.244239, 'loss_vowel': 0.178255, 'loss_consonant': 0.123389}\n",
      "   67 | 0.000026 | 151552/160635 | 3.1770 | 2.2642 |\n",
      "val: {'recall': 0.98543, 'recall_grapheme': 0.979475, 'recall_vowel': 0.991252, 'recall_consonant': 0.99152, 'acc_grapheme': 0.978237, 'acc_vowel': 0.992638, 'acc_consonant': 0.992016, 'loss_grapheme': 0.207084, 'loss_vowel': 0.124993, 'loss_consonant': 0.104328}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 0.000038 | 036864/160635 | 2.4610 | 2.1686 |\n",
      "val: {'recall': 0.984814, 'recall_grapheme': 0.978799, 'recall_vowel': 0.991126, 'recall_consonant': 0.990532, 'acc_grapheme': 0.977192, 'acc_vowel': 0.992737, 'acc_consonant': 0.991618, 'loss_grapheme': 0.253304, 'loss_vowel': 0.180456, 'loss_consonant': 0.125874}\n",
      "   70 | 0.000051 | 081920/160635 | 0.5252 | 1.9787 |\n",
      "val: {'recall': 0.985653, 'recall_grapheme': 0.979328, 'recall_vowel': 0.991478, 'recall_consonant': 0.99248, 'acc_grapheme': 0.977043, 'acc_vowel': 0.992961, 'acc_consonant': 0.992091, 'loss_grapheme': 0.195625, 'loss_vowel': 0.137956, 'loss_consonant': 0.101491}\n",
      "   71 | 0.000063 | 126976/160635 | 1.0431 | 2.2177 |\n",
      "val: {'recall': 0.985487, 'recall_grapheme': 0.980201, 'recall_vowel': 0.991331, 'recall_consonant': 0.990214, 'acc_grapheme': 0.977068, 'acc_vowel': 0.992314, 'acc_consonant': 0.991618, 'loss_grapheme': 0.24609, 'loss_vowel': 0.194368, 'loss_consonant': 0.120942}\n",
      "   73 | 0.000075 | 012288/160635 | 2.3321 | 2.5735 |\n",
      "val: {'recall': 0.985063, 'recall_grapheme': 0.979453, 'recall_vowel': 0.990398, 'recall_consonant': 0.990946, 'acc_grapheme': 0.97657, 'acc_vowel': 0.992066, 'acc_consonant': 0.991892, 'loss_grapheme': 0.284051, 'loss_vowel': 0.185397, 'loss_consonant': 0.124426}\n",
      "   74 | 0.000086 | 057344/160635 | 1.0313 | 2.2389 |\n",
      "val: {'recall': 0.983037, 'recall_grapheme': 0.97643, 'recall_vowel': 0.989576, 'recall_consonant': 0.989712, 'acc_grapheme': 0.976495, 'acc_vowel': 0.991867, 'acc_consonant': 0.991892, 'loss_grapheme': 0.255448, 'loss_vowel': 0.186054, 'loss_consonant': 0.118127}\n",
      "   75 | 0.000093 | 102400/160635 | 2.0855 | 2.1107 |\n",
      "val: {'recall': 0.985176, 'recall_grapheme': 0.979535, 'recall_vowel': 0.991674, 'recall_consonant': 0.989962, 'acc_grapheme': 0.976272, 'acc_vowel': 0.992265, 'acc_consonant': 0.991742, 'loss_grapheme': 0.2284, 'loss_vowel': 0.151701, 'loss_consonant': 0.114527}\n",
      "   76 | 0.000098 | 147456/160635 | 1.9177 | 2.2986 |\n",
      "val: {'recall': 0.984435, 'recall_grapheme': 0.977917, 'recall_vowel': 0.98964, 'recall_consonant': 0.992265, 'acc_grapheme': 0.97657, 'acc_vowel': 0.991916, 'acc_consonant': 0.990946, 'loss_grapheme': 0.213725, 'loss_vowel': 0.126215, 'loss_consonant': 0.105359}\n",
      "   78 | 0.000100 | 032768/160635 | 2.2592 | 2.0635 |\n",
      "val: {'recall': 0.984888, 'recall_grapheme': 0.979412, 'recall_vowel': 0.99116, 'recall_consonant': 0.989567, 'acc_grapheme': 0.977789, 'acc_vowel': 0.992165, 'acc_consonant': 0.991767, 'loss_grapheme': 0.22981, 'loss_vowel': 0.162296, 'loss_consonant': 0.107548}\n",
      "   79 | 0.000098 | 077824/160635 | 1.7650 | 2.2903 |\n",
      "val: {'recall': 0.98429, 'recall_grapheme': 0.977591, 'recall_vowel': 0.99205, 'recall_consonant': 0.989927, 'acc_grapheme': 0.975998, 'acc_vowel': 0.992314, 'acc_consonant': 0.991991, 'loss_grapheme': 0.219351, 'loss_vowel': 0.165211, 'loss_consonant': 0.1198}\n",
      "   80 | 0.000093 | 122880/160635 | 3.3062 | 2.3441 |\n",
      "val: {'recall': 0.983356, 'recall_grapheme': 0.977356, 'recall_vowel': 0.989716, 'recall_consonant': 0.988996, 'acc_grapheme': 0.975227, 'acc_vowel': 0.991096, 'acc_consonant': 0.991369, 'loss_grapheme': 0.317216, 'loss_vowel': 0.253836, 'loss_consonant': 0.156896}\n",
      "   82 | 0.000086 | 008192/160635 | 3.4231 | 2.1872 |\n",
      "val: {'recall': 0.984093, 'recall_grapheme': 0.977788, 'recall_vowel': 0.991582, 'recall_consonant': 0.989216, 'acc_grapheme': 0.978013, 'acc_vowel': 0.992663, 'acc_consonant': 0.991742, 'loss_grapheme': 0.264251, 'loss_vowel': 0.178791, 'loss_consonant': 0.122513}\n",
      "   83 | 0.000075 | 053248/160635 | 1.8126 | 2.2362 |\n",
      "val: {'recall': 0.984731, 'recall_grapheme': 0.978366, 'recall_vowel': 0.991464, 'recall_consonant': 0.990727, 'acc_grapheme': 0.976471, 'acc_vowel': 0.992115, 'acc_consonant': 0.991966, 'loss_grapheme': 0.257887, 'loss_vowel': 0.213593, 'loss_consonant': 0.138677}\n",
      "   84 | 0.000063 | 098304/160635 | 3.5990 | 2.1050 |\n",
      "val: {'recall': 0.986258, 'recall_grapheme': 0.981892, 'recall_vowel': 0.991453, 'recall_consonant': 0.989793, 'acc_grapheme': 0.978983, 'acc_vowel': 0.992687, 'acc_consonant': 0.992339, 'loss_grapheme': 0.203974, 'loss_vowel': 0.160997, 'loss_consonant': 0.106879}\n",
      "   85 | 0.000051 | 143360/160635 | 4.2096 | 2.0902 |\n",
      "val: {'recall': 0.986498, 'recall_grapheme': 0.981231, 'recall_vowel': 0.991647, 'recall_consonant': 0.991883, 'acc_grapheme': 0.979331, 'acc_vowel': 0.992886, 'acc_consonant': 0.993061, 'loss_grapheme': 0.235385, 'loss_vowel': 0.188152, 'loss_consonant': 0.122335}\n",
      "** saved\n",
      "   87 | 0.000038 | 028672/160635 | 1.8978 | 2.3862 |\n",
      "val: {'recall': 0.986913, 'recall_grapheme': 0.981427, 'recall_vowel': 0.992283, 'recall_consonant': 0.992515, 'acc_grapheme': 0.980152, 'acc_vowel': 0.993359, 'acc_consonant': 0.992488, 'loss_grapheme': 0.242671, 'loss_vowel': 0.191488, 'loss_consonant': 0.125944}\n",
      "** saved\n",
      "   88 | 0.000026 | 073728/160635 | 2.1623 | 2.0593 |\n",
      "val: {'recall': 0.986335, 'recall_grapheme': 0.98055, 'recall_vowel': 0.992249, 'recall_consonant': 0.991989, 'acc_grapheme': 0.979679, 'acc_vowel': 0.99311, 'acc_consonant': 0.992737, 'loss_grapheme': 0.220261, 'loss_vowel': 0.16776, 'loss_consonant': 0.115469}\n",
      "   89 | 0.000015 | 118784/160635 | 1.4199 | 2.1468 |\n",
      "val: {'recall': 0.98673, 'recall_grapheme': 0.981664, 'recall_vowel': 0.992544, 'recall_consonant': 0.991049, 'acc_grapheme': 0.980624, 'acc_vowel': 0.993235, 'acc_consonant': 0.992563, 'loss_grapheme': 0.169663, 'loss_vowel': 0.111079, 'loss_consonant': 0.082744}\n",
      "   91 | 0.000008 | 004096/160635 | 1.0223 | 1.5928 |\n",
      "val: {'recall': 0.9871, 'recall_grapheme': 0.982166, 'recall_vowel': 0.992015, 'recall_consonant': 0.99205, 'acc_grapheme': 0.980649, 'acc_vowel': 0.993235, 'acc_consonant': 0.992712, 'loss_grapheme': 0.192558, 'loss_vowel': 0.136108, 'loss_consonant': 0.099339}\n",
      "** saved\n",
      "   92 | 0.000003 | 049152/160635 | 0.9559 | 2.0824 |\n",
      "val: {'recall': 0.98675, 'recall_grapheme': 0.981698, 'recall_vowel': 0.991712, 'recall_consonant': 0.991891, 'acc_grapheme': 0.980525, 'acc_vowel': 0.992812, 'acc_consonant': 0.992563, 'loss_grapheme': 0.19267, 'loss_vowel': 0.135888, 'loss_consonant': 0.098126}\n",
      "   93 | 0.000001 | 094208/160635 | 1.4379 | 1.9450 |\n",
      "val: {'recall': 0.986994, 'recall_grapheme': 0.98194, 'recall_vowel': 0.992008, 'recall_consonant': 0.992089, 'acc_grapheme': 0.980475, 'acc_vowel': 0.993135, 'acc_consonant': 0.992613, 'loss_grapheme': 0.19059, 'loss_vowel': 0.135722, 'loss_consonant': 0.097139}\n",
      "   94 | 0.000003 | 139264/160635 | 2.0218 | 2.0622 |\n",
      "val: {'recall': 0.986912, 'recall_grapheme': 0.981857, 'recall_vowel': 0.991852, 'recall_consonant': 0.992084, 'acc_grapheme': 0.980575, 'acc_vowel': 0.993036, 'acc_consonant': 0.992638, 'loss_grapheme': 0.205607, 'loss_vowel': 0.149005, 'loss_consonant': 0.105468}\n",
      "   96 | 0.000008 | 024576/160635 | 2.2013 | 2.2195 |\n",
      "val: {'recall': 0.98664, 'recall_grapheme': 0.981135, 'recall_vowel': 0.991639, 'recall_consonant': 0.992653, 'acc_grapheme': 0.979903, 'acc_vowel': 0.993135, 'acc_consonant': 0.992812, 'loss_grapheme': 0.245401, 'loss_vowel': 0.18756, 'loss_consonant': 0.128635}\n",
      "   97 | 0.000015 | 069632/160635 | 1.5420 | 1.9482 |\n",
      "val: {'recall': 0.987189, 'recall_grapheme': 0.982487, 'recall_vowel': 0.992074, 'recall_consonant': 0.991709, 'acc_grapheme': 0.980301, 'acc_vowel': 0.99311, 'acc_consonant': 0.99229, 'loss_grapheme': 0.183034, 'loss_vowel': 0.128234, 'loss_consonant': 0.092508}\n",
      "** saved\n",
      "   98 | 0.000026 | 114688/160635 | 0.9734 | 2.0686 |\n",
      "val: {'recall': 0.98673, 'recall_grapheme': 0.982017, 'recall_vowel': 0.991721, 'recall_consonant': 0.991167, 'acc_grapheme': 0.980276, 'acc_vowel': 0.992986, 'acc_consonant': 0.992488, 'loss_grapheme': 0.179806, 'loss_vowel': 0.133639, 'loss_consonant': 0.096351}\n",
      "   99 | 0.000038 | 159744/160635 | 0.8079 | 2.0856 |\n",
      "val: {'recall': 0.986926, 'recall_grapheme': 0.982105, 'recall_vowel': 0.992242, 'recall_consonant': 0.991252, 'acc_grapheme': 0.979853, 'acc_vowel': 0.993284, 'acc_consonant': 0.992115, 'loss_grapheme': 0.192885, 'loss_vowel': 0.13872, 'loss_consonant': 0.099787}\n",
      "  101 | 0.000051 | 045056/160635 | 0.6514 | 1.9936 |\n",
      "val: {'recall': 0.985999, 'recall_grapheme': 0.979927, 'recall_vowel': 0.991734, 'recall_consonant': 0.992406, 'acc_grapheme': 0.978709, 'acc_vowel': 0.992862, 'acc_consonant': 0.992364, 'loss_grapheme': 0.208897, 'loss_vowel': 0.151445, 'loss_consonant': 0.098272}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 0.000063 | 090112/160635 | 3.7992 | 2.0780 |\n",
      "val: {'recall': 0.985838, 'recall_grapheme': 0.980367, 'recall_vowel': 0.992233, 'recall_consonant': 0.990388, 'acc_grapheme': 0.978261, 'acc_vowel': 0.99326, 'acc_consonant': 0.992265, 'loss_grapheme': 0.212108, 'loss_vowel': 0.146763, 'loss_consonant': 0.10454}\n",
      "  103 | 0.000075 | 135168/160635 | 1.2545 | 2.1160 |\n",
      "val: {'recall': 0.986154, 'recall_grapheme': 0.981112, 'recall_vowel': 0.991653, 'recall_consonant': 0.99074, 'acc_grapheme': 0.979331, 'acc_vowel': 0.992961, 'acc_consonant': 0.992265, 'loss_grapheme': 0.192632, 'loss_vowel': 0.139365, 'loss_consonant': 0.096497}\n",
      "  105 | 0.000086 | 020480/160635 | 3.0426 | 2.1825 |\n",
      "val: {'recall': 0.985144, 'recall_grapheme': 0.979303, 'recall_vowel': 0.991517, 'recall_consonant': 0.990453, 'acc_grapheme': 0.976595, 'acc_vowel': 0.99219, 'acc_consonant': 0.991643, 'loss_grapheme': 0.244186, 'loss_vowel': 0.160959, 'loss_consonant': 0.107405}\n",
      "  106 | 0.000093 | 065536/160635 | 3.2499 | 2.0794 |\n",
      "val: {'recall': 0.984782, 'recall_grapheme': 0.979198, 'recall_vowel': 0.989958, 'recall_consonant': 0.990776, 'acc_grapheme': 0.977366, 'acc_vowel': 0.992364, 'acc_consonant': 0.991444, 'loss_grapheme': 0.23177, 'loss_vowel': 0.172369, 'loss_consonant': 0.12062}\n",
      "  107 | 0.000098 | 110592/160635 | 1.7403 | 2.0769 |\n",
      "val: {'recall': 0.985114, 'recall_grapheme': 0.978998, 'recall_vowel': 0.991768, 'recall_consonant': 0.990695, 'acc_grapheme': 0.977167, 'acc_vowel': 0.992215, 'acc_consonant': 0.991195, 'loss_grapheme': 0.182182, 'loss_vowel': 0.113452, 'loss_consonant': 0.090033}\n",
      "  108 | 0.000100 | 155648/160635 | 0.7866 | 2.1169 |\n",
      "val: {'recall': 0.985178, 'recall_grapheme': 0.97933, 'recall_vowel': 0.991408, 'recall_consonant': 0.990642, 'acc_grapheme': 0.978386, 'acc_vowel': 0.993085, 'acc_consonant': 0.99219, 'loss_grapheme': 0.241691, 'loss_vowel': 0.168977, 'loss_consonant': 0.115851}\n",
      "  110 | 0.000098 | 040960/160635 | 1.2256 | 1.9533 |\n",
      "val: {'recall': 0.986152, 'recall_grapheme': 0.9808, 'recall_vowel': 0.992673, 'recall_consonant': 0.990335, 'acc_grapheme': 0.978958, 'acc_vowel': 0.992563, 'acc_consonant': 0.991991, 'loss_grapheme': 0.176315, 'loss_vowel': 0.127358, 'loss_consonant': 0.081577}\n",
      "  111 | 0.000093 | 086016/160635 | 1.4287 | 1.9306 |\n",
      "val: {'recall': 0.986625, 'recall_grapheme': 0.980085, 'recall_vowel': 0.993032, 'recall_consonant': 0.993296, 'acc_grapheme': 0.978809, 'acc_vowel': 0.992986, 'acc_consonant': 0.99321, 'loss_grapheme': 0.224598, 'loss_vowel': 0.136131, 'loss_consonant': 0.103552}\n",
      "  112 | 0.000086 | 131072/160635 | 2.4434 | 2.2246 |\n",
      "val: {'recall': 0.986617, 'recall_grapheme': 0.980781, 'recall_vowel': 0.991344, 'recall_consonant': 0.993563, 'acc_grapheme': 0.978087, 'acc_vowel': 0.992687, 'acc_consonant': 0.992712, 'loss_grapheme': 0.291174, 'loss_vowel': 0.234618, 'loss_consonant': 0.156752}\n",
      "  114 | 0.000075 | 016384/160635 | 3.0909 | 2.0659 |\n",
      "val: {'recall': 0.986252, 'recall_grapheme': 0.980244, 'recall_vowel': 0.992492, 'recall_consonant': 0.992029, 'acc_grapheme': 0.978411, 'acc_vowel': 0.99326, 'acc_consonant': 0.99321, 'loss_grapheme': 0.239715, 'loss_vowel': 0.174676, 'loss_consonant': 0.120309}\n",
      "  115 | 0.000063 | 061440/160635 | 2.7435 | 2.2152 |\n",
      "val: {'recall': 0.985633, 'recall_grapheme': 0.980377, 'recall_vowel': 0.992008, 'recall_consonant': 0.989771, 'acc_grapheme': 0.97856, 'acc_vowel': 0.99311, 'acc_consonant': 0.99229, 'loss_grapheme': 0.220867, 'loss_vowel': 0.18685, 'loss_consonant': 0.121345}\n",
      "  116 | 0.000051 | 106496/160635 | 1.9641 | 1.9814 |\n",
      "val: {'recall': 0.98672, 'recall_grapheme': 0.981439, 'recall_vowel': 0.991344, 'recall_consonant': 0.99266, 'acc_grapheme': 0.979331, 'acc_vowel': 0.992886, 'acc_consonant': 0.992663, 'loss_grapheme': 0.19061, 'loss_vowel': 0.144605, 'loss_consonant': 0.0998}\n",
      "  117 | 0.000038 | 151552/160635 | 3.8499 | 2.0685 |\n",
      "val: {'recall': 0.987457, 'recall_grapheme': 0.982574, 'recall_vowel': 0.991444, 'recall_consonant': 0.993235, 'acc_grapheme': 0.9804, 'acc_vowel': 0.993011, 'acc_consonant': 0.99311, 'loss_grapheme': 0.209328, 'loss_vowel': 0.163526, 'loss_consonant': 0.109974}\n",
      "** saved\n",
      "  119 | 0.000026 | 036864/160635 | 1.5581 | 2.0640 |\n",
      "val: {'recall': 0.987253, 'recall_grapheme': 0.981891, 'recall_vowel': 0.992643, 'recall_consonant': 0.992588, 'acc_grapheme': 0.979903, 'acc_vowel': 0.993483, 'acc_consonant': 0.992737, 'loss_grapheme': 0.195316, 'loss_vowel': 0.145269, 'loss_consonant': 0.102614}\n",
      "  120 | 0.000015 | 081920/160635 | 1.6854 | 1.8652 |\n",
      "val: {'recall': 0.987146, 'recall_grapheme': 0.981588, 'recall_vowel': 0.992318, 'recall_consonant': 0.99309, 'acc_grapheme': 0.980002, 'acc_vowel': 0.993583, 'acc_consonant': 0.992812, 'loss_grapheme': 0.188968, 'loss_vowel': 0.143925, 'loss_consonant': 0.098702}\n",
      "  121 | 0.000008 | 126976/160635 | 1.5892 | 2.0470 |\n",
      "val: {'recall': 0.987278, 'recall_grapheme': 0.981969, 'recall_vowel': 0.992131, 'recall_consonant': 0.993043, 'acc_grapheme': 0.980177, 'acc_vowel': 0.993533, 'acc_consonant': 0.992986, 'loss_grapheme': 0.192368, 'loss_vowel': 0.143548, 'loss_consonant': 0.102036}\n",
      "  123 | 0.000003 | 012288/160635 | 1.7558 | 1.4947 |\n",
      "val: {'recall': 0.986927, 'recall_grapheme': 0.981926, 'recall_vowel': 0.992396, 'recall_consonant': 0.991458, 'acc_grapheme': 0.9804, 'acc_vowel': 0.993658, 'acc_consonant': 0.993061, 'loss_grapheme': 0.15992, 'loss_vowel': 0.115563, 'loss_consonant': 0.082194}\n",
      "  124 | 0.000001 | 057344/160635 | 2.5704 | 1.9184 |\n",
      "val: {'recall': 0.987361, 'recall_grapheme': 0.982047, 'recall_vowel': 0.992045, 'recall_consonant': 0.993307, 'acc_grapheme': 0.980525, 'acc_vowel': 0.993483, 'acc_consonant': 0.99321, 'loss_grapheme': 0.2212, 'loss_vowel': 0.172722, 'loss_consonant': 0.119008}\n",
      "  125 | 0.000003 | 102400/160635 | 0.2237 | 1.9853 |\n",
      "val: {'recall': 0.98723, 'recall_grapheme': 0.982003, 'recall_vowel': 0.992061, 'recall_consonant': 0.992852, 'acc_grapheme': 0.980376, 'acc_vowel': 0.993508, 'acc_consonant': 0.99311, 'loss_grapheme': 0.205292, 'loss_vowel': 0.16053, 'loss_consonant': 0.10896}\n",
      "  126 | 0.000008 | 147456/160635 | 3.9018 | 1.9916 |\n",
      "val: {'recall': 0.98756, 'recall_grapheme': 0.982218, 'recall_vowel': 0.992572, 'recall_consonant': 0.993231, 'acc_grapheme': 0.981296, 'acc_vowel': 0.993533, 'acc_consonant': 0.993309, 'loss_grapheme': 0.181912, 'loss_vowel': 0.110176, 'loss_consonant': 0.089806}\n",
      "** saved\n",
      "  128 | 0.000015 | 032768/160635 | 2.7391 | 2.0200 |\n",
      "val: {'recall': 0.987052, 'recall_grapheme': 0.981766, 'recall_vowel': 0.991676, 'recall_consonant': 0.993, 'acc_grapheme': 0.980226, 'acc_vowel': 0.993658, 'acc_consonant': 0.993085, 'loss_grapheme': 0.206177, 'loss_vowel': 0.154077, 'loss_consonant': 0.105768}\n",
      "  129 | 0.000026 | 077824/160635 | 1.5283 | 1.9118 |\n",
      "val: {'recall': 0.986808, 'recall_grapheme': 0.981681, 'recall_vowel': 0.992522, 'recall_consonant': 0.991348, 'acc_grapheme': 0.9805, 'acc_vowel': 0.993757, 'acc_consonant': 0.99321, 'loss_grapheme': 0.186436, 'loss_vowel': 0.123077, 'loss_consonant': 0.091225}\n",
      "  130 | 0.000038 | 122880/160635 | 2.8731 | 2.0261 |\n",
      "val: {'recall': 0.986533, 'recall_grapheme': 0.981161, 'recall_vowel': 0.991478, 'recall_consonant': 0.992335, 'acc_grapheme': 0.979256, 'acc_vowel': 0.993334, 'acc_consonant': 0.993185, 'loss_grapheme': 0.198527, 'loss_vowel': 0.144574, 'loss_consonant': 0.101503}\n",
      "  132 | 0.000050 | 008192/160635 | 1.9532 | 2.0650 |\n",
      "val: {'recall': 0.986486, 'recall_grapheme': 0.981376, 'recall_vowel': 0.991752, 'recall_consonant': 0.991441, 'acc_grapheme': 0.979381, 'acc_vowel': 0.993309, 'acc_consonant': 0.993384, 'loss_grapheme': 0.209192, 'loss_vowel': 0.161391, 'loss_consonant': 0.115663}\n",
      "  133 | 0.000063 | 053248/160635 | 1.1200 | 2.0473 |\n",
      "val: {'recall': 0.985842, 'recall_grapheme': 0.979918, 'recall_vowel': 0.991316, 'recall_consonant': 0.992216, 'acc_grapheme': 0.979406, 'acc_vowel': 0.992911, 'acc_consonant': 0.992986, 'loss_grapheme': 0.20685, 'loss_vowel': 0.159611, 'loss_consonant': 0.106656}\n",
      "  134 | 0.000075 | 098304/160635 | 3.6543 | 2.0959 |\n",
      "val: {'recall': 0.986245, 'recall_grapheme': 0.981218, 'recall_vowel': 0.991565, 'recall_consonant': 0.990976, 'acc_grapheme': 0.978983, 'acc_vowel': 0.99311, 'acc_consonant': 0.992638, 'loss_grapheme': 0.237639, 'loss_vowel': 0.184315, 'loss_consonant': 0.12273}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  135 | 0.000086 | 143360/160635 | 2.7792 | 1.9964 |\n",
      "val: {'recall': 0.986377, 'recall_grapheme': 0.979782, 'recall_vowel': 0.992121, 'recall_consonant': 0.993825, 'acc_grapheme': 0.978958, 'acc_vowel': 0.992712, 'acc_consonant': 0.992986, 'loss_grapheme': 0.228357, 'loss_vowel': 0.179679, 'loss_consonant': 0.116876}\n",
      "  137 | 0.000093 | 028672/160635 | 2.9038 | 2.4141 |\n",
      "val: {'recall': 0.986627, 'recall_grapheme': 0.981186, 'recall_vowel': 0.991381, 'recall_consonant': 0.992754, 'acc_grapheme': 0.978634, 'acc_vowel': 0.992911, 'acc_consonant': 0.992613, 'loss_grapheme': 0.270124, 'loss_vowel': 0.198079, 'loss_consonant': 0.125416}\n",
      "  138 | 0.000098 | 073728/160635 | 2.3268 | 2.1209 |\n",
      "val: {'recall': 0.985957, 'recall_grapheme': 0.980551, 'recall_vowel': 0.990632, 'recall_consonant': 0.992093, 'acc_grapheme': 0.97764, 'acc_vowel': 0.99229, 'acc_consonant': 0.99224, 'loss_grapheme': 0.234382, 'loss_vowel': 0.173528, 'loss_consonant': 0.116617}\n",
      "  139 | 0.000100 | 118784/160635 | 1.9852 | 2.0317 |\n",
      "val: {'recall': 0.985843, 'recall_grapheme': 0.979969, 'recall_vowel': 0.991953, 'recall_consonant': 0.99148, 'acc_grapheme': 0.979256, 'acc_vowel': 0.99311, 'acc_consonant': 0.992936, 'loss_grapheme': 0.170496, 'loss_vowel': 0.109856, 'loss_consonant': 0.090586}\n",
      "  141 | 0.000098 | 004096/160635 | 1.8310 | 1.5500 |\n",
      "val: {'recall': 0.987358, 'recall_grapheme': 0.981521, 'recall_vowel': 0.993465, 'recall_consonant': 0.992927, 'acc_grapheme': 0.979182, 'acc_vowel': 0.993085, 'acc_consonant': 0.992414, 'loss_grapheme': 0.193764, 'loss_vowel': 0.135998, 'loss_consonant': 0.095332}\n",
      "  142 | 0.000093 | 049152/160635 | 2.3569 | 2.2823 |\n",
      "val: {'recall': 0.986132, 'recall_grapheme': 0.979802, 'recall_vowel': 0.992166, 'recall_consonant': 0.992756, 'acc_grapheme': 0.97759, 'acc_vowel': 0.992737, 'acc_consonant': 0.992439, 'loss_grapheme': 0.259088, 'loss_vowel': 0.207032, 'loss_consonant': 0.143553}\n",
      "  143 | 0.000086 | 094208/160635 | 1.8282 | 2.0920 |\n",
      "val: {'recall': 0.985892, 'recall_grapheme': 0.979095, 'recall_vowel': 0.992573, 'recall_consonant': 0.992804, 'acc_grapheme': 0.97749, 'acc_vowel': 0.993508, 'acc_consonant': 0.992066, 'loss_grapheme': 0.203046, 'loss_vowel': 0.137324, 'loss_consonant': 0.097167}\n",
      "  144 | 0.000075 | 139264/160635 | 1.7564 | 2.1499 |\n",
      "val: {'recall': 0.987641, 'recall_grapheme': 0.982298, 'recall_vowel': 0.992666, 'recall_consonant': 0.993302, 'acc_grapheme': 0.980425, 'acc_vowel': 0.993583, 'acc_consonant': 0.992961, 'loss_grapheme': 0.22953, 'loss_vowel': 0.159825, 'loss_consonant': 0.119016}\n",
      "** saved\n",
      "  146 | 0.000063 | 024576/160635 | 3.8639 | 1.9424 |\n",
      "val: {'recall': 0.987852, 'recall_grapheme': 0.982473, 'recall_vowel': 0.992403, 'recall_consonant': 0.994058, 'acc_grapheme': 0.980351, 'acc_vowel': 0.993434, 'acc_consonant': 0.993309, 'loss_grapheme': 0.184016, 'loss_vowel': 0.148277, 'loss_consonant': 0.095471}\n",
      "** saved\n",
      "  147 | 0.000050 | 069632/160635 | 3.0303 | 2.1641 |\n",
      "val: {'recall': 0.987165, 'recall_grapheme': 0.981463, 'recall_vowel': 0.992612, 'recall_consonant': 0.993123, 'acc_grapheme': 0.979729, 'acc_vowel': 0.993483, 'acc_consonant': 0.992663, 'loss_grapheme': 0.239893, 'loss_vowel': 0.178749, 'loss_consonant': 0.123605}\n",
      "  148 | 0.000038 | 114688/160635 | 3.6145 | 1.8702 |\n",
      "val: {'recall': 0.987416, 'recall_grapheme': 0.982782, 'recall_vowel': 0.992932, 'recall_consonant': 0.991165, 'acc_grapheme': 0.981296, 'acc_vowel': 0.993832, 'acc_consonant': 0.993409, 'loss_grapheme': 0.149354, 'loss_vowel': 0.103727, 'loss_consonant': 0.075524}\n",
      "  149 | 0.000026 | 159744/160635 | 1.7799 | 1.9329 |\n",
      "val: {'recall': 0.987745, 'recall_grapheme': 0.983181, 'recall_vowel': 0.992871, 'recall_consonant': 0.991745, 'acc_grapheme': 0.981246, 'acc_vowel': 0.993782, 'acc_consonant': 0.993135, 'loss_grapheme': 0.194078, 'loss_vowel': 0.155424, 'loss_consonant': 0.106678}\n",
      "  151 | 0.000015 | 045056/160635 | 1.6280 | 2.0814 |\n",
      "val: {'recall': 0.987624, 'recall_grapheme': 0.983075, 'recall_vowel': 0.992318, 'recall_consonant': 0.992029, 'acc_grapheme': 0.981346, 'acc_vowel': 0.993459, 'acc_consonant': 0.993508, 'loss_grapheme': 0.19651, 'loss_vowel': 0.148985, 'loss_consonant': 0.10611}\n",
      "  152 | 0.000008 | 090112/160635 | 1.1738 | 1.8801 |\n",
      "val: {'recall': 0.98795, 'recall_grapheme': 0.983231, 'recall_vowel': 0.99302, 'recall_consonant': 0.992318, 'acc_grapheme': 0.981793, 'acc_vowel': 0.993906, 'acc_consonant': 0.993658, 'loss_grapheme': 0.168541, 'loss_vowel': 0.116334, 'loss_consonant': 0.08582}\n",
      "** saved\n",
      "  153 | 0.000003 | 135168/160635 | 2.6435 | 2.0325 |\n",
      "val: {'recall': 0.987459, 'recall_grapheme': 0.982172, 'recall_vowel': 0.993227, 'recall_consonant': 0.992264, 'acc_grapheme': 0.981246, 'acc_vowel': 0.994155, 'acc_consonant': 0.993832, 'loss_grapheme': 0.18012, 'loss_vowel': 0.143839, 'loss_consonant': 0.099419}\n",
      "  155 | 0.000001 | 020480/160635 | 1.1622 | 2.3191 |\n",
      "val: {'recall': 0.987573, 'recall_grapheme': 0.982316, 'recall_vowel': 0.993327, 'recall_consonant': 0.992331, 'acc_grapheme': 0.980848, 'acc_vowel': 0.993956, 'acc_consonant': 0.993658, 'loss_grapheme': 0.210115, 'loss_vowel': 0.167128, 'loss_consonant': 0.11389}\n",
      "  156 | 0.000003 | 065536/160635 | 2.3733 | 2.0497 |\n",
      "val: {'recall': 0.9877, 'recall_grapheme': 0.982617, 'recall_vowel': 0.993359, 'recall_consonant': 0.992206, 'acc_grapheme': 0.980898, 'acc_vowel': 0.994006, 'acc_consonant': 0.993583, 'loss_grapheme': 0.216786, 'loss_vowel': 0.176985, 'loss_consonant': 0.119626}\n",
      "  157 | 0.000008 | 110592/160635 | 2.5753 | 2.0421 |\n",
      "val: {'recall': 0.987363, 'recall_grapheme': 0.982061, 'recall_vowel': 0.99292, 'recall_consonant': 0.992409, 'acc_grapheme': 0.980649, 'acc_vowel': 0.993807, 'acc_consonant': 0.993608, 'loss_grapheme': 0.241748, 'loss_vowel': 0.215034, 'loss_consonant': 0.140552}\n",
      "  158 | 0.000015 | 155648/160635 | 1.6688 | 1.8929 |\n",
      "val: {'recall': 0.98726, 'recall_grapheme': 0.981655, 'recall_vowel': 0.992728, 'recall_consonant': 0.993003, 'acc_grapheme': 0.98055, 'acc_vowel': 0.993757, 'acc_consonant': 0.993633, 'loss_grapheme': 0.21166, 'loss_vowel': 0.16847, 'loss_consonant': 0.11781}\n",
      "  160 | 0.000026 | 040960/160635 | 1.6448 | 1.8715 |\n",
      "val: {'recall': 0.987475, 'recall_grapheme': 0.982648, 'recall_vowel': 0.992119, 'recall_consonant': 0.992486, 'acc_grapheme': 0.9805, 'acc_vowel': 0.993658, 'acc_consonant': 0.993757, 'loss_grapheme': 0.200855, 'loss_vowel': 0.146288, 'loss_consonant': 0.104558}\n",
      "  161 | 0.000038 | 086016/160635 | 0.0448 | 1.9920 |\n",
      "val: {'recall': 0.987732, 'recall_grapheme': 0.982436, 'recall_vowel': 0.992802, 'recall_consonant': 0.993253, 'acc_grapheme': 0.980898, 'acc_vowel': 0.994031, 'acc_consonant': 0.993608, 'loss_grapheme': 0.156467, 'loss_vowel': 0.10872, 'loss_consonant': 0.08393}\n",
      "  162 | 0.000050 | 131072/160635 | 2.3863 | 1.9241 |\n",
      "val: {'recall': 0.987203, 'recall_grapheme': 0.982022, 'recall_vowel': 0.992142, 'recall_consonant': 0.992625, 'acc_grapheme': 0.980276, 'acc_vowel': 0.993732, 'acc_consonant': 0.993384, 'loss_grapheme': 0.20673, 'loss_vowel': 0.152478, 'loss_consonant': 0.104632}\n",
      "  164 | 0.000063 | 016384/160635 | 2.1137 | 1.9861 |\n",
      "val: {'recall': 0.987101, 'recall_grapheme': 0.981266, 'recall_vowel': 0.99272, 'recall_consonant': 0.99315, 'acc_grapheme': 0.98055, 'acc_vowel': 0.993757, 'acc_consonant': 0.993881, 'loss_grapheme': 0.224085, 'loss_vowel': 0.187953, 'loss_consonant': 0.118523}\n",
      "  165 | 0.000075 | 061440/160635 | 0.3799 | 1.9103 |\n",
      "val: {'recall': 0.98697, 'recall_grapheme': 0.981873, 'recall_vowel': 0.992661, 'recall_consonant': 0.991472, 'acc_grapheme': 0.980823, 'acc_vowel': 0.993608, 'acc_consonant': 0.99316, 'loss_grapheme': 0.175501, 'loss_vowel': 0.118241, 'loss_consonant': 0.087168}\n",
      "  166 | 0.000086 | 106496/160635 | 1.3590 | 2.0073 |\n",
      "val: {'recall': 0.985815, 'recall_grapheme': 0.980851, 'recall_vowel': 0.991614, 'recall_consonant': 0.989943, 'acc_grapheme': 0.979281, 'acc_vowel': 0.992663, 'acc_consonant': 0.992762, 'loss_grapheme': 0.209779, 'loss_vowel': 0.163393, 'loss_consonant': 0.10728}\n",
      "  167 | 0.000093 | 151552/160635 | 0.7880 | 1.9120 |\n",
      "val: {'recall': 0.983777, 'recall_grapheme': 0.977734, 'recall_vowel': 0.991243, 'recall_consonant': 0.988396, 'acc_grapheme': 0.977764, 'acc_vowel': 0.992787, 'acc_consonant': 0.992364, 'loss_grapheme': 0.177383, 'loss_vowel': 0.122478, 'loss_consonant': 0.082293}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  169 | 0.000098 | 036864/160635 | 0.5497 | 1.8971 |\n",
      "val: {'recall': 0.985981, 'recall_grapheme': 0.979667, 'recall_vowel': 0.99194, 'recall_consonant': 0.992651, 'acc_grapheme': 0.978684, 'acc_vowel': 0.992911, 'acc_consonant': 0.992687, 'loss_grapheme': 0.197685, 'loss_vowel': 0.14456, 'loss_consonant': 0.100354}\n",
      "  170 | 0.000100 | 081920/160635 | 2.5588 | 2.0958 |\n",
      "val: {'recall': 0.98582, 'recall_grapheme': 0.980733, 'recall_vowel': 0.992607, 'recall_consonant': 0.989209, 'acc_grapheme': 0.978237, 'acc_vowel': 0.99326, 'acc_consonant': 0.992862, 'loss_grapheme': 0.213107, 'loss_vowel': 0.147968, 'loss_consonant': 0.103087}\n",
      "  171 | 0.000098 | 126976/160635 | 3.7760 | 2.0841 |\n",
      "val: {'recall': 0.986159, 'recall_grapheme': 0.981718, 'recall_vowel': 0.991368, 'recall_consonant': 0.989833, 'acc_grapheme': 0.979182, 'acc_vowel': 0.993185, 'acc_consonant': 0.992091, 'loss_grapheme': 0.268548, 'loss_vowel': 0.221224, 'loss_consonant': 0.13798}\n",
      "  173 | 0.000093 | 012288/160635 | 1.9614 | 1.8485 |\n",
      "val: {'recall': 0.986466, 'recall_grapheme': 0.98075, 'recall_vowel': 0.992253, 'recall_consonant': 0.99211, 'acc_grapheme': 0.980326, 'acc_vowel': 0.993608, 'acc_consonant': 0.993185, 'loss_grapheme': 0.197912, 'loss_vowel': 0.147219, 'loss_consonant': 0.102307}\n",
      "  174 | 0.000086 | 057344/160635 | 2.9101 | 1.9233 |\n",
      "val: {'recall': 0.987105, 'recall_grapheme': 0.981207, 'recall_vowel': 0.993097, 'recall_consonant': 0.99291, 'acc_grapheme': 0.980624, 'acc_vowel': 0.993583, 'acc_consonant': 0.993334, 'loss_grapheme': 0.194587, 'loss_vowel': 0.158044, 'loss_consonant': 0.107495}\n",
      "  175 | 0.000075 | 102400/160635 | 2.3883 | 1.9379 |\n",
      "val: {'recall': 0.986262, 'recall_grapheme': 0.981638, 'recall_vowel': 0.992849, 'recall_consonant': 0.988924, 'acc_grapheme': 0.980699, 'acc_vowel': 0.993906, 'acc_consonant': 0.993384, 'loss_grapheme': 0.215495, 'loss_vowel': 0.153977, 'loss_consonant': 0.100072}\n",
      "  176 | 0.000063 | 147456/160635 | 1.7380 | 2.0170 |\n",
      "val: {'recall': 0.986731, 'recall_grapheme': 0.981053, 'recall_vowel': 0.992649, 'recall_consonant': 0.992168, 'acc_grapheme': 0.980724, 'acc_vowel': 0.994155, 'acc_consonant': 0.993185, 'loss_grapheme': 0.25556, 'loss_vowel': 0.216559, 'loss_consonant': 0.140628}\n",
      "  178 | 0.000050 | 032768/160635 | 1.3574 | 1.6800 |\n",
      "val: {'recall': 0.988009, 'recall_grapheme': 0.983305, 'recall_vowel': 0.993645, 'recall_consonant': 0.991782, 'acc_grapheme': 0.982888, 'acc_vowel': 0.994429, 'acc_consonant': 0.993384, 'loss_grapheme': 0.161884, 'loss_vowel': 0.103144, 'loss_consonant': 0.079458}\n",
      "** saved\n",
      "  179 | 0.000038 | 077824/160635 | 1.4134 | 1.8371 |\n",
      "val: {'recall': 0.987863, 'recall_grapheme': 0.982936, 'recall_vowel': 0.993175, 'recall_consonant': 0.992406, 'acc_grapheme': 0.982042, 'acc_vowel': 0.994354, 'acc_consonant': 0.993508, 'loss_grapheme': 0.183535, 'loss_vowel': 0.143681, 'loss_consonant': 0.099772}\n",
      "  180 | 0.000026 | 122880/160635 | 2.2630 | 2.0331 |\n",
      "val: {'recall': 0.987452, 'recall_grapheme': 0.982198, 'recall_vowel': 0.993132, 'recall_consonant': 0.992281, 'acc_grapheme': 0.981669, 'acc_vowel': 0.994155, 'acc_consonant': 0.993508, 'loss_grapheme': 0.20816, 'loss_vowel': 0.172201, 'loss_consonant': 0.115879}\n",
      "  182 | 0.000015 | 008192/160635 | 3.3066 | 1.8882 |\n",
      "val: {'recall': 0.98802, 'recall_grapheme': 0.98302, 'recall_vowel': 0.993337, 'recall_consonant': 0.992702, 'acc_grapheme': 0.982266, 'acc_vowel': 0.99423, 'acc_consonant': 0.993832, 'loss_grapheme': 0.201257, 'loss_vowel': 0.162757, 'loss_consonant': 0.107861}\n",
      "** saved\n",
      "  183 | 0.000008 | 053248/160635 | 1.0661 | 1.9203 |\n",
      "val: {'recall': 0.988556, 'recall_grapheme': 0.983932, 'recall_vowel': 0.994012, 'recall_consonant': 0.992347, 'acc_grapheme': 0.983311, 'acc_vowel': 0.994702, 'acc_consonant': 0.993608, 'loss_grapheme': 0.176231, 'loss_vowel': 0.12305, 'loss_consonant': 0.091135}\n",
      "** saved\n",
      "  184 | 0.000003 | 098304/160635 | 1.2055 | 1.9574 |\n",
      "val: {'recall': 0.988767, 'recall_grapheme': 0.984611, 'recall_vowel': 0.993422, 'recall_consonant': 0.992425, 'acc_grapheme': 0.983385, 'acc_vowel': 0.994503, 'acc_consonant': 0.993906, 'loss_grapheme': 0.187127, 'loss_vowel': 0.148147, 'loss_consonant': 0.099131}\n",
      "** saved\n",
      "  185 | 0.000001 | 143360/160635 | 2.5902 | 1.9046 |\n",
      "val: {'recall': 0.988276, 'recall_grapheme': 0.983728, 'recall_vowel': 0.993234, 'recall_consonant': 0.992415, 'acc_grapheme': 0.982614, 'acc_vowel': 0.994304, 'acc_consonant': 0.993807, 'loss_grapheme': 0.205482, 'loss_vowel': 0.170601, 'loss_consonant': 0.112532}\n",
      "  187 | 0.000003 | 028672/160635 | 1.1273 | 1.9633 |\n",
      "val: {'recall': 0.98849, 'recall_grapheme': 0.983828, 'recall_vowel': 0.993637, 'recall_consonant': 0.992668, 'acc_grapheme': 0.982465, 'acc_vowel': 0.994404, 'acc_consonant': 0.993757, 'loss_grapheme': 0.184335, 'loss_vowel': 0.146143, 'loss_consonant': 0.099217}\n",
      "  188 | 0.000008 | 073728/160635 | 2.2691 | 1.8915 |\n",
      "val: {'recall': 0.988525, 'recall_grapheme': 0.984111, 'recall_vowel': 0.993333, 'recall_consonant': 0.992547, 'acc_grapheme': 0.98244, 'acc_vowel': 0.994329, 'acc_consonant': 0.993881, 'loss_grapheme': 0.197331, 'loss_vowel': 0.161034, 'loss_consonant': 0.1096}\n",
      "  189 | 0.000015 | 118784/160635 | 2.7728 | 1.9673 |\n",
      "val: {'recall': 0.987867, 'recall_grapheme': 0.982202, 'recall_vowel': 0.993067, 'recall_consonant': 0.993998, 'acc_grapheme': 0.981171, 'acc_vowel': 0.994304, 'acc_consonant': 0.993558, 'loss_grapheme': 0.227089, 'loss_vowel': 0.193606, 'loss_consonant': 0.128238}\n",
      "  191 | 0.000026 | 004096/160635 | 2.7121 | 2.6289 |\n",
      "val: {'recall': 0.987945, 'recall_grapheme': 0.983201, 'recall_vowel': 0.993492, 'recall_consonant': 0.991885, 'acc_grapheme': 0.981868, 'acc_vowel': 0.994329, 'acc_consonant': 0.993384, 'loss_grapheme': 0.227414, 'loss_vowel': 0.199156, 'loss_consonant': 0.128322}\n",
      "  192 | 0.000038 | 049152/160635 | 2.2372 | 2.1461 |\n",
      "val: {'recall': 0.988211, 'recall_grapheme': 0.983214, 'recall_vowel': 0.993539, 'recall_consonant': 0.992878, 'acc_grapheme': 0.982067, 'acc_vowel': 0.994205, 'acc_consonant': 0.993782, 'loss_grapheme': 0.185731, 'loss_vowel': 0.138134, 'loss_consonant': 0.095379}\n",
      "  193 | 0.000050 | 094208/160635 | 0.3873 | 1.9013 |\n",
      "val: {'recall': 0.987811, 'recall_grapheme': 0.983229, 'recall_vowel': 0.993366, 'recall_consonant': 0.991419, 'acc_grapheme': 0.982092, 'acc_vowel': 0.993633, 'acc_consonant': 0.993881, 'loss_grapheme': 0.150238, 'loss_vowel': 0.114843, 'loss_consonant': 0.075442}\n",
      "  194 | 0.000063 | 139264/160635 | 2.8655 | 1.9134 |\n",
      "val: {'recall': 0.987827, 'recall_grapheme': 0.983342, 'recall_vowel': 0.993199, 'recall_consonant': 0.991424, 'acc_grapheme': 0.981694, 'acc_vowel': 0.993832, 'acc_consonant': 0.993483, 'loss_grapheme': 0.181299, 'loss_vowel': 0.126639, 'loss_consonant': 0.091643}\n",
      "  196 | 0.000075 | 024576/160635 | 0.9792 | 1.9065 |\n",
      "val: {'recall': 0.986605, 'recall_grapheme': 0.98097, 'recall_vowel': 0.991581, 'recall_consonant': 0.9929, 'acc_grapheme': 0.980997, 'acc_vowel': 0.993533, 'acc_consonant': 0.993633, 'loss_grapheme': 0.209691, 'loss_vowel': 0.163499, 'loss_consonant': 0.106771}\n",
      "  197 | 0.000086 | 069632/160635 | 2.3324 | 2.0283 |\n",
      "val: {'recall': 0.986353, 'recall_grapheme': 0.9815, 'recall_vowel': 0.992896, 'recall_consonant': 0.989515, 'acc_grapheme': 0.980052, 'acc_vowel': 0.993757, 'acc_consonant': 0.992886, 'loss_grapheme': 0.207718, 'loss_vowel': 0.169983, 'loss_consonant': 0.123394}\n",
      "  198 | 0.000093 | 114688/160635 | 2.8098 | 1.8892 |\n",
      "val: {'recall': 0.986779, 'recall_grapheme': 0.980151, 'recall_vowel': 0.992897, 'recall_consonant': 0.993916, 'acc_grapheme': 0.979953, 'acc_vowel': 0.993459, 'acc_consonant': 0.993384, 'loss_grapheme': 0.185871, 'loss_vowel': 0.135051, 'loss_consonant': 0.094825}\n",
      "  199 | 0.000098 | 159744/160635 | 1.9463 | 2.0374 |\n",
      "val: {'recall': 0.986583, 'recall_grapheme': 0.981809, 'recall_vowel': 0.992169, 'recall_consonant': 0.990545, 'acc_grapheme': 0.979878, 'acc_vowel': 0.993434, 'acc_consonant': 0.992986, 'loss_grapheme': 0.217114, 'loss_vowel': 0.161383, 'loss_consonant': 0.108024}\n",
      "  201 | 0.000100 | 045056/160635 | 4.1120 | 1.9805 |\n",
      "val: {'recall': 0.987654, 'recall_grapheme': 0.982238, 'recall_vowel': 0.992529, 'recall_consonant': 0.99361, 'acc_grapheme': 0.980425, 'acc_vowel': 0.993459, 'acc_consonant': 0.993583, 'loss_grapheme': 0.206985, 'loss_vowel': 0.163832, 'loss_consonant': 0.108402}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  202 | 0.000098 | 090112/160635 | 1.9797 | 2.0746 |\n",
      "val: {'recall': 0.987258, 'recall_grapheme': 0.981245, 'recall_vowel': 0.992241, 'recall_consonant': 0.9943, 'acc_grapheme': 0.979729, 'acc_vowel': 0.993185, 'acc_consonant': 0.992936, 'loss_grapheme': 0.303623, 'loss_vowel': 0.227468, 'loss_consonant': 0.143516}\n",
      "  203 | 0.000093 | 135168/160635 | 2.6338 | 2.0082 |\n",
      "val: {'recall': 0.987311, 'recall_grapheme': 0.982169, 'recall_vowel': 0.993013, 'recall_consonant': 0.991892, 'acc_grapheme': 0.981594, 'acc_vowel': 0.994055, 'acc_consonant': 0.994031, 'loss_grapheme': 0.189542, 'loss_vowel': 0.153, 'loss_consonant': 0.102781}\n",
      "  205 | 0.000086 | 020480/160635 | 3.4439 | 2.0573 |\n",
      "val: {'recall': 0.986924, 'recall_grapheme': 0.981991, 'recall_vowel': 0.993715, 'recall_consonant': 0.989999, 'acc_grapheme': 0.981569, 'acc_vowel': 0.994404, 'acc_consonant': 0.99321, 'loss_grapheme': 0.217566, 'loss_vowel': 0.165105, 'loss_consonant': 0.111523}\n",
      "  206 | 0.000075 | 065536/160635 | 1.7806 | 1.9520 |\n",
      "val: {'recall': 0.988124, 'recall_grapheme': 0.982783, 'recall_vowel': 0.993544, 'recall_consonant': 0.993387, 'acc_grapheme': 0.982515, 'acc_vowel': 0.994254, 'acc_consonant': 0.993782, 'loss_grapheme': 0.172553, 'loss_vowel': 0.129737, 'loss_consonant': 0.089891}\n",
      "  207 | 0.000063 | 110592/160635 | 1.8598 | 2.0523 |\n",
      "val: {'recall': 0.98775, 'recall_grapheme': 0.982676, 'recall_vowel': 0.993153, 'recall_consonant': 0.992496, 'acc_grapheme': 0.981619, 'acc_vowel': 0.993807, 'acc_consonant': 0.993533, 'loss_grapheme': 0.218239, 'loss_vowel': 0.170526, 'loss_consonant': 0.118218}\n",
      "  208 | 0.000051 | 155648/160635 | 3.2891 | 1.8944 |\n",
      "val: {'recall': 0.988643, 'recall_grapheme': 0.983378, 'recall_vowel': 0.994079, 'recall_consonant': 0.993737, 'acc_grapheme': 0.982664, 'acc_vowel': 0.994503, 'acc_consonant': 0.993981, 'loss_grapheme': 0.199093, 'loss_vowel': 0.173829, 'loss_consonant': 0.110242}\n",
      "  210 | 0.000038 | 040960/160635 | 1.6459 | 1.9396 |\n",
      "val: {'recall': 0.98847, 'recall_grapheme': 0.984362, 'recall_vowel': 0.993338, 'recall_consonant': 0.991816, 'acc_grapheme': 0.983161, 'acc_vowel': 0.99413, 'acc_consonant': 0.993931, 'loss_grapheme': 0.18714, 'loss_vowel': 0.131244, 'loss_consonant': 0.097822}\n",
      "  211 | 0.000026 | 086016/160635 | 0.7686 | 1.9492 |\n",
      "val: {'recall': 0.989093, 'recall_grapheme': 0.9842, 'recall_vowel': 0.99424, 'recall_consonant': 0.993734, 'acc_grapheme': 0.983708, 'acc_vowel': 0.994503, 'acc_consonant': 0.994155, 'loss_grapheme': 0.184342, 'loss_vowel': 0.150527, 'loss_consonant': 0.100361}\n",
      "** saved\n",
      "  212 | 0.000015 | 131072/160635 | 2.7178 | 2.0267 |\n",
      "val: {'recall': 0.988521, 'recall_grapheme': 0.983431, 'recall_vowel': 0.993447, 'recall_consonant': 0.993776, 'acc_grapheme': 0.982664, 'acc_vowel': 0.994329, 'acc_consonant': 0.993881, 'loss_grapheme': 0.188509, 'loss_vowel': 0.152661, 'loss_consonant': 0.103624}\n",
      "  214 | 0.000008 | 016384/160635 | 2.4645 | 2.1395 |\n",
      "val: {'recall': 0.988055, 'recall_grapheme': 0.982474, 'recall_vowel': 0.993437, 'recall_consonant': 0.993836, 'acc_grapheme': 0.982291, 'acc_vowel': 0.994354, 'acc_consonant': 0.993881, 'loss_grapheme': 0.20161, 'loss_vowel': 0.178946, 'loss_consonant': 0.11723}\n",
      "  215 | 0.000003 | 061440/160635 | 1.7724 | 1.9522 |\n",
      "val: {'recall': 0.988773, 'recall_grapheme': 0.983736, 'recall_vowel': 0.993703, 'recall_consonant': 0.993915, 'acc_grapheme': 0.983435, 'acc_vowel': 0.994304, 'acc_consonant': 0.99423, 'loss_grapheme': 0.195734, 'loss_vowel': 0.172168, 'loss_consonant': 0.112172}\n",
      "  216 | 0.000001 | 106496/160635 | 3.4236 | 1.8749 |\n",
      "val: {'recall': 0.988253, 'recall_grapheme': 0.982587, 'recall_vowel': 0.993941, 'recall_consonant': 0.993898, 'acc_grapheme': 0.982863, 'acc_vowel': 0.994379, 'acc_consonant': 0.99413, 'loss_grapheme': 0.216535, 'loss_vowel': 0.184584, 'loss_consonant': 0.120102}\n",
      "  217 | 0.000003 | 151552/160635 | 1.8823 | 1.8333 |\n",
      "val: {'recall': 0.989386, 'recall_grapheme': 0.984933, 'recall_vowel': 0.994428, 'recall_consonant': 0.993249, 'acc_grapheme': 0.984206, 'acc_vowel': 0.994503, 'acc_consonant': 0.994205, 'loss_grapheme': 0.173517, 'loss_vowel': 0.107825, 'loss_consonant': 0.085809}\n",
      "** saved\n",
      "  219 | 0.000008 | 036864/160635 | 1.3657 | 1.8409 |\n",
      "val: {'recall': 0.98952, 'recall_grapheme': 0.98496, 'recall_vowel': 0.994128, 'recall_consonant': 0.994034, 'acc_grapheme': 0.984032, 'acc_vowel': 0.994628, 'acc_consonant': 0.994528, 'loss_grapheme': 0.185609, 'loss_vowel': 0.14548, 'loss_consonant': 0.098939}\n",
      "** saved\n",
      "  220 | 0.000015 | 081920/160635 | 1.8874 | 1.8398 |\n",
      "val: {'recall': 0.98851, 'recall_grapheme': 0.983113, 'recall_vowel': 0.99407, 'recall_consonant': 0.993741, 'acc_grapheme': 0.982838, 'acc_vowel': 0.994603, 'acc_consonant': 0.993931, 'loss_grapheme': 0.20333, 'loss_vowel': 0.162874, 'loss_consonant': 0.108662}\n",
      "  221 | 0.000026 | 126976/160635 | 3.3791 | 1.8147 |\n",
      "val: {'recall': 0.988907, 'recall_grapheme': 0.984594, 'recall_vowel': 0.994159, 'recall_consonant': 0.992282, 'acc_grapheme': 0.984007, 'acc_vowel': 0.994603, 'acc_consonant': 0.994354, 'loss_grapheme': 0.182892, 'loss_vowel': 0.135736, 'loss_consonant': 0.096224}\n",
      "  223 | 0.000038 | 012288/160635 | 1.7998 | 2.2290 |\n",
      "val: {'recall': 0.988681, 'recall_grapheme': 0.984147, 'recall_vowel': 0.993041, 'recall_consonant': 0.993387, 'acc_grapheme': 0.982415, 'acc_vowel': 0.994379, 'acc_consonant': 0.99408, 'loss_grapheme': 0.218812, 'loss_vowel': 0.187851, 'loss_consonant': 0.123746}\n",
      "  224 | 0.000050 | 057344/160635 | 2.2883 | 2.0834 |\n",
      "val: {'recall': 0.988428, 'recall_grapheme': 0.983456, 'recall_vowel': 0.993374, 'recall_consonant': 0.993428, 'acc_grapheme': 0.982266, 'acc_vowel': 0.994379, 'acc_consonant': 0.994055, 'loss_grapheme': 0.224115, 'loss_vowel': 0.165381, 'loss_consonant': 0.112355}\n",
      "  225 | 0.000063 | 102400/160635 | 1.4716 | 1.7693 |\n",
      "val: {'recall': 0.98782, 'recall_grapheme': 0.983881, 'recall_vowel': 0.993011, 'recall_consonant': 0.990508, 'acc_grapheme': 0.982962, 'acc_vowel': 0.993757, 'acc_consonant': 0.993608, 'loss_grapheme': 0.17033, 'loss_vowel': 0.115639, 'loss_consonant': 0.088131}\n",
      "  226 | 0.000075 | 147456/160635 | 1.6731 | 1.7887 |\n",
      "val: {'recall': 0.988853, 'recall_grapheme': 0.984241, 'recall_vowel': 0.993298, 'recall_consonant': 0.993633, 'acc_grapheme': 0.982913, 'acc_vowel': 0.99418, 'acc_consonant': 0.993881, 'loss_grapheme': 0.173875, 'loss_vowel': 0.132423, 'loss_consonant': 0.090724}\n",
      "  228 | 0.000086 | 032768/160635 | 0.5883 | 1.8690 |\n",
      "val: {'recall': 0.987982, 'recall_grapheme': 0.982572, 'recall_vowel': 0.992854, 'recall_consonant': 0.993931, 'acc_grapheme': 0.982092, 'acc_vowel': 0.993981, 'acc_consonant': 0.993782, 'loss_grapheme': 0.226808, 'loss_vowel': 0.160404, 'loss_consonant': 0.111655}\n",
      "  229 | 0.000093 | 077824/160635 | 1.0576 | 2.0112 |\n",
      "val: {'recall': 0.988225, 'recall_grapheme': 0.984135, 'recall_vowel': 0.993392, 'recall_consonant': 0.991239, 'acc_grapheme': 0.982042, 'acc_vowel': 0.994652, 'acc_consonant': 0.993608, 'loss_grapheme': 0.229768, 'loss_vowel': 0.181117, 'loss_consonant': 0.12155}\n",
      "  230 | 0.000098 | 122880/160635 | 2.3372 | 1.9134 |\n",
      "val: {'recall': 0.988019, 'recall_grapheme': 0.9828, 'recall_vowel': 0.992418, 'recall_consonant': 0.994058, 'acc_grapheme': 0.982689, 'acc_vowel': 0.993981, 'acc_consonant': 0.994329, 'loss_grapheme': 0.192033, 'loss_vowel': 0.151526, 'loss_consonant': 0.101421}\n",
      "  231 | 0.000100 | 151552/160635 | 1.8730 | 2.0931 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-c3bffbee882d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbbx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbby2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbby1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(backbone='se_resnext50_32x4d', batch_size=1024, beta=1.0, ckp_name='model3_se_resnext50_fold1_mixup_cutmix.pth', cutmix_prob=0.5, factor=0.1, iter_val=200, lr=0.01, lrs='plateau', min_lr=0.0001, num_epochs=100000, optim='SGD', patience=10, predict=False, t_max=12, val_batch_size=1024)\n",
      "{'recall': 0.040004, 'recall_grapheme': 0.001886, 'recall_vowel': 0.075343, 'recall_consonant': 0.080902, 'acc_grapheme': 0.006168, 'acc_vowel': 0.085064, 'acc_consonant': 0.060192, 'loss_grapheme': 5.120304, 'loss_vowel': 2.479316, 'loss_consonant': 2.24724}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.010000 | 045056/160635 | 4.3485 | 5.5337 |\n",
      "val: {'recall': 0.619079, 'recall_grapheme': 0.304756, 'recall_vowel': 0.922558, 'recall_consonant': 0.944246, 'acc_grapheme': 0.481482, 'acc_vowel': 0.906081, 'acc_consonant': 0.920284, 'loss_grapheme': 2.407548, 'loss_vowel': 0.503989, 'loss_consonant': 0.319169}\n",
      "** saved\n",
      "    2 | 0.010000 | 090112/160635 | 5.2682 | 4.5590 |\n",
      "val: {'recall': 0.827354, 'recall_grapheme': 0.697855, 'recall_vowel': 0.960916, 'recall_consonant': 0.952792, 'acc_grapheme': 0.794677, 'acc_vowel': 0.94446, 'acc_consonant': 0.95411, 'loss_grapheme': 1.24508, 'loss_vowel': 0.414207, 'loss_consonant': 0.254942}\n",
      "** saved\n",
      "    3 | 0.010000 | 135168/160635 | 2.5135 | 4.3535 |\n",
      "val: {'recall': 0.916682, 'recall_grapheme': 0.865008, 'recall_vowel': 0.971118, 'recall_consonant': 0.965595, 'acc_grapheme': 0.875239, 'acc_vowel': 0.963537, 'acc_consonant': 0.965054, 'loss_grapheme': 0.826253, 'loss_vowel': 0.364424, 'loss_consonant': 0.244198}\n",
      "** saved\n",
      "    5 | 0.010000 | 020480/160635 | 6.1092 | 4.4748 |\n",
      "val: {'recall': 0.93774, 'recall_grapheme': 0.904973, 'recall_vowel': 0.971858, 'recall_consonant': 0.969155, 'acc_grapheme': 0.886731, 'acc_vowel': 0.967168, 'acc_consonant': 0.969854, 'loss_grapheme': 0.808228, 'loss_vowel': 0.393886, 'loss_consonant': 0.268043}\n",
      "** saved\n",
      "    6 | 0.010000 | 065536/160635 | 4.1412 | 3.8616 |\n",
      "val: {'recall': 0.944215, 'recall_grapheme': 0.919188, 'recall_vowel': 0.970217, 'recall_consonant': 0.968267, 'acc_grapheme': 0.90934, 'acc_vowel': 0.967964, 'acc_consonant': 0.962791, 'loss_grapheme': 0.742193, 'loss_vowel': 0.340334, 'loss_consonant': 0.258936}\n",
      "** saved\n",
      "    7 | 0.010000 | 110592/160635 | 5.4950 | 3.8696 |\n",
      "val: {'recall': 0.95185, 'recall_grapheme': 0.928287, 'recall_vowel': 0.97681, 'recall_consonant': 0.974016, 'acc_grapheme': 0.925407, 'acc_vowel': 0.970626, 'acc_consonant': 0.973088, 'loss_grapheme': 0.772292, 'loss_vowel': 0.376339, 'loss_consonant': 0.244574}\n",
      "** saved\n",
      "    8 | 0.010000 | 155648/160635 | 4.4379 | 3.7234 |\n",
      "val: {'recall': 0.958003, 'recall_grapheme': 0.935721, 'recall_vowel': 0.980376, 'recall_consonant': 0.980194, 'acc_grapheme': 0.932247, 'acc_vowel': 0.976421, 'acc_consonant': 0.973561, 'loss_grapheme': 0.518119, 'loss_vowel': 0.265574, 'loss_consonant': 0.193271}\n",
      "** saved\n",
      "   10 | 0.010000 | 040960/160635 | 5.4939 | 3.7726 |\n",
      "val: {'recall': 0.958205, 'recall_grapheme': 0.937282, 'recall_vowel': 0.979391, 'recall_consonant': 0.978866, 'acc_grapheme': 0.932247, 'acc_vowel': 0.979008, 'acc_consonant': 0.979281, 'loss_grapheme': 0.467955, 'loss_vowel': 0.29047, 'loss_consonant': 0.179109}\n",
      "** saved\n",
      "   11 | 0.010000 | 086016/160635 | 1.7770 | 3.4926 |\n",
      "val: {'recall': 0.9615, 'recall_grapheme': 0.942189, 'recall_vowel': 0.980923, 'recall_consonant': 0.980697, 'acc_grapheme': 0.938863, 'acc_vowel': 0.979281, 'acc_consonant': 0.978833, 'loss_grapheme': 0.493017, 'loss_vowel': 0.298204, 'loss_consonant': 0.188173}\n",
      "** saved\n",
      "   12 | 0.010000 | 131072/160635 | 3.8963 | 3.8042 |\n",
      "val: {'recall': 0.9614, 'recall_grapheme': 0.942541, 'recall_vowel': 0.98093, 'recall_consonant': 0.979589, 'acc_grapheme': 0.937346, 'acc_vowel': 0.975302, 'acc_consonant': 0.980102, 'loss_grapheme': 0.584903, 'loss_vowel': 0.312144, 'loss_consonant': 0.180905}\n",
      "   14 | 0.010000 | 016384/160635 | 3.1087 | 3.5250 |\n",
      "val: {'recall': 0.962153, 'recall_grapheme': 0.946047, 'recall_vowel': 0.979157, 'recall_consonant': 0.977361, 'acc_grapheme': 0.941624, 'acc_vowel': 0.973138, 'acc_consonant': 0.97856, 'loss_grapheme': 0.600794, 'loss_vowel': 0.311263, 'loss_consonant': 0.199764}\n",
      "** saved\n",
      "   15 | 0.010000 | 061440/160635 | 1.4508 | 3.5288 |\n",
      "val: {'recall': 0.96575, 'recall_grapheme': 0.948855, 'recall_vowel': 0.983038, 'recall_consonant': 0.982252, 'acc_grapheme': 0.942942, 'acc_vowel': 0.980898, 'acc_consonant': 0.98346, 'loss_grapheme': 0.504317, 'loss_vowel': 0.286942, 'loss_consonant': 0.179976}\n",
      "** saved\n",
      "   16 | 0.010000 | 106496/160635 | 0.8931 | 3.3264 |\n",
      "val: {'recall': 0.966047, 'recall_grapheme': 0.949763, 'recall_vowel': 0.982934, 'recall_consonant': 0.981727, 'acc_grapheme': 0.945828, 'acc_vowel': 0.983385, 'acc_consonant': 0.981918, 'loss_grapheme': 0.360237, 'loss_vowel': 0.180697, 'loss_consonant': 0.158576}\n",
      "** saved\n",
      "   17 | 0.010000 | 151552/160635 | 3.3472 | 3.5358 |\n",
      "val: {'recall': 0.963838, 'recall_grapheme': 0.945211, 'recall_vowel': 0.982634, 'recall_consonant': 0.982296, 'acc_grapheme': 0.939435, 'acc_vowel': 0.981744, 'acc_consonant': 0.982142, 'loss_grapheme': 0.603316, 'loss_vowel': 0.295623, 'loss_consonant': 0.204734}\n",
      "   19 | 0.010000 | 036864/160635 | 5.4226 | 3.2191 |\n",
      "val: {'recall': 0.968165, 'recall_grapheme': 0.95292, 'recall_vowel': 0.983322, 'recall_consonant': 0.983499, 'acc_grapheme': 0.947693, 'acc_vowel': 0.980699, 'acc_consonant': 0.983932, 'loss_grapheme': 0.545762, 'loss_vowel': 0.31754, 'loss_consonant': 0.186231}\n",
      "** saved\n",
      "   20 | 0.010000 | 081920/160635 | 3.6469 | 3.3886 |\n",
      "val: {'recall': 0.969701, 'recall_grapheme': 0.953671, 'recall_vowel': 0.985276, 'recall_consonant': 0.986185, 'acc_grapheme': 0.949459, 'acc_vowel': 0.984156, 'acc_consonant': 0.984654, 'loss_grapheme': 0.411126, 'loss_vowel': 0.247306, 'loss_consonant': 0.156439}\n",
      "** saved\n",
      "   21 | 0.010000 | 126976/160635 | 3.4545 | 3.1108 |\n",
      "val: {'recall': 0.97, 'recall_grapheme': 0.956261, 'recall_vowel': 0.984997, 'recall_consonant': 0.98248, 'acc_grapheme': 0.952046, 'acc_vowel': 0.986494, 'acc_consonant': 0.984703, 'loss_grapheme': 0.327671, 'loss_vowel': 0.178724, 'loss_consonant': 0.132133}\n",
      "** saved\n",
      "   23 | 0.010000 | 012288/160635 | 1.4229 | 3.4273 |\n",
      "val: {'recall': 0.970738, 'recall_grapheme': 0.956635, 'recall_vowel': 0.985166, 'recall_consonant': 0.984516, 'acc_grapheme': 0.95518, 'acc_vowel': 0.985052, 'acc_consonant': 0.985723, 'loss_grapheme': 0.442714, 'loss_vowel': 0.281409, 'loss_consonant': 0.171029}\n",
      "** saved\n",
      "   24 | 0.010000 | 057344/160635 | 4.7815 | 2.7705 |\n",
      "val: {'recall': 0.969558, 'recall_grapheme': 0.955205, 'recall_vowel': 0.983958, 'recall_consonant': 0.983865, 'acc_grapheme': 0.952618, 'acc_vowel': 0.983485, 'acc_consonant': 0.9854, 'loss_grapheme': 0.437898, 'loss_vowel': 0.272268, 'loss_consonant': 0.166213}\n",
      "   25 | 0.010000 | 102400/160635 | 1.4054 | 3.3386 |\n",
      "val: {'recall': 0.97023, 'recall_grapheme': 0.957263, 'recall_vowel': 0.982174, 'recall_consonant': 0.98422, 'acc_grapheme': 0.952916, 'acc_vowel': 0.984305, 'acc_consonant': 0.984679, 'loss_grapheme': 0.399484, 'loss_vowel': 0.229505, 'loss_consonant': 0.149031}\n",
      "   26 | 0.010000 | 147456/160635 | 1.1134 | 3.1133 |\n",
      "val: {'recall': 0.970999, 'recall_grapheme': 0.956981, 'recall_vowel': 0.985538, 'recall_consonant': 0.984496, 'acc_grapheme': 0.954931, 'acc_vowel': 0.985922, 'acc_consonant': 0.985823, 'loss_grapheme': 0.397941, 'loss_vowel': 0.247837, 'loss_consonant': 0.165954}\n",
      "** saved\n",
      "   28 | 0.010000 | 032768/160635 | 1.8512 | 2.9620 |\n",
      "val: {'recall': 0.971703, 'recall_grapheme': 0.958834, 'recall_vowel': 0.982625, 'recall_consonant': 0.986517, 'acc_grapheme': 0.95503, 'acc_vowel': 0.981619, 'acc_consonant': 0.985649, 'loss_grapheme': 0.396897, 'loss_vowel': 0.297125, 'loss_consonant': 0.16052}\n",
      "** saved\n",
      "   29 | 0.010000 | 077824/160635 | 1.3092 | 2.9300 |\n",
      "val: {'recall': 0.969054, 'recall_grapheme': 0.953919, 'recall_vowel': 0.983979, 'recall_consonant': 0.984399, 'acc_grapheme': 0.953538, 'acc_vowel': 0.984952, 'acc_consonant': 0.985972, 'loss_grapheme': 0.302763, 'loss_vowel': 0.191624, 'loss_consonant': 0.124812}\n",
      "   30 | 0.010000 | 122880/160635 | 2.8791 | 3.0253 |\n",
      "val: {'recall': 0.972628, 'recall_grapheme': 0.959871, 'recall_vowel': 0.985256, 'recall_consonant': 0.985515, 'acc_grapheme': 0.957368, 'acc_vowel': 0.985375, 'acc_consonant': 0.985052, 'loss_grapheme': 0.435753, 'loss_vowel': 0.259854, 'loss_consonant': 0.164306}\n",
      "** saved\n",
      "   32 | 0.010000 | 008192/160635 | 3.2421 | 3.8945 |\n",
      "val: {'recall': 0.972528, 'recall_grapheme': 0.960228, 'recall_vowel': 0.983356, 'recall_consonant': 0.986299, 'acc_grapheme': 0.956946, 'acc_vowel': 0.979928, 'acc_consonant': 0.985474, 'loss_grapheme': 0.427098, 'loss_vowel': 0.343625, 'loss_consonant': 0.184426}\n",
      "   33 | 0.010000 | 053248/160635 | 2.8232 | 3.4951 |\n",
      "val: {'recall': 0.971713, 'recall_grapheme': 0.957716, 'recall_vowel': 0.984623, 'recall_consonant': 0.986796, 'acc_grapheme': 0.955553, 'acc_vowel': 0.986444, 'acc_consonant': 0.985499, 'loss_grapheme': 0.407065, 'loss_vowel': 0.262189, 'loss_consonant': 0.171435}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 0.010000 | 098304/160635 | 3.0032 | 2.9480 |\n",
      "val: {'recall': 0.974049, 'recall_grapheme': 0.961959, 'recall_vowel': 0.985959, 'recall_consonant': 0.986319, 'acc_grapheme': 0.958985, 'acc_vowel': 0.985872, 'acc_consonant': 0.985599, 'loss_grapheme': 0.438802, 'loss_vowel': 0.241194, 'loss_consonant': 0.158914}\n",
      "** saved\n",
      "   35 | 0.010000 | 143360/160635 | 5.1995 | 2.9753 |\n",
      "val: {'recall': 0.973024, 'recall_grapheme': 0.959212, 'recall_vowel': 0.986018, 'recall_consonant': 0.987653, 'acc_grapheme': 0.957294, 'acc_vowel': 0.985574, 'acc_consonant': 0.985052, 'loss_grapheme': 0.376338, 'loss_vowel': 0.238082, 'loss_consonant': 0.156815}\n",
      "   37 | 0.010000 | 028672/160635 | 2.2374 | 2.9245 |\n",
      "val: {'recall': 0.971169, 'recall_grapheme': 0.958371, 'recall_vowel': 0.985123, 'recall_consonant': 0.982811, 'acc_grapheme': 0.955304, 'acc_vowel': 0.986295, 'acc_consonant': 0.98632, 'loss_grapheme': 0.378169, 'loss_vowel': 0.236004, 'loss_consonant': 0.162918}\n",
      "   38 | 0.010000 | 073728/160635 | 3.5145 | 2.8639 |\n",
      "val: {'recall': 0.975038, 'recall_grapheme': 0.963118, 'recall_vowel': 0.986843, 'recall_consonant': 0.987071, 'acc_grapheme': 0.961373, 'acc_vowel': 0.987837, 'acc_consonant': 0.987216, 'loss_grapheme': 0.361054, 'loss_vowel': 0.212108, 'loss_consonant': 0.155789}\n",
      "** saved\n",
      "   39 | 0.010000 | 118784/160635 | 1.8989 | 2.7872 |\n",
      "val: {'recall': 0.974305, 'recall_grapheme': 0.962237, 'recall_vowel': 0.987018, 'recall_consonant': 0.98573, 'acc_grapheme': 0.960328, 'acc_vowel': 0.987315, 'acc_consonant': 0.986643, 'loss_grapheme': 0.443383, 'loss_vowel': 0.246318, 'loss_consonant': 0.165812}\n",
      "   41 | 0.010000 | 004096/160635 | 4.0690 | 3.5387 |\n",
      "val: {'recall': 0.973829, 'recall_grapheme': 0.961933, 'recall_vowel': 0.986288, 'recall_consonant': 0.985161, 'acc_grapheme': 0.961472, 'acc_vowel': 0.986743, 'acc_consonant': 0.986594, 'loss_grapheme': 0.450012, 'loss_vowel': 0.241355, 'loss_consonant': 0.158012}\n",
      "   42 | 0.010000 | 049152/160635 | 3.4513 | 2.7965 |\n",
      "val: {'recall': 0.97422, 'recall_grapheme': 0.961304, 'recall_vowel': 0.987694, 'recall_consonant': 0.986578, 'acc_grapheme': 0.95998, 'acc_vowel': 0.987439, 'acc_consonant': 0.987713, 'loss_grapheme': 0.294797, 'loss_vowel': 0.173956, 'loss_consonant': 0.11822}\n",
      "   43 | 0.010000 | 094208/160635 | 2.5489 | 2.8625 |\n",
      "val: {'recall': 0.975148, 'recall_grapheme': 0.962684, 'recall_vowel': 0.98701, 'recall_consonant': 0.988216, 'acc_grapheme': 0.961224, 'acc_vowel': 0.986842, 'acc_consonant': 0.986793, 'loss_grapheme': 0.371618, 'loss_vowel': 0.215647, 'loss_consonant': 0.150408}\n",
      "** saved\n",
      "   44 | 0.010000 | 139264/160635 | 1.0191 | 2.7616 |\n",
      "val: {'recall': 0.974769, 'recall_grapheme': 0.963403, 'recall_vowel': 0.985577, 'recall_consonant': 0.986694, 'acc_grapheme': 0.96294, 'acc_vowel': 0.98734, 'acc_consonant': 0.987912, 'loss_grapheme': 0.281018, 'loss_vowel': 0.190917, 'loss_consonant': 0.132432}\n",
      "   46 | 0.010000 | 024576/160635 | 1.7791 | 3.0072 |\n",
      "val: {'recall': 0.975235, 'recall_grapheme': 0.964588, 'recall_vowel': 0.985615, 'recall_consonant': 0.986152, 'acc_grapheme': 0.962666, 'acc_vowel': 0.987116, 'acc_consonant': 0.986917, 'loss_grapheme': 0.445397, 'loss_vowel': 0.278243, 'loss_consonant': 0.167466}\n",
      "** saved\n",
      "   47 | 0.010000 | 069632/160635 | 2.9151 | 2.6897 |\n",
      "val: {'recall': 0.976441, 'recall_grapheme': 0.96597, 'recall_vowel': 0.98794, 'recall_consonant': 0.985883, 'acc_grapheme': 0.964432, 'acc_vowel': 0.988335, 'acc_consonant': 0.987812, 'loss_grapheme': 0.336171, 'loss_vowel': 0.212761, 'loss_consonant': 0.142274}\n",
      "** saved\n",
      "   48 | 0.010000 | 114688/160635 | 2.0305 | 2.7304 |\n",
      "val: {'recall': 0.976627, 'recall_grapheme': 0.965701, 'recall_vowel': 0.987495, 'recall_consonant': 0.987612, 'acc_grapheme': 0.96299, 'acc_vowel': 0.98826, 'acc_consonant': 0.987017, 'loss_grapheme': 0.404398, 'loss_vowel': 0.231125, 'loss_consonant': 0.162676}\n",
      "** saved\n",
      "   49 | 0.010000 | 159744/160635 | 3.3478 | 2.6756 |\n",
      "val: {'recall': 0.974783, 'recall_grapheme': 0.963808, 'recall_vowel': 0.988885, 'recall_consonant': 0.98263, 'acc_grapheme': 0.964731, 'acc_vowel': 0.98831, 'acc_consonant': 0.98739, 'loss_grapheme': 0.337172, 'loss_vowel': 0.184226, 'loss_consonant': 0.128738}\n",
      "   51 | 0.010000 | 045056/160635 | 3.2567 | 2.8521 |\n",
      "val: {'recall': 0.976895, 'recall_grapheme': 0.966471, 'recall_vowel': 0.986783, 'recall_consonant': 0.987854, 'acc_grapheme': 0.965353, 'acc_vowel': 0.988584, 'acc_consonant': 0.987862, 'loss_grapheme': 0.371718, 'loss_vowel': 0.250755, 'loss_consonant': 0.178463}\n",
      "** saved\n",
      "   52 | 0.010000 | 090112/160635 | 1.2957 | 2.5912 |\n",
      "val: {'recall': 0.976105, 'recall_grapheme': 0.965014, 'recall_vowel': 0.98892, 'recall_consonant': 0.985471, 'acc_grapheme': 0.965726, 'acc_vowel': 0.988161, 'acc_consonant': 0.988335, 'loss_grapheme': 0.275672, 'loss_vowel': 0.171372, 'loss_consonant': 0.101488}\n",
      "   53 | 0.010000 | 135168/160635 | 1.1214 | 2.5532 |\n",
      "val: {'recall': 0.9774, 'recall_grapheme': 0.967225, 'recall_vowel': 0.986857, 'recall_consonant': 0.988292, 'acc_grapheme': 0.965477, 'acc_vowel': 0.988608, 'acc_consonant': 0.986544, 'loss_grapheme': 0.279012, 'loss_vowel': 0.157912, 'loss_consonant': 0.1446}\n",
      "** saved\n",
      "   56 | 0.010000 | 065536/160635 | 2.3335 | 2.7034 |\n",
      "val: {'recall': 0.977539, 'recall_grapheme': 0.967267, 'recall_vowel': 0.986715, 'recall_consonant': 0.988907, 'acc_grapheme': 0.967168, 'acc_vowel': 0.988907, 'acc_consonant': 0.989056, 'loss_grapheme': 0.39492, 'loss_vowel': 0.257303, 'loss_consonant': 0.155096}\n",
      "** saved\n",
      "   57 | 0.010000 | 110592/160635 | 4.0406 | 2.8241 |\n",
      "val: {'recall': 0.97682, 'recall_grapheme': 0.965961, 'recall_vowel': 0.987787, 'recall_consonant': 0.987572, 'acc_grapheme': 0.965651, 'acc_vowel': 0.989603, 'acc_consonant': 0.98821, 'loss_grapheme': 0.328068, 'loss_vowel': 0.23837, 'loss_consonant': 0.169148}\n",
      "   58 | 0.010000 | 155648/160635 | 2.1979 | 2.8250 |\n",
      "val: {'recall': 0.978432, 'recall_grapheme': 0.969077, 'recall_vowel': 0.98796, 'recall_consonant': 0.987615, 'acc_grapheme': 0.968362, 'acc_vowel': 0.989156, 'acc_consonant': 0.989131, 'loss_grapheme': 0.310673, 'loss_vowel': 0.208204, 'loss_consonant': 0.13922}\n",
      "** saved\n",
      "   60 | 0.010000 | 040960/160635 | 2.1629 | 2.9274 |\n",
      "val: {'recall': 0.978185, 'recall_grapheme': 0.967876, 'recall_vowel': 0.988025, 'recall_consonant': 0.988963, 'acc_grapheme': 0.967417, 'acc_vowel': 0.98933, 'acc_consonant': 0.988708, 'loss_grapheme': 0.306619, 'loss_vowel': 0.191535, 'loss_consonant': 0.140879}\n",
      "   61 | 0.010000 | 086016/160635 | 0.4925 | 2.5241 |\n",
      "val: {'recall': 0.978817, 'recall_grapheme': 0.969489, 'recall_vowel': 0.98788, 'recall_consonant': 0.98841, 'acc_grapheme': 0.967964, 'acc_vowel': 0.988633, 'acc_consonant': 0.989255, 'loss_grapheme': 0.299571, 'loss_vowel': 0.179239, 'loss_consonant': 0.125575}\n",
      "** saved\n",
      "   62 | 0.010000 | 131072/160635 | 3.9392 | 2.6374 |\n",
      "val: {'recall': 0.978397, 'recall_grapheme': 0.969024, 'recall_vowel': 0.986851, 'recall_consonant': 0.988687, 'acc_grapheme': 0.967591, 'acc_vowel': 0.988708, 'acc_consonant': 0.989106, 'loss_grapheme': 0.317503, 'loss_vowel': 0.20114, 'loss_consonant': 0.138972}\n",
      "   64 | 0.010000 | 016384/160635 | 1.5939 | 2.2375 |\n",
      "val: {'recall': 0.979212, 'recall_grapheme': 0.969824, 'recall_vowel': 0.987667, 'recall_consonant': 0.989533, 'acc_grapheme': 0.967243, 'acc_vowel': 0.988633, 'acc_consonant': 0.987066, 'loss_grapheme': 0.315282, 'loss_vowel': 0.203681, 'loss_consonant': 0.145092}\n",
      "** saved\n",
      "   65 | 0.010000 | 061440/160635 | 2.6252 | 2.5841 |\n",
      "val: {'recall': 0.978556, 'recall_grapheme': 0.968007, 'recall_vowel': 0.988424, 'recall_consonant': 0.989788, 'acc_grapheme': 0.9658, 'acc_vowel': 0.987365, 'acc_consonant': 0.987713, 'loss_grapheme': 0.333209, 'loss_vowel': 0.215822, 'loss_consonant': 0.149904}\n",
      "   66 | 0.010000 | 106496/160635 | 2.4993 | 2.8037 |\n",
      "val: {'recall': 0.978103, 'recall_grapheme': 0.968861, 'recall_vowel': 0.987823, 'recall_consonant': 0.986867, 'acc_grapheme': 0.967616, 'acc_vowel': 0.988285, 'acc_consonant': 0.988832, 'loss_grapheme': 0.404244, 'loss_vowel': 0.274969, 'loss_consonant': 0.171189}\n",
      "   67 | 0.010000 | 151552/160635 | 2.2937 | 2.7518 |\n",
      "val: {'recall': 0.979405, 'recall_grapheme': 0.969859, 'recall_vowel': 0.988254, 'recall_consonant': 0.98965, 'acc_grapheme': 0.966795, 'acc_vowel': 0.989578, 'acc_consonant': 0.987539, 'loss_grapheme': 0.382567, 'loss_vowel': 0.260238, 'loss_consonant': 0.179104}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   69 | 0.010000 | 036864/160635 | 2.3102 | 2.5358 |\n",
      "val: {'recall': 0.977795, 'recall_grapheme': 0.967562, 'recall_vowel': 0.988873, 'recall_consonant': 0.987185, 'acc_grapheme': 0.965427, 'acc_vowel': 0.98923, 'acc_consonant': 0.987066, 'loss_grapheme': 0.394783, 'loss_vowel': 0.219057, 'loss_consonant': 0.168694}\n",
      "   70 | 0.010000 | 081920/160635 | 2.8215 | 2.6148 |\n",
      "val: {'recall': 0.979946, 'recall_grapheme': 0.971102, 'recall_vowel': 0.988889, 'recall_consonant': 0.988688, 'acc_grapheme': 0.969233, 'acc_vowel': 0.989753, 'acc_consonant': 0.989429, 'loss_grapheme': 0.274274, 'loss_vowel': 0.193647, 'loss_consonant': 0.137678}\n",
      "** saved\n",
      "   71 | 0.010000 | 126976/160635 | 2.3870 | 2.4534 |\n",
      "val: {'recall': 0.980217, 'recall_grapheme': 0.972409, 'recall_vowel': 0.987571, 'recall_consonant': 0.988479, 'acc_grapheme': 0.969332, 'acc_vowel': 0.989404, 'acc_consonant': 0.987464, 'loss_grapheme': 0.352871, 'loss_vowel': 0.213534, 'loss_consonant': 0.149456}\n",
      "** saved\n",
      "   73 | 0.010000 | 012288/160635 | 3.3822 | 2.8059 |\n",
      "val: {'recall': 0.976773, 'recall_grapheme': 0.966702, 'recall_vowel': 0.987804, 'recall_consonant': 0.985885, 'acc_grapheme': 0.965527, 'acc_vowel': 0.988161, 'acc_consonant': 0.98933, 'loss_grapheme': 0.348416, 'loss_vowel': 0.254156, 'loss_consonant': 0.154086}\n",
      "   74 | 0.010000 | 057344/160635 | 0.9927 | 2.7784 |\n",
      "val: {'recall': 0.976986, 'recall_grapheme': 0.966871, 'recall_vowel': 0.986951, 'recall_consonant': 0.987251, 'acc_grapheme': 0.966671, 'acc_vowel': 0.989379, 'acc_consonant': 0.989205, 'loss_grapheme': 0.301971, 'loss_vowel': 0.216214, 'loss_consonant': 0.13975}\n",
      "   74 | 0.010000 | 116736/160635 | 2.5710 | 2.5947 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  115 | 0.010000 | 061440/160635 | 2.4583 | 2.3523 |\n",
      "val: {'recall': 0.981129, 'recall_grapheme': 0.973491, 'recall_vowel': 0.988451, 'recall_consonant': 0.989085, 'acc_grapheme': 0.972168, 'acc_vowel': 0.990499, 'acc_consonant': 0.989976, 'loss_grapheme': 0.313539, 'loss_vowel': 0.200991, 'loss_consonant': 0.144666}\n",
      "  116 | 0.010000 | 106496/160635 | 1.9569 | 2.4711 |\n",
      "val: {'recall': 0.982192, 'recall_grapheme': 0.975308, 'recall_vowel': 0.988854, 'recall_consonant': 0.989298, 'acc_grapheme': 0.971745, 'acc_vowel': 0.990349, 'acc_consonant': 0.989951, 'loss_grapheme': 0.275765, 'loss_vowel': 0.169195, 'loss_consonant': 0.113746}\n",
      "** saved\n",
      "  117 | 0.010000 | 151552/160635 | 2.0201 | 2.4205 |\n",
      "val: {'recall': 0.981754, 'recall_grapheme': 0.972246, 'recall_vowel': 0.989643, 'recall_consonant': 0.992881, 'acc_grapheme': 0.97167, 'acc_vowel': 0.990424, 'acc_consonant': 0.988857, 'loss_grapheme': 0.267233, 'loss_vowel': 0.18243, 'loss_consonant': 0.133519}\n",
      "  119 | 0.010000 | 036864/160635 | 4.6009 | 2.4542 |\n",
      "val: {'recall': 0.982545, 'recall_grapheme': 0.975324, 'recall_vowel': 0.989704, 'recall_consonant': 0.989826, 'acc_grapheme': 0.972839, 'acc_vowel': 0.990946, 'acc_consonant': 0.989902, 'loss_grapheme': 0.26682, 'loss_vowel': 0.177766, 'loss_consonant': 0.130049}\n",
      "** saved\n",
      "  120 | 0.010000 | 081920/160635 | 2.4344 | 2.6888 |\n",
      "val: {'recall': 0.981708, 'recall_grapheme': 0.973955, 'recall_vowel': 0.989898, 'recall_consonant': 0.989024, 'acc_grapheme': 0.97162, 'acc_vowel': 0.990449, 'acc_consonant': 0.990001, 'loss_grapheme': 0.290185, 'loss_vowel': 0.191109, 'loss_consonant': 0.128999}\n",
      "  121 | 0.010000 | 126976/160635 | 3.8515 | 2.4213 |\n",
      "val: {'recall': 0.982142, 'recall_grapheme': 0.974317, 'recall_vowel': 0.988343, 'recall_consonant': 0.99159, 'acc_grapheme': 0.972068, 'acc_vowel': 0.990623, 'acc_consonant': 0.989877, 'loss_grapheme': 0.305864, 'loss_vowel': 0.201135, 'loss_consonant': 0.142942}\n",
      "  123 | 0.010000 | 012288/160635 | 3.1389 | 2.2658 |\n",
      "val: {'recall': 0.982034, 'recall_grapheme': 0.974582, 'recall_vowel': 0.98965, 'recall_consonant': 0.989323, 'acc_grapheme': 0.973759, 'acc_vowel': 0.99117, 'acc_consonant': 0.990872, 'loss_grapheme': 0.251747, 'loss_vowel': 0.168945, 'loss_consonant': 0.121809}\n",
      "  124 | 0.010000 | 057344/160635 | 0.2595 | 2.3707 |\n",
      "val: {'recall': 0.981619, 'recall_grapheme': 0.971958, 'recall_vowel': 0.990817, 'recall_consonant': 0.991744, 'acc_grapheme': 0.972168, 'acc_vowel': 0.99117, 'acc_consonant': 0.990051, 'loss_grapheme': 0.214559, 'loss_vowel': 0.150911, 'loss_consonant': 0.10776}\n",
      "  125 | 0.010000 | 102400/160635 | 1.7740 | 2.3075 |\n",
      "val: {'recall': 0.981801, 'recall_grapheme': 0.974131, 'recall_vowel': 0.989422, 'recall_consonant': 0.989523, 'acc_grapheme': 0.972466, 'acc_vowel': 0.991145, 'acc_consonant': 0.99025, 'loss_grapheme': 0.25037, 'loss_vowel': 0.172608, 'loss_consonant': 0.118744}\n",
      "  126 | 0.010000 | 147456/160635 | 1.2121 | 2.2848 |\n",
      "val: {'recall': 0.982371, 'recall_grapheme': 0.97479, 'recall_vowel': 0.990341, 'recall_consonant': 0.989564, 'acc_grapheme': 0.973436, 'acc_vowel': 0.991046, 'acc_consonant': 0.990698, 'loss_grapheme': 0.26841, 'loss_vowel': 0.176579, 'loss_consonant': 0.122408}\n",
      "  128 | 0.010000 | 032768/160635 | 2.3763 | 2.2767 |\n",
      "val: {'recall': 0.982043, 'recall_grapheme': 0.974251, 'recall_vowel': 0.98925, 'recall_consonant': 0.990419, 'acc_grapheme': 0.972889, 'acc_vowel': 0.991145, 'acc_consonant': 0.990225, 'loss_grapheme': 0.283616, 'loss_vowel': 0.189135, 'loss_consonant': 0.135755}\n",
      "  129 | 0.010000 | 077824/160635 | 0.7738 | 2.5061 |\n",
      "val: {'recall': 0.981381, 'recall_grapheme': 0.974375, 'recall_vowel': 0.988664, 'recall_consonant': 0.988109, 'acc_grapheme': 0.972765, 'acc_vowel': 0.99025, 'acc_consonant': 0.989728, 'loss_grapheme': 0.279919, 'loss_vowel': 0.191359, 'loss_consonant': 0.136316}\n",
      "  130 | 0.010000 | 122880/160635 | 0.3173 | 2.4866 |\n",
      "val: {'recall': 0.982679, 'recall_grapheme': 0.974829, 'recall_vowel': 0.990282, 'recall_consonant': 0.990775, 'acc_grapheme': 0.974108, 'acc_vowel': 0.991419, 'acc_consonant': 0.990673, 'loss_grapheme': 0.292839, 'loss_vowel': 0.214273, 'loss_consonant': 0.150108}\n",
      "** saved\n",
      "  132 | 0.010000 | 008192/160635 | 1.8594 | 2.2290 |\n",
      "val: {'recall': 0.982011, 'recall_grapheme': 0.974624, 'recall_vowel': 0.988978, 'recall_consonant': 0.989818, 'acc_grapheme': 0.972118, 'acc_vowel': 0.990673, 'acc_consonant': 0.990598, 'loss_grapheme': 0.270158, 'loss_vowel': 0.167479, 'loss_consonant': 0.1198}\n",
      "  133 | 0.010000 | 053248/160635 | 1.2702 | 2.3929 |\n",
      "val: {'recall': 0.982466, 'recall_grapheme': 0.974795, 'recall_vowel': 0.990097, 'recall_consonant': 0.990177, 'acc_grapheme': 0.97361, 'acc_vowel': 0.990872, 'acc_consonant': 0.9903, 'loss_grapheme': 0.268454, 'loss_vowel': 0.187532, 'loss_consonant': 0.126379}\n",
      "  134 | 0.010000 | 005120/160635 | 4.0991 | 2.2854 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  160 | 0.001000 | 040960/160635 | 2.3495 | 1.9895 |\n",
      "val: {'recall': 0.983491, 'recall_grapheme': 0.976899, 'recall_vowel': 0.989648, 'recall_consonant': 0.990517, 'acc_grapheme': 0.975351, 'acc_vowel': 0.991444, 'acc_consonant': 0.991096, 'loss_grapheme': 0.189355, 'loss_vowel': 0.116638, 'loss_consonant': 0.091151}\n",
      "  161 | 0.001000 | 086016/160635 | 1.3966 | 2.2144 |\n",
      "val: {'recall': 0.983231, 'recall_grapheme': 0.976033, 'recall_vowel': 0.990045, 'recall_consonant': 0.990813, 'acc_grapheme': 0.974779, 'acc_vowel': 0.991593, 'acc_consonant': 0.991195, 'loss_grapheme': 0.235409, 'loss_vowel': 0.160771, 'loss_consonant': 0.114142}\n",
      "  162 | 0.001000 | 131072/160635 | 2.1251 | 2.2012 |\n",
      "val: {'recall': 0.982889, 'recall_grapheme': 0.975623, 'recall_vowel': 0.989942, 'recall_consonant': 0.990369, 'acc_grapheme': 0.974555, 'acc_vowel': 0.991643, 'acc_consonant': 0.990922, 'loss_grapheme': 0.233491, 'loss_vowel': 0.161355, 'loss_consonant': 0.113815}\n",
      "  163 | 0.001000 | 001024/160635 | 3.0853 | 3.0853 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-45b0085dbc6e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
