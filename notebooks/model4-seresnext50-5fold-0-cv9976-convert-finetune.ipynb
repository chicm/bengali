{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations as albu\n",
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arange(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in train_loader:\n",
    "#    print(x)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "class BengaliNet4(nn.Module):\n",
    "    def __init__(self, backbone_name='se_resnext50_32x4d'):\n",
    "        super(BengaliNet4, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.n_word = 1295\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant + self.n_word\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        self.num_p2_features = self.backbone.layer2[-1].se_module.fc2.out_channels\n",
    "        self.num_p3_features = self.backbone.layer3[-1].se_module.fc2.out_channels\n",
    "        self.p2_head = nn.Conv2d(self.num_p2_features, self.num_p2_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.p3_head = nn.Conv2d(self.num_p3_features, self.num_p3_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_p2_features * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_p3_features * 4)\n",
    "        self.act2 = Swish()\n",
    "        self.act3 = Swish()\n",
    "        \n",
    "        self.fc_aux1 = nn.Linear(self.num_p3_features * 4, self.num_classes)\n",
    "        self.fc_aux2 = nn.Linear(self.num_p2_features * 4, self.num_classes)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        for fc in [self.fc, self.fc_aux1, self.fc_aux2]:\n",
    "            nn.init.zeros_(fc.bias.data)\n",
    "\n",
    "        print('init model4')\n",
    "        \n",
    "    def features(self, x):\n",
    "        x = self.backbone.layer0(x); #print(x.size())\n",
    "        x = self.backbone.layer1(x); #print(x.size())\n",
    "        x = self.backbone.layer2(x); p2 = x; p2 = self.p2_head(p2); p2 = self.bn2(p2); p2 = self.act2(p2) #print(x.size())\n",
    "        x = self.backbone.layer3(x); p3 = x; p3 = self.p3_head(p3); p3 = self.bn3(p3); p3 = self.act3(p3) #print(x.size())\n",
    "        x = self.backbone.layer4(x); #print(x.size())\n",
    "        return x, p2, p3\n",
    "        \n",
    "    def logits(self, x, p2, p3):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        p2 = self.avg_pool(p2)\n",
    "        p2 = torch.flatten(p2, 1)\n",
    "        \n",
    "        p3 = self.avg_pool(p3)\n",
    "        p3 = torch.flatten(p3, 1)\n",
    "        return self.fc(x), self.fc_aux1(p3), self.fc_aux2(p2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x, p2, p3 = self.features(x)\n",
    "        x, logits_aux1, logits_aux2 = self.logits(x, p2, p3)\n",
    "\n",
    "        return x, logits_aux1, logits_aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model4-ckps'\n",
    "def create_model(args):\n",
    "    model = BengaliNet4(args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, preds3, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2) == len(preds3)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    recall_word = sklearn.metrics.recall_score(preds3, y[:, 3], average='macro')\n",
    "    \n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    metrics['recall_word'] = round(recall_word, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    metrics['acc_word'] = round((preds3 == y[:, 3]).sum() / len(y), 6)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    loss3 = F.cross_entropy(outputs[3], y_true[:, 3], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 + loss3 #, loss0.item(), loss1.item(), loss2.item()\n",
    "    #return loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2, loss3 = 0., 0., 0., 0.\n",
    "    preds0, preds1, preds2, preds3 = [], [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(x)\n",
    "            #avg_outputs = torch.mean(torch.stack([outputs, outputs_aux1, outputs_aux2], 0), 0)\n",
    "            outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            preds3.append(torch.max(outputs[3], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            loss3 += F.cross_entropy(outputs[3], y[:, 3], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    preds3 = torch.cat(preds3, 0).cpu().numpy()\n",
    "    \n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, preds3, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    metrics['loss_word'] = round(loss3 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26991249636540915"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = 0.\n",
    "\n",
    "def train(args, model):\n",
    "    optimizer = make_optimizer(model)\n",
    "    scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        train_cycle(args, model, optimizer, scheduler)\n",
    "        #args.base_lr = 4e-4\n",
    "        #args.num_epochs = 100\n",
    "        #args.warmup_epochs = 10\n",
    "        scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "\n",
    "def train_cycle(args, model, optimizer, lr_scheduler):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "\n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    train_iter = 0\n",
    "    grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        grid.set_prob(epoch, args.st_epochs)\n",
    "\n",
    "        train_loss = 0\n",
    "\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "            batch_size = img.size(0)\n",
    "            r = np.random.rand()\n",
    "\n",
    "            if r < 0.3:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "                loss_primary = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "                loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "                loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "                loss = loss_primary + (loss_aux1 + loss_aux2)*0.5\n",
    "            elif r > 0.7:\n",
    "                img = grid(img)\n",
    "                outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "                loss_primary = criterion(outputs, targets)\n",
    "                loss_aux1 = criterion(outputs_aux1, targets)\n",
    "                loss_aux2 = criterion(outputs_aux2, targets)\n",
    "                loss = loss_primary + (loss_aux1 + loss_aux2)*0.5\n",
    "            else:\n",
    "                orig_img, targets = mixup(orig_img, targets)\n",
    "                outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "                loss_primary = mixup_criterion(outputs, targets)\n",
    "                loss_aux1 = mixup_criterion(outputs_aux1, targets)\n",
    "                loss_aux2 = mixup_criterion(outputs_aux2, targets)\n",
    "                loss = loss_primary + (loss_aux1 + loss_aux2)*0.5\n",
    "                #loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            #loss.backward()\n",
    "            lr_scheduler(optimizer, batch_idx, epoch)\n",
    "            optimizer.step()            \n",
    "            \n",
    "            current_lr = get_lrs(optimizer)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "        if True:#train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "            val_metrics = validate(model, val_loader)\n",
    "            print('\\nval:', val_metrics)\n",
    "                \n",
    "            if val_metrics[best_key] > best_metrics:\n",
    "                best_metrics = val_metrics[best_key]\n",
    "                save_model(model, model_file)\n",
    "                print('###>>>>> saved')\n",
    "                \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model4_se_resnext50_fold0_224.pth'\n",
    "\n",
    "args.base_lr = 1.5e-4\n",
    "args.num_epochs = 80\n",
    "args.warmup_epochs = 5\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 640\n",
    "args.val_batch_size = 1024\n",
    "args.st_epochs = 10\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160596, 6) (40244, 6)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model4\n",
      "model file: ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold0_224.pth, exist: True\n",
      "loading ./model4-ckps/se_resnext50_32x4d/model4_se_resnext50_fold0_224.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.backbone.parameters():\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate(nn.DataParallel(model), val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYCLE: 1\n",
      "{'recall': 0.997718, 'recall_grapheme': 0.997067, 'recall_vowel': 0.998569, 'recall_consonant': 0.99817, 'recall_word': 0.996409, 'acc_grapheme': 0.996844, 'acc_vowel': 0.998782, 'acc_consonant': 0.998633, 'acc_word': 0.996496, 'loss_grapheme': 0.053724, 'loss_vowel': 0.036053, 'loss_consonant': 0.028162, 'loss_word': 0.034346}\n",
      "    0 | 0.000030 | 160000/160596 | 12.9655 | 5.9866 ||\n",
      "val: {'recall': 0.997588, 'recall_grapheme': 0.996898, 'recall_vowel': 0.99843, 'recall_consonant': 0.998124, 'recall_word': 0.996112, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998758, 'acc_consonant': 0.998658, 'acc_word': 0.996223, 'loss_grapheme': 0.050285, 'loss_vowel': 0.03403, 'loss_consonant': 0.026416, 'loss_word': 0.031264}\n",
      "    1 | 0.000060 | 160000/160596 | 7.8102 | 5.5703 ||\n",
      "val: {'recall': 0.997329, 'recall_grapheme': 0.996386, 'recall_vowel': 0.99844, 'recall_consonant': 0.998104, 'recall_word': 0.995942, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998758, 'acc_consonant': 0.998559, 'acc_word': 0.996049, 'loss_grapheme': 0.069617, 'loss_vowel': 0.046163, 'loss_consonant': 0.036864, 'loss_word': 0.03991}\n",
      "    2 | 0.000090 | 160000/160596 | 0.7355 | 6.0384 ||\n",
      "val: {'recall': 0.99724, 'recall_grapheme': 0.996208, 'recall_vowel': 0.998483, 'recall_consonant': 0.998063, 'recall_word': 0.995875, 'acc_grapheme': 0.996496, 'acc_vowel': 0.998683, 'acc_consonant': 0.998484, 'acc_word': 0.995975, 'loss_grapheme': 0.056103, 'loss_vowel': 0.037717, 'loss_consonant': 0.030752, 'loss_word': 0.035027}\n",
      "    3 | 0.000119 | 160000/160596 | 13.7939 | 5.6513 |\n",
      "val: {'recall': 0.996949, 'recall_grapheme': 0.996011, 'recall_vowel': 0.99795, 'recall_consonant': 0.997822, 'recall_word': 0.994895, 'acc_grapheme': 0.99585, 'acc_vowel': 0.99831, 'acc_consonant': 0.998261, 'acc_word': 0.99503, 'loss_grapheme': 0.052182, 'loss_vowel': 0.034542, 'loss_consonant': 0.026685, 'loss_word': 0.034634}\n",
      "    4 | 0.000148 | 160000/160596 | 0.8353 | 5.2618 |||\n",
      "val: {'recall': 0.997156, 'recall_grapheme': 0.99647, 'recall_vowel': 0.998059, 'recall_consonant': 0.997626, 'recall_word': 0.995534, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998484, 'acc_consonant': 0.99836, 'acc_word': 0.995627, 'loss_grapheme': 0.041457, 'loss_vowel': 0.027341, 'loss_consonant': 0.022449, 'loss_word': 0.026865}\n",
      "    5 | 0.000148 | 160000/160596 | 3.5637 | 5.7078 ||\n",
      "val: {'recall': 0.996548, 'recall_grapheme': 0.995909, 'recall_vowel': 0.99786, 'recall_consonant': 0.996513, 'recall_word': 0.995595, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998509, 'acc_consonant': 0.99841, 'acc_word': 0.995701, 'loss_grapheme': 0.072168, 'loss_vowel': 0.04816, 'loss_consonant': 0.03483, 'loss_word': 0.046941}\n",
      "    6 | 0.000147 | 160000/160596 | 0.9815 | 5.5951 ||\n",
      "val: {'recall': 0.996773, 'recall_grapheme': 0.995723, 'recall_vowel': 0.99802, 'recall_consonant': 0.997624, 'recall_word': 0.995087, 'acc_grapheme': 0.995652, 'acc_vowel': 0.998261, 'acc_consonant': 0.998211, 'acc_word': 0.99513, 'loss_grapheme': 0.03446, 'loss_vowel': 0.020184, 'loss_consonant': 0.01714, 'loss_word': 0.027515}\n",
      "    7 | 0.000146 | 160000/160596 | 5.6528 | 5.8120 ||\n",
      "val: {'recall': 0.996474, 'recall_grapheme': 0.995677, 'recall_vowel': 0.997521, 'recall_consonant': 0.997022, 'recall_word': 0.994842, 'acc_grapheme': 0.995776, 'acc_vowel': 0.997913, 'acc_consonant': 0.997888, 'acc_word': 0.994881, 'loss_grapheme': 0.030824, 'loss_vowel': 0.019728, 'loss_consonant': 0.017297, 'loss_word': 0.025827}\n",
      "    8 | 0.000145 | 160000/160596 | 2.7462 | 6.2855 |||\n",
      "val: {'recall': 0.996404, 'recall_grapheme': 0.995283, 'recall_vowel': 0.998164, 'recall_consonant': 0.996888, 'recall_word': 0.994862, 'acc_grapheme': 0.995751, 'acc_vowel': 0.998161, 'acc_consonant': 0.998186, 'acc_word': 0.994956, 'loss_grapheme': 0.089964, 'loss_vowel': 0.058083, 'loss_consonant': 0.039416, 'loss_word': 0.055922}\n",
      "    9 | 0.000144 | 160000/160596 | 1.0436 | 6.3001 ||\n",
      "val: {'recall': 0.997177, 'recall_grapheme': 0.996483, 'recall_vowel': 0.997757, 'recall_consonant': 0.997986, 'recall_word': 0.995813, 'acc_grapheme': 0.996322, 'acc_vowel': 0.998211, 'acc_consonant': 0.998559, 'acc_word': 0.995925, 'loss_grapheme': 0.03593, 'loss_vowel': 0.025227, 'loss_consonant': 0.020315, 'loss_word': 0.024329}\n",
      "   10 | 0.000143 | 160000/160596 | 11.2593 | 6.2968 |\n",
      "val: {'recall': 0.99586, 'recall_grapheme': 0.994394, 'recall_vowel': 0.997606, 'recall_consonant': 0.997046, 'recall_word': 0.993878, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997938, 'acc_consonant': 0.997838, 'acc_word': 0.994061, 'loss_grapheme': 0.062189, 'loss_vowel': 0.034923, 'loss_consonant': 0.027339, 'loss_word': 0.043488}\n",
      "   11 | 0.000142 | 160000/160596 | 1.2694 | 5.6459 ||\n",
      "val: {'recall': 0.996453, 'recall_grapheme': 0.995453, 'recall_vowel': 0.998396, 'recall_consonant': 0.996511, 'recall_word': 0.995853, 'acc_grapheme': 0.995999, 'acc_vowel': 0.998608, 'acc_consonant': 0.998261, 'acc_word': 0.99595, 'loss_grapheme': 0.023017, 'loss_vowel': 0.013848, 'loss_consonant': 0.011687, 'loss_word': 0.019823}\n",
      "   12 | 0.000140 | 160000/160596 | 1.1147 | 5.7812 ||\n",
      "val: {'recall': 0.997024, 'recall_grapheme': 0.9962, 'recall_vowel': 0.997962, 'recall_consonant': 0.997732, 'recall_word': 0.995692, 'acc_grapheme': 0.996024, 'acc_vowel': 0.998459, 'acc_consonant': 0.998435, 'acc_word': 0.995801, 'loss_grapheme': 0.024543, 'loss_vowel': 0.014122, 'loss_consonant': 0.011764, 'loss_word': 0.020394}\n",
      "   13 | 0.000139 | 160000/160596 | 13.3153 | 5.5373 |\n",
      "val: {'recall': 0.996426, 'recall_grapheme': 0.995226, 'recall_vowel': 0.997699, 'recall_consonant': 0.997554, 'recall_word': 0.99467, 'acc_grapheme': 0.99513, 'acc_vowel': 0.998211, 'acc_consonant': 0.997987, 'acc_word': 0.994856, 'loss_grapheme': 0.104771, 'loss_vowel': 0.059547, 'loss_consonant': 0.051085, 'loss_word': 0.068273}\n",
      "   14 | 0.000137 | 160000/160596 | 6.5821 | 5.5656 |||\n",
      "val: {'recall': 0.996843, 'recall_grapheme': 0.995772, 'recall_vowel': 0.99821, 'recall_consonant': 0.997618, 'recall_word': 0.994881, 'acc_grapheme': 0.995403, 'acc_vowel': 0.998186, 'acc_consonant': 0.998112, 'acc_word': 0.994981, 'loss_grapheme': 0.031929, 'loss_vowel': 0.018455, 'loss_consonant': 0.015103, 'loss_word': 0.025682}\n",
      "   15 | 0.000136 | 160000/160596 | 1.3420 | 6.0767 |||\n",
      "val: {'recall': 0.996563, 'recall_grapheme': 0.995797, 'recall_vowel': 0.998211, 'recall_consonant': 0.996448, 'recall_word': 0.995525, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998211, 'acc_consonant': 0.998285, 'acc_word': 0.995627, 'loss_grapheme': 0.040449, 'loss_vowel': 0.027008, 'loss_consonant': 0.020181, 'loss_word': 0.02899}\n",
      "   16 | 0.000134 | 160000/160596 | 1.2393 | 5.8413 ||\n",
      "val: {'recall': 0.997168, 'recall_grapheme': 0.996207, 'recall_vowel': 0.998245, 'recall_consonant': 0.998012, 'recall_word': 0.995896, 'acc_grapheme': 0.996248, 'acc_vowel': 0.998509, 'acc_consonant': 0.998435, 'acc_word': 0.996024, 'loss_grapheme': 0.030993, 'loss_vowel': 0.02007, 'loss_consonant': 0.017586, 'loss_word': 0.02185}\n",
      "   17 | 0.000132 | 160000/160596 | 1.2414 | 5.5937 ||\n",
      "val: {'recall': 0.996364, 'recall_grapheme': 0.995747, 'recall_vowel': 0.997748, 'recall_consonant': 0.996213, 'recall_word': 0.995269, 'acc_grapheme': 0.99595, 'acc_vowel': 0.998285, 'acc_consonant': 0.998236, 'acc_word': 0.995378, 'loss_grapheme': 0.045228, 'loss_vowel': 0.028328, 'loss_consonant': 0.025976, 'loss_word': 0.030875}\n",
      "   18 | 0.000130 | 160000/160596 | 4.8486 | 6.2766 ||\n",
      "val: {'recall': 0.996559, 'recall_grapheme': 0.994995, 'recall_vowel': 0.998206, 'recall_consonant': 0.998041, 'recall_word': 0.995475, 'acc_grapheme': 0.995776, 'acc_vowel': 0.998285, 'acc_consonant': 0.998534, 'acc_word': 0.995502, 'loss_grapheme': 0.032538, 'loss_vowel': 0.020521, 'loss_consonant': 0.018298, 'loss_word': 0.02439}\n",
      "   19 | 0.000128 | 160000/160596 | 9.1607 | 6.2202 |||\n",
      "val: {'recall': 0.997433, 'recall_grapheme': 0.996683, 'recall_vowel': 0.998204, 'recall_consonant': 0.998161, 'recall_word': 0.996032, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998484, 'acc_consonant': 0.998683, 'acc_word': 0.996124, 'loss_grapheme': 0.054378, 'loss_vowel': 0.035272, 'loss_consonant': 0.027784, 'loss_word': 0.033944}\n",
      "   20 | 0.000126 | 160000/160596 | 7.0615 | 5.6644 |||\n",
      "val: {'recall': 0.996941, 'recall_grapheme': 0.996306, 'recall_vowel': 0.997919, 'recall_consonant': 0.997235, 'recall_word': 0.994963, 'acc_grapheme': 0.995652, 'acc_vowel': 0.998186, 'acc_consonant': 0.998136, 'acc_word': 0.995155, 'loss_grapheme': 0.068303, 'loss_vowel': 0.04451, 'loss_consonant': 0.033196, 'loss_word': 0.044111}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 0.000124 | 160000/160596 | 1.0600 | 5.8904 |||\n",
      "val: {'recall': 0.997305, 'recall_grapheme': 0.9967, 'recall_vowel': 0.998158, 'recall_consonant': 0.997662, 'recall_word': 0.994828, 'acc_grapheme': 0.995751, 'acc_vowel': 0.998037, 'acc_consonant': 0.998112, 'acc_word': 0.99503, 'loss_grapheme': 0.052154, 'loss_vowel': 0.032498, 'loss_consonant': 0.022602, 'loss_word': 0.038545}\n",
      "   22 | 0.000121 | 160000/160596 | 4.1207 | 5.5746 ||\n",
      "val: {'recall': 0.997356, 'recall_grapheme': 0.996551, 'recall_vowel': 0.998538, 'recall_consonant': 0.997782, 'recall_word': 0.995879, 'acc_grapheme': 0.996372, 'acc_vowel': 0.99841, 'acc_consonant': 0.99831, 'acc_word': 0.99595, 'loss_grapheme': 0.066727, 'loss_vowel': 0.048288, 'loss_consonant': 0.033742, 'loss_word': 0.039384}\n",
      "   23 | 0.000119 | 160000/160596 | 15.8434 | 5.9452 ||\n",
      "val: {'recall': 0.996974, 'recall_grapheme': 0.995963, 'recall_vowel': 0.998354, 'recall_consonant': 0.997617, 'recall_word': 0.995656, 'acc_grapheme': 0.995726, 'acc_vowel': 0.998285, 'acc_consonant': 0.998211, 'acc_word': 0.995726, 'loss_grapheme': 0.069299, 'loss_vowel': 0.048506, 'loss_consonant': 0.040869, 'loss_word': 0.0402}\n",
      "   24 | 0.000117 | 160000/160596 | 1.2045 | 6.2203 ||\n",
      "val: {'recall': 0.997223, 'recall_grapheme': 0.99667, 'recall_vowel': 0.99809, 'recall_consonant': 0.997461, 'recall_word': 0.99565, 'acc_grapheme': 0.996198, 'acc_vowel': 0.998459, 'acc_consonant': 0.998186, 'acc_word': 0.995776, 'loss_grapheme': 0.030827, 'loss_vowel': 0.01832, 'loss_consonant': 0.014634, 'loss_word': 0.02424}\n",
      "   25 | 0.000114 | 160000/160596 | 13.8491 | 5.5035 |\n",
      "val: {'recall': 0.996665, 'recall_grapheme': 0.995517, 'recall_vowel': 0.998346, 'recall_consonant': 0.997281, 'recall_word': 0.994892, 'acc_grapheme': 0.995328, 'acc_vowel': 0.99836, 'acc_consonant': 0.998261, 'acc_word': 0.995005, 'loss_grapheme': 0.050053, 'loss_vowel': 0.030618, 'loss_consonant': 0.026172, 'loss_word': 0.03263}\n",
      "   26 | 0.000112 | 160000/160596 | 4.9102 | 6.2604 |||\n",
      "val: {'recall': 0.997087, 'recall_grapheme': 0.996012, 'recall_vowel': 0.998304, 'recall_consonant': 0.998019, 'recall_word': 0.99564, 'acc_grapheme': 0.996198, 'acc_vowel': 0.998459, 'acc_consonant': 0.998534, 'acc_word': 0.995751, 'loss_grapheme': 0.051408, 'loss_vowel': 0.033402, 'loss_consonant': 0.027272, 'loss_word': 0.03246}\n",
      "   27 | 0.000109 | 160000/160596 | 3.0740 | 5.7510 ||\n",
      "val: {'recall': 0.996935, 'recall_grapheme': 0.996058, 'recall_vowel': 0.997682, 'recall_consonant': 0.997944, 'recall_word': 0.995663, 'acc_grapheme': 0.995925, 'acc_vowel': 0.998285, 'acc_consonant': 0.99836, 'acc_word': 0.995751, 'loss_grapheme': 0.090171, 'loss_vowel': 0.061385, 'loss_consonant': 0.043823, 'loss_word': 0.056236}\n",
      "   28 | 0.000106 | 160000/160596 | 13.5241 | 5.4958 |\n",
      "val: {'recall': 0.997119, 'recall_grapheme': 0.99603, 'recall_vowel': 0.998617, 'recall_consonant': 0.997798, 'recall_word': 0.995834, 'acc_grapheme': 0.996422, 'acc_vowel': 0.998534, 'acc_consonant': 0.998584, 'acc_word': 0.995925, 'loss_grapheme': 0.035239, 'loss_vowel': 0.022953, 'loss_consonant': 0.01905, 'loss_word': 0.024641}\n",
      "   29 | 0.000104 | 160000/160596 | 1.1854 | 5.5416 ||\n",
      "val: {'recall': 0.997447, 'recall_grapheme': 0.996824, 'recall_vowel': 0.998345, 'recall_consonant': 0.997793, 'recall_word': 0.996223, 'acc_grapheme': 0.99667, 'acc_vowel': 0.998509, 'acc_consonant': 0.998509, 'acc_word': 0.996347, 'loss_grapheme': 0.027576, 'loss_vowel': 0.019345, 'loss_consonant': 0.015561, 'loss_word': 0.021136}\n",
      "   30 | 0.000101 | 160000/160596 | 1.1663 | 5.8621 ||\n",
      "val: {'recall': 0.996866, 'recall_grapheme': 0.995867, 'recall_vowel': 0.998388, 'recall_consonant': 0.997341, 'recall_word': 0.995217, 'acc_grapheme': 0.99595, 'acc_vowel': 0.998285, 'acc_consonant': 0.99836, 'acc_word': 0.995378, 'loss_grapheme': 0.057229, 'loss_vowel': 0.036735, 'loss_consonant': 0.031095, 'loss_word': 0.036923}\n",
      "   31 | 0.000098 | 160000/160596 | 1.1139 | 5.6897 ||\n",
      "val: {'recall': 0.99722, 'recall_grapheme': 0.996412, 'recall_vowel': 0.998488, 'recall_consonant': 0.99757, 'recall_word': 0.995813, 'acc_grapheme': 0.996347, 'acc_vowel': 0.998459, 'acc_consonant': 0.998285, 'acc_word': 0.995975, 'loss_grapheme': 0.027058, 'loss_vowel': 0.016192, 'loss_consonant': 0.014128, 'loss_word': 0.021357}\n",
      "   32 | 0.000095 | 160000/160596 | 1.1586 | 5.2685 ||\n",
      "val: {'recall': 0.997068, 'recall_grapheme': 0.996245, 'recall_vowel': 0.998095, 'recall_consonant': 0.997686, 'recall_word': 0.995517, 'acc_grapheme': 0.995999, 'acc_vowel': 0.998385, 'acc_consonant': 0.99831, 'acc_word': 0.995652, 'loss_grapheme': 0.064031, 'loss_vowel': 0.04602, 'loss_consonant': 0.038169, 'loss_word': 0.038862}\n",
      "   33 | 0.000093 | 160000/160596 | 4.3376 | 5.6718 |||\n",
      "val: {'recall': 0.99678, 'recall_grapheme': 0.995552, 'recall_vowel': 0.998376, 'recall_consonant': 0.997642, 'recall_word': 0.995323, 'acc_grapheme': 0.99595, 'acc_vowel': 0.99841, 'acc_consonant': 0.998211, 'acc_word': 0.995453, 'loss_grapheme': 0.045084, 'loss_vowel': 0.030558, 'loss_consonant': 0.023793, 'loss_word': 0.03077}\n",
      "   34 | 0.000090 | 160000/160596 | 5.1538 | 5.5667 |||\n",
      "val: {'recall': 0.997331, 'recall_grapheme': 0.996547, 'recall_vowel': 0.99831, 'recall_consonant': 0.99792, 'recall_word': 0.996209, 'acc_grapheme': 0.996645, 'acc_vowel': 0.998534, 'acc_consonant': 0.998484, 'acc_word': 0.996322, 'loss_grapheme': 0.027277, 'loss_vowel': 0.018713, 'loss_consonant': 0.015801, 'loss_word': 0.020365}\n",
      "   35 | 0.000087 | 160000/160596 | 6.3408 | 5.5269 |||\n",
      "val: {'recall': 0.997, 'recall_grapheme': 0.995913, 'recall_vowel': 0.998465, 'recall_consonant': 0.99771, 'recall_word': 0.995915, 'acc_grapheme': 0.996372, 'acc_vowel': 0.998534, 'acc_consonant': 0.99836, 'acc_word': 0.995975, 'loss_grapheme': 0.034629, 'loss_vowel': 0.022682, 'loss_consonant': 0.019282, 'loss_word': 0.025104}\n",
      "   36 | 0.000084 | 160000/160596 | 1.1943 | 5.8277 ||\n",
      "val: {'recall': 0.997142, 'recall_grapheme': 0.99625, 'recall_vowel': 0.998193, 'recall_consonant': 0.997877, 'recall_word': 0.996484, 'acc_grapheme': 0.99672, 'acc_vowel': 0.998534, 'acc_consonant': 0.998385, 'acc_word': 0.996546, 'loss_grapheme': 0.047663, 'loss_vowel': 0.034545, 'loss_consonant': 0.029407, 'loss_word': 0.029168}\n",
      "   37 | 0.000081 | 160000/160596 | 3.4818 | 5.5551 ||\n",
      "val: {'recall': 0.996858, 'recall_grapheme': 0.996288, 'recall_vowel': 0.997802, 'recall_consonant': 0.997055, 'recall_word': 0.995593, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998161, 'acc_consonant': 0.998186, 'acc_word': 0.995652, 'loss_grapheme': 0.03776, 'loss_vowel': 0.022053, 'loss_consonant': 0.020181, 'loss_word': 0.026339}\n",
      "   38 | 0.000078 | 160000/160596 | 0.9993 | 5.8491 |||\n",
      "val: {'recall': 0.996898, 'recall_grapheme': 0.996547, 'recall_vowel': 0.998145, 'recall_consonant': 0.99635, 'recall_word': 0.99544, 'acc_grapheme': 0.996273, 'acc_vowel': 0.99841, 'acc_consonant': 0.998211, 'acc_word': 0.995577, 'loss_grapheme': 0.049436, 'loss_vowel': 0.032272, 'loss_consonant': 0.025406, 'loss_word': 0.032589}\n",
      "   39 | 0.000075 | 160000/160596 | 0.8723 | 5.2606 ||\n",
      "val: {'recall': 0.997192, 'recall_grapheme': 0.996316, 'recall_vowel': 0.998352, 'recall_consonant': 0.997786, 'recall_word': 0.995319, 'acc_grapheme': 0.996198, 'acc_vowel': 0.998261, 'acc_consonant': 0.998385, 'acc_word': 0.995453, 'loss_grapheme': 0.063244, 'loss_vowel': 0.042011, 'loss_consonant': 0.032868, 'loss_word': 0.040897}\n",
      "   40 | 0.000072 | 160000/160596 | 1.4359 | 6.1563 ||\n",
      "val: {'recall': 0.997474, 'recall_grapheme': 0.996858, 'recall_vowel': 0.998301, 'recall_consonant': 0.997877, 'recall_word': 0.995826, 'acc_grapheme': 0.996596, 'acc_vowel': 0.99836, 'acc_consonant': 0.998534, 'acc_word': 0.995975, 'loss_grapheme': 0.064388, 'loss_vowel': 0.038368, 'loss_consonant': 0.032323, 'loss_word': 0.041502}\n",
      "   41 | 0.000069 | 160000/160596 | 0.9945 | 6.0972 ||\n",
      "val: {'recall': 0.9972, 'recall_grapheme': 0.996209, 'recall_vowel': 0.998534, 'recall_consonant': 0.99785, 'recall_word': 0.996298, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998708, 'acc_consonant': 0.998435, 'acc_word': 0.996447, 'loss_grapheme': 0.036595, 'loss_vowel': 0.023149, 'loss_consonant': 0.02082, 'loss_word': 0.02432}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 0.000066 | 160000/160596 | 14.6596 | 5.4598 |\n",
      "val: {'recall': 0.997537, 'recall_grapheme': 0.996912, 'recall_vowel': 0.998267, 'recall_consonant': 0.998056, 'recall_word': 0.996433, 'acc_grapheme': 0.99677, 'acc_vowel': 0.998484, 'acc_consonant': 0.998559, 'acc_word': 0.996546, 'loss_grapheme': 0.067728, 'loss_vowel': 0.049037, 'loss_consonant': 0.036609, 'loss_word': 0.038031}\n",
      "   43 | 0.000063 | 160000/160596 | 1.0342 | 5.4772 ||\n",
      "val: {'recall': 0.997367, 'recall_grapheme': 0.996523, 'recall_vowel': 0.998446, 'recall_consonant': 0.997977, 'recall_word': 0.996105, 'acc_grapheme': 0.996571, 'acc_vowel': 0.998459, 'acc_consonant': 0.998459, 'acc_word': 0.996198, 'loss_grapheme': 0.036174, 'loss_vowel': 0.025477, 'loss_consonant': 0.021143, 'loss_word': 0.023965}\n",
      "   44 | 0.000060 | 160000/160596 | 0.8816 | 5.0771 |||\n",
      "val: {'recall': 0.997472, 'recall_grapheme': 0.996858, 'recall_vowel': 0.998425, 'recall_consonant': 0.997746, 'recall_word': 0.996292, 'acc_grapheme': 0.996968, 'acc_vowel': 0.998534, 'acc_consonant': 0.998459, 'acc_word': 0.996422, 'loss_grapheme': 0.020705, 'loss_vowel': 0.012464, 'loss_consonant': 0.010811, 'loss_word': 0.017887}\n",
      "   45 | 0.000058 | 160000/160596 | 7.1295 | 5.5001 |||\n",
      "val: {'recall': 0.996985, 'recall_grapheme': 0.995994, 'recall_vowel': 0.998147, 'recall_consonant': 0.997806, 'recall_word': 0.995057, 'acc_grapheme': 0.995701, 'acc_vowel': 0.998186, 'acc_consonant': 0.998186, 'acc_word': 0.995155, 'loss_grapheme': 0.072548, 'loss_vowel': 0.046799, 'loss_consonant': 0.03969, 'loss_word': 0.045326}\n",
      "   46 | 0.000055 | 160000/160596 | 3.0487 | 5.7240 ||\n",
      "val: {'recall': 0.997356, 'recall_grapheme': 0.996556, 'recall_vowel': 0.998572, 'recall_consonant': 0.997737, 'recall_word': 0.995508, 'acc_grapheme': 0.996298, 'acc_vowel': 0.99836, 'acc_consonant': 0.99841, 'acc_word': 0.995577, 'loss_grapheme': 0.04873, 'loss_vowel': 0.030585, 'loss_consonant': 0.026773, 'loss_word': 0.033083}\n",
      "   47 | 0.000052 | 160000/160596 | 6.4757 | 6.1986 ||\n",
      "val: {'recall': 0.997046, 'recall_grapheme': 0.996241, 'recall_vowel': 0.998386, 'recall_consonant': 0.997315, 'recall_word': 0.995963, 'acc_grapheme': 0.996372, 'acc_vowel': 0.998534, 'acc_consonant': 0.998435, 'acc_word': 0.996024, 'loss_grapheme': 0.074162, 'loss_vowel': 0.044349, 'loss_consonant': 0.036839, 'loss_word': 0.045083}\n",
      "   48 | 0.000049 | 160000/160596 | 12.5152 | 5.8045 |\n",
      "val: {'recall': 0.997269, 'recall_grapheme': 0.996286, 'recall_vowel': 0.998604, 'recall_consonant': 0.997901, 'recall_word': 0.996261, 'acc_grapheme': 0.99672, 'acc_vowel': 0.998534, 'acc_consonant': 0.998559, 'acc_word': 0.996372, 'loss_grapheme': 0.02833, 'loss_vowel': 0.020068, 'loss_consonant': 0.017855, 'loss_word': 0.019724}\n",
      "   49 | 0.000046 | 160000/160596 | 1.0900 | 5.7078 ||\n",
      "val: {'recall': 0.997198, 'recall_grapheme': 0.996239, 'recall_vowel': 0.998513, 'recall_consonant': 0.997799, 'recall_word': 0.995619, 'acc_grapheme': 0.996198, 'acc_vowel': 0.998484, 'acc_consonant': 0.998435, 'acc_word': 0.995701, 'loss_grapheme': 0.064773, 'loss_vowel': 0.040398, 'loss_consonant': 0.034452, 'loss_word': 0.04092}\n",
      "   50 | 0.000044 | 160000/160596 | 2.7968 | 5.4413 ||\n",
      "val: {'recall': 0.997312, 'recall_grapheme': 0.996494, 'recall_vowel': 0.998493, 'recall_consonant': 0.997768, 'recall_word': 0.996106, 'acc_grapheme': 0.996496, 'acc_vowel': 0.998534, 'acc_consonant': 0.998385, 'acc_word': 0.996223, 'loss_grapheme': 0.042436, 'loss_vowel': 0.026723, 'loss_consonant': 0.022378, 'loss_word': 0.028263}\n",
      "   51 | 0.000041 | 160000/160596 | 6.9863 | 5.8118 ||\n",
      "val: {'recall': 0.997084, 'recall_grapheme': 0.996157, 'recall_vowel': 0.99822, 'recall_consonant': 0.997799, 'recall_word': 0.995724, 'acc_grapheme': 0.996099, 'acc_vowel': 0.99836, 'acc_consonant': 0.998435, 'acc_word': 0.995825, 'loss_grapheme': 0.078421, 'loss_vowel': 0.054318, 'loss_consonant': 0.043894, 'loss_word': 0.044423}\n",
      "   52 | 0.000038 | 160000/160596 | 14.3289 | 5.3065 |\n",
      "val: {'recall': 0.997332, 'recall_grapheme': 0.996524, 'recall_vowel': 0.998446, 'recall_consonant': 0.997836, 'recall_word': 0.996316, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998584, 'acc_consonant': 0.998484, 'acc_word': 0.996447, 'loss_grapheme': 0.046738, 'loss_vowel': 0.033483, 'loss_consonant': 0.026361, 'loss_word': 0.029149}\n",
      "   53 | 0.000036 | 160000/160596 | 11.0646 | 5.7479 |\n",
      "val: {'recall': 0.99737, 'recall_grapheme': 0.996533, 'recall_vowel': 0.998517, 'recall_consonant': 0.997899, 'recall_word': 0.99637, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998633, 'acc_consonant': 0.998484, 'acc_word': 0.996496, 'loss_grapheme': 0.046796, 'loss_vowel': 0.02945, 'loss_consonant': 0.024148, 'loss_word': 0.029125}\n",
      "   54 | 0.000033 | 160000/160596 | 6.7811 | 5.6469 |||\n",
      "val: {'recall': 0.997424, 'recall_grapheme': 0.99661, 'recall_vowel': 0.998609, 'recall_consonant': 0.997867, 'recall_word': 0.996429, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998633, 'acc_consonant': 0.998459, 'acc_word': 0.996521, 'loss_grapheme': 0.033846, 'loss_vowel': 0.022645, 'loss_consonant': 0.019124, 'loss_word': 0.023188}\n",
      "   55 | 0.000031 | 160000/160596 | 0.9774 | 5.5952 ||\n",
      "val: {'recall': 0.997443, 'recall_grapheme': 0.996637, 'recall_vowel': 0.998489, 'recall_consonant': 0.998008, 'recall_word': 0.996414, 'acc_grapheme': 0.996695, 'acc_vowel': 0.998633, 'acc_consonant': 0.998608, 'acc_word': 0.996546, 'loss_grapheme': 0.028956, 'loss_vowel': 0.018862, 'loss_consonant': 0.014949, 'loss_word': 0.02091}\n",
      "   56 | 0.000029 | 160000/160596 | 12.5216 | 5.7720 |\n",
      "val: {'recall': 0.997443, 'recall_grapheme': 0.996849, 'recall_vowel': 0.998213, 'recall_consonant': 0.997862, 'recall_word': 0.996092, 'acc_grapheme': 0.996521, 'acc_vowel': 0.998559, 'acc_consonant': 0.998484, 'acc_word': 0.996223, 'loss_grapheme': 0.054819, 'loss_vowel': 0.036715, 'loss_consonant': 0.029966, 'loss_word': 0.034525}\n",
      "   57 | 0.000026 | 160000/160596 | 14.3939 | 5.2696 |\n",
      "val: {'recall': 0.997187, 'recall_grapheme': 0.996276, 'recall_vowel': 0.998204, 'recall_consonant': 0.997993, 'recall_word': 0.996343, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998584, 'acc_consonant': 0.998608, 'acc_word': 0.996472, 'loss_grapheme': 0.034148, 'loss_vowel': 0.02298, 'loss_consonant': 0.019871, 'loss_word': 0.022388}\n",
      "   58 | 0.000024 | 160000/160596 | 0.9042 | 5.8197 ||\n",
      "val: {'recall': 0.997477, 'recall_grapheme': 0.996784, 'recall_vowel': 0.998429, 'recall_consonant': 0.997911, 'recall_word': 0.995794, 'acc_grapheme': 0.996372, 'acc_vowel': 0.998459, 'acc_consonant': 0.998435, 'acc_word': 0.9959, 'loss_grapheme': 0.067827, 'loss_vowel': 0.044969, 'loss_consonant': 0.036918, 'loss_word': 0.041852}\n",
      "   59 | 0.000022 | 160000/160596 | 13.9062 | 5.6289 |\n",
      "val: {'recall': 0.997514, 'recall_grapheme': 0.996742, 'recall_vowel': 0.998606, 'recall_consonant': 0.997966, 'recall_word': 0.996485, 'acc_grapheme': 0.99677, 'acc_vowel': 0.998683, 'acc_consonant': 0.998708, 'acc_word': 0.996596, 'loss_grapheme': 0.056237, 'loss_vowel': 0.036078, 'loss_consonant': 0.032229, 'loss_word': 0.032717}\n",
      "   60 | 0.000020 | 160000/160596 | 4.3869 | 5.2028 ||\n",
      "val: {'recall': 0.997193, 'recall_grapheme': 0.99632, 'recall_vowel': 0.998417, 'recall_consonant': 0.997715, 'recall_word': 0.996146, 'acc_grapheme': 0.996521, 'acc_vowel': 0.998534, 'acc_consonant': 0.998435, 'acc_word': 0.996298, 'loss_grapheme': 0.038818, 'loss_vowel': 0.024907, 'loss_consonant': 0.021809, 'loss_word': 0.025463}\n",
      "   61 | 0.000018 | 160000/160596 | 7.3901 | 5.8810 ||\n",
      "val: {'recall': 0.997372, 'recall_grapheme': 0.996551, 'recall_vowel': 0.998493, 'recall_consonant': 0.997896, 'recall_word': 0.996016, 'acc_grapheme': 0.996447, 'acc_vowel': 0.998584, 'acc_consonant': 0.998484, 'acc_word': 0.996124, 'loss_grapheme': 0.077424, 'loss_vowel': 0.050541, 'loss_consonant': 0.039818, 'loss_word': 0.046623}\n",
      "   62 | 0.000016 | 160000/160596 | 1.1311 | 5.4025 |||\n",
      "val: {'recall': 0.997301, 'recall_grapheme': 0.996463, 'recall_vowel': 0.998527, 'recall_consonant': 0.997751, 'recall_word': 0.996045, 'acc_grapheme': 0.996596, 'acc_vowel': 0.998608, 'acc_consonant': 0.998459, 'acc_word': 0.996198, 'loss_grapheme': 0.028898, 'loss_vowel': 0.018294, 'loss_consonant': 0.016, 'loss_word': 0.021097}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   63 | 0.000014 | 160000/160596 | 7.3366 | 5.3388 ||\n",
      "val: {'recall': 0.997169, 'recall_grapheme': 0.996223, 'recall_vowel': 0.998481, 'recall_consonant': 0.997748, 'recall_word': 0.996268, 'acc_grapheme': 0.996521, 'acc_vowel': 0.998608, 'acc_consonant': 0.998459, 'acc_word': 0.996397, 'loss_grapheme': 0.023479, 'loss_vowel': 0.016169, 'loss_consonant': 0.014648, 'loss_word': 0.017513}\n",
      "   64 | 0.000013 | 160000/160596 | 0.8939 | 5.4571 ||\n",
      "val: {'recall': 0.99742, 'recall_grapheme': 0.996568, 'recall_vowel': 0.998604, 'recall_consonant': 0.997939, 'recall_word': 0.996806, 'acc_grapheme': 0.997018, 'acc_vowel': 0.998733, 'acc_consonant': 0.998608, 'acc_word': 0.996919, 'loss_grapheme': 0.023622, 'loss_vowel': 0.017236, 'loss_consonant': 0.014628, 'loss_word': 0.017275}\n",
      "   65 | 0.000011 | 160000/160596 | 0.8816 | 5.4897 ||\n",
      "val: {'recall': 0.997477, 'recall_grapheme': 0.996666, 'recall_vowel': 0.998701, 'recall_consonant': 0.997876, 'recall_word': 0.996587, 'acc_grapheme': 0.996795, 'acc_vowel': 0.998733, 'acc_consonant': 0.998559, 'acc_word': 0.99672, 'loss_grapheme': 0.023366, 'loss_vowel': 0.017102, 'loss_consonant': 0.014128, 'loss_word': 0.01736}\n",
      "   66 | 0.000010 | 160000/160596 | 10.0396 | 5.3784 |\n",
      "val: {'recall': 0.997585, 'recall_grapheme': 0.996844, 'recall_vowel': 0.998684, 'recall_consonant': 0.997967, 'recall_word': 0.996612, 'acc_grapheme': 0.996869, 'acc_vowel': 0.998683, 'acc_consonant': 0.998584, 'acc_word': 0.99672, 'loss_grapheme': 0.025729, 'loss_vowel': 0.017385, 'loss_consonant': 0.013778, 'loss_word': 0.019215}\n",
      "   67 | 0.000008 | 160000/160596 | 12.9285 | 5.3109 ||\n",
      "val: {'recall': 0.997551, 'recall_grapheme': 0.996863, 'recall_vowel': 0.998606, 'recall_consonant': 0.997872, 'recall_word': 0.996473, 'acc_grapheme': 0.996944, 'acc_vowel': 0.998733, 'acc_consonant': 0.998584, 'acc_word': 0.996596, 'loss_grapheme': 0.033528, 'loss_vowel': 0.023013, 'loss_consonant': 0.020087, 'loss_word': 0.022051}\n",
      "   68 | 0.000007 | 160000/160596 | 3.3318 | 5.6734 ||\n",
      "val: {'recall': 0.997323, 'recall_grapheme': 0.996376, 'recall_vowel': 0.998573, 'recall_consonant': 0.997965, 'recall_word': 0.996363, 'acc_grapheme': 0.99667, 'acc_vowel': 0.998633, 'acc_consonant': 0.998658, 'acc_word': 0.996496, 'loss_grapheme': 0.026339, 'loss_vowel': 0.018082, 'loss_consonant': 0.014323, 'loss_word': 0.019223}\n",
      "   69 | 0.000006 | 160000/160596 | 1.0850 | 6.3025 |||\n",
      "val: {'recall': 0.997381, 'recall_grapheme': 0.996858, 'recall_vowel': 0.998571, 'recall_consonant': 0.997235, 'recall_word': 0.995867, 'acc_grapheme': 0.996571, 'acc_vowel': 0.998608, 'acc_consonant': 0.998335, 'acc_word': 0.995999, 'loss_grapheme': 0.057769, 'loss_vowel': 0.036626, 'loss_consonant': 0.032194, 'loss_word': 0.035923}\n",
      "   70 | 0.000005 | 160000/160596 | 0.9220 | 5.3588 |||\n",
      "val: {'recall': 0.997553, 'recall_grapheme': 0.996799, 'recall_vowel': 0.9987, 'recall_consonant': 0.997914, 'recall_word': 0.996593, 'acc_grapheme': 0.996993, 'acc_vowel': 0.998733, 'acc_consonant': 0.998633, 'acc_word': 0.996745, 'loss_grapheme': 0.017291, 'loss_vowel': 0.010921, 'loss_consonant': 0.009304, 'loss_word': 0.015096}\n",
      "   71 | 0.000004 | 160000/160596 | 3.4978 | 5.4404 ||\n",
      "val: {'recall': 0.997179, 'recall_grapheme': 0.996237, 'recall_vowel': 0.998558, 'recall_consonant': 0.997682, 'recall_word': 0.996249, 'acc_grapheme': 0.996472, 'acc_vowel': 0.998683, 'acc_consonant': 0.998385, 'acc_word': 0.996372, 'loss_grapheme': 0.072165, 'loss_vowel': 0.047697, 'loss_consonant': 0.037383, 'loss_word': 0.044633}\n",
      "   72 | 0.000003 | 160000/160596 | 0.9253 | 5.4540 ||\n",
      "val: {'recall': 0.997426, 'recall_grapheme': 0.996668, 'recall_vowel': 0.9984, 'recall_consonant': 0.997968, 'recall_word': 0.996332, 'acc_grapheme': 0.997043, 'acc_vowel': 0.998633, 'acc_consonant': 0.998559, 'acc_word': 0.996472, 'loss_grapheme': 0.026215, 'loss_vowel': 0.01666, 'loss_consonant': 0.015414, 'loss_word': 0.019357}\n",
      "   73 | 0.000002 | 160000/160596 | 10.9229 | 5.8341 ||\n",
      "val: {'recall': 0.996905, 'recall_grapheme': 0.995689, 'recall_vowel': 0.998385, 'recall_consonant': 0.997858, 'recall_word': 0.996058, 'acc_grapheme': 0.996223, 'acc_vowel': 0.998584, 'acc_consonant': 0.998435, 'acc_word': 0.996148, 'loss_grapheme': 0.098781, 'loss_vowel': 0.059221, 'loss_consonant': 0.050915, 'loss_word': 0.061998}\n",
      "   74 | 0.000001 | 160000/160596 | 11.0177 | 5.9036 ||\n",
      "val: {'recall': 0.997247, 'recall_grapheme': 0.99636, 'recall_vowel': 0.998345, 'recall_consonant': 0.997924, 'recall_word': 0.99637, 'acc_grapheme': 0.996422, 'acc_vowel': 0.998633, 'acc_consonant': 0.998509, 'acc_word': 0.996521, 'loss_grapheme': 0.062485, 'loss_vowel': 0.042122, 'loss_consonant': 0.034496, 'loss_word': 0.03766}\n",
      "   75 | 0.000001 | 160000/160596 | 6.3496 | 5.4639 ||\n",
      "val: {'recall': 0.997335, 'recall_grapheme': 0.996405, 'recall_vowel': 0.998573, 'recall_consonant': 0.997957, 'recall_word': 0.996375, 'acc_grapheme': 0.996695, 'acc_vowel': 0.998683, 'acc_consonant': 0.998509, 'acc_word': 0.996521, 'loss_grapheme': 0.034999, 'loss_vowel': 0.022515, 'loss_consonant': 0.019227, 'loss_word': 0.023774}\n",
      "   76 | 0.000001 | 160000/160596 | 4.0433 | 5.2337 ||\n",
      "val: {'recall': 0.997277, 'recall_grapheme': 0.996381, 'recall_vowel': 0.998562, 'recall_consonant': 0.997785, 'recall_word': 0.995865, 'acc_grapheme': 0.996372, 'acc_vowel': 0.998633, 'acc_consonant': 0.998385, 'acc_word': 0.995999, 'loss_grapheme': 0.071627, 'loss_vowel': 0.044149, 'loss_consonant': 0.038108, 'loss_word': 0.04436}\n",
      "   77 | 0.000000 | 160000/160596 | 15.0299 | 5.4326 ||\n",
      "val: {'recall': 0.997141, 'recall_grapheme': 0.996176, 'recall_vowel': 0.998521, 'recall_consonant': 0.997688, 'recall_word': 0.9962, 'acc_grapheme': 0.996596, 'acc_vowel': 0.998608, 'acc_consonant': 0.99841, 'acc_word': 0.996347, 'loss_grapheme': 0.058121, 'loss_vowel': 0.03797, 'loss_consonant': 0.029402, 'loss_word': 0.037469}\n",
      "   78 | 0.000000 | 160000/160596 | 4.0145 | 5.5815 ||\n",
      "val: {'recall': 0.997389, 'recall_grapheme': 0.996526, 'recall_vowel': 0.998654, 'recall_consonant': 0.997851, 'recall_word': 0.995959, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998658, 'acc_consonant': 0.998435, 'acc_word': 0.996099, 'loss_grapheme': 0.056635, 'loss_vowel': 0.034773, 'loss_consonant': 0.030613, 'loss_word': 0.03537}\n",
      "   79 | 0.000000 | 160000/160596 | 2.0040 | 5.2613 ||\n",
      "val: {'recall': 0.997218, 'recall_grapheme': 0.996244, 'recall_vowel': 0.99848, 'recall_consonant': 0.997906, 'recall_word': 0.996337, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998584, 'acc_consonant': 0.998509, 'acc_word': 0.996472, 'loss_grapheme': 0.040176, 'loss_vowel': 0.027066, 'loss_consonant': 0.022001, 'loss_word': 0.026968}\n",
      "CYCLE: 2\n",
      "{'recall': 0.997218, 'recall_grapheme': 0.996244, 'recall_vowel': 0.99848, 'recall_consonant': 0.997906, 'recall_word': 0.996337, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998584, 'acc_consonant': 0.998509, 'acc_word': 0.996472, 'loss_grapheme': 0.040176, 'loss_vowel': 0.027066, 'loss_consonant': 0.022001, 'loss_word': 0.026968}\n",
      "    0 | 0.000030 | 160000/160596 | 4.2306 | 4.8043 ||\n",
      "val: {'recall': 0.997336, 'recall_grapheme': 0.996441, 'recall_vowel': 0.998564, 'recall_consonant': 0.997897, 'recall_word': 0.996378, 'acc_grapheme': 0.99667, 'acc_vowel': 0.998608, 'acc_consonant': 0.998584, 'acc_word': 0.996521, 'loss_grapheme': 0.048938, 'loss_vowel': 0.032866, 'loss_consonant': 0.025525, 'loss_word': 0.032249}\n",
      "    1 | 0.000060 | 160000/160596 | 0.5575 | 5.4816 ||\n",
      "val: {'recall': 0.997265, 'recall_grapheme': 0.996465, 'recall_vowel': 0.998568, 'recall_consonant': 0.997562, 'recall_word': 0.995735, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998534, 'acc_consonant': 0.998261, 'acc_word': 0.995875, 'loss_grapheme': 0.036046, 'loss_vowel': 0.025055, 'loss_consonant': 0.01981, 'loss_word': 0.026766}\n",
      "    2 | 0.000090 | 160000/160596 | 14.3547 | 5.6807 |\n",
      "val: {'recall': 0.996957, 'recall_grapheme': 0.995935, 'recall_vowel': 0.998109, 'recall_consonant': 0.997851, 'recall_word': 0.995402, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998211, 'acc_consonant': 0.998335, 'acc_word': 0.995527, 'loss_grapheme': 0.119303, 'loss_vowel': 0.070466, 'loss_consonant': 0.052761, 'loss_word': 0.073541}\n",
      "    3 | 0.000119 | 160000/160596 | 6.4870 | 5.9346 ||\n",
      "val: {'recall': 0.996337, 'recall_grapheme': 0.995219, 'recall_vowel': 0.997329, 'recall_consonant': 0.997581, 'recall_word': 0.994505, 'acc_grapheme': 0.995428, 'acc_vowel': 0.997938, 'acc_consonant': 0.998161, 'acc_word': 0.994558, 'loss_grapheme': 0.089907, 'loss_vowel': 0.052495, 'loss_consonant': 0.043753, 'loss_word': 0.057856}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 | 0.000148 | 160000/160596 | 0.9098 | 5.8904 |||\n",
      "val: {'recall': 0.997415, 'recall_grapheme': 0.996772, 'recall_vowel': 0.998159, 'recall_consonant': 0.997956, 'recall_word': 0.99652, 'acc_grapheme': 0.997018, 'acc_vowel': 0.998484, 'acc_consonant': 0.998708, 'acc_word': 0.996645, 'loss_grapheme': 0.022326, 'loss_vowel': 0.014776, 'loss_consonant': 0.013098, 'loss_word': 0.018249}\n",
      "    5 | 0.000148 | 160000/160596 | 10.9768 | 6.1308 |\n",
      "val: {'recall': 0.996735, 'recall_grapheme': 0.996215, 'recall_vowel': 0.998453, 'recall_consonant': 0.996058, 'recall_word': 0.995799, 'acc_grapheme': 0.996248, 'acc_vowel': 0.998435, 'acc_consonant': 0.99836, 'acc_word': 0.995801, 'loss_grapheme': 0.048717, 'loss_vowel': 0.034124, 'loss_consonant': 0.026089, 'loss_word': 0.031528}\n",
      "    6 | 0.000147 | 160000/160596 | 12.8278 | 5.2024 |\n",
      "val: {'recall': 0.996651, 'recall_grapheme': 0.996218, 'recall_vowel': 0.998251, 'recall_consonant': 0.995916, 'recall_word': 0.995311, 'acc_grapheme': 0.9959, 'acc_vowel': 0.998211, 'acc_consonant': 0.998285, 'acc_word': 0.995353, 'loss_grapheme': 0.037098, 'loss_vowel': 0.023752, 'loss_consonant': 0.017177, 'loss_word': 0.02858}\n",
      "    7 | 0.000146 | 160000/160596 | 11.9674 | 5.5977 |\n",
      "val: {'recall': 0.996853, 'recall_grapheme': 0.996488, 'recall_vowel': 0.998234, 'recall_consonant': 0.996202, 'recall_word': 0.995722, 'acc_grapheme': 0.996124, 'acc_vowel': 0.99836, 'acc_consonant': 0.99836, 'acc_word': 0.995825, 'loss_grapheme': 0.0653, 'loss_vowel': 0.041002, 'loss_consonant': 0.032344, 'loss_word': 0.038108}\n",
      "    8 | 0.000145 | 160000/160596 | 8.4301 | 5.2976 ||\n",
      "val: {'recall': 0.99648, 'recall_grapheme': 0.995141, 'recall_vowel': 0.998091, 'recall_consonant': 0.997546, 'recall_word': 0.995273, 'acc_grapheme': 0.995577, 'acc_vowel': 0.998261, 'acc_consonant': 0.998087, 'acc_word': 0.995378, 'loss_grapheme': 0.046816, 'loss_vowel': 0.029017, 'loss_consonant': 0.024606, 'loss_word': 0.032665}\n",
      "    9 | 0.000144 | 160000/160596 | 1.0133 | 5.5888 ||\n",
      "val: {'recall': 0.997017, 'recall_grapheme': 0.995947, 'recall_vowel': 0.998483, 'recall_consonant': 0.99769, 'recall_word': 0.995477, 'acc_grapheme': 0.995776, 'acc_vowel': 0.998186, 'acc_consonant': 0.998285, 'acc_word': 0.995527, 'loss_grapheme': 0.040114, 'loss_vowel': 0.023593, 'loss_consonant': 0.019593, 'loss_word': 0.028557}\n",
      "   10 | 0.000143 | 160000/160596 | 8.0093 | 5.2883 |||\n",
      "val: {'recall': 0.995824, 'recall_grapheme': 0.994799, 'recall_vowel': 0.998315, 'recall_consonant': 0.995382, 'recall_word': 0.994813, 'acc_grapheme': 0.995105, 'acc_vowel': 0.998087, 'acc_consonant': 0.998037, 'acc_word': 0.994931, 'loss_grapheme': 0.040618, 'loss_vowel': 0.022044, 'loss_consonant': 0.02028, 'loss_word': 0.030638}\n",
      "   11 | 0.000142 | 160000/160596 | 1.0375 | 5.3818 ||\n",
      "val: {'recall': 0.997007, 'recall_grapheme': 0.995947, 'recall_vowel': 0.998659, 'recall_consonant': 0.997477, 'recall_word': 0.995731, 'acc_grapheme': 0.995825, 'acc_vowel': 0.998509, 'acc_consonant': 0.998062, 'acc_word': 0.995676, 'loss_grapheme': 0.054649, 'loss_vowel': 0.033671, 'loss_consonant': 0.028449, 'loss_word': 0.035825}\n",
      "   12 | 0.000140 | 160000/160596 | 6.4611 | 5.9132 ||\n",
      "val: {'recall': 0.996717, 'recall_grapheme': 0.996071, 'recall_vowel': 0.998467, 'recall_consonant': 0.996259, 'recall_word': 0.995872, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998584, 'acc_consonant': 0.99841, 'acc_word': 0.99595, 'loss_grapheme': 0.062174, 'loss_vowel': 0.040071, 'loss_consonant': 0.031598, 'loss_word': 0.040172}\n",
      "   13 | 0.000139 | 160000/160596 | 1.0917 | 6.1456 ||\n",
      "val: {'recall': 0.997237, 'recall_grapheme': 0.996241, 'recall_vowel': 0.99849, 'recall_consonant': 0.997973, 'recall_word': 0.99547, 'acc_grapheme': 0.995999, 'acc_vowel': 0.998459, 'acc_consonant': 0.998509, 'acc_word': 0.995527, 'loss_grapheme': 0.062623, 'loss_vowel': 0.037346, 'loss_consonant': 0.031427, 'loss_word': 0.039988}\n",
      "   14 | 0.000137 | 160000/160596 | 1.0003 | 5.9439 ||\n",
      "val: {'recall': 0.997381, 'recall_grapheme': 0.996692, 'recall_vowel': 0.998336, 'recall_consonant': 0.997803, 'recall_word': 0.995702, 'acc_grapheme': 0.996024, 'acc_vowel': 0.998435, 'acc_consonant': 0.99831, 'acc_word': 0.995751, 'loss_grapheme': 0.042666, 'loss_vowel': 0.021812, 'loss_consonant': 0.021903, 'loss_word': 0.03146}\n",
      "   15 | 0.000136 | 160000/160596 | 14.5040 | 5.7255 ||\n",
      "val: {'recall': 0.996819, 'recall_grapheme': 0.995764, 'recall_vowel': 0.997966, 'recall_consonant': 0.997781, 'recall_word': 0.995559, 'acc_grapheme': 0.99595, 'acc_vowel': 0.998509, 'acc_consonant': 0.998285, 'acc_word': 0.995627, 'loss_grapheme': 0.051124, 'loss_vowel': 0.034772, 'loss_consonant': 0.027782, 'loss_word': 0.032933}\n",
      "   16 | 0.000134 | 160000/160596 | 1.0854 | 5.6739 |||\n",
      "val: {'recall': 0.996823, 'recall_grapheme': 0.995647, 'recall_vowel': 0.998367, 'recall_consonant': 0.997631, 'recall_word': 0.995684, 'acc_grapheme': 0.995701, 'acc_vowel': 0.998459, 'acc_consonant': 0.99841, 'acc_word': 0.995726, 'loss_grapheme': 0.048951, 'loss_vowel': 0.031937, 'loss_consonant': 0.024954, 'loss_word': 0.032083}\n",
      "   17 | 0.000132 | 160000/160596 | 5.2381 | 5.9584 ||\n",
      "val: {'recall': 0.996824, 'recall_grapheme': 0.995908, 'recall_vowel': 0.997684, 'recall_consonant': 0.997798, 'recall_word': 0.995476, 'acc_grapheme': 0.995801, 'acc_vowel': 0.998285, 'acc_consonant': 0.998385, 'acc_word': 0.995502, 'loss_grapheme': 0.045392, 'loss_vowel': 0.031057, 'loss_consonant': 0.025482, 'loss_word': 0.029274}\n",
      "   18 | 0.000130 | 160000/160596 | 1.1783 | 5.9841 ||\n",
      "val: {'recall': 0.996881, 'recall_grapheme': 0.996507, 'recall_vowel': 0.998363, 'recall_consonant': 0.996147, 'recall_word': 0.995598, 'acc_grapheme': 0.996049, 'acc_vowel': 0.998584, 'acc_consonant': 0.998484, 'acc_word': 0.995701, 'loss_grapheme': 0.044283, 'loss_vowel': 0.028918, 'loss_consonant': 0.025572, 'loss_word': 0.028627}\n",
      "   19 | 0.000128 | 160000/160596 | 0.9355 | 5.5909 ||\n",
      "val: {'recall': 0.996486, 'recall_grapheme': 0.995109, 'recall_vowel': 0.997991, 'recall_consonant': 0.997735, 'recall_word': 0.994705, 'acc_grapheme': 0.995428, 'acc_vowel': 0.998261, 'acc_consonant': 0.998112, 'acc_word': 0.994757, 'loss_grapheme': 0.056673, 'loss_vowel': 0.037716, 'loss_consonant': 0.031107, 'loss_word': 0.039141}\n",
      "   20 | 0.000126 | 160000/160596 | 7.1059 | 5.3047 ||\n",
      "val: {'recall': 0.997059, 'recall_grapheme': 0.996009, 'recall_vowel': 0.99796, 'recall_consonant': 0.998259, 'recall_word': 0.996171, 'acc_grapheme': 0.996447, 'acc_vowel': 0.998385, 'acc_consonant': 0.998807, 'acc_word': 0.996248, 'loss_grapheme': 0.029122, 'loss_vowel': 0.016671, 'loss_consonant': 0.015039, 'loss_word': 0.021109}\n",
      "   21 | 0.000124 | 160000/160596 | 10.8801 | 5.4816 |\n",
      "val: {'recall': 0.997133, 'recall_grapheme': 0.996473, 'recall_vowel': 0.997929, 'recall_consonant': 0.997659, 'recall_word': 0.995776, 'acc_grapheme': 0.996223, 'acc_vowel': 0.998559, 'acc_consonant': 0.998385, 'acc_word': 0.9959, 'loss_grapheme': 0.045619, 'loss_vowel': 0.027523, 'loss_consonant': 0.021911, 'loss_word': 0.029192}\n",
      "   22 | 0.000121 | 160000/160596 | 13.5131 | 5.9331 |\n",
      "val: {'recall': 0.996878, 'recall_grapheme': 0.995782, 'recall_vowel': 0.998072, 'recall_consonant': 0.997877, 'recall_word': 0.995251, 'acc_grapheme': 0.9959, 'acc_vowel': 0.99831, 'acc_consonant': 0.998435, 'acc_word': 0.995279, 'loss_grapheme': 0.057071, 'loss_vowel': 0.036792, 'loss_consonant': 0.03081, 'loss_word': 0.034502}\n",
      "   23 | 0.000119 | 160000/160596 | 5.8548 | 5.0669 ||\n",
      "val: {'recall': 0.997303, 'recall_grapheme': 0.996307, 'recall_vowel': 0.998585, 'recall_consonant': 0.998014, 'recall_word': 0.995565, 'acc_grapheme': 0.996223, 'acc_vowel': 0.998484, 'acc_consonant': 0.998459, 'acc_word': 0.995652, 'loss_grapheme': 0.046524, 'loss_vowel': 0.031244, 'loss_consonant': 0.025754, 'loss_word': 0.030214}\n",
      "   24 | 0.000117 | 160000/160596 | 7.1480 | 5.6133 ||\n",
      "val: {'recall': 0.997621, 'recall_grapheme': 0.996981, 'recall_vowel': 0.998567, 'recall_consonant': 0.997956, 'recall_word': 0.996359, 'acc_grapheme': 0.996596, 'acc_vowel': 0.998608, 'acc_consonant': 0.998509, 'acc_word': 0.996422, 'loss_grapheme': 0.096801, 'loss_vowel': 0.061223, 'loss_consonant': 0.047582, 'loss_word': 0.062028}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 0.000114 | 160000/160596 | 6.0655 | 5.7730 |||\n",
      "val: {'recall': 0.997274, 'recall_grapheme': 0.996353, 'recall_vowel': 0.998428, 'recall_consonant': 0.99796, 'recall_word': 0.996191, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998484, 'acc_consonant': 0.998534, 'acc_word': 0.996273, 'loss_grapheme': 0.060595, 'loss_vowel': 0.041571, 'loss_consonant': 0.031549, 'loss_word': 0.037808}\n",
      "   26 | 0.000112 | 160000/160596 | 0.9895 | 5.4671 ||\n",
      "val: {'recall': 0.997405, 'recall_grapheme': 0.996481, 'recall_vowel': 0.998521, 'recall_consonant': 0.998138, 'recall_word': 0.996579, 'acc_grapheme': 0.996645, 'acc_vowel': 0.998608, 'acc_consonant': 0.998782, 'acc_word': 0.99672, 'loss_grapheme': 0.028161, 'loss_vowel': 0.018129, 'loss_consonant': 0.014739, 'loss_word': 0.019408}\n",
      "   27 | 0.000109 | 160000/160596 | 1.0163 | 5.6899 ||\n",
      "val: {'recall': 0.996831, 'recall_grapheme': 0.995755, 'recall_vowel': 0.998274, 'recall_consonant': 0.997541, 'recall_word': 0.995238, 'acc_grapheme': 0.995577, 'acc_vowel': 0.998211, 'acc_consonant': 0.998211, 'acc_word': 0.995328, 'loss_grapheme': 0.051189, 'loss_vowel': 0.032143, 'loss_consonant': 0.028348, 'loss_word': 0.034176}\n",
      "   28 | 0.000106 | 160000/160596 | 3.9334 | 5.0910 |||\n",
      "val: {'recall': 0.997839, 'recall_grapheme': 0.997329, 'recall_vowel': 0.998743, 'recall_consonant': 0.997956, 'recall_word': 0.99626, 'acc_grapheme': 0.99667, 'acc_vowel': 0.998633, 'acc_consonant': 0.998733, 'acc_word': 0.996372, 'loss_grapheme': 0.028072, 'loss_vowel': 0.016515, 'loss_consonant': 0.013927, 'loss_word': 0.020614}\n",
      "###>>>>> saved\n",
      "   29 | 0.000104 | 160000/160596 | 0.9400 | 5.3447 ||\n",
      "val: {'recall': 0.997343, 'recall_grapheme': 0.996654, 'recall_vowel': 0.998043, 'recall_consonant': 0.998023, 'recall_word': 0.996026, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998261, 'acc_consonant': 0.998658, 'acc_word': 0.996099, 'loss_grapheme': 0.041568, 'loss_vowel': 0.025263, 'loss_consonant': 0.023227, 'loss_word': 0.027231}\n",
      "   30 | 0.000101 | 160000/160596 | 6.1234 | 5.8374 ||\n",
      "val: {'recall': 0.996839, 'recall_grapheme': 0.995558, 'recall_vowel': 0.998438, 'recall_consonant': 0.997802, 'recall_word': 0.995728, 'acc_grapheme': 0.996223, 'acc_vowel': 0.998435, 'acc_consonant': 0.998435, 'acc_word': 0.995776, 'loss_grapheme': 0.052029, 'loss_vowel': 0.032217, 'loss_consonant': 0.026941, 'loss_word': 0.032492}\n",
      "   31 | 0.000098 | 160000/160596 | 13.1889 | 5.5596 |\n",
      "val: {'recall': 0.99712, 'recall_grapheme': 0.996048, 'recall_vowel': 0.998368, 'recall_consonant': 0.998017, 'recall_word': 0.9964, 'acc_grapheme': 0.996496, 'acc_vowel': 0.998633, 'acc_consonant': 0.998584, 'acc_word': 0.996472, 'loss_grapheme': 0.054744, 'loss_vowel': 0.035976, 'loss_consonant': 0.028561, 'loss_word': 0.035085}\n",
      "   32 | 0.000095 | 160000/160596 | 7.4119 | 5.3869 |||\n",
      "val: {'recall': 0.997264, 'recall_grapheme': 0.996367, 'recall_vowel': 0.998454, 'recall_consonant': 0.997868, 'recall_word': 0.99581, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998608, 'acc_consonant': 0.998484, 'acc_word': 0.995875, 'loss_grapheme': 0.034109, 'loss_vowel': 0.020145, 'loss_consonant': 0.018398, 'loss_word': 0.023765}\n",
      "   33 | 0.000093 | 160000/160596 | 1.1086 | 6.0362 |||\n",
      "val: {'recall': 0.996878, 'recall_grapheme': 0.996011, 'recall_vowel': 0.998264, 'recall_consonant': 0.997226, 'recall_word': 0.995854, 'acc_grapheme': 0.996148, 'acc_vowel': 0.998459, 'acc_consonant': 0.998385, 'acc_word': 0.995999, 'loss_grapheme': 0.048819, 'loss_vowel': 0.028938, 'loss_consonant': 0.026904, 'loss_word': 0.031027}\n",
      "   34 | 0.000090 | 160000/160596 | 3.0530 | 5.5594 ||\n",
      "val: {'recall': 0.99735, 'recall_grapheme': 0.996663, 'recall_vowel': 0.998352, 'recall_consonant': 0.997722, 'recall_word': 0.996252, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998509, 'acc_consonant': 0.99841, 'acc_word': 0.996347, 'loss_grapheme': 0.036969, 'loss_vowel': 0.025122, 'loss_consonant': 0.02085, 'loss_word': 0.026124}\n",
      "   35 | 0.000087 | 160000/160596 | 13.4643 | 5.7198 |\n",
      "val: {'recall': 0.997345, 'recall_grapheme': 0.996659, 'recall_vowel': 0.998138, 'recall_consonant': 0.997922, 'recall_word': 0.996189, 'acc_grapheme': 0.996422, 'acc_vowel': 0.998658, 'acc_consonant': 0.998559, 'acc_word': 0.996273, 'loss_grapheme': 0.041563, 'loss_vowel': 0.025417, 'loss_consonant': 0.023821, 'loss_word': 0.028716}\n",
      "   36 | 0.000084 | 160000/160596 | 6.1201 | 5.1217 ||\n",
      "val: {'recall': 0.997244, 'recall_grapheme': 0.996456, 'recall_vowel': 0.998092, 'recall_consonant': 0.99797, 'recall_word': 0.996011, 'acc_grapheme': 0.996372, 'acc_vowel': 0.998584, 'acc_consonant': 0.998435, 'acc_word': 0.996074, 'loss_grapheme': 0.089517, 'loss_vowel': 0.058493, 'loss_consonant': 0.047811, 'loss_word': 0.052921}\n",
      "   37 | 0.000081 | 160000/160596 | 3.9371 | 5.3212 |||\n",
      "val: {'recall': 0.997312, 'recall_grapheme': 0.996349, 'recall_vowel': 0.998818, 'recall_consonant': 0.997733, 'recall_word': 0.995882, 'acc_grapheme': 0.996248, 'acc_vowel': 0.998584, 'acc_consonant': 0.998261, 'acc_word': 0.995975, 'loss_grapheme': 0.057882, 'loss_vowel': 0.03608, 'loss_consonant': 0.030686, 'loss_word': 0.037304}\n",
      "   38 | 0.000078 | 160000/160596 | 5.8395 | 5.5486 ||\n",
      "val: {'recall': 0.997266, 'recall_grapheme': 0.996409, 'recall_vowel': 0.99842, 'recall_consonant': 0.997823, 'recall_word': 0.995935, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998534, 'acc_consonant': 0.998385, 'acc_word': 0.996049, 'loss_grapheme': 0.082012, 'loss_vowel': 0.049093, 'loss_consonant': 0.039763, 'loss_word': 0.052441}\n",
      "   39 | 0.000075 | 160000/160596 | 0.9347 | 5.2481 ||\n",
      "val: {'recall': 0.997268, 'recall_grapheme': 0.996184, 'recall_vowel': 0.998654, 'recall_consonant': 0.998051, 'recall_word': 0.996208, 'acc_grapheme': 0.996472, 'acc_vowel': 0.998708, 'acc_consonant': 0.998608, 'acc_word': 0.996298, 'loss_grapheme': 0.033526, 'loss_vowel': 0.020423, 'loss_consonant': 0.018617, 'loss_word': 0.023714}\n",
      "   40 | 0.000072 | 160000/160596 | 5.7085 | 5.7723 ||\n",
      "val: {'recall': 0.997104, 'recall_grapheme': 0.996123, 'recall_vowel': 0.998189, 'recall_consonant': 0.997981, 'recall_word': 0.996031, 'acc_grapheme': 0.996472, 'acc_vowel': 0.998435, 'acc_consonant': 0.998484, 'acc_word': 0.996148, 'loss_grapheme': 0.060851, 'loss_vowel': 0.037825, 'loss_consonant': 0.033664, 'loss_word': 0.039116}\n",
      "   41 | 0.000069 | 160000/160596 | 1.3473 | 5.5189 |||\n",
      "val: {'recall': 0.997522, 'recall_grapheme': 0.996917, 'recall_vowel': 0.998497, 'recall_consonant': 0.997756, 'recall_word': 0.996303, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998484, 'acc_consonant': 0.998435, 'acc_word': 0.996372, 'loss_grapheme': 0.040598, 'loss_vowel': 0.025298, 'loss_consonant': 0.020496, 'loss_word': 0.027678}\n",
      "   42 | 0.000066 | 160000/160596 | 6.9297 | 5.5504 ||\n",
      "val: {'recall': 0.997479, 'recall_grapheme': 0.996843, 'recall_vowel': 0.998588, 'recall_consonant': 0.997643, 'recall_word': 0.99559, 'acc_grapheme': 0.996124, 'acc_vowel': 0.998559, 'acc_consonant': 0.998435, 'acc_word': 0.995627, 'loss_grapheme': 0.058793, 'loss_vowel': 0.033409, 'loss_consonant': 0.028915, 'loss_word': 0.037506}\n",
      "   43 | 0.000063 | 160000/160596 | 6.5612 | 5.5218 ||\n",
      "val: {'recall': 0.997381, 'recall_grapheme': 0.99673, 'recall_vowel': 0.998096, 'recall_consonant': 0.99797, 'recall_word': 0.996526, 'acc_grapheme': 0.99672, 'acc_vowel': 0.998658, 'acc_consonant': 0.998559, 'acc_word': 0.996621, 'loss_grapheme': 0.029293, 'loss_vowel': 0.017726, 'loss_consonant': 0.016998, 'loss_word': 0.021313}\n",
      "   44 | 0.000060 | 160000/160596 | 6.0085 | 5.5149 |||\n",
      "val: {'recall': 0.997199, 'recall_grapheme': 0.996545, 'recall_vowel': 0.998285, 'recall_consonant': 0.997419, 'recall_word': 0.99544, 'acc_grapheme': 0.996024, 'acc_vowel': 0.998459, 'acc_consonant': 0.998211, 'acc_word': 0.995577, 'loss_grapheme': 0.058169, 'loss_vowel': 0.035772, 'loss_consonant': 0.02974, 'loss_word': 0.039078}\n",
      "   45 | 0.000058 | 160000/160596 | 0.9667 | 5.4939 |||\n",
      "val: {'recall': 0.997363, 'recall_grapheme': 0.996633, 'recall_vowel': 0.998077, 'recall_consonant': 0.99811, 'recall_word': 0.996367, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998584, 'acc_consonant': 0.998708, 'acc_word': 0.996496, 'loss_grapheme': 0.026462, 'loss_vowel': 0.017246, 'loss_consonant': 0.014701, 'loss_word': 0.020037}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 | 0.000055 | 160000/160596 | 14.4797 | 5.6864 |\n",
      "val: {'recall': 0.997355, 'recall_grapheme': 0.996427, 'recall_vowel': 0.998687, 'recall_consonant': 0.997881, 'recall_word': 0.996375, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998683, 'acc_consonant': 0.998534, 'acc_word': 0.996472, 'loss_grapheme': 0.0414, 'loss_vowel': 0.029941, 'loss_consonant': 0.023989, 'loss_word': 0.027685}\n",
      "   47 | 0.000052 | 160000/160596 | 3.1590 | 5.2538 ||\n",
      "val: {'recall': 0.997333, 'recall_grapheme': 0.996835, 'recall_vowel': 0.998199, 'recall_consonant': 0.997462, 'recall_word': 0.995172, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998435, 'acc_consonant': 0.998285, 'acc_word': 0.995279, 'loss_grapheme': 0.063717, 'loss_vowel': 0.038872, 'loss_consonant': 0.032387, 'loss_word': 0.041782}\n",
      "   48 | 0.000049 | 160000/160596 | 4.0468 | 5.2289 ||\n",
      "val: {'recall': 0.997233, 'recall_grapheme': 0.996417, 'recall_vowel': 0.998308, 'recall_consonant': 0.99779, 'recall_word': 0.996084, 'acc_grapheme': 0.996496, 'acc_vowel': 0.998559, 'acc_consonant': 0.998509, 'acc_word': 0.996148, 'loss_grapheme': 0.043381, 'loss_vowel': 0.027096, 'loss_consonant': 0.02135, 'loss_word': 0.029477}\n",
      "   49 | 0.000046 | 160000/160596 | 5.6945 | 5.3422 ||\n",
      "val: {'recall': 0.997412, 'recall_grapheme': 0.996684, 'recall_vowel': 0.998374, 'recall_consonant': 0.997907, 'recall_word': 0.996111, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998534, 'acc_consonant': 0.998559, 'acc_word': 0.996173, 'loss_grapheme': 0.037314, 'loss_vowel': 0.023657, 'loss_consonant': 0.020097, 'loss_word': 0.02545}\n",
      "   50 | 0.000044 | 160000/160596 | 5.5831 | 5.4478 ||\n",
      "val: {'recall': 0.996789, 'recall_grapheme': 0.995883, 'recall_vowel': 0.998084, 'recall_consonant': 0.997304, 'recall_word': 0.995326, 'acc_grapheme': 0.995825, 'acc_vowel': 0.998335, 'acc_consonant': 0.998385, 'acc_word': 0.995378, 'loss_grapheme': 0.074954, 'loss_vowel': 0.04334, 'loss_consonant': 0.03868, 'loss_word': 0.049493}\n",
      "   51 | 0.000041 | 160000/160596 | 5.0020 | 5.7014 ||\n",
      "val: {'recall': 0.997178, 'recall_grapheme': 0.996157, 'recall_vowel': 0.99839, 'recall_consonant': 0.998007, 'recall_word': 0.996125, 'acc_grapheme': 0.996322, 'acc_vowel': 0.998608, 'acc_consonant': 0.998658, 'acc_word': 0.996198, 'loss_grapheme': 0.072631, 'loss_vowel': 0.042256, 'loss_consonant': 0.037064, 'loss_word': 0.044112}\n",
      "   52 | 0.000038 | 160000/160596 | 11.3652 | 5.1136 ||\n",
      "val: {'recall': 0.997378, 'recall_grapheme': 0.996652, 'recall_vowel': 0.998338, 'recall_consonant': 0.997871, 'recall_word': 0.996245, 'acc_grapheme': 0.996496, 'acc_vowel': 0.998658, 'acc_consonant': 0.998534, 'acc_word': 0.996322, 'loss_grapheme': 0.040594, 'loss_vowel': 0.026418, 'loss_consonant': 0.022308, 'loss_word': 0.026691}\n",
      "   53 | 0.000036 | 160000/160596 | 10.9606 | 5.3770 |\n",
      "val: {'recall': 0.997547, 'recall_grapheme': 0.996851, 'recall_vowel': 0.998443, 'recall_consonant': 0.998046, 'recall_word': 0.996588, 'acc_grapheme': 0.99677, 'acc_vowel': 0.998832, 'acc_consonant': 0.998708, 'acc_word': 0.99667, 'loss_grapheme': 0.052604, 'loss_vowel': 0.034724, 'loss_consonant': 0.02918, 'loss_word': 0.031794}\n",
      "   54 | 0.000033 | 160000/160596 | 7.8508 | 5.5952 ||\n",
      "val: {'recall': 0.997366, 'recall_grapheme': 0.996664, 'recall_vowel': 0.998314, 'recall_consonant': 0.997821, 'recall_word': 0.996154, 'acc_grapheme': 0.99667, 'acc_vowel': 0.998584, 'acc_consonant': 0.998534, 'acc_word': 0.996248, 'loss_grapheme': 0.040445, 'loss_vowel': 0.027323, 'loss_consonant': 0.02305, 'loss_word': 0.026809}\n",
      "   55 | 0.000031 | 160000/160596 | 6.8233 | 5.5964 |||\n",
      "val: {'recall': 0.997453, 'recall_grapheme': 0.9967, 'recall_vowel': 0.998403, 'recall_consonant': 0.99801, 'recall_word': 0.996593, 'acc_grapheme': 0.996968, 'acc_vowel': 0.998633, 'acc_consonant': 0.998658, 'acc_word': 0.99672, 'loss_grapheme': 0.042441, 'loss_vowel': 0.030035, 'loss_consonant': 0.024939, 'loss_word': 0.027263}\n",
      "   56 | 0.000029 | 160000/160596 | 7.7228 | 5.1931 ||\n",
      "val: {'recall': 0.99727, 'recall_grapheme': 0.99638, 'recall_vowel': 0.998396, 'recall_consonant': 0.997924, 'recall_word': 0.996581, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998633, 'acc_consonant': 0.998608, 'acc_word': 0.99667, 'loss_grapheme': 0.039752, 'loss_vowel': 0.026258, 'loss_consonant': 0.021448, 'loss_word': 0.02703}\n",
      "   57 | 0.000026 | 160000/160596 | 0.7926 | 5.3769 ||\n",
      "val: {'recall': 0.997389, 'recall_grapheme': 0.99654, 'recall_vowel': 0.998442, 'recall_consonant': 0.998035, 'recall_word': 0.996529, 'acc_grapheme': 0.99672, 'acc_vowel': 0.998708, 'acc_consonant': 0.998683, 'acc_word': 0.996645, 'loss_grapheme': 0.031658, 'loss_vowel': 0.021499, 'loss_consonant': 0.019156, 'loss_word': 0.020664}\n",
      "   58 | 0.000024 | 160000/160596 | 4.6870 | 5.6703 |||\n",
      "val: {'recall': 0.997426, 'recall_grapheme': 0.996679, 'recall_vowel': 0.998512, 'recall_consonant': 0.997832, 'recall_word': 0.996365, 'acc_grapheme': 0.99677, 'acc_vowel': 0.998658, 'acc_consonant': 0.998484, 'acc_word': 0.996496, 'loss_grapheme': 0.025536, 'loss_vowel': 0.015237, 'loss_consonant': 0.013485, 'loss_word': 0.019353}\n",
      "   59 | 0.000022 | 160000/160596 | 7.3572 | 5.4609 ||\n",
      "val: {'recall': 0.997222, 'recall_grapheme': 0.996347, 'recall_vowel': 0.998305, 'recall_consonant': 0.997891, 'recall_word': 0.996165, 'acc_grapheme': 0.996571, 'acc_vowel': 0.998608, 'acc_consonant': 0.998484, 'acc_word': 0.996298, 'loss_grapheme': 0.035586, 'loss_vowel': 0.024369, 'loss_consonant': 0.020913, 'loss_word': 0.024011}\n",
      "   60 | 0.000020 | 160000/160596 | 15.0110 | 5.7723 ||\n",
      "val: {'recall': 0.996929, 'recall_grapheme': 0.995828, 'recall_vowel': 0.998238, 'recall_consonant': 0.997822, 'recall_word': 0.995901, 'acc_grapheme': 0.996148, 'acc_vowel': 0.998633, 'acc_consonant': 0.998435, 'acc_word': 0.996049, 'loss_grapheme': 0.069015, 'loss_vowel': 0.042816, 'loss_consonant': 0.035738, 'loss_word': 0.04363}\n",
      "   61 | 0.000018 | 160000/160596 | 14.8699 | 5.5004 |\n",
      "val: {'recall': 0.997497, 'recall_grapheme': 0.996799, 'recall_vowel': 0.99852, 'recall_consonant': 0.99787, 'recall_word': 0.996533, 'acc_grapheme': 0.996844, 'acc_vowel': 0.998608, 'acc_consonant': 0.998534, 'acc_word': 0.996645, 'loss_grapheme': 0.030819, 'loss_vowel': 0.02035, 'loss_consonant': 0.017853, 'loss_word': 0.021616}\n",
      "   62 | 0.000016 | 160000/160596 | 2.0743 | 5.4134 ||\n",
      "val: {'recall': 0.997418, 'recall_grapheme': 0.996724, 'recall_vowel': 0.998346, 'recall_consonant': 0.997876, 'recall_word': 0.996401, 'acc_grapheme': 0.996993, 'acc_vowel': 0.998608, 'acc_consonant': 0.998509, 'acc_word': 0.996521, 'loss_grapheme': 0.027683, 'loss_vowel': 0.017416, 'loss_consonant': 0.015375, 'loss_word': 0.02064}\n",
      "   63 | 0.000014 | 160000/160596 | 1.0680 | 5.1857 ||\n",
      "val: {'recall': 0.99756, 'recall_grapheme': 0.996904, 'recall_vowel': 0.998484, 'recall_consonant': 0.99795, 'recall_word': 0.996754, 'acc_grapheme': 0.997093, 'acc_vowel': 0.998807, 'acc_consonant': 0.998633, 'acc_word': 0.996844, 'loss_grapheme': 0.033895, 'loss_vowel': 0.025681, 'loss_consonant': 0.020172, 'loss_word': 0.022755}\n",
      "   64 | 0.000013 | 160000/160596 | 2.7359 | 5.6143 ||\n",
      "val: {'recall': 0.997296, 'recall_grapheme': 0.996542, 'recall_vowel': 0.998347, 'recall_consonant': 0.997753, 'recall_word': 0.996252, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998608, 'acc_consonant': 0.998484, 'acc_word': 0.996372, 'loss_grapheme': 0.047301, 'loss_vowel': 0.030097, 'loss_consonant': 0.024997, 'loss_word': 0.030352}\n",
      "   65 | 0.000011 | 160000/160596 | 15.2533 | 5.4637 |\n",
      "val: {'recall': 0.997096, 'recall_grapheme': 0.996237, 'recall_vowel': 0.998178, 'recall_consonant': 0.997733, 'recall_word': 0.995983, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998534, 'acc_consonant': 0.99841, 'acc_word': 0.996074, 'loss_grapheme': 0.070801, 'loss_vowel': 0.04344, 'loss_consonant': 0.036324, 'loss_word': 0.044322}\n",
      "   66 | 0.000010 | 160000/160596 | 6.3259 | 5.2390 ||\n",
      "val: {'recall': 0.996927, 'recall_grapheme': 0.996026, 'recall_vowel': 0.998074, 'recall_consonant': 0.997583, 'recall_word': 0.995767, 'acc_grapheme': 0.996198, 'acc_vowel': 0.998385, 'acc_consonant': 0.99831, 'acc_word': 0.9959, 'loss_grapheme': 0.070232, 'loss_vowel': 0.042415, 'loss_consonant': 0.036388, 'loss_word': 0.042933}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 0.000008 | 160000/160596 | 0.7282 | 5.1206 ||\n",
      "val: {'recall': 0.997645, 'recall_grapheme': 0.997038, 'recall_vowel': 0.998539, 'recall_consonant': 0.997963, 'recall_word': 0.996738, 'acc_grapheme': 0.997118, 'acc_vowel': 0.998733, 'acc_consonant': 0.998683, 'acc_word': 0.996819, 'loss_grapheme': 0.020915, 'loss_vowel': 0.013994, 'loss_consonant': 0.012406, 'loss_word': 0.016366}\n",
      "   68 | 0.000007 | 160000/160596 | 13.0432 | 4.9529 |\n",
      "val: {'recall': 0.997561, 'recall_grapheme': 0.996933, 'recall_vowel': 0.998461, 'recall_consonant': 0.997918, 'recall_word': 0.996649, 'acc_grapheme': 0.996968, 'acc_vowel': 0.998733, 'acc_consonant': 0.998608, 'acc_word': 0.996745, 'loss_grapheme': 0.050717, 'loss_vowel': 0.034988, 'loss_consonant': 0.028759, 'loss_word': 0.029343}\n",
      "   69 | 0.000006 | 160000/160596 | 5.7878 | 5.8231 ||\n",
      "val: {'recall': 0.997109, 'recall_grapheme': 0.996105, 'recall_vowel': 0.998275, 'recall_consonant': 0.997949, 'recall_word': 0.996195, 'acc_grapheme': 0.996571, 'acc_vowel': 0.998559, 'acc_consonant': 0.998534, 'acc_word': 0.996298, 'loss_grapheme': 0.045128, 'loss_vowel': 0.029381, 'loss_consonant': 0.025134, 'loss_word': 0.029127}\n",
      "   70 | 0.000005 | 160000/160596 | 0.9044 | 4.9886 ||\n",
      "val: {'recall': 0.997507, 'recall_grapheme': 0.996786, 'recall_vowel': 0.998567, 'recall_consonant': 0.997887, 'recall_word': 0.996455, 'acc_grapheme': 0.996844, 'acc_vowel': 0.998683, 'acc_consonant': 0.998484, 'acc_word': 0.996571, 'loss_grapheme': 0.020587, 'loss_vowel': 0.012609, 'loss_consonant': 0.011373, 'loss_word': 0.017128}\n",
      "   71 | 0.000004 | 160000/160596 | 6.2375 | 5.2074 ||\n",
      "val: {'recall': 0.997309, 'recall_grapheme': 0.996511, 'recall_vowel': 0.998375, 'recall_consonant': 0.997837, 'recall_word': 0.996212, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998633, 'acc_consonant': 0.998509, 'acc_word': 0.996322, 'loss_grapheme': 0.051006, 'loss_vowel': 0.034289, 'loss_consonant': 0.027069, 'loss_word': 0.032877}\n",
      "   72 | 0.000003 | 160000/160596 | 0.8013 | 5.5700 |||\n",
      "val: {'recall': 0.99743, 'recall_grapheme': 0.99664, 'recall_vowel': 0.998508, 'recall_consonant': 0.997931, 'recall_word': 0.996476, 'acc_grapheme': 0.996844, 'acc_vowel': 0.998708, 'acc_consonant': 0.998559, 'acc_word': 0.996596, 'loss_grapheme': 0.035955, 'loss_vowel': 0.024403, 'loss_consonant': 0.02085, 'loss_word': 0.024309}\n",
      "   73 | 0.000002 | 160000/160596 | 6.8543 | 5.1123 ||\n",
      "val: {'recall': 0.997341, 'recall_grapheme': 0.996613, 'recall_vowel': 0.99833, 'recall_consonant': 0.99781, 'recall_word': 0.996231, 'acc_grapheme': 0.996645, 'acc_vowel': 0.998608, 'acc_consonant': 0.998509, 'acc_word': 0.996322, 'loss_grapheme': 0.041788, 'loss_vowel': 0.028578, 'loss_consonant': 0.024212, 'loss_word': 0.027309}\n",
      "   74 | 0.000001 | 160000/160596 | 5.2971 | 5.1507 ||\n",
      "val: {'recall': 0.997625, 'recall_grapheme': 0.997005, 'recall_vowel': 0.998535, 'recall_consonant': 0.997955, 'recall_word': 0.996606, 'acc_grapheme': 0.996944, 'acc_vowel': 0.998758, 'acc_consonant': 0.998633, 'acc_word': 0.99672, 'loss_grapheme': 0.040318, 'loss_vowel': 0.027241, 'loss_consonant': 0.021785, 'loss_word': 0.027233}\n",
      "   75 | 0.000001 | 160000/160596 | 4.0310 | 5.6627 ||\n",
      "val: {'recall': 0.997259, 'recall_grapheme': 0.996498, 'recall_vowel': 0.998316, 'recall_consonant': 0.997723, 'recall_word': 0.996032, 'acc_grapheme': 0.996521, 'acc_vowel': 0.998534, 'acc_consonant': 0.998459, 'acc_word': 0.996148, 'loss_grapheme': 0.081079, 'loss_vowel': 0.050252, 'loss_consonant': 0.036797, 'loss_word': 0.053251}\n",
      "   76 | 0.000001 | 160000/160596 | 0.7194 | 5.3941 ||\n",
      "val: {'recall': 0.997557, 'recall_grapheme': 0.996935, 'recall_vowel': 0.998544, 'recall_consonant': 0.997816, 'recall_word': 0.996536, 'acc_grapheme': 0.996944, 'acc_vowel': 0.998708, 'acc_consonant': 0.998509, 'acc_word': 0.996645, 'loss_grapheme': 0.031368, 'loss_vowel': 0.020688, 'loss_consonant': 0.017624, 'loss_word': 0.021435}\n",
      "   77 | 0.000000 | 160000/160596 | 0.9030 | 5.5643 ||\n",
      "val: {'recall': 0.99766, 'recall_grapheme': 0.997037, 'recall_vowel': 0.998575, 'recall_consonant': 0.99799, 'recall_word': 0.996636, 'acc_grapheme': 0.997093, 'acc_vowel': 0.998758, 'acc_consonant': 0.998683, 'acc_word': 0.99677, 'loss_grapheme': 0.034027, 'loss_vowel': 0.023393, 'loss_consonant': 0.018914, 'loss_word': 0.024314}\n",
      "   78 | 0.000000 | 160000/160596 | 0.8848 | 5.4686 ||\n",
      "val: {'recall': 0.997769, 'recall_grapheme': 0.997128, 'recall_vowel': 0.9987, 'recall_consonant': 0.998119, 'recall_word': 0.996802, 'acc_grapheme': 0.997167, 'acc_vowel': 0.998807, 'acc_consonant': 0.998782, 'acc_word': 0.996919, 'loss_grapheme': 0.018249, 'loss_vowel': 0.011523, 'loss_consonant': 0.010387, 'loss_word': 0.014981}\n",
      "   79 | 0.000000 | 160000/160596 | 6.9165 | 5.6825 ||\n",
      "val: {'recall': 0.997556, 'recall_grapheme': 0.996875, 'recall_vowel': 0.998553, 'recall_consonant': 0.997921, 'recall_word': 0.996812, 'acc_grapheme': 0.997093, 'acc_vowel': 0.998807, 'acc_consonant': 0.998633, 'acc_word': 0.996919, 'loss_grapheme': 0.027374, 'loss_vowel': 0.018521, 'loss_consonant': 0.016583, 'loss_word': 0.019262}\n",
      "CYCLE: 3\n",
      "{'recall': 0.997556, 'recall_grapheme': 0.996875, 'recall_vowel': 0.998553, 'recall_consonant': 0.997921, 'recall_word': 0.996812, 'acc_grapheme': 0.997093, 'acc_vowel': 0.998807, 'acc_consonant': 0.998633, 'acc_word': 0.996919, 'loss_grapheme': 0.027374, 'loss_vowel': 0.018521, 'loss_consonant': 0.016583, 'loss_word': 0.019262}\n",
      "    0 | 0.000030 | 160000/160596 | 8.0140 | 6.2544 ||\n",
      "val: {'recall': 0.997634, 'recall_grapheme': 0.997009, 'recall_vowel': 0.99849, 'recall_consonant': 0.998028, 'recall_word': 0.996716, 'acc_grapheme': 0.997068, 'acc_vowel': 0.998758, 'acc_consonant': 0.998733, 'acc_word': 0.996819, 'loss_grapheme': 0.050204, 'loss_vowel': 0.034498, 'loss_consonant': 0.027819, 'loss_word': 0.031068}\n",
      "    1 | 0.000060 | 160000/160596 | 0.4681 | 5.5171 ||\n",
      "val: {'recall': 0.997302, 'recall_grapheme': 0.996996, 'recall_vowel': 0.998663, 'recall_consonant': 0.996552, 'recall_word': 0.996241, 'acc_grapheme': 0.996869, 'acc_vowel': 0.998708, 'acc_consonant': 0.99841, 'acc_word': 0.996372, 'loss_grapheme': 0.035871, 'loss_vowel': 0.023195, 'loss_consonant': 0.019205, 'loss_word': 0.025411}\n",
      "    2 | 0.000090 | 160000/160596 | 5.5066 | 4.9965 ||\n",
      "val: {'recall': 0.996995, 'recall_grapheme': 0.995941, 'recall_vowel': 0.998341, 'recall_consonant': 0.997759, 'recall_word': 0.995693, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998435, 'acc_consonant': 0.998385, 'acc_word': 0.995776, 'loss_grapheme': 0.064113, 'loss_vowel': 0.037362, 'loss_consonant': 0.033458, 'loss_word': 0.040339}\n",
      "    3 | 0.000119 | 160000/160596 | 0.5487 | 5.3026 ||\n",
      "val: {'recall': 0.997285, 'recall_grapheme': 0.996339, 'recall_vowel': 0.998771, 'recall_consonant': 0.99769, 'recall_word': 0.995917, 'acc_grapheme': 0.996347, 'acc_vowel': 0.998584, 'acc_consonant': 0.998459, 'acc_word': 0.995999, 'loss_grapheme': 0.042137, 'loss_vowel': 0.027343, 'loss_consonant': 0.022085, 'loss_word': 0.028917}\n",
      "    4 | 0.000148 | 160000/160596 | 10.4912 | 5.0635 ||\n",
      "val: {'recall': 0.996768, 'recall_grapheme': 0.995496, 'recall_vowel': 0.998187, 'recall_consonant': 0.997893, 'recall_word': 0.995554, 'acc_grapheme': 0.99585, 'acc_vowel': 0.99841, 'acc_consonant': 0.998509, 'acc_word': 0.995652, 'loss_grapheme': 0.057231, 'loss_vowel': 0.035982, 'loss_consonant': 0.027908, 'loss_word': 0.037643}\n",
      "    5 | 0.000148 | 160000/160596 | 0.6257 | 6.2036 ||\n",
      "val: {'recall': 0.996982, 'recall_grapheme': 0.995719, 'recall_vowel': 0.998407, 'recall_consonant': 0.998082, 'recall_word': 0.995704, 'acc_grapheme': 0.996248, 'acc_vowel': 0.998559, 'acc_consonant': 0.998534, 'acc_word': 0.995801, 'loss_grapheme': 0.050023, 'loss_vowel': 0.030805, 'loss_consonant': 0.026682, 'loss_word': 0.034786}\n",
      "    6 | 0.000147 | 160000/160596 | 2.9768 | 5.5178 ||\n",
      "val: {'recall': 0.996184, 'recall_grapheme': 0.994967, 'recall_vowel': 0.99781, 'recall_consonant': 0.996991, 'recall_word': 0.994522, 'acc_grapheme': 0.995055, 'acc_vowel': 0.998012, 'acc_consonant': 0.998037, 'acc_word': 0.994558, 'loss_grapheme': 0.065398, 'loss_vowel': 0.042663, 'loss_consonant': 0.03464, 'loss_word': 0.046344}\n",
      "    7 | 0.000146 | 160000/160596 | 0.8679 | 5.4291 ||\n",
      "val: {'recall': 0.997037, 'recall_grapheme': 0.995971, 'recall_vowel': 0.998108, 'recall_consonant': 0.9981, 'recall_word': 0.99579, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998385, 'acc_consonant': 0.998435, 'acc_word': 0.9959, 'loss_grapheme': 0.049552, 'loss_vowel': 0.030358, 'loss_consonant': 0.030135, 'loss_word': 0.033545}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 | 0.000145 | 160000/160596 | 3.5107 | 5.5183 |||\n",
      "val: {'recall': 0.996481, 'recall_grapheme': 0.99518, 'recall_vowel': 0.99771, 'recall_consonant': 0.997855, 'recall_word': 0.994826, 'acc_grapheme': 0.995676, 'acc_vowel': 0.998012, 'acc_consonant': 0.998161, 'acc_word': 0.994906, 'loss_grapheme': 0.032154, 'loss_vowel': 0.0196, 'loss_consonant': 0.016373, 'loss_word': 0.026567}\n",
      "    9 | 0.000144 | 160000/160596 | 0.8367 | 5.2435 ||\n",
      "val: {'recall': 0.997185, 'recall_grapheme': 0.996385, 'recall_vowel': 0.998137, 'recall_consonant': 0.997831, 'recall_word': 0.995435, 'acc_grapheme': 0.995975, 'acc_vowel': 0.998385, 'acc_consonant': 0.998335, 'acc_word': 0.995527, 'loss_grapheme': 0.027364, 'loss_vowel': 0.015229, 'loss_consonant': 0.01566, 'loss_word': 0.022573}\n",
      "   10 | 0.000143 | 160000/160596 | 6.3547 | 5.3057 ||\n",
      "val: {'recall': 0.996551, 'recall_grapheme': 0.995442, 'recall_vowel': 0.99835, 'recall_consonant': 0.996972, 'recall_word': 0.994711, 'acc_grapheme': 0.995378, 'acc_vowel': 0.998261, 'acc_consonant': 0.998161, 'acc_word': 0.994782, 'loss_grapheme': 0.060432, 'loss_vowel': 0.036952, 'loss_consonant': 0.029554, 'loss_word': 0.041784}\n",
      "   11 | 0.000142 | 098560/160596 | 1.1058 | 5.4132 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-6df1386d1bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-e61e0cb30f7d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cycles\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CYCLE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#args.base_lr = 4e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#args.num_epochs = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-e61e0cb30f7d>\u001b[0m in \u001b[0;36mtrain_cycle\u001b[0;34m(args, model, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYCLE: 1\n",
      "{'recall': 0.997498, 'recall_grapheme': 0.996893, 'recall_vowel': 0.99822, 'recall_consonant': 0.997987, 'recall_word': 0.996026, 'acc_grapheme': 0.996372, 'acc_vowel': 0.998633, 'acc_consonant': 0.998534, 'acc_word': 0.996099, 'loss_grapheme': 0.132114, 'loss_vowel': 0.083359, 'loss_consonant': 0.058515, 'loss_word': 0.084024}\n",
      "    0 | 0.000030 | 160000/160596 | 12.7884 | 6.0407 ||\n",
      "val: {'recall': 0.997627, 'recall_grapheme': 0.997045, 'recall_vowel': 0.998395, 'recall_consonant': 0.998022, 'recall_word': 0.996112, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998658, 'acc_consonant': 0.998584, 'acc_word': 0.996223, 'loss_grapheme': 0.076319, 'loss_vowel': 0.051092, 'loss_consonant': 0.037538, 'loss_word': 0.048984}\n",
      "###>>>>> saved\n",
      "    1 | 0.000060 | 160000/160596 | 15.8839 | 6.5456 |\n",
      "val: {'recall': 0.997121, 'recall_grapheme': 0.996174, 'recall_vowel': 0.998147, 'recall_consonant': 0.997988, 'recall_word': 0.995936, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998484, 'acc_consonant': 0.998584, 'acc_word': 0.995975, 'loss_grapheme': 0.055421, 'loss_vowel': 0.037714, 'loss_consonant': 0.029248, 'loss_word': 0.036254}\n",
      "    2 | 0.000090 | 160000/160596 | 6.9213 | 6.1571 ||\n",
      "val: {'recall': 0.99723, 'recall_grapheme': 0.996374, 'recall_vowel': 0.998307, 'recall_consonant': 0.997864, 'recall_word': 0.995449, 'acc_grapheme': 0.996148, 'acc_vowel': 0.998484, 'acc_consonant': 0.99841, 'acc_word': 0.995577, 'loss_grapheme': 0.053739, 'loss_vowel': 0.032553, 'loss_consonant': 0.026241, 'loss_word': 0.037696}\n",
      "    3 | 0.000119 | 160000/160596 | 3.7351 | 5.9264 ||\n",
      "val: {'recall': 0.996825, 'recall_grapheme': 0.99569, 'recall_vowel': 0.998223, 'recall_consonant': 0.997697, 'recall_word': 0.99533, 'acc_grapheme': 0.9959, 'acc_vowel': 0.998385, 'acc_consonant': 0.998285, 'acc_word': 0.995403, 'loss_grapheme': 0.059262, 'loss_vowel': 0.038595, 'loss_consonant': 0.030545, 'loss_word': 0.039024}\n",
      "    4 | 0.000148 | 160000/160596 | 11.5614 | 6.5178 ||\n",
      "val: {'recall': 0.996855, 'recall_grapheme': 0.996022, 'recall_vowel': 0.997905, 'recall_consonant': 0.997472, 'recall_word': 0.994984, 'acc_grapheme': 0.995577, 'acc_vowel': 0.998136, 'acc_consonant': 0.998112, 'acc_word': 0.99508, 'loss_grapheme': 0.049797, 'loss_vowel': 0.029084, 'loss_consonant': 0.0251, 'loss_word': 0.033384}\n",
      "    5 | 0.000148 | 160000/160596 | 14.7111 | 6.8549 ||\n",
      "val: {'recall': 0.996698, 'recall_grapheme': 0.995604, 'recall_vowel': 0.997739, 'recall_consonant': 0.997843, 'recall_word': 0.994803, 'acc_grapheme': 0.995229, 'acc_vowel': 0.998261, 'acc_consonant': 0.998037, 'acc_word': 0.994906, 'loss_grapheme': 0.070013, 'loss_vowel': 0.043086, 'loss_consonant': 0.034356, 'loss_word': 0.047199}\n",
      "    6 | 0.000147 | 160000/160596 | 16.1724 | 5.9343 |\n",
      "val: {'recall': 0.996192, 'recall_grapheme': 0.995027, 'recall_vowel': 0.997632, 'recall_consonant': 0.997082, 'recall_word': 0.994578, 'acc_grapheme': 0.995353, 'acc_vowel': 0.997987, 'acc_consonant': 0.997913, 'acc_word': 0.994682, 'loss_grapheme': 0.033544, 'loss_vowel': 0.020248, 'loss_consonant': 0.016733, 'loss_word': 0.028867}\n",
      "    7 | 0.000146 | 160000/160596 | 12.0942 | 6.6783 |\n",
      "val: {'recall': 0.996853, 'recall_grapheme': 0.996192, 'recall_vowel': 0.997617, 'recall_consonant': 0.997412, 'recall_word': 0.995351, 'acc_grapheme': 0.996024, 'acc_vowel': 0.998236, 'acc_consonant': 0.998435, 'acc_word': 0.995453, 'loss_grapheme': 0.041746, 'loss_vowel': 0.027827, 'loss_consonant': 0.021225, 'loss_word': 0.029589}\n",
      "    8 | 0.000145 | 160000/160596 | 13.2319 | 6.3870 |\n",
      "val: {'recall': 0.996946, 'recall_grapheme': 0.996028, 'recall_vowel': 0.997798, 'recall_consonant': 0.997931, 'recall_word': 0.995573, 'acc_grapheme': 0.995925, 'acc_vowel': 0.998136, 'acc_consonant': 0.99831, 'acc_word': 0.995676, 'loss_grapheme': 0.079223, 'loss_vowel': 0.049721, 'loss_consonant': 0.037521, 'loss_word': 0.046704}\n",
      "    9 | 0.000144 | 160000/160596 | 1.5425 | 6.9897 ||\n",
      "val: {'recall': 0.996936, 'recall_grapheme': 0.996098, 'recall_vowel': 0.997941, 'recall_consonant': 0.997608, 'recall_word': 0.995094, 'acc_grapheme': 0.995801, 'acc_vowel': 0.998385, 'acc_consonant': 0.998236, 'acc_word': 0.995179, 'loss_grapheme': 0.032933, 'loss_vowel': 0.018629, 'loss_consonant': 0.015827, 'loss_word': 0.02723}\n",
      "   10 | 0.000143 | 160000/160596 | 8.3522 | 7.0370 ||\n",
      "val: {'recall': 0.99627, 'recall_grapheme': 0.995164, 'recall_vowel': 0.997466, 'recall_consonant': 0.997287, 'recall_word': 0.995051, 'acc_grapheme': 0.995453, 'acc_vowel': 0.997987, 'acc_consonant': 0.998236, 'acc_word': 0.995105, 'loss_grapheme': 0.115464, 'loss_vowel': 0.073656, 'loss_consonant': 0.054673, 'loss_word': 0.071387}\n",
      "   11 | 0.000142 | 160000/160596 | 1.5096 | 6.8650 |||\n",
      "val: {'recall': 0.997024, 'recall_grapheme': 0.996077, 'recall_vowel': 0.998072, 'recall_consonant': 0.997868, 'recall_word': 0.996007, 'acc_grapheme': 0.996347, 'acc_vowel': 0.998285, 'acc_consonant': 0.998559, 'acc_word': 0.996024, 'loss_grapheme': 0.04073, 'loss_vowel': 0.025544, 'loss_consonant': 0.020274, 'loss_word': 0.029196}\n",
      "   12 | 0.000140 | 160000/160596 | 1.6003 | 7.1267 ||\n",
      "val: {'recall': 0.996797, 'recall_grapheme': 0.995748, 'recall_vowel': 0.998405, 'recall_consonant': 0.997286, 'recall_word': 0.995656, 'acc_grapheme': 0.995801, 'acc_vowel': 0.998484, 'acc_consonant': 0.99831, 'acc_word': 0.995676, 'loss_grapheme': 0.051318, 'loss_vowel': 0.030642, 'loss_consonant': 0.026392, 'loss_word': 0.03377}\n",
      "   13 | 0.000139 | 160000/160596 | 2.9958 | 7.1390 ||\n",
      "val: {'recall': 0.997169, 'recall_grapheme': 0.996615, 'recall_vowel': 0.998487, 'recall_consonant': 0.996957, 'recall_word': 0.99627, 'acc_grapheme': 0.996645, 'acc_vowel': 0.998633, 'acc_consonant': 0.998335, 'acc_word': 0.996273, 'loss_grapheme': 0.049856, 'loss_vowel': 0.035532, 'loss_consonant': 0.025597, 'loss_word': 0.032169}\n",
      "   14 | 0.000137 | 160000/160596 | 2.8384 | 6.3868 ||\n",
      "val: {'recall': 0.997147, 'recall_grapheme': 0.996394, 'recall_vowel': 0.998194, 'recall_consonant': 0.997609, 'recall_word': 0.995637, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998509, 'acc_consonant': 0.99831, 'acc_word': 0.995726, 'loss_grapheme': 0.055187, 'loss_vowel': 0.031562, 'loss_consonant': 0.026007, 'loss_word': 0.036661}\n",
      "   15 | 0.000136 | 160000/160596 | 4.7805 | 7.4071 ||\n",
      "val: {'recall': 0.997386, 'recall_grapheme': 0.996799, 'recall_vowel': 0.998068, 'recall_consonant': 0.997877, 'recall_word': 0.996089, 'acc_grapheme': 0.996496, 'acc_vowel': 0.998484, 'acc_consonant': 0.998484, 'acc_word': 0.996124, 'loss_grapheme': 0.050742, 'loss_vowel': 0.036348, 'loss_consonant': 0.026294, 'loss_word': 0.034331}\n",
      "   16 | 0.000134 | 160000/160596 | 15.5304 | 6.1805 ||\n",
      "val: {'recall': 0.996829, 'recall_grapheme': 0.995637, 'recall_vowel': 0.997887, 'recall_consonant': 0.998153, 'recall_word': 0.995549, 'acc_grapheme': 0.9959, 'acc_vowel': 0.99831, 'acc_consonant': 0.998435, 'acc_word': 0.995602, 'loss_grapheme': 0.048469, 'loss_vowel': 0.034441, 'loss_consonant': 0.027546, 'loss_word': 0.031208}\n",
      "   17 | 0.000132 | 160000/160596 | 5.6183 | 6.8512 |||\n",
      "val: {'recall': 0.996928, 'recall_grapheme': 0.996127, 'recall_vowel': 0.998106, 'recall_consonant': 0.997353, 'recall_word': 0.995358, 'acc_grapheme': 0.995801, 'acc_vowel': 0.998385, 'acc_consonant': 0.998335, 'acc_word': 0.995502, 'loss_grapheme': 0.086968, 'loss_vowel': 0.058546, 'loss_consonant': 0.042799, 'loss_word': 0.051701}\n",
      "   18 | 0.000130 | 160000/160596 | 13.2873 | 6.9615 |\n",
      "val: {'recall': 0.996954, 'recall_grapheme': 0.996347, 'recall_vowel': 0.997732, 'recall_consonant': 0.997389, 'recall_word': 0.995497, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998335, 'acc_consonant': 0.998385, 'acc_word': 0.995527, 'loss_grapheme': 0.073872, 'loss_vowel': 0.045873, 'loss_consonant': 0.035913, 'loss_word': 0.04513}\n",
      "   19 | 0.000128 | 160000/160596 | 7.4148 | 6.6079 |||\n",
      "val: {'recall': 0.996404, 'recall_grapheme': 0.995284, 'recall_vowel': 0.997533, 'recall_consonant': 0.997514, 'recall_word': 0.994675, 'acc_grapheme': 0.995328, 'acc_vowel': 0.997987, 'acc_consonant': 0.997913, 'acc_word': 0.994707, 'loss_grapheme': 0.088662, 'loss_vowel': 0.057144, 'loss_consonant': 0.04645, 'loss_word': 0.056197}\n",
      "   20 | 0.000126 | 160000/160596 | 9.0057 | 6.3514 ||\n",
      "val: {'recall': 0.996796, 'recall_grapheme': 0.995947, 'recall_vowel': 0.997783, 'recall_consonant': 0.997507, 'recall_word': 0.995899, 'acc_grapheme': 0.996248, 'acc_vowel': 0.99836, 'acc_consonant': 0.998683, 'acc_word': 0.99595, 'loss_grapheme': 0.032991, 'loss_vowel': 0.022293, 'loss_consonant': 0.01744, 'loss_word': 0.024436}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 0.000124 | 160000/160596 | 1.5590 | 7.1577 ||\n",
      "val: {'recall': 0.997323, 'recall_grapheme': 0.996731, 'recall_vowel': 0.997769, 'recall_consonant': 0.99806, 'recall_word': 0.995886, 'acc_grapheme': 0.996447, 'acc_vowel': 0.998385, 'acc_consonant': 0.998534, 'acc_word': 0.995975, 'loss_grapheme': 0.054767, 'loss_vowel': 0.033527, 'loss_consonant': 0.029463, 'loss_word': 0.03649}\n",
      "   22 | 0.000121 | 160000/160596 | 1.5189 | 6.6509 |||\n",
      "val: {'recall': 0.997124, 'recall_grapheme': 0.996714, 'recall_vowel': 0.997526, 'recall_consonant': 0.997544, 'recall_word': 0.995537, 'acc_grapheme': 0.996074, 'acc_vowel': 0.998136, 'acc_consonant': 0.998584, 'acc_word': 0.995627, 'loss_grapheme': 0.040991, 'loss_vowel': 0.026306, 'loss_consonant': 0.020716, 'loss_word': 0.028771}\n",
      "   23 | 0.000119 | 160000/160596 | 6.9661 | 6.7586 ||\n",
      "val: {'recall': 0.997022, 'recall_grapheme': 0.996422, 'recall_vowel': 0.997497, 'recall_consonant': 0.997747, 'recall_word': 0.995296, 'acc_grapheme': 0.99585, 'acc_vowel': 0.99836, 'acc_consonant': 0.998385, 'acc_word': 0.995428, 'loss_grapheme': 0.068268, 'loss_vowel': 0.043589, 'loss_consonant': 0.032266, 'loss_word': 0.043692}\n",
      "   24 | 0.000117 | 160000/160596 | 1.4211 | 5.9954 ||\n",
      "val: {'recall': 0.997189, 'recall_grapheme': 0.996533, 'recall_vowel': 0.997804, 'recall_consonant': 0.997884, 'recall_word': 0.995686, 'acc_grapheme': 0.995825, 'acc_vowel': 0.99831, 'acc_consonant': 0.998459, 'acc_word': 0.995751, 'loss_grapheme': 0.032033, 'loss_vowel': 0.019501, 'loss_consonant': 0.016566, 'loss_word': 0.024394}\n",
      "   25 | 0.000114 | 160000/160596 | 8.7239 | 5.6673 ||\n",
      "val: {'recall': 0.99711, 'recall_grapheme': 0.996337, 'recall_vowel': 0.997968, 'recall_consonant': 0.997797, 'recall_word': 0.995504, 'acc_grapheme': 0.99595, 'acc_vowel': 0.998285, 'acc_consonant': 0.998385, 'acc_word': 0.995652, 'loss_grapheme': 0.072233, 'loss_vowel': 0.047918, 'loss_consonant': 0.037318, 'loss_word': 0.045912}\n",
      "   26 | 0.000112 | 160000/160596 | 12.2109 | 6.3922 ||\n",
      "val: {'recall': 0.997399, 'recall_grapheme': 0.996984, 'recall_vowel': 0.99765, 'recall_consonant': 0.997978, 'recall_word': 0.99578, 'acc_grapheme': 0.996322, 'acc_vowel': 0.998285, 'acc_consonant': 0.998559, 'acc_word': 0.995875, 'loss_grapheme': 0.043093, 'loss_vowel': 0.029999, 'loss_consonant': 0.023864, 'loss_word': 0.028273}\n",
      "   27 | 0.000109 | 160000/160596 | 6.1857 | 6.3751 |||\n",
      "val: {'recall': 0.997112, 'recall_grapheme': 0.996255, 'recall_vowel': 0.997988, 'recall_consonant': 0.997948, 'recall_word': 0.995322, 'acc_grapheme': 0.9959, 'acc_vowel': 0.998211, 'acc_consonant': 0.998459, 'acc_word': 0.995453, 'loss_grapheme': 0.043487, 'loss_vowel': 0.028722, 'loss_consonant': 0.021878, 'loss_word': 0.031614}\n",
      "   28 | 0.000106 | 160000/160596 | 13.9029 | 6.5001 |\n",
      "val: {'recall': 0.996962, 'recall_grapheme': 0.995877, 'recall_vowel': 0.998237, 'recall_consonant': 0.997855, 'recall_word': 0.995227, 'acc_grapheme': 0.995751, 'acc_vowel': 0.99836, 'acc_consonant': 0.998459, 'acc_word': 0.995304, 'loss_grapheme': 0.051906, 'loss_vowel': 0.034388, 'loss_consonant': 0.0261, 'loss_word': 0.034056}\n",
      "   29 | 0.000104 | 160000/160596 | 5.7499 | 6.0348 ||\n",
      "val: {'recall': 0.996782, 'recall_grapheme': 0.995807, 'recall_vowel': 0.997917, 'recall_consonant': 0.997598, 'recall_word': 0.995486, 'acc_grapheme': 0.995701, 'acc_vowel': 0.998161, 'acc_consonant': 0.998559, 'acc_word': 0.995577, 'loss_grapheme': 0.0514, 'loss_vowel': 0.034942, 'loss_consonant': 0.027379, 'loss_word': 0.032756}\n",
      "   30 | 0.000101 | 160000/160596 | 1.2926 | 6.4201 |||\n",
      "val: {'recall': 0.997225, 'recall_grapheme': 0.996357, 'recall_vowel': 0.998277, 'recall_consonant': 0.997907, 'recall_word': 0.995887, 'acc_grapheme': 0.996347, 'acc_vowel': 0.998459, 'acc_consonant': 0.998534, 'acc_word': 0.995999, 'loss_grapheme': 0.029364, 'loss_vowel': 0.019222, 'loss_consonant': 0.015716, 'loss_word': 0.022063}\n",
      "   31 | 0.000098 | 160000/160596 | 1.3928 | 6.7190 |||\n",
      "val: {'recall': 0.996872, 'recall_grapheme': 0.996519, 'recall_vowel': 0.997784, 'recall_consonant': 0.996665, 'recall_word': 0.995663, 'acc_grapheme': 0.995975, 'acc_vowel': 0.998285, 'acc_consonant': 0.99836, 'acc_word': 0.995776, 'loss_grapheme': 0.054109, 'loss_vowel': 0.031794, 'loss_consonant': 0.027025, 'loss_word': 0.035305}\n",
      "   32 | 0.000095 | 160000/160596 | 1.3227 | 5.7591 ||\n",
      "val: {'recall': 0.996977, 'recall_grapheme': 0.995946, 'recall_vowel': 0.997984, 'recall_consonant': 0.998031, 'recall_word': 0.995389, 'acc_grapheme': 0.99595, 'acc_vowel': 0.998385, 'acc_consonant': 0.998509, 'acc_word': 0.995552, 'loss_grapheme': 0.057212, 'loss_vowel': 0.037616, 'loss_consonant': 0.028351, 'loss_word': 0.036386}\n",
      "   33 | 0.000093 | 160000/160596 | 6.0395 | 6.8852 ||\n",
      "val: {'recall': 0.996919, 'recall_grapheme': 0.995887, 'recall_vowel': 0.998062, 'recall_consonant': 0.99784, 'recall_word': 0.995478, 'acc_grapheme': 0.995925, 'acc_vowel': 0.998385, 'acc_consonant': 0.998335, 'acc_word': 0.995627, 'loss_grapheme': 0.081357, 'loss_vowel': 0.058594, 'loss_consonant': 0.04427, 'loss_word': 0.054275}\n",
      "   34 | 0.000090 | 160000/160596 | 2.4558 | 6.5390 ||\n",
      "val: {'recall': 0.996944, 'recall_grapheme': 0.996693, 'recall_vowel': 0.997865, 'recall_consonant': 0.996526, 'recall_word': 0.995741, 'acc_grapheme': 0.996223, 'acc_vowel': 0.998385, 'acc_consonant': 0.99836, 'acc_word': 0.99585, 'loss_grapheme': 0.045754, 'loss_vowel': 0.030479, 'loss_consonant': 0.022835, 'loss_word': 0.030607}\n",
      "   35 | 0.000087 | 160000/160596 | 1.2579 | 6.1599 |||\n",
      "val: {'recall': 0.997578, 'recall_grapheme': 0.99688, 'recall_vowel': 0.998559, 'recall_consonant': 0.997991, 'recall_word': 0.99642, 'acc_grapheme': 0.99672, 'acc_vowel': 0.998683, 'acc_consonant': 0.998584, 'acc_word': 0.996521, 'loss_grapheme': 0.028775, 'loss_vowel': 0.018054, 'loss_consonant': 0.015427, 'loss_word': 0.021104}\n",
      "   36 | 0.000084 | 160000/160596 | 5.0351 | 6.0693 ||\n",
      "val: {'recall': 0.997154, 'recall_grapheme': 0.996275, 'recall_vowel': 0.998265, 'recall_consonant': 0.997801, 'recall_word': 0.995469, 'acc_grapheme': 0.995925, 'acc_vowel': 0.998435, 'acc_consonant': 0.99831, 'acc_word': 0.995552, 'loss_grapheme': 0.062598, 'loss_vowel': 0.039521, 'loss_consonant': 0.031003, 'loss_word': 0.040118}\n",
      "   37 | 0.000081 | 160000/160596 | 1.1885 | 6.2908 ||\n",
      "val: {'recall': 0.996969, 'recall_grapheme': 0.996113, 'recall_vowel': 0.998033, 'recall_consonant': 0.997615, 'recall_word': 0.99526, 'acc_grapheme': 0.995751, 'acc_vowel': 0.998261, 'acc_consonant': 0.99836, 'acc_word': 0.995353, 'loss_grapheme': 0.08418, 'loss_vowel': 0.058567, 'loss_consonant': 0.044171, 'loss_word': 0.054621}\n",
      "   38 | 0.000078 | 160000/160596 | 7.4460 | 6.4038 ||\n",
      "val: {'recall': 0.997167, 'recall_grapheme': 0.996443, 'recall_vowel': 0.997793, 'recall_consonant': 0.99799, 'recall_word': 0.995481, 'acc_grapheme': 0.996024, 'acc_vowel': 0.998509, 'acc_consonant': 0.998534, 'acc_word': 0.995602, 'loss_grapheme': 0.055996, 'loss_vowel': 0.037232, 'loss_consonant': 0.029864, 'loss_word': 0.037926}\n",
      "   39 | 0.000075 | 160000/160596 | 6.8164 | 5.7938 ||\n",
      "val: {'recall': 0.997441, 'recall_grapheme': 0.996836, 'recall_vowel': 0.998064, 'recall_consonant': 0.998029, 'recall_word': 0.996128, 'acc_grapheme': 0.996521, 'acc_vowel': 0.998534, 'acc_consonant': 0.998559, 'acc_word': 0.996248, 'loss_grapheme': 0.027706, 'loss_vowel': 0.017767, 'loss_consonant': 0.014739, 'loss_word': 0.021268}\n",
      "   40 | 0.000072 | 160000/160596 | 14.6555 | 5.9791 |\n",
      "val: {'recall': 0.997036, 'recall_grapheme': 0.996233, 'recall_vowel': 0.997863, 'recall_consonant': 0.997814, 'recall_word': 0.995883, 'acc_grapheme': 0.995925, 'acc_vowel': 0.998534, 'acc_consonant': 0.998435, 'acc_word': 0.99595, 'loss_grapheme': 0.087185, 'loss_vowel': 0.061253, 'loss_consonant': 0.044447, 'loss_word': 0.049478}\n",
      "   41 | 0.000069 | 160000/160596 | 1.0503 | 6.3388 |||\n",
      "val: {'recall': 0.997149, 'recall_grapheme': 0.996324, 'recall_vowel': 0.998184, 'recall_consonant': 0.997766, 'recall_word': 0.995878, 'acc_grapheme': 0.996347, 'acc_vowel': 0.998658, 'acc_consonant': 0.99831, 'acc_word': 0.995975, 'loss_grapheme': 0.03198, 'loss_vowel': 0.019152, 'loss_consonant': 0.016488, 'loss_word': 0.023651}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 0.000066 | 160000/160596 | 3.9906 | 6.5162 |||\n",
      "val: {'recall': 0.997145, 'recall_grapheme': 0.996552, 'recall_vowel': 0.998256, 'recall_consonant': 0.997219, 'recall_word': 0.995237, 'acc_grapheme': 0.996099, 'acc_vowel': 0.998435, 'acc_consonant': 0.998211, 'acc_word': 0.995378, 'loss_grapheme': 0.076635, 'loss_vowel': 0.047777, 'loss_consonant': 0.037093, 'loss_word': 0.049307}\n",
      "   43 | 0.000063 | 160000/160596 | 1.1832 | 6.1932 |||\n",
      "val: {'recall': 0.997583, 'recall_grapheme': 0.9968, 'recall_vowel': 0.998603, 'recall_consonant': 0.998127, 'recall_word': 0.996422, 'acc_grapheme': 0.99672, 'acc_vowel': 0.998683, 'acc_consonant': 0.998683, 'acc_word': 0.996521, 'loss_grapheme': 0.026095, 'loss_vowel': 0.017138, 'loss_consonant': 0.013987, 'loss_word': 0.019375}\n",
      "   44 | 0.000060 | 160000/160596 | 4.8584 | 6.2760 ||\n",
      "val: {'recall': 0.997324, 'recall_grapheme': 0.996856, 'recall_vowel': 0.998219, 'recall_consonant': 0.997364, 'recall_word': 0.996142, 'acc_grapheme': 0.996571, 'acc_vowel': 0.998509, 'acc_consonant': 0.99841, 'acc_word': 0.996298, 'loss_grapheme': 0.03129, 'loss_vowel': 0.02064, 'loss_consonant': 0.016782, 'loss_word': 0.022497}\n",
      "   45 | 0.000058 | 160000/160596 | 14.2052 | 6.2602 |\n",
      "val: {'recall': 0.997042, 'recall_grapheme': 0.996068, 'recall_vowel': 0.998284, 'recall_consonant': 0.997749, 'recall_word': 0.996041, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998608, 'acc_consonant': 0.99831, 'acc_word': 0.996148, 'loss_grapheme': 0.044968, 'loss_vowel': 0.03116, 'loss_consonant': 0.024349, 'loss_word': 0.027527}\n",
      "   46 | 0.000055 | 160000/160596 | 1.0850 | 6.3553 |||\n",
      "val: {'recall': 0.997591, 'recall_grapheme': 0.996896, 'recall_vowel': 0.998659, 'recall_consonant': 0.99791, 'recall_word': 0.996159, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998683, 'acc_consonant': 0.998484, 'acc_word': 0.996298, 'loss_grapheme': 0.0277, 'loss_vowel': 0.018306, 'loss_consonant': 0.0149, 'loss_word': 0.020699}\n",
      "   47 | 0.000052 | 160000/160596 | 6.8801 | 6.5327 ||\n",
      "val: {'recall': 0.997517, 'recall_grapheme': 0.996885, 'recall_vowel': 0.998285, 'recall_consonant': 0.998013, 'recall_word': 0.996277, 'acc_grapheme': 0.996521, 'acc_vowel': 0.998658, 'acc_consonant': 0.998459, 'acc_word': 0.996397, 'loss_grapheme': 0.045769, 'loss_vowel': 0.031544, 'loss_consonant': 0.025121, 'loss_word': 0.028982}\n",
      "   48 | 0.000049 | 160000/160596 | 1.2225 | 6.3142 ||\n",
      "val: {'recall': 0.997549, 'recall_grapheme': 0.996958, 'recall_vowel': 0.998274, 'recall_consonant': 0.998007, 'recall_word': 0.995869, 'acc_grapheme': 0.996198, 'acc_vowel': 0.998633, 'acc_consonant': 0.998534, 'acc_word': 0.995999, 'loss_grapheme': 0.052548, 'loss_vowel': 0.033502, 'loss_consonant': 0.027407, 'loss_word': 0.03333}\n",
      "   49 | 0.000046 | 160000/160596 | 12.1986 | 6.9595 ||\n",
      "val: {'recall': 0.997387, 'recall_grapheme': 0.996705, 'recall_vowel': 0.998163, 'recall_consonant': 0.997977, 'recall_word': 0.996222, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998758, 'acc_consonant': 0.998534, 'acc_word': 0.996372, 'loss_grapheme': 0.043023, 'loss_vowel': 0.02884, 'loss_consonant': 0.023703, 'loss_word': 0.027194}\n",
      "   50 | 0.000044 | 160000/160596 | 5.1401 | 6.9279 |||\n",
      "val: {'recall': 0.997394, 'recall_grapheme': 0.996826, 'recall_vowel': 0.998027, 'recall_consonant': 0.997896, 'recall_word': 0.996236, 'acc_grapheme': 0.996571, 'acc_vowel': 0.998584, 'acc_consonant': 0.998435, 'acc_word': 0.996372, 'loss_grapheme': 0.076778, 'loss_vowel': 0.049178, 'loss_consonant': 0.041242, 'loss_word': 0.043555}\n",
      "   51 | 0.000041 | 160000/160596 | 10.2624 | 6.3400 |\n",
      "val: {'recall': 0.997566, 'recall_grapheme': 0.996959, 'recall_vowel': 0.998034, 'recall_consonant': 0.99831, 'recall_word': 0.996211, 'acc_grapheme': 0.996596, 'acc_vowel': 0.998584, 'acc_consonant': 0.998782, 'acc_word': 0.996347, 'loss_grapheme': 0.05, 'loss_vowel': 0.032634, 'loss_consonant': 0.025641, 'loss_word': 0.031867}\n",
      "   53 | 0.000037 | 096000/160596 | 13.1745 | 6.7635 |\n",
      "val: {'recall': 0.997502, 'recall_grapheme': 0.996858, 'recall_vowel': 0.998153, 'recall_consonant': 0.998139, 'recall_word': 0.996685, 'acc_grapheme': 0.99672, 'acc_vowel': 0.998782, 'acc_consonant': 0.998608, 'acc_word': 0.996795, 'loss_grapheme': 0.048143, 'loss_vowel': 0.032304, 'loss_consonant': 0.027235, 'loss_word': 0.029125}\n",
      "   54 | 0.000033 | 160000/160596 | 10.9287 | 6.1183 ||\n",
      "val: {'recall': 0.997482, 'recall_grapheme': 0.996967, 'recall_vowel': 0.997949, 'recall_consonant': 0.998044, 'recall_word': 0.996026, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998509, 'acc_consonant': 0.998534, 'acc_word': 0.996148, 'loss_grapheme': 0.049283, 'loss_vowel': 0.032666, 'loss_consonant': 0.025775, 'loss_word': 0.031007}\n",
      "   55 | 0.000031 | 160000/160596 | 11.5939 | 6.2606 |\n",
      "val: {'recall': 0.997314, 'recall_grapheme': 0.996551, 'recall_vowel': 0.998149, 'recall_consonant': 0.998005, 'recall_word': 0.99603, 'acc_grapheme': 0.996273, 'acc_vowel': 0.998658, 'acc_consonant': 0.998509, 'acc_word': 0.996148, 'loss_grapheme': 0.094247, 'loss_vowel': 0.057941, 'loss_consonant': 0.048278, 'loss_word': 0.053629}\n",
      "   56 | 0.000029 | 160000/160596 | 1.0072 | 6.0107 ||\n",
      "val: {'recall': 0.997672, 'recall_grapheme': 0.997115, 'recall_vowel': 0.998413, 'recall_consonant': 0.998044, 'recall_word': 0.996651, 'acc_grapheme': 0.996919, 'acc_vowel': 0.998857, 'acc_consonant': 0.998708, 'acc_word': 0.996745, 'loss_grapheme': 0.02838, 'loss_vowel': 0.020417, 'loss_consonant': 0.017622, 'loss_word': 0.019188}\n",
      "###>>>>> saved\n",
      "   57 | 0.000026 | 160000/160596 | 1.0457 | 6.0927 |||\n",
      "val: {'recall': 0.997351, 'recall_grapheme': 0.997059, 'recall_vowel': 0.998469, 'recall_consonant': 0.996817, 'recall_word': 0.996729, 'acc_grapheme': 0.996993, 'acc_vowel': 0.998857, 'acc_consonant': 0.998584, 'acc_word': 0.996819, 'loss_grapheme': 0.022195, 'loss_vowel': 0.015071, 'loss_consonant': 0.013008, 'loss_word': 0.016879}\n",
      "   58 | 0.000025 | 115840/160596 | 6.6634 | 6.6070 |||\n",
      "val: {'recall': 0.997345, 'recall_grapheme': 0.996897, 'recall_vowel': 0.998686, 'recall_consonant': 0.996899, 'recall_word': 0.996747, 'acc_grapheme': 0.996968, 'acc_vowel': 0.998907, 'acc_consonant': 0.998708, 'acc_word': 0.996844, 'loss_grapheme': 0.045937, 'loss_vowel': 0.030224, 'loss_consonant': 0.025873, 'loss_word': 0.027499}\n",
      "   59 | 0.000022 | 160000/160596 | 9.2410 | 6.5828 ||\n",
      "val: {'recall': 0.997513, 'recall_grapheme': 0.996806, 'recall_vowel': 0.998351, 'recall_consonant': 0.99809, 'recall_word': 0.996647, 'acc_grapheme': 0.99677, 'acc_vowel': 0.998782, 'acc_consonant': 0.998683, 'acc_word': 0.996745, 'loss_grapheme': 0.033519, 'loss_vowel': 0.024592, 'loss_consonant': 0.01986, 'loss_word': 0.021626}\n",
      "   60 | 0.000020 | 160000/160596 | 1.1681 | 6.4451 ||\n",
      "val: {'recall': 0.997534, 'recall_grapheme': 0.996841, 'recall_vowel': 0.998469, 'recall_consonant': 0.997987, 'recall_word': 0.996189, 'acc_grapheme': 0.996695, 'acc_vowel': 0.998807, 'acc_consonant': 0.998608, 'acc_word': 0.996298, 'loss_grapheme': 0.043473, 'loss_vowel': 0.031269, 'loss_consonant': 0.025575, 'loss_word': 0.027491}\n",
      "   61 | 0.000018 | 160000/160596 | 7.6045 | 6.0435 ||\n",
      "val: {'recall': 0.997477, 'recall_grapheme': 0.996776, 'recall_vowel': 0.998406, 'recall_consonant': 0.99795, 'recall_word': 0.996229, 'acc_grapheme': 0.996621, 'acc_vowel': 0.998758, 'acc_consonant': 0.998534, 'acc_word': 0.996372, 'loss_grapheme': 0.034643, 'loss_vowel': 0.023963, 'loss_consonant': 0.020714, 'loss_word': 0.021971}\n",
      "   62 | 0.000016 | 160000/160596 | 0.5223 | 6.5760 ||\n",
      "val: {'recall': 0.997424, 'recall_grapheme': 0.996626, 'recall_vowel': 0.998494, 'recall_consonant': 0.99795, 'recall_word': 0.996051, 'acc_grapheme': 0.996322, 'acc_vowel': 0.998708, 'acc_consonant': 0.998509, 'acc_word': 0.996173, 'loss_grapheme': 0.08431, 'loss_vowel': 0.052095, 'loss_consonant': 0.039678, 'loss_word': 0.052793}\n",
      "   63 | 0.000014 | 160000/160596 | 5.8800 | 5.6472 |||\n",
      "val: {'recall': 0.997505, 'recall_grapheme': 0.99688, 'recall_vowel': 0.998312, 'recall_consonant': 0.997948, 'recall_word': 0.99602, 'acc_grapheme': 0.996521, 'acc_vowel': 0.998683, 'acc_consonant': 0.998484, 'acc_word': 0.996173, 'loss_grapheme': 0.071487, 'loss_vowel': 0.048515, 'loss_consonant': 0.037167, 'loss_word': 0.044865}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   64 | 0.000013 | 160000/160596 | 0.9669 | 5.9342 ||\n",
      "val: {'recall': 0.997714, 'recall_grapheme': 0.997073, 'recall_vowel': 0.998622, 'recall_consonant': 0.998086, 'recall_word': 0.996663, 'acc_grapheme': 0.996869, 'acc_vowel': 0.998832, 'acc_consonant': 0.998758, 'acc_word': 0.996745, 'loss_grapheme': 0.038651, 'loss_vowel': 0.026906, 'loss_consonant': 0.020957, 'loss_word': 0.025053}\n",
      "###>>>>> saved\n",
      "   65 | 0.000011 | 160000/160596 | 3.5143 | 6.1874 ||\n",
      "val: {'recall': 0.997392, 'recall_grapheme': 0.996659, 'recall_vowel': 0.998303, 'recall_consonant': 0.997947, 'recall_word': 0.996059, 'acc_grapheme': 0.996273, 'acc_vowel': 0.998708, 'acc_consonant': 0.998509, 'acc_word': 0.996173, 'loss_grapheme': 0.072503, 'loss_vowel': 0.047282, 'loss_consonant': 0.037336, 'loss_word': 0.04224}\n",
      "   66 | 0.000010 | 160000/160596 | 7.6927 | 6.2418 ||\n",
      "val: {'recall': 0.997718, 'recall_grapheme': 0.997067, 'recall_vowel': 0.998569, 'recall_consonant': 0.99817, 'recall_word': 0.996409, 'acc_grapheme': 0.996844, 'acc_vowel': 0.998782, 'acc_consonant': 0.998633, 'acc_word': 0.996496, 'loss_grapheme': 0.053724, 'loss_vowel': 0.036053, 'loss_consonant': 0.028162, 'loss_word': 0.034346}\n",
      "###>>>>> saved\n",
      "   67 | 0.000008 | 160000/160596 | 11.4973 | 6.3578 |\n",
      "val: {'recall': 0.997451, 'recall_grapheme': 0.996716, 'recall_vowel': 0.998357, 'recall_consonant': 0.998015, 'recall_word': 0.996404, 'acc_grapheme': 0.996695, 'acc_vowel': 0.998807, 'acc_consonant': 0.998584, 'acc_word': 0.996496, 'loss_grapheme': 0.035316, 'loss_vowel': 0.023878, 'loss_consonant': 0.020468, 'loss_word': 0.023054}\n",
      "   68 | 0.000007 | 160000/160596 | 6.7501 | 6.6173 ||\n",
      "val: {'recall': 0.997022, 'recall_grapheme': 0.996584, 'recall_vowel': 0.998195, 'recall_consonant': 0.996724, 'recall_word': 0.995899, 'acc_grapheme': 0.996472, 'acc_vowel': 0.998608, 'acc_consonant': 0.99841, 'acc_word': 0.996049, 'loss_grapheme': 0.067353, 'loss_vowel': 0.039827, 'loss_consonant': 0.035431, 'loss_word': 0.040258}\n",
      "   69 | 0.000006 | 160000/160596 | 14.1904 | 6.3704 |\n",
      "val: {'recall': 0.997332, 'recall_grapheme': 0.996519, 'recall_vowel': 0.99831, 'recall_consonant': 0.997981, 'recall_word': 0.996083, 'acc_grapheme': 0.996347, 'acc_vowel': 0.998708, 'acc_consonant': 0.998509, 'acc_word': 0.996173, 'loss_grapheme': 0.065081, 'loss_vowel': 0.043913, 'loss_consonant': 0.035719, 'loss_word': 0.037144}\n",
      "   70 | 0.000005 | 160000/160596 | 6.7321 | 6.3943 ||\n",
      "val: {'recall': 0.997626, 'recall_grapheme': 0.99693, 'recall_vowel': 0.998586, 'recall_consonant': 0.99806, 'recall_word': 0.99589, 'acc_grapheme': 0.996596, 'acc_vowel': 0.998758, 'acc_consonant': 0.998509, 'acc_word': 0.995999, 'loss_grapheme': 0.050874, 'loss_vowel': 0.031733, 'loss_consonant': 0.02678, 'loss_word': 0.03204}\n",
      "   71 | 0.000004 | 160000/160596 | 1.0091 | 5.8330 |||\n",
      "val: {'recall': 0.997503, 'recall_grapheme': 0.996786, 'recall_vowel': 0.998481, 'recall_consonant': 0.997961, 'recall_word': 0.996433, 'acc_grapheme': 0.996869, 'acc_vowel': 0.998782, 'acc_consonant': 0.998559, 'acc_word': 0.996546, 'loss_grapheme': 0.030609, 'loss_vowel': 0.019885, 'loss_consonant': 0.017441, 'loss_word': 0.02119}\n",
      "   72 | 0.000003 | 160000/160596 | 7.0153 | 5.9381 ||\n",
      "val: {'recall': 0.997421, 'recall_grapheme': 0.996655, 'recall_vowel': 0.998443, 'recall_consonant': 0.99793, 'recall_word': 0.996127, 'acc_grapheme': 0.996546, 'acc_vowel': 0.998733, 'acc_consonant': 0.998509, 'acc_word': 0.996248, 'loss_grapheme': 0.070257, 'loss_vowel': 0.04583, 'loss_consonant': 0.036452, 'loss_word': 0.042367}\n",
      "   73 | 0.000002 | 160000/160596 | 5.1157 | 6.3891 ||\n",
      "val: {'recall': 0.997491, 'recall_grapheme': 0.9968, 'recall_vowel': 0.998419, 'recall_consonant': 0.997945, 'recall_word': 0.996056, 'acc_grapheme': 0.996422, 'acc_vowel': 0.998807, 'acc_consonant': 0.998459, 'acc_word': 0.996198, 'loss_grapheme': 0.058394, 'loss_vowel': 0.03756, 'loss_consonant': 0.030734, 'loss_word': 0.035304}\n",
      "   74 | 0.000001 | 160000/160596 | 3.1451 | 6.6228 ||\n",
      "val: {'recall': 0.99752, 'recall_grapheme': 0.996825, 'recall_vowel': 0.998335, 'recall_consonant': 0.998096, 'recall_word': 0.996445, 'acc_grapheme': 0.996745, 'acc_vowel': 0.998758, 'acc_consonant': 0.998584, 'acc_word': 0.996546, 'loss_grapheme': 0.044328, 'loss_vowel': 0.029482, 'loss_consonant': 0.02535, 'loss_word': 0.026417}\n",
      "   75 | 0.000001 | 160000/160596 | 2.5358 | 5.9023 ||\n",
      "val: {'recall': 0.997562, 'recall_grapheme': 0.996959, 'recall_vowel': 0.998311, 'recall_consonant': 0.998018, 'recall_word': 0.996309, 'acc_grapheme': 0.996571, 'acc_vowel': 0.998708, 'acc_consonant': 0.998584, 'acc_word': 0.996397, 'loss_grapheme': 0.051949, 'loss_vowel': 0.033897, 'loss_consonant': 0.028111, 'loss_word': 0.031622}\n",
      "   76 | 0.000001 | 160000/160596 | 5.6001 | 6.5210 ||\n",
      "val: {'recall': 0.997375, 'recall_grapheme': 0.997045, 'recall_vowel': 0.998613, 'recall_consonant': 0.996795, 'recall_word': 0.996606, 'acc_grapheme': 0.996944, 'acc_vowel': 0.998857, 'acc_consonant': 0.998608, 'acc_word': 0.996745, 'loss_grapheme': 0.036031, 'loss_vowel': 0.025862, 'loss_consonant': 0.020575, 'loss_word': 0.023638}\n",
      "   77 | 0.000000 | 160000/160596 | 5.4857 | 5.9917 |||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6df1386d1bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-ce31fa1c165d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cycles\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CYCLE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#args.base_lr = 4e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#args.num_epochs = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ce31fa1c165d>\u001b[0m in \u001b[0;36mtrain_cycle\u001b[0;34m(args, model, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#train_iter > 0 and train_iter % args.iter_val == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-d19374fd65cb>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYCLE: 1\n",
      "{'recall': 0.994744, 'recall_grapheme': 0.992397, 'recall_vowel': 0.997031, 'recall_consonant': 0.99715, 'recall_word': 0.988796, 'acc_grapheme': 0.992421, 'acc_vowel': 0.997465, 'acc_consonant': 0.997515, 'acc_word': 0.989141, 'loss_grapheme': 0.051274, 'loss_vowel': 0.044025, 'loss_consonant': 0.036861, 'loss_word': 0.707041}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.000030 | 160000/160596 | 13.5191 | 16.2231 |\n",
      "val: {'recall': 0.994267, 'recall_grapheme': 0.991667, 'recall_vowel': 0.997044, 'recall_consonant': 0.996688, 'recall_word': 0.989588, 'acc_grapheme': 0.991924, 'acc_vowel': 0.997341, 'acc_consonant': 0.997142, 'acc_word': 0.989315, 'loss_grapheme': 0.060404, 'loss_vowel': 0.049112, 'loss_consonant': 0.044607, 'loss_word': 0.691783}\n",
      "    1 | 0.000060 | 160000/160596 | 14.7654 | 15.2369 |\n",
      "val: {'recall': 0.994122, 'recall_grapheme': 0.991519, 'recall_vowel': 0.99668, 'recall_consonant': 0.996773, 'recall_word': 0.99096, 'acc_grapheme': 0.992396, 'acc_vowel': 0.997043, 'acc_consonant': 0.996944, 'acc_word': 0.990806, 'loss_grapheme': 0.069435, 'loss_vowel': 0.056182, 'loss_consonant': 0.051753, 'loss_word': 0.507367}\n",
      "    2 | 0.000090 | 160000/160596 | 15.7133 | 14.6691 |\n",
      "val: {'recall': 0.993512, 'recall_grapheme': 0.990841, 'recall_vowel': 0.996079, 'recall_consonant': 0.996286, 'recall_word': 0.989377, 'acc_grapheme': 0.99103, 'acc_vowel': 0.996372, 'acc_consonant': 0.996397, 'acc_word': 0.989415, 'loss_grapheme': 0.127439, 'loss_vowel': 0.098302, 'loss_consonant': 0.080045, 'loss_word': 0.514789}\n",
      "    3 | 0.000119 | 160000/160596 | 13.2901 | 14.3223 |\n",
      "val: {'recall': 0.993668, 'recall_grapheme': 0.990533, 'recall_vowel': 0.996916, 'recall_consonant': 0.996688, 'recall_word': 0.990222, 'acc_grapheme': 0.991353, 'acc_vowel': 0.996968, 'acc_consonant': 0.996944, 'acc_word': 0.990309, 'loss_grapheme': 0.154067, 'loss_vowel': 0.102351, 'loss_consonant': 0.076058, 'loss_word': 0.360312}\n",
      "    4 | 0.000148 | 160000/160596 | 13.1955 | 14.5470 |\n",
      "val: {'recall': 0.992772, 'recall_grapheme': 0.989534, 'recall_vowel': 0.995725, 'recall_consonant': 0.996298, 'recall_word': 0.988978, 'acc_grapheme': 0.990409, 'acc_vowel': 0.996198, 'acc_consonant': 0.996273, 'acc_word': 0.988918, 'loss_grapheme': 0.213255, 'loss_vowel': 0.132025, 'loss_consonant': 0.098798, 'loss_word': 0.354731}\n",
      "    5 | 0.000148 | 160000/160596 | 17.5672 | 13.6875 |\n",
      "val: {'recall': 0.994029, 'recall_grapheme': 0.991585, 'recall_vowel': 0.996469, 'recall_consonant': 0.996477, 'recall_word': 0.991577, 'acc_grapheme': 0.992819, 'acc_vowel': 0.99672, 'acc_consonant': 0.996869, 'acc_word': 0.991576, 'loss_grapheme': 0.192651, 'loss_vowel': 0.11648, 'loss_consonant': 0.075073, 'loss_word': 0.251176}\n",
      "    6 | 0.000147 | 160000/160596 | 18.7615 | 13.3054 |\n",
      "val: {'recall': 0.994313, 'recall_grapheme': 0.992096, 'recall_vowel': 0.996699, 'recall_consonant': 0.99636, 'recall_word': 0.991149, 'acc_grapheme': 0.991974, 'acc_vowel': 0.996968, 'acc_consonant': 0.996745, 'acc_word': 0.991253, 'loss_grapheme': 0.201737, 'loss_vowel': 0.143503, 'loss_consonant': 0.091411, 'loss_word': 0.232047}\n",
      "    7 | 0.000146 | 160000/160596 | 11.5550 | 13.1582 |\n",
      "val: {'recall': 0.993599, 'recall_grapheme': 0.991429, 'recall_vowel': 0.996382, 'recall_consonant': 0.995156, 'recall_word': 0.990505, 'acc_grapheme': 0.991775, 'acc_vowel': 0.996993, 'acc_consonant': 0.996521, 'acc_word': 0.990558, 'loss_grapheme': 0.22424, 'loss_vowel': 0.128547, 'loss_consonant': 0.087357, 'loss_word': 0.256968}\n",
      "    8 | 0.000145 | 160000/160596 | 9.6009 | 13.1318 ||\n",
      "val: {'recall': 0.994136, 'recall_grapheme': 0.991743, 'recall_vowel': 0.997077, 'recall_consonant': 0.995981, 'recall_word': 0.991615, 'acc_grapheme': 0.992396, 'acc_vowel': 0.996894, 'acc_consonant': 0.996596, 'acc_word': 0.991626, 'loss_grapheme': 0.230279, 'loss_vowel': 0.132698, 'loss_consonant': 0.091031, 'loss_word': 0.233662}\n",
      "    9 | 0.000144 | 160000/160596 | 8.7100 | 12.7453 ||\n",
      "val: {'recall': 0.993684, 'recall_grapheme': 0.990821, 'recall_vowel': 0.996679, 'recall_consonant': 0.996414, 'recall_word': 0.991096, 'acc_grapheme': 0.991676, 'acc_vowel': 0.996571, 'acc_consonant': 0.996571, 'acc_word': 0.991055, 'loss_grapheme': 0.199049, 'loss_vowel': 0.117696, 'loss_consonant': 0.079977, 'loss_word': 0.204785}\n",
      "   10 | 0.000143 | 160000/160596 | 11.4732 | 12.4363 |\n",
      "val: {'recall': 0.993211, 'recall_grapheme': 0.990172, 'recall_vowel': 0.99605, 'recall_consonant': 0.99645, 'recall_word': 0.991458, 'acc_grapheme': 0.992098, 'acc_vowel': 0.996695, 'acc_consonant': 0.996745, 'acc_word': 0.991427, 'loss_grapheme': 0.224289, 'loss_vowel': 0.110172, 'loss_consonant': 0.085996, 'loss_word': 0.209673}\n",
      "   11 | 0.000142 | 160000/160596 | 12.0322 | 12.7372 |\n",
      "val: {'recall': 0.993591, 'recall_grapheme': 0.991718, 'recall_vowel': 0.996271, 'recall_consonant': 0.994657, 'recall_word': 0.991659, 'acc_grapheme': 0.992123, 'acc_vowel': 0.99672, 'acc_consonant': 0.996645, 'acc_word': 0.991725, 'loss_grapheme': 0.237996, 'loss_vowel': 0.159837, 'loss_consonant': 0.095688, 'loss_word': 0.209076}\n",
      "   12 | 0.000140 | 160000/160596 | 18.2678 | 11.8323 |\n",
      "val: {'recall': 0.993826, 'recall_grapheme': 0.991477, 'recall_vowel': 0.995873, 'recall_consonant': 0.996479, 'recall_word': 0.990517, 'acc_grapheme': 0.991552, 'acc_vowel': 0.996645, 'acc_consonant': 0.996919, 'acc_word': 0.990582, 'loss_grapheme': 0.240972, 'loss_vowel': 0.143158, 'loss_consonant': 0.096728, 'loss_word': 0.212606}\n",
      "   13 | 0.000139 | 160000/160596 | 9.1719 | 12.3097 ||\n",
      "val: {'recall': 0.994436, 'recall_grapheme': 0.992261, 'recall_vowel': 0.996993, 'recall_consonant': 0.996226, 'recall_word': 0.992002, 'acc_grapheme': 0.992645, 'acc_vowel': 0.997018, 'acc_consonant': 0.997217, 'acc_word': 0.991974, 'loss_grapheme': 0.208363, 'loss_vowel': 0.119168, 'loss_consonant': 0.080524, 'loss_word': 0.18558}\n",
      "   14 | 0.000137 | 160000/160596 | 9.7697 | 11.9729 ||\n",
      "val: {'recall': 0.994421, 'recall_grapheme': 0.992631, 'recall_vowel': 0.996461, 'recall_consonant': 0.995963, 'recall_word': 0.992331, 'acc_grapheme': 0.993117, 'acc_vowel': 0.996919, 'acc_consonant': 0.997192, 'acc_word': 0.992421, 'loss_grapheme': 0.22688, 'loss_vowel': 0.132236, 'loss_consonant': 0.082867, 'loss_word': 0.193878}\n",
      "   15 | 0.000136 | 160000/160596 | 9.8861 | 11.9632 ||\n",
      "val: {'recall': 0.994059, 'recall_grapheme': 0.991926, 'recall_vowel': 0.997119, 'recall_consonant': 0.995265, 'recall_word': 0.992673, 'acc_grapheme': 0.993117, 'acc_vowel': 0.997142, 'acc_consonant': 0.997341, 'acc_word': 0.992769, 'loss_grapheme': 0.275851, 'loss_vowel': 0.16475, 'loss_consonant': 0.106338, 'loss_word': 0.226327}\n",
      "   16 | 0.000134 | 160000/160596 | 6.2021 | 11.6160 ||\n",
      "val: {'recall': 0.995258, 'recall_grapheme': 0.993821, 'recall_vowel': 0.997514, 'recall_consonant': 0.995877, 'recall_word': 0.993472, 'acc_grapheme': 0.993738, 'acc_vowel': 0.997813, 'acc_consonant': 0.997689, 'acc_word': 0.993589, 'loss_grapheme': 0.198508, 'loss_vowel': 0.118812, 'loss_consonant': 0.078362, 'loss_word': 0.157368}\n",
      "###>>>>> saved\n",
      "   17 | 0.000132 | 160000/160596 | 8.5523 | 11.3620 ||\n",
      "val: {'recall': 0.993046, 'recall_grapheme': 0.990938, 'recall_vowel': 0.995942, 'recall_consonant': 0.994364, 'recall_word': 0.990721, 'acc_grapheme': 0.991651, 'acc_vowel': 0.996472, 'acc_consonant': 0.996869, 'acc_word': 0.990806, 'loss_grapheme': 0.250538, 'loss_vowel': 0.13909, 'loss_consonant': 0.099518, 'loss_word': 0.216755}\n",
      "   18 | 0.000130 | 160000/160596 | 3.3799 | 11.5860 ||\n",
      "val: {'recall': 0.99494, 'recall_grapheme': 0.993309, 'recall_vowel': 0.997576, 'recall_consonant': 0.995567, 'recall_word': 0.993304, 'acc_grapheme': 0.99349, 'acc_vowel': 0.997664, 'acc_consonant': 0.997714, 'acc_word': 0.993341, 'loss_grapheme': 0.168828, 'loss_vowel': 0.120772, 'loss_consonant': 0.075688, 'loss_word': 0.120745}\n",
      "   19 | 0.000128 | 160000/160596 | 5.4634 | 11.7757 ||\n",
      "val: {'recall': 0.994961, 'recall_grapheme': 0.992529, 'recall_vowel': 0.997374, 'recall_consonant': 0.997413, 'recall_word': 0.993546, 'acc_grapheme': 0.993614, 'acc_vowel': 0.997316, 'acc_consonant': 0.99759, 'acc_word': 0.99349, 'loss_grapheme': 0.165334, 'loss_vowel': 0.10607, 'loss_consonant': 0.069274, 'loss_word': 0.137256}\n",
      "   20 | 0.000126 | 160000/160596 | 4.2783 | 11.4673 ||\n",
      "val: {'recall': 0.994189, 'recall_grapheme': 0.991991, 'recall_vowel': 0.997175, 'recall_consonant': 0.995601, 'recall_word': 0.992782, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997465, 'acc_consonant': 0.997416, 'acc_word': 0.992918, 'loss_grapheme': 0.235179, 'loss_vowel': 0.135814, 'loss_consonant': 0.091187, 'loss_word': 0.167999}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 0.000124 | 160000/160596 | 16.9718 | 10.6579 |\n",
      "val: {'recall': 0.993567, 'recall_grapheme': 0.990838, 'recall_vowel': 0.997542, 'recall_consonant': 0.995051, 'recall_word': 0.992189, 'acc_grapheme': 0.991974, 'acc_vowel': 0.997292, 'acc_consonant': 0.997018, 'acc_word': 0.992272, 'loss_grapheme': 0.218633, 'loss_vowel': 0.152869, 'loss_consonant': 0.099685, 'loss_word': 0.141267}\n",
      "   22 | 0.000121 | 160000/160596 | 5.0350 | 10.8975 ||\n",
      "val: {'recall': 0.994751, 'recall_grapheme': 0.99296, 'recall_vowel': 0.997277, 'recall_consonant': 0.995806, 'recall_word': 0.993694, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997863, 'acc_consonant': 0.99754, 'acc_word': 0.993788, 'loss_grapheme': 0.245615, 'loss_vowel': 0.144242, 'loss_consonant': 0.097046, 'loss_word': 0.178591}\n",
      "   23 | 0.000119 | 160000/160596 | 9.0374 | 10.9487 ||\n",
      "val: {'recall': 0.993748, 'recall_grapheme': 0.991392, 'recall_vowel': 0.996975, 'recall_consonant': 0.995232, 'recall_word': 0.992373, 'acc_grapheme': 0.992869, 'acc_vowel': 0.997192, 'acc_consonant': 0.997118, 'acc_word': 0.992297, 'loss_grapheme': 0.222306, 'loss_vowel': 0.115787, 'loss_consonant': 0.089439, 'loss_word': 0.152298}\n",
      "   24 | 0.000117 | 160000/160596 | 18.0210 | 11.3736 |\n",
      "val: {'recall': 0.993819, 'recall_grapheme': 0.99133, 'recall_vowel': 0.997091, 'recall_consonant': 0.995527, 'recall_word': 0.993037, 'acc_grapheme': 0.992595, 'acc_vowel': 0.997366, 'acc_consonant': 0.997316, 'acc_word': 0.993067, 'loss_grapheme': 0.262307, 'loss_vowel': 0.174035, 'loss_consonant': 0.12037, 'loss_word': 0.163608}\n",
      "   25 | 0.000114 | 160000/160596 | 4.2489 | 11.0943 ||\n",
      "val: {'recall': 0.994724, 'recall_grapheme': 0.993066, 'recall_vowel': 0.99708, 'recall_consonant': 0.995684, 'recall_word': 0.992842, 'acc_grapheme': 0.993042, 'acc_vowel': 0.997441, 'acc_consonant': 0.997739, 'acc_word': 0.992869, 'loss_grapheme': 0.208653, 'loss_vowel': 0.121292, 'loss_consonant': 0.078742, 'loss_word': 0.157695}\n",
      "   26 | 0.000112 | 160000/160596 | 10.0125 | 10.2754 |\n",
      "val: {'recall': 0.994285, 'recall_grapheme': 0.991728, 'recall_vowel': 0.99741, 'recall_consonant': 0.996274, 'recall_word': 0.992778, 'acc_grapheme': 0.993241, 'acc_vowel': 0.997292, 'acc_consonant': 0.99749, 'acc_word': 0.992819, 'loss_grapheme': 0.200544, 'loss_vowel': 0.115657, 'loss_consonant': 0.081356, 'loss_word': 0.145513}\n",
      "   27 | 0.000109 | 160000/160596 | 9.3998 | 10.7916 ||\n",
      "val: {'recall': 0.994852, 'recall_grapheme': 0.99298, 'recall_vowel': 0.997979, 'recall_consonant': 0.995468, 'recall_word': 0.993685, 'acc_grapheme': 0.993763, 'acc_vowel': 0.997764, 'acc_consonant': 0.99749, 'acc_word': 0.993763, 'loss_grapheme': 0.221668, 'loss_vowel': 0.129801, 'loss_consonant': 0.087232, 'loss_word': 0.157033}\n",
      "   28 | 0.000106 | 160000/160596 | 15.3128 | 10.0868 |\n",
      "val: {'recall': 0.995562, 'recall_grapheme': 0.994117, 'recall_vowel': 0.997775, 'recall_consonant': 0.996239, 'recall_word': 0.994051, 'acc_grapheme': 0.994285, 'acc_vowel': 0.997863, 'acc_consonant': 0.997838, 'acc_word': 0.994111, 'loss_grapheme': 0.191318, 'loss_vowel': 0.103311, 'loss_consonant': 0.07152, 'loss_word': 0.143207}\n",
      "###>>>>> saved\n",
      "   29 | 0.000104 | 160000/160596 | 2.5101 | 11.2146 ||\n",
      "val: {'recall': 0.995183, 'recall_grapheme': 0.993622, 'recall_vowel': 0.997546, 'recall_consonant': 0.995943, 'recall_word': 0.993936, 'acc_grapheme': 0.99421, 'acc_vowel': 0.998062, 'acc_consonant': 0.997863, 'acc_word': 0.993962, 'loss_grapheme': 0.175879, 'loss_vowel': 0.110006, 'loss_consonant': 0.075955, 'loss_word': 0.119764}\n",
      "   30 | 0.000101 | 160000/160596 | 11.4396 | 10.2525 |\n",
      "val: {'recall': 0.995481, 'recall_grapheme': 0.994303, 'recall_vowel': 0.997258, 'recall_consonant': 0.996061, 'recall_word': 0.99389, 'acc_grapheme': 0.994508, 'acc_vowel': 0.99754, 'acc_consonant': 0.997788, 'acc_word': 0.993912, 'loss_grapheme': 0.208597, 'loss_vowel': 0.118224, 'loss_consonant': 0.079878, 'loss_word': 0.161212}\n",
      "   31 | 0.000098 | 160000/160596 | 10.3388 | 10.7888 |\n",
      "val: {'recall': 0.995275, 'recall_grapheme': 0.99379, 'recall_vowel': 0.997205, 'recall_consonant': 0.996317, 'recall_word': 0.993748, 'acc_grapheme': 0.994235, 'acc_vowel': 0.99754, 'acc_consonant': 0.997689, 'acc_word': 0.993813, 'loss_grapheme': 0.270596, 'loss_vowel': 0.144969, 'loss_consonant': 0.103119, 'loss_word': 0.199339}\n",
      "   32 | 0.000095 | 160000/160596 | 8.1336 | 10.3903 ||\n",
      "val: {'recall': 0.994648, 'recall_grapheme': 0.992974, 'recall_vowel': 0.997221, 'recall_consonant': 0.995424, 'recall_word': 0.993149, 'acc_grapheme': 0.993614, 'acc_vowel': 0.997267, 'acc_consonant': 0.997465, 'acc_word': 0.993092, 'loss_grapheme': 0.283667, 'loss_vowel': 0.149266, 'loss_consonant': 0.10366, 'loss_word': 0.205274}\n",
      "   33 | 0.000093 | 160000/160596 | 12.3600 | 10.4181 |\n",
      "val: {'recall': 0.994877, 'recall_grapheme': 0.993081, 'recall_vowel': 0.996813, 'recall_consonant': 0.996531, 'recall_word': 0.993367, 'acc_grapheme': 0.993713, 'acc_vowel': 0.997242, 'acc_consonant': 0.997391, 'acc_word': 0.99339, 'loss_grapheme': 0.194517, 'loss_vowel': 0.13502, 'loss_consonant': 0.088899, 'loss_word': 0.124181}\n",
      "   34 | 0.000090 | 160000/160596 | 17.7221 | 10.6092 |\n",
      "val: {'recall': 0.994787, 'recall_grapheme': 0.9928, 'recall_vowel': 0.996713, 'recall_consonant': 0.996834, 'recall_word': 0.992945, 'acc_grapheme': 0.992645, 'acc_vowel': 0.997217, 'acc_consonant': 0.997316, 'acc_word': 0.992993, 'loss_grapheme': 0.252395, 'loss_vowel': 0.170629, 'loss_consonant': 0.112299, 'loss_word': 0.151389}\n",
      "   35 | 0.000087 | 160000/160596 | 17.0626 | 10.1739 |\n",
      "val: {'recall': 0.994589, 'recall_grapheme': 0.992487, 'recall_vowel': 0.997092, 'recall_consonant': 0.996291, 'recall_word': 0.992665, 'acc_grapheme': 0.993067, 'acc_vowel': 0.997416, 'acc_consonant': 0.997267, 'acc_word': 0.99267, 'loss_grapheme': 0.292969, 'loss_vowel': 0.155688, 'loss_consonant': 0.107114, 'loss_word': 0.217679}\n",
      "   36 | 0.000084 | 160000/160596 | 15.5484 | 9.8751 ||\n",
      "val: {'recall': 0.995384, 'recall_grapheme': 0.99384, 'recall_vowel': 0.998235, 'recall_consonant': 0.995621, 'recall_word': 0.994046, 'acc_grapheme': 0.994086, 'acc_vowel': 0.998186, 'acc_consonant': 0.997888, 'acc_word': 0.994111, 'loss_grapheme': 0.203902, 'loss_vowel': 0.127689, 'loss_consonant': 0.082707, 'loss_word': 0.144795}\n",
      "   37 | 0.000081 | 160000/160596 | 4.4300 | 10.1524 ||\n",
      "val: {'recall': 0.995892, 'recall_grapheme': 0.994239, 'recall_vowel': 0.997763, 'recall_consonant': 0.997327, 'recall_word': 0.993752, 'acc_grapheme': 0.994335, 'acc_vowel': 0.997838, 'acc_consonant': 0.997938, 'acc_word': 0.993763, 'loss_grapheme': 0.225948, 'loss_vowel': 0.133505, 'loss_consonant': 0.089419, 'loss_word': 0.163022}\n",
      "###>>>>> saved\n",
      "   38 | 0.000078 | 160000/160596 | 7.1577 | 10.1806 ||\n",
      "val: {'recall': 0.994829, 'recall_grapheme': 0.992691, 'recall_vowel': 0.997247, 'recall_consonant': 0.996688, 'recall_word': 0.99317, 'acc_grapheme': 0.993291, 'acc_vowel': 0.997664, 'acc_consonant': 0.99754, 'acc_word': 0.993192, 'loss_grapheme': 0.233809, 'loss_vowel': 0.141788, 'loss_consonant': 0.09752, 'loss_word': 0.158045}\n",
      "   39 | 0.000075 | 160000/160596 | 8.3298 | 10.1606 ||\n",
      "val: {'recall': 0.995221, 'recall_grapheme': 0.993355, 'recall_vowel': 0.997424, 'recall_consonant': 0.996749, 'recall_word': 0.993641, 'acc_grapheme': 0.993788, 'acc_vowel': 0.997615, 'acc_consonant': 0.997615, 'acc_word': 0.993713, 'loss_grapheme': 0.220856, 'loss_vowel': 0.114194, 'loss_consonant': 0.084065, 'loss_word': 0.150278}\n",
      "   40 | 0.000072 | 160000/160596 | 14.2194 | 9.5740 ||\n",
      "val: {'recall': 0.995087, 'recall_grapheme': 0.993552, 'recall_vowel': 0.997595, 'recall_consonant': 0.995647, 'recall_word': 0.993955, 'acc_grapheme': 0.994235, 'acc_vowel': 0.997987, 'acc_consonant': 0.997764, 'acc_word': 0.994036, 'loss_grapheme': 0.211166, 'loss_vowel': 0.131533, 'loss_consonant': 0.090275, 'loss_word': 0.13112}\n",
      "   41 | 0.000069 | 160000/160596 | 1.8985 | 9.8700 |||\n",
      "val: {'recall': 0.996207, 'recall_grapheme': 0.995104, 'recall_vowel': 0.998276, 'recall_consonant': 0.996345, 'recall_word': 0.994507, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998385, 'acc_consonant': 0.998037, 'acc_word': 0.994558, 'loss_grapheme': 0.159376, 'loss_vowel': 0.10012, 'loss_consonant': 0.06849, 'loss_word': 0.113265}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###>>>>> saved\n",
      "   42 | 0.000066 | 160000/160596 | 3.6289 | 10.0790 ||\n",
      "val: {'recall': 0.995378, 'recall_grapheme': 0.993991, 'recall_vowel': 0.99773, 'recall_consonant': 0.995801, 'recall_word': 0.994396, 'acc_grapheme': 0.994359, 'acc_vowel': 0.998161, 'acc_consonant': 0.997913, 'acc_word': 0.994434, 'loss_grapheme': 0.201855, 'loss_vowel': 0.120582, 'loss_consonant': 0.08279, 'loss_word': 0.130497}\n",
      "   43 | 0.000063 | 160000/160596 | 3.2498 | 10.3223 ||\n",
      "val: {'recall': 0.995013, 'recall_grapheme': 0.993752, 'recall_vowel': 0.997033, 'recall_consonant': 0.995512, 'recall_word': 0.993677, 'acc_grapheme': 0.994036, 'acc_vowel': 0.997565, 'acc_consonant': 0.997639, 'acc_word': 0.993763, 'loss_grapheme': 0.219137, 'loss_vowel': 0.132844, 'loss_consonant': 0.091363, 'loss_word': 0.139311}\n",
      "   44 | 0.000060 | 160000/160596 | 17.1036 | 10.1444 |\n",
      "val: {'recall': 0.995154, 'recall_grapheme': 0.993548, 'recall_vowel': 0.997715, 'recall_consonant': 0.995803, 'recall_word': 0.993558, 'acc_grapheme': 0.993589, 'acc_vowel': 0.997739, 'acc_consonant': 0.997689, 'acc_word': 0.993713, 'loss_grapheme': 0.236329, 'loss_vowel': 0.144311, 'loss_consonant': 0.100021, 'loss_word': 0.15328}\n",
      "   45 | 0.000058 | 160000/160596 | 17.8874 | 9.7105 ||\n",
      "val: {'recall': 0.995232, 'recall_grapheme': 0.992978, 'recall_vowel': 0.997546, 'recall_consonant': 0.997427, 'recall_word': 0.992942, 'acc_grapheme': 0.993763, 'acc_vowel': 0.99749, 'acc_consonant': 0.99759, 'acc_word': 0.993067, 'loss_grapheme': 0.253769, 'loss_vowel': 0.128275, 'loss_consonant': 0.10084, 'loss_word': 0.171815}\n",
      "   46 | 0.000055 | 160000/160596 | 12.5638 | 10.4523 |\n",
      "val: {'recall': 0.995246, 'recall_grapheme': 0.993169, 'recall_vowel': 0.997497, 'recall_consonant': 0.99715, 'recall_word': 0.992675, 'acc_grapheme': 0.993664, 'acc_vowel': 0.99754, 'acc_consonant': 0.997391, 'acc_word': 0.992819, 'loss_grapheme': 0.25488, 'loss_vowel': 0.133671, 'loss_consonant': 0.09884, 'loss_word': 0.177169}\n",
      "   47 | 0.000052 | 160000/160596 | 7.2229 | 10.2492 ||\n",
      "val: {'recall': 0.995126, 'recall_grapheme': 0.993399, 'recall_vowel': 0.997571, 'recall_consonant': 0.996135, 'recall_word': 0.993676, 'acc_grapheme': 0.994285, 'acc_vowel': 0.997813, 'acc_consonant': 0.997714, 'acc_word': 0.993713, 'loss_grapheme': 0.269112, 'loss_vowel': 0.137006, 'loss_consonant': 0.101236, 'loss_word': 0.19391}\n",
      "   48 | 0.000049 | 160000/160596 | 8.4898 | 9.4444 ||\n",
      "val: {'recall': 0.995409, 'recall_grapheme': 0.99399, 'recall_vowel': 0.997358, 'recall_consonant': 0.996297, 'recall_word': 0.993658, 'acc_grapheme': 0.994533, 'acc_vowel': 0.997615, 'acc_consonant': 0.997788, 'acc_word': 0.993713, 'loss_grapheme': 0.219817, 'loss_vowel': 0.119845, 'loss_consonant': 0.087775, 'loss_word': 0.14891}\n",
      "   49 | 0.000046 | 160000/160596 | 15.9356 | 9.9087 ||\n",
      "val: {'recall': 0.996216, 'recall_grapheme': 0.995081, 'recall_vowel': 0.997548, 'recall_consonant': 0.997153, 'recall_word': 0.994, 'acc_grapheme': 0.994881, 'acc_vowel': 0.997813, 'acc_consonant': 0.997987, 'acc_word': 0.994061, 'loss_grapheme': 0.230132, 'loss_vowel': 0.118812, 'loss_consonant': 0.089296, 'loss_word': 0.161292}\n",
      "###>>>>> saved\n",
      "   50 | 0.000044 | 160000/160596 | 14.1984 | 9.8678 ||\n",
      "val: {'recall': 0.995488, 'recall_grapheme': 0.994049, 'recall_vowel': 0.997541, 'recall_consonant': 0.996312, 'recall_word': 0.994201, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997863, 'acc_consonant': 0.997962, 'acc_word': 0.99426, 'loss_grapheme': 0.241089, 'loss_vowel': 0.142868, 'loss_consonant': 0.102709, 'loss_word': 0.150062}\n",
      "   51 | 0.000041 | 160000/160596 | 9.1474 | 9.6070 |||\n",
      "val: {'recall': 0.995778, 'recall_grapheme': 0.994046, 'recall_vowel': 0.997703, 'recall_consonant': 0.997316, 'recall_word': 0.993935, 'acc_grapheme': 0.994285, 'acc_vowel': 0.997962, 'acc_consonant': 0.997888, 'acc_word': 0.993937, 'loss_grapheme': 0.167626, 'loss_vowel': 0.100755, 'loss_consonant': 0.075235, 'loss_word': 0.115495}\n",
      "   52 | 0.000038 | 160000/160596 | 8.2071 | 9.8426 |||\n",
      "val: {'recall': 0.995549, 'recall_grapheme': 0.993401, 'recall_vowel': 0.997818, 'recall_consonant': 0.997576, 'recall_word': 0.993668, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997913, 'acc_consonant': 0.997938, 'acc_word': 0.993763, 'loss_grapheme': 0.245382, 'loss_vowel': 0.146809, 'loss_consonant': 0.102312, 'loss_word': 0.156711}\n",
      "   53 | 0.000036 | 160000/160596 | 8.4110 | 9.9345 |||\n",
      "val: {'recall': 0.995999, 'recall_grapheme': 0.994293, 'recall_vowel': 0.997698, 'recall_consonant': 0.99771, 'recall_word': 0.994276, 'acc_grapheme': 0.994856, 'acc_vowel': 0.997788, 'acc_consonant': 0.998136, 'acc_word': 0.99431, 'loss_grapheme': 0.241097, 'loss_vowel': 0.131182, 'loss_consonant': 0.1008, 'loss_word': 0.158438}\n",
      "   54 | 0.000033 | 160000/160596 | 8.7111 | 9.6959 |||\n",
      "val: {'recall': 0.996015, 'recall_grapheme': 0.994448, 'recall_vowel': 0.997715, 'recall_consonant': 0.997448, 'recall_word': 0.994027, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997888, 'acc_consonant': 0.997838, 'acc_word': 0.994012, 'loss_grapheme': 0.231229, 'loss_vowel': 0.128686, 'loss_consonant': 0.095142, 'loss_word': 0.155229}\n",
      "   55 | 0.000031 | 160000/160596 | 7.5763 | 9.5854 ||\n",
      "val: {'recall': 0.995874, 'recall_grapheme': 0.994173, 'recall_vowel': 0.997776, 'recall_consonant': 0.997373, 'recall_word': 0.993848, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997888, 'acc_consonant': 0.997938, 'acc_word': 0.993912, 'loss_grapheme': 0.226452, 'loss_vowel': 0.112941, 'loss_consonant': 0.088896, 'loss_word': 0.155492}\n",
      "   56 | 0.000029 | 160000/160596 | 2.3569 | 10.2106 ||\n",
      "val: {'recall': 0.996494, 'recall_grapheme': 0.995089, 'recall_vowel': 0.99807, 'recall_consonant': 0.997726, 'recall_word': 0.994632, 'acc_grapheme': 0.995055, 'acc_vowel': 0.998211, 'acc_consonant': 0.998236, 'acc_word': 0.994682, 'loss_grapheme': 0.159156, 'loss_vowel': 0.100424, 'loss_consonant': 0.069257, 'loss_word': 0.10498}\n",
      "###>>>>> saved\n",
      "   57 | 0.000026 | 160000/160596 | 6.1031 | 9.5540 |||\n",
      "val: {'recall': 0.996033, 'recall_grapheme': 0.994194, 'recall_vowel': 0.998123, 'recall_consonant': 0.997622, 'recall_word': 0.994156, 'acc_grapheme': 0.994682, 'acc_vowel': 0.998136, 'acc_consonant': 0.998136, 'acc_word': 0.994235, 'loss_grapheme': 0.177877, 'loss_vowel': 0.106403, 'loss_consonant': 0.074563, 'loss_word': 0.126762}\n",
      "   58 | 0.000024 | 160000/160596 | 1.9538 | 9.2801 ||\n",
      "val: {'recall': 0.996001, 'recall_grapheme': 0.994312, 'recall_vowel': 0.997808, 'recall_consonant': 0.997573, 'recall_word': 0.99372, 'acc_grapheme': 0.994558, 'acc_vowel': 0.997962, 'acc_consonant': 0.997863, 'acc_word': 0.993713, 'loss_grapheme': 0.229633, 'loss_vowel': 0.116631, 'loss_consonant': 0.089826, 'loss_word': 0.162297}\n",
      "   59 | 0.000022 | 160000/160596 | 16.9664 | 9.4408 ||\n",
      "val: {'recall': 0.996001, 'recall_grapheme': 0.994161, 'recall_vowel': 0.998061, 'recall_consonant': 0.997622, 'recall_word': 0.994207, 'acc_grapheme': 0.994583, 'acc_vowel': 0.998062, 'acc_consonant': 0.998012, 'acc_word': 0.994235, 'loss_grapheme': 0.2087, 'loss_vowel': 0.126431, 'loss_consonant': 0.091224, 'loss_word': 0.134723}\n",
      "   60 | 0.000020 | 160000/160596 | 5.9501 | 9.9699 | |\n",
      "val: {'recall': 0.996065, 'recall_grapheme': 0.99439, 'recall_vowel': 0.997836, 'recall_consonant': 0.997646, 'recall_word': 0.99468, 'acc_grapheme': 0.994881, 'acc_vowel': 0.998087, 'acc_consonant': 0.997987, 'acc_word': 0.994732, 'loss_grapheme': 0.207494, 'loss_vowel': 0.119772, 'loss_consonant': 0.084022, 'loss_word': 0.136156}\n",
      "   61 | 0.000018 | 160000/160596 | 7.4896 | 9.4325 |||\n",
      "val: {'recall': 0.995734, 'recall_grapheme': 0.994049, 'recall_vowel': 0.997551, 'recall_consonant': 0.997288, 'recall_word': 0.994277, 'acc_grapheme': 0.99421, 'acc_vowel': 0.997987, 'acc_consonant': 0.998037, 'acc_word': 0.994335, 'loss_grapheme': 0.239658, 'loss_vowel': 0.16302, 'loss_consonant': 0.111938, 'loss_word': 0.136634}\n",
      "   62 | 0.000016 | 160000/160596 | 5.3766 | 9.3104 ||\n",
      "val: {'recall': 0.996035, 'recall_grapheme': 0.994305, 'recall_vowel': 0.997955, 'recall_consonant': 0.997574, 'recall_word': 0.994205, 'acc_grapheme': 0.994409, 'acc_vowel': 0.998161, 'acc_consonant': 0.998012, 'acc_word': 0.994285, 'loss_grapheme': 0.222332, 'loss_vowel': 0.130189, 'loss_consonant': 0.092579, 'loss_word': 0.139997}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   63 | 0.000014 | 160000/160596 | 6.7829 | 10.0811 ||\n",
      "val: {'recall': 0.996168, 'recall_grapheme': 0.994447, 'recall_vowel': 0.998185, 'recall_consonant': 0.997596, 'recall_word': 0.994998, 'acc_grapheme': 0.994906, 'acc_vowel': 0.998161, 'acc_consonant': 0.998012, 'acc_word': 0.99508, 'loss_grapheme': 0.210053, 'loss_vowel': 0.127437, 'loss_consonant': 0.089812, 'loss_word': 0.126097}\n",
      "   64 | 0.000013 | 160000/160596 | 15.3425 | 9.8944 ||\n",
      "val: {'recall': 0.995717, 'recall_grapheme': 0.99376, 'recall_vowel': 0.997936, 'recall_consonant': 0.997409, 'recall_word': 0.994176, 'acc_grapheme': 0.994533, 'acc_vowel': 0.997962, 'acc_consonant': 0.997689, 'acc_word': 0.99421, 'loss_grapheme': 0.2582, 'loss_vowel': 0.135459, 'loss_consonant': 0.102781, 'loss_word': 0.17121}\n",
      "   65 | 0.000011 | 160000/160596 | 13.5563 | 10.0860 |\n",
      "val: {'recall': 0.995152, 'recall_grapheme': 0.993505, 'recall_vowel': 0.997803, 'recall_consonant': 0.995795, 'recall_word': 0.994141, 'acc_grapheme': 0.994235, 'acc_vowel': 0.998012, 'acc_consonant': 0.997764, 'acc_word': 0.99421, 'loss_grapheme': 0.239389, 'loss_vowel': 0.152107, 'loss_consonant': 0.107952, 'loss_word': 0.139704}\n",
      "   66 | 0.000010 | 160000/160596 | 16.0102 | 9.5907 ||\n",
      "val: {'recall': 0.995861, 'recall_grapheme': 0.994081, 'recall_vowel': 0.997821, 'recall_consonant': 0.997461, 'recall_word': 0.994089, 'acc_grapheme': 0.994508, 'acc_vowel': 0.997888, 'acc_consonant': 0.997863, 'acc_word': 0.994161, 'loss_grapheme': 0.214847, 'loss_vowel': 0.127491, 'loss_consonant': 0.090371, 'loss_word': 0.135794}\n",
      "   67 | 0.000008 | 160000/160596 | 13.5252 | 9.1074 ||\n",
      "val: {'recall': 0.996017, 'recall_grapheme': 0.994158, 'recall_vowel': 0.998069, 'recall_consonant': 0.997683, 'recall_word': 0.994466, 'acc_grapheme': 0.994732, 'acc_vowel': 0.998136, 'acc_consonant': 0.998062, 'acc_word': 0.994558, 'loss_grapheme': 0.231048, 'loss_vowel': 0.145016, 'loss_consonant': 0.102813, 'loss_word': 0.135555}\n",
      "   68 | 0.000007 | 160000/160596 | 16.0670 | 9.8386 ||\n",
      "val: {'recall': 0.995819, 'recall_grapheme': 0.993944, 'recall_vowel': 0.99781, 'recall_consonant': 0.997578, 'recall_word': 0.994365, 'acc_grapheme': 0.994608, 'acc_vowel': 0.998062, 'acc_consonant': 0.997938, 'acc_word': 0.994459, 'loss_grapheme': 0.220703, 'loss_vowel': 0.13762, 'loss_consonant': 0.098585, 'loss_word': 0.129306}\n",
      "   69 | 0.000006 | 160000/160596 | 14.8498 | 9.5082 ||\n",
      "val: {'recall': 0.995999, 'recall_grapheme': 0.994232, 'recall_vowel': 0.99807, 'recall_consonant': 0.997461, 'recall_word': 0.99419, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998136, 'acc_consonant': 0.997863, 'acc_word': 0.994285, 'loss_grapheme': 0.228684, 'loss_vowel': 0.142139, 'loss_consonant': 0.102657, 'loss_word': 0.138139}\n",
      "   70 | 0.000005 | 160000/160596 | 13.9738 | 9.8213 ||\n",
      "val: {'recall': 0.99603, 'recall_grapheme': 0.994162, 'recall_vowel': 0.998233, 'recall_consonant': 0.997563, 'recall_word': 0.994598, 'acc_grapheme': 0.994508, 'acc_vowel': 0.998211, 'acc_consonant': 0.997987, 'acc_word': 0.994658, 'loss_grapheme': 0.226857, 'loss_vowel': 0.13965, 'loss_consonant': 0.099332, 'loss_word': 0.138062}\n",
      "   71 | 0.000004 | 160000/160596 | 5.2766 | 9.0934 ||\n",
      "val: {'recall': 0.996322, 'recall_grapheme': 0.994878, 'recall_vowel': 0.997833, 'recall_consonant': 0.997697, 'recall_word': 0.994726, 'acc_grapheme': 0.995279, 'acc_vowel': 0.99836, 'acc_consonant': 0.998087, 'acc_word': 0.994807, 'loss_grapheme': 0.142766, 'loss_vowel': 0.08795, 'loss_consonant': 0.059664, 'loss_word': 0.09945}\n",
      "   72 | 0.000003 | 160000/160596 | 17.0197 | 9.3247 ||\n",
      "val: {'recall': 0.995972, 'recall_grapheme': 0.994266, 'recall_vowel': 0.997657, 'recall_consonant': 0.997701, 'recall_word': 0.994418, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998062, 'acc_consonant': 0.998012, 'acc_word': 0.994508, 'loss_grapheme': 0.189116, 'loss_vowel': 0.118448, 'loss_consonant': 0.082441, 'loss_word': 0.115126}\n",
      "   73 | 0.000002 | 160000/160596 | 16.9143 | 9.3825 |\n",
      "val: {'recall': 0.995936, 'recall_grapheme': 0.994214, 'recall_vowel': 0.998005, 'recall_consonant': 0.997312, 'recall_word': 0.994193, 'acc_grapheme': 0.994707, 'acc_vowel': 0.998062, 'acc_consonant': 0.997813, 'acc_word': 0.99421, 'loss_grapheme': 0.200154, 'loss_vowel': 0.111788, 'loss_consonant': 0.083124, 'loss_word': 0.134036}\n",
      "   74 | 0.000001 | 160000/160596 | 10.6687 | 10.1763 |\n",
      "val: {'recall': 0.995808, 'recall_grapheme': 0.99395, 'recall_vowel': 0.997791, 'recall_consonant': 0.997539, 'recall_word': 0.994132, 'acc_grapheme': 0.994583, 'acc_vowel': 0.998062, 'acc_consonant': 0.997888, 'acc_word': 0.994185, 'loss_grapheme': 0.215035, 'loss_vowel': 0.127875, 'loss_consonant': 0.090882, 'loss_word': 0.13523}\n",
      "   75 | 0.000001 | 160000/160596 | 8.7196 | 10.1983 ||\n",
      "val: {'recall': 0.995603, 'recall_grapheme': 0.993852, 'recall_vowel': 0.997637, 'recall_consonant': 0.99707, 'recall_word': 0.993495, 'acc_grapheme': 0.994285, 'acc_vowel': 0.997838, 'acc_consonant': 0.997788, 'acc_word': 0.993564, 'loss_grapheme': 0.203053, 'loss_vowel': 0.11025, 'loss_consonant': 0.085629, 'loss_word': 0.137454}\n",
      "   76 | 0.000001 | 160000/160596 | 9.3985 | 9.5478 |||\n",
      "val: {'recall': 0.996196, 'recall_grapheme': 0.994757, 'recall_vowel': 0.997759, 'recall_consonant': 0.997509, 'recall_word': 0.994129, 'acc_grapheme': 0.994881, 'acc_vowel': 0.998012, 'acc_consonant': 0.997863, 'acc_word': 0.994136, 'loss_grapheme': 0.173108, 'loss_vowel': 0.094913, 'loss_consonant': 0.07509, 'loss_word': 0.113593}\n",
      "   77 | 0.000000 | 160000/160596 | 4.5223 | 9.2633 |||\n",
      "val: {'recall': 0.996014, 'recall_grapheme': 0.99424, 'recall_vowel': 0.99807, 'recall_consonant': 0.997507, 'recall_word': 0.994317, 'acc_grapheme': 0.994757, 'acc_vowel': 0.998285, 'acc_consonant': 0.997863, 'acc_word': 0.994384, 'loss_grapheme': 0.188333, 'loss_vowel': 0.108369, 'loss_consonant': 0.07663, 'loss_word': 0.126458}\n",
      "   78 | 0.000000 | 160000/160596 | 6.0160 | 9.3796 ||\n",
      "val: {'recall': 0.996029, 'recall_grapheme': 0.994334, 'recall_vowel': 0.997928, 'recall_consonant': 0.997518, 'recall_word': 0.994118, 'acc_grapheme': 0.994782, 'acc_vowel': 0.998037, 'acc_consonant': 0.997913, 'acc_word': 0.994161, 'loss_grapheme': 0.197873, 'loss_vowel': 0.111129, 'loss_consonant': 0.082169, 'loss_word': 0.128693}\n",
      "   79 | 0.000000 | 160000/160596 | 1.0995 | 9.4272 |||\n",
      "val: {'recall': 0.996612, 'recall_grapheme': 0.995372, 'recall_vowel': 0.998122, 'recall_consonant': 0.997582, 'recall_word': 0.994852, 'acc_grapheme': 0.995304, 'acc_vowel': 0.99836, 'acc_consonant': 0.998037, 'acc_word': 0.994931, 'loss_grapheme': 0.141336, 'loss_vowel': 0.091665, 'loss_consonant': 0.06416, 'loss_word': 0.091894}\n",
      "###>>>>> saved\n",
      "CYCLE: 2\n",
      "{'recall': 0.996612, 'recall_grapheme': 0.995372, 'recall_vowel': 0.998122, 'recall_consonant': 0.997582, 'recall_word': 0.994852, 'acc_grapheme': 0.995304, 'acc_vowel': 0.99836, 'acc_consonant': 0.998037, 'acc_word': 0.994931, 'loss_grapheme': 0.141336, 'loss_vowel': 0.091665, 'loss_consonant': 0.06416, 'loss_word': 0.091894}\n",
      "    0 | 0.000030 | 160000/160596 | 7.5162 | 9.6690 |||\n",
      "val: {'recall': 0.996352, 'recall_grapheme': 0.994886, 'recall_vowel': 0.998105, 'recall_consonant': 0.997529, 'recall_word': 0.994691, 'acc_grapheme': 0.99503, 'acc_vowel': 0.998335, 'acc_consonant': 0.998087, 'acc_word': 0.994732, 'loss_grapheme': 0.213318, 'loss_vowel': 0.121342, 'loss_consonant': 0.086811, 'loss_word': 0.137806}\n",
      "    1 | 0.000060 | 160000/160596 | 13.1989 | 9.4805 ||\n",
      "val: {'recall': 0.995811, 'recall_grapheme': 0.994085, 'recall_vowel': 0.997481, 'recall_consonant': 0.997591, 'recall_word': 0.994166, 'acc_grapheme': 0.994508, 'acc_vowel': 0.998037, 'acc_consonant': 0.997987, 'acc_word': 0.994235, 'loss_grapheme': 0.235313, 'loss_vowel': 0.131455, 'loss_consonant': 0.092566, 'loss_word': 0.153159}\n",
      "    2 | 0.000090 | 160000/160596 | 5.8576 | 9.4557 |||\n",
      "val: {'recall': 0.996046, 'recall_grapheme': 0.994483, 'recall_vowel': 0.997498, 'recall_consonant': 0.997718, 'recall_word': 0.993858, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997938, 'acc_consonant': 0.997987, 'acc_word': 0.993887, 'loss_grapheme': 0.185026, 'loss_vowel': 0.107517, 'loss_consonant': 0.073468, 'loss_word': 0.126274}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 | 0.000119 | 160000/160596 | 8.6064 | 9.8559 |||\n",
      "val: {'recall': 0.99537, 'recall_grapheme': 0.993429, 'recall_vowel': 0.997194, 'recall_consonant': 0.997426, 'recall_word': 0.993629, 'acc_grapheme': 0.993912, 'acc_vowel': 0.997764, 'acc_consonant': 0.997838, 'acc_word': 0.993689, 'loss_grapheme': 0.19278, 'loss_vowel': 0.127564, 'loss_consonant': 0.092346, 'loss_word': 0.11302}\n",
      "    4 | 0.000148 | 160000/160596 | 3.8305 | 9.9229 |||\n",
      "val: {'recall': 0.994928, 'recall_grapheme': 0.993169, 'recall_vowel': 0.997291, 'recall_consonant': 0.996082, 'recall_word': 0.993215, 'acc_grapheme': 0.99349, 'acc_vowel': 0.997739, 'acc_consonant': 0.99754, 'acc_word': 0.993241, 'loss_grapheme': 0.168983, 'loss_vowel': 0.110529, 'loss_consonant': 0.074026, 'loss_word': 0.115751}\n",
      "    5 | 0.000148 | 160000/160596 | 6.2714 | 9.6942 |||\n",
      "val: {'recall': 0.995385, 'recall_grapheme': 0.993339, 'recall_vowel': 0.997762, 'recall_consonant': 0.997102, 'recall_word': 0.993981, 'acc_grapheme': 0.993639, 'acc_vowel': 0.997938, 'acc_consonant': 0.997714, 'acc_word': 0.994012, 'loss_grapheme': 0.196064, 'loss_vowel': 0.12988, 'loss_consonant': 0.086489, 'loss_word': 0.118903}\n",
      "    6 | 0.000147 | 160000/160596 | 6.2702 | 9.5970 |||\n",
      "val: {'recall': 0.995205, 'recall_grapheme': 0.993463, 'recall_vowel': 0.997328, 'recall_consonant': 0.996565, 'recall_word': 0.992606, 'acc_grapheme': 0.993838, 'acc_vowel': 0.997615, 'acc_consonant': 0.997142, 'acc_word': 0.992719, 'loss_grapheme': 0.143389, 'loss_vowel': 0.086397, 'loss_consonant': 0.062039, 'loss_word': 0.102237}\n",
      "    7 | 0.000146 | 160000/160596 | 5.3290 | 9.2297 |||\n",
      "val: {'recall': 0.995254, 'recall_grapheme': 0.993211, 'recall_vowel': 0.99746, 'recall_consonant': 0.997133, 'recall_word': 0.993454, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997689, 'acc_consonant': 0.997689, 'acc_word': 0.993515, 'loss_grapheme': 0.207582, 'loss_vowel': 0.123536, 'loss_consonant': 0.092373, 'loss_word': 0.125751}\n",
      "    8 | 0.000145 | 160000/160596 | 6.8970 | 10.0109 ||\n",
      "val: {'recall': 0.995651, 'recall_grapheme': 0.993878, 'recall_vowel': 0.997427, 'recall_consonant': 0.99742, 'recall_word': 0.993991, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997714, 'acc_consonant': 0.997714, 'acc_word': 0.994036, 'loss_grapheme': 0.262506, 'loss_vowel': 0.137251, 'loss_consonant': 0.102966, 'loss_word': 0.167188}\n",
      "    9 | 0.000144 | 160000/160596 | 5.8301 | 9.8908 |||\n",
      "val: {'recall': 0.995688, 'recall_grapheme': 0.993774, 'recall_vowel': 0.997862, 'recall_consonant': 0.997342, 'recall_word': 0.994129, 'acc_grapheme': 0.994782, 'acc_vowel': 0.997838, 'acc_consonant': 0.997764, 'acc_word': 0.994285, 'loss_grapheme': 0.225101, 'loss_vowel': 0.138098, 'loss_consonant': 0.096892, 'loss_word': 0.14176}\n",
      "   10 | 0.000143 | 160000/160596 | 6.9627 | 9.3542 ||\n",
      "val: {'recall': 0.995159, 'recall_grapheme': 0.992898, 'recall_vowel': 0.997549, 'recall_consonant': 0.997292, 'recall_word': 0.99287, 'acc_grapheme': 0.99344, 'acc_vowel': 0.997391, 'acc_consonant': 0.997465, 'acc_word': 0.992918, 'loss_grapheme': 0.159391, 'loss_vowel': 0.093167, 'loss_consonant': 0.067916, 'loss_word': 0.10626}\n",
      "   11 | 0.000142 | 160000/160596 | 5.0258 | 9.6370 |||\n",
      "val: {'recall': 0.995446, 'recall_grapheme': 0.993617, 'recall_vowel': 0.997686, 'recall_consonant': 0.996863, 'recall_word': 0.994006, 'acc_grapheme': 0.994335, 'acc_vowel': 0.997689, 'acc_consonant': 0.997987, 'acc_word': 0.994036, 'loss_grapheme': 0.223783, 'loss_vowel': 0.134158, 'loss_consonant': 0.093708, 'loss_word': 0.139015}\n",
      "   12 | 0.000140 | 160000/160596 | 8.9670 | 9.2498 |||\n",
      "val: {'recall': 0.99542, 'recall_grapheme': 0.99419, 'recall_vowel': 0.997233, 'recall_consonant': 0.996067, 'recall_word': 0.994091, 'acc_grapheme': 0.994583, 'acc_vowel': 0.997764, 'acc_consonant': 0.997987, 'acc_word': 0.994136, 'loss_grapheme': 0.185405, 'loss_vowel': 0.112632, 'loss_consonant': 0.075557, 'loss_word': 0.127313}\n",
      "   13 | 0.000139 | 160000/160596 | 8.2454 | 9.0179 |||\n",
      "val: {'recall': 0.995541, 'recall_grapheme': 0.993554, 'recall_vowel': 0.997525, 'recall_consonant': 0.997531, 'recall_word': 0.994077, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997962, 'acc_consonant': 0.997913, 'acc_word': 0.994086, 'loss_grapheme': 0.224535, 'loss_vowel': 0.143419, 'loss_consonant': 0.100089, 'loss_word': 0.137541}\n",
      "   14 | 0.000137 | 160000/160596 | 14.3449 | 9.5041 ||\n",
      "val: {'recall': 0.994336, 'recall_grapheme': 0.991709, 'recall_vowel': 0.997275, 'recall_consonant': 0.99665, 'recall_word': 0.992258, 'acc_grapheme': 0.992844, 'acc_vowel': 0.997292, 'acc_consonant': 0.997714, 'acc_word': 0.992421, 'loss_grapheme': 0.254924, 'loss_vowel': 0.148172, 'loss_consonant': 0.111228, 'loss_word': 0.161019}\n",
      "   15 | 0.000136 | 160000/160596 | 15.9764 | 9.7676 ||\n",
      "val: {'recall': 0.99514, 'recall_grapheme': 0.99345, 'recall_vowel': 0.997445, 'recall_consonant': 0.996215, 'recall_word': 0.994007, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997962, 'acc_consonant': 0.997764, 'acc_word': 0.994086, 'loss_grapheme': 0.222851, 'loss_vowel': 0.123177, 'loss_consonant': 0.090073, 'loss_word': 0.133595}\n",
      "   16 | 0.000134 | 160000/160596 | 7.1524 | 9.3554 |||\n",
      "val: {'recall': 0.996025, 'recall_grapheme': 0.994115, 'recall_vowel': 0.998259, 'recall_consonant': 0.997611, 'recall_word': 0.994298, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998186, 'acc_consonant': 0.997987, 'acc_word': 0.994335, 'loss_grapheme': 0.225303, 'loss_vowel': 0.11448, 'loss_consonant': 0.090028, 'loss_word': 0.133095}\n",
      "   17 | 0.000132 | 160000/160596 | 8.3640 | 9.4934 ||\n",
      "val: {'recall': 0.995848, 'recall_grapheme': 0.994151, 'recall_vowel': 0.997529, 'recall_consonant': 0.997561, 'recall_word': 0.99411, 'acc_grapheme': 0.99431, 'acc_vowel': 0.997938, 'acc_consonant': 0.997863, 'acc_word': 0.994235, 'loss_grapheme': 0.232157, 'loss_vowel': 0.155408, 'loss_consonant': 0.110764, 'loss_word': 0.125633}\n",
      "   18 | 0.000130 | 160000/160596 | 14.1183 | 9.5801 ||\n",
      "val: {'recall': 0.9959, 'recall_grapheme': 0.994369, 'recall_vowel': 0.997287, 'recall_consonant': 0.997576, 'recall_word': 0.993508, 'acc_grapheme': 0.993862, 'acc_vowel': 0.997813, 'acc_consonant': 0.997863, 'acc_word': 0.99349, 'loss_grapheme': 0.180648, 'loss_vowel': 0.114761, 'loss_consonant': 0.080854, 'loss_word': 0.115549}\n",
      "   19 | 0.000128 | 160000/160596 | 5.6797 | 9.3254 |||\n",
      "val: {'recall': 0.995434, 'recall_grapheme': 0.993874, 'recall_vowel': 0.997729, 'recall_consonant': 0.996257, 'recall_word': 0.99438, 'acc_grapheme': 0.994832, 'acc_vowel': 0.997913, 'acc_consonant': 0.997913, 'acc_word': 0.994359, 'loss_grapheme': 0.219132, 'loss_vowel': 0.131558, 'loss_consonant': 0.093306, 'loss_word': 0.140068}\n",
      "   20 | 0.000126 | 160000/160596 | 15.8697 | 9.5645 ||\n",
      "val: {'recall': 0.995607, 'recall_grapheme': 0.994141, 'recall_vowel': 0.997108, 'recall_consonant': 0.997039, 'recall_word': 0.993777, 'acc_grapheme': 0.994409, 'acc_vowel': 0.997689, 'acc_consonant': 0.997913, 'acc_word': 0.993887, 'loss_grapheme': 0.251186, 'loss_vowel': 0.136581, 'loss_consonant': 0.104065, 'loss_word': 0.158185}\n",
      "   21 | 0.000124 | 160000/160596 | 9.2174 | 9.5065 |||\n",
      "val: {'recall': 0.994572, 'recall_grapheme': 0.992738, 'recall_vowel': 0.997109, 'recall_consonant': 0.995701, 'recall_word': 0.99402, 'acc_grapheme': 0.993713, 'acc_vowel': 0.997639, 'acc_consonant': 0.997813, 'acc_word': 0.994036, 'loss_grapheme': 0.187767, 'loss_vowel': 0.116553, 'loss_consonant': 0.080272, 'loss_word': 0.110282}\n",
      "   22 | 0.000121 | 160000/160596 | 12.6370 | 9.5891 ||\n",
      "val: {'recall': 0.995641, 'recall_grapheme': 0.99359, 'recall_vowel': 0.997861, 'recall_consonant': 0.997521, 'recall_word': 0.994022, 'acc_grapheme': 0.994235, 'acc_vowel': 0.997962, 'acc_consonant': 0.997813, 'acc_word': 0.994036, 'loss_grapheme': 0.25048, 'loss_vowel': 0.130083, 'loss_consonant': 0.095209, 'loss_word': 0.155501}\n",
      "   23 | 0.000119 | 160000/160596 | 6.6404 | 9.1798 |||\n",
      "val: {'recall': 0.995802, 'recall_grapheme': 0.994297, 'recall_vowel': 0.997279, 'recall_consonant': 0.997335, 'recall_word': 0.994013, 'acc_grapheme': 0.994409, 'acc_vowel': 0.997888, 'acc_consonant': 0.997987, 'acc_word': 0.993987, 'loss_grapheme': 0.192343, 'loss_vowel': 0.112996, 'loss_consonant': 0.081457, 'loss_word': 0.122535}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 0.000117 | 160000/160596 | 10.1707 | 9.4029 ||\n",
      "val: {'recall': 0.995231, 'recall_grapheme': 0.993279, 'recall_vowel': 0.997045, 'recall_consonant': 0.99732, 'recall_word': 0.993024, 'acc_grapheme': 0.993862, 'acc_vowel': 0.997267, 'acc_consonant': 0.997838, 'acc_word': 0.992993, 'loss_grapheme': 0.243026, 'loss_vowel': 0.143282, 'loss_consonant': 0.107101, 'loss_word': 0.146342}\n",
      "   25 | 0.000114 | 160000/160596 | 3.6174 | 9.6174 |||\n",
      "val: {'recall': 0.99578, 'recall_grapheme': 0.993985, 'recall_vowel': 0.997721, 'recall_consonant': 0.99743, 'recall_word': 0.993852, 'acc_grapheme': 0.994533, 'acc_vowel': 0.997714, 'acc_consonant': 0.998062, 'acc_word': 0.993862, 'loss_grapheme': 0.232283, 'loss_vowel': 0.128963, 'loss_consonant': 0.092051, 'loss_word': 0.143839}\n",
      "   26 | 0.000112 | 160000/160596 | 15.3239 | 9.0249 ||\n",
      "val: {'recall': 0.996352, 'recall_grapheme': 0.994872, 'recall_vowel': 0.997761, 'recall_consonant': 0.997902, 'recall_word': 0.994711, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998112, 'acc_consonant': 0.998285, 'acc_word': 0.994732, 'loss_grapheme': 0.201739, 'loss_vowel': 0.118657, 'loss_consonant': 0.078846, 'loss_word': 0.124154}\n",
      "   27 | 0.000109 | 160000/160596 | 7.2169 | 8.5508 ||\n",
      "val: {'recall': 0.99627, 'recall_grapheme': 0.994845, 'recall_vowel': 0.997663, 'recall_consonant': 0.997727, 'recall_word': 0.994622, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998136, 'acc_consonant': 0.998186, 'acc_word': 0.994658, 'loss_grapheme': 0.156767, 'loss_vowel': 0.097187, 'loss_consonant': 0.068101, 'loss_word': 0.09933}\n",
      "   28 | 0.000106 | 160000/160596 | 2.6494 | 9.1519 |||\n",
      "val: {'recall': 0.995766, 'recall_grapheme': 0.994115, 'recall_vowel': 0.997624, 'recall_consonant': 0.997209, 'recall_word': 0.993968, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997714, 'acc_consonant': 0.998037, 'acc_word': 0.994012, 'loss_grapheme': 0.168434, 'loss_vowel': 0.098242, 'loss_consonant': 0.072566, 'loss_word': 0.113943}\n",
      "   29 | 0.000104 | 160000/160596 | 12.7002 | 9.1203 |\n",
      "val: {'recall': 0.995119, 'recall_grapheme': 0.993783, 'recall_vowel': 0.997618, 'recall_consonant': 0.99529, 'recall_word': 0.993905, 'acc_grapheme': 0.994185, 'acc_vowel': 0.997788, 'acc_consonant': 0.997987, 'acc_word': 0.993962, 'loss_grapheme': 0.267066, 'loss_vowel': 0.129271, 'loss_consonant': 0.105697, 'loss_word': 0.166862}\n",
      "   30 | 0.000101 | 160000/160596 | 16.0734 | 9.7213 ||\n",
      "val: {'recall': 0.996721, 'recall_grapheme': 0.995587, 'recall_vowel': 0.997951, 'recall_consonant': 0.997758, 'recall_word': 0.994906, 'acc_grapheme': 0.99513, 'acc_vowel': 0.998186, 'acc_consonant': 0.998087, 'acc_word': 0.994931, 'loss_grapheme': 0.201751, 'loss_vowel': 0.123961, 'loss_consonant': 0.08561, 'loss_word': 0.116308}\n",
      "###>>>>> saved\n",
      "   31 | 0.000098 | 160000/160596 | 14.2354 | 9.3138 ||\n",
      "val: {'recall': 0.995877, 'recall_grapheme': 0.994267, 'recall_vowel': 0.99756, 'recall_consonant': 0.997414, 'recall_word': 0.994264, 'acc_grapheme': 0.994359, 'acc_vowel': 0.998012, 'acc_consonant': 0.997913, 'acc_word': 0.99426, 'loss_grapheme': 0.195364, 'loss_vowel': 0.129538, 'loss_consonant': 0.085341, 'loss_word': 0.106842}\n",
      "   32 | 0.000095 | 160000/160596 | 3.8526 | 8.8845 ||\n",
      "val: {'recall': 0.996562, 'recall_grapheme': 0.995554, 'recall_vowel': 0.997784, 'recall_consonant': 0.997353, 'recall_word': 0.994455, 'acc_grapheme': 0.995403, 'acc_vowel': 0.997888, 'acc_consonant': 0.99841, 'acc_word': 0.994583, 'loss_grapheme': 0.191647, 'loss_vowel': 0.103934, 'loss_consonant': 0.083945, 'loss_word': 0.122782}\n",
      "   33 | 0.000093 | 160000/160596 | 14.1468 | 8.8948 |\n",
      "val: {'recall': 0.996447, 'recall_grapheme': 0.994986, 'recall_vowel': 0.998096, 'recall_consonant': 0.997718, 'recall_word': 0.994802, 'acc_grapheme': 0.995279, 'acc_vowel': 0.998037, 'acc_consonant': 0.998186, 'acc_word': 0.994856, 'loss_grapheme': 0.22829, 'loss_vowel': 0.140803, 'loss_consonant': 0.095422, 'loss_word': 0.138916}\n",
      "   34 | 0.000090 | 160000/160596 | 10.2374 | 8.7575 ||\n",
      "val: {'recall': 0.996439, 'recall_grapheme': 0.994886, 'recall_vowel': 0.998314, 'recall_consonant': 0.997671, 'recall_word': 0.994815, 'acc_grapheme': 0.994956, 'acc_vowel': 0.998285, 'acc_consonant': 0.998012, 'acc_word': 0.994856, 'loss_grapheme': 0.18834, 'loss_vowel': 0.107791, 'loss_consonant': 0.075751, 'loss_word': 0.118442}\n",
      "   35 | 0.000087 | 160000/160596 | 5.3871 | 8.8584 ||\n",
      "val: {'recall': 0.995735, 'recall_grapheme': 0.994315, 'recall_vowel': 0.997227, 'recall_consonant': 0.997082, 'recall_word': 0.993838, 'acc_grapheme': 0.994881, 'acc_vowel': 0.997739, 'acc_consonant': 0.998136, 'acc_word': 0.993912, 'loss_grapheme': 0.214536, 'loss_vowel': 0.127973, 'loss_consonant': 0.097202, 'loss_word': 0.133731}\n",
      "   36 | 0.000084 | 160000/160596 | 14.7870 | 9.0883 |\n",
      "val: {'recall': 0.996318, 'recall_grapheme': 0.994866, 'recall_vowel': 0.997814, 'recall_consonant': 0.997725, 'recall_word': 0.994778, 'acc_grapheme': 0.99513, 'acc_vowel': 0.998285, 'acc_consonant': 0.998136, 'acc_word': 0.994782, 'loss_grapheme': 0.171884, 'loss_vowel': 0.100424, 'loss_consonant': 0.076446, 'loss_word': 0.103908}\n",
      "   37 | 0.000081 | 160000/160596 | 14.5930 | 8.5923 ||\n",
      "val: {'recall': 0.995929, 'recall_grapheme': 0.994097, 'recall_vowel': 0.997965, 'recall_consonant': 0.997558, 'recall_word': 0.994861, 'acc_grapheme': 0.995229, 'acc_vowel': 0.998112, 'acc_consonant': 0.998136, 'acc_word': 0.994906, 'loss_grapheme': 0.180728, 'loss_vowel': 0.116611, 'loss_consonant': 0.081778, 'loss_word': 0.107989}\n",
      "   38 | 0.000078 | 160000/160596 | 13.3366 | 9.1835 ||\n",
      "val: {'recall': 0.996543, 'recall_grapheme': 0.995161, 'recall_vowel': 0.998039, 'recall_consonant': 0.997812, 'recall_word': 0.995329, 'acc_grapheme': 0.995428, 'acc_vowel': 0.998161, 'acc_consonant': 0.998285, 'acc_word': 0.995328, 'loss_grapheme': 0.212308, 'loss_vowel': 0.13226, 'loss_consonant': 0.093806, 'loss_word': 0.122778}\n",
      "   39 | 0.000075 | 160000/160596 | 10.7132 | 8.9789 ||\n",
      "val: {'recall': 0.996588, 'recall_grapheme': 0.995307, 'recall_vowel': 0.998021, 'recall_consonant': 0.997715, 'recall_word': 0.995374, 'acc_grapheme': 0.995304, 'acc_vowel': 0.998236, 'acc_consonant': 0.998211, 'acc_word': 0.995428, 'loss_grapheme': 0.190009, 'loss_vowel': 0.110148, 'loss_consonant': 0.082026, 'loss_word': 0.114095}\n",
      "   40 | 0.000072 | 160000/160596 | 4.5663 | 8.5742 |||\n",
      "val: {'recall': 0.996621, 'recall_grapheme': 0.995222, 'recall_vowel': 0.998085, 'recall_consonant': 0.997955, 'recall_word': 0.995419, 'acc_grapheme': 0.995552, 'acc_vowel': 0.998385, 'acc_consonant': 0.99831, 'acc_word': 0.995428, 'loss_grapheme': 0.18092, 'loss_vowel': 0.115019, 'loss_consonant': 0.07964, 'loss_word': 0.110945}\n",
      "   41 | 0.000069 | 160000/160596 | 14.4182 | 9.0641 ||\n",
      "val: {'recall': 0.996386, 'recall_grapheme': 0.995262, 'recall_vowel': 0.99777, 'recall_consonant': 0.997249, 'recall_word': 0.995249, 'acc_grapheme': 0.995701, 'acc_vowel': 0.99831, 'acc_consonant': 0.998236, 'acc_word': 0.995304, 'loss_grapheme': 0.194996, 'loss_vowel': 0.127262, 'loss_consonant': 0.083705, 'loss_word': 0.11345}\n",
      "   42 | 0.000066 | 160000/160596 | 1.2785 | 8.9133 ||\n",
      "val: {'recall': 0.99614, 'recall_grapheme': 0.994613, 'recall_vowel': 0.9977, 'recall_consonant': 0.997635, 'recall_word': 0.994706, 'acc_grapheme': 0.994956, 'acc_vowel': 0.998112, 'acc_consonant': 0.998087, 'acc_word': 0.994707, 'loss_grapheme': 0.189475, 'loss_vowel': 0.113498, 'loss_consonant': 0.079986, 'loss_word': 0.115294}\n",
      "   43 | 0.000063 | 160000/160596 | 10.4890 | 9.5735 |\n",
      "val: {'recall': 0.996296, 'recall_grapheme': 0.995147, 'recall_vowel': 0.997538, 'recall_consonant': 0.99735, 'recall_word': 0.994891, 'acc_grapheme': 0.995155, 'acc_vowel': 0.998136, 'acc_consonant': 0.998285, 'acc_word': 0.994956, 'loss_grapheme': 0.19301, 'loss_vowel': 0.117974, 'loss_consonant': 0.082775, 'loss_word': 0.107848}\n",
      "   44 | 0.000060 | 160000/160596 | 5.8144 | 8.3555 |||\n",
      "val: {'recall': 0.996648, 'recall_grapheme': 0.995526, 'recall_vowel': 0.99778, 'recall_consonant': 0.997761, 'recall_word': 0.994642, 'acc_grapheme': 0.995304, 'acc_vowel': 0.998037, 'acc_consonant': 0.998236, 'acc_word': 0.994707, 'loss_grapheme': 0.140895, 'loss_vowel': 0.083491, 'loss_consonant': 0.060192, 'loss_word': 0.094563}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 | 0.000058 | 160000/160596 | 15.3887 | 9.1880 ||\n",
      "val: {'recall': 0.996287, 'recall_grapheme': 0.994962, 'recall_vowel': 0.99743, 'recall_consonant': 0.997794, 'recall_word': 0.994464, 'acc_grapheme': 0.994832, 'acc_vowel': 0.998037, 'acc_consonant': 0.998062, 'acc_word': 0.994533, 'loss_grapheme': 0.190746, 'loss_vowel': 0.107423, 'loss_consonant': 0.07889, 'loss_word': 0.11536}\n",
      "   46 | 0.000055 | 160000/160596 | 7.3814 | 8.9218 |||\n",
      "val: {'recall': 0.996735, 'recall_grapheme': 0.995576, 'recall_vowel': 0.997987, 'recall_consonant': 0.997801, 'recall_word': 0.99519, 'acc_grapheme': 0.995478, 'acc_vowel': 0.99836, 'acc_consonant': 0.998087, 'acc_word': 0.995204, 'loss_grapheme': 0.20867, 'loss_vowel': 0.108323, 'loss_consonant': 0.084947, 'loss_word': 0.119926}\n",
      "###>>>>> saved\n",
      "   47 | 0.000052 | 160000/160596 | 15.9650 | 9.0853 ||\n",
      "val: {'recall': 0.99582, 'recall_grapheme': 0.994723, 'recall_vowel': 0.997219, 'recall_consonant': 0.996615, 'recall_word': 0.994525, 'acc_grapheme': 0.994832, 'acc_vowel': 0.997838, 'acc_consonant': 0.997813, 'acc_word': 0.994558, 'loss_grapheme': 0.21731, 'loss_vowel': 0.122732, 'loss_consonant': 0.091828, 'loss_word': 0.124453}\n",
      "   48 | 0.000049 | 160000/160596 | 3.6525 | 8.3461 ||\n",
      "val: {'recall': 0.996613, 'recall_grapheme': 0.995443, 'recall_vowel': 0.997676, 'recall_consonant': 0.99789, 'recall_word': 0.995269, 'acc_grapheme': 0.995453, 'acc_vowel': 0.998211, 'acc_consonant': 0.998236, 'acc_word': 0.995328, 'loss_grapheme': 0.195845, 'loss_vowel': 0.116576, 'loss_consonant': 0.084773, 'loss_word': 0.115451}\n",
      "   49 | 0.000046 | 160000/160596 | 6.5103 | 8.7160 ||\n",
      "val: {'recall': 0.996619, 'recall_grapheme': 0.995347, 'recall_vowel': 0.997866, 'recall_consonant': 0.997918, 'recall_word': 0.994984, 'acc_grapheme': 0.995453, 'acc_vowel': 0.998261, 'acc_consonant': 0.998186, 'acc_word': 0.99503, 'loss_grapheme': 0.196357, 'loss_vowel': 0.109327, 'loss_consonant': 0.0824, 'loss_word': 0.118747}\n",
      "   50 | 0.000044 | 160000/160596 | 6.9794 | 9.0178 |||\n",
      "val: {'recall': 0.996196, 'recall_grapheme': 0.994781, 'recall_vowel': 0.997511, 'recall_consonant': 0.997711, 'recall_word': 0.994834, 'acc_grapheme': 0.994981, 'acc_vowel': 0.997987, 'acc_consonant': 0.998136, 'acc_word': 0.994881, 'loss_grapheme': 0.199757, 'loss_vowel': 0.121824, 'loss_consonant': 0.090668, 'loss_word': 0.112936}\n",
      "   51 | 0.000041 | 160000/160596 | 5.4549 | 9.0920 |||\n",
      "val: {'recall': 0.996575, 'recall_grapheme': 0.995378, 'recall_vowel': 0.997863, 'recall_consonant': 0.997683, 'recall_word': 0.995113, 'acc_grapheme': 0.995478, 'acc_vowel': 0.99831, 'acc_consonant': 0.998186, 'acc_word': 0.995179, 'loss_grapheme': 0.220761, 'loss_vowel': 0.128821, 'loss_consonant': 0.095806, 'loss_word': 0.123857}\n",
      "   52 | 0.000038 | 160000/160596 | 10.9276 | 8.7693 ||\n",
      "val: {'recall': 0.996522, 'recall_grapheme': 0.995147, 'recall_vowel': 0.998039, 'recall_consonant': 0.997755, 'recall_word': 0.995531, 'acc_grapheme': 0.995627, 'acc_vowel': 0.99841, 'acc_consonant': 0.998285, 'acc_word': 0.995602, 'loss_grapheme': 0.197409, 'loss_vowel': 0.113219, 'loss_consonant': 0.08408, 'loss_word': 0.115803}\n",
      "   53 | 0.000036 | 160000/160596 | 6.5817 | 8.8916 |||\n",
      "val: {'recall': 0.996647, 'recall_grapheme': 0.995718, 'recall_vowel': 0.997911, 'recall_consonant': 0.997241, 'recall_word': 0.995433, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998261, 'acc_consonant': 0.99831, 'acc_word': 0.995453, 'loss_grapheme': 0.141088, 'loss_vowel': 0.083209, 'loss_consonant': 0.058496, 'loss_word': 0.091787}\n",
      "   54 | 0.000033 | 160000/160596 | 5.1446 | 8.3852 |||\n",
      "val: {'recall': 0.996708, 'recall_grapheme': 0.995476, 'recall_vowel': 0.998143, 'recall_consonant': 0.997737, 'recall_word': 0.995367, 'acc_grapheme': 0.995527, 'acc_vowel': 0.998435, 'acc_consonant': 0.99831, 'acc_word': 0.995403, 'loss_grapheme': 0.129663, 'loss_vowel': 0.084016, 'loss_consonant': 0.058103, 'loss_word': 0.083552}\n",
      "   55 | 0.000031 | 160000/160596 | 14.2612 | 8.8484 ||\n",
      "val: {'recall': 0.996396, 'recall_grapheme': 0.995178, 'recall_vowel': 0.997995, 'recall_consonant': 0.997233, 'recall_word': 0.995385, 'acc_grapheme': 0.995428, 'acc_vowel': 0.998335, 'acc_consonant': 0.998161, 'acc_word': 0.995428, 'loss_grapheme': 0.199103, 'loss_vowel': 0.109914, 'loss_consonant': 0.081248, 'loss_word': 0.119473}\n",
      "   56 | 0.000029 | 160000/160596 | 7.4262 | 9.1050 |||\n",
      "val: {'recall': 0.996531, 'recall_grapheme': 0.995231, 'recall_vowel': 0.997719, 'recall_consonant': 0.997943, 'recall_word': 0.995755, 'acc_grapheme': 0.995627, 'acc_vowel': 0.998211, 'acc_consonant': 0.998385, 'acc_word': 0.995751, 'loss_grapheme': 0.18135, 'loss_vowel': 0.114906, 'loss_consonant': 0.079944, 'loss_word': 0.103539}\n",
      "   57 | 0.000026 | 160000/160596 | 13.4174 | 8.3366 ||\n",
      "val: {'recall': 0.996786, 'recall_grapheme': 0.995677, 'recall_vowel': 0.997962, 'recall_consonant': 0.997828, 'recall_word': 0.995531, 'acc_grapheme': 0.995801, 'acc_vowel': 0.998285, 'acc_consonant': 0.998335, 'acc_word': 0.995527, 'loss_grapheme': 0.185633, 'loss_vowel': 0.110812, 'loss_consonant': 0.078923, 'loss_word': 0.10875}\n",
      "###>>>>> saved\n",
      "   58 | 0.000024 | 160000/160596 | 7.9421 | 8.3932 |||\n",
      "val: {'recall': 0.996258, 'recall_grapheme': 0.995316, 'recall_vowel': 0.997741, 'recall_consonant': 0.996657, 'recall_word': 0.995137, 'acc_grapheme': 0.995502, 'acc_vowel': 0.998236, 'acc_consonant': 0.998012, 'acc_word': 0.995155, 'loss_grapheme': 0.2092, 'loss_vowel': 0.116933, 'loss_consonant': 0.09146, 'loss_word': 0.118818}\n",
      "   59 | 0.000022 | 160000/160596 | 7.8361 | 8.3929 ||\n",
      "val: {'recall': 0.996494, 'recall_grapheme': 0.995177, 'recall_vowel': 0.998342, 'recall_consonant': 0.99728, 'recall_word': 0.995082, 'acc_grapheme': 0.995478, 'acc_vowel': 0.998385, 'acc_consonant': 0.998186, 'acc_word': 0.995155, 'loss_grapheme': 0.197144, 'loss_vowel': 0.111092, 'loss_consonant': 0.084217, 'loss_word': 0.124376}\n",
      "   60 | 0.000020 | 160000/160596 | 14.4240 | 8.4263 ||\n",
      "val: {'recall': 0.996555, 'recall_grapheme': 0.995448, 'recall_vowel': 0.998062, 'recall_consonant': 0.997262, 'recall_word': 0.995383, 'acc_grapheme': 0.995602, 'acc_vowel': 0.998285, 'acc_consonant': 0.998186, 'acc_word': 0.995378, 'loss_grapheme': 0.200866, 'loss_vowel': 0.110113, 'loss_consonant': 0.082244, 'loss_word': 0.12721}\n",
      "   61 | 0.000018 | 160000/160596 | 13.8233 | 8.8098 ||\n",
      "val: {'recall': 0.996578, 'recall_grapheme': 0.995292, 'recall_vowel': 0.998143, 'recall_consonant': 0.997586, 'recall_word': 0.995479, 'acc_grapheme': 0.995304, 'acc_vowel': 0.998136, 'acc_consonant': 0.998037, 'acc_word': 0.995527, 'loss_grapheme': 0.172771, 'loss_vowel': 0.112704, 'loss_consonant': 0.083905, 'loss_word': 0.096399}\n",
      "   62 | 0.000016 | 160000/160596 | 10.3054 | 9.0379 ||\n",
      "val: {'recall': 0.996861, 'recall_grapheme': 0.995763, 'recall_vowel': 0.998194, 'recall_consonant': 0.997725, 'recall_word': 0.995748, 'acc_grapheme': 0.995776, 'acc_vowel': 0.998385, 'acc_consonant': 0.998261, 'acc_word': 0.995776, 'loss_grapheme': 0.16432, 'loss_vowel': 0.106907, 'loss_consonant': 0.076183, 'loss_word': 0.092149}\n",
      "###>>>>> saved\n",
      "   63 | 0.000014 | 160000/160596 | 8.4825 | 8.3845 |||\n",
      "val: {'recall': 0.996782, 'recall_grapheme': 0.995696, 'recall_vowel': 0.997925, 'recall_consonant': 0.997811, 'recall_word': 0.99546, 'acc_grapheme': 0.995875, 'acc_vowel': 0.99836, 'acc_consonant': 0.99831, 'acc_word': 0.995502, 'loss_grapheme': 0.181707, 'loss_vowel': 0.114275, 'loss_consonant': 0.08073, 'loss_word': 0.110581}\n",
      "   64 | 0.000013 | 160000/160596 | 3.2793 | 8.8099 |||\n",
      "val: {'recall': 0.996717, 'recall_grapheme': 0.99579, 'recall_vowel': 0.998058, 'recall_consonant': 0.99723, 'recall_word': 0.995197, 'acc_grapheme': 0.995776, 'acc_vowel': 0.998236, 'acc_consonant': 0.998186, 'acc_word': 0.995279, 'loss_grapheme': 0.172719, 'loss_vowel': 0.096672, 'loss_consonant': 0.073565, 'loss_word': 0.112496}\n",
      "   65 | 0.000011 | 160000/160596 | 4.4487 | 8.6954 ||\n",
      "val: {'recall': 0.996885, 'recall_grapheme': 0.995893, 'recall_vowel': 0.998048, 'recall_consonant': 0.997706, 'recall_word': 0.995673, 'acc_grapheme': 0.995975, 'acc_vowel': 0.998385, 'acc_consonant': 0.998285, 'acc_word': 0.995701, 'loss_grapheme': 0.153574, 'loss_vowel': 0.091686, 'loss_consonant': 0.066402, 'loss_word': 0.092572}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###>>>>> saved\n",
      "   66 | 0.000010 | 160000/160596 | 6.5751 | 8.8596 |||\n",
      "val: {'recall': 0.996633, 'recall_grapheme': 0.995698, 'recall_vowel': 0.997825, 'recall_consonant': 0.99731, 'recall_word': 0.995198, 'acc_grapheme': 0.995726, 'acc_vowel': 0.998186, 'acc_consonant': 0.998261, 'acc_word': 0.995254, 'loss_grapheme': 0.152551, 'loss_vowel': 0.088179, 'loss_consonant': 0.064188, 'loss_word': 0.09608}\n",
      "   67 | 0.000008 | 160000/160596 | 6.1815 | 8.8011 ||\n",
      "val: {'recall': 0.996039, 'recall_grapheme': 0.994652, 'recall_vowel': 0.997756, 'recall_consonant': 0.997094, 'recall_word': 0.99481, 'acc_grapheme': 0.994881, 'acc_vowel': 0.998062, 'acc_consonant': 0.997987, 'acc_word': 0.994881, 'loss_grapheme': 0.229378, 'loss_vowel': 0.143013, 'loss_consonant': 0.110547, 'loss_word': 0.120738}\n",
      "   68 | 0.000007 | 160000/160596 | 8.3275 | 8.5445 ||\n",
      "val: {'recall': 0.99654, 'recall_grapheme': 0.995434, 'recall_vowel': 0.998036, 'recall_consonant': 0.997253, 'recall_word': 0.995196, 'acc_grapheme': 0.995602, 'acc_vowel': 0.99836, 'acc_consonant': 0.998236, 'acc_word': 0.995229, 'loss_grapheme': 0.181376, 'loss_vowel': 0.103681, 'loss_consonant': 0.074561, 'loss_word': 0.111444}\n",
      "   69 | 0.000006 | 160000/160596 | 15.0338 | 8.4217 ||\n",
      "val: {'recall': 0.996958, 'recall_grapheme': 0.995848, 'recall_vowel': 0.99831, 'recall_consonant': 0.997824, 'recall_word': 0.995763, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998509, 'acc_consonant': 0.998335, 'acc_word': 0.995801, 'loss_grapheme': 0.181576, 'loss_vowel': 0.115222, 'loss_consonant': 0.081212, 'loss_word': 0.105675}\n",
      "###>>>>> saved\n",
      "   70 | 0.000005 | 160000/160596 | 4.6970 | 8.8892 ||\n",
      "val: {'recall': 0.996518, 'recall_grapheme': 0.995463, 'recall_vowel': 0.997794, 'recall_consonant': 0.997353, 'recall_word': 0.99522, 'acc_grapheme': 0.995751, 'acc_vowel': 0.99841, 'acc_consonant': 0.998236, 'acc_word': 0.995254, 'loss_grapheme': 0.201565, 'loss_vowel': 0.114315, 'loss_consonant': 0.08607, 'loss_word': 0.123179}\n",
      "   71 | 0.000004 | 160000/160596 | 14.3814 | 8.9499 ||\n",
      "val: {'recall': 0.996849, 'recall_grapheme': 0.995816, 'recall_vowel': 0.99803, 'recall_consonant': 0.997733, 'recall_word': 0.995436, 'acc_grapheme': 0.99585, 'acc_vowel': 0.99841, 'acc_consonant': 0.998261, 'acc_word': 0.995428, 'loss_grapheme': 0.198167, 'loss_vowel': 0.113332, 'loss_consonant': 0.082985, 'loss_word': 0.120731}\n",
      "   72 | 0.000003 | 160000/160596 | 7.3915 | 8.8886 |||\n",
      "val: {'recall': 0.996582, 'recall_grapheme': 0.995194, 'recall_vowel': 0.998128, 'recall_consonant': 0.997813, 'recall_word': 0.995397, 'acc_grapheme': 0.995577, 'acc_vowel': 0.99841, 'acc_consonant': 0.998285, 'acc_word': 0.995428, 'loss_grapheme': 0.188025, 'loss_vowel': 0.111802, 'loss_consonant': 0.083465, 'loss_word': 0.109135}\n",
      "   73 | 0.000002 | 160000/160596 | 14.2116 | 8.2965 ||\n",
      "val: {'recall': 0.996737, 'recall_grapheme': 0.995517, 'recall_vowel': 0.998021, 'recall_consonant': 0.997893, 'recall_word': 0.995557, 'acc_grapheme': 0.995776, 'acc_vowel': 0.998385, 'acc_consonant': 0.998335, 'acc_word': 0.995602, 'loss_grapheme': 0.188944, 'loss_vowel': 0.115498, 'loss_consonant': 0.084888, 'loss_word': 0.107746}\n",
      "   74 | 0.000001 | 160000/160596 | 13.0634 | 8.8480 |\n",
      "val: {'recall': 0.996605, 'recall_grapheme': 0.995369, 'recall_vowel': 0.998129, 'recall_consonant': 0.997553, 'recall_word': 0.995461, 'acc_grapheme': 0.995527, 'acc_vowel': 0.99841, 'acc_consonant': 0.998161, 'acc_word': 0.995478, 'loss_grapheme': 0.192956, 'loss_vowel': 0.104992, 'loss_consonant': 0.079553, 'loss_word': 0.115793}\n",
      "   75 | 0.000001 | 160000/160596 | 15.0715 | 8.2784 |\n",
      "val: {'recall': 0.996689, 'recall_grapheme': 0.995489, 'recall_vowel': 0.998056, 'recall_consonant': 0.99772, 'recall_word': 0.995657, 'acc_grapheme': 0.995602, 'acc_vowel': 0.998335, 'acc_consonant': 0.998236, 'acc_word': 0.995676, 'loss_grapheme': 0.194802, 'loss_vowel': 0.118866, 'loss_consonant': 0.08919, 'loss_word': 0.106139}\n",
      "   76 | 0.000001 | 160000/160596 | 13.0171 | 8.9216 |\n",
      "val: {'recall': 0.996686, 'recall_grapheme': 0.995357, 'recall_vowel': 0.998271, 'recall_consonant': 0.997759, 'recall_word': 0.995683, 'acc_grapheme': 0.995527, 'acc_vowel': 0.998584, 'acc_consonant': 0.998285, 'acc_word': 0.995676, 'loss_grapheme': 0.191508, 'loss_vowel': 0.113795, 'loss_consonant': 0.081901, 'loss_word': 0.110314}\n",
      "   77 | 0.000000 | 160000/160596 | 3.0560 | 8.5048 |||\n",
      "val: {'recall': 0.99702, 'recall_grapheme': 0.996037, 'recall_vowel': 0.99814, 'recall_consonant': 0.997866, 'recall_word': 0.995836, 'acc_grapheme': 0.996024, 'acc_vowel': 0.998559, 'acc_consonant': 0.998484, 'acc_word': 0.99585, 'loss_grapheme': 0.133049, 'loss_vowel': 0.081735, 'loss_consonant': 0.057626, 'loss_word': 0.080593}\n",
      "###>>>>> saved\n",
      "   78 | 0.000000 | 160000/160596 | 13.5863 | 8.8182 |\n",
      "val: {'recall': 0.996743, 'recall_grapheme': 0.995424, 'recall_vowel': 0.998321, 'recall_consonant': 0.997804, 'recall_word': 0.995415, 'acc_grapheme': 0.995602, 'acc_vowel': 0.99841, 'acc_consonant': 0.998211, 'acc_word': 0.995453, 'loss_grapheme': 0.200129, 'loss_vowel': 0.124995, 'loss_consonant': 0.094225, 'loss_word': 0.108112}\n",
      "   79 | 0.000000 | 160000/160596 | 11.4896 | 8.5460 |\n",
      "val: {'recall': 0.996517, 'recall_grapheme': 0.995142, 'recall_vowel': 0.998121, 'recall_consonant': 0.997664, 'recall_word': 0.995253, 'acc_grapheme': 0.995527, 'acc_vowel': 0.99841, 'acc_consonant': 0.998186, 'acc_word': 0.995304, 'loss_grapheme': 0.234363, 'loss_vowel': 0.13437, 'loss_consonant': 0.099909, 'loss_word': 0.138073}\n",
      "CYCLE: 3\n",
      "{'recall': 0.996517, 'recall_grapheme': 0.995142, 'recall_vowel': 0.998121, 'recall_consonant': 0.997664, 'recall_word': 0.995253, 'acc_grapheme': 0.995527, 'acc_vowel': 0.99841, 'acc_consonant': 0.998186, 'acc_word': 0.995304, 'loss_grapheme': 0.234363, 'loss_vowel': 0.13437, 'loss_consonant': 0.099909, 'loss_word': 0.138073}\n",
      "    0 | 0.000030 | 160000/160596 | 5.8400 | 8.5823 ||\n",
      "val: {'recall': 0.996357, 'recall_grapheme': 0.99494, 'recall_vowel': 0.998037, 'recall_consonant': 0.997512, 'recall_word': 0.995038, 'acc_grapheme': 0.995328, 'acc_vowel': 0.998385, 'acc_consonant': 0.998012, 'acc_word': 0.99508, 'loss_grapheme': 0.1954, 'loss_vowel': 0.1237, 'loss_consonant': 0.0893, 'loss_word': 0.109799}\n",
      "    1 | 0.000060 | 160000/160596 | 7.2654 | 8.4756 |||\n",
      "val: {'recall': 0.996617, 'recall_grapheme': 0.995667, 'recall_vowel': 0.997959, 'recall_consonant': 0.997175, 'recall_word': 0.995194, 'acc_grapheme': 0.995627, 'acc_vowel': 0.998136, 'acc_consonant': 0.998186, 'acc_word': 0.995229, 'loss_grapheme': 0.192187, 'loss_vowel': 0.106499, 'loss_consonant': 0.078951, 'loss_word': 0.121859}\n",
      "    2 | 0.000090 | 160000/160596 | 8.6994 | 8.5699 ||\n",
      "val: {'recall': 0.996398, 'recall_grapheme': 0.995182, 'recall_vowel': 0.998032, 'recall_consonant': 0.997199, 'recall_word': 0.994931, 'acc_grapheme': 0.995179, 'acc_vowel': 0.998261, 'acc_consonant': 0.998112, 'acc_word': 0.994981, 'loss_grapheme': 0.187243, 'loss_vowel': 0.107719, 'loss_consonant': 0.078516, 'loss_word': 0.115276}\n",
      "    3 | 0.000119 | 160000/160596 | 4.9440 | 8.7719 |||\n",
      "val: {'recall': 0.995685, 'recall_grapheme': 0.994629, 'recall_vowel': 0.997424, 'recall_consonant': 0.996057, 'recall_word': 0.993872, 'acc_grapheme': 0.994832, 'acc_vowel': 0.997913, 'acc_consonant': 0.997813, 'acc_word': 0.993887, 'loss_grapheme': 0.201204, 'loss_vowel': 0.106078, 'loss_consonant': 0.076507, 'loss_word': 0.137888}\n",
      "    4 | 0.000148 | 160000/160596 | 7.6908 | 8.7485 ||\n",
      "val: {'recall': 0.99566, 'recall_grapheme': 0.994549, 'recall_vowel': 0.997297, 'recall_consonant': 0.996244, 'recall_word': 0.993759, 'acc_grapheme': 0.994782, 'acc_vowel': 0.997863, 'acc_consonant': 0.997788, 'acc_word': 0.993862, 'loss_grapheme': 0.144879, 'loss_vowel': 0.082739, 'loss_consonant': 0.057618, 'loss_word': 0.102612}\n",
      "    5 | 0.000148 | 160000/160596 | 5.6619 | 8.3155 ||\n",
      "val: {'recall': 0.996271, 'recall_grapheme': 0.994819, 'recall_vowel': 0.997807, 'recall_consonant': 0.997641, 'recall_word': 0.994483, 'acc_grapheme': 0.99508, 'acc_vowel': 0.998037, 'acc_consonant': 0.998112, 'acc_word': 0.994533, 'loss_grapheme': 0.168174, 'loss_vowel': 0.082889, 'loss_consonant': 0.066721, 'loss_word': 0.110748}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 | 0.000147 | 160000/160596 | 14.9069 | 9.0419 ||\n",
      "val: {'recall': 0.995851, 'recall_grapheme': 0.994122, 'recall_vowel': 0.997899, 'recall_consonant': 0.997262, 'recall_word': 0.994092, 'acc_grapheme': 0.994235, 'acc_vowel': 0.997888, 'acc_consonant': 0.997739, 'acc_word': 0.994161, 'loss_grapheme': 0.191561, 'loss_vowel': 0.105633, 'loss_consonant': 0.081668, 'loss_word': 0.112553}\n",
      "    7 | 0.000146 | 160000/160596 | 4.9063 | 8.9092 |||\n",
      "val: {'recall': 0.995831, 'recall_grapheme': 0.994298, 'recall_vowel': 0.997388, 'recall_consonant': 0.997342, 'recall_word': 0.994379, 'acc_grapheme': 0.994707, 'acc_vowel': 0.998012, 'acc_consonant': 0.998112, 'acc_word': 0.994409, 'loss_grapheme': 0.144679, 'loss_vowel': 0.084012, 'loss_consonant': 0.062502, 'loss_word': 0.096612}\n",
      "    8 | 0.000145 | 160000/160596 | 14.3975 | 9.0968 ||\n",
      "val: {'recall': 0.99633, 'recall_grapheme': 0.994966, 'recall_vowel': 0.997788, 'recall_consonant': 0.997601, 'recall_word': 0.994087, 'acc_grapheme': 0.994881, 'acc_vowel': 0.997913, 'acc_consonant': 0.997987, 'acc_word': 0.99421, 'loss_grapheme': 0.202354, 'loss_vowel': 0.126008, 'loss_consonant': 0.091619, 'loss_word': 0.121001}\n",
      "    9 | 0.000144 | 160000/160596 | 13.0041 | 9.0773 ||\n",
      "val: {'recall': 0.995828, 'recall_grapheme': 0.994587, 'recall_vowel': 0.997636, 'recall_consonant': 0.996502, 'recall_word': 0.994201, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997913, 'acc_consonant': 0.997913, 'acc_word': 0.99426, 'loss_grapheme': 0.19598, 'loss_vowel': 0.118227, 'loss_consonant': 0.08144, 'loss_word': 0.126833}\n",
      "   10 | 0.000143 | 160000/160596 | 9.7213 | 8.6548 |||\n",
      "val: {'recall': 0.996147, 'recall_grapheme': 0.994665, 'recall_vowel': 0.997791, 'recall_consonant': 0.997469, 'recall_word': 0.994411, 'acc_grapheme': 0.994732, 'acc_vowel': 0.997938, 'acc_consonant': 0.997962, 'acc_word': 0.994484, 'loss_grapheme': 0.203909, 'loss_vowel': 0.11457, 'loss_consonant': 0.08457, 'loss_word': 0.133411}\n",
      "   11 | 0.000142 | 160000/160596 | 5.0196 | 8.5067 |||\n",
      "val: {'recall': 0.995874, 'recall_grapheme': 0.994515, 'recall_vowel': 0.99788, 'recall_consonant': 0.996584, 'recall_word': 0.994443, 'acc_grapheme': 0.994981, 'acc_vowel': 0.998136, 'acc_consonant': 0.998112, 'acc_word': 0.994508, 'loss_grapheme': 0.16633, 'loss_vowel': 0.103936, 'loss_consonant': 0.074255, 'loss_word': 0.098733}\n",
      "   12 | 0.000140 | 160000/160596 | 6.9848 | 9.0723 |||\n",
      "val: {'recall': 0.996304, 'recall_grapheme': 0.995201, 'recall_vowel': 0.997212, 'recall_consonant': 0.997602, 'recall_word': 0.994499, 'acc_grapheme': 0.99503, 'acc_vowel': 0.997689, 'acc_consonant': 0.997913, 'acc_word': 0.994533, 'loss_grapheme': 0.206515, 'loss_vowel': 0.11664, 'loss_consonant': 0.086192, 'loss_word': 0.127573}\n",
      "   13 | 0.000139 | 160000/160596 | 5.3340 | 9.2350 |||\n",
      "val: {'recall': 0.995053, 'recall_grapheme': 0.993229, 'recall_vowel': 0.996876, 'recall_consonant': 0.996877, 'recall_word': 0.993739, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997465, 'acc_consonant': 0.997565, 'acc_word': 0.993813, 'loss_grapheme': 0.215917, 'loss_vowel': 0.129722, 'loss_consonant': 0.095992, 'loss_word': 0.123006}\n",
      "   14 | 0.000137 | 160000/160596 | 6.3237 | 8.9819 |||\n",
      "val: {'recall': 0.996085, 'recall_grapheme': 0.99451, 'recall_vowel': 0.997851, 'recall_consonant': 0.997469, 'recall_word': 0.994476, 'acc_grapheme': 0.99513, 'acc_vowel': 0.998112, 'acc_consonant': 0.997938, 'acc_word': 0.994583, 'loss_grapheme': 0.205327, 'loss_vowel': 0.129874, 'loss_consonant': 0.090489, 'loss_word': 0.122493}\n",
      "   15 | 0.000136 | 160000/160596 | 11.2491 | 8.4916 ||\n",
      "val: {'recall': 0.995527, 'recall_grapheme': 0.994052, 'recall_vowel': 0.997377, 'recall_consonant': 0.996626, 'recall_word': 0.994481, 'acc_grapheme': 0.994658, 'acc_vowel': 0.997938, 'acc_consonant': 0.997938, 'acc_word': 0.994459, 'loss_grapheme': 0.261605, 'loss_vowel': 0.145169, 'loss_consonant': 0.105637, 'loss_word': 0.153958}\n",
      "   16 | 0.000134 | 160000/160596 | 5.0090 | 9.1000 |||\n",
      "val: {'recall': 0.995544, 'recall_grapheme': 0.994569, 'recall_vowel': 0.997104, 'recall_consonant': 0.995932, 'recall_word': 0.994406, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997714, 'acc_consonant': 0.998062, 'acc_word': 0.994459, 'loss_grapheme': 0.188908, 'loss_vowel': 0.107279, 'loss_consonant': 0.074963, 'loss_word': 0.120936}\n",
      "   17 | 0.000132 | 160000/160596 | 7.1565 | 8.4877 ||\n",
      "val: {'recall': 0.996439, 'recall_grapheme': 0.995568, 'recall_vowel': 0.997375, 'recall_consonant': 0.997247, 'recall_word': 0.994671, 'acc_grapheme': 0.99513, 'acc_vowel': 0.997913, 'acc_consonant': 0.998186, 'acc_word': 0.994732, 'loss_grapheme': 0.194206, 'loss_vowel': 0.109836, 'loss_consonant': 0.077013, 'loss_word': 0.120192}\n",
      "   18 | 0.000130 | 160000/160596 | 10.5800 | 8.6870 ||\n",
      "val: {'recall': 0.996435, 'recall_grapheme': 0.995379, 'recall_vowel': 0.997717, 'recall_consonant': 0.997265, 'recall_word': 0.994832, 'acc_grapheme': 0.995353, 'acc_vowel': 0.998112, 'acc_consonant': 0.998236, 'acc_word': 0.994956, 'loss_grapheme': 0.167623, 'loss_vowel': 0.10031, 'loss_consonant': 0.070448, 'loss_word': 0.113032}\n",
      "   19 | 0.000128 | 160000/160596 | 15.8926 | 8.9488 ||\n",
      "val: {'recall': 0.996343, 'recall_grapheme': 0.994985, 'recall_vowel': 0.997648, 'recall_consonant': 0.997756, 'recall_word': 0.994812, 'acc_grapheme': 0.995179, 'acc_vowel': 0.998236, 'acc_consonant': 0.998285, 'acc_word': 0.994881, 'loss_grapheme': 0.147834, 'loss_vowel': 0.092351, 'loss_consonant': 0.062325, 'loss_word': 0.102715}\n",
      "   20 | 0.000126 | 160000/160596 | 8.9046 | 8.6494 ||\n",
      "val: {'recall': 0.995881, 'recall_grapheme': 0.994522, 'recall_vowel': 0.99765, 'recall_consonant': 0.996829, 'recall_word': 0.994909, 'acc_grapheme': 0.99503, 'acc_vowel': 0.998062, 'acc_consonant': 0.998211, 'acc_word': 0.994981, 'loss_grapheme': 0.218603, 'loss_vowel': 0.121321, 'loss_consonant': 0.086933, 'loss_word': 0.145866}\n",
      "   21 | 0.000124 | 160000/160596 | 7.7212 | 8.7675 ||\n",
      "val: {'recall': 0.996151, 'recall_grapheme': 0.995002, 'recall_vowel': 0.997674, 'recall_consonant': 0.996924, 'recall_word': 0.994777, 'acc_grapheme': 0.99503, 'acc_vowel': 0.998087, 'acc_consonant': 0.998186, 'acc_word': 0.994832, 'loss_grapheme': 0.194475, 'loss_vowel': 0.120154, 'loss_consonant': 0.0843, 'loss_word': 0.114541}\n",
      "   22 | 0.000121 | 160000/160596 | 15.0189 | 8.7605 ||\n",
      "val: {'recall': 0.995851, 'recall_grapheme': 0.994238, 'recall_vowel': 0.997811, 'recall_consonant': 0.99712, 'recall_word': 0.994366, 'acc_grapheme': 0.994558, 'acc_vowel': 0.997938, 'acc_consonant': 0.998186, 'acc_word': 0.994434, 'loss_grapheme': 0.220446, 'loss_vowel': 0.143391, 'loss_consonant': 0.101535, 'loss_word': 0.11604}\n",
      "   23 | 0.000119 | 160000/160596 | 7.2155 | 8.6845 |||\n",
      "val: {'recall': 0.996614, 'recall_grapheme': 0.9959, 'recall_vowel': 0.997498, 'recall_consonant': 0.997156, 'recall_word': 0.994315, 'acc_grapheme': 0.99513, 'acc_vowel': 0.997888, 'acc_consonant': 0.998136, 'acc_word': 0.994434, 'loss_grapheme': 0.218355, 'loss_vowel': 0.119509, 'loss_consonant': 0.088843, 'loss_word': 0.13802}\n",
      "   24 | 0.000117 | 160000/160596 | 11.6985 | 8.7768 |\n",
      "val: {'recall': 0.995889, 'recall_grapheme': 0.995003, 'recall_vowel': 0.99689, 'recall_consonant': 0.99666, 'recall_word': 0.993519, 'acc_grapheme': 0.994658, 'acc_vowel': 0.997391, 'acc_consonant': 0.997838, 'acc_word': 0.993639, 'loss_grapheme': 0.212387, 'loss_vowel': 0.120575, 'loss_consonant': 0.089773, 'loss_word': 0.138671}\n",
      "   25 | 0.000114 | 160000/160596 | 0.7202 | 8.7649 ||\n",
      "val: {'recall': 0.996675, 'recall_grapheme': 0.995713, 'recall_vowel': 0.997821, 'recall_consonant': 0.997454, 'recall_word': 0.995144, 'acc_grapheme': 0.995751, 'acc_vowel': 0.998012, 'acc_consonant': 0.998335, 'acc_word': 0.995229, 'loss_grapheme': 0.125683, 'loss_vowel': 0.071876, 'loss_consonant': 0.053205, 'loss_word': 0.077431}\n",
      "   26 | 0.000112 | 160000/160596 | 1.8995 | 8.6585 ||\n",
      "val: {'recall': 0.996258, 'recall_grapheme': 0.995045, 'recall_vowel': 0.997574, 'recall_consonant': 0.997367, 'recall_word': 0.994695, 'acc_grapheme': 0.99508, 'acc_vowel': 0.997962, 'acc_consonant': 0.998087, 'acc_word': 0.994782, 'loss_grapheme': 0.13928, 'loss_vowel': 0.087757, 'loss_consonant': 0.060272, 'loss_word': 0.081906}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 0.000109 | 160000/160596 | 12.6458 | 8.4536 ||\n",
      "val: {'recall': 0.996527, 'recall_grapheme': 0.995456, 'recall_vowel': 0.997616, 'recall_consonant': 0.997582, 'recall_word': 0.995389, 'acc_grapheme': 0.995527, 'acc_vowel': 0.998236, 'acc_consonant': 0.998261, 'acc_word': 0.995453, 'loss_grapheme': 0.216646, 'loss_vowel': 0.125456, 'loss_consonant': 0.084566, 'loss_word': 0.136005}\n",
      "   28 | 0.000106 | 160000/160596 | 13.8348 | 8.9147 |\n",
      "val: {'recall': 0.996139, 'recall_grapheme': 0.99484, 'recall_vowel': 0.997291, 'recall_consonant': 0.997584, 'recall_word': 0.994901, 'acc_grapheme': 0.994981, 'acc_vowel': 0.997987, 'acc_consonant': 0.998112, 'acc_word': 0.994981, 'loss_grapheme': 0.221499, 'loss_vowel': 0.133914, 'loss_consonant': 0.091652, 'loss_word': 0.127087}\n",
      "   29 | 0.000104 | 160000/160596 | 5.0358 | 8.4889 |||\n",
      "val: {'recall': 0.995676, 'recall_grapheme': 0.994342, 'recall_vowel': 0.997737, 'recall_consonant': 0.996281, 'recall_word': 0.994328, 'acc_grapheme': 0.994856, 'acc_vowel': 0.997962, 'acc_consonant': 0.997962, 'acc_word': 0.994359, 'loss_grapheme': 0.155607, 'loss_vowel': 0.093067, 'loss_consonant': 0.066202, 'loss_word': 0.096976}\n",
      "   30 | 0.000101 | 160000/160596 | 5.9951 | 8.5974 |||\n",
      "val: {'recall': 0.995925, 'recall_grapheme': 0.99498, 'recall_vowel': 0.997774, 'recall_consonant': 0.995965, 'recall_word': 0.994065, 'acc_grapheme': 0.994832, 'acc_vowel': 0.997863, 'acc_consonant': 0.998211, 'acc_word': 0.994111, 'loss_grapheme': 0.19095, 'loss_vowel': 0.10153, 'loss_consonant': 0.084039, 'loss_word': 0.116721}\n",
      "   31 | 0.000098 | 160000/160596 | 6.8970 | 8.3789 |||\n",
      "val: {'recall': 0.996254, 'recall_grapheme': 0.995131, 'recall_vowel': 0.997385, 'recall_consonant': 0.997368, 'recall_word': 0.994799, 'acc_grapheme': 0.995403, 'acc_vowel': 0.997813, 'acc_consonant': 0.998261, 'acc_word': 0.994832, 'loss_grapheme': 0.216087, 'loss_vowel': 0.113889, 'loss_consonant': 0.083555, 'loss_word': 0.133179}\n",
      "   32 | 0.000095 | 160000/160596 | 15.5840 | 8.7070 |\n",
      "val: {'recall': 0.996655, 'recall_grapheme': 0.995708, 'recall_vowel': 0.997513, 'recall_consonant': 0.997689, 'recall_word': 0.995403, 'acc_grapheme': 0.995676, 'acc_vowel': 0.998062, 'acc_consonant': 0.998335, 'acc_word': 0.995403, 'loss_grapheme': 0.173938, 'loss_vowel': 0.108558, 'loss_consonant': 0.078719, 'loss_word': 0.105327}\n",
      "   33 | 0.000093 | 160000/160596 | 6.4389 | 8.4670 |||\n",
      "val: {'recall': 0.995497, 'recall_grapheme': 0.993718, 'recall_vowel': 0.997532, 'recall_consonant': 0.997021, 'recall_word': 0.993958, 'acc_grapheme': 0.994732, 'acc_vowel': 0.997714, 'acc_consonant': 0.997813, 'acc_word': 0.993987, 'loss_grapheme': 0.13695, 'loss_vowel': 0.091901, 'loss_consonant': 0.065697, 'loss_word': 0.095836}\n",
      "   34 | 0.000090 | 160000/160596 | 4.0660 | 8.4167 |||\n",
      "val: {'recall': 0.996139, 'recall_grapheme': 0.994851, 'recall_vowel': 0.99766, 'recall_consonant': 0.997194, 'recall_word': 0.99449, 'acc_grapheme': 0.995105, 'acc_vowel': 0.997962, 'acc_consonant': 0.998012, 'acc_word': 0.994583, 'loss_grapheme': 0.183092, 'loss_vowel': 0.110859, 'loss_consonant': 0.07742, 'loss_word': 0.119538}\n",
      "   35 | 0.000087 | 160000/160596 | 7.1556 | 8.3782 ||\n",
      "val: {'recall': 0.996511, 'recall_grapheme': 0.995365, 'recall_vowel': 0.997818, 'recall_consonant': 0.997497, 'recall_word': 0.995123, 'acc_grapheme': 0.995428, 'acc_vowel': 0.998062, 'acc_consonant': 0.998087, 'acc_word': 0.995204, 'loss_grapheme': 0.202498, 'loss_vowel': 0.131783, 'loss_consonant': 0.093518, 'loss_word': 0.113782}\n",
      "   36 | 0.000084 | 160000/160596 | 1.8912 | 8.7405 ||\n",
      "val: {'recall': 0.996782, 'recall_grapheme': 0.995929, 'recall_vowel': 0.997997, 'recall_consonant': 0.997272, 'recall_word': 0.995173, 'acc_grapheme': 0.995577, 'acc_vowel': 0.998285, 'acc_consonant': 0.998087, 'acc_word': 0.995204, 'loss_grapheme': 0.14577, 'loss_vowel': 0.087491, 'loss_consonant': 0.058119, 'loss_word': 0.089039}\n",
      "   37 | 0.000081 | 160000/160596 | 15.0985 | 8.6376 ||\n",
      "val: {'recall': 0.996669, 'recall_grapheme': 0.995592, 'recall_vowel': 0.997745, 'recall_consonant': 0.997747, 'recall_word': 0.995164, 'acc_grapheme': 0.995328, 'acc_vowel': 0.998161, 'acc_consonant': 0.998136, 'acc_word': 0.995229, 'loss_grapheme': 0.180547, 'loss_vowel': 0.124748, 'loss_consonant': 0.0912, 'loss_word': 0.100241}\n",
      "   38 | 0.000078 | 160000/160596 | 6.8065 | 8.2804 ||\n",
      "val: {'recall': 0.996544, 'recall_grapheme': 0.995538, 'recall_vowel': 0.997903, 'recall_consonant': 0.997198, 'recall_word': 0.994599, 'acc_grapheme': 0.995428, 'acc_vowel': 0.997987, 'acc_consonant': 0.998112, 'acc_word': 0.994658, 'loss_grapheme': 0.170184, 'loss_vowel': 0.096022, 'loss_consonant': 0.073369, 'loss_word': 0.108219}\n",
      "   39 | 0.000075 | 160000/160596 | 13.0295 | 8.2304 ||\n",
      "val: {'recall': 0.996737, 'recall_grapheme': 0.99578, 'recall_vowel': 0.997673, 'recall_consonant': 0.997715, 'recall_word': 0.994929, 'acc_grapheme': 0.995577, 'acc_vowel': 0.998087, 'acc_consonant': 0.998236, 'acc_word': 0.994981, 'loss_grapheme': 0.157871, 'loss_vowel': 0.086527, 'loss_consonant': 0.064112, 'loss_word': 0.105809}\n",
      "   40 | 0.000072 | 160000/160596 | 14.2211 | 8.4658 ||\n",
      "val: {'recall': 0.99629, 'recall_grapheme': 0.994908, 'recall_vowel': 0.997507, 'recall_consonant': 0.997836, 'recall_word': 0.994797, 'acc_grapheme': 0.995179, 'acc_vowel': 0.998112, 'acc_consonant': 0.998161, 'acc_word': 0.994856, 'loss_grapheme': 0.152599, 'loss_vowel': 0.107938, 'loss_consonant': 0.077848, 'loss_word': 0.084071}\n",
      "   41 | 0.000069 | 160000/160596 | 8.1941 | 8.4012 ||\n",
      "val: {'recall': 0.996632, 'recall_grapheme': 0.995538, 'recall_vowel': 0.997946, 'recall_consonant': 0.997505, 'recall_word': 0.994765, 'acc_grapheme': 0.995328, 'acc_vowel': 0.998062, 'acc_consonant': 0.998136, 'acc_word': 0.994832, 'loss_grapheme': 0.199015, 'loss_vowel': 0.113555, 'loss_consonant': 0.083706, 'loss_word': 0.132189}\n",
      "   42 | 0.000066 | 160000/160596 | 5.1503 | 8.3971 |||\n",
      "val: {'recall': 0.996898, 'recall_grapheme': 0.995731, 'recall_vowel': 0.998293, 'recall_consonant': 0.997836, 'recall_word': 0.995097, 'acc_grapheme': 0.995602, 'acc_vowel': 0.99836, 'acc_consonant': 0.99836, 'acc_word': 0.995155, 'loss_grapheme': 0.157788, 'loss_vowel': 0.091277, 'loss_consonant': 0.069335, 'loss_word': 0.092213}\n",
      "   43 | 0.000063 | 160000/160596 | 4.2622 | 8.5169 ||\n",
      "val: {'recall': 0.996378, 'recall_grapheme': 0.995354, 'recall_vowel': 0.997781, 'recall_consonant': 0.997021, 'recall_word': 0.994806, 'acc_grapheme': 0.995577, 'acc_vowel': 0.998261, 'acc_consonant': 0.998112, 'acc_word': 0.994906, 'loss_grapheme': 0.157039, 'loss_vowel': 0.087874, 'loss_consonant': 0.068463, 'loss_word': 0.09882}\n",
      "   44 | 0.000060 | 160000/160596 | 1.5613 | 8.1860 |||\n",
      "val: {'recall': 0.997182, 'recall_grapheme': 0.99635, 'recall_vowel': 0.998329, 'recall_consonant': 0.9977, 'recall_word': 0.995519, 'acc_grapheme': 0.996049, 'acc_vowel': 0.998211, 'acc_consonant': 0.998385, 'acc_word': 0.995602, 'loss_grapheme': 0.149234, 'loss_vowel': 0.091124, 'loss_consonant': 0.065173, 'loss_word': 0.09957}\n",
      "###>>>>> saved\n",
      "   45 | 0.000058 | 160000/160596 | 8.0381 | 8.6173 |||\n",
      "val: {'recall': 0.995901, 'recall_grapheme': 0.994881, 'recall_vowel': 0.997154, 'recall_consonant': 0.996686, 'recall_word': 0.994235, 'acc_grapheme': 0.994832, 'acc_vowel': 0.997664, 'acc_consonant': 0.997888, 'acc_word': 0.994335, 'loss_grapheme': 0.192607, 'loss_vowel': 0.111366, 'loss_consonant': 0.083534, 'loss_word': 0.121841}\n",
      "   46 | 0.000055 | 160000/160596 | 4.8895 | 8.1181 |||\n",
      "val: {'recall': 0.996081, 'recall_grapheme': 0.994786, 'recall_vowel': 0.997732, 'recall_consonant': 0.997018, 'recall_word': 0.994132, 'acc_grapheme': 0.995229, 'acc_vowel': 0.997863, 'acc_consonant': 0.997913, 'acc_word': 0.994161, 'loss_grapheme': 0.160302, 'loss_vowel': 0.114507, 'loss_consonant': 0.076497, 'loss_word': 0.110402}\n",
      "   47 | 0.000052 | 160000/160596 | 11.5318 | 8.1590 |\n",
      "val: {'recall': 0.996673, 'recall_grapheme': 0.995556, 'recall_vowel': 0.997959, 'recall_consonant': 0.99762, 'recall_word': 0.995404, 'acc_grapheme': 0.995701, 'acc_vowel': 0.99831, 'acc_consonant': 0.998186, 'acc_word': 0.995502, 'loss_grapheme': 0.186234, 'loss_vowel': 0.091963, 'loss_consonant': 0.077215, 'loss_word': 0.11691}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 0.000049 | 160000/160596 | 5.4270 | 8.4843 |||\n",
      "val: {'recall': 0.996929, 'recall_grapheme': 0.996411, 'recall_vowel': 0.997428, 'recall_consonant': 0.997468, 'recall_word': 0.995234, 'acc_grapheme': 0.995925, 'acc_vowel': 0.998012, 'acc_consonant': 0.998335, 'acc_word': 0.995279, 'loss_grapheme': 0.202035, 'loss_vowel': 0.113786, 'loss_consonant': 0.090212, 'loss_word': 0.127162}\n",
      "   49 | 0.000046 | 160000/160596 | 3.7988 | 7.9082 ||\n",
      "val: {'recall': 0.997214, 'recall_grapheme': 0.99663, 'recall_vowel': 0.997785, 'recall_consonant': 0.997813, 'recall_word': 0.995588, 'acc_grapheme': 0.996049, 'acc_vowel': 0.998459, 'acc_consonant': 0.998385, 'acc_word': 0.995676, 'loss_grapheme': 0.16191, 'loss_vowel': 0.091391, 'loss_consonant': 0.066615, 'loss_word': 0.095959}\n",
      "###>>>>> saved\n",
      "   50 | 0.000044 | 160000/160596 | 13.4983 | 8.2749 |\n",
      "val: {'recall': 0.997258, 'recall_grapheme': 0.996423, 'recall_vowel': 0.998467, 'recall_consonant': 0.99772, 'recall_word': 0.995466, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998608, 'acc_consonant': 0.998484, 'acc_word': 0.995552, 'loss_grapheme': 0.149944, 'loss_vowel': 0.09298, 'loss_consonant': 0.067274, 'loss_word': 0.092241}\n",
      "###>>>>> saved\n",
      "   51 | 0.000041 | 160000/160596 | 13.4661 | 8.5236 ||\n",
      "val: {'recall': 0.996996, 'recall_grapheme': 0.995968, 'recall_vowel': 0.998141, 'recall_consonant': 0.997907, 'recall_word': 0.995564, 'acc_grapheme': 0.99595, 'acc_vowel': 0.998608, 'acc_consonant': 0.998534, 'acc_word': 0.995652, 'loss_grapheme': 0.194562, 'loss_vowel': 0.107069, 'loss_consonant': 0.080955, 'loss_word': 0.12134}\n",
      "   52 | 0.000038 | 160000/160596 | 4.6199 | 8.5003 |||\n",
      "val: {'recall': 0.997186, 'recall_grapheme': 0.996463, 'recall_vowel': 0.998288, 'recall_consonant': 0.997532, 'recall_word': 0.995908, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998708, 'acc_consonant': 0.998484, 'acc_word': 0.995999, 'loss_grapheme': 0.150734, 'loss_vowel': 0.090101, 'loss_consonant': 0.063921, 'loss_word': 0.096547}\n",
      "   53 | 0.000036 | 160000/160596 | 7.1892 | 8.4542 ||\n",
      "val: {'recall': 0.997238, 'recall_grapheme': 0.996409, 'recall_vowel': 0.998286, 'recall_consonant': 0.997849, 'recall_word': 0.995781, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998608, 'acc_consonant': 0.99841, 'acc_word': 0.9959, 'loss_grapheme': 0.163378, 'loss_vowel': 0.101834, 'loss_consonant': 0.073667, 'loss_word': 0.102158}\n",
      "   54 | 0.000033 | 160000/160596 | 5.2416 | 8.1621 ||\n",
      "val: {'recall': 0.997245, 'recall_grapheme': 0.996586, 'recall_vowel': 0.997887, 'recall_consonant': 0.997923, 'recall_word': 0.995738, 'acc_grapheme': 0.996322, 'acc_vowel': 0.998509, 'acc_consonant': 0.998509, 'acc_word': 0.995825, 'loss_grapheme': 0.159615, 'loss_vowel': 0.099459, 'loss_consonant': 0.071184, 'loss_word': 0.094421}\n",
      "   55 | 0.000031 | 160000/160596 | 7.8424 | 8.0192 ||\n",
      "val: {'recall': 0.996808, 'recall_grapheme': 0.995762, 'recall_vowel': 0.997846, 'recall_consonant': 0.997863, 'recall_word': 0.995478, 'acc_grapheme': 0.995801, 'acc_vowel': 0.99831, 'acc_consonant': 0.998385, 'acc_word': 0.995577, 'loss_grapheme': 0.175005, 'loss_vowel': 0.108338, 'loss_consonant': 0.083565, 'loss_word': 0.097746}\n",
      "   56 | 0.000029 | 160000/160596 | 8.3033 | 8.3461 |||\n",
      "val: {'recall': 0.997088, 'recall_grapheme': 0.996492, 'recall_vowel': 0.99756, 'recall_consonant': 0.99781, 'recall_word': 0.995307, 'acc_grapheme': 0.996099, 'acc_vowel': 0.998161, 'acc_consonant': 0.99836, 'acc_word': 0.995403, 'loss_grapheme': 0.149642, 'loss_vowel': 0.091323, 'loss_consonant': 0.067106, 'loss_word': 0.0936}\n",
      "   57 | 0.000026 | 160000/160596 | 12.1203 | 8.4538 |\n",
      "val: {'recall': 0.997203, 'recall_grapheme': 0.99649, 'recall_vowel': 0.997963, 'recall_consonant': 0.997868, 'recall_word': 0.99564, 'acc_grapheme': 0.995875, 'acc_vowel': 0.99841, 'acc_consonant': 0.998534, 'acc_word': 0.995676, 'loss_grapheme': 0.160072, 'loss_vowel': 0.090171, 'loss_consonant': 0.069074, 'loss_word': 0.096334}\n",
      "   58 | 0.000024 | 160000/160596 | 6.0058 | 8.2997 ||\n",
      "val: {'recall': 0.996899, 'recall_grapheme': 0.996285, 'recall_vowel': 0.997749, 'recall_consonant': 0.997277, 'recall_word': 0.995345, 'acc_grapheme': 0.99585, 'acc_vowel': 0.99831, 'acc_consonant': 0.99831, 'acc_word': 0.995428, 'loss_grapheme': 0.151714, 'loss_vowel': 0.08725, 'loss_consonant': 0.064332, 'loss_word': 0.095812}\n",
      "   59 | 0.000022 | 160000/160596 | 4.6163 | 8.5331 |||\n",
      "val: {'recall': 0.997138, 'recall_grapheme': 0.996349, 'recall_vowel': 0.997872, 'recall_consonant': 0.997981, 'recall_word': 0.995978, 'acc_grapheme': 0.996273, 'acc_vowel': 0.998435, 'acc_consonant': 0.998435, 'acc_word': 0.996024, 'loss_grapheme': 0.146285, 'loss_vowel': 0.085204, 'loss_consonant': 0.06586, 'loss_word': 0.089551}\n",
      "   60 | 0.000020 | 160000/160596 | 13.5279 | 8.1118 ||\n",
      "val: {'recall': 0.997395, 'recall_grapheme': 0.996815, 'recall_vowel': 0.998009, 'recall_consonant': 0.997941, 'recall_word': 0.996136, 'acc_grapheme': 0.996472, 'acc_vowel': 0.998534, 'acc_consonant': 0.998584, 'acc_word': 0.996248, 'loss_grapheme': 0.18021, 'loss_vowel': 0.1044, 'loss_consonant': 0.075371, 'loss_word': 0.112318}\n",
      "###>>>>> saved\n",
      "   61 | 0.000018 | 160000/160596 | 7.1806 | 8.2137 |||\n",
      "val: {'recall': 0.996803, 'recall_grapheme': 0.996074, 'recall_vowel': 0.99795, 'recall_consonant': 0.997116, 'recall_word': 0.9953, 'acc_grapheme': 0.9959, 'acc_vowel': 0.99831, 'acc_consonant': 0.998335, 'acc_word': 0.995403, 'loss_grapheme': 0.169318, 'loss_vowel': 0.105271, 'loss_consonant': 0.080311, 'loss_word': 0.099133}\n",
      "   62 | 0.000016 | 160000/160596 | 3.3368 | 8.3583 ||\n",
      "val: {'recall': 0.997019, 'recall_grapheme': 0.996187, 'recall_vowel': 0.998063, 'recall_consonant': 0.997641, 'recall_word': 0.995535, 'acc_grapheme': 0.99595, 'acc_vowel': 0.998435, 'acc_consonant': 0.998385, 'acc_word': 0.995577, 'loss_grapheme': 0.169889, 'loss_vowel': 0.099497, 'loss_consonant': 0.074502, 'loss_word': 0.104172}\n",
      "   63 | 0.000014 | 160000/160596 | 11.5573 | 8.2502 |\n",
      "val: {'recall': 0.997302, 'recall_grapheme': 0.996521, 'recall_vowel': 0.998261, 'recall_consonant': 0.997906, 'recall_word': 0.995931, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998658, 'acc_consonant': 0.998435, 'acc_word': 0.995999, 'loss_grapheme': 0.155252, 'loss_vowel': 0.098667, 'loss_consonant': 0.073257, 'loss_word': 0.093545}\n",
      "   64 | 0.000013 | 160000/160596 | 5.0796 | 8.3624 ||\n",
      "val: {'recall': 0.997267, 'recall_grapheme': 0.996823, 'recall_vowel': 0.998069, 'recall_consonant': 0.997354, 'recall_word': 0.996066, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998559, 'acc_consonant': 0.998484, 'acc_word': 0.996148, 'loss_grapheme': 0.116235, 'loss_vowel': 0.068603, 'loss_consonant': 0.049724, 'loss_word': 0.072441}\n",
      "   65 | 0.000011 | 160000/160596 | 5.7402 | 8.4537 ||\n",
      "val: {'recall': 0.997174, 'recall_grapheme': 0.996676, 'recall_vowel': 0.99811, 'recall_consonant': 0.997233, 'recall_word': 0.995443, 'acc_grapheme': 0.996173, 'acc_vowel': 0.998484, 'acc_consonant': 0.998335, 'acc_word': 0.995527, 'loss_grapheme': 0.153423, 'loss_vowel': 0.088818, 'loss_consonant': 0.066665, 'loss_word': 0.098524}\n",
      "   66 | 0.000010 | 160000/160596 | 6.3990 | 8.5585 ||\n",
      "val: {'recall': 0.996917, 'recall_grapheme': 0.996213, 'recall_vowel': 0.997903, 'recall_consonant': 0.99734, 'recall_word': 0.995313, 'acc_grapheme': 0.995975, 'acc_vowel': 0.99831, 'acc_consonant': 0.998435, 'acc_word': 0.995428, 'loss_grapheme': 0.174782, 'loss_vowel': 0.10482, 'loss_consonant': 0.076164, 'loss_word': 0.108373}\n",
      "   67 | 0.000008 | 160000/160596 | 5.8047 | 8.1975 |||\n",
      "val: {'recall': 0.996541, 'recall_grapheme': 0.995676, 'recall_vowel': 0.997703, 'recall_consonant': 0.997111, 'recall_word': 0.994935, 'acc_grapheme': 0.995527, 'acc_vowel': 0.998261, 'acc_consonant': 0.998161, 'acc_word': 0.99503, 'loss_grapheme': 0.174203, 'loss_vowel': 0.099185, 'loss_consonant': 0.080106, 'loss_word': 0.10505}\n",
      "   68 | 0.000007 | 160000/160596 | 12.2296 | 8.1483 ||\n",
      "val: {'recall': 0.997086, 'recall_grapheme': 0.996513, 'recall_vowel': 0.997865, 'recall_consonant': 0.997454, 'recall_word': 0.99577, 'acc_grapheme': 0.996322, 'acc_vowel': 0.998584, 'acc_consonant': 0.998459, 'acc_word': 0.9959, 'loss_grapheme': 0.165863, 'loss_vowel': 0.097426, 'loss_consonant': 0.070417, 'loss_word': 0.100723}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 0.000006 | 160000/160596 | 3.7578 | 8.0367 |||\n",
      "val: {'recall': 0.997498, 'recall_grapheme': 0.996893, 'recall_vowel': 0.99822, 'recall_consonant': 0.997987, 'recall_word': 0.996026, 'acc_grapheme': 0.996372, 'acc_vowel': 0.998633, 'acc_consonant': 0.998534, 'acc_word': 0.996099, 'loss_grapheme': 0.132114, 'loss_vowel': 0.083359, 'loss_consonant': 0.058515, 'loss_word': 0.084024}\n",
      "###>>>>> saved\n",
      "   70 | 0.000005 | 160000/160596 | 11.5364 | 8.4926 ||\n",
      "val: {'recall': 0.99712, 'recall_grapheme': 0.996228, 'recall_vowel': 0.998171, 'recall_consonant': 0.997855, 'recall_word': 0.996019, 'acc_grapheme': 0.996148, 'acc_vowel': 0.998658, 'acc_consonant': 0.998435, 'acc_word': 0.996148, 'loss_grapheme': 0.153361, 'loss_vowel': 0.090587, 'loss_consonant': 0.070349, 'loss_word': 0.092097}\n",
      "   71 | 0.000004 | 160000/160596 | 8.9344 | 8.0685 |||\n",
      "val: {'recall': 0.997023, 'recall_grapheme': 0.996197, 'recall_vowel': 0.997901, 'recall_consonant': 0.997796, 'recall_word': 0.995719, 'acc_grapheme': 0.996074, 'acc_vowel': 0.99841, 'acc_consonant': 0.998385, 'acc_word': 0.995825, 'loss_grapheme': 0.164716, 'loss_vowel': 0.096196, 'loss_consonant': 0.072386, 'loss_word': 0.099577}\n",
      "   72 | 0.000003 | 160000/160596 | 7.1307 | 8.4990 |||\n",
      "val: {'recall': 0.99626, 'recall_grapheme': 0.995139, 'recall_vowel': 0.997616, 'recall_consonant': 0.997144, 'recall_word': 0.994414, 'acc_grapheme': 0.99513, 'acc_vowel': 0.997938, 'acc_consonant': 0.998112, 'acc_word': 0.994459, 'loss_grapheme': 0.196096, 'loss_vowel': 0.117644, 'loss_consonant': 0.09295, 'loss_word': 0.122239}\n",
      "   73 | 0.000002 | 160000/160596 | 14.2429 | 7.9916 ||\n",
      "val: {'recall': 0.996889, 'recall_grapheme': 0.996003, 'recall_vowel': 0.997745, 'recall_consonant': 0.997805, 'recall_word': 0.995429, 'acc_grapheme': 0.995825, 'acc_vowel': 0.99841, 'acc_consonant': 0.998335, 'acc_word': 0.995527, 'loss_grapheme': 0.167211, 'loss_vowel': 0.102881, 'loss_consonant': 0.077866, 'loss_word': 0.095513}\n",
      "   74 | 0.000001 | 160000/160596 | 6.3103 | 8.2793 |||\n",
      "val: {'recall': 0.996819, 'recall_grapheme': 0.996066, 'recall_vowel': 0.997877, 'recall_consonant': 0.997267, 'recall_word': 0.99538, 'acc_grapheme': 0.995801, 'acc_vowel': 0.998435, 'acc_consonant': 0.998236, 'acc_word': 0.995502, 'loss_grapheme': 0.166656, 'loss_vowel': 0.09722, 'loss_consonant': 0.075622, 'loss_word': 0.097693}\n",
      "   75 | 0.000001 | 160000/160596 | 3.8377 | 7.8880 |||\n",
      "val: {'recall': 0.997057, 'recall_grapheme': 0.99622, 'recall_vowel': 0.997844, 'recall_consonant': 0.997942, 'recall_word': 0.99568, 'acc_grapheme': 0.996049, 'acc_vowel': 0.998509, 'acc_consonant': 0.998459, 'acc_word': 0.995801, 'loss_grapheme': 0.154702, 'loss_vowel': 0.094428, 'loss_consonant': 0.071194, 'loss_word': 0.090942}\n",
      "   76 | 0.000001 | 160000/160596 | 1.8786 | 8.2382 |||\n",
      "val: {'recall': 0.996892, 'recall_grapheme': 0.995969, 'recall_vowel': 0.997799, 'recall_consonant': 0.997832, 'recall_word': 0.995509, 'acc_grapheme': 0.9959, 'acc_vowel': 0.998484, 'acc_consonant': 0.998335, 'acc_word': 0.995627, 'loss_grapheme': 0.153057, 'loss_vowel': 0.088803, 'loss_consonant': 0.066325, 'loss_word': 0.088918}\n",
      "   77 | 0.000000 | 160000/160596 | 5.8142 | 7.9935 ||\n",
      "val: {'recall': 0.99658, 'recall_grapheme': 0.995753, 'recall_vowel': 0.997628, 'recall_consonant': 0.997187, 'recall_word': 0.995084, 'acc_grapheme': 0.995751, 'acc_vowel': 0.998186, 'acc_consonant': 0.998161, 'acc_word': 0.995179, 'loss_grapheme': 0.178276, 'loss_vowel': 0.099004, 'loss_consonant': 0.079616, 'loss_word': 0.112023}\n",
      "   78 | 0.000000 | 160000/160596 | 9.9866 | 8.3715 ||\n",
      "val: {'recall': 0.99716, 'recall_grapheme': 0.996424, 'recall_vowel': 0.997972, 'recall_consonant': 0.997822, 'recall_word': 0.995604, 'acc_grapheme': 0.996124, 'acc_vowel': 0.998509, 'acc_consonant': 0.99841, 'acc_word': 0.995701, 'loss_grapheme': 0.139375, 'loss_vowel': 0.078173, 'loss_consonant': 0.061411, 'loss_word': 0.086465}\n",
      "   79 | 0.000000 | 160000/160596 | 1.4263 | 8.4897 ||\n",
      "val: {'recall': 0.997162, 'recall_grapheme': 0.996426, 'recall_vowel': 0.997885, 'recall_consonant': 0.99791, 'recall_word': 0.995757, 'acc_grapheme': 0.996099, 'acc_vowel': 0.998559, 'acc_consonant': 0.998435, 'acc_word': 0.9959, 'loss_grapheme': 0.143333, 'loss_vowel': 0.085117, 'loss_consonant': 0.063569, 'loss_word': 0.088041}\n",
      "CYCLE: 4\n",
      "{'recall': 0.997162, 'recall_grapheme': 0.996426, 'recall_vowel': 0.997885, 'recall_consonant': 0.99791, 'recall_word': 0.995757, 'acc_grapheme': 0.996099, 'acc_vowel': 0.998559, 'acc_consonant': 0.998435, 'acc_word': 0.9959, 'loss_grapheme': 0.143333, 'loss_vowel': 0.085117, 'loss_consonant': 0.063569, 'loss_word': 0.088041}\n",
      "    0 | 0.000030 | 160000/160596 | 3.1188 | 8.6542 ||\n",
      "val: {'recall': 0.99661, 'recall_grapheme': 0.995619, 'recall_vowel': 0.997676, 'recall_consonant': 0.997527, 'recall_word': 0.994776, 'acc_grapheme': 0.995552, 'acc_vowel': 0.998161, 'acc_consonant': 0.998136, 'acc_word': 0.994906, 'loss_grapheme': 0.159359, 'loss_vowel': 0.093568, 'loss_consonant': 0.070884, 'loss_word': 0.098186}\n",
      "    1 | 0.000060 | 160000/160596 | 14.7067 | 8.3110 ||\n",
      "val: {'recall': 0.996901, 'recall_grapheme': 0.995879, 'recall_vowel': 0.998112, 'recall_consonant': 0.997736, 'recall_word': 0.9951, 'acc_grapheme': 0.995527, 'acc_vowel': 0.99841, 'acc_consonant': 0.998285, 'acc_word': 0.995204, 'loss_grapheme': 0.163796, 'loss_vowel': 0.092784, 'loss_consonant': 0.069767, 'loss_word': 0.103177}\n",
      "    2 | 0.000090 | 160000/160596 | 7.6581 | 7.8798 |||\n",
      "val: {'recall': 0.996486, 'recall_grapheme': 0.995549, 'recall_vowel': 0.997708, 'recall_consonant': 0.997137, 'recall_word': 0.99436, 'acc_grapheme': 0.995403, 'acc_vowel': 0.997938, 'acc_consonant': 0.998112, 'acc_word': 0.994384, 'loss_grapheme': 0.164867, 'loss_vowel': 0.092666, 'loss_consonant': 0.075428, 'loss_word': 0.106895}\n",
      "    3 | 0.000119 | 160000/160596 | 9.0014 | 8.1916 ||\n",
      "val: {'recall': 0.996831, 'recall_grapheme': 0.996509, 'recall_vowel': 0.998319, 'recall_consonant': 0.995985, 'recall_word': 0.995377, 'acc_grapheme': 0.995801, 'acc_vowel': 0.998658, 'acc_consonant': 0.998335, 'acc_word': 0.995403, 'loss_grapheme': 0.143664, 'loss_vowel': 0.086304, 'loss_consonant': 0.061013, 'loss_word': 0.100892}\n",
      "    4 | 0.000148 | 160000/160596 | 8.9435 | 8.3024 ||\n",
      "val: {'recall': 0.996296, 'recall_grapheme': 0.995038, 'recall_vowel': 0.998141, 'recall_consonant': 0.996967, 'recall_word': 0.994512, 'acc_grapheme': 0.994931, 'acc_vowel': 0.997987, 'acc_consonant': 0.997888, 'acc_word': 0.994658, 'loss_grapheme': 0.141318, 'loss_vowel': 0.099024, 'loss_consonant': 0.070948, 'loss_word': 0.087099}\n",
      "    5 | 0.000148 | 160000/160596 | 6.5728 | 8.6371 |||\n",
      "val: {'recall': 0.996309, 'recall_grapheme': 0.994938, 'recall_vowel': 0.998017, 'recall_consonant': 0.997343, 'recall_word': 0.994312, 'acc_grapheme': 0.994807, 'acc_vowel': 0.998062, 'acc_consonant': 0.997987, 'acc_word': 0.994434, 'loss_grapheme': 0.167576, 'loss_vowel': 0.097686, 'loss_consonant': 0.076855, 'loss_word': 0.10597}\n",
      "    6 | 0.000147 | 160000/160596 | 4.7479 | 8.4008 ||\n",
      "val: {'recall': 0.995892, 'recall_grapheme': 0.994375, 'recall_vowel': 0.99737, 'recall_consonant': 0.997448, 'recall_word': 0.994225, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998087, 'acc_consonant': 0.997962, 'acc_word': 0.994185, 'loss_grapheme': 0.201118, 'loss_vowel': 0.117362, 'loss_consonant': 0.089331, 'loss_word': 0.129859}\n",
      "    7 | 0.000146 | 160000/160596 | 8.5660 | 8.2756 |||\n",
      "val: {'recall': 0.995531, 'recall_grapheme': 0.993851, 'recall_vowel': 0.997205, 'recall_consonant': 0.997216, 'recall_word': 0.992577, 'acc_grapheme': 0.993266, 'acc_vowel': 0.997391, 'acc_consonant': 0.99759, 'acc_word': 0.992595, 'loss_grapheme': 0.166241, 'loss_vowel': 0.103571, 'loss_consonant': 0.07229, 'loss_word': 0.116669}\n",
      "    8 | 0.000145 | 160000/160596 | 4.0725 | 8.6994 |||\n",
      "val: {'recall': 0.99647, 'recall_grapheme': 0.995851, 'recall_vowel': 0.997653, 'recall_consonant': 0.996527, 'recall_word': 0.994602, 'acc_grapheme': 0.995378, 'acc_vowel': 0.998012, 'acc_consonant': 0.998037, 'acc_word': 0.994633, 'loss_grapheme': 0.146714, 'loss_vowel': 0.090343, 'loss_consonant': 0.067969, 'loss_word': 0.103836}\n",
      "    9 | 0.000144 | 160000/160596 | 6.3518 | 8.4688 |||\n",
      "val: {'recall': 0.99637, 'recall_grapheme': 0.995445, 'recall_vowel': 0.997913, 'recall_consonant': 0.996676, 'recall_word': 0.994999, 'acc_grapheme': 0.995304, 'acc_vowel': 0.998136, 'acc_consonant': 0.998112, 'acc_word': 0.99508, 'loss_grapheme': 0.170699, 'loss_vowel': 0.102304, 'loss_consonant': 0.076732, 'loss_word': 0.113014}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 | 0.000143 | 160000/160596 | 5.0539 | 8.6628 ||\n",
      "val: {'recall': 0.99605, 'recall_grapheme': 0.994534, 'recall_vowel': 0.997466, 'recall_consonant': 0.997664, 'recall_word': 0.994315, 'acc_grapheme': 0.994956, 'acc_vowel': 0.997838, 'acc_consonant': 0.998161, 'acc_word': 0.994359, 'loss_grapheme': 0.167985, 'loss_vowel': 0.100405, 'loss_consonant': 0.074104, 'loss_word': 0.104733}\n",
      "   11 | 0.000142 | 160000/160596 | 13.9985 | 7.9454 |\n",
      "val: {'recall': 0.996102, 'recall_grapheme': 0.994722, 'recall_vowel': 0.997261, 'recall_consonant': 0.997701, 'recall_word': 0.994891, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998012, 'acc_consonant': 0.998211, 'acc_word': 0.995005, 'loss_grapheme': 0.16785, 'loss_vowel': 0.10523, 'loss_consonant': 0.068006, 'loss_word': 0.113005}\n",
      "   12 | 0.000140 | 160000/160596 | 2.3755 | 8.3402 ||\n",
      "val: {'recall': 0.996366, 'recall_grapheme': 0.995465, 'recall_vowel': 0.997259, 'recall_consonant': 0.997277, 'recall_word': 0.994439, 'acc_grapheme': 0.995105, 'acc_vowel': 0.997863, 'acc_consonant': 0.997813, 'acc_word': 0.994508, 'loss_grapheme': 0.154686, 'loss_vowel': 0.088394, 'loss_consonant': 0.066025, 'loss_word': 0.102879}\n",
      "   13 | 0.000139 | 160000/160596 | 1.3807 | 7.9930 |||\n",
      "val: {'recall': 0.996294, 'recall_grapheme': 0.995265, 'recall_vowel': 0.997582, 'recall_consonant': 0.997063, 'recall_word': 0.994527, 'acc_grapheme': 0.995229, 'acc_vowel': 0.998236, 'acc_consonant': 0.998062, 'acc_word': 0.994583, 'loss_grapheme': 0.150912, 'loss_vowel': 0.095497, 'loss_consonant': 0.064886, 'loss_word': 0.099192}\n",
      "   14 | 0.000137 | 160000/160596 | 6.5699 | 8.4063 |||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-6df1386d1bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-f8923ea1aff0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cycles\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CYCLE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#args.base_lr = 4e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#args.num_epochs = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-f8923ea1aff0>\u001b[0m in \u001b[0;36mtrain_cycle\u001b[0;34m(args, model, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#train_iter > 0 and train_iter % args.iter_val == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-5ca1aeb200dd>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
