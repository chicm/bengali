{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image\n",
    "from utils import bn_update, moving_average, copy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations as albu\n",
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arange(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in train_loader:\n",
    "#    print(x)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNet B0-B8.\n",
    "    Args:\n",
    "        cfg (CfgNode): configs\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='tf_efficientnet_b1'):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        pretrained = True\n",
    "        input_channels = 1\n",
    "        pool_type = 'avg'\n",
    "        drop_connect_rate = 0.2\n",
    "        self.drop_rate = 0.\n",
    "        cls_head = 'linear'\n",
    "        num_total_classes = 168 + 11 + 7 + 1295\n",
    "\n",
    "        backbone = timm.create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=input_channels,\n",
    "            drop_connect_rate=drop_connect_rate,\n",
    "        )\n",
    "        self.conv_stem = backbone.conv_stem\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.act1 = backbone.act1\n",
    "        ### Original blocks ###\n",
    "        for i in range(len((backbone.blocks))):\n",
    "            setattr(self, \"block{}\".format(str(i)), backbone.blocks[i])\n",
    "        self.conv_head = backbone.conv_head\n",
    "        self.bn2 = backbone.bn2\n",
    "        self.act2 = backbone.act2\n",
    "        self.aux_block5 = backbone.blocks[5]\n",
    "        self.aux_num_features = self.block5[-1].bn3.num_features\n",
    "        self.aux_head4 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act4 = Swish()\n",
    "        self.aux_head5 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act5 = Swish()\n",
    "        self.global_pool = SelectAdaptivePool2d(pool_type=pool_type)\n",
    "        self.num_features = backbone.num_features * self.global_pool.feat_mult()\n",
    "        assert cls_head == 'linear'\n",
    "        if cls_head == \"linear\":\n",
    "            ### Baseline head ###\n",
    "            self.fc = nn.Linear(self.num_features, num_total_classes)            \n",
    "            self.aux_fc1 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            self.aux_fc2 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            \n",
    "            for fc in [self.fc, self.aux_fc1, self.aux_fc2]:\n",
    "                nn.init.zeros_(fc.bias.data)\n",
    "        elif cls_head == \"norm_softmax\":\n",
    "            ### NormSoftmax ###\n",
    "            self.grapheme_fc = NormSoftmax(self.num_features, num_grapheme_classes)\n",
    "            self.consonant_fc = NormSoftmax(self.num_features, num_consonant_classes)\n",
    "            self.vowel_fc = NormSoftmax(self.num_features, num_vowel_classes)\n",
    "        # Replace with Mish activation\n",
    "        #if cfg.MODEL_ACTIVATION == \"mish\":\n",
    "        #    convert_swish_to_mish(self)\n",
    "        del backbone\n",
    "\n",
    "    def _features(self, x):\n",
    "        x = self.conv_stem(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x); b4 = x\n",
    "        x = self.block5(x); b4 = self.aux_block5(b4); b5 = x\n",
    "        x = self.block6(x)\n",
    "        x = self.conv_head(x); b4 = self.aux_head4(b4); b5 = self.aux_head5(b5)\n",
    "        x = self.bn2(x); b4 = self.bn4(b4); b5 = self.bn5(b5)\n",
    "        x = self.act2(x); b4 = self.act4(b4); b5 = self.act5(b5)\n",
    "        return b4, b5, x\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "\n",
    "        # _, _, x = self._features(x)\n",
    "        b4, b5, x = self._features(x)\n",
    "        x = self.global_pool(x); b4 = self.global_pool(b4); b5 = self.global_pool(b5)\n",
    "        x = torch.flatten(x, 1); b4 = torch.flatten(b4, 1); b5 = torch.flatten(b5, 1)\n",
    "        if self.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.drop_rate, training=self.training)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        aux_logits1 = self.aux_fc1(b4)\n",
    "        aux_logits2 = self.aux_fc2(b5)\n",
    "        \n",
    "        return logits, aux_logits1, aux_logits2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model4-ckps'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, preds3, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2) == len(preds3)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    recall_word = sklearn.metrics.recall_score(preds3, y[:, 3], average='macro')\n",
    "    \n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    metrics['recall_word'] = round(recall_word, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    metrics['acc_word'] = round((preds3 == y[:, 3]).sum() / len(y), 6)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    loss3 = F.cross_entropy(outputs[3], y_true[:, 3], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 + loss3 #, loss0.item(), loss1.item(), loss2.item()\n",
    "    #return loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2, loss3 = 0., 0., 0., 0.\n",
    "    preds0, preds1, preds2, preds3 = [], [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(x)\n",
    "            #avg_outputs = torch.mean(torch.stack([outputs, outputs_aux1, outputs_aux2], 0), 0)\n",
    "            outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            preds3.append(torch.max(outputs[3], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            loss3 += F.cross_entropy(outputs[3], y[:, 3], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    preds3 = torch.cat(preds3, 0).cpu().numpy()\n",
    "    \n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, preds3, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    metrics['loss_word'] = round(loss3 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5157008222205659"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "        img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "        batch_size = img.size(0)\n",
    "        r = np.random.rand()\n",
    "\n",
    "        if r < 0.3:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            #img[:, :, bby1:bby2, bbx1:bbx2] = img[rand_index, :, bby1:bby2, bbx1:bbx2] #for new cutmix\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "            loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r > 0.7:\n",
    "            img = grid(img)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, targets)\n",
    "            loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        else:\n",
    "            orig_img, targets = mixup(orig_img, targets)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "            loss_primary = mixup_criterion(outputs, targets)\n",
    "            loss_aux1 = mixup_criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = mixup_criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "            #loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        lr_scheduler(optimizer, batch_idx, epoch)\n",
    "        optimizer.step()            \n",
    "        \n",
    "        current_lr = get_lrs(optimizer)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "            epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "            loss.item(), train_loss/(batch_idx+1)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = 0.\n",
    "\n",
    "def validate_and_save(model, model_file, val_loader, save=False):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        best_metrics = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "def train(args):\n",
    "    model, model_file = create_model(args)\n",
    "    model = model.cuda()\n",
    "\n",
    "    swa_model, _ = create_model(args)\n",
    "    swa_model = swa_model.cuda()\n",
    "    swa_model_file = model_file\n",
    "\n",
    "    optimizer = make_optimizer(model)\n",
    "    lr_scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    [model, swa_model], optimizer = amp.initialize([model, swa_model], optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        swa_model = nn.DataParallel(swa_model)\n",
    "    \n",
    "    validate_and_save(model, model_file, val_loader, save=False)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "        for epoch in range(args.start_epoch, args.num_epochs):\n",
    "            grid.set_prob(epoch, args.st_epochs)\n",
    "            train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\n",
    "            validate_and_save(model, model_file, val_loader, save=True)\n",
    "            \n",
    "            if (epoch+1) == args.swa_start and cycle == 1:\n",
    "                copy_model(swa_model, model)\n",
    "                swa_n = 0\n",
    "            if (epoch+1) >= args.swa_start and (epoch+1) % args.swa_freq == 0:\n",
    "                print('SWA>>>:')\n",
    "                moving_average(swa_model, model, 1.0 / (swa_n + 1))\n",
    "                swa_n += 1\n",
    "                bn_update(train_loader, swa_model)\n",
    "                validate_and_save(swa_model, swa_model_file, val_loader, save=True)\n",
    "\n",
    "        #args.base_lr = 4e-4\n",
    "        # reset scheduler at each cycle\n",
    "        lr_scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'tf_efficientnet_b1'\n",
    "args.ckp_name = 'model4_eb1_fold2.pth'\n",
    "\n",
    "args.base_lr = 3e-4\n",
    "args.num_epochs = 100\n",
    "args.start_epoch = 0\n",
    "args.warmup_epochs = 10\n",
    "\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 2048\n",
    "args.st_epochs = 10\n",
    "\n",
    "args.swa_start = 20\n",
    "args.swa_freq = 5\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160678, 6) (40162, 6)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.backbone.parameters():\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth, exist: True\n",
      "loading ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth...\n",
      "model file: ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth, exist: True\n",
      "loading ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth...\n",
      "\n",
      "val: {'recall': 0.990337, 'recall_grapheme': 0.987332, 'recall_vowel': 0.994154, 'recall_consonant': 0.99253, 'recall_word': 0.986458, 'acc_grapheme': 0.986181, 'acc_vowel': 0.994796, 'acc_consonant': 0.994771, 'acc_word': 0.986505, 'loss_grapheme': 0.060364, 'loss_vowel': 0.027494, 'loss_consonant': 0.025339, 'loss_word': 0.056859}\n",
      "CYCLE: 1\n",
      "    0 | 0.000030 | 159744/160678 | 9.4789 | 7.5058 ||\n",
      "val: {'recall': 0.9897, 'recall_grapheme': 0.98597, 'recall_vowel': 0.994533, 'recall_consonant': 0.992325, 'recall_word': 0.984844, 'acc_grapheme': 0.984861, 'acc_vowel': 0.994771, 'acc_consonant': 0.994273, 'acc_word': 0.984787, 'loss_grapheme': 0.093394, 'loss_vowel': 0.048771, 'loss_consonant': 0.039665, 'loss_word': 0.083364}\n",
      "    1 | 0.000060 | 159744/160678 | 4.0287 | 7.4837 |||\n",
      "val: {'recall': 0.988867, 'recall_grapheme': 0.984635, 'recall_vowel': 0.994203, 'recall_consonant': 0.991994, 'recall_word': 0.982992, 'acc_grapheme': 0.983218, 'acc_vowel': 0.994522, 'acc_consonant': 0.993775, 'acc_word': 0.982919, 'loss_grapheme': 0.124764, 'loss_vowel': 0.068152, 'loss_consonant': 0.053017, 'loss_word': 0.1132}\n",
      "    2 | 0.000090 | 159744/160678 | 20.7453 | 8.4226 ||\n",
      "val: {'recall': 0.988826, 'recall_grapheme': 0.984029, 'recall_vowel': 0.993959, 'recall_consonant': 0.993287, 'recall_word': 0.983216, 'acc_grapheme': 0.982396, 'acc_vowel': 0.994472, 'acc_consonant': 0.993775, 'acc_word': 0.983118, 'loss_grapheme': 0.198613, 'loss_vowel': 0.123562, 'loss_consonant': 0.087219, 'loss_word': 0.182401}\n",
      "    3 | 0.000119 | 159744/160678 | 14.2137 | 9.5569 ||\n",
      "val: {'recall': 0.989628, 'recall_grapheme': 0.985624, 'recall_vowel': 0.994374, 'recall_consonant': 0.992889, 'recall_word': 0.984075, 'acc_grapheme': 0.984314, 'acc_vowel': 0.994796, 'acc_consonant': 0.994248, 'acc_word': 0.984089, 'loss_grapheme': 0.130989, 'loss_vowel': 0.07759, 'loss_consonant': 0.058215, 'loss_word': 0.11605}\n",
      "    4 | 0.000149 | 159744/160678 | 5.9295 | 7.4212 ||\n",
      "val: {'recall': 0.989254, 'recall_grapheme': 0.985504, 'recall_vowel': 0.994187, 'recall_consonant': 0.991821, 'recall_word': 0.983988, 'acc_grapheme': 0.983816, 'acc_vowel': 0.994522, 'acc_consonant': 0.994049, 'acc_word': 0.983915, 'loss_grapheme': 0.097342, 'loss_vowel': 0.05256, 'loss_consonant': 0.041463, 'loss_word': 0.087231}\n",
      "    5 | 0.000178 | 159744/160678 | 1.1505 | 8.3418 ||\n",
      "val: {'recall': 0.98952, 'recall_grapheme': 0.985604, 'recall_vowel': 0.993674, 'recall_consonant': 0.993199, 'recall_word': 0.984096, 'acc_grapheme': 0.984015, 'acc_vowel': 0.994447, 'acc_consonant': 0.994099, 'acc_word': 0.984015, 'loss_grapheme': 0.112664, 'loss_vowel': 0.062254, 'loss_consonant': 0.048323, 'loss_word': 0.101156}\n",
      "    6 | 0.000207 | 159744/160678 | 7.8204 | 7.3338 ||\n",
      "val: {'recall': 0.988302, 'recall_grapheme': 0.983628, 'recall_vowel': 0.993814, 'recall_consonant': 0.99214, 'recall_word': 0.98317, 'acc_grapheme': 0.98282, 'acc_vowel': 0.994423, 'acc_consonant': 0.99375, 'acc_word': 0.983093, 'loss_grapheme': 0.114893, 'loss_vowel': 0.057148, 'loss_consonant': 0.048045, 'loss_word': 0.103509}\n",
      "    7 | 0.000236 | 159744/160678 | 1.5589 | 9.1883 |||\n",
      "val: {'recall': 0.989148, 'recall_grapheme': 0.984867, 'recall_vowel': 0.994042, 'recall_consonant': 0.992817, 'recall_word': 0.984226, 'acc_grapheme': 0.984015, 'acc_vowel': 0.994622, 'acc_consonant': 0.994398, 'acc_word': 0.984264, 'loss_grapheme': 0.071892, 'loss_vowel': 0.033866, 'loss_consonant': 0.03066, 'loss_word': 0.069013}\n",
      "    8 | 0.000264 | 159744/160678 | 22.0324 | 7.3306 |\n",
      "val: {'recall': 0.988381, 'recall_grapheme': 0.984054, 'recall_vowel': 0.99339, 'recall_consonant': 0.992027, 'recall_word': 0.982322, 'acc_grapheme': 0.982147, 'acc_vowel': 0.994149, 'acc_consonant': 0.993701, 'acc_word': 0.982147, 'loss_grapheme': 0.116549, 'loss_vowel': 0.062023, 'loss_consonant': 0.051112, 'loss_word': 0.105645}\n",
      "    9 | 0.000292 | 159744/160678 | 1.4455 | 8.6475 ||\n",
      "val: {'recall': 0.988038, 'recall_grapheme': 0.983318, 'recall_vowel': 0.993912, 'recall_consonant': 0.991603, 'recall_word': 0.981801, 'acc_grapheme': 0.981301, 'acc_vowel': 0.994149, 'acc_consonant': 0.993526, 'acc_word': 0.981649, 'loss_grapheme': 0.167142, 'loss_vowel': 0.099567, 'loss_consonant': 0.077222, 'loss_word': 0.146315}\n",
      "   10 | 0.000291 | 159744/160678 | 6.3695 | 8.2325 |||\n",
      "val: {'recall': 0.987783, 'recall_grapheme': 0.983187, 'recall_vowel': 0.993469, 'recall_consonant': 0.99129, 'recall_word': 0.982503, 'acc_grapheme': 0.982396, 'acc_vowel': 0.994074, 'acc_consonant': 0.992829, 'acc_word': 0.982322, 'loss_grapheme': 0.120025, 'loss_vowel': 0.060708, 'loss_consonant': 0.046784, 'loss_word': 0.108085}\n",
      "   11 | 0.000289 | 159744/160678 | 8.7469 | 8.5575 |||\n",
      "val: {'recall': 0.987851, 'recall_grapheme': 0.982804, 'recall_vowel': 0.993652, 'recall_consonant': 0.992142, 'recall_word': 0.981464, 'acc_grapheme': 0.982098, 'acc_vowel': 0.99395, 'acc_consonant': 0.993128, 'acc_word': 0.981151, 'loss_grapheme': 0.097852, 'loss_vowel': 0.045088, 'loss_consonant': 0.03734, 'loss_word': 0.093883}\n",
      "   12 | 0.000288 | 159744/160678 | 22.7467 | 9.1434 ||\n",
      "val: {'recall': 0.988312, 'recall_grapheme': 0.984165, 'recall_vowel': 0.993167, 'recall_consonant': 0.991749, 'recall_word': 0.982114, 'acc_grapheme': 0.981774, 'acc_vowel': 0.994124, 'acc_consonant': 0.993551, 'acc_word': 0.981973, 'loss_grapheme': 0.200834, 'loss_vowel': 0.117403, 'loss_consonant': 0.087521, 'loss_word': 0.183559}\n",
      "   13 | 0.000286 | 159744/160678 | 18.0365 | 8.9615 ||\n",
      "val: {'recall': 0.987763, 'recall_grapheme': 0.983076, 'recall_vowel': 0.993173, 'recall_consonant': 0.991725, 'recall_word': 0.981333, 'acc_grapheme': 0.98145, 'acc_vowel': 0.993725, 'acc_consonant': 0.992954, 'acc_word': 0.981176, 'loss_grapheme': 0.192689, 'loss_vowel': 0.103755, 'loss_consonant': 0.082574, 'loss_word': 0.170247}\n",
      "   14 | 0.000284 | 159744/160678 | 6.4102 | 8.7515 ||\n",
      "val: {'recall': 0.98821, 'recall_grapheme': 0.983942, 'recall_vowel': 0.993467, 'recall_consonant': 0.991488, 'recall_word': 0.982952, 'acc_grapheme': 0.982546, 'acc_vowel': 0.993974, 'acc_consonant': 0.993252, 'acc_word': 0.98282, 'loss_grapheme': 0.133114, 'loss_vowel': 0.075729, 'loss_consonant': 0.056035, 'loss_word': 0.119192}\n",
      "   15 | 0.000281 | 159744/160678 | 7.5311 | 8.6044 |||\n",
      "val: {'recall': 0.988251, 'recall_grapheme': 0.983091, 'recall_vowel': 0.993439, 'recall_consonant': 0.993383, 'recall_word': 0.982447, 'acc_grapheme': 0.982122, 'acc_vowel': 0.994074, 'acc_consonant': 0.993501, 'acc_word': 0.982322, 'loss_grapheme': 0.159895, 'loss_vowel': 0.088814, 'loss_consonant': 0.066124, 'loss_word': 0.145406}\n",
      "   16 | 0.000279 | 159744/160678 | 1.4970 | 7.7891 ||\n",
      "val: {'recall': 0.989114, 'recall_grapheme': 0.984873, 'recall_vowel': 0.993962, 'recall_consonant': 0.992747, 'recall_word': 0.984427, 'acc_grapheme': 0.983741, 'acc_vowel': 0.994522, 'acc_consonant': 0.993825, 'acc_word': 0.984164, 'loss_grapheme': 0.090506, 'loss_vowel': 0.049134, 'loss_consonant': 0.03996, 'loss_word': 0.082238}\n",
      "   17 | 0.000277 | 159744/160678 | 13.0773 | 8.4651 ||\n",
      "val: {'recall': 0.98907, 'recall_grapheme': 0.984583, 'recall_vowel': 0.994328, 'recall_consonant': 0.992786, 'recall_word': 0.984125, 'acc_grapheme': 0.98384, 'acc_vowel': 0.994472, 'acc_consonant': 0.9939, 'acc_word': 0.984114, 'loss_grapheme': 0.098308, 'loss_vowel': 0.046535, 'loss_consonant': 0.037275, 'loss_word': 0.087163}\n",
      "   18 | 0.000274 | 159744/160678 | 1.7857 | 8.5358 |||\n",
      "val: {'recall': 0.98793, 'recall_grapheme': 0.982645, 'recall_vowel': 0.994124, 'recall_consonant': 0.992306, 'recall_word': 0.981399, 'acc_grapheme': 0.981873, 'acc_vowel': 0.994298, 'acc_consonant': 0.993227, 'acc_word': 0.981226, 'loss_grapheme': 0.117725, 'loss_vowel': 0.06263, 'loss_consonant': 0.049334, 'loss_word': 0.106963}\n",
      "   19 | 0.000271 | 159744/160678 | 9.5747 | 7.8902 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988936, 'recall_grapheme': 0.985005, 'recall_vowel': 0.994368, 'recall_consonant': 0.991367, 'recall_word': 0.983945, 'acc_grapheme': 0.983318, 'acc_vowel': 0.994672, 'acc_consonant': 0.993701, 'acc_word': 0.983865, 'loss_grapheme': 0.086683, 'loss_vowel': 0.04361, 'loss_consonant': 0.037653, 'loss_word': 0.08012}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990259, 'recall_grapheme': 0.987308, 'recall_vowel': 0.994358, 'recall_consonant': 0.992061, 'recall_word': 0.985989, 'acc_grapheme': 0.986355, 'acc_vowel': 0.994771, 'acc_consonant': 0.994622, 'acc_word': 0.986007, 'loss_grapheme': 0.050811, 'loss_vowel': 0.021157, 'loss_consonant': 0.018222, 'loss_word': 0.050973}\n",
      "   20 | 0.000269 | 159744/160678 | 1.3526 | 8.2948 |||\n",
      "val: {'recall': 0.989608, 'recall_grapheme': 0.985785, 'recall_vowel': 0.994008, 'recall_consonant': 0.992855, 'recall_word': 0.984754, 'acc_grapheme': 0.984986, 'acc_vowel': 0.994622, 'acc_consonant': 0.993974, 'acc_word': 0.984712, 'loss_grapheme': 0.089215, 'loss_vowel': 0.048105, 'loss_consonant': 0.039147, 'loss_word': 0.077621}\n",
      "   21 | 0.000266 | 159744/160678 | 17.4389 | 7.9859 |\n",
      "val: {'recall': 0.98894, 'recall_grapheme': 0.984428, 'recall_vowel': 0.993729, 'recall_consonant': 0.993175, 'recall_word': 0.983352, 'acc_grapheme': 0.982919, 'acc_vowel': 0.994323, 'acc_consonant': 0.993725, 'acc_word': 0.983218, 'loss_grapheme': 0.134452, 'loss_vowel': 0.070016, 'loss_consonant': 0.054962, 'loss_word': 0.117261}\n",
      "   22 | 0.000263 | 159744/160678 | 8.3894 | 8.1962 ||\n",
      "val: {'recall': 0.98821, 'recall_grapheme': 0.983993, 'recall_vowel': 0.993011, 'recall_consonant': 0.991842, 'recall_word': 0.982179, 'acc_grapheme': 0.98277, 'acc_vowel': 0.993999, 'acc_consonant': 0.993676, 'acc_word': 0.981799, 'loss_grapheme': 0.111032, 'loss_vowel': 0.052795, 'loss_consonant': 0.047378, 'loss_word': 0.102439}\n",
      "   23 | 0.000259 | 159744/160678 | 21.3693 | 8.6082 ||\n",
      "val: {'recall': 0.988251, 'recall_grapheme': 0.983532, 'recall_vowel': 0.993355, 'recall_consonant': 0.992584, 'recall_word': 0.9828, 'acc_grapheme': 0.982048, 'acc_vowel': 0.994074, 'acc_consonant': 0.993153, 'acc_word': 0.982645, 'loss_grapheme': 0.21431, 'loss_vowel': 0.137527, 'loss_consonant': 0.100121, 'loss_word': 0.195662}\n",
      "   24 | 0.000256 | 159744/160678 | 22.2085 | 8.2222 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988296, 'recall_grapheme': 0.98345, 'recall_vowel': 0.993721, 'recall_consonant': 0.992562, 'recall_word': 0.982441, 'acc_grapheme': 0.982421, 'acc_vowel': 0.994149, 'acc_consonant': 0.993576, 'acc_word': 0.982371, 'loss_grapheme': 0.136336, 'loss_vowel': 0.071931, 'loss_consonant': 0.059342, 'loss_word': 0.121907}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:17<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990523, 'recall_grapheme': 0.987284, 'recall_vowel': 0.994374, 'recall_consonant': 0.993151, 'recall_word': 0.98644, 'acc_grapheme': 0.986505, 'acc_vowel': 0.994796, 'acc_consonant': 0.994921, 'acc_word': 0.98653, 'loss_grapheme': 0.04935, 'loss_vowel': 0.020715, 'loss_consonant': 0.017762, 'loss_word': 0.049699}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   25 | 0.000253 | 159744/160678 | 1.8741 | 9.1208 |||\n",
      "val: {'recall': 0.989504, 'recall_grapheme': 0.985249, 'recall_vowel': 0.994153, 'recall_consonant': 0.993362, 'recall_word': 0.984132, 'acc_grapheme': 0.98389, 'acc_vowel': 0.994647, 'acc_consonant': 0.993626, 'acc_word': 0.984189, 'loss_grapheme': 0.12757, 'loss_vowel': 0.075535, 'loss_consonant': 0.057451, 'loss_word': 0.107479}\n",
      "   26 | 0.000249 | 159744/160678 | 8.0163 | 8.0592 ||\n",
      "val: {'recall': 0.989168, 'recall_grapheme': 0.985324, 'recall_vowel': 0.993484, 'recall_consonant': 0.992538, 'recall_word': 0.983632, 'acc_grapheme': 0.983666, 'acc_vowel': 0.994348, 'acc_consonant': 0.994099, 'acc_word': 0.983492, 'loss_grapheme': 0.092086, 'loss_vowel': 0.048081, 'loss_consonant': 0.038966, 'loss_word': 0.082575}\n",
      "   27 | 0.000246 | 159744/160678 | 19.8267 | 7.8566 |\n",
      "val: {'recall': 0.988787, 'recall_grapheme': 0.984511, 'recall_vowel': 0.993542, 'recall_consonant': 0.992586, 'recall_word': 0.984157, 'acc_grapheme': 0.983641, 'acc_vowel': 0.994348, 'acc_consonant': 0.993925, 'acc_word': 0.984164, 'loss_grapheme': 0.113229, 'loss_vowel': 0.067164, 'loss_consonant': 0.052078, 'loss_word': 0.09782}\n",
      "   28 | 0.000242 | 159744/160678 | 8.8421 | 8.0728 ||\n",
      "val: {'recall': 0.987799, 'recall_grapheme': 0.982051, 'recall_vowel': 0.994318, 'recall_consonant': 0.992774, 'recall_word': 0.98155, 'acc_grapheme': 0.9815, 'acc_vowel': 0.994124, 'acc_consonant': 0.993302, 'acc_word': 0.981375, 'loss_grapheme': 0.126428, 'loss_vowel': 0.06627, 'loss_consonant': 0.05442, 'loss_word': 0.113281}\n",
      "   29 | 0.000238 | 159744/160678 | 19.3711 | 7.9960 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.9889, 'recall_grapheme': 0.985202, 'recall_vowel': 0.99384, 'recall_consonant': 0.991354, 'recall_word': 0.98418, 'acc_grapheme': 0.984314, 'acc_vowel': 0.994423, 'acc_consonant': 0.994099, 'acc_word': 0.984164, 'loss_grapheme': 0.092515, 'loss_vowel': 0.050087, 'loss_consonant': 0.041369, 'loss_word': 0.082299}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:17<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990405, 'recall_grapheme': 0.987344, 'recall_vowel': 0.994453, 'recall_consonant': 0.992477, 'recall_word': 0.986534, 'acc_grapheme': 0.986679, 'acc_vowel': 0.994746, 'acc_consonant': 0.994871, 'acc_word': 0.986629, 'loss_grapheme': 0.048845, 'loss_vowel': 0.020465, 'loss_consonant': 0.017512, 'loss_word': 0.049324}\n",
      "   30 | 0.000234 | 159744/160678 | 4.0542 | 8.5301 |||\n",
      "val: {'recall': 0.988301, 'recall_grapheme': 0.98392, 'recall_vowel': 0.993878, 'recall_consonant': 0.991488, 'recall_word': 0.982791, 'acc_grapheme': 0.982795, 'acc_vowel': 0.994223, 'acc_consonant': 0.993377, 'acc_word': 0.982595, 'loss_grapheme': 0.131153, 'loss_vowel': 0.066151, 'loss_consonant': 0.052463, 'loss_word': 0.115094}\n",
      "   31 | 0.000230 | 159744/160678 | 7.5961 | 7.6611 |||\n",
      "val: {'recall': 0.988946, 'recall_grapheme': 0.985046, 'recall_vowel': 0.993665, 'recall_consonant': 0.992026, 'recall_word': 0.983982, 'acc_grapheme': 0.983766, 'acc_vowel': 0.994398, 'acc_consonant': 0.994074, 'acc_word': 0.983865, 'loss_grapheme': 0.084214, 'loss_vowel': 0.041244, 'loss_consonant': 0.035013, 'loss_word': 0.077242}\n",
      "   32 | 0.000226 | 159744/160678 | 2.8031 | 7.6238 ||\n",
      "val: {'recall': 0.989047, 'recall_grapheme': 0.984987, 'recall_vowel': 0.993882, 'recall_consonant': 0.992332, 'recall_word': 0.983722, 'acc_grapheme': 0.983716, 'acc_vowel': 0.994398, 'acc_consonant': 0.993676, 'acc_word': 0.983741, 'loss_grapheme': 0.102771, 'loss_vowel': 0.051123, 'loss_consonant': 0.04159, 'loss_word': 0.092602}\n",
      "   33 | 0.000222 | 159744/160678 | 9.0990 | 8.5912 |||\n",
      "val: {'recall': 0.98931, 'recall_grapheme': 0.985302, 'recall_vowel': 0.99379, 'recall_consonant': 0.992848, 'recall_word': 0.984243, 'acc_grapheme': 0.984264, 'acc_vowel': 0.994622, 'acc_consonant': 0.994447, 'acc_word': 0.984239, 'loss_grapheme': 0.08908, 'loss_vowel': 0.045797, 'loss_consonant': 0.039658, 'loss_word': 0.079147}\n",
      "   34 | 0.000218 | 159744/160678 | 1.2664 | 7.9592 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989462, 'recall_grapheme': 0.985308, 'recall_vowel': 0.99446, 'recall_consonant': 0.992773, 'recall_word': 0.984418, 'acc_grapheme': 0.984463, 'acc_vowel': 0.994821, 'acc_consonant': 0.994099, 'acc_word': 0.984438, 'loss_grapheme': 0.087647, 'loss_vowel': 0.042956, 'loss_consonant': 0.036811, 'loss_word': 0.07858}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990528, 'recall_grapheme': 0.987228, 'recall_vowel': 0.994569, 'recall_consonant': 0.993086, 'recall_word': 0.986522, 'acc_grapheme': 0.986754, 'acc_vowel': 0.994846, 'acc_consonant': 0.994945, 'acc_word': 0.986629, 'loss_grapheme': 0.048186, 'loss_vowel': 0.020125, 'loss_consonant': 0.017279, 'loss_word': 0.048626}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   35 | 0.000214 | 159744/160678 | 14.2309 | 8.0334 ||\n",
      "val: {'recall': 0.989974, 'recall_grapheme': 0.985437, 'recall_vowel': 0.994838, 'recall_consonant': 0.994185, 'recall_word': 0.984454, 'acc_grapheme': 0.984214, 'acc_vowel': 0.99497, 'acc_consonant': 0.993999, 'acc_word': 0.984388, 'loss_grapheme': 0.112981, 'loss_vowel': 0.064195, 'loss_consonant': 0.05201, 'loss_word': 0.100207}\n",
      "   36 | 0.000210 | 159744/160678 | 19.6993 | 7.6900 |\n",
      "val: {'recall': 0.98959, 'recall_grapheme': 0.985444, 'recall_vowel': 0.993779, 'recall_consonant': 0.993694, 'recall_word': 0.984512, 'acc_grapheme': 0.984388, 'acc_vowel': 0.994547, 'acc_consonant': 0.994273, 'acc_word': 0.984538, 'loss_grapheme': 0.11717, 'loss_vowel': 0.078271, 'loss_consonant': 0.05862, 'loss_word': 0.09919}\n",
      "   37 | 0.000205 | 159744/160678 | 12.7835 | 8.6160 ||\n",
      "val: {'recall': 0.989366, 'recall_grapheme': 0.985562, 'recall_vowel': 0.993939, 'recall_consonant': 0.992401, 'recall_word': 0.983776, 'acc_grapheme': 0.983716, 'acc_vowel': 0.994647, 'acc_consonant': 0.993427, 'acc_word': 0.983616, 'loss_grapheme': 0.141291, 'loss_vowel': 0.080914, 'loss_consonant': 0.059146, 'loss_word': 0.124526}\n",
      "   38 | 0.000201 | 159744/160678 | 5.6055 | 7.9059 ||\n",
      "val: {'recall': 0.989018, 'recall_grapheme': 0.98506, 'recall_vowel': 0.993957, 'recall_consonant': 0.991993, 'recall_word': 0.984094, 'acc_grapheme': 0.983965, 'acc_vowel': 0.994572, 'acc_consonant': 0.9939, 'acc_word': 0.984089, 'loss_grapheme': 0.075804, 'loss_vowel': 0.037231, 'loss_consonant': 0.031392, 'loss_word': 0.072526}\n",
      "   39 | 0.000196 | 159744/160678 | 21.7066 | 8.6481 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989023, 'recall_grapheme': 0.984342, 'recall_vowel': 0.994443, 'recall_consonant': 0.992963, 'recall_word': 0.983748, 'acc_grapheme': 0.983118, 'acc_vowel': 0.994696, 'acc_consonant': 0.99375, 'acc_word': 0.983691, 'loss_grapheme': 0.17906, 'loss_vowel': 0.121054, 'loss_consonant': 0.082317, 'loss_word': 0.16104}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990482, 'recall_grapheme': 0.987076, 'recall_vowel': 0.994555, 'recall_consonant': 0.993222, 'recall_word': 0.986593, 'acc_grapheme': 0.986779, 'acc_vowel': 0.994821, 'acc_consonant': 0.99502, 'acc_word': 0.986704, 'loss_grapheme': 0.04847, 'loss_vowel': 0.020214, 'loss_consonant': 0.017444, 'loss_word': 0.048813}\n",
      "   40 | 0.000192 | 159744/160678 | 1.3636 | 8.1943 |||\n",
      "val: {'recall': 0.989221, 'recall_grapheme': 0.985267, 'recall_vowel': 0.994034, 'recall_consonant': 0.992315, 'recall_word': 0.984422, 'acc_grapheme': 0.984289, 'acc_vowel': 0.994672, 'acc_consonant': 0.994198, 'acc_word': 0.984413, 'loss_grapheme': 0.094775, 'loss_vowel': 0.050315, 'loss_consonant': 0.041422, 'loss_word': 0.083259}\n",
      "   41 | 0.000187 | 159744/160678 | 11.6867 | 8.1244 |\n",
      "val: {'recall': 0.989693, 'recall_grapheme': 0.985799, 'recall_vowel': 0.994763, 'recall_consonant': 0.992412, 'recall_word': 0.985061, 'acc_grapheme': 0.985085, 'acc_vowel': 0.99512, 'acc_consonant': 0.994348, 'acc_word': 0.985036, 'loss_grapheme': 0.076287, 'loss_vowel': 0.037787, 'loss_consonant': 0.03272, 'loss_word': 0.069233}\n",
      "   42 | 0.000183 | 159744/160678 | 1.4885 | 7.5204 ||\n",
      "val: {'recall': 0.990017, 'recall_grapheme': 0.986483, 'recall_vowel': 0.994468, 'recall_consonant': 0.992633, 'recall_word': 0.986581, 'acc_grapheme': 0.986579, 'acc_vowel': 0.994896, 'acc_consonant': 0.994821, 'acc_word': 0.986654, 'loss_grapheme': 0.053229, 'loss_vowel': 0.023438, 'loss_consonant': 0.02181, 'loss_word': 0.051261}\n",
      "   43 | 0.000178 | 159744/160678 | 18.0521 | 8.4082 ||\n",
      "val: {'recall': 0.989007, 'recall_grapheme': 0.984708, 'recall_vowel': 0.993812, 'recall_consonant': 0.9928, 'recall_word': 0.983783, 'acc_grapheme': 0.983591, 'acc_vowel': 0.994323, 'acc_consonant': 0.993875, 'acc_word': 0.983741, 'loss_grapheme': 0.18133, 'loss_vowel': 0.117377, 'loss_consonant': 0.081829, 'loss_word': 0.157044}\n",
      "   44 | 0.000173 | 159744/160678 | 16.0388 | 7.5934 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989256, 'recall_grapheme': 0.985324, 'recall_vowel': 0.994337, 'recall_consonant': 0.992042, 'recall_word': 0.983813, 'acc_grapheme': 0.98384, 'acc_vowel': 0.994622, 'acc_consonant': 0.993427, 'acc_word': 0.983741, 'loss_grapheme': 0.104321, 'loss_vowel': 0.054441, 'loss_consonant': 0.042862, 'loss_word': 0.093389}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990604, 'recall_grapheme': 0.987275, 'recall_vowel': 0.994623, 'recall_consonant': 0.993244, 'recall_word': 0.986541, 'acc_grapheme': 0.986928, 'acc_vowel': 0.994821, 'acc_consonant': 0.99502, 'acc_word': 0.986629, 'loss_grapheme': 0.048175, 'loss_vowel': 0.020155, 'loss_consonant': 0.017371, 'loss_word': 0.048402}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   45 | 0.000169 | 159744/160678 | 9.8821 | 8.0816 ||\n",
      "val: {'recall': 0.988767, 'recall_grapheme': 0.984553, 'recall_vowel': 0.99404, 'recall_consonant': 0.991923, 'recall_word': 0.983402, 'acc_grapheme': 0.983168, 'acc_vowel': 0.994497, 'acc_consonant': 0.993775, 'acc_word': 0.983293, 'loss_grapheme': 0.142123, 'loss_vowel': 0.083155, 'loss_consonant': 0.061987, 'loss_word': 0.122737}\n",
      "   46 | 0.000164 | 159744/160678 | 14.7486 | 7.7555 |\n",
      "val: {'recall': 0.988536, 'recall_grapheme': 0.984106, 'recall_vowel': 0.994245, 'recall_consonant': 0.991688, 'recall_word': 0.983444, 'acc_grapheme': 0.983367, 'acc_vowel': 0.994721, 'acc_consonant': 0.993551, 'acc_word': 0.983392, 'loss_grapheme': 0.096446, 'loss_vowel': 0.048952, 'loss_consonant': 0.040613, 'loss_word': 0.088372}\n",
      "   47 | 0.000159 | 159744/160678 | 9.4408 | 8.5702 |||\n",
      "val: {'recall': 0.987409, 'recall_grapheme': 0.981846, 'recall_vowel': 0.993434, 'recall_consonant': 0.992507, 'recall_word': 0.980862, 'acc_grapheme': 0.980554, 'acc_vowel': 0.994099, 'acc_consonant': 0.992779, 'acc_word': 0.980604, 'loss_grapheme': 0.217725, 'loss_vowel': 0.101375, 'loss_consonant': 0.08739, 'loss_word': 0.186683}\n",
      "   48 | 0.000155 | 159744/160678 | 6.1712 | 8.5792 |||\n",
      "val: {'recall': 0.988402, 'recall_grapheme': 0.983778, 'recall_vowel': 0.994014, 'recall_consonant': 0.992037, 'recall_word': 0.983032, 'acc_grapheme': 0.982919, 'acc_vowel': 0.994497, 'acc_consonant': 0.993476, 'acc_word': 0.982919, 'loss_grapheme': 0.108543, 'loss_vowel': 0.05969, 'loss_consonant': 0.045379, 'loss_word': 0.097649}\n",
      "   49 | 0.000150 | 159744/160678 | 8.3325 | 7.3340 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989493, 'recall_grapheme': 0.985365, 'recall_vowel': 0.994385, 'recall_consonant': 0.992858, 'recall_word': 0.983786, 'acc_grapheme': 0.983691, 'acc_vowel': 0.994597, 'acc_consonant': 0.993725, 'acc_word': 0.983716, 'loss_grapheme': 0.115793, 'loss_vowel': 0.066759, 'loss_consonant': 0.051506, 'loss_word': 0.103687}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.99067, 'recall_grapheme': 0.987273, 'recall_vowel': 0.994997, 'recall_consonant': 0.993139, 'recall_word': 0.986673, 'acc_grapheme': 0.987028, 'acc_vowel': 0.994896, 'acc_consonant': 0.995045, 'acc_word': 0.986754, 'loss_grapheme': 0.04789, 'loss_vowel': 0.020027, 'loss_consonant': 0.017247, 'loss_word': 0.048142}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   50 | 0.000145 | 159744/160678 | 8.1429 | 8.1141 |||\n",
      "val: {'recall': 0.988597, 'recall_grapheme': 0.983627, 'recall_vowel': 0.994229, 'recall_consonant': 0.992904, 'recall_word': 0.982406, 'acc_grapheme': 0.982322, 'acc_vowel': 0.994522, 'acc_consonant': 0.993302, 'acc_word': 0.982247, 'loss_grapheme': 0.142553, 'loss_vowel': 0.072437, 'loss_consonant': 0.058442, 'loss_word': 0.127221}\n",
      "   51 | 0.000141 | 159744/160678 | 6.6190 | 8.6466 ||\n",
      "val: {'recall': 0.989179, 'recall_grapheme': 0.984598, 'recall_vowel': 0.994363, 'recall_consonant': 0.993156, 'recall_word': 0.983238, 'acc_grapheme': 0.983367, 'acc_vowel': 0.994547, 'acc_consonant': 0.9938, 'acc_word': 0.983093, 'loss_grapheme': 0.111921, 'loss_vowel': 0.058334, 'loss_consonant': 0.048294, 'loss_word': 0.09853}\n",
      "   52 | 0.000136 | 159744/160678 | 9.2693 | 6.9484 |||\n",
      "val: {'recall': 0.989004, 'recall_grapheme': 0.984328, 'recall_vowel': 0.994288, 'recall_consonant': 0.99307, 'recall_word': 0.983595, 'acc_grapheme': 0.983567, 'acc_vowel': 0.994746, 'acc_consonant': 0.994149, 'acc_word': 0.983492, 'loss_grapheme': 0.121638, 'loss_vowel': 0.067192, 'loss_consonant': 0.051795, 'loss_word': 0.10714}\n",
      "   53 | 0.000131 | 159744/160678 | 19.8615 | 8.2764 |\n",
      "val: {'recall': 0.989316, 'recall_grapheme': 0.985066, 'recall_vowel': 0.994392, 'recall_consonant': 0.992742, 'recall_word': 0.984566, 'acc_grapheme': 0.984289, 'acc_vowel': 0.994821, 'acc_consonant': 0.994149, 'acc_word': 0.984612, 'loss_grapheme': 0.097666, 'loss_vowel': 0.055802, 'loss_consonant': 0.044412, 'loss_word': 0.085275}\n",
      "   54 | 0.000127 | 159744/160678 | 14.9805 | 8.1731 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988859, 'recall_grapheme': 0.984429, 'recall_vowel': 0.993731, 'recall_consonant': 0.992847, 'recall_word': 0.982388, 'acc_grapheme': 0.982745, 'acc_vowel': 0.994398, 'acc_consonant': 0.993427, 'acc_word': 0.982197, 'loss_grapheme': 0.15828, 'loss_vowel': 0.089957, 'loss_consonant': 0.06743, 'loss_word': 0.142371}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990735, 'recall_grapheme': 0.987324, 'recall_vowel': 0.994994, 'recall_consonant': 0.993297, 'recall_word': 0.986861, 'acc_grapheme': 0.987077, 'acc_vowel': 0.994896, 'acc_consonant': 0.995145, 'acc_word': 0.986953, 'loss_grapheme': 0.047679, 'loss_vowel': 0.019918, 'loss_consonant': 0.017206, 'loss_word': 0.047904}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   55 | 0.000122 | 159744/160678 | 8.7599 | 7.8213 |||\n",
      "val: {'recall': 0.988512, 'recall_grapheme': 0.983831, 'recall_vowel': 0.994164, 'recall_consonant': 0.992221, 'recall_word': 0.982757, 'acc_grapheme': 0.982844, 'acc_vowel': 0.994472, 'acc_consonant': 0.993452, 'acc_word': 0.982571, 'loss_grapheme': 0.093986, 'loss_vowel': 0.041215, 'loss_consonant': 0.037965, 'loss_word': 0.086272}\n",
      "   56 | 0.000117 | 159744/160678 | 1.5579 | 7.5881 |||\n",
      "val: {'recall': 0.989571, 'recall_grapheme': 0.985042, 'recall_vowel': 0.994847, 'recall_consonant': 0.993353, 'recall_word': 0.984827, 'acc_grapheme': 0.984687, 'acc_vowel': 0.99502, 'acc_consonant': 0.994447, 'acc_word': 0.984687, 'loss_grapheme': 0.08658, 'loss_vowel': 0.04303, 'loss_consonant': 0.035035, 'loss_word': 0.079984}\n",
      "   57 | 0.000113 | 159744/160678 | 16.1320 | 8.2565 ||\n",
      "val: {'recall': 0.988717, 'recall_grapheme': 0.983891, 'recall_vowel': 0.993862, 'recall_consonant': 0.993226, 'recall_word': 0.983182, 'acc_grapheme': 0.982571, 'acc_vowel': 0.994522, 'acc_consonant': 0.993875, 'acc_word': 0.983019, 'loss_grapheme': 0.175026, 'loss_vowel': 0.102521, 'loss_consonant': 0.07527, 'loss_word': 0.158063}\n",
      "   58 | 0.000108 | 159744/160678 | 1.4717 | 7.8004 ||\n",
      "val: {'recall': 0.99033, 'recall_grapheme': 0.986635, 'recall_vowel': 0.994865, 'recall_consonant': 0.993185, 'recall_word': 0.985929, 'acc_grapheme': 0.985882, 'acc_vowel': 0.99517, 'acc_consonant': 0.994771, 'acc_word': 0.985857, 'loss_grapheme': 0.070745, 'loss_vowel': 0.034698, 'loss_consonant': 0.029817, 'loss_word': 0.064785}\n",
      "   59 | 0.000104 | 159744/160678 | 3.3133 | 7.4002 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988833, 'recall_grapheme': 0.984511, 'recall_vowel': 0.994377, 'recall_consonant': 0.991932, 'recall_word': 0.98303, 'acc_grapheme': 0.983218, 'acc_vowel': 0.994771, 'acc_consonant': 0.993651, 'acc_word': 0.982894, 'loss_grapheme': 0.121664, 'loss_vowel': 0.063489, 'loss_consonant': 0.047925, 'loss_word': 0.11098}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:17<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990658, 'recall_grapheme': 0.987222, 'recall_vowel': 0.994908, 'recall_consonant': 0.993281, 'recall_word': 0.98685, 'acc_grapheme': 0.987003, 'acc_vowel': 0.994921, 'acc_consonant': 0.99512, 'acc_word': 0.986953, 'loss_grapheme': 0.047559, 'loss_vowel': 0.019896, 'loss_consonant': 0.017145, 'loss_word': 0.047745}\n",
      "   60 | 0.000099 | 159744/160678 | 4.6438 | 8.5090 ||\n",
      "val: {'recall': 0.988982, 'recall_grapheme': 0.984513, 'recall_vowel': 0.994432, 'recall_consonant': 0.99247, 'recall_word': 0.983044, 'acc_grapheme': 0.98277, 'acc_vowel': 0.994398, 'acc_consonant': 0.993725, 'acc_word': 0.982844, 'loss_grapheme': 0.146558, 'loss_vowel': 0.073358, 'loss_consonant': 0.058898, 'loss_word': 0.128465}\n",
      "   61 | 0.000095 | 159744/160678 | 10.6517 | 7.0547 |\n",
      "val: {'recall': 0.989536, 'recall_grapheme': 0.985423, 'recall_vowel': 0.994394, 'recall_consonant': 0.992903, 'recall_word': 0.984706, 'acc_grapheme': 0.984662, 'acc_vowel': 0.994896, 'acc_consonant': 0.994373, 'acc_word': 0.984662, 'loss_grapheme': 0.082994, 'loss_vowel': 0.042477, 'loss_consonant': 0.036448, 'loss_word': 0.074941}\n",
      "   62 | 0.000090 | 159744/160678 | 22.7484 | 8.1026 ||\n",
      "val: {'recall': 0.988723, 'recall_grapheme': 0.983885, 'recall_vowel': 0.993713, 'recall_consonant': 0.99341, 'recall_word': 0.983301, 'acc_grapheme': 0.982695, 'acc_vowel': 0.994597, 'acc_consonant': 0.9939, 'acc_word': 0.983218, 'loss_grapheme': 0.170759, 'loss_vowel': 0.102486, 'loss_consonant': 0.075641, 'loss_word': 0.151501}\n",
      "   63 | 0.000086 | 159744/160678 | 6.7573 | 8.4727 |||\n",
      "val: {'recall': 0.988886, 'recall_grapheme': 0.984277, 'recall_vowel': 0.994476, 'recall_consonant': 0.992515, 'recall_word': 0.983315, 'acc_grapheme': 0.983243, 'acc_vowel': 0.994672, 'acc_consonant': 0.993725, 'acc_word': 0.983143, 'loss_grapheme': 0.113506, 'loss_vowel': 0.057914, 'loss_consonant': 0.047619, 'loss_word': 0.098856}\n",
      "   64 | 0.000082 | 159744/160678 | 12.4690 | 7.2275 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989267, 'recall_grapheme': 0.98476, 'recall_vowel': 0.994137, 'recall_consonant': 0.99341, 'recall_word': 0.984396, 'acc_grapheme': 0.98394, 'acc_vowel': 0.994846, 'acc_consonant': 0.994223, 'acc_word': 0.984338, 'loss_grapheme': 0.089384, 'loss_vowel': 0.046607, 'loss_consonant': 0.036563, 'loss_word': 0.081633}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990633, 'recall_grapheme': 0.987103, 'recall_vowel': 0.995025, 'recall_consonant': 0.993301, 'recall_word': 0.986872, 'acc_grapheme': 0.986853, 'acc_vowel': 0.994921, 'acc_consonant': 0.995219, 'acc_word': 0.986978, 'loss_grapheme': 0.047322, 'loss_vowel': 0.019783, 'loss_consonant': 0.017022, 'loss_word': 0.047532}\n",
      "   65 | 0.000078 | 159744/160678 | 18.8463 | 7.9064 ||\n",
      "val: {'recall': 0.988745, 'recall_grapheme': 0.983924, 'recall_vowel': 0.994189, 'recall_consonant': 0.992942, 'recall_word': 0.983294, 'acc_grapheme': 0.983069, 'acc_vowel': 0.994522, 'acc_consonant': 0.9939, 'acc_word': 0.983218, 'loss_grapheme': 0.137053, 'loss_vowel': 0.074878, 'loss_consonant': 0.056614, 'loss_word': 0.118922}\n",
      "   66 | 0.000074 | 159744/160678 | 20.9526 | 8.9481 |\n",
      "val: {'recall': 0.989395, 'recall_grapheme': 0.985209, 'recall_vowel': 0.994419, 'recall_consonant': 0.992742, 'recall_word': 0.983909, 'acc_grapheme': 0.983865, 'acc_vowel': 0.994896, 'acc_consonant': 0.994099, 'acc_word': 0.983915, 'loss_grapheme': 0.160569, 'loss_vowel': 0.106633, 'loss_consonant': 0.076556, 'loss_word': 0.140707}\n",
      "   67 | 0.000070 | 159744/160678 | 0.4762 | 7.4331 ||\n",
      "val: {'recall': 0.990557, 'recall_grapheme': 0.987122, 'recall_vowel': 0.994611, 'recall_consonant': 0.993375, 'recall_word': 0.986205, 'acc_grapheme': 0.986081, 'acc_vowel': 0.99507, 'acc_consonant': 0.994896, 'acc_word': 0.986206, 'loss_grapheme': 0.071874, 'loss_vowel': 0.036881, 'loss_consonant': 0.030734, 'loss_word': 0.064863}\n",
      "   68 | 0.000066 | 159744/160678 | 22.0222 | 8.2049 |\n",
      "val: {'recall': 0.989911, 'recall_grapheme': 0.985731, 'recall_vowel': 0.994861, 'recall_consonant': 0.99332, 'recall_word': 0.985007, 'acc_grapheme': 0.984712, 'acc_vowel': 0.995219, 'acc_consonant': 0.994597, 'acc_word': 0.985011, 'loss_grapheme': 0.119518, 'loss_vowel': 0.07471, 'loss_consonant': 0.053454, 'loss_word': 0.104457}\n",
      "   69 | 0.000062 | 159744/160678 | 5.0886 | 8.1213 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.988821, 'recall_grapheme': 0.984254, 'recall_vowel': 0.994623, 'recall_consonant': 0.992151, 'recall_word': 0.98317, 'acc_grapheme': 0.982994, 'acc_vowel': 0.994846, 'acc_consonant': 0.993925, 'acc_word': 0.982969, 'loss_grapheme': 0.157407, 'loss_vowel': 0.088928, 'loss_consonant': 0.065717, 'loss_word': 0.138219}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990765, 'recall_grapheme': 0.987321, 'recall_vowel': 0.995107, 'recall_consonant': 0.993313, 'recall_word': 0.9869, 'acc_grapheme': 0.987028, 'acc_vowel': 0.99497, 'acc_consonant': 0.995269, 'acc_word': 0.987003, 'loss_grapheme': 0.047143, 'loss_vowel': 0.019707, 'loss_consonant': 0.016946, 'loss_word': 0.047352}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   70 | 0.000058 | 159744/160678 | 1.4352 | 7.4325 |||\n",
      "val: {'recall': 0.989979, 'recall_grapheme': 0.986158, 'recall_vowel': 0.995098, 'recall_consonant': 0.992499, 'recall_word': 0.985187, 'acc_grapheme': 0.985235, 'acc_vowel': 0.99517, 'acc_consonant': 0.994647, 'acc_word': 0.985235, 'loss_grapheme': 0.082649, 'loss_vowel': 0.04285, 'loss_consonant': 0.035072, 'loss_word': 0.074061}\n",
      "   71 | 0.000054 | 159744/160678 | 9.1432 | 8.8498 ||\n",
      "val: {'recall': 0.989769, 'recall_grapheme': 0.985506, 'recall_vowel': 0.994795, 'recall_consonant': 0.993267, 'recall_word': 0.984611, 'acc_grapheme': 0.984488, 'acc_vowel': 0.99502, 'acc_consonant': 0.994423, 'acc_word': 0.984587, 'loss_grapheme': 0.14918, 'loss_vowel': 0.096265, 'loss_consonant': 0.069723, 'loss_word': 0.125846}\n",
      "   72 | 0.000051 | 159744/160678 | 14.3821 | 7.2387 ||\n",
      "val: {'recall': 0.98874, 'recall_grapheme': 0.984213, 'recall_vowel': 0.994334, 'recall_consonant': 0.992201, 'recall_word': 0.983477, 'acc_grapheme': 0.983118, 'acc_vowel': 0.994871, 'acc_consonant': 0.993925, 'acc_word': 0.983417, 'loss_grapheme': 0.119961, 'loss_vowel': 0.062979, 'loss_consonant': 0.051564, 'loss_word': 0.104173}\n",
      "   73 | 0.000047 | 159744/160678 | 21.9308 | 7.3499 |\n",
      "val: {'recall': 0.989948, 'recall_grapheme': 0.986103, 'recall_vowel': 0.994776, 'recall_consonant': 0.992809, 'recall_word': 0.985635, 'acc_grapheme': 0.985011, 'acc_vowel': 0.995095, 'acc_consonant': 0.994597, 'acc_word': 0.985683, 'loss_grapheme': 0.126253, 'loss_vowel': 0.07736, 'loss_consonant': 0.058005, 'loss_word': 0.105666}\n",
      "   74 | 0.000044 | 159744/160678 | 21.3870 | 7.7021 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990407, 'recall_grapheme': 0.986887, 'recall_vowel': 0.994903, 'recall_consonant': 0.992953, 'recall_word': 0.986495, 'acc_grapheme': 0.986181, 'acc_vowel': 0.99517, 'acc_consonant': 0.99497, 'acc_word': 0.986554, 'loss_grapheme': 0.071698, 'loss_vowel': 0.036856, 'loss_consonant': 0.030908, 'loss_word': 0.065154}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:19<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990837, 'recall_grapheme': 0.987494, 'recall_vowel': 0.99501, 'recall_consonant': 0.993349, 'recall_word': 0.986901, 'acc_grapheme': 0.987052, 'acc_vowel': 0.994995, 'acc_consonant': 0.995319, 'acc_word': 0.987003, 'loss_grapheme': 0.046995, 'loss_vowel': 0.019641, 'loss_consonant': 0.016824, 'loss_word': 0.047232}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   75 | 0.000041 | 159744/160678 | 9.6152 | 7.6573 ||\n",
      "val: {'recall': 0.988524, 'recall_grapheme': 0.98377, 'recall_vowel': 0.994311, 'recall_consonant': 0.992246, 'recall_word': 0.982668, 'acc_grapheme': 0.982147, 'acc_vowel': 0.994721, 'acc_consonant': 0.99375, 'acc_word': 0.982496, 'loss_grapheme': 0.173966, 'loss_vowel': 0.099902, 'loss_consonant': 0.074183, 'loss_word': 0.149593}\n",
      "   76 | 0.000038 | 159744/160678 | 5.6551 | 7.9571 |||\n",
      "val: {'recall': 0.989448, 'recall_grapheme': 0.98506, 'recall_vowel': 0.994526, 'recall_consonant': 0.993147, 'recall_word': 0.984442, 'acc_grapheme': 0.984114, 'acc_vowel': 0.994995, 'acc_consonant': 0.994323, 'acc_word': 0.984438, 'loss_grapheme': 0.143166, 'loss_vowel': 0.089371, 'loss_consonant': 0.064969, 'loss_word': 0.122126}\n",
      "   77 | 0.000034 | 159744/160678 | 5.6261 | 8.2637 ||\n",
      "val: {'recall': 0.989554, 'recall_grapheme': 0.985475, 'recall_vowel': 0.994727, 'recall_consonant': 0.992537, 'recall_word': 0.984369, 'acc_grapheme': 0.984662, 'acc_vowel': 0.99502, 'acc_consonant': 0.994348, 'acc_word': 0.984314, 'loss_grapheme': 0.0931, 'loss_vowel': 0.049973, 'loss_consonant': 0.03946, 'loss_word': 0.084241}\n",
      "   78 | 0.000031 | 159744/160678 | 1.4629 | 8.1889 |||\n",
      "val: {'recall': 0.99028, 'recall_grapheme': 0.986345, 'recall_vowel': 0.994966, 'recall_consonant': 0.993465, 'recall_word': 0.985766, 'acc_grapheme': 0.985708, 'acc_vowel': 0.99512, 'acc_consonant': 0.994945, 'acc_word': 0.985807, 'loss_grapheme': 0.095771, 'loss_vowel': 0.054119, 'loss_consonant': 0.042415, 'loss_word': 0.083062}\n",
      "   79 | 0.000029 | 159744/160678 | 8.6998 | 7.0314 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989344, 'recall_grapheme': 0.985257, 'recall_vowel': 0.994543, 'recall_consonant': 0.99232, 'recall_word': 0.984742, 'acc_grapheme': 0.984289, 'acc_vowel': 0.99497, 'acc_consonant': 0.994149, 'acc_word': 0.984712, 'loss_grapheme': 0.099024, 'loss_vowel': 0.052992, 'loss_consonant': 0.043358, 'loss_word': 0.085514}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:19<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990749, 'recall_grapheme': 0.987258, 'recall_vowel': 0.995147, 'recall_consonant': 0.993331, 'recall_word': 0.986846, 'acc_grapheme': 0.987077, 'acc_vowel': 0.995045, 'acc_consonant': 0.995244, 'acc_word': 0.986928, 'loss_grapheme': 0.046931, 'loss_vowel': 0.019604, 'loss_consonant': 0.016838, 'loss_word': 0.047109}\n",
      "   80 | 0.000026 | 159744/160678 | 15.3885 | 7.5373 |\n",
      "val: {'recall': 0.98957, 'recall_grapheme': 0.985631, 'recall_vowel': 0.99444, 'recall_consonant': 0.992579, 'recall_word': 0.984922, 'acc_grapheme': 0.984662, 'acc_vowel': 0.99497, 'acc_consonant': 0.994373, 'acc_word': 0.984911, 'loss_grapheme': 0.101753, 'loss_vowel': 0.056557, 'loss_consonant': 0.044298, 'loss_word': 0.090373}\n",
      "   81 | 0.000023 | 159744/160678 | 1.7577 | 7.8793 ||\n",
      "val: {'recall': 0.990522, 'recall_grapheme': 0.986996, 'recall_vowel': 0.994571, 'recall_consonant': 0.993525, 'recall_word': 0.986112, 'acc_grapheme': 0.985783, 'acc_vowel': 0.994945, 'acc_consonant': 0.995145, 'acc_word': 0.986156, 'loss_grapheme': 0.067677, 'loss_vowel': 0.03361, 'loss_consonant': 0.028516, 'loss_word': 0.062615}\n",
      "   82 | 0.000021 | 159744/160678 | 1.1360 | 7.2479 |||\n",
      "val: {'recall': 0.990057, 'recall_grapheme': 0.985891, 'recall_vowel': 0.995002, 'recall_consonant': 0.993442, 'recall_word': 0.985407, 'acc_grapheme': 0.98511, 'acc_vowel': 0.99517, 'acc_consonant': 0.994721, 'acc_word': 0.985384, 'loss_grapheme': 0.076405, 'loss_vowel': 0.03892, 'loss_consonant': 0.032247, 'loss_word': 0.069326}\n",
      "   83 | 0.000019 | 159744/160678 | 7.5724 | 8.4899 |||\n",
      "val: {'recall': 0.990154, 'recall_grapheme': 0.986269, 'recall_vowel': 0.994808, 'recall_consonant': 0.993268, 'recall_word': 0.985668, 'acc_grapheme': 0.985235, 'acc_vowel': 0.995145, 'acc_consonant': 0.994696, 'acc_word': 0.985758, 'loss_grapheme': 0.098606, 'loss_vowel': 0.058772, 'loss_consonant': 0.045829, 'loss_word': 0.083217}\n",
      "   84 | 0.000016 | 159744/160678 | 15.3236 | 7.8595 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.98992, 'recall_grapheme': 0.98589, 'recall_vowel': 0.994457, 'recall_consonant': 0.993442, 'recall_word': 0.984912, 'acc_grapheme': 0.984886, 'acc_vowel': 0.994871, 'acc_consonant': 0.994647, 'acc_word': 0.984986, 'loss_grapheme': 0.149554, 'loss_vowel': 0.092069, 'loss_consonant': 0.067512, 'loss_word': 0.130215}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:17<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990874, 'recall_grapheme': 0.987456, 'recall_vowel': 0.995082, 'recall_consonant': 0.993501, 'recall_word': 0.98687, 'acc_grapheme': 0.987177, 'acc_vowel': 0.99502, 'acc_consonant': 0.995319, 'acc_word': 0.986928, 'loss_grapheme': 0.046695, 'loss_vowel': 0.019567, 'loss_consonant': 0.016764, 'loss_word': 0.046924}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b1/model4_eb1_fold2.pth\n",
      "   85 | 0.000014 | 159744/160678 | 9.2611 | 8.2875 ||\n",
      "val: {'recall': 0.989734, 'recall_grapheme': 0.985593, 'recall_vowel': 0.994912, 'recall_consonant': 0.992838, 'recall_word': 0.98458, 'acc_grapheme': 0.984687, 'acc_vowel': 0.995219, 'acc_consonant': 0.994198, 'acc_word': 0.984563, 'loss_grapheme': 0.10875, 'loss_vowel': 0.060622, 'loss_consonant': 0.046919, 'loss_word': 0.092252}\n",
      "   86 | 0.000012 | 159744/160678 | 9.5796 | 7.8082 |||\n",
      "val: {'recall': 0.989653, 'recall_grapheme': 0.985559, 'recall_vowel': 0.994945, 'recall_consonant': 0.992549, 'recall_word': 0.98451, 'acc_grapheme': 0.984363, 'acc_vowel': 0.995095, 'acc_consonant': 0.994398, 'acc_word': 0.984438, 'loss_grapheme': 0.107546, 'loss_vowel': 0.058317, 'loss_consonant': 0.04576, 'loss_word': 0.093372}\n",
      "   87 | 0.000011 | 159744/160678 | 1.2944 | 8.0322 |||\n",
      "val: {'recall': 0.990337, 'recall_grapheme': 0.986458, 'recall_vowel': 0.994921, 'recall_consonant': 0.99351, 'recall_word': 0.985592, 'acc_grapheme': 0.985832, 'acc_vowel': 0.99512, 'acc_consonant': 0.994846, 'acc_word': 0.985583, 'loss_grapheme': 0.089791, 'loss_vowel': 0.048316, 'loss_consonant': 0.038525, 'loss_word': 0.078478}\n",
      "   88 | 0.000009 | 159744/160678 | 14.1044 | 7.4641 ||\n",
      "val: {'recall': 0.989467, 'recall_grapheme': 0.984978, 'recall_vowel': 0.994782, 'recall_consonant': 0.99313, 'recall_word': 0.984299, 'acc_grapheme': 0.98399, 'acc_vowel': 0.99497, 'acc_consonant': 0.994223, 'acc_word': 0.984264, 'loss_grapheme': 0.121106, 'loss_vowel': 0.071386, 'loss_consonant': 0.05246, 'loss_word': 0.104644}\n",
      "   89 | 0.000007 | 159744/160678 | 6.9067 | 6.9135 |||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989938, 'recall_grapheme': 0.985733, 'recall_vowel': 0.994999, 'recall_consonant': 0.993287, 'recall_word': 0.985276, 'acc_grapheme': 0.985135, 'acc_vowel': 0.995219, 'acc_consonant': 0.994696, 'acc_word': 0.985285, 'loss_grapheme': 0.083325, 'loss_vowel': 0.043152, 'loss_consonant': 0.035369, 'loss_word': 0.073227}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990764, 'recall_grapheme': 0.98732, 'recall_vowel': 0.994979, 'recall_consonant': 0.993435, 'recall_word': 0.98691, 'acc_grapheme': 0.987127, 'acc_vowel': 0.995045, 'acc_consonant': 0.995319, 'acc_word': 0.986978, 'loss_grapheme': 0.046645, 'loss_vowel': 0.019548, 'loss_consonant': 0.016726, 'loss_word': 0.046864}\n",
      "   90 | 0.000006 | 159744/160678 | 1.2949 | 7.9403 ||\n",
      "val: {'recall': 0.989849, 'recall_grapheme': 0.985834, 'recall_vowel': 0.99495, 'recall_consonant': 0.992777, 'recall_word': 0.98526, 'acc_grapheme': 0.985085, 'acc_vowel': 0.995219, 'acc_consonant': 0.994672, 'acc_word': 0.985309, 'loss_grapheme': 0.093168, 'loss_vowel': 0.050202, 'loss_consonant': 0.040594, 'loss_word': 0.082058}\n",
      "   91 | 0.000005 | 159744/160678 | 6.5384 | 7.4562 ||\n",
      "val: {'recall': 0.989665, 'recall_grapheme': 0.985477, 'recall_vowel': 0.994698, 'recall_consonant': 0.993009, 'recall_word': 0.984725, 'acc_grapheme': 0.984587, 'acc_vowel': 0.995095, 'acc_consonant': 0.994497, 'acc_word': 0.984687, 'loss_grapheme': 0.088921, 'loss_vowel': 0.046834, 'loss_consonant': 0.03689, 'loss_word': 0.081246}\n",
      "   92 | 0.000004 | 159744/160678 | 1.2873 | 7.6910 |||\n",
      "val: {'recall': 0.990191, 'recall_grapheme': 0.986251, 'recall_vowel': 0.994806, 'recall_consonant': 0.993457, 'recall_word': 0.985681, 'acc_grapheme': 0.985434, 'acc_vowel': 0.995219, 'acc_consonant': 0.994871, 'acc_word': 0.985683, 'loss_grapheme': 0.077078, 'loss_vowel': 0.039976, 'loss_consonant': 0.033086, 'loss_word': 0.06906}\n",
      "   93 | 0.000003 | 159744/160678 | 3.8026 | 7.2871 ||\n",
      "val: {'recall': 0.989612, 'recall_grapheme': 0.985408, 'recall_vowel': 0.994458, 'recall_consonant': 0.993175, 'recall_word': 0.984517, 'acc_grapheme': 0.984289, 'acc_vowel': 0.99502, 'acc_consonant': 0.994373, 'acc_word': 0.984463, 'loss_grapheme': 0.125611, 'loss_vowel': 0.073688, 'loss_consonant': 0.054948, 'loss_word': 0.109399}\n",
      "   94 | 0.000002 | 159744/160678 | 4.7098 | 8.1774 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989938, 'recall_grapheme': 0.98582, 'recall_vowel': 0.994737, 'recall_consonant': 0.993374, 'recall_word': 0.984966, 'acc_grapheme': 0.984886, 'acc_vowel': 0.995045, 'acc_consonant': 0.994672, 'acc_word': 0.984911, 'loss_grapheme': 0.116045, 'loss_vowel': 0.066882, 'loss_consonant': 0.049797, 'loss_word': 0.101202}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:18<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.99087, 'recall_grapheme': 0.987467, 'recall_vowel': 0.995065, 'recall_consonant': 0.993481, 'recall_word': 0.987022, 'acc_grapheme': 0.987152, 'acc_vowel': 0.994995, 'acc_consonant': 0.995394, 'acc_word': 0.987127, 'loss_grapheme': 0.046701, 'loss_vowel': 0.019486, 'loss_consonant': 0.016681, 'loss_word': 0.046889}\n",
      "   95 | 0.000001 | 159744/160678 | 1.2975 | 8.5468 |||\n",
      "val: {'recall': 0.990227, 'recall_grapheme': 0.986365, 'recall_vowel': 0.994869, 'recall_consonant': 0.993309, 'recall_word': 0.985665, 'acc_grapheme': 0.985509, 'acc_vowel': 0.995194, 'acc_consonant': 0.994746, 'acc_word': 0.985683, 'loss_grapheme': 0.07892, 'loss_vowel': 0.041762, 'loss_consonant': 0.034488, 'loss_word': 0.069593}\n",
      "   96 | 0.000001 | 159744/160678 | 10.4923 | 7.7610 ||\n",
      "val: {'recall': 0.989153, 'recall_grapheme': 0.984478, 'recall_vowel': 0.994497, 'recall_consonant': 0.993158, 'recall_word': 0.984466, 'acc_grapheme': 0.983766, 'acc_vowel': 0.994921, 'acc_consonant': 0.994223, 'acc_word': 0.984438, 'loss_grapheme': 0.125089, 'loss_vowel': 0.075384, 'loss_consonant': 0.056423, 'loss_word': 0.105931}\n",
      "   97 | 0.000000 | 159744/160678 | 1.3126 | 7.4748 ||\n",
      "val: {'recall': 0.99043, 'recall_grapheme': 0.986737, 'recall_vowel': 0.994841, 'recall_consonant': 0.993405, 'recall_word': 0.985747, 'acc_grapheme': 0.985683, 'acc_vowel': 0.99512, 'acc_consonant': 0.994871, 'acc_word': 0.985708, 'loss_grapheme': 0.077783, 'loss_vowel': 0.039155, 'loss_consonant': 0.032477, 'loss_word': 0.070089}\n",
      "   98 | 0.000000 | 159744/160678 | 20.6472 | 7.5699 |\n",
      "val: {'recall': 0.989676, 'recall_grapheme': 0.985426, 'recall_vowel': 0.994732, 'recall_consonant': 0.99312, 'recall_word': 0.985302, 'acc_grapheme': 0.984986, 'acc_vowel': 0.99502, 'acc_consonant': 0.994472, 'acc_word': 0.985309, 'loss_grapheme': 0.088671, 'loss_vowel': 0.048244, 'loss_consonant': 0.039483, 'loss_word': 0.076632}\n",
      "   99 | 0.000000 | 159744/160678 | 1.1716 | 7.2684 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.989921, 'recall_grapheme': 0.985769, 'recall_vowel': 0.994862, 'recall_consonant': 0.993284, 'recall_word': 0.984913, 'acc_grapheme': 0.984787, 'acc_vowel': 0.995095, 'acc_consonant': 0.994497, 'acc_word': 0.984886, 'loss_grapheme': 0.107947, 'loss_vowel': 0.062297, 'loss_consonant': 0.047194, 'loss_word': 0.092843}\n",
      "SWA>>>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:19<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val: {'recall': 0.990667, 'recall_grapheme': 0.987063, 'recall_vowel': 0.995106, 'recall_consonant': 0.993435, 'recall_word': 0.987038, 'acc_grapheme': 0.986978, 'acc_vowel': 0.995045, 'acc_consonant': 0.995319, 'acc_word': 0.987127, 'loss_grapheme': 0.046485, 'loss_vowel': 0.019401, 'loss_consonant': 0.016649, 'loss_word': 0.04668}\n",
      "CYCLE: 2\n",
      "    0 | 0.000030 | 159744/160678 | 12.8697 | 7.6799 ||\n",
      "val: {'recall': 0.989102, 'recall_grapheme': 0.984462, 'recall_vowel': 0.99448, 'recall_consonant': 0.993005, 'recall_word': 0.983482, 'acc_grapheme': 0.983318, 'acc_vowel': 0.994547, 'acc_consonant': 0.993925, 'acc_word': 0.983442, 'loss_grapheme': 0.145482, 'loss_vowel': 0.073542, 'loss_consonant': 0.060885, 'loss_word': 0.122437}\n",
      "    1 | 0.000060 | 159744/160678 | 0.8475 | 6.7534 |||\n",
      "val: {'recall': 0.990684, 'recall_grapheme': 0.987308, 'recall_vowel': 0.995227, 'recall_consonant': 0.992893, 'recall_word': 0.986735, 'acc_grapheme': 0.986729, 'acc_vowel': 0.995344, 'acc_consonant': 0.995045, 'acc_word': 0.986779, 'loss_grapheme': 0.056396, 'loss_vowel': 0.025363, 'loss_consonant': 0.022259, 'loss_word': 0.053425}\n",
      "    2 | 0.000090 | 159744/160678 | 20.6372 | 7.7015 ||\n",
      "val: {'recall': 0.990292, 'recall_grapheme': 0.986357, 'recall_vowel': 0.995111, 'recall_consonant': 0.993344, 'recall_word': 0.98626, 'acc_grapheme': 0.986032, 'acc_vowel': 0.995319, 'acc_consonant': 0.994821, 'acc_word': 0.986305, 'loss_grapheme': 0.064476, 'loss_vowel': 0.030896, 'loss_consonant': 0.026526, 'loss_word': 0.059077}\n",
      "    3 | 0.000119 | 159744/160678 | 14.3443 | 7.7940 ||\n",
      "val: {'recall': 0.989869, 'recall_grapheme': 0.985513, 'recall_vowel': 0.994811, 'recall_consonant': 0.993638, 'recall_word': 0.984925, 'acc_grapheme': 0.984836, 'acc_vowel': 0.995045, 'acc_consonant': 0.994622, 'acc_word': 0.984861, 'loss_grapheme': 0.124996, 'loss_vowel': 0.076466, 'loss_consonant': 0.056869, 'loss_word': 0.108751}\n",
      "    4 | 0.000149 | 159744/160678 | 19.0541 | 7.6936 ||\n",
      "val: {'recall': 0.988921, 'recall_grapheme': 0.984427, 'recall_vowel': 0.993861, 'recall_consonant': 0.992968, 'recall_word': 0.983678, 'acc_grapheme': 0.983467, 'acc_vowel': 0.994597, 'acc_consonant': 0.993925, 'acc_word': 0.983591, 'loss_grapheme': 0.201423, 'loss_vowel': 0.13099, 'loss_consonant': 0.093521, 'loss_word': 0.170967}\n",
      "    5 | 0.000178 | 159744/160678 | 1.1190 | 7.5923 ||\n",
      "val: {'recall': 0.990318, 'recall_grapheme': 0.986611, 'recall_vowel': 0.994932, 'recall_consonant': 0.993118, 'recall_word': 0.98584, 'acc_grapheme': 0.986056, 'acc_vowel': 0.995145, 'acc_consonant': 0.994696, 'acc_word': 0.985857, 'loss_grapheme': 0.069813, 'loss_vowel': 0.034131, 'loss_consonant': 0.029941, 'loss_word': 0.063188}\n",
      "    6 | 0.000207 | 159744/160678 | 0.9020 | 7.0082 |||\n",
      "val: {'recall': 0.987803, 'recall_grapheme': 0.982572, 'recall_vowel': 0.993694, 'recall_consonant': 0.992373, 'recall_word': 0.981081, 'acc_grapheme': 0.9816, 'acc_vowel': 0.994423, 'acc_consonant': 0.993626, 'acc_word': 0.980703, 'loss_grapheme': 0.112516, 'loss_vowel': 0.052465, 'loss_consonant': 0.045784, 'loss_word': 0.1064}\n",
      "    7 | 0.000236 | 159744/160678 | 13.0325 | 7.7627 |\n",
      "val: {'recall': 0.989111, 'recall_grapheme': 0.984522, 'recall_vowel': 0.994515, 'recall_consonant': 0.992887, 'recall_word': 0.984146, 'acc_grapheme': 0.983915, 'acc_vowel': 0.994846, 'acc_consonant': 0.994323, 'acc_word': 0.984139, 'loss_grapheme': 0.12797, 'loss_vowel': 0.076555, 'loss_consonant': 0.058864, 'loss_word': 0.111144}\n",
      "    8 | 0.000264 | 159744/160678 | 21.1512 | 8.3317 |\n",
      "val: {'recall': 0.989297, 'recall_grapheme': 0.985071, 'recall_vowel': 0.994425, 'recall_consonant': 0.99262, 'recall_word': 0.984705, 'acc_grapheme': 0.98399, 'acc_vowel': 0.994572, 'acc_consonant': 0.994248, 'acc_word': 0.984662, 'loss_grapheme': 0.155684, 'loss_vowel': 0.101889, 'loss_consonant': 0.073435, 'loss_word': 0.133466}\n",
      "    9 | 0.000292 | 159744/160678 | 8.8383 | 8.1615 |||\n",
      "val: {'recall': 0.988681, 'recall_grapheme': 0.984704, 'recall_vowel': 0.993865, 'recall_consonant': 0.991453, 'recall_word': 0.982765, 'acc_grapheme': 0.982496, 'acc_vowel': 0.994522, 'acc_consonant': 0.9938, 'acc_word': 0.982645, 'loss_grapheme': 0.142747, 'loss_vowel': 0.070467, 'loss_consonant': 0.056295, 'loss_word': 0.121737}\n",
      "   10 | 0.000291 | 159744/160678 | 6.3448 | 7.5836 ||\n",
      "val: {'recall': 0.988918, 'recall_grapheme': 0.984294, 'recall_vowel': 0.99484, 'recall_consonant': 0.992245, 'recall_word': 0.983471, 'acc_grapheme': 0.983268, 'acc_vowel': 0.994945, 'acc_consonant': 0.993775, 'acc_word': 0.983218, 'loss_grapheme': 0.137885, 'loss_vowel': 0.080468, 'loss_consonant': 0.060027, 'loss_word': 0.125798}\n",
      "   11 | 0.000289 | 159744/160678 | 21.2871 | 9.1393 ||\n",
      "val: {'recall': 0.987872, 'recall_grapheme': 0.982925, 'recall_vowel': 0.993736, 'recall_consonant': 0.991902, 'recall_word': 0.981397, 'acc_grapheme': 0.981375, 'acc_vowel': 0.994447, 'acc_consonant': 0.993427, 'acc_word': 0.981176, 'loss_grapheme': 0.227173, 'loss_vowel': 0.139507, 'loss_consonant': 0.098465, 'loss_word': 0.217652}\n",
      "   12 | 0.000288 | 159744/160678 | 21.7174 | 8.2145 ||\n",
      "val: {'recall': 0.988705, 'recall_grapheme': 0.98393, 'recall_vowel': 0.993853, 'recall_consonant': 0.993107, 'recall_word': 0.983563, 'acc_grapheme': 0.983143, 'acc_vowel': 0.994597, 'acc_consonant': 0.993974, 'acc_word': 0.983517, 'loss_grapheme': 0.134024, 'loss_vowel': 0.082404, 'loss_consonant': 0.060628, 'loss_word': 0.117871}\n",
      "   13 | 0.000286 | 125952/160678 | 9.7885 | 8.0830 |||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-5f0c7a4726e5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-433613421c48>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate(nn.DataParallel(model), val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
