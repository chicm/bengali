{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from efficientnet_pytorch import EfficientNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    train = train_df.iloc[:split_index]\n",
    "    val = train_df.iloc[split_index:]\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nargs = Namespace()\\nargs.backbone = 'se_resnext50_32x4d'\\nargs.ckp_name = 'best_model.pth'\\nargs.predict = False\\n\\nbnet = create_model(args)[0].cuda()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "\n",
    "bnet = create_model(args)[0].cuda()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum().item()\n",
    "        res.append(correct_k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand(1)\n",
    "            if args.beta > 0 and r < args.cutmix_prob:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'inceptionresnetv2'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "args.optim = 'SGD'\n",
    "args.lr = 1e-4\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-5\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 2048\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(180756, 5) (20084, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/inceptionresnetv2/best_model.pth, exist: True\n",
      "loading ./models/inceptionresnetv2/best_model.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.976341, 'recall_grapheme': 0.964064, 'recall_vowel': 0.987263, 'recall_consonant': 0.989972, 'acc_grapheme': 0.965545, 'acc_vowel': 0.990042, 'acc_consonant': 0.990341, 'loss_grapheme': 0.186893, 'loss_vowel': 0.082564, 'loss_consonant': 0.065909}\n",
      "    1 | 0.000100 | 024576/180756 | 0.0085 | 1.1132 |\n",
      "val: {'recall': 0.975258, 'recall_grapheme': 0.963895, 'recall_vowel': 0.987486, 'recall_consonant': 0.985757, 'acc_grapheme': 0.965346, 'acc_vowel': 0.990141, 'acc_consonant': 0.990092, 'loss_grapheme': 0.152215, 'loss_vowel': 0.049587, 'loss_consonant': 0.0435}\n",
      "    2 | 0.000098 | 049152/180756 | 2.4519 | 2.2276 |\n",
      "val: {'recall': 0.976364, 'recall_grapheme': 0.964881, 'recall_vowel': 0.987465, 'recall_consonant': 0.988231, 'acc_grapheme': 0.965893, 'acc_vowel': 0.990092, 'acc_consonant': 0.990341, 'loss_grapheme': 0.178467, 'loss_vowel': 0.080176, 'loss_consonant': 0.063563}\n",
      "** saved\n",
      "    3 | 0.000094 | 073728/180756 | 0.0117 | 1.8251 |\n",
      "val: {'recall': 0.976059, 'recall_grapheme': 0.96457, 'recall_vowel': 0.987092, 'recall_consonant': 0.988004, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990042, 'acc_consonant': 0.989992, 'loss_grapheme': 0.162665, 'loss_vowel': 0.06425, 'loss_consonant': 0.052609}\n",
      "    4 | 0.000087 | 098304/180756 | 0.0144 | 1.7554 |\n",
      "val: {'recall': 0.976513, 'recall_grapheme': 0.964311, 'recall_vowel': 0.987464, 'recall_consonant': 0.989966, 'acc_grapheme': 0.965694, 'acc_vowel': 0.99039, 'acc_consonant': 0.990141, 'loss_grapheme': 0.176906, 'loss_vowel': 0.079861, 'loss_consonant': 0.064499}\n",
      "** saved\n",
      "    5 | 0.000077 | 122880/180756 | 0.0111 | 1.6595 |\n",
      "val: {'recall': 0.976418, 'recall_grapheme': 0.964719, 'recall_vowel': 0.987506, 'recall_consonant': 0.988728, 'acc_grapheme': 0.965993, 'acc_vowel': 0.990241, 'acc_consonant': 0.99044, 'loss_grapheme': 0.168548, 'loss_vowel': 0.073913, 'loss_consonant': 0.059018}\n",
      "    6 | 0.000067 | 147456/180756 | 3.9940 | 1.5681 |\n",
      "val: {'recall': 0.976054, 'recall_grapheme': 0.964348, 'recall_vowel': 0.988059, 'recall_consonant': 0.987459, 'acc_grapheme': 0.966092, 'acc_vowel': 0.990141, 'acc_consonant': 0.990341, 'loss_grapheme': 0.1855, 'loss_vowel': 0.088009, 'loss_consonant': 0.068866}\n",
      "    7 | 0.000055 | 172032/180756 | 3.8000 | 1.6519 |\n",
      "val: {'recall': 0.975921, 'recall_grapheme': 0.963223, 'recall_vowel': 0.98807, 'recall_consonant': 0.989168, 'acc_grapheme': 0.965047, 'acc_vowel': 0.990341, 'acc_consonant': 0.99044, 'loss_grapheme': 0.198597, 'loss_vowel': 0.098626, 'loss_consonant': 0.07451}\n",
      "    9 | 0.000043 | 016384/180756 | 3.5852 | 2.1141 |\n",
      "val: {'recall': 0.976547, 'recall_grapheme': 0.964365, 'recall_vowel': 0.987598, 'recall_consonant': 0.989861, 'acc_grapheme': 0.966192, 'acc_vowel': 0.990241, 'acc_consonant': 0.990341, 'loss_grapheme': 0.187132, 'loss_vowel': 0.0873, 'loss_consonant': 0.068701}\n",
      "** saved\n",
      "   10 | 0.000033 | 040960/180756 | 0.0115 | 1.6444 |\n",
      "val: {'recall': 0.976181, 'recall_grapheme': 0.964523, 'recall_vowel': 0.987434, 'recall_consonant': 0.988242, 'acc_grapheme': 0.966142, 'acc_vowel': 0.990191, 'acc_consonant': 0.990341, 'loss_grapheme': 0.162196, 'loss_vowel': 0.063727, 'loss_consonant': 0.0524}\n",
      "   11 | 0.000023 | 065536/180756 | 3.1662 | 1.7889 |\n",
      "val: {'recall': 0.97635, 'recall_grapheme': 0.965141, 'recall_vowel': 0.987369, 'recall_consonant': 0.987751, 'acc_grapheme': 0.965744, 'acc_vowel': 0.990241, 'acc_consonant': 0.989892, 'loss_grapheme': 0.158232, 'loss_vowel': 0.062115, 'loss_consonant': 0.051125}\n",
      "   12 | 0.000016 | 090112/180756 | 3.9008 | 1.8339 |\n",
      "val: {'recall': 0.976727, 'recall_grapheme': 0.965066, 'recall_vowel': 0.987958, 'recall_consonant': 0.988818, 'acc_grapheme': 0.966092, 'acc_vowel': 0.990191, 'acc_consonant': 0.990141, 'loss_grapheme': 0.169266, 'loss_vowel': 0.071217, 'loss_consonant': 0.056729}\n",
      "** saved\n",
      "   13 | 0.000012 | 114688/180756 | 0.0146 | 1.8887 |\n",
      "val: {'recall': 0.976828, 'recall_grapheme': 0.965302, 'recall_vowel': 0.987869, 'recall_consonant': 0.98884, 'acc_grapheme': 0.966491, 'acc_vowel': 0.990241, 'acc_consonant': 0.99044, 'loss_grapheme': 0.180459, 'loss_vowel': 0.082051, 'loss_consonant': 0.064482}\n",
      "** saved\n",
      "   14 | 0.000010 | 139264/180756 | 0.0069 | 1.7138 |\n",
      "val: {'recall': 0.975448, 'recall_grapheme': 0.963947, 'recall_vowel': 0.987986, 'recall_consonant': 0.985915, 'acc_grapheme': 0.965644, 'acc_vowel': 0.990341, 'acc_consonant': 0.990092, 'loss_grapheme': 0.159373, 'loss_vowel': 0.060858, 'loss_consonant': 0.05132}\n",
      "   15 | 0.000012 | 163840/180756 | 0.0102 | 1.9161 |\n",
      "val: {'recall': 0.975656, 'recall_grapheme': 0.964559, 'recall_vowel': 0.987678, 'recall_consonant': 0.985827, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990191, 'acc_consonant': 0.990191, 'loss_grapheme': 0.155697, 'loss_vowel': 0.057041, 'loss_consonant': 0.047529}\n",
      "   17 | 0.000016 | 008192/180756 | 0.0105 | 1.6704 |\n",
      "val: {'recall': 0.975891, 'recall_grapheme': 0.963901, 'recall_vowel': 0.987649, 'recall_consonant': 0.988113, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990191, 'acc_consonant': 0.990241, 'loss_grapheme': 0.154538, 'loss_vowel': 0.055782, 'loss_consonant': 0.047495}\n",
      "   18 | 0.000023 | 032768/180756 | 1.2723 | 2.0395 |\n",
      "val: {'recall': 0.976162, 'recall_grapheme': 0.964309, 'recall_vowel': 0.987884, 'recall_consonant': 0.988149, 'acc_grapheme': 0.966142, 'acc_vowel': 0.990141, 'acc_consonant': 0.99049, 'loss_grapheme': 0.170824, 'loss_vowel': 0.074427, 'loss_consonant': 0.058051}\n",
      "   19 | 0.000032 | 057344/180756 | 4.5158 | 1.7326 |\n",
      "val: {'recall': 0.976151, 'recall_grapheme': 0.964386, 'recall_vowel': 0.987515, 'recall_consonant': 0.988317, 'acc_grapheme': 0.965794, 'acc_vowel': 0.990241, 'acc_consonant': 0.990241, 'loss_grapheme': 0.175485, 'loss_vowel': 0.075886, 'loss_consonant': 0.060785}\n",
      "   20 | 0.000043 | 081920/180756 | 0.0096 | 1.5090 |\n",
      "val: {'recall': 0.975615, 'recall_grapheme': 0.964611, 'recall_vowel': 0.987738, 'recall_consonant': 0.985501, 'acc_grapheme': 0.965246, 'acc_vowel': 0.990141, 'acc_consonant': 0.989843, 'loss_grapheme': 0.158931, 'loss_vowel': 0.059316, 'loss_consonant': 0.049921}\n",
      "   21 | 0.000055 | 106496/180756 | 3.3471 | 1.8059 |\n",
      "val: {'recall': 0.976442, 'recall_grapheme': 0.96468, 'recall_vowel': 0.987822, 'recall_consonant': 0.988588, 'acc_grapheme': 0.965694, 'acc_vowel': 0.99049, 'acc_consonant': 0.990341, 'loss_grapheme': 0.17315, 'loss_vowel': 0.076599, 'loss_consonant': 0.061149}\n",
      "   22 | 0.000067 | 131072/180756 | 2.6399 | 1.5817 |\n",
      "val: {'recall': 0.976507, 'recall_grapheme': 0.964872, 'recall_vowel': 0.987938, 'recall_consonant': 0.988344, 'acc_grapheme': 0.966142, 'acc_vowel': 0.990291, 'acc_consonant': 0.99039, 'loss_grapheme': 0.166906, 'loss_vowel': 0.070202, 'loss_consonant': 0.056006}\n",
      "   23 | 0.000077 | 155648/180756 | 0.9279 | 1.5775 |\n",
      "val: {'recall': 0.97515, 'recall_grapheme': 0.963166, 'recall_vowel': 0.987375, 'recall_consonant': 0.986892, 'acc_grapheme': 0.965346, 'acc_vowel': 0.989992, 'acc_consonant': 0.989942, 'loss_grapheme': 0.161208, 'loss_vowel': 0.062639, 'loss_consonant': 0.05138}\n",
      "   24 | 0.000087 | 180224/180756 | 0.0083 | 1.6998 |\n",
      "val: {'recall': 0.97528, 'recall_grapheme': 0.964029, 'recall_vowel': 0.987418, 'recall_consonant': 0.985645, 'acc_grapheme': 0.965595, 'acc_vowel': 0.990092, 'acc_consonant': 0.990191, 'loss_grapheme': 0.155555, 'loss_vowel': 0.055308, 'loss_consonant': 0.047419}\n",
      "   26 | 0.000094 | 024576/180756 | 0.0090 | 1.2232 |\n",
      "val: {'recall': 0.976276, 'recall_grapheme': 0.964829, 'recall_vowel': 0.987409, 'recall_consonant': 0.988035, 'acc_grapheme': 0.966242, 'acc_vowel': 0.990241, 'acc_consonant': 0.990092, 'loss_grapheme': 0.154597, 'loss_vowel': 0.056095, 'loss_consonant': 0.047973}\n",
      "   27 | 0.000098 | 049152/180756 | 0.0115 | 1.6998 |\n",
      "val: {'recall': 0.976058, 'recall_grapheme': 0.964525, 'recall_vowel': 0.987816, 'recall_consonant': 0.987366, 'acc_grapheme': 0.965843, 'acc_vowel': 0.99039, 'acc_consonant': 0.989594, 'loss_grapheme': 0.15223, 'loss_vowel': 0.051662, 'loss_consonant': 0.045511}\n",
      "   28 | 0.000100 | 073728/180756 | 4.3771 | 1.7533 |\n",
      "val: {'recall': 0.977126, 'recall_grapheme': 0.965499, 'recall_vowel': 0.987439, 'recall_consonant': 0.990067, 'acc_grapheme': 0.966192, 'acc_vowel': 0.990191, 'acc_consonant': 0.99054, 'loss_grapheme': 0.190878, 'loss_vowel': 0.090159, 'loss_consonant': 0.071977}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   29 | 0.000098 | 098304/180756 | 0.0068 | 1.9750 |\n",
      "val: {'recall': 0.976667, 'recall_grapheme': 0.965217, 'recall_vowel': 0.986929, 'recall_consonant': 0.989306, 'acc_grapheme': 0.966242, 'acc_vowel': 0.990042, 'acc_consonant': 0.990191, 'loss_grapheme': 0.161852, 'loss_vowel': 0.066753, 'loss_consonant': 0.053954}\n",
      "   30 | 0.000094 | 122880/180756 | 1.8115 | 1.6612 |\n",
      "val: {'recall': 0.976375, 'recall_grapheme': 0.964423, 'recall_vowel': 0.987598, 'recall_consonant': 0.989056, 'acc_grapheme': 0.965893, 'acc_vowel': 0.99044, 'acc_consonant': 0.990141, 'loss_grapheme': 0.166233, 'loss_vowel': 0.067427, 'loss_consonant': 0.056925}\n",
      "   31 | 0.000087 | 147456/180756 | 4.1691 | 1.3480 |\n",
      "val: {'recall': 0.975713, 'recall_grapheme': 0.964196, 'recall_vowel': 0.987234, 'recall_consonant': 0.987227, 'acc_grapheme': 0.966391, 'acc_vowel': 0.990141, 'acc_consonant': 0.990042, 'loss_grapheme': 0.161361, 'loss_vowel': 0.064096, 'loss_consonant': 0.053293}\n",
      "   32 | 0.000078 | 172032/180756 | 3.9404 | 1.6839 |\n",
      "val: {'recall': 0.976703, 'recall_grapheme': 0.965788, 'recall_vowel': 0.987489, 'recall_consonant': 0.987745, 'acc_grapheme': 0.965993, 'acc_vowel': 0.990141, 'acc_consonant': 0.990141, 'loss_grapheme': 0.158954, 'loss_vowel': 0.061812, 'loss_consonant': 0.050675}\n",
      "   34 | 0.000067 | 016384/180756 | 3.5287 | 2.0476 |\n",
      "val: {'recall': 0.975878, 'recall_grapheme': 0.963521, 'recall_vowel': 0.987424, 'recall_consonant': 0.989045, 'acc_grapheme': 0.965545, 'acc_vowel': 0.990241, 'acc_consonant': 0.990141, 'loss_grapheme': 0.161714, 'loss_vowel': 0.063953, 'loss_consonant': 0.05333}\n",
      "   35 | 0.000055 | 040960/180756 | 0.0104 | 1.2297 |\n",
      "val: {'recall': 0.974852, 'recall_grapheme': 0.963558, 'recall_vowel': 0.987209, 'recall_consonant': 0.985082, 'acc_grapheme': 0.965445, 'acc_vowel': 0.990291, 'acc_consonant': 0.989643, 'loss_grapheme': 0.154324, 'loss_vowel': 0.04759, 'loss_consonant': 0.043909}\n",
      "   36 | 0.000043 | 065536/180756 | 4.6421 | 1.3506 |\n",
      "val: {'recall': 0.9768, 'recall_grapheme': 0.964866, 'recall_vowel': 0.98793, 'recall_consonant': 0.98954, 'acc_grapheme': 0.966142, 'acc_vowel': 0.990341, 'acc_consonant': 0.99039, 'loss_grapheme': 0.20372, 'loss_vowel': 0.103667, 'loss_consonant': 0.078929}\n",
      "   37 | 0.000033 | 090112/180756 | 3.9024 | 1.6415 |\n",
      "val: {'recall': 0.977036, 'recall_grapheme': 0.96522, 'recall_vowel': 0.987731, 'recall_consonant': 0.989974, 'acc_grapheme': 0.966391, 'acc_vowel': 0.990191, 'acc_consonant': 0.99039, 'loss_grapheme': 0.179074, 'loss_vowel': 0.083442, 'loss_consonant': 0.066276}\n",
      "   38 | 0.000023 | 114688/180756 | 4.7082 | 1.5175 |\n",
      "val: {'recall': 0.976379, 'recall_grapheme': 0.96422, 'recall_vowel': 0.98738, 'recall_consonant': 0.989694, 'acc_grapheme': 0.966142, 'acc_vowel': 0.990291, 'acc_consonant': 0.99044, 'loss_grapheme': 0.16799, 'loss_vowel': 0.071713, 'loss_consonant': 0.058628}\n",
      "   39 | 0.000016 | 139264/180756 | 0.0085 | 1.7552 |\n",
      "val: {'recall': 0.975486, 'recall_grapheme': 0.964727, 'recall_vowel': 0.987298, 'recall_consonant': 0.98519, 'acc_grapheme': 0.965644, 'acc_vowel': 0.990191, 'acc_consonant': 0.989892, 'loss_grapheme': 0.152905, 'loss_vowel': 0.050396, 'loss_consonant': 0.044816}\n",
      "   40 | 0.000012 | 163840/180756 | 3.2680 | 1.7775 |\n",
      "val: {'recall': 0.976421, 'recall_grapheme': 0.964598, 'recall_vowel': 0.987519, 'recall_consonant': 0.988968, 'acc_grapheme': 0.966341, 'acc_vowel': 0.990141, 'acc_consonant': 0.990092, 'loss_grapheme': 0.159805, 'loss_vowel': 0.063157, 'loss_consonant': 0.050746}\n",
      "   42 | 0.000010 | 008192/180756 | 0.0074 | 1.3565 |\n",
      "val: {'recall': 0.975484, 'recall_grapheme': 0.964239, 'recall_vowel': 0.98778, 'recall_consonant': 0.985677, 'acc_grapheme': 0.965943, 'acc_vowel': 0.99039, 'acc_consonant': 0.990141, 'loss_grapheme': 0.156984, 'loss_vowel': 0.057726, 'loss_consonant': 0.04917}\n",
      "   43 | 0.000012 | 032768/180756 | 0.0196 | 1.4146 |\n",
      "val: {'recall': 0.976545, 'recall_grapheme': 0.965267, 'recall_vowel': 0.988135, 'recall_consonant': 0.987509, 'acc_grapheme': 0.966142, 'acc_vowel': 0.99044, 'acc_consonant': 0.989942, 'loss_grapheme': 0.15799, 'loss_vowel': 0.059134, 'loss_consonant': 0.048991}\n",
      "   44 | 0.000016 | 057344/180756 | 4.0324 | 1.3771 |\n",
      "val: {'recall': 0.976315, 'recall_grapheme': 0.964371, 'recall_vowel': 0.987519, 'recall_consonant': 0.988999, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990042, 'acc_consonant': 0.990042, 'loss_grapheme': 0.151323, 'loss_vowel': 0.051998, 'loss_consonant': 0.044805}\n",
      "   45 | 0.000023 | 081920/180756 | 0.0085 | 1.7908 |\n",
      "val: {'recall': 0.976107, 'recall_grapheme': 0.964771, 'recall_vowel': 0.987274, 'recall_consonant': 0.987613, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990341, 'acc_consonant': 0.990042, 'loss_grapheme': 0.15505, 'loss_vowel': 0.059732, 'loss_consonant': 0.049751}\n",
      "   46 | 0.000033 | 106496/180756 | 4.3806 | 1.3905 |\n",
      "val: {'recall': 0.97647, 'recall_grapheme': 0.965165, 'recall_vowel': 0.987551, 'recall_consonant': 0.987997, 'acc_grapheme': 0.966292, 'acc_vowel': 0.99044, 'acc_consonant': 0.989942, 'loss_grapheme': 0.167304, 'loss_vowel': 0.069605, 'loss_consonant': 0.056411}\n",
      "   47 | 0.000043 | 131072/180756 | 0.0087 | 1.6281 |\n",
      "val: {'recall': 0.975729, 'recall_grapheme': 0.963672, 'recall_vowel': 0.987174, 'recall_consonant': 0.988397, 'acc_grapheme': 0.965843, 'acc_vowel': 0.990191, 'acc_consonant': 0.990191, 'loss_grapheme': 0.160833, 'loss_vowel': 0.063045, 'loss_consonant': 0.052508}\n",
      "   48 | 0.000055 | 155648/180756 | 4.6733 | 1.5980 |\n",
      "val: {'recall': 0.976357, 'recall_grapheme': 0.964194, 'recall_vowel': 0.987403, 'recall_consonant': 0.989635, 'acc_grapheme': 0.966341, 'acc_vowel': 0.990291, 'acc_consonant': 0.99054, 'loss_grapheme': 0.189028, 'loss_vowel': 0.091592, 'loss_consonant': 0.071307}\n",
      "   49 | 0.000067 | 180224/180756 | 2.3301 | 1.7674 |\n",
      "val: {'recall': 0.97626, 'recall_grapheme': 0.96439, 'recall_vowel': 0.98781, 'recall_consonant': 0.988448, 'acc_grapheme': 0.965495, 'acc_vowel': 0.99039, 'acc_consonant': 0.99054, 'loss_grapheme': 0.175386, 'loss_vowel': 0.078178, 'loss_consonant': 0.061122}\n",
      "   51 | 0.000077 | 024576/180756 | 0.0097 | 1.8645 |\n",
      "val: {'recall': 0.97606, 'recall_grapheme': 0.964358, 'recall_vowel': 0.987511, 'recall_consonant': 0.988013, 'acc_grapheme': 0.965744, 'acc_vowel': 0.990341, 'acc_consonant': 0.990191, 'loss_grapheme': 0.161871, 'loss_vowel': 0.064415, 'loss_consonant': 0.052543}\n",
      "   52 | 0.000087 | 049152/180756 | 0.0176 | 1.4138 |\n",
      "val: {'recall': 0.976286, 'recall_grapheme': 0.964969, 'recall_vowel': 0.98759, 'recall_consonant': 0.987616, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990241, 'acc_consonant': 0.990042, 'loss_grapheme': 0.156403, 'loss_vowel': 0.058634, 'loss_consonant': 0.049251}\n",
      "   53 | 0.000094 | 073728/180756 | 0.9210 | 1.4203 |\n",
      "val: {'recall': 0.976118, 'recall_grapheme': 0.964581, 'recall_vowel': 0.987427, 'recall_consonant': 0.987882, 'acc_grapheme': 0.966292, 'acc_vowel': 0.990341, 'acc_consonant': 0.990191, 'loss_grapheme': 0.156627, 'loss_vowel': 0.059936, 'loss_consonant': 0.049297}\n",
      "   54 | 0.000098 | 098304/180756 | 3.4007 | 1.5235 |\n",
      "val: {'recall': 0.975878, 'recall_grapheme': 0.965162, 'recall_vowel': 0.987855, 'recall_consonant': 0.985333, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990241, 'acc_consonant': 0.990042, 'loss_grapheme': 0.155983, 'loss_vowel': 0.058832, 'loss_consonant': 0.04934}\n",
      "   55 | 0.000100 | 122880/180756 | 4.3210 | 1.6397 |\n",
      "val: {'recall': 0.976569, 'recall_grapheme': 0.964438, 'recall_vowel': 0.987735, 'recall_consonant': 0.989665, 'acc_grapheme': 0.966092, 'acc_vowel': 0.990241, 'acc_consonant': 0.99039, 'loss_grapheme': 0.185334, 'loss_vowel': 0.090656, 'loss_consonant': 0.069132}\n",
      "   56 | 0.000098 | 147456/180756 | 4.4979 | 1.6534 |\n",
      "val: {'recall': 0.97578, 'recall_grapheme': 0.963652, 'recall_vowel': 0.987563, 'recall_consonant': 0.988256, 'acc_grapheme': 0.965296, 'acc_vowel': 0.990341, 'acc_consonant': 0.989892, 'loss_grapheme': 0.153105, 'loss_vowel': 0.05105, 'loss_consonant': 0.045268}\n",
      "   57 | 0.000094 | 172032/180756 | 0.0071 | 1.5209 |\n",
      "val: {'recall': 0.976352, 'recall_grapheme': 0.964738, 'recall_vowel': 0.987904, 'recall_consonant': 0.988028, 'acc_grapheme': 0.966192, 'acc_vowel': 0.99044, 'acc_consonant': 0.990191, 'loss_grapheme': 0.162018, 'loss_vowel': 0.064824, 'loss_consonant': 0.052848}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 0.000087 | 016384/180756 | 4.0898 | 2.1518 |\n",
      "val: {'recall': 0.977239, 'recall_grapheme': 0.966465, 'recall_vowel': 0.987357, 'recall_consonant': 0.988669, 'acc_grapheme': 0.966939, 'acc_vowel': 0.990191, 'acc_consonant': 0.99049, 'loss_grapheme': 0.208402, 'loss_vowel': 0.109987, 'loss_consonant': 0.081441}\n",
      "** saved\n",
      "   60 | 0.000077 | 040960/180756 | 3.0870 | 1.3461 |\n",
      "val: {'recall': 0.975346, 'recall_grapheme': 0.96423, 'recall_vowel': 0.987313, 'recall_consonant': 0.98561, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990191, 'acc_consonant': 0.990042, 'loss_grapheme': 0.155403, 'loss_vowel': 0.05597, 'loss_consonant': 0.047815}\n",
      "   61 | 0.000067 | 065536/180756 | 0.0117 | 2.2741 |\n",
      "val: {'recall': 0.976287, 'recall_grapheme': 0.964388, 'recall_vowel': 0.987538, 'recall_consonant': 0.988831, 'acc_grapheme': 0.966341, 'acc_vowel': 0.99039, 'acc_consonant': 0.990092, 'loss_grapheme': 0.168969, 'loss_vowel': 0.071869, 'loss_consonant': 0.05789}\n",
      "   62 | 0.000055 | 090112/180756 | 0.0115 | 1.7708 |\n",
      "val: {'recall': 0.975607, 'recall_grapheme': 0.964697, 'recall_vowel': 0.987472, 'recall_consonant': 0.985563, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990141, 'acc_consonant': 0.989992, 'loss_grapheme': 0.161787, 'loss_vowel': 0.060613, 'loss_consonant': 0.051701}\n",
      "   63 | 0.000043 | 114688/180756 | 0.0150 | 1.6306 |\n",
      "val: {'recall': 0.976865, 'recall_grapheme': 0.964878, 'recall_vowel': 0.988148, 'recall_consonant': 0.989557, 'acc_grapheme': 0.966541, 'acc_vowel': 0.99054, 'acc_consonant': 0.99054, 'loss_grapheme': 0.203741, 'loss_vowel': 0.105669, 'loss_consonant': 0.078421}\n",
      "   64 | 0.000033 | 139264/180756 | 4.0289 | 1.5922 |\n",
      "val: {'recall': 0.975793, 'recall_grapheme': 0.96408, 'recall_vowel': 0.987142, 'recall_consonant': 0.987869, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990291, 'acc_consonant': 0.989693, 'loss_grapheme': 0.15822, 'loss_vowel': 0.058079, 'loss_consonant': 0.049739}\n",
      "   65 | 0.000023 | 163840/180756 | 4.2787 | 1.7333 |\n",
      "val: {'recall': 0.976595, 'recall_grapheme': 0.964491, 'recall_vowel': 0.987809, 'recall_consonant': 0.989589, 'acc_grapheme': 0.96659, 'acc_vowel': 0.990241, 'acc_consonant': 0.99054, 'loss_grapheme': 0.168314, 'loss_vowel': 0.072619, 'loss_consonant': 0.058769}\n",
      "   67 | 0.000016 | 008192/180756 | 0.0147 | 1.5179 |\n",
      "val: {'recall': 0.976641, 'recall_grapheme': 0.964855, 'recall_vowel': 0.987913, 'recall_consonant': 0.988943, 'acc_grapheme': 0.967038, 'acc_vowel': 0.99039, 'acc_consonant': 0.990191, 'loss_grapheme': 0.172467, 'loss_vowel': 0.076442, 'loss_consonant': 0.060681}\n",
      "   68 | 0.000012 | 032768/180756 | 4.3119 | 1.9582 |\n",
      "val: {'recall': 0.97641, 'recall_grapheme': 0.964921, 'recall_vowel': 0.9878, 'recall_consonant': 0.988, 'acc_grapheme': 0.966092, 'acc_vowel': 0.99039, 'acc_consonant': 0.989942, 'loss_grapheme': 0.180949, 'loss_vowel': 0.083579, 'loss_consonant': 0.066094}\n",
      "   69 | 0.000010 | 057344/180756 | 0.0094 | 1.7863 |\n",
      "val: {'recall': 0.975509, 'recall_grapheme': 0.964448, 'recall_vowel': 0.987614, 'recall_consonant': 0.985524, 'acc_grapheme': 0.966541, 'acc_vowel': 0.990341, 'acc_consonant': 0.989892, 'loss_grapheme': 0.154726, 'loss_vowel': 0.056827, 'loss_consonant': 0.048476}\n",
      "   70 | 0.000012 | 081920/180756 | 0.0088 | 1.6795 |\n",
      "val: {'recall': 0.975877, 'recall_grapheme': 0.964085, 'recall_vowel': 0.987551, 'recall_consonant': 0.987787, 'acc_grapheme': 0.966341, 'acc_vowel': 0.990241, 'acc_consonant': 0.990042, 'loss_grapheme': 0.151229, 'loss_vowel': 0.051787, 'loss_consonant': 0.045192}\n",
      "   71 | 0.000016 | 106496/180756 | 0.0094 | 1.5454 |\n",
      "val: {'recall': 0.976311, 'recall_grapheme': 0.964689, 'recall_vowel': 0.988174, 'recall_consonant': 0.98769, 'acc_grapheme': 0.966242, 'acc_vowel': 0.99049, 'acc_consonant': 0.989942, 'loss_grapheme': 0.168821, 'loss_vowel': 0.071435, 'loss_consonant': 0.057396}\n",
      "   72 | 0.000023 | 131072/180756 | 0.0089 | 1.8537 |\n",
      "val: {'recall': 0.977144, 'recall_grapheme': 0.965744, 'recall_vowel': 0.987097, 'recall_consonant': 0.989992, 'acc_grapheme': 0.966541, 'acc_vowel': 0.990092, 'acc_consonant': 0.99054, 'loss_grapheme': 0.171513, 'loss_vowel': 0.075155, 'loss_consonant': 0.060192}\n",
      "   73 | 0.000032 | 155648/180756 | 0.0101 | 1.6735 |\n",
      "val: {'recall': 0.976572, 'recall_grapheme': 0.964954, 'recall_vowel': 0.987628, 'recall_consonant': 0.988753, 'acc_grapheme': 0.965993, 'acc_vowel': 0.99039, 'acc_consonant': 0.990042, 'loss_grapheme': 0.18286, 'loss_vowel': 0.086041, 'loss_consonant': 0.066607}\n",
      "   74 | 0.000043 | 180224/180756 | 4.1988 | 1.7208 |\n",
      "val: {'recall': 0.976418, 'recall_grapheme': 0.96487, 'recall_vowel': 0.987374, 'recall_consonant': 0.988557, 'acc_grapheme': 0.966192, 'acc_vowel': 0.990341, 'acc_consonant': 0.990092, 'loss_grapheme': 0.162761, 'loss_vowel': 0.067187, 'loss_consonant': 0.054611}\n",
      "   76 | 0.000055 | 024576/180756 | 4.3996 | 1.2883 |\n",
      "val: {'recall': 0.975801, 'recall_grapheme': 0.963766, 'recall_vowel': 0.987418, 'recall_consonant': 0.988254, 'acc_grapheme': 0.965893, 'acc_vowel': 0.99049, 'acc_consonant': 0.990092, 'loss_grapheme': 0.160285, 'loss_vowel': 0.062929, 'loss_consonant': 0.052096}\n",
      "   77 | 0.000067 | 049152/180756 | 0.0188 | 1.2792 |\n",
      "val: {'recall': 0.976784, 'recall_grapheme': 0.965592, 'recall_vowel': 0.987236, 'recall_consonant': 0.988715, 'acc_grapheme': 0.966242, 'acc_vowel': 0.990291, 'acc_consonant': 0.990042, 'loss_grapheme': 0.162572, 'loss_vowel': 0.063551, 'loss_consonant': 0.052481}\n",
      "   78 | 0.000078 | 073728/180756 | 0.0138 | 1.9871 |\n",
      "val: {'recall': 0.976543, 'recall_grapheme': 0.964246, 'recall_vowel': 0.988144, 'recall_consonant': 0.989538, 'acc_grapheme': 0.965644, 'acc_vowel': 0.99044, 'acc_consonant': 0.990689, 'loss_grapheme': 0.220477, 'loss_vowel': 0.11877, 'loss_consonant': 0.088101}\n",
      "   79 | 0.000087 | 098304/180756 | 2.9090 | 1.6185 |\n",
      "val: {'recall': 0.975306, 'recall_grapheme': 0.964087, 'recall_vowel': 0.987769, 'recall_consonant': 0.985282, 'acc_grapheme': 0.966192, 'acc_vowel': 0.99049, 'acc_consonant': 0.989594, 'loss_grapheme': 0.161898, 'loss_vowel': 0.062514, 'loss_consonant': 0.052166}\n",
      "   80 | 0.000094 | 122880/180756 | 3.4128 | 1.4053 |\n",
      "val: {'recall': 0.97552, 'recall_grapheme': 0.964063, 'recall_vowel': 0.987227, 'recall_consonant': 0.986728, 'acc_grapheme': 0.966391, 'acc_vowel': 0.99039, 'acc_consonant': 0.989992, 'loss_grapheme': 0.153353, 'loss_vowel': 0.054688, 'loss_consonant': 0.046745}\n",
      "   81 | 0.000098 | 147456/180756 | 0.0100 | 1.6782 |\n",
      "val: {'recall': 0.975102, 'recall_grapheme': 0.96369, 'recall_vowel': 0.987416, 'recall_consonant': 0.985612, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990241, 'acc_consonant': 0.989793, 'loss_grapheme': 0.153358, 'loss_vowel': 0.052015, 'loss_consonant': 0.045786}\n",
      "   82 | 0.000100 | 172032/180756 | 0.0190 | 1.3924 |\n",
      "val: {'recall': 0.975411, 'recall_grapheme': 0.964201, 'recall_vowel': 0.987165, 'recall_consonant': 0.986076, 'acc_grapheme': 0.966391, 'acc_vowel': 0.990291, 'acc_consonant': 0.990291, 'loss_grapheme': 0.160035, 'loss_vowel': 0.06229, 'loss_consonant': 0.051529}\n",
      "   84 | 0.000098 | 016384/180756 | 0.0136 | 1.4766 |\n",
      "val: {'recall': 0.976278, 'recall_grapheme': 0.964998, 'recall_vowel': 0.987403, 'recall_consonant': 0.987715, 'acc_grapheme': 0.966491, 'acc_vowel': 0.990241, 'acc_consonant': 0.989743, 'loss_grapheme': 0.160574, 'loss_vowel': 0.061427, 'loss_consonant': 0.051966}\n",
      "   85 | 0.000094 | 040960/180756 | 0.0068 | 1.5694 |\n",
      "val: {'recall': 0.976172, 'recall_grapheme': 0.963715, 'recall_vowel': 0.987734, 'recall_consonant': 0.989522, 'acc_grapheme': 0.966341, 'acc_vowel': 0.99049, 'acc_consonant': 0.99044, 'loss_grapheme': 0.16213, 'loss_vowel': 0.066507, 'loss_consonant': 0.05368}\n",
      "   86 | 0.000087 | 065536/180756 | 2.0957 | 1.6796 |\n",
      "val: {'recall': 0.975623, 'recall_grapheme': 0.964915, 'recall_vowel': 0.987099, 'recall_consonant': 0.985563, 'acc_grapheme': 0.966541, 'acc_vowel': 0.990092, 'acc_consonant': 0.990092, 'loss_grapheme': 0.163418, 'loss_vowel': 0.065567, 'loss_consonant': 0.053166}\n",
      "   87 | 0.000078 | 090112/180756 | 0.0092 | 1.3350 |\n",
      "val: {'recall': 0.975002, 'recall_grapheme': 0.963656, 'recall_vowel': 0.98736, 'recall_consonant': 0.985336, 'acc_grapheme': 0.965993, 'acc_vowel': 0.990141, 'acc_consonant': 0.989942, 'loss_grapheme': 0.152947, 'loss_vowel': 0.053409, 'loss_consonant': 0.046575}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88 | 0.000067 | 114688/180756 | 3.7324 | 1.5624 |\n",
      "val: {'recall': 0.976673, 'recall_grapheme': 0.965096, 'recall_vowel': 0.988147, 'recall_consonant': 0.988351, 'acc_grapheme': 0.966491, 'acc_vowel': 0.99039, 'acc_consonant': 0.99059, 'loss_grapheme': 0.184828, 'loss_vowel': 0.08589, 'loss_consonant': 0.067056}\n",
      "   89 | 0.000055 | 139264/180756 | 0.0281 | 1.6649 |\n",
      "val: {'recall': 0.975047, 'recall_grapheme': 0.963727, 'recall_vowel': 0.987459, 'recall_consonant': 0.985274, 'acc_grapheme': 0.965644, 'acc_vowel': 0.990092, 'acc_consonant': 0.989992, 'loss_grapheme': 0.157127, 'loss_vowel': 0.056618, 'loss_consonant': 0.047855}\n",
      "   90 | 0.000043 | 163840/180756 | 0.0075 | 1.7707 |\n",
      "val: {'recall': 0.975891, 'recall_grapheme': 0.964574, 'recall_vowel': 0.987614, 'recall_consonant': 0.986804, 'acc_grapheme': 0.966391, 'acc_vowel': 0.99044, 'acc_consonant': 0.990042, 'loss_grapheme': 0.153706, 'loss_vowel': 0.0561, 'loss_consonant': 0.047958}\n",
      "   92 | 0.000032 | 008192/180756 | 0.0077 | 1.7214 |\n",
      "val: {'recall': 0.976167, 'recall_grapheme': 0.964056, 'recall_vowel': 0.987321, 'recall_consonant': 0.989234, 'acc_grapheme': 0.965843, 'acc_vowel': 0.990241, 'acc_consonant': 0.990141, 'loss_grapheme': 0.156904, 'loss_vowel': 0.059189, 'loss_consonant': 0.050065}\n",
      "   93 | 0.000023 | 032768/180756 | 4.6343 | 1.6637 |\n",
      "val: {'recall': 0.976543, 'recall_grapheme': 0.965105, 'recall_vowel': 0.98744, 'recall_consonant': 0.98852, 'acc_grapheme': 0.966092, 'acc_vowel': 0.990092, 'acc_consonant': 0.99054, 'loss_grapheme': 0.161541, 'loss_vowel': 0.063292, 'loss_consonant': 0.05174}\n",
      "   94 | 0.000016 | 057344/180756 | 0.0074 | 1.8291 |\n",
      "val: {'recall': 0.977274, 'recall_grapheme': 0.965844, 'recall_vowel': 0.987867, 'recall_consonant': 0.989542, 'acc_grapheme': 0.966491, 'acc_vowel': 0.990291, 'acc_consonant': 0.990639, 'loss_grapheme': 0.205638, 'loss_vowel': 0.105017, 'loss_consonant': 0.080263}\n",
      "** saved\n",
      "   95 | 0.000012 | 081920/180756 | 3.5787 | 1.6350 |\n",
      "val: {'recall': 0.97535, 'recall_grapheme': 0.963859, 'recall_vowel': 0.987493, 'recall_consonant': 0.98619, 'acc_grapheme': 0.965893, 'acc_vowel': 0.990092, 'acc_consonant': 0.989544, 'loss_grapheme': 0.15605, 'loss_vowel': 0.05588, 'loss_consonant': 0.048004}\n",
      "   96 | 0.000010 | 106496/180756 | 0.0101 | 1.7046 |\n",
      "val: {'recall': 0.976252, 'recall_grapheme': 0.964783, 'recall_vowel': 0.987365, 'recall_consonant': 0.988079, 'acc_grapheme': 0.96659, 'acc_vowel': 0.99039, 'acc_consonant': 0.990042, 'loss_grapheme': 0.156166, 'loss_vowel': 0.059972, 'loss_consonant': 0.050391}\n",
      "   97 | 0.000012 | 131072/180756 | 0.0080 | 1.7244 |\n",
      "val: {'recall': 0.975679, 'recall_grapheme': 0.964795, 'recall_vowel': 0.987721, 'recall_consonant': 0.985405, 'acc_grapheme': 0.966142, 'acc_vowel': 0.990141, 'acc_consonant': 0.989843, 'loss_grapheme': 0.158123, 'loss_vowel': 0.060629, 'loss_consonant': 0.049709}\n",
      "   98 | 0.000016 | 155648/180756 | 0.0107 | 1.5833 |\n",
      "val: {'recall': 0.975249, 'recall_grapheme': 0.963882, 'recall_vowel': 0.987456, 'recall_consonant': 0.985777, 'acc_grapheme': 0.966092, 'acc_vowel': 0.990341, 'acc_consonant': 0.989793, 'loss_grapheme': 0.154371, 'loss_vowel': 0.055536, 'loss_consonant': 0.047784}\n",
      "   99 | 0.000023 | 180224/180756 | 0.0097 | 1.5326 |\n",
      "val: {'recall': 0.974542, 'recall_grapheme': 0.96298, 'recall_vowel': 0.987164, 'recall_consonant': 0.985044, 'acc_grapheme': 0.965644, 'acc_vowel': 0.990291, 'acc_consonant': 0.989494, 'loss_grapheme': 0.153369, 'loss_vowel': 0.050037, 'loss_consonant': 0.044785}\n",
      "  101 | 0.000032 | 024576/180756 | 0.0125 | 1.7166 |\n",
      "val: {'recall': 0.975896, 'recall_grapheme': 0.965072, 'recall_vowel': 0.987781, 'recall_consonant': 0.985657, 'acc_grapheme': 0.966142, 'acc_vowel': 0.990291, 'acc_consonant': 0.989992, 'loss_grapheme': 0.153235, 'loss_vowel': 0.055656, 'loss_consonant': 0.047074}\n",
      "  102 | 0.000043 | 049152/180756 | 4.5604 | 1.4731 |\n",
      "val: {'recall': 0.975894, 'recall_grapheme': 0.96459, 'recall_vowel': 0.987469, 'recall_consonant': 0.986927, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990291, 'acc_consonant': 0.990241, 'loss_grapheme': 0.163039, 'loss_vowel': 0.065019, 'loss_consonant': 0.053806}\n",
      "  103 | 0.000055 | 073728/180756 | 4.3027 | 1.7664 |\n",
      "val: {'recall': 0.976577, 'recall_grapheme': 0.964845, 'recall_vowel': 0.9874, 'recall_consonant': 0.989218, 'acc_grapheme': 0.966292, 'acc_vowel': 0.990092, 'acc_consonant': 0.99039, 'loss_grapheme': 0.169289, 'loss_vowel': 0.074106, 'loss_consonant': 0.059204}\n",
      "  104 | 0.000067 | 098304/180756 | 0.0104 | 1.4932 |\n",
      "val: {'recall': 0.975221, 'recall_grapheme': 0.96423, 'recall_vowel': 0.987242, 'recall_consonant': 0.985181, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990141, 'acc_consonant': 0.990042, 'loss_grapheme': 0.154659, 'loss_vowel': 0.054332, 'loss_consonant': 0.046842}\n",
      "  105 | 0.000077 | 122880/180756 | 0.0064 | 1.8062 |\n",
      "val: {'recall': 0.975153, 'recall_grapheme': 0.963246, 'recall_vowel': 0.987293, 'recall_consonant': 0.986828, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990141, 'acc_consonant': 0.989942, 'loss_grapheme': 0.151796, 'loss_vowel': 0.053076, 'loss_consonant': 0.046129}\n"
     ]
    }
   ],
   "source": [
    "train(args) #inceptionresnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.07458, 'recall_grapheme': 0.001257, 'recall_vowel': 0.13502, 'recall_consonant': 0.160785, 'acc_grapheme': 0.003635, 'acc_vowel': 0.149173, 'acc_consonant': 0.18084, 'loss_grapheme': 5.140628, 'loss_vowel': 2.363855, 'loss_consonant': 1.917337}\n",
      "    1 | 0.000040 | 024576/180756 | 5.9492 | 6.4747 |\n",
      "val: {'recall': 0.278253, 'recall_grapheme': 0.013213, 'recall_vowel': 0.477369, 'recall_consonant': 0.609216, 'acc_grapheme': 0.072296, 'acc_vowel': 0.746664, 'acc_consonant': 0.778978, 'loss_grapheme': 4.377518, 'loss_vowel': 0.917273, 'loss_consonant': 0.688966}\n",
      "** saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000039 | 049152/180756 | 4.4458 | 5.4273 |\n",
      "val: {'recall': 0.437907, 'recall_grapheme': 0.144446, 'recall_vowel': 0.823923, 'recall_consonant': 0.638812, 'acc_grapheme': 0.24059, 'acc_vowel': 0.838229, 'acc_consonant': 0.895738, 'loss_grapheme': 3.429989, 'loss_vowel': 0.630349, 'loss_consonant': 0.404714}\n",
      "** saved\n",
      "    3 | 0.000037 | 073728/180756 | 3.2732 | 4.7400 |\n",
      "val: {'recall': 0.58344, 'recall_grapheme': 0.327591, 'recall_vowel': 0.888892, 'recall_consonant': 0.789686, 'acc_grapheme': 0.45942, 'acc_vowel': 0.898476, 'acc_consonant': 0.924716, 'loss_grapheme': 2.420991, 'loss_vowel': 0.459054, 'loss_consonant': 0.309041}\n",
      "** saved\n",
      "    4 | 0.000034 | 098304/180756 | 2.5346 | 4.3281 |\n",
      "val: {'recall': 0.754576, 'recall_grapheme': 0.567345, 'recall_vowel': 0.932444, 'recall_consonant': 0.951171, 'acc_grapheme': 0.632693, 'acc_vowel': 0.932135, 'acc_consonant': 0.940948, 'loss_grapheme': 1.711213, 'loss_vowel': 0.372935, 'loss_consonant': 0.269201}\n",
      "** saved\n",
      "    5 | 0.000030 | 122880/180756 | 4.9720 | 3.9105 |\n",
      "val: {'recall': 0.803231, 'recall_grapheme': 0.656596, 'recall_vowel': 0.944813, 'recall_consonant': 0.954918, 'acc_grapheme': 0.733121, 'acc_vowel': 0.943338, 'acc_consonant': 0.951205, 'loss_grapheme': 1.328073, 'loss_vowel': 0.316435, 'loss_consonant': 0.231848}\n",
      "** saved\n",
      "    6 | 0.000026 | 147456/180756 | 1.8389 | 3.7835 |\n",
      "val: {'recall': 0.854152, 'recall_grapheme': 0.749745, 'recall_vowel': 0.954113, 'recall_consonant': 0.963006, 'acc_grapheme': 0.784704, 'acc_vowel': 0.949761, 'acc_consonant': 0.957329, 'loss_grapheme': 1.093298, 'loss_vowel': 0.32104, 'loss_consonant': 0.228569}\n",
      "** saved\n",
      "    7 | 0.000021 | 172032/180756 | 1.6318 | 3.3471 |\n",
      "val: {'recall': 0.880635, 'recall_grapheme': 0.800835, 'recall_vowel': 0.956603, 'recall_consonant': 0.964269, 'acc_grapheme': 0.818214, 'acc_vowel': 0.95718, 'acc_consonant': 0.960815, 'loss_grapheme': 0.945271, 'loss_vowel': 0.290346, 'loss_consonant': 0.207619}\n",
      "** saved\n",
      "    9 | 0.000015 | 016384/180756 | 1.5731 | 3.5816 |\n",
      "val: {'recall': 0.898485, 'recall_grapheme': 0.834272, 'recall_vowel': 0.95958, 'recall_consonant': 0.965818, 'acc_grapheme': 0.834943, 'acc_vowel': 0.958773, 'acc_consonant': 0.961512, 'loss_grapheme': 0.878568, 'loss_vowel': 0.296181, 'loss_consonant': 0.213146}\n",
      "** saved\n",
      "   10 | 0.000011 | 040960/180756 | 1.4739 | 3.8160 |\n",
      "val: {'recall': 0.902646, 'recall_grapheme': 0.840054, 'recall_vowel': 0.962581, 'recall_consonant': 0.967894, 'acc_grapheme': 0.844254, 'acc_vowel': 0.959819, 'acc_consonant': 0.964001, 'loss_grapheme': 0.835964, 'loss_vowel': 0.287804, 'loss_consonant': 0.205966}\n",
      "** saved\n",
      "   11 | 0.000007 | 065536/180756 | 1.7047 | 3.2833 |\n",
      "val: {'recall': 0.905195, 'recall_grapheme': 0.843659, 'recall_vowel': 0.964464, 'recall_consonant': 0.968999, 'acc_grapheme': 0.848536, 'acc_vowel': 0.96181, 'acc_consonant': 0.964997, 'loss_grapheme': 0.795332, 'loss_vowel': 0.268139, 'loss_consonant': 0.192703}\n",
      "** saved\n",
      "   12 | 0.000004 | 090112/180756 | 6.9024 | 3.5044 |\n",
      "val: {'recall': 0.90769, 'recall_grapheme': 0.847967, 'recall_vowel': 0.96525, 'recall_consonant': 0.969576, 'acc_grapheme': 0.852221, 'acc_vowel': 0.962756, 'acc_consonant': 0.965495, 'loss_grapheme': 0.782444, 'loss_vowel': 0.263566, 'loss_consonant': 0.190497}\n",
      "** saved\n",
      "   13 | 0.000002 | 114688/180756 | 1.4332 | 3.4525 |\n",
      "val: {'recall': 0.90761, 'recall_grapheme': 0.847604, 'recall_vowel': 0.965327, 'recall_consonant': 0.969904, 'acc_grapheme': 0.852569, 'acc_vowel': 0.962707, 'acc_consonant': 0.964997, 'loss_grapheme': 0.780785, 'loss_vowel': 0.2679, 'loss_consonant': 0.193473}\n",
      "   14 | 0.000001 | 139264/180756 | 1.3821 | 3.5148 |\n",
      "val: {'recall': 0.907374, 'recall_grapheme': 0.847306, 'recall_vowel': 0.965088, 'recall_consonant': 0.969794, 'acc_grapheme': 0.853714, 'acc_vowel': 0.962657, 'acc_consonant': 0.965196, 'loss_grapheme': 0.777054, 'loss_vowel': 0.265761, 'loss_consonant': 0.190986}\n",
      "   15 | 0.000002 | 163840/180756 | 6.9746 | 3.3436 |\n",
      "val: {'recall': 0.907773, 'recall_grapheme': 0.847435, 'recall_vowel': 0.966118, 'recall_consonant': 0.970103, 'acc_grapheme': 0.853615, 'acc_vowel': 0.963354, 'acc_consonant': 0.965595, 'loss_grapheme': 0.772052, 'loss_vowel': 0.263615, 'loss_consonant': 0.191181}\n",
      "** saved\n",
      "   17 | 0.000004 | 008192/180756 | 1.4609 | 2.4779 |\n",
      "val: {'recall': 0.913738, 'recall_grapheme': 0.859384, 'recall_vowel': 0.966276, 'recall_consonant': 0.969906, 'acc_grapheme': 0.856104, 'acc_vowel': 0.963802, 'acc_consonant': 0.965495, 'loss_grapheme': 0.767495, 'loss_vowel': 0.27523, 'loss_consonant': 0.199056}\n",
      "** saved\n",
      "   18 | 0.000007 | 032768/180756 | 1.3919 | 4.2582 |\n",
      "val: {'recall': 0.915232, 'recall_grapheme': 0.861934, 'recall_vowel': 0.966964, 'recall_consonant': 0.970096, 'acc_grapheme': 0.859341, 'acc_vowel': 0.964549, 'acc_consonant': 0.966491, 'loss_grapheme': 0.750427, 'loss_vowel': 0.277039, 'loss_consonant': 0.200434}\n",
      "** saved\n",
      "   19 | 0.000011 | 057344/180756 | 1.3179 | 2.9143 |\n",
      "val: {'recall': 0.919103, 'recall_grapheme': 0.869529, 'recall_vowel': 0.967727, 'recall_consonant': 0.969626, 'acc_grapheme': 0.86676, 'acc_vowel': 0.965843, 'acc_consonant': 0.967337, 'loss_grapheme': 0.721714, 'loss_vowel': 0.252053, 'loss_consonant': 0.184928}\n",
      "** saved\n",
      "   20 | 0.000015 | 081920/180756 | 5.8443 | 3.0186 |\n",
      "val: {'recall': 0.920612, 'recall_grapheme': 0.871696, 'recall_vowel': 0.969343, 'recall_consonant': 0.969713, 'acc_grapheme': 0.871938, 'acc_vowel': 0.967038, 'acc_consonant': 0.967337, 'loss_grapheme': 0.680147, 'loss_vowel': 0.244297, 'loss_consonant': 0.177238}\n",
      "** saved\n",
      "   21 | 0.000021 | 106496/180756 | 1.1576 | 2.9260 |\n",
      "val: {'recall': 0.926951, 'recall_grapheme': 0.883734, 'recall_vowel': 0.969751, 'recall_consonant': 0.970584, 'acc_grapheme': 0.879606, 'acc_vowel': 0.970175, 'acc_consonant': 0.970623, 'loss_grapheme': 0.634957, 'loss_vowel': 0.235532, 'loss_consonant': 0.173444}\n",
      "** saved\n",
      "   22 | 0.000026 | 131072/180756 | 1.0924 | 3.0481 |\n",
      "val: {'recall': 0.931527, 'recall_grapheme': 0.891686, 'recall_vowel': 0.971804, 'recall_consonant': 0.97093, 'acc_grapheme': 0.888518, 'acc_vowel': 0.970424, 'acc_consonant': 0.971918, 'loss_grapheme': 0.618644, 'loss_vowel': 0.232395, 'loss_consonant': 0.170508}\n",
      "** saved\n",
      "   23 | 0.000030 | 155648/180756 | 6.5754 | 3.3956 |\n",
      "val: {'recall': 0.932704, 'recall_grapheme': 0.892387, 'recall_vowel': 0.972383, 'recall_consonant': 0.973657, 'acc_grapheme': 0.89514, 'acc_vowel': 0.972864, 'acc_consonant': 0.972167, 'loss_grapheme': 0.590911, 'loss_vowel': 0.234271, 'loss_consonant': 0.167197}\n",
      "** saved\n",
      "   24 | 0.000034 | 180224/180756 | 6.2238 | 2.6584 |\n",
      "val: {'recall': 0.937073, 'recall_grapheme': 0.899511, 'recall_vowel': 0.972312, 'recall_consonant': 0.976956, 'acc_grapheme': 0.901314, 'acc_vowel': 0.973959, 'acc_consonant': 0.974407, 'loss_grapheme': 0.503337, 'loss_vowel': 0.204842, 'loss_consonant': 0.149493}\n",
      "** saved\n",
      "   26 | 0.000037 | 024576/180756 | 0.8506 | 2.6825 |\n",
      "val: {'recall': 0.939475, 'recall_grapheme': 0.902807, 'recall_vowel': 0.974356, 'recall_consonant': 0.977929, 'acc_grapheme': 0.903157, 'acc_vowel': 0.97371, 'acc_consonant': 0.973611, 'loss_grapheme': 0.523531, 'loss_vowel': 0.211616, 'loss_consonant': 0.154963}\n",
      "** saved\n",
      "   27 | 0.000039 | 049152/180756 | 0.7739 | 3.2456 |\n",
      "val: {'recall': 0.943538, 'recall_grapheme': 0.909017, 'recall_vowel': 0.975854, 'recall_consonant': 0.980263, 'acc_grapheme': 0.90724, 'acc_vowel': 0.9761, 'acc_consonant': 0.974457, 'loss_grapheme': 0.508618, 'loss_vowel': 0.208891, 'loss_consonant': 0.156694}\n",
      "** saved\n",
      "   28 | 0.000040 | 073728/180756 | 3.6383 | 2.6676 |\n",
      "val: {'recall': 0.947488, 'recall_grapheme': 0.914212, 'recall_vowel': 0.976635, 'recall_consonant': 0.984892, 'acc_grapheme': 0.911273, 'acc_vowel': 0.977046, 'acc_consonant': 0.975154, 'loss_grapheme': 0.450099, 'loss_vowel': 0.184055, 'loss_consonant': 0.138895}\n",
      "** saved\n",
      "   29 | 0.000039 | 098304/180756 | 6.0463 | 3.0920 |\n",
      "val: {'recall': 0.948886, 'recall_grapheme': 0.916334, 'recall_vowel': 0.97713, 'recall_consonant': 0.985745, 'acc_grapheme': 0.913712, 'acc_vowel': 0.977594, 'acc_consonant': 0.975105, 'loss_grapheme': 0.465274, 'loss_vowel': 0.197108, 'loss_consonant': 0.149643}\n",
      "** saved\n",
      "   30 | 0.000037 | 122880/180756 | 0.6060 | 2.7346 |\n",
      "val: {'recall': 0.950927, 'recall_grapheme': 0.919989, 'recall_vowel': 0.977336, 'recall_consonant': 0.986394, 'acc_grapheme': 0.918542, 'acc_vowel': 0.977694, 'acc_consonant': 0.977196, 'loss_grapheme': 0.422447, 'loss_vowel': 0.176836, 'loss_consonant': 0.136136}\n",
      "** saved\n",
      "   31 | 0.000034 | 147456/180756 | 0.5060 | 2.4749 |\n",
      "val: {'recall': 0.953576, 'recall_grapheme': 0.925228, 'recall_vowel': 0.978147, 'recall_consonant': 0.985699, 'acc_grapheme': 0.921928, 'acc_vowel': 0.978739, 'acc_consonant': 0.979038, 'loss_grapheme': 0.367862, 'loss_vowel': 0.148525, 'loss_consonant': 0.112425}\n",
      "** saved\n",
      "   32 | 0.000030 | 172032/180756 | 4.8794 | 2.4426 |\n",
      "val: {'recall': 0.954859, 'recall_grapheme': 0.927092, 'recall_vowel': 0.978718, 'recall_consonant': 0.986534, 'acc_grapheme': 0.924617, 'acc_vowel': 0.980133, 'acc_consonant': 0.979884, 'loss_grapheme': 0.346149, 'loss_vowel': 0.142302, 'loss_consonant': 0.109062}\n",
      "** saved\n",
      "   34 | 0.000026 | 016384/180756 | 0.5014 | 1.2592 |\n",
      "val: {'recall': 0.954072, 'recall_grapheme': 0.925321, 'recall_vowel': 0.978325, 'recall_consonant': 0.987323, 'acc_grapheme': 0.926459, 'acc_vowel': 0.980133, 'acc_consonant': 0.980183, 'loss_grapheme': 0.32233, 'loss_vowel': 0.127517, 'loss_consonant': 0.101396}\n",
      "   35 | 0.000021 | 040960/180756 | 2.1595 | 1.6558 |\n",
      "val: {'recall': 0.956519, 'recall_grapheme': 0.929784, 'recall_vowel': 0.979213, 'recall_consonant': 0.987293, 'acc_grapheme': 0.92865, 'acc_vowel': 0.980283, 'acc_consonant': 0.98098, 'loss_grapheme': 0.315712, 'loss_vowel': 0.124164, 'loss_consonant': 0.095107}\n",
      "** saved\n",
      "   36 | 0.000015 | 065536/180756 | 0.5387 | 2.4987 |\n",
      "val: {'recall': 0.95698, 'recall_grapheme': 0.930402, 'recall_vowel': 0.979749, 'recall_consonant': 0.987368, 'acc_grapheme': 0.927654, 'acc_vowel': 0.980183, 'acc_consonant': 0.980233, 'loss_grapheme': 0.328278, 'loss_vowel': 0.139974, 'loss_consonant': 0.108448}\n",
      "** saved\n",
      "   37 | 0.000011 | 090112/180756 | 0.4874 | 2.5569 |\n",
      "val: {'recall': 0.957531, 'recall_grapheme': 0.931297, 'recall_vowel': 0.979447, 'recall_consonant': 0.988083, 'acc_grapheme': 0.929496, 'acc_vowel': 0.980034, 'acc_consonant': 0.979984, 'loss_grapheme': 0.342418, 'loss_vowel': 0.149875, 'loss_consonant': 0.115813}\n",
      "** saved\n",
      "   38 | 0.000007 | 114688/180756 | 0.4397 | 2.8045 |\n",
      "val: {'recall': 0.957639, 'recall_grapheme': 0.931514, 'recall_vowel': 0.9799, 'recall_consonant': 0.987629, 'acc_grapheme': 0.926957, 'acc_vowel': 0.980133, 'acc_consonant': 0.979884, 'loss_grapheme': 0.364701, 'loss_vowel': 0.168044, 'loss_consonant': 0.124669}\n",
      "** saved\n",
      "   39 | 0.000004 | 139264/180756 | 5.9363 | 2.6856 |\n",
      "val: {'recall': 0.957362, 'recall_grapheme': 0.931108, 'recall_vowel': 0.97948, 'recall_consonant': 0.987751, 'acc_grapheme': 0.929347, 'acc_vowel': 0.980034, 'acc_consonant': 0.980133, 'loss_grapheme': 0.342348, 'loss_vowel': 0.153241, 'loss_consonant': 0.115314}\n",
      "   40 | 0.000002 | 163840/180756 | 6.1542 | 2.4091 |\n",
      "val: {'recall': 0.957724, 'recall_grapheme': 0.931815, 'recall_vowel': 0.979421, 'recall_consonant': 0.987847, 'acc_grapheme': 0.929645, 'acc_vowel': 0.980482, 'acc_consonant': 0.980781, 'loss_grapheme': 0.327195, 'loss_vowel': 0.143394, 'loss_consonant': 0.109093}\n",
      "** saved\n",
      "   42 | 0.000001 | 008192/180756 | 1.6373 | 2.5416 |\n",
      "val: {'recall': 0.957916, 'recall_grapheme': 0.932002, 'recall_vowel': 0.979733, 'recall_consonant': 0.987927, 'acc_grapheme': 0.929297, 'acc_vowel': 0.980183, 'acc_consonant': 0.980183, 'loss_grapheme': 0.338341, 'loss_vowel': 0.152621, 'loss_consonant': 0.115358}\n",
      "** saved\n",
      "   43 | 0.000002 | 032768/180756 | 4.7143 | 3.0396 |\n",
      "val: {'recall': 0.957283, 'recall_grapheme': 0.930561, 'recall_vowel': 0.979811, 'recall_consonant': 0.988199, 'acc_grapheme': 0.92865, 'acc_vowel': 0.980333, 'acc_consonant': 0.980233, 'loss_grapheme': 0.345923, 'loss_vowel': 0.157311, 'loss_consonant': 0.117998}\n",
      "   44 | 0.000004 | 057344/180756 | 5.6663 | 2.9603 |\n",
      "val: {'recall': 0.958336, 'recall_grapheme': 0.932496, 'recall_vowel': 0.980128, 'recall_consonant': 0.988224, 'acc_grapheme': 0.929297, 'acc_vowel': 0.980233, 'acc_consonant': 0.980133, 'loss_grapheme': 0.350461, 'loss_vowel': 0.162142, 'loss_consonant': 0.118832}\n",
      "** saved\n",
      "   45 | 0.000007 | 081920/180756 | 0.4206 | 2.5854 |\n",
      "val: {'recall': 0.95779, 'recall_grapheme': 0.931591, 'recall_vowel': 0.979722, 'recall_consonant': 0.988256, 'acc_grapheme': 0.930193, 'acc_vowel': 0.980532, 'acc_consonant': 0.980432, 'loss_grapheme': 0.327501, 'loss_vowel': 0.143149, 'loss_consonant': 0.109385}\n",
      "   46 | 0.000011 | 106496/180756 | 0.4087 | 2.4127 |\n",
      "val: {'recall': 0.957915, 'recall_grapheme': 0.931801, 'recall_vowel': 0.980024, 'recall_consonant': 0.988034, 'acc_grapheme': 0.930343, 'acc_vowel': 0.980781, 'acc_consonant': 0.980781, 'loss_grapheme': 0.322213, 'loss_vowel': 0.144724, 'loss_consonant': 0.108562}\n",
      "   47 | 0.000015 | 131072/180756 | 2.1212 | 2.3057 |\n",
      "val: {'recall': 0.958736, 'recall_grapheme': 0.93335, 'recall_vowel': 0.980333, 'recall_consonant': 0.987913, 'acc_grapheme': 0.932035, 'acc_vowel': 0.981528, 'acc_consonant': 0.981627, 'loss_grapheme': 0.305004, 'loss_vowel': 0.129049, 'loss_consonant': 0.099451}\n",
      "** saved\n",
      "   48 | 0.000020 | 155648/180756 | 0.4411 | 2.4631 |\n",
      "val: {'recall': 0.958697, 'recall_grapheme': 0.933776, 'recall_vowel': 0.9788, 'recall_consonant': 0.988436, 'acc_grapheme': 0.931338, 'acc_vowel': 0.981129, 'acc_consonant': 0.981328, 'loss_grapheme': 0.30775, 'loss_vowel': 0.134938, 'loss_consonant': 0.103568}\n",
      "   49 | 0.000026 | 180224/180756 | 0.4139 | 2.5140 |\n",
      "val: {'recall': 0.959045, 'recall_grapheme': 0.933683, 'recall_vowel': 0.980189, 'recall_consonant': 0.988626, 'acc_grapheme': 0.932932, 'acc_vowel': 0.981129, 'acc_consonant': 0.981179, 'loss_grapheme': 0.308658, 'loss_vowel': 0.135809, 'loss_consonant': 0.103543}\n",
      "** saved\n",
      "   51 | 0.000030 | 024576/180756 | 0.4301 | 2.2555 |\n",
      "val: {'recall': 0.959465, 'recall_grapheme': 0.93435, 'recall_vowel': 0.980446, 'recall_consonant': 0.988712, 'acc_grapheme': 0.933828, 'acc_vowel': 0.981179, 'acc_consonant': 0.982125, 'loss_grapheme': 0.301174, 'loss_vowel': 0.136697, 'loss_consonant': 0.103638}\n",
      "** saved\n",
      "   52 | 0.000034 | 049152/180756 | 0.4044 | 2.5313 |\n",
      "val: {'recall': 0.959665, 'recall_grapheme': 0.934152, 'recall_vowel': 0.98145, 'recall_consonant': 0.988905, 'acc_grapheme': 0.935023, 'acc_vowel': 0.982075, 'acc_consonant': 0.98093, 'loss_grapheme': 0.296926, 'loss_vowel': 0.132662, 'loss_consonant': 0.103287}\n",
      "** saved\n",
      "   53 | 0.000037 | 073728/180756 | 0.3419 | 2.5974 |\n",
      "val: {'recall': 0.960746, 'recall_grapheme': 0.936442, 'recall_vowel': 0.981181, 'recall_consonant': 0.988919, 'acc_grapheme': 0.934774, 'acc_vowel': 0.982474, 'acc_consonant': 0.982922, 'loss_grapheme': 0.295436, 'loss_vowel': 0.130364, 'loss_consonant': 0.100779}\n",
      "** saved\n",
      "   54 | 0.000039 | 098304/180756 | 0.3444 | 2.4636 |\n",
      "val: {'recall': 0.961563, 'recall_grapheme': 0.937677, 'recall_vowel': 0.981159, 'recall_consonant': 0.989737, 'acc_grapheme': 0.936766, 'acc_vowel': 0.982225, 'acc_consonant': 0.982025, 'loss_grapheme': 0.277544, 'loss_vowel': 0.118468, 'loss_consonant': 0.095099}\n",
      "** saved\n",
      "   55 | 0.000040 | 122880/180756 | 3.5484 | 2.3360 |\n",
      "val: {'recall': 0.961201, 'recall_grapheme': 0.937358, 'recall_vowel': 0.981002, 'recall_consonant': 0.989087, 'acc_grapheme': 0.937015, 'acc_vowel': 0.981926, 'acc_consonant': 0.983619, 'loss_grapheme': 0.279421, 'loss_vowel': 0.128154, 'loss_consonant': 0.096499}\n",
      "   56 | 0.000039 | 147456/180756 | 0.3946 | 2.8214 |\n",
      "val: {'recall': 0.962275, 'recall_grapheme': 0.939617, 'recall_vowel': 0.981062, 'recall_consonant': 0.988804, 'acc_grapheme': 0.936268, 'acc_vowel': 0.982673, 'acc_consonant': 0.981229, 'loss_grapheme': 0.299511, 'loss_vowel': 0.151514, 'loss_consonant': 0.113317}\n",
      "** saved\n",
      "   57 | 0.000037 | 172032/180756 | 0.3666 | 2.3750 |\n",
      "val: {'recall': 0.961995, 'recall_grapheme': 0.939072, 'recall_vowel': 0.98053, 'recall_consonant': 0.989305, 'acc_grapheme': 0.939554, 'acc_vowel': 0.982922, 'acc_consonant': 0.984465, 'loss_grapheme': 0.258881, 'loss_vowel': 0.116009, 'loss_consonant': 0.089325}\n",
      "   59 | 0.000034 | 016384/180756 | 5.3297 | 1.8553 |\n",
      "val: {'recall': 0.962892, 'recall_grapheme': 0.939531, 'recall_vowel': 0.982682, 'recall_consonant': 0.989823, 'acc_grapheme': 0.939255, 'acc_vowel': 0.983918, 'acc_consonant': 0.983469, 'loss_grapheme': 0.25394, 'loss_vowel': 0.110098, 'loss_consonant': 0.090016}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   60 | 0.000030 | 040960/180756 | 0.2915 | 1.8240 |\n",
      "val: {'recall': 0.963969, 'recall_grapheme': 0.942094, 'recall_vowel': 0.981729, 'recall_consonant': 0.98996, 'acc_grapheme': 0.940799, 'acc_vowel': 0.983918, 'acc_consonant': 0.984714, 'loss_grapheme': 0.243609, 'loss_vowel': 0.111367, 'loss_consonant': 0.086747}\n",
      "** saved\n",
      "   61 | 0.000026 | 065536/180756 | 2.9280 | 1.9589 |\n",
      "val: {'recall': 0.96327, 'recall_grapheme': 0.940485, 'recall_vowel': 0.982443, 'recall_consonant': 0.989667, 'acc_grapheme': 0.940151, 'acc_vowel': 0.983967, 'acc_consonant': 0.983718, 'loss_grapheme': 0.255047, 'loss_vowel': 0.117094, 'loss_consonant': 0.089394}\n",
      "   62 | 0.000021 | 090112/180756 | 0.3134 | 1.9919 |\n",
      "val: {'recall': 0.963296, 'recall_grapheme': 0.940203, 'recall_vowel': 0.982431, 'recall_consonant': 0.990349, 'acc_grapheme': 0.940749, 'acc_vowel': 0.983868, 'acc_consonant': 0.983967, 'loss_grapheme': 0.24437, 'loss_vowel': 0.105124, 'loss_consonant': 0.082845}\n",
      "   63 | 0.000015 | 114688/180756 | 0.2720 | 2.6848 |\n",
      "val: {'recall': 0.96387, 'recall_grapheme': 0.941419, 'recall_vowel': 0.982906, 'recall_consonant': 0.989735, 'acc_grapheme': 0.940948, 'acc_vowel': 0.984167, 'acc_consonant': 0.984266, 'loss_grapheme': 0.268986, 'loss_vowel': 0.129186, 'loss_consonant': 0.097132}\n",
      "   64 | 0.000011 | 139264/180756 | 2.4300 | 2.3532 |\n",
      "val: {'recall': 0.964465, 'recall_grapheme': 0.942278, 'recall_vowel': 0.982872, 'recall_consonant': 0.990432, 'acc_grapheme': 0.941794, 'acc_vowel': 0.983818, 'acc_consonant': 0.984913, 'loss_grapheme': 0.247866, 'loss_vowel': 0.113644, 'loss_consonant': 0.087567}\n",
      "** saved\n",
      "   65 | 0.000007 | 163840/180756 | 0.3371 | 2.1681 |\n",
      "val: {'recall': 0.96445, 'recall_grapheme': 0.942421, 'recall_vowel': 0.982786, 'recall_consonant': 0.990172, 'acc_grapheme': 0.942442, 'acc_vowel': 0.983818, 'acc_consonant': 0.984565, 'loss_grapheme': 0.244169, 'loss_vowel': 0.111051, 'loss_consonant': 0.087409}\n",
      "   67 | 0.000004 | 008192/180756 | 3.2978 | 2.8429 |\n",
      "val: {'recall': 0.964582, 'recall_grapheme': 0.942577, 'recall_vowel': 0.982813, 'recall_consonant': 0.99036, 'acc_grapheme': 0.942043, 'acc_vowel': 0.983918, 'acc_consonant': 0.984415, 'loss_grapheme': 0.252373, 'loss_vowel': 0.118274, 'loss_consonant': 0.092342}\n",
      "** saved\n",
      "   68 | 0.000002 | 032768/180756 | 0.2643 | 1.9877 |\n",
      "val: {'recall': 0.964009, 'recall_grapheme': 0.941601, 'recall_vowel': 0.98267, 'recall_consonant': 0.990165, 'acc_grapheme': 0.942541, 'acc_vowel': 0.983967, 'acc_consonant': 0.984963, 'loss_grapheme': 0.241381, 'loss_vowel': 0.108154, 'loss_consonant': 0.084488}\n",
      "   69 | 0.000001 | 057344/180756 | 0.3014 | 2.4756 |\n",
      "val: {'recall': 0.964198, 'recall_grapheme': 0.941965, 'recall_vowel': 0.982559, 'recall_consonant': 0.990304, 'acc_grapheme': 0.942392, 'acc_vowel': 0.983918, 'acc_consonant': 0.984864, 'loss_grapheme': 0.24969, 'loss_vowel': 0.115157, 'loss_consonant': 0.08987}\n",
      "   70 | 0.000002 | 081920/180756 | 0.2911 | 2.6314 |\n",
      "val: {'recall': 0.964424, 'recall_grapheme': 0.942382, 'recall_vowel': 0.982602, 'recall_consonant': 0.99033, 'acc_grapheme': 0.942143, 'acc_vowel': 0.983818, 'acc_consonant': 0.984266, 'loss_grapheme': 0.2635, 'loss_vowel': 0.125078, 'loss_consonant': 0.09618}\n",
      "   71 | 0.000004 | 106496/180756 | 5.6015 | 2.2767 |\n",
      "val: {'recall': 0.964625, 'recall_grapheme': 0.942652, 'recall_vowel': 0.982751, 'recall_consonant': 0.990444, 'acc_grapheme': 0.942591, 'acc_vowel': 0.983868, 'acc_consonant': 0.984764, 'loss_grapheme': 0.245119, 'loss_vowel': 0.111859, 'loss_consonant': 0.087447}\n",
      "** saved\n",
      "   72 | 0.000007 | 131072/180756 | 5.7849 | 2.4530 |\n",
      "val: {'recall': 0.964963, 'recall_grapheme': 0.943268, 'recall_vowel': 0.982914, 'recall_consonant': 0.990401, 'acc_grapheme': 0.943039, 'acc_vowel': 0.984366, 'acc_consonant': 0.984366, 'loss_grapheme': 0.249056, 'loss_vowel': 0.113844, 'loss_consonant': 0.089132}\n",
      "** saved\n",
      "   73 | 0.000011 | 155648/180756 | 0.2876 | 2.3489 |\n",
      "val: {'recall': 0.964391, 'recall_grapheme': 0.942095, 'recall_vowel': 0.982707, 'recall_consonant': 0.990667, 'acc_grapheme': 0.942093, 'acc_vowel': 0.983669, 'acc_consonant': 0.985511, 'loss_grapheme': 0.239272, 'loss_vowel': 0.104924, 'loss_consonant': 0.082424}\n",
      "   74 | 0.000015 | 180224/180756 | 0.2817 | 2.4944 |\n",
      "val: {'recall': 0.964884, 'recall_grapheme': 0.943078, 'recall_vowel': 0.98297, 'recall_consonant': 0.99041, 'acc_grapheme': 0.94279, 'acc_vowel': 0.984017, 'acc_consonant': 0.984714, 'loss_grapheme': 0.246317, 'loss_vowel': 0.11381, 'loss_consonant': 0.088586}\n",
      "   76 | 0.000021 | 024576/180756 | 0.2764 | 2.3397 |\n",
      "val: {'recall': 0.965228, 'recall_grapheme': 0.943527, 'recall_vowel': 0.983147, 'recall_consonant': 0.99071, 'acc_grapheme': 0.94284, 'acc_vowel': 0.984366, 'acc_consonant': 0.984963, 'loss_grapheme': 0.242614, 'loss_vowel': 0.110345, 'loss_consonant': 0.088085}\n",
      "** saved\n",
      "   77 | 0.000026 | 049152/180756 | 0.2508 | 2.4536 |\n",
      "val: {'recall': 0.96433, 'recall_grapheme': 0.942035, 'recall_vowel': 0.982575, 'recall_consonant': 0.990677, 'acc_grapheme': 0.942193, 'acc_vowel': 0.983469, 'acc_consonant': 0.984316, 'loss_grapheme': 0.253866, 'loss_vowel': 0.124468, 'loss_consonant': 0.094175}\n",
      "   78 | 0.000030 | 073728/180756 | 0.2732 | 1.9369 |\n",
      "val: {'recall': 0.965145, 'recall_grapheme': 0.943555, 'recall_vowel': 0.982749, 'recall_consonant': 0.99072, 'acc_grapheme': 0.943587, 'acc_vowel': 0.984067, 'acc_consonant': 0.984415, 'loss_grapheme': 0.237523, 'loss_vowel': 0.103101, 'loss_consonant': 0.081698}\n",
      "   79 | 0.000034 | 098304/180756 | 0.2875 | 2.5473 |\n",
      "val: {'recall': 0.965243, 'recall_grapheme': 0.943841, 'recall_vowel': 0.982717, 'recall_consonant': 0.990575, 'acc_grapheme': 0.944184, 'acc_vowel': 0.984565, 'acc_consonant': 0.985411, 'loss_grapheme': 0.246541, 'loss_vowel': 0.118241, 'loss_consonant': 0.092895}\n",
      "** saved\n",
      "   80 | 0.000037 | 122880/180756 | 0.2570 | 1.9891 |\n",
      "val: {'recall': 0.964497, 'recall_grapheme': 0.943566, 'recall_vowel': 0.982675, 'recall_consonant': 0.988182, 'acc_grapheme': 0.945379, 'acc_vowel': 0.984963, 'acc_consonant': 0.985959, 'loss_grapheme': 0.224326, 'loss_vowel': 0.103314, 'loss_consonant': 0.079599}\n",
      "   81 | 0.000039 | 147456/180756 | 5.1003 | 2.6258 |\n",
      "val: {'recall': 0.965186, 'recall_grapheme': 0.943338, 'recall_vowel': 0.983451, 'recall_consonant': 0.990616, 'acc_grapheme': 0.943836, 'acc_vowel': 0.984316, 'acc_consonant': 0.985461, 'loss_grapheme': 0.24827, 'loss_vowel': 0.115064, 'loss_consonant': 0.087755}\n",
      "   82 | 0.000040 | 172032/180756 | 0.3393 | 2.2866 |\n",
      "val: {'recall': 0.964593, 'recall_grapheme': 0.943405, 'recall_vowel': 0.983231, 'recall_consonant': 0.988332, 'acc_grapheme': 0.943388, 'acc_vowel': 0.985013, 'acc_consonant': 0.98581, 'loss_grapheme': 0.240477, 'loss_vowel': 0.114445, 'loss_consonant': 0.09074}\n",
      "   84 | 0.000039 | 016384/180756 | 0.2257 | 1.9517 |\n",
      "val: {'recall': 0.966177, 'recall_grapheme': 0.945049, 'recall_vowel': 0.983137, 'recall_consonant': 0.991472, 'acc_grapheme': 0.946226, 'acc_vowel': 0.984963, 'acc_consonant': 0.986407, 'loss_grapheme': 0.227956, 'loss_vowel': 0.107168, 'loss_consonant': 0.085019}\n",
      "** saved\n",
      "   85 | 0.000037 | 040960/180756 | 0.2124 | 2.3930 |\n",
      "val: {'recall': 0.966394, 'recall_grapheme': 0.945675, 'recall_vowel': 0.983295, 'recall_consonant': 0.990932, 'acc_grapheme': 0.946475, 'acc_vowel': 0.984764, 'acc_consonant': 0.985113, 'loss_grapheme': 0.224895, 'loss_vowel': 0.106638, 'loss_consonant': 0.081143}\n",
      "** saved\n",
      "   86 | 0.000034 | 065536/180756 | 0.2761 | 1.8608 |\n",
      "val: {'recall': 0.965289, 'recall_grapheme': 0.945796, 'recall_vowel': 0.983233, 'recall_consonant': 0.986333, 'acc_grapheme': 0.946724, 'acc_vowel': 0.985162, 'acc_consonant': 0.985361, 'loss_grapheme': 0.224576, 'loss_vowel': 0.098874, 'loss_consonant': 0.081697}\n",
      "   87 | 0.000030 | 090112/180756 | 0.2618 | 2.6537 |\n",
      "val: {'recall': 0.966601, 'recall_grapheme': 0.946313, 'recall_vowel': 0.982451, 'recall_consonant': 0.991325, 'acc_grapheme': 0.945429, 'acc_vowel': 0.984615, 'acc_consonant': 0.985959, 'loss_grapheme': 0.241664, 'loss_vowel': 0.119001, 'loss_consonant': 0.090054}\n",
      "** saved\n",
      "   88 | 0.000026 | 114688/180756 | 0.2592 | 2.2798 |\n",
      "val: {'recall': 0.966491, 'recall_grapheme': 0.946598, 'recall_vowel': 0.983936, 'recall_consonant': 0.98883, 'acc_grapheme': 0.947271, 'acc_vowel': 0.985461, 'acc_consonant': 0.985859, 'loss_grapheme': 0.224343, 'loss_vowel': 0.108181, 'loss_consonant': 0.083963}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   89 | 0.000021 | 139264/180756 | 0.2647 | 2.0814 |\n",
      "val: {'recall': 0.965821, 'recall_grapheme': 0.945204, 'recall_vowel': 0.984261, 'recall_consonant': 0.988614, 'acc_grapheme': 0.94762, 'acc_vowel': 0.985411, 'acc_consonant': 0.986606, 'loss_grapheme': 0.207762, 'loss_vowel': 0.09633, 'loss_consonant': 0.074066}\n",
      "   90 | 0.000015 | 163840/180756 | 0.1954 | 2.2083 |\n",
      "val: {'recall': 0.966486, 'recall_grapheme': 0.946695, 'recall_vowel': 0.983565, 'recall_consonant': 0.988989, 'acc_grapheme': 0.948068, 'acc_vowel': 0.98561, 'acc_consonant': 0.986606, 'loss_grapheme': 0.217433, 'loss_vowel': 0.099862, 'loss_consonant': 0.07997}\n",
      "   92 | 0.000011 | 008192/180756 | 3.9731 | 2.0994 |\n",
      "val: {'recall': 0.967025, 'recall_grapheme': 0.946581, 'recall_vowel': 0.98362, 'recall_consonant': 0.991317, 'acc_grapheme': 0.948566, 'acc_vowel': 0.98576, 'acc_consonant': 0.986805, 'loss_grapheme': 0.21569, 'loss_vowel': 0.100773, 'loss_consonant': 0.079335}\n",
      "** saved\n",
      "   93 | 0.000007 | 032768/180756 | 5.7383 | 2.0215 |\n",
      "val: {'recall': 0.967287, 'recall_grapheme': 0.946784, 'recall_vowel': 0.984147, 'recall_consonant': 0.991432, 'acc_grapheme': 0.949412, 'acc_vowel': 0.986059, 'acc_consonant': 0.986457, 'loss_grapheme': 0.203824, 'loss_vowel': 0.0871, 'loss_consonant': 0.069569}\n",
      "** saved\n",
      "   94 | 0.000004 | 057344/180756 | 0.2024 | 2.2462 |\n",
      "val: {'recall': 0.967394, 'recall_grapheme': 0.946936, 'recall_vowel': 0.984147, 'recall_consonant': 0.991559, 'acc_grapheme': 0.949363, 'acc_vowel': 0.985909, 'acc_consonant': 0.986457, 'loss_grapheme': 0.210357, 'loss_vowel': 0.094919, 'loss_consonant': 0.076059}\n",
      "** saved\n",
      "   95 | 0.000002 | 081920/180756 | 0.2263 | 2.1486 |\n",
      "val: {'recall': 0.966882, 'recall_grapheme': 0.94703, 'recall_vowel': 0.984117, 'recall_consonant': 0.989351, 'acc_grapheme': 0.948715, 'acc_vowel': 0.986059, 'acc_consonant': 0.986606, 'loss_grapheme': 0.213606, 'loss_vowel': 0.097984, 'loss_consonant': 0.077594}\n",
      "   96 | 0.000001 | 106496/180756 | 2.4642 | 2.2858 |\n",
      "val: {'recall': 0.966794, 'recall_grapheme': 0.947018, 'recall_vowel': 0.984116, 'recall_consonant': 0.989022, 'acc_grapheme': 0.948566, 'acc_vowel': 0.986009, 'acc_consonant': 0.986457, 'loss_grapheme': 0.219154, 'loss_vowel': 0.104421, 'loss_consonant': 0.081353}\n",
      "   97 | 0.000002 | 131072/180756 | 4.4599 | 2.0723 |\n",
      "val: {'recall': 0.966894, 'recall_grapheme': 0.947021, 'recall_vowel': 0.984259, 'recall_consonant': 0.989275, 'acc_grapheme': 0.949213, 'acc_vowel': 0.986009, 'acc_consonant': 0.986656, 'loss_grapheme': 0.211887, 'loss_vowel': 0.096848, 'loss_consonant': 0.076928}\n",
      "   98 | 0.000004 | 155648/180756 | 5.7701 | 1.9027 |\n",
      "val: {'recall': 0.966867, 'recall_grapheme': 0.947409, 'recall_vowel': 0.983821, 'recall_consonant': 0.98883, 'acc_grapheme': 0.949512, 'acc_vowel': 0.985959, 'acc_consonant': 0.986457, 'loss_grapheme': 0.204857, 'loss_vowel': 0.088651, 'loss_consonant': 0.070161}\n",
      "   99 | 0.000007 | 180224/180756 | 0.2221 | 2.2820 |\n",
      "val: {'recall': 0.96775, 'recall_grapheme': 0.947371, 'recall_vowel': 0.984199, 'recall_consonant': 0.99206, 'acc_grapheme': 0.948815, 'acc_vowel': 0.98581, 'acc_consonant': 0.986507, 'loss_grapheme': 0.224649, 'loss_vowel': 0.109725, 'loss_consonant': 0.086937}\n",
      "** saved\n",
      "  101 | 0.000011 | 024576/180756 | 5.6575 | 2.5718 |\n",
      "val: {'recall': 0.96755, 'recall_grapheme': 0.947117, 'recall_vowel': 0.984079, 'recall_consonant': 0.991888, 'acc_grapheme': 0.948666, 'acc_vowel': 0.985511, 'acc_consonant': 0.986656, 'loss_grapheme': 0.216903, 'loss_vowel': 0.100545, 'loss_consonant': 0.079794}\n",
      "  102 | 0.000015 | 049152/180756 | 5.1417 | 2.2686 |\n",
      "val: {'recall': 0.966238, 'recall_grapheme': 0.947325, 'recall_vowel': 0.98379, 'recall_consonant': 0.986513, 'acc_grapheme': 0.949363, 'acc_vowel': 0.986108, 'acc_consonant': 0.986606, 'loss_grapheme': 0.204968, 'loss_vowel': 0.093791, 'loss_consonant': 0.072976}\n",
      "  103 | 0.000021 | 073728/180756 | 0.2013 | 2.3940 |\n",
      "val: {'recall': 0.966968, 'recall_grapheme': 0.947189, 'recall_vowel': 0.984329, 'recall_consonant': 0.989165, 'acc_grapheme': 0.948417, 'acc_vowel': 0.98571, 'acc_consonant': 0.986756, 'loss_grapheme': 0.2151, 'loss_vowel': 0.104902, 'loss_consonant': 0.080249}\n",
      "  104 | 0.000026 | 098304/180756 | 4.7725 | 2.5089 |\n",
      "val: {'recall': 0.967432, 'recall_grapheme': 0.946584, 'recall_vowel': 0.984254, 'recall_consonant': 0.992307, 'acc_grapheme': 0.948516, 'acc_vowel': 0.986108, 'acc_consonant': 0.985909, 'loss_grapheme': 0.222472, 'loss_vowel': 0.10064, 'loss_consonant': 0.080962}\n",
      "  105 | 0.000030 | 122880/180756 | 5.3781 | 2.1033 |\n",
      "val: {'recall': 0.96804, 'recall_grapheme': 0.94808, 'recall_vowel': 0.983878, 'recall_consonant': 0.992121, 'acc_grapheme': 0.949263, 'acc_vowel': 0.985859, 'acc_consonant': 0.986059, 'loss_grapheme': 0.209083, 'loss_vowel': 0.093407, 'loss_consonant': 0.07679}\n",
      "** saved\n",
      "  106 | 0.000034 | 147456/180756 | 4.2679 | 2.3377 |\n",
      "val: {'recall': 0.96626, 'recall_grapheme': 0.946293, 'recall_vowel': 0.983416, 'recall_consonant': 0.989038, 'acc_grapheme': 0.949811, 'acc_vowel': 0.98576, 'acc_consonant': 0.986009, 'loss_grapheme': 0.211151, 'loss_vowel': 0.105029, 'loss_consonant': 0.083187}\n",
      "  107 | 0.000037 | 172032/180756 | 0.2015 | 2.3029 |\n",
      "val: {'recall': 0.967625, 'recall_grapheme': 0.947382, 'recall_vowel': 0.983965, 'recall_consonant': 0.991772, 'acc_grapheme': 0.948466, 'acc_vowel': 0.98566, 'acc_consonant': 0.986009, 'loss_grapheme': 0.220716, 'loss_vowel': 0.106064, 'loss_consonant': 0.083076}\n",
      "  109 | 0.000039 | 016384/180756 | 5.1164 | 1.8877 |\n",
      "val: {'recall': 0.96678, 'recall_grapheme': 0.947063, 'recall_vowel': 0.984252, 'recall_consonant': 0.988741, 'acc_grapheme': 0.949512, 'acc_vowel': 0.986208, 'acc_consonant': 0.987104, 'loss_grapheme': 0.218054, 'loss_vowel': 0.107178, 'loss_consonant': 0.081213}\n",
      "  110 | 0.000040 | 040960/180756 | 4.2936 | 2.3185 |\n",
      "val: {'recall': 0.967931, 'recall_grapheme': 0.94941, 'recall_vowel': 0.983518, 'recall_consonant': 0.989387, 'acc_grapheme': 0.949014, 'acc_vowel': 0.98581, 'acc_consonant': 0.987054, 'loss_grapheme': 0.229285, 'loss_vowel': 0.117723, 'loss_consonant': 0.092468}\n",
      "  111 | 0.000039 | 065536/180756 | 0.2087 | 2.5994 |\n",
      "val: {'recall': 0.965191, 'recall_grapheme': 0.945836, 'recall_vowel': 0.984344, 'recall_consonant': 0.984746, 'acc_grapheme': 0.948616, 'acc_vowel': 0.98571, 'acc_consonant': 0.986308, 'loss_grapheme': 0.232044, 'loss_vowel': 0.122402, 'loss_consonant': 0.096041}\n",
      "  112 | 0.000037 | 090112/180756 | 5.2800 | 2.6888 |\n",
      "val: {'recall': 0.966524, 'recall_grapheme': 0.945109, 'recall_vowel': 0.983917, 'recall_consonant': 0.991961, 'acc_grapheme': 0.948018, 'acc_vowel': 0.98566, 'acc_consonant': 0.98576, 'loss_grapheme': 0.225322, 'loss_vowel': 0.120095, 'loss_consonant': 0.090616}\n",
      "  113 | 0.000034 | 114688/180756 | 5.3772 | 1.8076 |\n",
      "val: {'recall': 0.9682, 'recall_grapheme': 0.948124, 'recall_vowel': 0.985043, 'recall_consonant': 0.991507, 'acc_grapheme': 0.951354, 'acc_vowel': 0.986706, 'acc_consonant': 0.987453, 'loss_grapheme': 0.191978, 'loss_vowel': 0.084321, 'loss_consonant': 0.068183}\n",
      "** saved\n",
      "  114 | 0.000030 | 139264/180756 | 0.1654 | 1.6866 |\n",
      "val: {'recall': 0.968284, 'recall_grapheme': 0.95007, 'recall_vowel': 0.984313, 'recall_consonant': 0.988684, 'acc_grapheme': 0.953147, 'acc_vowel': 0.986357, 'acc_consonant': 0.987204, 'loss_grapheme': 0.183737, 'loss_vowel': 0.076625, 'loss_consonant': 0.061906}\n",
      "** saved\n",
      "  115 | 0.000026 | 163840/180756 | 0.2049 | 2.3971 |\n",
      "val: {'recall': 0.9676, 'recall_grapheme': 0.948358, 'recall_vowel': 0.984109, 'recall_consonant': 0.989576, 'acc_grapheme': 0.950508, 'acc_vowel': 0.98581, 'acc_consonant': 0.986407, 'loss_grapheme': 0.215928, 'loss_vowel': 0.104226, 'loss_consonant': 0.079502}\n",
      "  117 | 0.000021 | 008192/180756 | 0.1648 | 2.5093 |\n",
      "val: {'recall': 0.969215, 'recall_grapheme': 0.950158, 'recall_vowel': 0.98479, 'recall_consonant': 0.991754, 'acc_grapheme': 0.952798, 'acc_vowel': 0.986407, 'acc_consonant': 0.987104, 'loss_grapheme': 0.201211, 'loss_vowel': 0.09288, 'loss_consonant': 0.074547}\n",
      "** saved\n",
      "  118 | 0.000015 | 032768/180756 | 0.1489 | 1.4192 |\n",
      "val: {'recall': 0.968966, 'recall_grapheme': 0.949932, 'recall_vowel': 0.984216, 'recall_consonant': 0.991783, 'acc_grapheme': 0.952599, 'acc_vowel': 0.986756, 'acc_consonant': 0.987353, 'loss_grapheme': 0.190481, 'loss_vowel': 0.085307, 'loss_consonant': 0.067726}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  119 | 0.000011 | 057344/180756 | 5.5293 | 1.8946 |\n",
      "val: {'recall': 0.968599, 'recall_grapheme': 0.948878, 'recall_vowel': 0.984752, 'recall_consonant': 0.991886, 'acc_grapheme': 0.95245, 'acc_vowel': 0.986656, 'acc_consonant': 0.987353, 'loss_grapheme': 0.192636, 'loss_vowel': 0.088519, 'loss_consonant': 0.071187}\n",
      "  120 | 0.000007 | 081920/180756 | 0.1956 | 1.9332 |\n",
      "val: {'recall': 0.968784, 'recall_grapheme': 0.949254, 'recall_vowel': 0.984958, 'recall_consonant': 0.99167, 'acc_grapheme': 0.953296, 'acc_vowel': 0.986855, 'acc_consonant': 0.987552, 'loss_grapheme': 0.186309, 'loss_vowel': 0.080656, 'loss_consonant': 0.064414}\n",
      "  121 | 0.000004 | 106496/180756 | 4.4213 | 2.5060 |\n",
      "val: {'recall': 0.968981, 'recall_grapheme': 0.949402, 'recall_vowel': 0.985234, 'recall_consonant': 0.991885, 'acc_grapheme': 0.952002, 'acc_vowel': 0.986905, 'acc_consonant': 0.986905, 'loss_grapheme': 0.209559, 'loss_vowel': 0.103785, 'loss_consonant': 0.082104}\n",
      "  122 | 0.000002 | 131072/180756 | 0.1577 | 1.8326 |\n",
      "val: {'recall': 0.968966, 'recall_grapheme': 0.949282, 'recall_vowel': 0.985452, 'recall_consonant': 0.991848, 'acc_grapheme': 0.9525, 'acc_vowel': 0.986955, 'acc_consonant': 0.987403, 'loss_grapheme': 0.187605, 'loss_vowel': 0.083223, 'loss_consonant': 0.066929}\n",
      "  123 | 0.000001 | 155648/180756 | 0.2052 | 2.2573 |\n",
      "val: {'recall': 0.968999, 'recall_grapheme': 0.949313, 'recall_vowel': 0.98545, 'recall_consonant': 0.99192, 'acc_grapheme': 0.95235, 'acc_vowel': 0.987005, 'acc_consonant': 0.987254, 'loss_grapheme': 0.196101, 'loss_vowel': 0.091552, 'loss_consonant': 0.072942}\n",
      "  124 | 0.000002 | 180224/180756 | 4.6172 | 2.0652 |\n",
      "val: {'recall': 0.968924, 'recall_grapheme': 0.949186, 'recall_vowel': 0.985501, 'recall_consonant': 0.991822, 'acc_grapheme': 0.9525, 'acc_vowel': 0.987054, 'acc_consonant': 0.987303, 'loss_grapheme': 0.193139, 'loss_vowel': 0.088606, 'loss_consonant': 0.071255}\n",
      "  126 | 0.000004 | 024576/180756 | 0.1825 | 2.0358 |\n",
      "val: {'recall': 0.969143, 'recall_grapheme': 0.949761, 'recall_vowel': 0.985083, 'recall_consonant': 0.991967, 'acc_grapheme': 0.953346, 'acc_vowel': 0.986855, 'acc_consonant': 0.987652, 'loss_grapheme': 0.183092, 'loss_vowel': 0.078112, 'loss_consonant': 0.06347}\n",
      "  127 | 0.000007 | 049152/180756 | 5.0989 | 1.7627 |\n",
      "val: {'recall': 0.969042, 'recall_grapheme': 0.949526, 'recall_vowel': 0.985251, 'recall_consonant': 0.991866, 'acc_grapheme': 0.953396, 'acc_vowel': 0.987054, 'acc_consonant': 0.987702, 'loss_grapheme': 0.178513, 'loss_vowel': 0.075225, 'loss_consonant': 0.061337}\n",
      "  128 | 0.000011 | 073728/180756 | 0.9961 | 1.8957 |\n",
      "val: {'recall': 0.968336, 'recall_grapheme': 0.949227, 'recall_vowel': 0.985294, 'recall_consonant': 0.989596, 'acc_grapheme': 0.952699, 'acc_vowel': 0.986855, 'acc_consonant': 0.986756, 'loss_grapheme': 0.195702, 'loss_vowel': 0.091345, 'loss_consonant': 0.074332}\n",
      "  129 | 0.000015 | 098304/180756 | 3.7507 | 2.2523 |\n",
      "val: {'recall': 0.968778, 'recall_grapheme': 0.950054, 'recall_vowel': 0.985358, 'recall_consonant': 0.989646, 'acc_grapheme': 0.953296, 'acc_vowel': 0.987005, 'acc_consonant': 0.986905, 'loss_grapheme': 0.199855, 'loss_vowel': 0.095858, 'loss_consonant': 0.076544}\n",
      "  130 | 0.000020 | 122880/180756 | 4.7613 | 2.6018 |\n",
      "val: {'recall': 0.968239, 'recall_grapheme': 0.948493, 'recall_vowel': 0.984224, 'recall_consonant': 0.991746, 'acc_grapheme': 0.952002, 'acc_vowel': 0.986407, 'acc_consonant': 0.987254, 'loss_grapheme': 0.212334, 'loss_vowel': 0.107995, 'loss_consonant': 0.087681}\n",
      "  131 | 0.000026 | 147456/180756 | 0.1758 | 2.0486 |\n",
      "val: {'recall': 0.969, 'recall_grapheme': 0.949795, 'recall_vowel': 0.984914, 'recall_consonant': 0.991495, 'acc_grapheme': 0.952948, 'acc_vowel': 0.986656, 'acc_consonant': 0.987801, 'loss_grapheme': 0.194354, 'loss_vowel': 0.084545, 'loss_consonant': 0.068678}\n",
      "  132 | 0.000030 | 172032/180756 | 0.1535 | 2.1528 |\n",
      "val: {'recall': 0.968531, 'recall_grapheme': 0.950132, 'recall_vowel': 0.984574, 'recall_consonant': 0.989286, 'acc_grapheme': 0.951603, 'acc_vowel': 0.986805, 'acc_consonant': 0.986955, 'loss_grapheme': 0.201007, 'loss_vowel': 0.092392, 'loss_consonant': 0.073484}\n",
      "  134 | 0.000034 | 016384/180756 | 0.1845 | 2.6788 |\n",
      "val: {'recall': 0.969213, 'recall_grapheme': 0.949914, 'recall_vowel': 0.985353, 'recall_consonant': 0.991669, 'acc_grapheme': 0.952848, 'acc_vowel': 0.986905, 'acc_consonant': 0.987054, 'loss_grapheme': 0.200947, 'loss_vowel': 0.093095, 'loss_consonant': 0.074808}\n",
      "  135 | 0.000037 | 040960/180756 | 0.4952 | 2.4473 |\n",
      "val: {'recall': 0.969479, 'recall_grapheme': 0.950817, 'recall_vowel': 0.984508, 'recall_consonant': 0.991773, 'acc_grapheme': 0.951952, 'acc_vowel': 0.986805, 'acc_consonant': 0.987453, 'loss_grapheme': 0.195176, 'loss_vowel': 0.087425, 'loss_consonant': 0.071272}\n",
      "** saved\n",
      "  136 | 0.000039 | 065536/180756 | 1.6761 | 2.1087 |\n",
      "val: {'recall': 0.968686, 'recall_grapheme': 0.949845, 'recall_vowel': 0.985491, 'recall_consonant': 0.989563, 'acc_grapheme': 0.952599, 'acc_vowel': 0.986905, 'acc_consonant': 0.986556, 'loss_grapheme': 0.202579, 'loss_vowel': 0.098633, 'loss_consonant': 0.08224}\n",
      "  137 | 0.000040 | 090112/180756 | 5.7125 | 2.3923 |\n",
      "val: {'recall': 0.96815, 'recall_grapheme': 0.948921, 'recall_vowel': 0.984738, 'recall_consonant': 0.990019, 'acc_grapheme': 0.953296, 'acc_vowel': 0.986905, 'acc_consonant': 0.986357, 'loss_grapheme': 0.211903, 'loss_vowel': 0.106383, 'loss_consonant': 0.084445}\n",
      "  138 | 0.000039 | 114688/180756 | 0.3149 | 1.9593 |\n",
      "val: {'recall': 0.970377, 'recall_grapheme': 0.952582, 'recall_vowel': 0.9845, 'recall_consonant': 0.991843, 'acc_grapheme': 0.953047, 'acc_vowel': 0.986457, 'acc_consonant': 0.987054, 'loss_grapheme': 0.196794, 'loss_vowel': 0.086761, 'loss_consonant': 0.073014}\n",
      "** saved\n",
      "  139 | 0.000037 | 139264/180756 | 0.1303 | 1.8438 |\n",
      "val: {'recall': 0.968968, 'recall_grapheme': 0.951583, 'recall_vowel': 0.985187, 'recall_consonant': 0.98752, 'acc_grapheme': 0.954043, 'acc_vowel': 0.987303, 'acc_consonant': 0.98815, 'loss_grapheme': 0.18644, 'loss_vowel': 0.087022, 'loss_consonant': 0.067359}\n",
      "  140 | 0.000034 | 163840/180756 | 4.3481 | 2.1852 |\n",
      "val: {'recall': 0.968771, 'recall_grapheme': 0.950819, 'recall_vowel': 0.984388, 'recall_consonant': 0.98906, 'acc_grapheme': 0.952251, 'acc_vowel': 0.986656, 'acc_consonant': 0.987602, 'loss_grapheme': 0.201762, 'loss_vowel': 0.09951, 'loss_consonant': 0.07908}\n",
      "  142 | 0.000030 | 008192/180756 | 3.6886 | 1.9398 |\n",
      "val: {'recall': 0.970283, 'recall_grapheme': 0.952344, 'recall_vowel': 0.984186, 'recall_consonant': 0.99226, 'acc_grapheme': 0.954292, 'acc_vowel': 0.986507, 'acc_consonant': 0.987502, 'loss_grapheme': 0.187128, 'loss_vowel': 0.085629, 'loss_consonant': 0.071437}\n",
      "  143 | 0.000026 | 032768/180756 | 2.1635 | 2.3893 |\n",
      "val: {'recall': 0.970018, 'recall_grapheme': 0.95346, 'recall_vowel': 0.985435, 'recall_consonant': 0.987718, 'acc_grapheme': 0.954491, 'acc_vowel': 0.987104, 'acc_consonant': 0.987602, 'loss_grapheme': 0.196978, 'loss_vowel': 0.094596, 'loss_consonant': 0.075861}\n",
      "  144 | 0.000020 | 057344/180756 | 4.9892 | 2.3299 |\n",
      "val: {'recall': 0.970266, 'recall_grapheme': 0.952956, 'recall_vowel': 0.985272, 'recall_consonant': 0.989879, 'acc_grapheme': 0.95474, 'acc_vowel': 0.987303, 'acc_consonant': 0.988, 'loss_grapheme': 0.194375, 'loss_vowel': 0.095829, 'loss_consonant': 0.074912}\n",
      "  145 | 0.000015 | 081920/180756 | 4.6135 | 2.3907 |\n",
      "val: {'recall': 0.970037, 'recall_grapheme': 0.952535, 'recall_vowel': 0.985523, 'recall_consonant': 0.989558, 'acc_grapheme': 0.954939, 'acc_vowel': 0.987154, 'acc_consonant': 0.987951, 'loss_grapheme': 0.198006, 'loss_vowel': 0.099876, 'loss_consonant': 0.078735}\n",
      "  146 | 0.000011 | 106496/180756 | 4.7358 | 2.3396 |\n",
      "val: {'recall': 0.970357, 'recall_grapheme': 0.951973, 'recall_vowel': 0.984876, 'recall_consonant': 0.992607, 'acc_grapheme': 0.954491, 'acc_vowel': 0.987054, 'acc_consonant': 0.98805, 'loss_grapheme': 0.205488, 'loss_vowel': 0.107106, 'loss_consonant': 0.084041}\n",
      "  147 | 0.000007 | 131072/180756 | 5.3951 | 2.0653 |\n",
      "val: {'recall': 0.970344, 'recall_grapheme': 0.952973, 'recall_vowel': 0.985197, 'recall_consonant': 0.990232, 'acc_grapheme': 0.955736, 'acc_vowel': 0.987353, 'acc_consonant': 0.988349, 'loss_grapheme': 0.180739, 'loss_vowel': 0.082067, 'loss_consonant': 0.066905}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  148 | 0.000004 | 155648/180756 | 0.1456 | 1.8366 |\n",
      "val: {'recall': 0.970482, 'recall_grapheme': 0.953163, 'recall_vowel': 0.985494, 'recall_consonant': 0.990109, 'acc_grapheme': 0.956433, 'acc_vowel': 0.987453, 'acc_consonant': 0.988897, 'loss_grapheme': 0.172401, 'loss_vowel': 0.074538, 'loss_consonant': 0.061104}\n",
      "** saved\n",
      "  149 | 0.000002 | 180224/180756 | 0.1117 | 2.0051 |\n",
      "val: {'recall': 0.970056, 'recall_grapheme': 0.952477, 'recall_vowel': 0.985124, 'recall_consonant': 0.990146, 'acc_grapheme': 0.955636, 'acc_vowel': 0.987204, 'acc_consonant': 0.988847, 'loss_grapheme': 0.178338, 'loss_vowel': 0.08025, 'loss_consonant': 0.065393}\n",
      "  151 | 0.000001 | 024576/180756 | 0.1515 | 2.0407 |\n",
      "val: {'recall': 0.970077, 'recall_grapheme': 0.952493, 'recall_vowel': 0.985174, 'recall_consonant': 0.99015, 'acc_grapheme': 0.955487, 'acc_vowel': 0.987303, 'acc_consonant': 0.988648, 'loss_grapheme': 0.184359, 'loss_vowel': 0.085525, 'loss_consonant': 0.068861}\n",
      "  152 | 0.000002 | 049152/180756 | 0.1573 | 2.2106 |\n",
      "val: {'recall': 0.970226, 'recall_grapheme': 0.952833, 'recall_vowel': 0.985066, 'recall_consonant': 0.990171, 'acc_grapheme': 0.955935, 'acc_vowel': 0.987204, 'acc_consonant': 0.988299, 'loss_grapheme': 0.187051, 'loss_vowel': 0.089878, 'loss_consonant': 0.072574}\n",
      "  153 | 0.000004 | 022528/180756 | 0.1328 | 1.4626 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-28f20a7d4cf4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) #efficient b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.965397, 'recall_grapheme': 0.944814, 'recall_vowel': 0.982054, 'recall_consonant': 0.989908, 'acc_grapheme': 0.943985, 'acc_vowel': 0.985113, 'acc_consonant': 0.98561, 'loss_grapheme': 0.253814, 'loss_vowel': 0.118889, 'loss_consonant': 0.094402}\n",
      "    1 | 0.000020 | 024576/180756 | 0.2663 | 2.4646 |\n",
      "val: {'recall': 0.964915, 'recall_grapheme': 0.944224, 'recall_vowel': 0.981453, 'recall_consonant': 0.989758, 'acc_grapheme': 0.944035, 'acc_vowel': 0.984864, 'acc_consonant': 0.985561, 'loss_grapheme': 0.260207, 'loss_vowel': 0.126617, 'loss_consonant': 0.103775}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000020 | 049152/180756 | 0.2677 | 2.3186 |\n",
      "val: {'recall': 0.96517, 'recall_grapheme': 0.946017, 'recall_vowel': 0.981363, 'recall_consonant': 0.987284, 'acc_grapheme': 0.94533, 'acc_vowel': 0.985411, 'acc_consonant': 0.985959, 'loss_grapheme': 0.243896, 'loss_vowel': 0.113981, 'loss_consonant': 0.089509}\n",
      "    3 | 0.000019 | 073728/180756 | 0.3286 | 2.6794 |\n",
      "val: {'recall': 0.964866, 'recall_grapheme': 0.944576, 'recall_vowel': 0.982986, 'recall_consonant': 0.987326, 'acc_grapheme': 0.944633, 'acc_vowel': 0.985411, 'acc_consonant': 0.98576, 'loss_grapheme': 0.262579, 'loss_vowel': 0.126556, 'loss_consonant': 0.095788}\n",
      "    4 | 0.000017 | 098304/180756 | 0.2975 | 2.4868 |\n",
      "val: {'recall': 0.96526, 'recall_grapheme': 0.944161, 'recall_vowel': 0.98217, 'recall_consonant': 0.990548, 'acc_grapheme': 0.945429, 'acc_vowel': 0.98561, 'acc_consonant': 0.985909, 'loss_grapheme': 0.244029, 'loss_vowel': 0.111893, 'loss_consonant': 0.087076}\n",
      "    5 | 0.000015 | 122880/180756 | 5.5230 | 2.4114 |\n",
      "val: {'recall': 0.966459, 'recall_grapheme': 0.946551, 'recall_vowel': 0.982382, 'recall_consonant': 0.990351, 'acc_grapheme': 0.946973, 'acc_vowel': 0.985959, 'acc_consonant': 0.986556, 'loss_grapheme': 0.234653, 'loss_vowel': 0.112181, 'loss_consonant': 0.088859}\n",
      "** saved\n",
      "    6 | 0.000013 | 147456/180756 | 2.1326 | 2.3909 |\n",
      "val: {'recall': 0.966952, 'recall_grapheme': 0.947489, 'recall_vowel': 0.983824, 'recall_consonant': 0.989005, 'acc_grapheme': 0.947371, 'acc_vowel': 0.986009, 'acc_consonant': 0.986706, 'loss_grapheme': 0.235793, 'loss_vowel': 0.113036, 'loss_consonant': 0.090679}\n",
      "** saved\n",
      "    7 | 0.000011 | 172032/180756 | 5.3813 | 2.2282 |\n",
      "val: {'recall': 0.967021, 'recall_grapheme': 0.948479, 'recall_vowel': 0.982346, 'recall_consonant': 0.988781, 'acc_grapheme': 0.948715, 'acc_vowel': 0.985909, 'acc_consonant': 0.986606, 'loss_grapheme': 0.234005, 'loss_vowel': 0.107213, 'loss_consonant': 0.08412}\n",
      "** saved\n",
      "    9 | 0.000008 | 016384/180756 | 0.2495 | 1.5953 |\n",
      "val: {'recall': 0.966724, 'recall_grapheme': 0.947966, 'recall_vowel': 0.982275, 'recall_consonant': 0.988691, 'acc_grapheme': 0.948715, 'acc_vowel': 0.98576, 'acc_consonant': 0.986955, 'loss_grapheme': 0.219224, 'loss_vowel': 0.095584, 'loss_consonant': 0.078878}\n",
      "   10 | 0.000006 | 040960/180756 | 0.2502 | 2.0975 |\n",
      "val: {'recall': 0.967444, 'recall_grapheme': 0.947711, 'recall_vowel': 0.982982, 'recall_consonant': 0.991371, 'acc_grapheme': 0.948317, 'acc_vowel': 0.986158, 'acc_consonant': 0.986855, 'loss_grapheme': 0.225081, 'loss_vowel': 0.101222, 'loss_consonant': 0.081881}\n",
      "** saved\n",
      "   11 | 0.000004 | 065536/180756 | 3.7767 | 2.1811 |\n",
      "val: {'recall': 0.966871, 'recall_grapheme': 0.947901, 'recall_vowel': 0.9827, 'recall_consonant': 0.98898, 'acc_grapheme': 0.948267, 'acc_vowel': 0.986059, 'acc_consonant': 0.986756, 'loss_grapheme': 0.224653, 'loss_vowel': 0.104404, 'loss_consonant': 0.084539}\n",
      "   12 | 0.000002 | 090112/180756 | 4.0224 | 2.1965 |\n",
      "val: {'recall': 0.966996, 'recall_grapheme': 0.948162, 'recall_vowel': 0.982824, 'recall_consonant': 0.988838, 'acc_grapheme': 0.948317, 'acc_vowel': 0.986009, 'acc_consonant': 0.987005, 'loss_grapheme': 0.224422, 'loss_vowel': 0.105371, 'loss_consonant': 0.083886}\n",
      "   13 | 0.000001 | 114688/180756 | 0.2896 | 2.4306 |\n",
      "val: {'recall': 0.967979, 'recall_grapheme': 0.94884, 'recall_vowel': 0.98306, 'recall_consonant': 0.991175, 'acc_grapheme': 0.948417, 'acc_vowel': 0.986208, 'acc_consonant': 0.986805, 'loss_grapheme': 0.236347, 'loss_vowel': 0.113949, 'loss_consonant': 0.089461}\n",
      "** saved\n",
      "   14 | 0.000001 | 139264/180756 | 6.3525 | 2.6887 |\n",
      "val: {'recall': 0.967247, 'recall_grapheme': 0.948454, 'recall_vowel': 0.983086, 'recall_consonant': 0.988994, 'acc_grapheme': 0.948018, 'acc_vowel': 0.986108, 'acc_consonant': 0.986556, 'loss_grapheme': 0.243596, 'loss_vowel': 0.120239, 'loss_consonant': 0.094057}\n",
      "   15 | 0.000001 | 163840/180756 | 5.7202 | 2.1976 |\n",
      "val: {'recall': 0.96686, 'recall_grapheme': 0.947951, 'recall_vowel': 0.982404, 'recall_consonant': 0.989135, 'acc_grapheme': 0.948168, 'acc_vowel': 0.985909, 'acc_consonant': 0.986955, 'loss_grapheme': 0.230064, 'loss_vowel': 0.106717, 'loss_consonant': 0.083683}\n",
      "   17 | 0.000002 | 008192/180756 | 2.5746 | 4.5369 |\n",
      "val: {'recall': 0.966843, 'recall_grapheme': 0.947757, 'recall_vowel': 0.982806, 'recall_consonant': 0.98905, 'acc_grapheme': 0.94762, 'acc_vowel': 0.986009, 'acc_consonant': 0.986556, 'loss_grapheme': 0.239802, 'loss_vowel': 0.117043, 'loss_consonant': 0.09125}\n",
      "   18 | 0.000004 | 032768/180756 | 0.2616 | 2.1251 |\n",
      "val: {'recall': 0.967121, 'recall_grapheme': 0.948364, 'recall_vowel': 0.982872, 'recall_consonant': 0.988883, 'acc_grapheme': 0.949064, 'acc_vowel': 0.986108, 'acc_consonant': 0.987104, 'loss_grapheme': 0.219099, 'loss_vowel': 0.099068, 'loss_consonant': 0.078412}\n",
      "   19 | 0.000006 | 057344/180756 | 1.0556 | 2.6183 |\n",
      "val: {'recall': 0.966384, 'recall_grapheme': 0.947142, 'recall_vowel': 0.982666, 'recall_consonant': 0.988586, 'acc_grapheme': 0.948217, 'acc_vowel': 0.986108, 'acc_consonant': 0.986955, 'loss_grapheme': 0.221987, 'loss_vowel': 0.102145, 'loss_consonant': 0.081404}\n",
      "   20 | 0.000008 | 081920/180756 | 5.5787 | 2.3108 |\n",
      "val: {'recall': 0.967788, 'recall_grapheme': 0.948221, 'recall_vowel': 0.983365, 'recall_consonant': 0.991344, 'acc_grapheme': 0.948964, 'acc_vowel': 0.986059, 'acc_consonant': 0.987154, 'loss_grapheme': 0.227257, 'loss_vowel': 0.106712, 'loss_consonant': 0.084675}\n",
      "   21 | 0.000010 | 106496/180756 | 5.3788 | 1.9495 |\n",
      "val: {'recall': 0.967623, 'recall_grapheme': 0.948524, 'recall_vowel': 0.982419, 'recall_consonant': 0.991027, 'acc_grapheme': 0.949363, 'acc_vowel': 0.986059, 'acc_consonant': 0.987204, 'loss_grapheme': 0.213431, 'loss_vowel': 0.095474, 'loss_consonant': 0.075576}\n",
      "   22 | 0.000013 | 131072/180756 | 5.0654 | 2.2558 |\n",
      "val: {'recall': 0.967245, 'recall_grapheme': 0.948779, 'recall_vowel': 0.98245, 'recall_consonant': 0.988972, 'acc_grapheme': 0.949263, 'acc_vowel': 0.985909, 'acc_consonant': 0.987353, 'loss_grapheme': 0.225709, 'loss_vowel': 0.106288, 'loss_consonant': 0.084229}\n",
      "   23 | 0.000015 | 155648/180756 | 2.7645 | 2.1771 |\n",
      "val: {'recall': 0.966633, 'recall_grapheme': 0.948927, 'recall_vowel': 0.980987, 'recall_consonant': 0.987692, 'acc_grapheme': 0.95006, 'acc_vowel': 0.98581, 'acc_consonant': 0.987054, 'loss_grapheme': 0.216288, 'loss_vowel': 0.093641, 'loss_consonant': 0.07397}\n",
      "   24 | 0.000017 | 180224/180756 | 0.2436 | 2.0259 |\n",
      "val: {'recall': 0.968353, 'recall_grapheme': 0.949158, 'recall_vowel': 0.983244, 'recall_consonant': 0.991855, 'acc_grapheme': 0.950657, 'acc_vowel': 0.986258, 'acc_consonant': 0.987951, 'loss_grapheme': 0.205252, 'loss_vowel': 0.091675, 'loss_consonant': 0.073042}\n",
      "** saved\n",
      "   26 | 0.000019 | 024576/180756 | 0.1847 | 1.9072 |\n",
      "val: {'recall': 0.968301, 'recall_grapheme': 0.949384, 'recall_vowel': 0.982945, 'recall_consonant': 0.991489, 'acc_grapheme': 0.950209, 'acc_vowel': 0.986357, 'acc_consonant': 0.987303, 'loss_grapheme': 0.207879, 'loss_vowel': 0.096408, 'loss_consonant': 0.074546}\n",
      "   27 | 0.000020 | 049152/180756 | 0.2863 | 2.6991 |\n",
      "val: {'recall': 0.969083, 'recall_grapheme': 0.950676, 'recall_vowel': 0.983163, 'recall_consonant': 0.991817, 'acc_grapheme': 0.950159, 'acc_vowel': 0.986457, 'acc_consonant': 0.987204, 'loss_grapheme': 0.227501, 'loss_vowel': 0.112076, 'loss_consonant': 0.088859}\n",
      "** saved\n",
      "   28 | 0.000020 | 073728/180756 | 6.2136 | 2.3123 |\n",
      "val: {'recall': 0.968408, 'recall_grapheme': 0.949503, 'recall_vowel': 0.98269, 'recall_consonant': 0.991935, 'acc_grapheme': 0.95006, 'acc_vowel': 0.986208, 'acc_consonant': 0.986706, 'loss_grapheme': 0.226129, 'loss_vowel': 0.106988, 'loss_consonant': 0.08842}\n",
      "   29 | 0.000020 | 098304/180756 | 5.6909 | 1.9008 |\n",
      "val: {'recall': 0.968527, 'recall_grapheme': 0.949996, 'recall_vowel': 0.982464, 'recall_consonant': 0.991653, 'acc_grapheme': 0.950757, 'acc_vowel': 0.986258, 'acc_consonant': 0.987602, 'loss_grapheme': 0.212323, 'loss_vowel': 0.096782, 'loss_consonant': 0.078064}\n",
      "   30 | 0.000019 | 122880/180756 | 0.2144 | 2.6952 |\n",
      "val: {'recall': 0.968737, 'recall_grapheme': 0.949855, 'recall_vowel': 0.983024, 'recall_consonant': 0.992213, 'acc_grapheme': 0.950159, 'acc_vowel': 0.986208, 'acc_consonant': 0.986905, 'loss_grapheme': 0.229862, 'loss_vowel': 0.114237, 'loss_consonant': 0.093805}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 0.000017 | 147456/180756 | 1.0917 | 2.2785 |\n",
      "val: {'recall': 0.96967, 'recall_grapheme': 0.951849, 'recall_vowel': 0.982762, 'recall_consonant': 0.992223, 'acc_grapheme': 0.9524, 'acc_vowel': 0.986507, 'acc_consonant': 0.987552, 'loss_grapheme': 0.215217, 'loss_vowel': 0.102191, 'loss_consonant': 0.085412}\n",
      "** saved\n",
      "   32 | 0.000015 | 172032/180756 | 2.0361 | 2.2145 |\n",
      "val: {'recall': 0.968838, 'recall_grapheme': 0.950552, 'recall_vowel': 0.983134, 'recall_consonant': 0.991114, 'acc_grapheme': 0.951952, 'acc_vowel': 0.986706, 'acc_consonant': 0.987652, 'loss_grapheme': 0.206998, 'loss_vowel': 0.092428, 'loss_consonant': 0.075055}\n",
      "   34 | 0.000013 | 016384/180756 | 2.7617 | 2.3104 |\n",
      "val: {'recall': 0.96944, 'recall_grapheme': 0.951163, 'recall_vowel': 0.982992, 'recall_consonant': 0.992442, 'acc_grapheme': 0.952599, 'acc_vowel': 0.986606, 'acc_consonant': 0.987602, 'loss_grapheme': 0.204472, 'loss_vowel': 0.094666, 'loss_consonant': 0.076104}\n",
      "   35 | 0.000011 | 040960/180756 | 3.8170 | 2.4111 |\n",
      "val: {'recall': 0.969235, 'recall_grapheme': 0.950532, 'recall_vowel': 0.98373, 'recall_consonant': 0.992145, 'acc_grapheme': 0.952599, 'acc_vowel': 0.987054, 'acc_consonant': 0.9882, 'loss_grapheme': 0.198331, 'loss_vowel': 0.087621, 'loss_consonant': 0.071477}\n",
      "   36 | 0.000008 | 065536/180756 | 5.8837 | 2.1138 |\n",
      "val: {'recall': 0.969707, 'recall_grapheme': 0.951023, 'recall_vowel': 0.98452, 'recall_consonant': 0.992263, 'acc_grapheme': 0.952201, 'acc_vowel': 0.986656, 'acc_consonant': 0.987751, 'loss_grapheme': 0.211004, 'loss_vowel': 0.103002, 'loss_consonant': 0.081992}\n",
      "** saved\n",
      "   37 | 0.000006 | 090112/180756 | 0.1916 | 1.9653 |\n",
      "val: {'recall': 0.969829, 'recall_grapheme': 0.951883, 'recall_vowel': 0.983213, 'recall_consonant': 0.992335, 'acc_grapheme': 0.953147, 'acc_vowel': 0.986507, 'acc_consonant': 0.98805, 'loss_grapheme': 0.197981, 'loss_vowel': 0.087304, 'loss_consonant': 0.071552}\n",
      "** saved\n",
      "   38 | 0.000004 | 114688/180756 | 5.0761 | 2.4749 |\n",
      "val: {'recall': 0.969845, 'recall_grapheme': 0.952148, 'recall_vowel': 0.983271, 'recall_consonant': 0.991815, 'acc_grapheme': 0.952898, 'acc_vowel': 0.986507, 'acc_consonant': 0.987751, 'loss_grapheme': 0.207476, 'loss_vowel': 0.097035, 'loss_consonant': 0.077124}\n",
      "** saved\n",
      "   39 | 0.000002 | 139264/180756 | 0.2129 | 2.2789 |\n",
      "val: {'recall': 0.970164, 'recall_grapheme': 0.952233, 'recall_vowel': 0.98374, 'recall_consonant': 0.992449, 'acc_grapheme': 0.952599, 'acc_vowel': 0.986507, 'acc_consonant': 0.987702, 'loss_grapheme': 0.218172, 'loss_vowel': 0.106762, 'loss_consonant': 0.085092}\n",
      "** saved\n",
      "   40 | 0.000001 | 163840/180756 | 6.0716 | 2.3481 |\n",
      "val: {'recall': 0.969623, 'recall_grapheme': 0.951399, 'recall_vowel': 0.983533, 'recall_consonant': 0.992163, 'acc_grapheme': 0.952599, 'acc_vowel': 0.986606, 'acc_consonant': 0.987552, 'loss_grapheme': 0.212857, 'loss_vowel': 0.102179, 'loss_consonant': 0.082876}\n",
      "   42 | 0.000001 | 008192/180756 | 4.1589 | 2.6192 |\n",
      "val: {'recall': 0.969899, 'recall_grapheme': 0.951721, 'recall_vowel': 0.983816, 'recall_consonant': 0.992339, 'acc_grapheme': 0.952997, 'acc_vowel': 0.986656, 'acc_consonant': 0.98805, 'loss_grapheme': 0.196958, 'loss_vowel': 0.088474, 'loss_consonant': 0.071432}\n",
      "   43 | 0.000001 | 032768/180756 | 0.2342 | 1.2934 |\n",
      "val: {'recall': 0.970005, 'recall_grapheme': 0.952038, 'recall_vowel': 0.983569, 'recall_consonant': 0.992377, 'acc_grapheme': 0.953097, 'acc_vowel': 0.986756, 'acc_consonant': 0.988, 'loss_grapheme': 0.200141, 'loss_vowel': 0.091351, 'loss_consonant': 0.073299}\n",
      "   44 | 0.000002 | 057344/180756 | 0.2020 | 2.3554 |\n",
      "val: {'recall': 0.970162, 'recall_grapheme': 0.952225, 'recall_vowel': 0.983871, 'recall_consonant': 0.992327, 'acc_grapheme': 0.952798, 'acc_vowel': 0.986756, 'acc_consonant': 0.987552, 'loss_grapheme': 0.212951, 'loss_vowel': 0.10485, 'loss_consonant': 0.084001}\n",
      "   45 | 0.000004 | 081920/180756 | 4.2908 | 2.1722 |\n",
      "val: {'recall': 0.970253, 'recall_grapheme': 0.952455, 'recall_vowel': 0.983771, 'recall_consonant': 0.992331, 'acc_grapheme': 0.953147, 'acc_vowel': 0.986756, 'acc_consonant': 0.987702, 'loss_grapheme': 0.204958, 'loss_vowel': 0.096923, 'loss_consonant': 0.078293}\n",
      "** saved\n",
      "   46 | 0.000006 | 106496/180756 | 0.1988 | 2.2449 |\n",
      "val: {'recall': 0.969973, 'recall_grapheme': 0.952135, 'recall_vowel': 0.983019, 'recall_consonant': 0.992605, 'acc_grapheme': 0.952798, 'acc_vowel': 0.986706, 'acc_consonant': 0.987901, 'loss_grapheme': 0.20849, 'loss_vowel': 0.096879, 'loss_consonant': 0.078079}\n",
      "   47 | 0.000008 | 131072/180756 | 5.8792 | 2.2021 |\n",
      "val: {'recall': 0.969935, 'recall_grapheme': 0.952241, 'recall_vowel': 0.983202, 'recall_consonant': 0.992054, 'acc_grapheme': 0.952748, 'acc_vowel': 0.986805, 'acc_consonant': 0.988, 'loss_grapheme': 0.208041, 'loss_vowel': 0.097825, 'loss_consonant': 0.077562}\n",
      "   48 | 0.000010 | 155648/180756 | 4.6836 | 2.2913 |\n",
      "val: {'recall': 0.969496, 'recall_grapheme': 0.951329, 'recall_vowel': 0.983098, 'recall_consonant': 0.99223, 'acc_grapheme': 0.952848, 'acc_vowel': 0.986706, 'acc_consonant': 0.988249, 'loss_grapheme': 0.203507, 'loss_vowel': 0.096086, 'loss_consonant': 0.077334}\n",
      "   49 | 0.000013 | 180224/180756 | 2.3695 | 2.1963 |\n",
      "val: {'recall': 0.969283, 'recall_grapheme': 0.951718, 'recall_vowel': 0.983447, 'recall_consonant': 0.990248, 'acc_grapheme': 0.953296, 'acc_vowel': 0.987054, 'acc_consonant': 0.988399, 'loss_grapheme': 0.199133, 'loss_vowel': 0.094051, 'loss_consonant': 0.074271}\n",
      "   51 | 0.000015 | 024576/180756 | 5.5038 | 3.0317 |\n",
      "val: {'recall': 0.969668, 'recall_grapheme': 0.951761, 'recall_vowel': 0.983656, 'recall_consonant': 0.991495, 'acc_grapheme': 0.953296, 'acc_vowel': 0.987005, 'acc_consonant': 0.9882, 'loss_grapheme': 0.209096, 'loss_vowel': 0.103223, 'loss_consonant': 0.078853}\n",
      "   52 | 0.000017 | 049152/180756 | 0.1731 | 2.2789 |\n",
      "val: {'recall': 0.970044, 'recall_grapheme': 0.952171, 'recall_vowel': 0.983713, 'recall_consonant': 0.99212, 'acc_grapheme': 0.953794, 'acc_vowel': 0.986805, 'acc_consonant': 0.98815, 'loss_grapheme': 0.199561, 'loss_vowel': 0.092791, 'loss_consonant': 0.07485}\n",
      "   53 | 0.000019 | 073728/180756 | 0.1921 | 2.8405 |\n",
      "val: {'recall': 0.969405, 'recall_grapheme': 0.950996, 'recall_vowel': 0.983515, 'recall_consonant': 0.992112, 'acc_grapheme': 0.952649, 'acc_vowel': 0.986556, 'acc_consonant': 0.987751, 'loss_grapheme': 0.21886, 'loss_vowel': 0.111113, 'loss_consonant': 0.086554}\n",
      "   54 | 0.000020 | 098304/180756 | 0.2038 | 2.0971 |\n",
      "val: {'recall': 0.969899, 'recall_grapheme': 0.951942, 'recall_vowel': 0.983303, 'recall_consonant': 0.992408, 'acc_grapheme': 0.953794, 'acc_vowel': 0.987104, 'acc_consonant': 0.9881, 'loss_grapheme': 0.19509, 'loss_vowel': 0.090501, 'loss_consonant': 0.07206}\n",
      "   55 | 0.000020 | 122880/180756 | 0.1567 | 2.3005 |\n",
      "val: {'recall': 0.969695, 'recall_grapheme': 0.951334, 'recall_vowel': 0.983525, 'recall_consonant': 0.992587, 'acc_grapheme': 0.953495, 'acc_vowel': 0.987552, 'acc_consonant': 0.988349, 'loss_grapheme': 0.203052, 'loss_vowel': 0.098224, 'loss_consonant': 0.076075}\n",
      "   56 | 0.000020 | 147456/180756 | 0.1866 | 2.3328 |\n",
      "val: {'recall': 0.970674, 'recall_grapheme': 0.952764, 'recall_vowel': 0.984773, 'recall_consonant': 0.992393, 'acc_grapheme': 0.953844, 'acc_vowel': 0.987552, 'acc_consonant': 0.987801, 'loss_grapheme': 0.205687, 'loss_vowel': 0.102326, 'loss_consonant': 0.078274}\n",
      "** saved\n",
      "   57 | 0.000019 | 172032/180756 | 0.2177 | 1.9542 |\n",
      "val: {'recall': 0.969893, 'recall_grapheme': 0.95261, 'recall_vowel': 0.983868, 'recall_consonant': 0.990486, 'acc_grapheme': 0.953894, 'acc_vowel': 0.987552, 'acc_consonant': 0.988548, 'loss_grapheme': 0.187936, 'loss_vowel': 0.082714, 'loss_consonant': 0.065298}\n",
      "   59 | 0.000017 | 016384/180756 | 0.1594 | 1.9107 |\n",
      "val: {'recall': 0.970146, 'recall_grapheme': 0.952389, 'recall_vowel': 0.983275, 'recall_consonant': 0.99253, 'acc_grapheme': 0.953645, 'acc_vowel': 0.987154, 'acc_consonant': 0.9882, 'loss_grapheme': 0.202289, 'loss_vowel': 0.100425, 'loss_consonant': 0.076138}\n",
      "   60 | 0.000015 | 040960/180756 | 4.4001 | 2.1351 |\n",
      "val: {'recall': 0.970885, 'recall_grapheme': 0.953948, 'recall_vowel': 0.983481, 'recall_consonant': 0.992165, 'acc_grapheme': 0.95469, 'acc_vowel': 0.987254, 'acc_consonant': 0.988648, 'loss_grapheme': 0.192418, 'loss_vowel': 0.089268, 'loss_consonant': 0.07016}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   61 | 0.000013 | 065536/180756 | 0.1855 | 2.2404 |\n",
      "val: {'recall': 0.970651, 'recall_grapheme': 0.953273, 'recall_vowel': 0.983391, 'recall_consonant': 0.992667, 'acc_grapheme': 0.954342, 'acc_vowel': 0.987254, 'acc_consonant': 0.9881, 'loss_grapheme': 0.1906, 'loss_vowel': 0.092087, 'loss_consonant': 0.073611}\n",
      "   62 | 0.000011 | 090112/180756 | 0.1858 | 2.3109 |\n",
      "val: {'recall': 0.970687, 'recall_grapheme': 0.952635, 'recall_vowel': 0.98425, 'recall_consonant': 0.993229, 'acc_grapheme': 0.954242, 'acc_vowel': 0.987453, 'acc_consonant': 0.988249, 'loss_grapheme': 0.200222, 'loss_vowel': 0.097787, 'loss_consonant': 0.07707}\n",
      "   63 | 0.000008 | 114688/180756 | 0.1439 | 2.3343 |\n",
      "val: {'recall': 0.970776, 'recall_grapheme': 0.953202, 'recall_vowel': 0.984024, 'recall_consonant': 0.992675, 'acc_grapheme': 0.95479, 'acc_vowel': 0.987453, 'acc_consonant': 0.987951, 'loss_grapheme': 0.199982, 'loss_vowel': 0.100248, 'loss_consonant': 0.080494}\n",
      "   64 | 0.000006 | 139264/180756 | 5.0327 | 2.1890 |\n",
      "val: {'recall': 0.970642, 'recall_grapheme': 0.952924, 'recall_vowel': 0.984102, 'recall_consonant': 0.992618, 'acc_grapheme': 0.954641, 'acc_vowel': 0.987552, 'acc_consonant': 0.988, 'loss_grapheme': 0.197779, 'loss_vowel': 0.095989, 'loss_consonant': 0.075328}\n",
      "   65 | 0.000004 | 163840/180756 | 0.1863 | 2.2969 |\n",
      "val: {'recall': 0.97049, 'recall_grapheme': 0.952648, 'recall_vowel': 0.983614, 'recall_consonant': 0.99305, 'acc_grapheme': 0.954541, 'acc_vowel': 0.987403, 'acc_consonant': 0.988449, 'loss_grapheme': 0.198591, 'loss_vowel': 0.09813, 'loss_consonant': 0.077356}\n",
      "   67 | 0.000002 | 008192/180756 | 0.1684 | 1.7791 |\n",
      "val: {'recall': 0.970883, 'recall_grapheme': 0.953385, 'recall_vowel': 0.984006, 'recall_consonant': 0.992755, 'acc_grapheme': 0.955437, 'acc_vowel': 0.987602, 'acc_consonant': 0.988349, 'loss_grapheme': 0.186294, 'loss_vowel': 0.084387, 'loss_consonant': 0.068365}\n",
      "   68 | 0.000001 | 032768/180756 | 4.6987 | 1.8711 |\n",
      "val: {'recall': 0.970924, 'recall_grapheme': 0.953425, 'recall_vowel': 0.984023, 'recall_consonant': 0.992824, 'acc_grapheme': 0.954939, 'acc_vowel': 0.987453, 'acc_consonant': 0.988349, 'loss_grapheme': 0.19223, 'loss_vowel': 0.092067, 'loss_consonant': 0.073227}\n",
      "** saved\n",
      "   69 | 0.000001 | 057344/180756 | 5.6478 | 1.8000 |\n",
      "val: {'recall': 0.970793, 'recall_grapheme': 0.953159, 'recall_vowel': 0.984198, 'recall_consonant': 0.992654, 'acc_grapheme': 0.954989, 'acc_vowel': 0.987552, 'acc_consonant': 0.988349, 'loss_grapheme': 0.189344, 'loss_vowel': 0.087891, 'loss_consonant': 0.069979}\n",
      "   70 | 0.000001 | 081920/180756 | 3.6599 | 2.4118 |\n",
      "val: {'recall': 0.97056, 'recall_grapheme': 0.952704, 'recall_vowel': 0.98404, 'recall_consonant': 0.992792, 'acc_grapheme': 0.954093, 'acc_vowel': 0.987353, 'acc_consonant': 0.988249, 'loss_grapheme': 0.202647, 'loss_vowel': 0.100121, 'loss_consonant': 0.078904}\n",
      "   71 | 0.000002 | 106496/180756 | 0.1519 | 1.9740 |\n",
      "val: {'recall': 0.970821, 'recall_grapheme': 0.953583, 'recall_vowel': 0.983458, 'recall_consonant': 0.992662, 'acc_grapheme': 0.955487, 'acc_vowel': 0.987453, 'acc_consonant': 0.988399, 'loss_grapheme': 0.184054, 'loss_vowel': 0.082978, 'loss_consonant': 0.06762}\n",
      "   72 | 0.000004 | 131072/180756 | 5.3688 | 2.1056 |\n",
      "val: {'recall': 0.971028, 'recall_grapheme': 0.953626, 'recall_vowel': 0.984083, 'recall_consonant': 0.992779, 'acc_grapheme': 0.955188, 'acc_vowel': 0.987552, 'acc_consonant': 0.988399, 'loss_grapheme': 0.189633, 'loss_vowel': 0.088203, 'loss_consonant': 0.07094}\n",
      "** saved\n",
      "   73 | 0.000006 | 155648/180756 | 4.7665 | 1.9057 |\n",
      "val: {'recall': 0.971018, 'recall_grapheme': 0.954019, 'recall_vowel': 0.984115, 'recall_consonant': 0.991917, 'acc_grapheme': 0.955636, 'acc_vowel': 0.987602, 'acc_consonant': 0.98805, 'loss_grapheme': 0.181747, 'loss_vowel': 0.080212, 'loss_consonant': 0.066077}\n",
      "   74 | 0.000008 | 180224/180756 | 3.3132 | 2.2462 |\n",
      "val: {'recall': 0.970981, 'recall_grapheme': 0.953861, 'recall_vowel': 0.983818, 'recall_consonant': 0.992385, 'acc_grapheme': 0.955238, 'acc_vowel': 0.987453, 'acc_consonant': 0.988249, 'loss_grapheme': 0.190296, 'loss_vowel': 0.089102, 'loss_consonant': 0.072505}\n",
      "   76 | 0.000011 | 024576/180756 | 0.1551 | 2.5063 |\n",
      "val: {'recall': 0.97088, 'recall_grapheme': 0.953144, 'recall_vowel': 0.984686, 'recall_consonant': 0.992544, 'acc_grapheme': 0.954939, 'acc_vowel': 0.987652, 'acc_consonant': 0.988, 'loss_grapheme': 0.196927, 'loss_vowel': 0.094322, 'loss_consonant': 0.074682}\n",
      "   77 | 0.000013 | 049152/180756 | 4.1123 | 2.1334 |\n",
      "val: {'recall': 0.970901, 'recall_grapheme': 0.953157, 'recall_vowel': 0.984331, 'recall_consonant': 0.992959, 'acc_grapheme': 0.954989, 'acc_vowel': 0.987453, 'acc_consonant': 0.9882, 'loss_grapheme': 0.194425, 'loss_vowel': 0.097834, 'loss_consonant': 0.075895}\n",
      "   78 | 0.000015 | 073728/180756 | 4.8268 | 2.5075 |\n",
      "val: {'recall': 0.970651, 'recall_grapheme': 0.953008, 'recall_vowel': 0.983793, 'recall_consonant': 0.992795, 'acc_grapheme': 0.954541, 'acc_vowel': 0.987353, 'acc_consonant': 0.988249, 'loss_grapheme': 0.212237, 'loss_vowel': 0.112142, 'loss_consonant': 0.088018}\n",
      "   79 | 0.000017 | 098304/180756 | 0.1735 | 2.1280 |\n",
      "val: {'recall': 0.970645, 'recall_grapheme': 0.952784, 'recall_vowel': 0.984123, 'recall_consonant': 0.992891, 'acc_grapheme': 0.955188, 'acc_vowel': 0.987652, 'acc_consonant': 0.988399, 'loss_grapheme': 0.195014, 'loss_vowel': 0.092762, 'loss_consonant': 0.073102}\n",
      "   80 | 0.000019 | 122880/180756 | 5.4934 | 1.9754 |\n",
      "val: {'recall': 0.969352, 'recall_grapheme': 0.952989, 'recall_vowel': 0.983492, 'recall_consonant': 0.987939, 'acc_grapheme': 0.954939, 'acc_vowel': 0.987254, 'acc_consonant': 0.98815, 'loss_grapheme': 0.18134, 'loss_vowel': 0.08264, 'loss_consonant': 0.067478}\n",
      "   81 | 0.000020 | 147456/180756 | 4.4625 | 1.9422 |\n",
      "val: {'recall': 0.970878, 'recall_grapheme': 0.953407, 'recall_vowel': 0.984334, 'recall_consonant': 0.992362, 'acc_grapheme': 0.955437, 'acc_vowel': 0.987552, 'acc_consonant': 0.988797, 'loss_grapheme': 0.185446, 'loss_vowel': 0.084964, 'loss_consonant': 0.070719}\n",
      "   82 | 0.000020 | 172032/180756 | 4.0884 | 2.2332 |\n",
      "val: {'recall': 0.971537, 'recall_grapheme': 0.954248, 'recall_vowel': 0.98502, 'recall_consonant': 0.992632, 'acc_grapheme': 0.955238, 'acc_vowel': 0.987652, 'acc_consonant': 0.988498, 'loss_grapheme': 0.19241, 'loss_vowel': 0.096953, 'loss_consonant': 0.074058}\n",
      "** saved\n",
      "   84 | 0.000020 | 016384/180756 | 4.3867 | 2.2499 |\n",
      "val: {'recall': 0.971543, 'recall_grapheme': 0.954314, 'recall_vowel': 0.984341, 'recall_consonant': 0.993205, 'acc_grapheme': 0.956284, 'acc_vowel': 0.98815, 'acc_consonant': 0.988996, 'loss_grapheme': 0.187093, 'loss_vowel': 0.090636, 'loss_consonant': 0.072008}\n",
      "** saved\n",
      "   85 | 0.000019 | 040960/180756 | 0.1281 | 2.1374 |\n",
      "val: {'recall': 0.97101, 'recall_grapheme': 0.953373, 'recall_vowel': 0.983922, 'recall_consonant': 0.993373, 'acc_grapheme': 0.956383, 'acc_vowel': 0.987502, 'acc_consonant': 0.988648, 'loss_grapheme': 0.186101, 'loss_vowel': 0.090154, 'loss_consonant': 0.073691}\n",
      "   86 | 0.000017 | 065536/180756 | 0.1694 | 1.8183 |\n",
      "val: {'recall': 0.9709, 'recall_grapheme': 0.953345, 'recall_vowel': 0.984087, 'recall_consonant': 0.992824, 'acc_grapheme': 0.955935, 'acc_vowel': 0.987901, 'acc_consonant': 0.988648, 'loss_grapheme': 0.18326, 'loss_vowel': 0.085814, 'loss_consonant': 0.068019}\n",
      "   87 | 0.000015 | 090112/180756 | 0.1713 | 2.4594 |\n",
      "val: {'recall': 0.970988, 'recall_grapheme': 0.953328, 'recall_vowel': 0.984064, 'recall_consonant': 0.993232, 'acc_grapheme': 0.954989, 'acc_vowel': 0.987652, 'acc_consonant': 0.988399, 'loss_grapheme': 0.198366, 'loss_vowel': 0.098718, 'loss_consonant': 0.07807}\n",
      "   88 | 0.000013 | 114688/180756 | 4.8553 | 2.1888 |\n",
      "val: {'recall': 0.971875, 'recall_grapheme': 0.954785, 'recall_vowel': 0.985109, 'recall_consonant': 0.992821, 'acc_grapheme': 0.956881, 'acc_vowel': 0.988349, 'acc_consonant': 0.989096, 'loss_grapheme': 0.183127, 'loss_vowel': 0.08823, 'loss_consonant': 0.067262}\n",
      "** saved\n",
      "   89 | 0.000011 | 139264/180756 | 0.1420 | 2.2839 |\n",
      "val: {'recall': 0.971046, 'recall_grapheme': 0.953547, 'recall_vowel': 0.984241, 'recall_consonant': 0.992848, 'acc_grapheme': 0.956333, 'acc_vowel': 0.987702, 'acc_consonant': 0.988399, 'loss_grapheme': 0.192232, 'loss_vowel': 0.091585, 'loss_consonant': 0.071782}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   90 | 0.000008 | 163840/180756 | 4.8655 | 2.0834 |\n",
      "val: {'recall': 0.971744, 'recall_grapheme': 0.95498, 'recall_vowel': 0.984696, 'recall_consonant': 0.99232, 'acc_grapheme': 0.956881, 'acc_vowel': 0.987702, 'acc_consonant': 0.988299, 'loss_grapheme': 0.192793, 'loss_vowel': 0.094162, 'loss_consonant': 0.074712}\n",
      "   92 | 0.000006 | 008192/180756 | 4.5999 | 3.7436 |\n",
      "val: {'recall': 0.971564, 'recall_grapheme': 0.954644, 'recall_vowel': 0.98416, 'recall_consonant': 0.992808, 'acc_grapheme': 0.956931, 'acc_vowel': 0.987851, 'acc_consonant': 0.988299, 'loss_grapheme': 0.187393, 'loss_vowel': 0.090875, 'loss_consonant': 0.071252}\n",
      "   93 | 0.000004 | 032768/180756 | 0.1494 | 1.7893 |\n",
      "val: {'recall': 0.971466, 'recall_grapheme': 0.954414, 'recall_vowel': 0.984317, 'recall_consonant': 0.992721, 'acc_grapheme': 0.956682, 'acc_vowel': 0.987951, 'acc_consonant': 0.988399, 'loss_grapheme': 0.183207, 'loss_vowel': 0.088073, 'loss_consonant': 0.068737}\n",
      "   94 | 0.000002 | 057344/180756 | 5.1835 | 2.3849 |\n",
      "val: {'recall': 0.971669, 'recall_grapheme': 0.954891, 'recall_vowel': 0.984009, 'recall_consonant': 0.992883, 'acc_grapheme': 0.956881, 'acc_vowel': 0.987901, 'acc_consonant': 0.988498, 'loss_grapheme': 0.196007, 'loss_vowel': 0.097979, 'loss_consonant': 0.07644}\n",
      "   95 | 0.000001 | 081920/180756 | 0.1294 | 2.2417 |\n",
      "val: {'recall': 0.971966, 'recall_grapheme': 0.955374, 'recall_vowel': 0.984158, 'recall_consonant': 0.992957, 'acc_grapheme': 0.957479, 'acc_vowel': 0.98815, 'acc_consonant': 0.988498, 'loss_grapheme': 0.184052, 'loss_vowel': 0.085858, 'loss_consonant': 0.068459}\n",
      "** saved\n",
      "   96 | 0.000001 | 106496/180756 | 0.1150 | 1.7174 |\n",
      "val: {'recall': 0.971996, 'recall_grapheme': 0.955227, 'recall_vowel': 0.984688, 'recall_consonant': 0.992841, 'acc_grapheme': 0.957479, 'acc_vowel': 0.9882, 'acc_consonant': 0.988897, 'loss_grapheme': 0.174693, 'loss_vowel': 0.077856, 'loss_consonant': 0.062397}\n",
      "** saved\n",
      "   97 | 0.000001 | 131072/180756 | 0.1333 | 2.0741 |\n",
      "val: {'recall': 0.97246, 'recall_grapheme': 0.956123, 'recall_vowel': 0.984552, 'recall_consonant': 0.993041, 'acc_grapheme': 0.957777, 'acc_vowel': 0.9882, 'acc_consonant': 0.988598, 'loss_grapheme': 0.182668, 'loss_vowel': 0.086308, 'loss_consonant': 0.068335}\n",
      "** saved\n",
      "   98 | 0.000002 | 155648/180756 | 4.6395 | 2.1629 |\n",
      "val: {'recall': 0.97198, 'recall_grapheme': 0.955381, 'recall_vowel': 0.984221, 'recall_consonant': 0.992935, 'acc_grapheme': 0.957329, 'acc_vowel': 0.988, 'acc_consonant': 0.988847, 'loss_grapheme': 0.183837, 'loss_vowel': 0.086916, 'loss_consonant': 0.068622}\n",
      "   99 | 0.000004 | 180224/180756 | 1.1530 | 2.2109 |\n",
      "val: {'recall': 0.972011, 'recall_grapheme': 0.955015, 'recall_vowel': 0.984675, 'recall_consonant': 0.993337, 'acc_grapheme': 0.95723, 'acc_vowel': 0.988, 'acc_consonant': 0.988996, 'loss_grapheme': 0.185992, 'loss_vowel': 0.090161, 'loss_consonant': 0.071465}\n",
      "  101 | 0.000006 | 024576/180756 | 0.1322 | 1.6959 |\n",
      "val: {'recall': 0.972331, 'recall_grapheme': 0.95581, 'recall_vowel': 0.984717, 'recall_consonant': 0.992988, 'acc_grapheme': 0.957528, 'acc_vowel': 0.988299, 'acc_consonant': 0.989146, 'loss_grapheme': 0.174456, 'loss_vowel': 0.079324, 'loss_consonant': 0.062487}\n",
      "  102 | 0.000008 | 049152/180756 | 3.9952 | 2.2269 |\n",
      "val: {'recall': 0.971828, 'recall_grapheme': 0.955205, 'recall_vowel': 0.984072, 'recall_consonant': 0.992832, 'acc_grapheme': 0.95718, 'acc_vowel': 0.9881, 'acc_consonant': 0.988498, 'loss_grapheme': 0.178747, 'loss_vowel': 0.083008, 'loss_consonant': 0.06652}\n",
      "  103 | 0.000011 | 073728/180756 | 0.1088 | 2.3748 |\n",
      "val: {'recall': 0.97218, 'recall_grapheme': 0.955334, 'recall_vowel': 0.984598, 'recall_consonant': 0.993454, 'acc_grapheme': 0.957279, 'acc_vowel': 0.987951, 'acc_consonant': 0.988897, 'loss_grapheme': 0.19487, 'loss_vowel': 0.100181, 'loss_consonant': 0.077318}\n",
      "  104 | 0.000013 | 098304/180756 | 0.1442 | 2.1993 |\n",
      "val: {'recall': 0.971694, 'recall_grapheme': 0.954767, 'recall_vowel': 0.983618, 'recall_consonant': 0.993622, 'acc_grapheme': 0.95703, 'acc_vowel': 0.987801, 'acc_consonant': 0.988449, 'loss_grapheme': 0.182847, 'loss_vowel': 0.087715, 'loss_consonant': 0.071695}\n",
      "  105 | 0.000015 | 122880/180756 | 0.1497 | 2.3663 |\n",
      "val: {'recall': 0.971705, 'recall_grapheme': 0.954576, 'recall_vowel': 0.984503, 'recall_consonant': 0.993164, 'acc_grapheme': 0.956782, 'acc_vowel': 0.987901, 'acc_consonant': 0.9882, 'loss_grapheme': 0.197654, 'loss_vowel': 0.095354, 'loss_consonant': 0.077417}\n",
      "  106 | 0.000017 | 147456/180756 | 5.3503 | 2.2684 |\n",
      "val: {'recall': 0.971379, 'recall_grapheme': 0.953457, 'recall_vowel': 0.985238, 'recall_consonant': 0.993365, 'acc_grapheme': 0.956333, 'acc_vowel': 0.988648, 'acc_consonant': 0.988498, 'loss_grapheme': 0.185796, 'loss_vowel': 0.091883, 'loss_consonant': 0.073153}\n",
      "  107 | 0.000019 | 172032/180756 | 5.4357 | 2.3045 |\n",
      "val: {'recall': 0.971804, 'recall_grapheme': 0.954922, 'recall_vowel': 0.984281, 'recall_consonant': 0.99309, 'acc_grapheme': 0.95713, 'acc_vowel': 0.987901, 'acc_consonant': 0.988449, 'loss_grapheme': 0.193602, 'loss_vowel': 0.096426, 'loss_consonant': 0.077365}\n",
      "  109 | 0.000020 | 016384/180756 | 0.1295 | 2.2584 |\n",
      "val: {'recall': 0.972248, 'recall_grapheme': 0.955444, 'recall_vowel': 0.985271, 'recall_consonant': 0.992832, 'acc_grapheme': 0.957628, 'acc_vowel': 0.988747, 'acc_consonant': 0.989295, 'loss_grapheme': 0.17367, 'loss_vowel': 0.079395, 'loss_consonant': 0.061664}\n",
      "  110 | 0.000020 | 040960/180756 | 5.4013 | 2.2401 |\n",
      "val: {'recall': 0.972504, 'recall_grapheme': 0.955955, 'recall_vowel': 0.985355, 'recall_consonant': 0.992752, 'acc_grapheme': 0.958275, 'acc_vowel': 0.98805, 'acc_consonant': 0.988797, 'loss_grapheme': 0.187352, 'loss_vowel': 0.089108, 'loss_consonant': 0.070286}\n",
      "** saved\n",
      "  111 | 0.000020 | 065536/180756 | 0.1322 | 2.2001 |\n",
      "val: {'recall': 0.970972, 'recall_grapheme': 0.954607, 'recall_vowel': 0.984407, 'recall_consonant': 0.990265, 'acc_grapheme': 0.957528, 'acc_vowel': 0.98815, 'acc_consonant': 0.988797, 'loss_grapheme': 0.177731, 'loss_vowel': 0.083929, 'loss_consonant': 0.068438}\n",
      "  112 | 0.000019 | 090112/180756 | 0.1340 | 2.4228 |\n",
      "val: {'recall': 0.972956, 'recall_grapheme': 0.956407, 'recall_vowel': 0.985655, 'recall_consonant': 0.993357, 'acc_grapheme': 0.958524, 'acc_vowel': 0.988797, 'acc_consonant': 0.988548, 'loss_grapheme': 0.188483, 'loss_vowel': 0.096024, 'loss_consonant': 0.074296}\n",
      "** saved\n",
      "  113 | 0.000017 | 114688/180756 | 0.1666 | 1.6644 |\n",
      "val: {'recall': 0.972733, 'recall_grapheme': 0.956586, 'recall_vowel': 0.98516, 'recall_consonant': 0.9926, 'acc_grapheme': 0.959221, 'acc_vowel': 0.988697, 'acc_consonant': 0.989245, 'loss_grapheme': 0.169431, 'loss_vowel': 0.074409, 'loss_consonant': 0.059947}\n",
      "  114 | 0.000015 | 139264/180756 | 0.1040 | 1.9193 |\n",
      "val: {'recall': 0.972792, 'recall_grapheme': 0.956204, 'recall_vowel': 0.985426, 'recall_consonant': 0.993334, 'acc_grapheme': 0.958524, 'acc_vowel': 0.988897, 'acc_consonant': 0.989594, 'loss_grapheme': 0.170982, 'loss_vowel': 0.075878, 'loss_consonant': 0.062672}\n",
      "  115 | 0.000013 | 163840/180756 | 0.1591 | 2.0887 |\n",
      "val: {'recall': 0.971661, 'recall_grapheme': 0.95531, 'recall_vowel': 0.984754, 'recall_consonant': 0.991269, 'acc_grapheme': 0.957877, 'acc_vowel': 0.988449, 'acc_consonant': 0.989146, 'loss_grapheme': 0.177353, 'loss_vowel': 0.080857, 'loss_consonant': 0.065052}\n",
      "  117 | 0.000011 | 008192/180756 | 0.1056 | 1.9020 |\n",
      "val: {'recall': 0.97216, 'recall_grapheme': 0.95621, 'recall_vowel': 0.985333, 'recall_consonant': 0.990887, 'acc_grapheme': 0.958823, 'acc_vowel': 0.988797, 'acc_consonant': 0.990092, 'loss_grapheme': 0.163055, 'loss_vowel': 0.069825, 'loss_consonant': 0.055525}\n",
      "  118 | 0.000008 | 032768/180756 | 0.1372 | 1.5309 |\n",
      "val: {'recall': 0.972198, 'recall_grapheme': 0.956819, 'recall_vowel': 0.984693, 'recall_consonant': 0.99046, 'acc_grapheme': 0.958873, 'acc_vowel': 0.988697, 'acc_consonant': 0.989195, 'loss_grapheme': 0.169197, 'loss_vowel': 0.074599, 'loss_consonant': 0.060462}\n",
      "  119 | 0.000006 | 057344/180756 | 5.3377 | 2.8886 |\n",
      "val: {'recall': 0.971954, 'recall_grapheme': 0.955943, 'recall_vowel': 0.984824, 'recall_consonant': 0.991105, 'acc_grapheme': 0.958474, 'acc_vowel': 0.988299, 'acc_consonant': 0.988847, 'loss_grapheme': 0.201669, 'loss_vowel': 0.105412, 'loss_consonant': 0.082283}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  120 | 0.000004 | 081920/180756 | 3.3982 | 1.8886 |\n",
      "val: {'recall': 0.972507, 'recall_grapheme': 0.95696, 'recall_vowel': 0.98508, 'recall_consonant': 0.991025, 'acc_grapheme': 0.959221, 'acc_vowel': 0.988697, 'acc_consonant': 0.989444, 'loss_grapheme': 0.179282, 'loss_vowel': 0.086574, 'loss_consonant': 0.067219}\n",
      "  121 | 0.000002 | 106496/180756 | 0.1157 | 1.8320 |\n",
      "val: {'recall': 0.972416, 'recall_grapheme': 0.956902, 'recall_vowel': 0.985036, 'recall_consonant': 0.990824, 'acc_grapheme': 0.959221, 'acc_vowel': 0.988847, 'acc_consonant': 0.989295, 'loss_grapheme': 0.166118, 'loss_vowel': 0.073162, 'loss_consonant': 0.059085}\n",
      "  122 | 0.000001 | 131072/180756 | 0.1019 | 2.1207 |\n",
      "val: {'recall': 0.972484, 'recall_grapheme': 0.956981, 'recall_vowel': 0.984997, 'recall_consonant': 0.990977, 'acc_grapheme': 0.959271, 'acc_vowel': 0.988598, 'acc_consonant': 0.989444, 'loss_grapheme': 0.171854, 'loss_vowel': 0.079668, 'loss_consonant': 0.063482}\n",
      "  123 | 0.000001 | 155648/180756 | 0.4524 | 1.9286 |\n",
      "val: {'recall': 0.972386, 'recall_grapheme': 0.956716, 'recall_vowel': 0.985033, 'recall_consonant': 0.99108, 'acc_grapheme': 0.959122, 'acc_vowel': 0.988847, 'acc_consonant': 0.989643, 'loss_grapheme': 0.166599, 'loss_vowel': 0.073616, 'loss_consonant': 0.059188}\n",
      "  124 | 0.000001 | 180224/180756 | 0.1447 | 1.7697 |\n",
      "val: {'recall': 0.972343, 'recall_grapheme': 0.956967, 'recall_vowel': 0.984835, 'recall_consonant': 0.990603, 'acc_grapheme': 0.959371, 'acc_vowel': 0.988797, 'acc_consonant': 0.989345, 'loss_grapheme': 0.162295, 'loss_vowel': 0.069369, 'loss_consonant': 0.055751}\n",
      "  126 | 0.000002 | 024576/180756 | 0.1099 | 2.6038 |\n",
      "val: {'recall': 0.972242, 'recall_grapheme': 0.956543, 'recall_vowel': 0.984962, 'recall_consonant': 0.990918, 'acc_grapheme': 0.958574, 'acc_vowel': 0.988498, 'acc_consonant': 0.988996, 'loss_grapheme': 0.188782, 'loss_vowel': 0.094342, 'loss_consonant': 0.073575}\n",
      "  127 | 0.000004 | 049152/180756 | 3.5748 | 2.2091 |\n",
      "val: {'recall': 0.972268, 'recall_grapheme': 0.956383, 'recall_vowel': 0.985137, 'recall_consonant': 0.991169, 'acc_grapheme': 0.958873, 'acc_vowel': 0.988747, 'acc_consonant': 0.989544, 'loss_grapheme': 0.18077, 'loss_vowel': 0.087141, 'loss_consonant': 0.068918}\n",
      "  128 | 0.000006 | 073728/180756 | 0.1108 | 1.8309 |\n",
      "val: {'recall': 0.972825, 'recall_grapheme': 0.956553, 'recall_vowel': 0.984975, 'recall_consonant': 0.993221, 'acc_grapheme': 0.959171, 'acc_vowel': 0.988747, 'acc_consonant': 0.989544, 'loss_grapheme': 0.166744, 'loss_vowel': 0.07233, 'loss_consonant': 0.058942}\n",
      "  129 | 0.000008 | 098304/180756 | 0.1122 | 2.0717 |\n",
      "val: {'recall': 0.972244, 'recall_grapheme': 0.956454, 'recall_vowel': 0.985102, 'recall_consonant': 0.990965, 'acc_grapheme': 0.959122, 'acc_vowel': 0.988797, 'acc_consonant': 0.989245, 'loss_grapheme': 0.174848, 'loss_vowel': 0.083432, 'loss_consonant': 0.066121}\n",
      "  130 | 0.000010 | 122880/180756 | 4.6028 | 2.2645 |\n",
      "val: {'recall': 0.972639, 'recall_grapheme': 0.957572, 'recall_vowel': 0.984637, 'recall_consonant': 0.990773, 'acc_grapheme': 0.959371, 'acc_vowel': 0.988449, 'acc_consonant': 0.989295, 'loss_grapheme': 0.185186, 'loss_vowel': 0.092097, 'loss_consonant': 0.071407}\n",
      "  131 | 0.000013 | 147456/180756 | 4.8245 | 1.9840 |\n",
      "val: {'recall': 0.972081, 'recall_grapheme': 0.956095, 'recall_vowel': 0.985063, 'recall_consonant': 0.99107, 'acc_grapheme': 0.958474, 'acc_vowel': 0.988548, 'acc_consonant': 0.989345, 'loss_grapheme': 0.17533, 'loss_vowel': 0.082279, 'loss_consonant': 0.064904}\n",
      "  132 | 0.000015 | 172032/180756 | 1.4025 | 1.7522 |\n",
      "val: {'recall': 0.972552, 'recall_grapheme': 0.957198, 'recall_vowel': 0.985114, 'recall_consonant': 0.990697, 'acc_grapheme': 0.959072, 'acc_vowel': 0.988747, 'acc_consonant': 0.989693, 'loss_grapheme': 0.165761, 'loss_vowel': 0.071023, 'loss_consonant': 0.058949}\n",
      "  134 | 0.000017 | 016384/180756 | 0.1243 | 1.9885 |\n",
      "val: {'recall': 0.972279, 'recall_grapheme': 0.957301, 'recall_vowel': 0.983656, 'recall_consonant': 0.990861, 'acc_grapheme': 0.959122, 'acc_vowel': 0.98815, 'acc_consonant': 0.989544, 'loss_grapheme': 0.179677, 'loss_vowel': 0.086422, 'loss_consonant': 0.068684}\n",
      "  135 | 0.000019 | 040960/180756 | 0.1816 | 2.2489 |\n",
      "val: {'recall': 0.972743, 'recall_grapheme': 0.956313, 'recall_vowel': 0.985275, 'recall_consonant': 0.993072, 'acc_grapheme': 0.957728, 'acc_vowel': 0.988249, 'acc_consonant': 0.989146, 'loss_grapheme': 0.181823, 'loss_vowel': 0.087593, 'loss_consonant': 0.069668}\n",
      "  136 | 0.000020 | 065536/180756 | 4.3279 | 1.5697 |\n",
      "val: {'recall': 0.973654, 'recall_grapheme': 0.958408, 'recall_vowel': 0.984498, 'recall_consonant': 0.993304, 'acc_grapheme': 0.95962, 'acc_vowel': 0.988697, 'acc_consonant': 0.989594, 'loss_grapheme': 0.16013, 'loss_vowel': 0.069918, 'loss_consonant': 0.055005}\n",
      "** saved\n",
      "  137 | 0.000020 | 090112/180756 | 0.1144 | 1.8339 |\n",
      "val: {'recall': 0.973663, 'recall_grapheme': 0.958316, 'recall_vowel': 0.984419, 'recall_consonant': 0.9936, 'acc_grapheme': 0.959968, 'acc_vowel': 0.988697, 'acc_consonant': 0.989992, 'loss_grapheme': 0.164246, 'loss_vowel': 0.072643, 'loss_consonant': 0.058957}\n",
      "** saved\n",
      "  138 | 0.000020 | 114688/180756 | 3.6273 | 1.8934 |\n",
      "val: {'recall': 0.973152, 'recall_grapheme': 0.958624, 'recall_vowel': 0.984582, 'recall_consonant': 0.990777, 'acc_grapheme': 0.959918, 'acc_vowel': 0.988847, 'acc_consonant': 0.989395, 'loss_grapheme': 0.163872, 'loss_vowel': 0.073554, 'loss_consonant': 0.058543}\n",
      "  139 | 0.000019 | 139264/180756 | 0.1235 | 2.0211 |\n",
      "val: {'recall': 0.973489, 'recall_grapheme': 0.958597, 'recall_vowel': 0.985913, 'recall_consonant': 0.990851, 'acc_grapheme': 0.960068, 'acc_vowel': 0.989345, 'acc_consonant': 0.989195, 'loss_grapheme': 0.169255, 'loss_vowel': 0.079755, 'loss_consonant': 0.06514}\n",
      "  140 | 0.000017 | 163840/180756 | 0.1020 | 1.9941 |\n",
      "val: {'recall': 0.972703, 'recall_grapheme': 0.957732, 'recall_vowel': 0.98484, 'recall_consonant': 0.990508, 'acc_grapheme': 0.959769, 'acc_vowel': 0.989146, 'acc_consonant': 0.989444, 'loss_grapheme': 0.169636, 'loss_vowel': 0.076631, 'loss_consonant': 0.059583}\n",
      "  142 | 0.000015 | 008192/180756 | 0.1027 | 1.0693 |\n",
      "val: {'recall': 0.973971, 'recall_grapheme': 0.958648, 'recall_vowel': 0.98511, 'recall_consonant': 0.993476, 'acc_grapheme': 0.960267, 'acc_vowel': 0.988996, 'acc_consonant': 0.990241, 'loss_grapheme': 0.168007, 'loss_vowel': 0.076206, 'loss_consonant': 0.061946}\n",
      "** saved\n",
      "  143 | 0.000013 | 032768/180756 | 0.0950 | 1.1344 |\n",
      "val: {'recall': 0.974514, 'recall_grapheme': 0.959942, 'recall_vowel': 0.984651, 'recall_consonant': 0.993519, 'acc_grapheme': 0.960815, 'acc_vowel': 0.988797, 'acc_consonant': 0.989942, 'loss_grapheme': 0.1576, 'loss_vowel': 0.066543, 'loss_consonant': 0.054047}\n",
      "** saved\n",
      "  144 | 0.000010 | 057344/180756 | 0.1263 | 1.9215 |\n",
      "val: {'recall': 0.973857, 'recall_grapheme': 0.95846, 'recall_vowel': 0.985574, 'recall_consonant': 0.992935, 'acc_grapheme': 0.95957, 'acc_vowel': 0.989096, 'acc_consonant': 0.989494, 'loss_grapheme': 0.167867, 'loss_vowel': 0.076628, 'loss_consonant': 0.061471}\n",
      "  144 | 0.000008 | 136192/180756 | 3.9106 | 2.0790 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-54080d9d42c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-28f20a7d4cf4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/_initialize.py\u001b[0m in \u001b[0;36mnew_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mnew_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mdisable_casts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnew_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)  # efficientnet-b3 , cv9738 batch_size 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a7ab210f85a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./models/se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'densenet201'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 768\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(180756, 5) (20084, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/densenet201/best_model.pth, exist: True\n",
      "loading ./models/densenet201/best_model.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.979639, 'recall_grapheme': 0.968705, 'recall_vowel': 0.987912, 'recall_consonant': 0.993236, 'acc_grapheme': 0.966391, 'acc_vowel': 0.990191, 'acc_consonant': 0.989793, 'loss_grapheme': 0.266216, 'loss_vowel': 0.15312, 'loss_consonant': 0.12891}\n",
      "    0 | 0.000020 | 153600/180756 | 4.5478 | 2.9927 |\n",
      "val: {'recall': 0.97718, 'recall_grapheme': 0.965373, 'recall_vowel': 0.98753, 'recall_consonant': 0.990444, 'acc_grapheme': 0.964151, 'acc_vowel': 0.990141, 'acc_consonant': 0.988847, 'loss_grapheme': 0.406527, 'loss_vowel': 0.25841, 'loss_consonant': 0.183216}\n",
      "    1 | 0.000020 | 126720/180756 | 3.9056 | 3.0462 |\n",
      "val: {'recall': 0.977188, 'recall_grapheme': 0.96641, 'recall_vowel': 0.987693, 'recall_consonant': 0.988237, 'acc_grapheme': 0.964897, 'acc_vowel': 0.989594, 'acc_consonant': 0.989444, 'loss_grapheme': 0.410402, 'loss_vowel': 0.255828, 'loss_consonant': 0.185089}\n",
      "    2 | 0.000019 | 099840/180756 | 0.0443 | 2.7690 |\n",
      "val: {'recall': 0.977882, 'recall_grapheme': 0.967617, 'recall_vowel': 0.987844, 'recall_consonant': 0.98845, 'acc_grapheme': 0.964947, 'acc_vowel': 0.989594, 'acc_consonant': 0.988648, 'loss_grapheme': 0.332014, 'loss_vowel': 0.195669, 'loss_consonant': 0.164403}\n",
      "    3 | 0.000017 | 072960/180756 | 3.5724 | 2.8983 |\n",
      "val: {'recall': 0.978038, 'recall_grapheme': 0.967264, 'recall_vowel': 0.987062, 'recall_consonant': 0.990563, 'acc_grapheme': 0.965545, 'acc_vowel': 0.989843, 'acc_consonant': 0.987453, 'loss_grapheme': 0.301375, 'loss_vowel': 0.187247, 'loss_consonant': 0.165022}\n",
      "    4 | 0.000015 | 046080/180756 | 2.1664 | 3.0447 |\n",
      "val: {'recall': 0.977701, 'recall_grapheme': 0.966704, 'recall_vowel': 0.987541, 'recall_consonant': 0.989854, 'acc_grapheme': 0.965744, 'acc_vowel': 0.989643, 'acc_consonant': 0.988449, 'loss_grapheme': 0.378091, 'loss_vowel': 0.229089, 'loss_consonant': 0.168062}\n",
      "    5 | 0.000013 | 019200/180756 | 4.0153 | 3.8638 |\n",
      "val: {'recall': 0.977985, 'recall_grapheme': 0.966886, 'recall_vowel': 0.987811, 'recall_consonant': 0.99036, 'acc_grapheme': 0.965296, 'acc_vowel': 0.989395, 'acc_consonant': 0.989494, 'loss_grapheme': 0.45623, 'loss_vowel': 0.274772, 'loss_consonant': 0.190839}\n",
      "    5 | 0.000011 | 172800/180756 | 5.1591 | 3.1932 |\n",
      "val: {'recall': 0.978355, 'recall_grapheme': 0.967779, 'recall_vowel': 0.987394, 'recall_consonant': 0.990467, 'acc_grapheme': 0.966192, 'acc_vowel': 0.989544, 'acc_consonant': 0.9881, 'loss_grapheme': 0.404729, 'loss_vowel': 0.247033, 'loss_consonant': 0.1876}\n",
      "    6 | 0.000008 | 145920/180756 | 4.0838 | 3.0398 |\n",
      "val: {'recall': 0.978648, 'recall_grapheme': 0.968277, 'recall_vowel': 0.987469, 'recall_consonant': 0.99057, 'acc_grapheme': 0.96664, 'acc_vowel': 0.989843, 'acc_consonant': 0.989096, 'loss_grapheme': 0.304581, 'loss_vowel': 0.17918, 'loss_consonant': 0.142916}\n",
      "    7 | 0.000006 | 119040/180756 | 0.4206 | 2.9215 |\n",
      "val: {'recall': 0.97818, 'recall_grapheme': 0.967596, 'recall_vowel': 0.98759, 'recall_consonant': 0.989937, 'acc_grapheme': 0.966292, 'acc_vowel': 0.989843, 'acc_consonant': 0.989544, 'loss_grapheme': 0.296623, 'loss_vowel': 0.172809, 'loss_consonant': 0.130704}\n",
      "    8 | 0.000004 | 092160/180756 | 0.0279 | 3.0913 |\n",
      "val: {'recall': 0.978469, 'recall_grapheme': 0.967926, 'recall_vowel': 0.987709, 'recall_consonant': 0.990316, 'acc_grapheme': 0.966341, 'acc_vowel': 0.990141, 'acc_consonant': 0.988697, 'loss_grapheme': 0.341871, 'loss_vowel': 0.207939, 'loss_consonant': 0.16778}\n",
      "    9 | 0.000002 | 065280/180756 | 3.2244 | 3.1484 |\n",
      "val: {'recall': 0.978408, 'recall_grapheme': 0.967935, 'recall_vowel': 0.987283, 'recall_consonant': 0.990479, 'acc_grapheme': 0.966142, 'acc_vowel': 0.989693, 'acc_consonant': 0.988399, 'loss_grapheme': 0.368504, 'loss_vowel': 0.227733, 'loss_consonant': 0.175067}\n",
      "   10 | 0.000001 | 038400/180756 | 0.0330 | 3.1604 |\n",
      "val: {'recall': 0.979035, 'recall_grapheme': 0.969081, 'recall_vowel': 0.987357, 'recall_consonant': 0.990621, 'acc_grapheme': 0.965943, 'acc_vowel': 0.989992, 'acc_consonant': 0.989146, 'loss_grapheme': 0.372916, 'loss_vowel': 0.2227, 'loss_consonant': 0.166831}\n",
      "   11 | 0.000001 | 011520/180756 | 1.9862 | 2.8273 |\n",
      "val: {'recall': 0.978187, 'recall_grapheme': 0.967556, 'recall_vowel': 0.987321, 'recall_consonant': 0.990317, 'acc_grapheme': 0.966242, 'acc_vowel': 0.989743, 'acc_consonant': 0.990341, 'loss_grapheme': 0.290722, 'loss_vowel': 0.171698, 'loss_consonant': 0.12755}\n",
      "   11 | 0.000001 | 165120/180756 | 2.0309 | 2.9615 |\n",
      "val: {'recall': 0.978868, 'recall_grapheme': 0.968754, 'recall_vowel': 0.987524, 'recall_consonant': 0.990441, 'acc_grapheme': 0.965943, 'acc_vowel': 0.989693, 'acc_consonant': 0.990191, 'loss_grapheme': 0.375523, 'loss_vowel': 0.224931, 'loss_consonant': 0.158849}\n",
      "   12 | 0.000002 | 138240/180756 | 1.6209 | 2.9879 |\n",
      "val: {'recall': 0.978479, 'recall_grapheme': 0.967769, 'recall_vowel': 0.987982, 'recall_consonant': 0.990394, 'acc_grapheme': 0.966441, 'acc_vowel': 0.990092, 'acc_consonant': 0.989444, 'loss_grapheme': 0.324751, 'loss_vowel': 0.19473, 'loss_consonant': 0.148433}\n",
      "   13 | 0.000004 | 111360/180756 | 0.8628 | 3.1008 |\n",
      "val: {'recall': 0.978989, 'recall_grapheme': 0.968601, 'recall_vowel': 0.988002, 'recall_consonant': 0.990755, 'acc_grapheme': 0.967038, 'acc_vowel': 0.989992, 'acc_consonant': 0.990291, 'loss_grapheme': 0.300289, 'loss_vowel': 0.181536, 'loss_consonant': 0.138249}\n",
      "   14 | 0.000006 | 084480/180756 | 3.9504 | 3.1542 |\n",
      "val: {'recall': 0.979196, 'recall_grapheme': 0.968229, 'recall_vowel': 0.987725, 'recall_consonant': 0.9926, 'acc_grapheme': 0.966292, 'acc_vowel': 0.990092, 'acc_consonant': 0.988548, 'loss_grapheme': 0.291057, 'loss_vowel': 0.177089, 'loss_consonant': 0.14994}\n",
      "   15 | 0.000008 | 057600/180756 | 4.8525 | 2.9692 |\n",
      "val: {'recall': 0.978374, 'recall_grapheme': 0.968456, 'recall_vowel': 0.987827, 'recall_consonant': 0.988755, 'acc_grapheme': 0.96659, 'acc_vowel': 0.990191, 'acc_consonant': 0.989793, 'loss_grapheme': 0.311735, 'loss_vowel': 0.183669, 'loss_consonant': 0.140562}\n",
      "   16 | 0.000010 | 030720/180756 | 4.7458 | 3.3365 |\n",
      "val: {'recall': 0.97805, 'recall_grapheme': 0.967194, 'recall_vowel': 0.987329, 'recall_consonant': 0.99048, 'acc_grapheme': 0.965744, 'acc_vowel': 0.989444, 'acc_consonant': 0.988847, 'loss_grapheme': 0.460187, 'loss_vowel': 0.290091, 'loss_consonant': 0.200173}\n",
      "   17 | 0.000013 | 003840/180756 | 0.0260 | 3.1152 |\n",
      "val: {'recall': 0.977727, 'recall_grapheme': 0.967023, 'recall_vowel': 0.988322, 'recall_consonant': 0.98854, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990042, 'acc_consonant': 0.9881, 'loss_grapheme': 0.275217, 'loss_vowel': 0.168802, 'loss_consonant': 0.15521}\n",
      "   17 | 0.000015 | 157440/180756 | 1.8514 | 3.0566 |\n",
      "val: {'recall': 0.979006, 'recall_grapheme': 0.969178, 'recall_vowel': 0.986925, 'recall_consonant': 0.990745, 'acc_grapheme': 0.966989, 'acc_vowel': 0.989843, 'acc_consonant': 0.989046, 'loss_grapheme': 0.351295, 'loss_vowel': 0.218096, 'loss_consonant': 0.173483}\n",
      "   18 | 0.000017 | 130560/180756 | 0.0547 | 3.1339 |\n",
      "val: {'recall': 0.978494, 'recall_grapheme': 0.968402, 'recall_vowel': 0.988428, 'recall_consonant': 0.988744, 'acc_grapheme': 0.965843, 'acc_vowel': 0.990241, 'acc_consonant': 0.989643, 'loss_grapheme': 0.285928, 'loss_vowel': 0.157589, 'loss_consonant': 0.136737}\n",
      "   19 | 0.000019 | 103680/180756 | 3.2045 | 3.1968 |\n",
      "val: {'recall': 0.979061, 'recall_grapheme': 0.968377, 'recall_vowel': 0.987945, 'recall_consonant': 0.991544, 'acc_grapheme': 0.965794, 'acc_vowel': 0.990241, 'acc_consonant': 0.989096, 'loss_grapheme': 0.317552, 'loss_vowel': 0.191975, 'loss_consonant': 0.157057}\n",
      "   20 | 0.000020 | 076800/180756 | 3.6981 | 2.9781 |\n",
      "val: {'recall': 0.979362, 'recall_grapheme': 0.969331, 'recall_vowel': 0.988117, 'recall_consonant': 0.990668, 'acc_grapheme': 0.966491, 'acc_vowel': 0.990241, 'acc_consonant': 0.989295, 'loss_grapheme': 0.385255, 'loss_vowel': 0.223619, 'loss_consonant': 0.17152}\n",
      "   21 | 0.000020 | 049920/180756 | 4.3403 | 2.7478 |\n",
      "val: {'recall': 0.976312, 'recall_grapheme': 0.964581, 'recall_vowel': 0.987609, 'recall_consonant': 0.988477, 'acc_grapheme': 0.965196, 'acc_vowel': 0.989843, 'acc_consonant': 0.989245, 'loss_grapheme': 0.283951, 'loss_vowel': 0.167152, 'loss_consonant': 0.134724}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 0.000020 | 023040/180756 | 2.6757 | 3.0263 |\n",
      "val: {'recall': 0.978681, 'recall_grapheme': 0.966701, 'recall_vowel': 0.988151, 'recall_consonant': 0.99317, 'acc_grapheme': 0.965595, 'acc_vowel': 0.990191, 'acc_consonant': 0.989494, 'loss_grapheme': 0.304428, 'loss_vowel': 0.186286, 'loss_consonant': 0.160129}\n",
      "   22 | 0.000019 | 176640/180756 | 0.0540 | 3.0258 |\n",
      "val: {'recall': 0.977527, 'recall_grapheme': 0.968036, 'recall_vowel': 0.986764, 'recall_consonant': 0.987274, 'acc_grapheme': 0.96664, 'acc_vowel': 0.989843, 'acc_consonant': 0.989096, 'loss_grapheme': 0.255726, 'loss_vowel': 0.146429, 'loss_consonant': 0.133479}\n",
      "   23 | 0.000017 | 149760/180756 | 2.6475 | 3.0810 |\n",
      "val: {'recall': 0.978796, 'recall_grapheme': 0.96737, 'recall_vowel': 0.987882, 'recall_consonant': 0.99256, 'acc_grapheme': 0.966541, 'acc_vowel': 0.989892, 'acc_consonant': 0.988349, 'loss_grapheme': 0.321729, 'loss_vowel': 0.193959, 'loss_consonant': 0.162415}\n",
      "   24 | 0.000015 | 122880/180756 | 2.1553 | 2.8156 |\n",
      "val: {'recall': 0.977134, 'recall_grapheme': 0.967296, 'recall_vowel': 0.987702, 'recall_consonant': 0.986243, 'acc_grapheme': 0.965843, 'acc_vowel': 0.990042, 'acc_consonant': 0.99044, 'loss_grapheme': 0.325227, 'loss_vowel': 0.200122, 'loss_consonant': 0.149815}\n",
      "   25 | 0.000013 | 096000/180756 | 0.0393 | 2.8399 |\n",
      "val: {'recall': 0.978031, 'recall_grapheme': 0.967774, 'recall_vowel': 0.988234, 'recall_consonant': 0.988343, 'acc_grapheme': 0.966043, 'acc_vowel': 0.990092, 'acc_consonant': 0.989245, 'loss_grapheme': 0.303751, 'loss_vowel': 0.179734, 'loss_consonant': 0.147067}\n",
      "   26 | 0.000011 | 069120/180756 | 3.7171 | 2.8519 |\n",
      "val: {'recall': 0.978289, 'recall_grapheme': 0.968643, 'recall_vowel': 0.988006, 'recall_consonant': 0.987863, 'acc_grapheme': 0.96659, 'acc_vowel': 0.99039, 'acc_consonant': 0.988996, 'loss_grapheme': 0.330242, 'loss_vowel': 0.198692, 'loss_consonant': 0.158252}\n",
      "   27 | 0.000008 | 042240/180756 | 3.0916 | 2.4978 |\n",
      "val: {'recall': 0.977742, 'recall_grapheme': 0.96719, 'recall_vowel': 0.98819, 'recall_consonant': 0.988397, 'acc_grapheme': 0.96664, 'acc_vowel': 0.99054, 'acc_consonant': 0.989195, 'loss_grapheme': 0.282583, 'loss_vowel': 0.167044, 'loss_consonant': 0.134884}\n",
      "   28 | 0.000006 | 015360/180756 | 2.8963 | 3.6098 |\n",
      "val: {'recall': 0.97785, 'recall_grapheme': 0.967605, 'recall_vowel': 0.988067, 'recall_consonant': 0.988122, 'acc_grapheme': 0.966092, 'acc_vowel': 0.990291, 'acc_consonant': 0.990241, 'loss_grapheme': 0.385705, 'loss_vowel': 0.248493, 'loss_consonant': 0.165224}\n",
      "   28 | 0.000004 | 168960/180756 | 0.0526 | 3.1233 |\n",
      "val: {'recall': 0.978593, 'recall_grapheme': 0.967887, 'recall_vowel': 0.988202, 'recall_consonant': 0.990396, 'acc_grapheme': 0.966839, 'acc_vowel': 0.99039, 'acc_consonant': 0.988349, 'loss_grapheme': 0.379277, 'loss_vowel': 0.239532, 'loss_consonant': 0.183314}\n",
      "   29 | 0.000002 | 142080/180756 | 1.2287 | 3.0753 |\n",
      "val: {'recall': 0.978652, 'recall_grapheme': 0.968119, 'recall_vowel': 0.987789, 'recall_consonant': 0.99058, 'acc_grapheme': 0.96664, 'acc_vowel': 0.990191, 'acc_consonant': 0.989046, 'loss_grapheme': 0.326752, 'loss_vowel': 0.193633, 'loss_consonant': 0.157651}\n",
      "   30 | 0.000001 | 115200/180756 | 0.0462 | 2.8754 |\n",
      "val: {'recall': 0.978768, 'recall_grapheme': 0.9682, 'recall_vowel': 0.988331, 'recall_consonant': 0.990341, 'acc_grapheme': 0.966889, 'acc_vowel': 0.990291, 'acc_consonant': 0.988598, 'loss_grapheme': 0.331814, 'loss_vowel': 0.209699, 'loss_consonant': 0.168802}\n",
      "   31 | 0.000001 | 088320/180756 | 0.0400 | 2.8402 |\n",
      "val: {'recall': 0.978606, 'recall_grapheme': 0.969202, 'recall_vowel': 0.987635, 'recall_consonant': 0.988383, 'acc_grapheme': 0.967337, 'acc_vowel': 0.990191, 'acc_consonant': 0.989693, 'loss_grapheme': 0.252209, 'loss_vowel': 0.146998, 'loss_consonant': 0.129914}\n",
      "   32 | 0.000001 | 061440/180756 | 4.3074 | 2.8114 |\n",
      "val: {'recall': 0.97889, 'recall_grapheme': 0.968554, 'recall_vowel': 0.988139, 'recall_consonant': 0.990314, 'acc_grapheme': 0.967088, 'acc_vowel': 0.99044, 'acc_consonant': 0.988449, 'loss_grapheme': 0.303051, 'loss_vowel': 0.190567, 'loss_consonant': 0.158283}\n",
      "   33 | 0.000002 | 034560/180756 | 4.2219 | 2.7772 |\n",
      "val: {'recall': 0.978152, 'recall_grapheme': 0.96859, 'recall_vowel': 0.987366, 'recall_consonant': 0.988062, 'acc_grapheme': 0.966889, 'acc_vowel': 0.990042, 'acc_consonant': 0.989793, 'loss_grapheme': 0.399018, 'loss_vowel': 0.241339, 'loss_consonant': 0.174647}\n",
      "   34 | 0.000004 | 007680/180756 | 4.4068 | 3.3455 |\n",
      "val: {'recall': 0.978663, 'recall_grapheme': 0.969075, 'recall_vowel': 0.987946, 'recall_consonant': 0.988554, 'acc_grapheme': 0.966889, 'acc_vowel': 0.990191, 'acc_consonant': 0.988349, 'loss_grapheme': 0.374347, 'loss_vowel': 0.231126, 'loss_consonant': 0.184801}\n",
      "   34 | 0.000006 | 161280/180756 | 2.4011 | 2.9787 |\n",
      "val: {'recall': 0.979106, 'recall_grapheme': 0.968576, 'recall_vowel': 0.988747, 'recall_consonant': 0.990526, 'acc_grapheme': 0.96664, 'acc_vowel': 0.99059, 'acc_consonant': 0.99059, 'loss_grapheme': 0.339166, 'loss_vowel': 0.217595, 'loss_consonant': 0.15544}\n",
      "   35 | 0.000008 | 134400/180756 | 1.0370 | 2.9411 |\n",
      "val: {'recall': 0.978543, 'recall_grapheme': 0.969131, 'recall_vowel': 0.987695, 'recall_consonant': 0.988215, 'acc_grapheme': 0.967238, 'acc_vowel': 0.990092, 'acc_consonant': 0.990191, 'loss_grapheme': 0.277078, 'loss_vowel': 0.161932, 'loss_consonant': 0.132146}\n",
      "   36 | 0.000010 | 107520/180756 | 0.6396 | 3.2315 |\n",
      "val: {'recall': 0.978137, 'recall_grapheme': 0.968298, 'recall_vowel': 0.987573, 'recall_consonant': 0.98838, 'acc_grapheme': 0.96664, 'acc_vowel': 0.99039, 'acc_consonant': 0.990739, 'loss_grapheme': 0.349369, 'loss_vowel': 0.215827, 'loss_consonant': 0.153735}\n",
      "   37 | 0.000013 | 080640/180756 | 2.2862 | 2.8998 |\n",
      "val: {'recall': 0.978569, 'recall_grapheme': 0.968028, 'recall_vowel': 0.98743, 'recall_consonant': 0.990791, 'acc_grapheme': 0.967138, 'acc_vowel': 0.990191, 'acc_consonant': 0.989643, 'loss_grapheme': 0.275756, 'loss_vowel': 0.167312, 'loss_consonant': 0.128174}\n",
      "   38 | 0.000015 | 053760/180756 | 2.5251 | 2.9685 |\n",
      "val: {'recall': 0.978214, 'recall_grapheme': 0.968154, 'recall_vowel': 0.987937, 'recall_consonant': 0.988609, 'acc_grapheme': 0.966491, 'acc_vowel': 0.990241, 'acc_consonant': 0.990092, 'loss_grapheme': 0.269909, 'loss_vowel': 0.158906, 'loss_consonant': 0.133622}\n",
      "   39 | 0.000017 | 026880/180756 | 5.0245 | 2.9784 |\n",
      "val: {'recall': 0.978424, 'recall_grapheme': 0.967364, 'recall_vowel': 0.988193, 'recall_consonant': 0.990775, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990241, 'acc_consonant': 0.989494, 'loss_grapheme': 0.361396, 'loss_vowel': 0.220054, 'loss_consonant': 0.168599}\n",
      "   39 | 0.000019 | 180480/180756 | 3.5398 | 3.0229 |\n",
      "val: {'recall': 0.978103, 'recall_grapheme': 0.968153, 'recall_vowel': 0.987505, 'recall_consonant': 0.988599, 'acc_grapheme': 0.965943, 'acc_vowel': 0.990141, 'acc_consonant': 0.989494, 'loss_grapheme': 0.332259, 'loss_vowel': 0.206618, 'loss_consonant': 0.157142}\n",
      "   40 | 0.000020 | 153600/180756 | 4.0828 | 2.9273 |\n",
      "val: {'recall': 0.977858, 'recall_grapheme': 0.967214, 'recall_vowel': 0.988042, 'recall_consonant': 0.988964, 'acc_grapheme': 0.965794, 'acc_vowel': 0.989892, 'acc_consonant': 0.989942, 'loss_grapheme': 0.366267, 'loss_vowel': 0.226068, 'loss_consonant': 0.166178}\n",
      "   41 | 0.000020 | 126720/180756 | 0.5049 | 3.0192 |\n",
      "val: {'recall': 0.977812, 'recall_grapheme': 0.967468, 'recall_vowel': 0.988173, 'recall_consonant': 0.988139, 'acc_grapheme': 0.965744, 'acc_vowel': 0.990042, 'acc_consonant': 0.990639, 'loss_grapheme': 0.364, 'loss_vowel': 0.220882, 'loss_consonant': 0.154329}\n",
      "   42 | 0.000020 | 099840/180756 | 4.3198 | 2.6555 |\n",
      "val: {'recall': 0.977565, 'recall_grapheme': 0.96693, 'recall_vowel': 0.98779, 'recall_consonant': 0.98861, 'acc_grapheme': 0.966292, 'acc_vowel': 0.990241, 'acc_consonant': 0.989942, 'loss_grapheme': 0.321134, 'loss_vowel': 0.196693, 'loss_consonant': 0.154994}\n",
      "   43 | 0.000019 | 072960/180756 | 1.0315 | 3.0342 |\n",
      "val: {'recall': 0.978297, 'recall_grapheme': 0.967401, 'recall_vowel': 0.98808, 'recall_consonant': 0.990305, 'acc_grapheme': 0.965246, 'acc_vowel': 0.990291, 'acc_consonant': 0.990042, 'loss_grapheme': 0.356056, 'loss_vowel': 0.213099, 'loss_consonant': 0.157766}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 | 0.000017 | 046080/180756 | 3.8302 | 2.8624 |\n",
      "val: {'recall': 0.978227, 'recall_grapheme': 0.967463, 'recall_vowel': 0.987047, 'recall_consonant': 0.990933, 'acc_grapheme': 0.966192, 'acc_vowel': 0.990092, 'acc_consonant': 0.99039, 'loss_grapheme': 0.351208, 'loss_vowel': 0.218829, 'loss_consonant': 0.160556}\n",
      "   45 | 0.000015 | 019200/180756 | 3.8934 | 3.0265 |\n",
      "val: {'recall': 0.978613, 'recall_grapheme': 0.968133, 'recall_vowel': 0.987902, 'recall_consonant': 0.990285, 'acc_grapheme': 0.965644, 'acc_vowel': 0.990042, 'acc_consonant': 0.989594, 'loss_grapheme': 0.361923, 'loss_vowel': 0.234222, 'loss_consonant': 0.163663}\n",
      "   45 | 0.000013 | 172800/180756 | 2.4299 | 2.8987 |\n",
      "val: {'recall': 0.978477, 'recall_grapheme': 0.967841, 'recall_vowel': 0.987142, 'recall_consonant': 0.991083, 'acc_grapheme': 0.967038, 'acc_vowel': 0.989793, 'acc_consonant': 0.99049, 'loss_grapheme': 0.350092, 'loss_vowel': 0.211925, 'loss_consonant': 0.152599}\n",
      "   46 | 0.000011 | 145920/180756 | 4.4946 | 2.9939 |\n",
      "val: {'recall': 0.979296, 'recall_grapheme': 0.968654, 'recall_vowel': 0.988567, 'recall_consonant': 0.991307, 'acc_grapheme': 0.966292, 'acc_vowel': 0.990341, 'acc_consonant': 0.989345, 'loss_grapheme': 0.397941, 'loss_vowel': 0.256804, 'loss_consonant': 0.180335}\n",
      "   47 | 0.000008 | 119040/180756 | 4.1580 | 3.0071 |\n",
      "val: {'recall': 0.979078, 'recall_grapheme': 0.967928, 'recall_vowel': 0.988279, 'recall_consonant': 0.992177, 'acc_grapheme': 0.966192, 'acc_vowel': 0.99044, 'acc_consonant': 0.988449, 'loss_grapheme': 0.400746, 'loss_vowel': 0.260384, 'loss_consonant': 0.192713}\n",
      "   48 | 0.000006 | 092160/180756 | 2.5136 | 2.7329 |\n",
      "val: {'recall': 0.978553, 'recall_grapheme': 0.968906, 'recall_vowel': 0.987919, 'recall_consonant': 0.98848, 'acc_grapheme': 0.967088, 'acc_vowel': 0.990241, 'acc_consonant': 0.990042, 'loss_grapheme': 0.281474, 'loss_vowel': 0.166245, 'loss_consonant': 0.136415}\n",
      "   49 | 0.000004 | 065280/180756 | 4.7732 | 2.9401 |\n",
      "val: {'recall': 0.97892, 'recall_grapheme': 0.96947, 'recall_vowel': 0.98833, 'recall_consonant': 0.988411, 'acc_grapheme': 0.967138, 'acc_vowel': 0.99039, 'acc_consonant': 0.989295, 'loss_grapheme': 0.365466, 'loss_vowel': 0.233769, 'loss_consonant': 0.175116}\n",
      "   50 | 0.000002 | 038400/180756 | 0.0407 | 2.6230 |\n",
      "val: {'recall': 0.978997, 'recall_grapheme': 0.969703, 'recall_vowel': 0.988086, 'recall_consonant': 0.988494, 'acc_grapheme': 0.967287, 'acc_vowel': 0.99044, 'acc_consonant': 0.990092, 'loss_grapheme': 0.26928, 'loss_vowel': 0.156238, 'loss_consonant': 0.133624}\n",
      "   51 | 0.000001 | 011520/180756 | 3.7023 | 3.2023 |\n",
      "val: {'recall': 0.978628, 'recall_grapheme': 0.968895, 'recall_vowel': 0.988148, 'recall_consonant': 0.988574, 'acc_grapheme': 0.96659, 'acc_vowel': 0.99039, 'acc_consonant': 0.989843, 'loss_grapheme': 0.367391, 'loss_vowel': 0.225646, 'loss_consonant': 0.16853}\n",
      "   51 | 0.000001 | 165120/180756 | 0.2057 | 2.9326 |\n",
      "val: {'recall': 0.978696, 'recall_grapheme': 0.968752, 'recall_vowel': 0.988726, 'recall_consonant': 0.988552, 'acc_grapheme': 0.967088, 'acc_vowel': 0.99054, 'acc_consonant': 0.99054, 'loss_grapheme': 0.241753, 'loss_vowel': 0.136468, 'loss_consonant': 0.112752}\n",
      "   52 | 0.000001 | 138240/180756 | 2.1663 | 2.9798 |\n",
      "val: {'recall': 0.978528, 'recall_grapheme': 0.968883, 'recall_vowel': 0.987899, 'recall_consonant': 0.988445, 'acc_grapheme': 0.966789, 'acc_vowel': 0.990241, 'acc_consonant': 0.990739, 'loss_grapheme': 0.350779, 'loss_vowel': 0.211383, 'loss_consonant': 0.152429}\n",
      "   53 | 0.000002 | 111360/180756 | 3.7535 | 3.1809 |\n",
      "val: {'recall': 0.978671, 'recall_grapheme': 0.969048, 'recall_vowel': 0.988008, 'recall_consonant': 0.988581, 'acc_grapheme': 0.966541, 'acc_vowel': 0.990291, 'acc_consonant': 0.99044, 'loss_grapheme': 0.427889, 'loss_vowel': 0.255112, 'loss_consonant': 0.177502}\n",
      "   54 | 0.000004 | 084480/180756 | 0.0309 | 2.8076 |\n",
      "val: {'recall': 0.978262, 'recall_grapheme': 0.968421, 'recall_vowel': 0.988063, 'recall_consonant': 0.988144, 'acc_grapheme': 0.967188, 'acc_vowel': 0.990241, 'acc_consonant': 0.989395, 'loss_grapheme': 0.263297, 'loss_vowel': 0.157029, 'loss_consonant': 0.138636}\n",
      "   55 | 0.000006 | 057600/180756 | 0.0403 | 2.5512 |\n",
      "val: {'recall': 0.979019, 'recall_grapheme': 0.969527, 'recall_vowel': 0.988239, 'recall_consonant': 0.988782, 'acc_grapheme': 0.967487, 'acc_vowel': 0.99049, 'acc_consonant': 0.99059, 'loss_grapheme': 0.22924, 'loss_vowel': 0.131352, 'loss_consonant': 0.113249}\n",
      "   56 | 0.000008 | 030720/180756 | 4.4173 | 2.8331 |\n",
      "val: {'recall': 0.979102, 'recall_grapheme': 0.969608, 'recall_vowel': 0.988747, 'recall_consonant': 0.988442, 'acc_grapheme': 0.966889, 'acc_vowel': 0.990639, 'acc_consonant': 0.990838, 'loss_grapheme': 0.344128, 'loss_vowel': 0.216332, 'loss_consonant': 0.154742}\n",
      "   57 | 0.000011 | 003840/180756 | 5.3573 | 2.5260 |\n",
      "val: {'recall': 0.97842, 'recall_grapheme': 0.968313, 'recall_vowel': 0.988277, 'recall_consonant': 0.988777, 'acc_grapheme': 0.96659, 'acc_vowel': 0.99054, 'acc_consonant': 0.99054, 'loss_grapheme': 0.373472, 'loss_vowel': 0.228528, 'loss_consonant': 0.161444}\n",
      "   57 | 0.000013 | 157440/180756 | 4.8332 | 2.9660 |\n",
      "val: {'recall': 0.978664, 'recall_grapheme': 0.968931, 'recall_vowel': 0.988004, 'recall_consonant': 0.988789, 'acc_grapheme': 0.967636, 'acc_vowel': 0.990241, 'acc_consonant': 0.989594, 'loss_grapheme': 0.338272, 'loss_vowel': 0.206774, 'loss_consonant': 0.162358}\n",
      "   58 | 0.000015 | 130560/180756 | 5.0467 | 2.9377 |\n",
      "val: {'recall': 0.978481, 'recall_grapheme': 0.967227, 'recall_vowel': 0.98843, 'recall_consonant': 0.991038, 'acc_grapheme': 0.966839, 'acc_vowel': 0.99044, 'acc_consonant': 0.988996, 'loss_grapheme': 0.263853, 'loss_vowel': 0.157453, 'loss_consonant': 0.145746}\n",
      "   59 | 0.000017 | 075264/180756 | 0.5736 | 3.0150 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6c6ea13b8436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# densenet201\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-dc025a7bdc33>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbbx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbby2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbby1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)  # densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
