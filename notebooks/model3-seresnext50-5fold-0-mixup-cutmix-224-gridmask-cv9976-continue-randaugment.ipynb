{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: cvcore\r\n",
      "Version: 0.0.1\r\n",
      "Summary: Computer Vision Pytorch-based Toolbox\r\n",
      "Home-page: UNKNOWN\r\n",
      "Author: UNKNOWN\r\n",
      "Author-email: UNKNOWN\r\n",
      "License: UNKNOWN\r\n",
      "Location: /home/chec/bengaliai-cv19\r\n",
      "Requires: albumentations, torch, torchvision, timm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show cvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "'''\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)\n",
    "'''\n",
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHEM = False\n",
    "def ohem_loss(cls_pred, cls_target, rate=0.5):\n",
    "    batch_size = cls_pred.size(0) \n",
    "    ohem_cls_loss = F.cross_entropy(cls_pred, cls_target, reduction='none', ignore_index=-1)\n",
    "\n",
    "    sorted_ohem_loss, idx = torch.sort(ohem_cls_loss, descending=True)\n",
    "    keep_num = min(sorted_ohem_loss.size()[0], int(batch_size*rate) )\n",
    "    if keep_num < sorted_ohem_loss.size()[0]:\n",
    "        keep_idx_cuda = idx[:keep_num]\n",
    "        ohem_cls_loss = ohem_cls_loss[keep_idx_cuda]\n",
    "    cls_loss = ohem_cls_loss.sum() / keep_num\n",
    "    return cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    if OHEM:\n",
    "        loss0 = ohem_loss(outputs[0], y_true[:, 0])\n",
    "        loss1 = ohem_loss(outputs[1], y_true[:, 1])\n",
    "        loss2 = ohem_loss(outputs[2], y_true[:, 2])\n",
    "    else:\n",
    "        loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "        loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "        loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303244743705573"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from over9000.lookahead import Lookahead\n",
    "def LookaheadSGD(params, alpha=0.5, k=6, *args, **kwargs):\n",
    "     sgd = optim.SGD(params, *args, **kwargs)\n",
    "     return Lookahead(sgd, alpha, k)\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_old(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam( [{'params': model.parameters(), 'initial_lr': args.lr }], lr=args.lr, weight_decay=1e-5)\n",
    "        #optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-5)\n",
    "        optimizer = LookaheadSGD(\n",
    "            [{'params': model.parameters(), 'initial_lr': args.lr }],\n",
    "            lr=args.lr, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, args.t_max, eta_min=args.min_lr) #, last_epoch=args.t_max)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "    \n",
    "    grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "\n",
    "        grid.set_prob(epoch, args.st_epochs)\n",
    "\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if True:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            elif r > 0.6: # grid mask\n",
    "                img = grid(img)\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, targets)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model):\n",
    "    optimizer = make_optimizer(model)\n",
    "    scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        train_cycle(args, model, optimizer, scheduler)\n",
    "        scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "\n",
    "def train_cycle(args, model, optimizer, lr_scheduler):\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            batch_size = img.size(0)\n",
    "            r = np.random.rand()\n",
    "\n",
    "            if True:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            #loss.backward()\n",
    "            lr_scheduler(optimizer, batch_idx, epoch)\n",
    "            optimizer.step()            \n",
    "            \n",
    "            current_lr = get_lrs(optimizer)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "        if True:#train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "            val_metrics = validate(model, val_loader)\n",
    "            print('\\nval:', val_metrics)\n",
    "                \n",
    "            if val_metrics[best_key] > best_metrics:\n",
    "                best_metrics = val_metrics[best_key]\n",
    "                save_model(model, model_file)\n",
    "                print('###>>>>> saved')\n",
    "                \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model3_se_resnext50_fold0_mixup_cutmix_224_gridmask.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 1e-4\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.5\n",
    "args.patience = 0\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "\n",
    "args.base_lr = 4e-4\n",
    "args.num_epochs = 150\n",
    "args.warmup_epochs = 10\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 768\n",
    "args.val_batch_size = 1024\n",
    "args.st_epochs = 10\n",
    "\n",
    "args.beta = 1.5\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160596, 5) (40244, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model3_se_resnext50_fold0_mixup_cutmix_224_gridmask.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model3_se_resnext50_fold0_mixup_cutmix_224_gridmask.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYCLE: 1\n",
      "{'recall': 0.997662, 'recall_grapheme': 0.997015, 'recall_vowel': 0.998562, 'recall_consonant': 0.998055, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998484, 'acc_consonant': 0.998758, 'loss_grapheme': 0.020853, 'loss_vowel': 0.012834, 'loss_consonant': 0.009888}\n",
      "    0 | 0.000040 | 160512/160596 | 3.7143 | 4.5922 |\n",
      "val: {'recall': 0.991667, 'recall_grapheme': 0.988034, 'recall_vowel': 0.994864, 'recall_consonant': 0.995736, 'acc_grapheme': 0.987949, 'acc_vowel': 0.995701, 'acc_consonant': 0.994931, 'loss_grapheme': 0.162769, 'loss_vowel': 0.131382, 'loss_consonant': 0.088483}\n",
      "    1 | 0.000080 | 160512/160596 | 1.3471 | 3.8837 |\n",
      "val: {'recall': 0.991355, 'recall_grapheme': 0.987691, 'recall_vowel': 0.99516, 'recall_consonant': 0.99488, 'acc_grapheme': 0.988421, 'acc_vowel': 0.996024, 'acc_consonant': 0.995701, 'loss_grapheme': 0.115625, 'loss_vowel': 0.102441, 'loss_consonant': 0.065003}\n",
      "    2 | 0.000120 | 160512/160596 | 4.2119 | 3.5793 |\n",
      "val: {'recall': 0.991888, 'recall_grapheme': 0.988735, 'recall_vowel': 0.994374, 'recall_consonant': 0.995708, 'acc_grapheme': 0.988644, 'acc_vowel': 0.995254, 'acc_consonant': 0.995875, 'loss_grapheme': 0.16375, 'loss_vowel': 0.129432, 'loss_consonant': 0.086408}\n",
      "    3 | 0.000160 | 160512/160596 | 1.4980 | 3.3802 |\n",
      "val: {'recall': 0.992461, 'recall_grapheme': 0.989229, 'recall_vowel': 0.995122, 'recall_consonant': 0.996266, 'acc_grapheme': 0.989415, 'acc_vowel': 0.995751, 'acc_consonant': 0.995999, 'loss_grapheme': 0.219212, 'loss_vowel': 0.168663, 'loss_consonant': 0.107202}\n",
      "    4 | 0.000199 | 160512/160596 | 4.1546 | 3.3741 |\n",
      "val: {'recall': 0.99285, 'recall_grapheme': 0.990583, 'recall_vowel': 0.995214, 'recall_consonant': 0.995019, 'acc_grapheme': 0.990235, 'acc_vowel': 0.996074, 'acc_consonant': 0.996173, 'loss_grapheme': 0.216343, 'loss_vowel': 0.179369, 'loss_consonant': 0.114327}\n",
      "    5 | 0.000239 | 160512/160596 | 4.2175 | 3.2508 |\n",
      "val: {'recall': 0.993223, 'recall_grapheme': 0.991427, 'recall_vowel': 0.995355, 'recall_consonant': 0.994683, 'acc_grapheme': 0.990781, 'acc_vowel': 0.995676, 'acc_consonant': 0.996124, 'loss_grapheme': 0.239934, 'loss_vowel': 0.181993, 'loss_consonant': 0.113967}\n",
      "    6 | 0.000278 | 160512/160596 | 3.6280 | 3.2881 |\n",
      "val: {'recall': 0.991191, 'recall_grapheme': 0.988232, 'recall_vowel': 0.993761, 'recall_consonant': 0.994539, 'acc_grapheme': 0.988396, 'acc_vowel': 0.994086, 'acc_consonant': 0.994533, 'loss_grapheme': 0.19596, 'loss_vowel': 0.174532, 'loss_consonant': 0.111811}\n",
      "    7 | 0.000318 | 160512/160596 | 3.5646 | 3.1825 |\n",
      "val: {'recall': 0.99307, 'recall_grapheme': 0.990866, 'recall_vowel': 0.995695, 'recall_consonant': 0.994852, 'acc_grapheme': 0.990483, 'acc_vowel': 0.995999, 'acc_consonant': 0.995975, 'loss_grapheme': 0.222215, 'loss_vowel': 0.17793, 'loss_consonant': 0.115123}\n",
      "    8 | 0.000357 | 160512/160596 | 3.4658 | 3.1291 |\n",
      "val: {'recall': 0.993641, 'recall_grapheme': 0.991699, 'recall_vowel': 0.996006, 'recall_consonant': 0.995161, 'acc_grapheme': 0.991502, 'acc_vowel': 0.996148, 'acc_consonant': 0.996447, 'loss_grapheme': 0.175727, 'loss_vowel': 0.145701, 'loss_consonant': 0.089442}\n",
      "    9 | 0.000395 | 160512/160596 | 3.0636 | 3.1595 |\n",
      "val: {'recall': 0.991349, 'recall_grapheme': 0.988192, 'recall_vowel': 0.994494, 'recall_consonant': 0.994519, 'acc_grapheme': 0.988321, 'acc_vowel': 0.993763, 'acc_consonant': 0.99508, 'loss_grapheme': 0.252745, 'loss_vowel': 0.18801, 'loss_consonant': 0.125162}\n",
      "   10 | 0.000395 | 160512/160596 | 3.2388 | 3.1175 |\n",
      "val: {'recall': 0.99187, 'recall_grapheme': 0.989441, 'recall_vowel': 0.995176, 'recall_consonant': 0.993421, 'acc_grapheme': 0.989564, 'acc_vowel': 0.996248, 'acc_consonant': 0.995776, 'loss_grapheme': 0.210258, 'loss_vowel': 0.168428, 'loss_consonant': 0.111084}\n",
      "   11 | 0.000394 | 160512/160596 | 3.9990 | 3.2290 |\n",
      "val: {'recall': 0.983082, 'recall_grapheme': 0.980528, 'recall_vowel': 0.990771, 'recall_consonant': 0.980501, 'acc_grapheme': 0.982656, 'acc_vowel': 0.991502, 'acc_consonant': 0.991552, 'loss_grapheme': 0.251594, 'loss_vowel': 0.223582, 'loss_consonant': 0.143008}\n",
      "   12 | 0.000393 | 160512/160596 | 4.2242 | 3.0378 |\n",
      "val: {'recall': 0.991266, 'recall_grapheme': 0.988112, 'recall_vowel': 0.995062, 'recall_consonant': 0.993779, 'acc_grapheme': 0.988247, 'acc_vowel': 0.9959, 'acc_consonant': 0.994832, 'loss_grapheme': 0.285114, 'loss_vowel': 0.22204, 'loss_consonant': 0.139943}\n",
      "   13 | 0.000391 | 160512/160596 | 3.5964 | 3.1090 |\n",
      "val: {'recall': 0.989439, 'recall_grapheme': 0.98542, 'recall_vowel': 0.994342, 'recall_consonant': 0.992576, 'acc_grapheme': 0.985116, 'acc_vowel': 0.993515, 'acc_consonant': 0.993813, 'loss_grapheme': 0.266574, 'loss_vowel': 0.202288, 'loss_consonant': 0.138361}\n",
      "   14 | 0.000390 | 160512/160596 | 3.7579 | 3.0984 |\n",
      "val: {'recall': 0.993075, 'recall_grapheme': 0.991631, 'recall_vowel': 0.995284, 'recall_consonant': 0.993753, 'acc_grapheme': 0.991253, 'acc_vowel': 0.995602, 'acc_consonant': 0.995428, 'loss_grapheme': 0.193755, 'loss_vowel': 0.16755, 'loss_consonant': 0.105809}\n",
      "   15 | 0.000389 | 160512/160596 | 3.3291 | 3.0267 |\n",
      "val: {'recall': 0.993237, 'recall_grapheme': 0.990295, 'recall_vowel': 0.995888, 'recall_consonant': 0.996468, 'acc_grapheme': 0.990955, 'acc_vowel': 0.996372, 'acc_consonant': 0.996099, 'loss_grapheme': 0.209272, 'loss_vowel': 0.173865, 'loss_consonant': 0.122074}\n",
      "   16 | 0.000387 | 160512/160596 | 3.5238 | 3.1225 |\n",
      "val: {'recall': 0.991978, 'recall_grapheme': 0.988478, 'recall_vowel': 0.99568, 'recall_consonant': 0.995275, 'acc_grapheme': 0.98939, 'acc_vowel': 0.995229, 'acc_consonant': 0.995527, 'loss_grapheme': 0.248748, 'loss_vowel': 0.218466, 'loss_consonant': 0.143668}\n",
      "   17 | 0.000386 | 160512/160596 | 3.4784 | 3.0641 |\n",
      "val: {'recall': 0.987075, 'recall_grapheme': 0.983589, 'recall_vowel': 0.992381, 'recall_consonant': 0.988741, 'acc_grapheme': 0.984942, 'acc_vowel': 0.993614, 'acc_consonant': 0.992272, 'loss_grapheme': 0.272035, 'loss_vowel': 0.246854, 'loss_consonant': 0.160795}\n",
      "   18 | 0.000384 | 160512/160596 | 2.8770 | 2.9708 |\n",
      "val: {'recall': 0.993468, 'recall_grapheme': 0.990792, 'recall_vowel': 0.996148, 'recall_consonant': 0.99614, 'acc_grapheme': 0.990881, 'acc_vowel': 0.996198, 'acc_consonant': 0.995552, 'loss_grapheme': 0.222015, 'loss_vowel': 0.192432, 'loss_consonant': 0.123191}\n",
      "   19 | 0.000383 | 160512/160596 | 4.1587 | 2.9851 |\n",
      "val: {'recall': 0.993937, 'recall_grapheme': 0.991402, 'recall_vowel': 0.996349, 'recall_consonant': 0.996594, 'acc_grapheme': 0.991825, 'acc_vowel': 0.996795, 'acc_consonant': 0.997068, 'loss_grapheme': 0.174388, 'loss_vowel': 0.157873, 'loss_consonant': 0.103766}\n",
      "   20 | 0.000381 | 160512/160596 | 3.5615 | 2.9740 |\n",
      "val: {'recall': 0.991984, 'recall_grapheme': 0.98893, 'recall_vowel': 0.994638, 'recall_consonant': 0.995436, 'acc_grapheme': 0.989514, 'acc_vowel': 0.995403, 'acc_consonant': 0.99508, 'loss_grapheme': 0.259132, 'loss_vowel': 0.212665, 'loss_consonant': 0.146887}\n",
      "   21 | 0.000379 | 160512/160596 | 4.0814 | 2.8649 |\n",
      "val: {'recall': 0.993187, 'recall_grapheme': 0.990244, 'recall_vowel': 0.996248, 'recall_consonant': 0.996011, 'acc_grapheme': 0.991055, 'acc_vowel': 0.996447, 'acc_consonant': 0.996645, 'loss_grapheme': 0.206557, 'loss_vowel': 0.161405, 'loss_consonant': 0.110932}\n",
      "   22 | 0.000377 | 160512/160596 | 3.7433 | 3.0039 |\n",
      "val: {'recall': 0.992404, 'recall_grapheme': 0.98954, 'recall_vowel': 0.995831, 'recall_consonant': 0.994706, 'acc_grapheme': 0.990085, 'acc_vowel': 0.99585, 'acc_consonant': 0.995502, 'loss_grapheme': 0.21928, 'loss_vowel': 0.203866, 'loss_consonant': 0.137831}\n",
      "   23 | 0.000375 | 160512/160596 | 3.9587 | 2.9033 |\n",
      "val: {'recall': 0.994139, 'recall_grapheme': 0.992078, 'recall_vowel': 0.996023, 'recall_consonant': 0.996375, 'acc_grapheme': 0.991502, 'acc_vowel': 0.99595, 'acc_consonant': 0.99667, 'loss_grapheme': 0.160552, 'loss_vowel': 0.144529, 'loss_consonant': 0.094084}\n",
      "   24 | 0.000373 | 160512/160596 | 2.7909 | 2.9967 |\n",
      "val: {'recall': 0.991642, 'recall_grapheme': 0.988659, 'recall_vowel': 0.994621, 'recall_consonant': 0.994627, 'acc_grapheme': 0.989936, 'acc_vowel': 0.994459, 'acc_consonant': 0.995204, 'loss_grapheme': 0.216541, 'loss_vowel': 0.210464, 'loss_consonant': 0.132028}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 0.000371 | 160512/160596 | 2.8086 | 2.9233 |\n",
      "val: {'recall': 0.994253, 'recall_grapheme': 0.992119, 'recall_vowel': 0.996172, 'recall_consonant': 0.996601, 'acc_grapheme': 0.992645, 'acc_vowel': 0.996472, 'acc_consonant': 0.996372, 'loss_grapheme': 0.182938, 'loss_vowel': 0.151994, 'loss_consonant': 0.105618}\n",
      "   26 | 0.000369 | 160512/160596 | 2.1511 | 2.9727 |\n",
      "val: {'recall': 0.994593, 'recall_grapheme': 0.992691, 'recall_vowel': 0.996725, 'recall_consonant': 0.996266, 'acc_grapheme': 0.992893, 'acc_vowel': 0.996521, 'acc_consonant': 0.99677, 'loss_grapheme': 0.147412, 'loss_vowel': 0.127952, 'loss_consonant': 0.08814}\n",
      "   27 | 0.000367 | 160512/160596 | 3.2896 | 2.8683 |\n",
      "val: {'recall': 0.993786, 'recall_grapheme': 0.991826, 'recall_vowel': 0.996218, 'recall_consonant': 0.995275, 'acc_grapheme': 0.991949, 'acc_vowel': 0.996596, 'acc_consonant': 0.99677, 'loss_grapheme': 0.18575, 'loss_vowel': 0.166305, 'loss_consonant': 0.115988}\n",
      "   28 | 0.000364 | 160512/160596 | 2.2451 | 2.9602 |\n",
      "val: {'recall': 0.993448, 'recall_grapheme': 0.990544, 'recall_vowel': 0.995709, 'recall_consonant': 0.996993, 'acc_grapheme': 0.990781, 'acc_vowel': 0.996248, 'acc_consonant': 0.996546, 'loss_grapheme': 0.194273, 'loss_vowel': 0.175281, 'loss_consonant': 0.111317}\n",
      "   29 | 0.000362 | 160512/160596 | 3.8270 | 2.8804 |\n",
      "val: {'recall': 0.993226, 'recall_grapheme': 0.990994, 'recall_vowel': 0.995103, 'recall_consonant': 0.995812, 'acc_grapheme': 0.991775, 'acc_vowel': 0.996372, 'acc_consonant': 0.99667, 'loss_grapheme': 0.183198, 'loss_vowel': 0.159419, 'loss_consonant': 0.106239}\n",
      "   30 | 0.000359 | 160512/160596 | 3.5096 | 2.9264 |\n",
      "val: {'recall': 0.992818, 'recall_grapheme': 0.989795, 'recall_vowel': 0.995846, 'recall_consonant': 0.995836, 'acc_grapheme': 0.990955, 'acc_vowel': 0.995925, 'acc_consonant': 0.996148, 'loss_grapheme': 0.182697, 'loss_vowel': 0.183196, 'loss_consonant': 0.113878}\n",
      "   31 | 0.000357 | 160512/160596 | 2.7374 | 2.8697 |\n",
      "val: {'recall': 0.991178, 'recall_grapheme': 0.990218, 'recall_vowel': 0.992433, 'recall_consonant': 0.991842, 'acc_grapheme': 0.989613, 'acc_vowel': 0.993241, 'acc_consonant': 0.994856, 'loss_grapheme': 0.170558, 'loss_vowel': 0.151681, 'loss_consonant': 0.101883}\n",
      "   32 | 0.000354 | 160512/160596 | 2.8915 | 2.9039 |\n",
      "val: {'recall': 0.994236, 'recall_grapheme': 0.991834, 'recall_vowel': 0.996424, 'recall_consonant': 0.996852, 'acc_grapheme': 0.992272, 'acc_vowel': 0.996894, 'acc_consonant': 0.996944, 'loss_grapheme': 0.17934, 'loss_vowel': 0.167336, 'loss_consonant': 0.110993}\n",
      "   33 | 0.000351 | 160512/160596 | 3.6799 | 2.9269 |\n",
      "val: {'recall': 0.993639, 'recall_grapheme': 0.991372, 'recall_vowel': 0.99654, 'recall_consonant': 0.995273, 'acc_grapheme': 0.99185, 'acc_vowel': 0.99667, 'acc_consonant': 0.996223, 'loss_grapheme': 0.151733, 'loss_vowel': 0.132078, 'loss_consonant': 0.090512}\n",
      "   34 | 0.000349 | 160512/160596 | 3.3014 | 2.9417 |\n",
      "val: {'recall': 0.994214, 'recall_grapheme': 0.991943, 'recall_vowel': 0.995905, 'recall_consonant': 0.997066, 'acc_grapheme': 0.992446, 'acc_vowel': 0.996496, 'acc_consonant': 0.9959, 'loss_grapheme': 0.19785, 'loss_vowel': 0.148395, 'loss_consonant': 0.114588}\n",
      "   35 | 0.000346 | 160512/160596 | 3.2191 | 2.8026 |\n",
      "val: {'recall': 0.995308, 'recall_grapheme': 0.99356, 'recall_vowel': 0.996683, 'recall_consonant': 0.997431, 'acc_grapheme': 0.993291, 'acc_vowel': 0.996894, 'acc_consonant': 0.997316, 'loss_grapheme': 0.210451, 'loss_vowel': 0.189619, 'loss_consonant': 0.12461}\n",
      "   36 | 0.000343 | 160512/160596 | 3.0241 | 2.8863 |\n",
      "val: {'recall': 0.979764, 'recall_grapheme': 0.979885, 'recall_vowel': 0.984481, 'recall_consonant': 0.974807, 'acc_grapheme': 0.980345, 'acc_vowel': 0.988222, 'acc_consonant': 0.988769, 'loss_grapheme': 0.259474, 'loss_vowel': 0.219991, 'loss_consonant': 0.151223}\n",
      "   37 | 0.000340 | 160512/160596 | 3.2206 | 2.8875 |\n",
      "val: {'recall': 0.991439, 'recall_grapheme': 0.988994, 'recall_vowel': 0.995591, 'recall_consonant': 0.992179, 'acc_grapheme': 0.990409, 'acc_vowel': 0.995726, 'acc_consonant': 0.996148, 'loss_grapheme': 0.174884, 'loss_vowel': 0.138462, 'loss_consonant': 0.095258}\n",
      "   38 | 0.000337 | 160512/160596 | 3.0624 | 2.8854 |\n",
      "val: {'recall': 0.994921, 'recall_grapheme': 0.992895, 'recall_vowel': 0.997223, 'recall_consonant': 0.996669, 'acc_grapheme': 0.993862, 'acc_vowel': 0.997217, 'acc_consonant': 0.996944, 'loss_grapheme': 0.163395, 'loss_vowel': 0.144751, 'loss_consonant': 0.095146}\n",
      "   39 | 0.000334 | 160512/160596 | 2.5477 | 2.8129 |\n",
      "val: {'recall': 0.994246, 'recall_grapheme': 0.991793, 'recall_vowel': 0.996605, 'recall_consonant': 0.996792, 'acc_grapheme': 0.992521, 'acc_vowel': 0.996919, 'acc_consonant': 0.996844, 'loss_grapheme': 0.147007, 'loss_vowel': 0.115868, 'loss_consonant': 0.080622}\n",
      "   40 | 0.000331 | 160512/160596 | 2.6465 | 2.8754 |\n",
      "val: {'recall': 0.99334, 'recall_grapheme': 0.990508, 'recall_vowel': 0.995817, 'recall_consonant': 0.996528, 'acc_grapheme': 0.991601, 'acc_vowel': 0.996074, 'acc_consonant': 0.996372, 'loss_grapheme': 0.149868, 'loss_vowel': 0.130802, 'loss_consonant': 0.084466}\n",
      "   41 | 0.000328 | 160512/160596 | 3.2888 | 2.8002 |\n",
      "val: {'recall': 0.994701, 'recall_grapheme': 0.992832, 'recall_vowel': 0.996518, 'recall_consonant': 0.99662, 'acc_grapheme': 0.992769, 'acc_vowel': 0.996894, 'acc_consonant': 0.996968, 'loss_grapheme': 0.166431, 'loss_vowel': 0.134999, 'loss_consonant': 0.095437}\n",
      "   42 | 0.000324 | 160512/160596 | 2.9028 | 2.7340 |\n",
      "val: {'recall': 0.994957, 'recall_grapheme': 0.992546, 'recall_vowel': 0.997532, 'recall_consonant': 0.997204, 'acc_grapheme': 0.993689, 'acc_vowel': 0.997938, 'acc_consonant': 0.997515, 'loss_grapheme': 0.144505, 'loss_vowel': 0.116842, 'loss_consonant': 0.085335}\n",
      "   43 | 0.000321 | 160512/160596 | 1.7040 | 2.8230 |\n",
      "val: {'recall': 0.994727, 'recall_grapheme': 0.992849, 'recall_vowel': 0.997258, 'recall_consonant': 0.995952, 'acc_grapheme': 0.993539, 'acc_vowel': 0.997515, 'acc_consonant': 0.997416, 'loss_grapheme': 0.133427, 'loss_vowel': 0.113632, 'loss_consonant': 0.082107}\n",
      "   44 | 0.000318 | 160512/160596 | 1.7766 | 2.7305 |\n",
      "val: {'recall': 0.993449, 'recall_grapheme': 0.990593, 'recall_vowel': 0.995814, 'recall_consonant': 0.996797, 'acc_grapheme': 0.991775, 'acc_vowel': 0.996322, 'acc_consonant': 0.996645, 'loss_grapheme': 0.173343, 'loss_vowel': 0.155582, 'loss_consonant': 0.102682}\n",
      "   45 | 0.000314 | 160512/160596 | 2.5604 | 2.6747 |\n",
      "val: {'recall': 0.994429, 'recall_grapheme': 0.992911, 'recall_vowel': 0.99694, 'recall_consonant': 0.994956, 'acc_grapheme': 0.992918, 'acc_vowel': 0.997118, 'acc_consonant': 0.996745, 'loss_grapheme': 0.155301, 'loss_vowel': 0.137405, 'loss_consonant': 0.098063}\n",
      "   46 | 0.000311 | 160512/160596 | 3.5274 | 2.7760 |\n",
      "val: {'recall': 0.994137, 'recall_grapheme': 0.992623, 'recall_vowel': 0.996038, 'recall_consonant': 0.995263, 'acc_grapheme': 0.99262, 'acc_vowel': 0.996795, 'acc_consonant': 0.997068, 'loss_grapheme': 0.181429, 'loss_vowel': 0.16889, 'loss_consonant': 0.110023}\n",
      "   47 | 0.000307 | 160512/160596 | 2.9542 | 2.8496 |\n",
      "val: {'recall': 0.994165, 'recall_grapheme': 0.99214, 'recall_vowel': 0.996426, 'recall_consonant': 0.995955, 'acc_grapheme': 0.992645, 'acc_vowel': 0.99677, 'acc_consonant': 0.996944, 'loss_grapheme': 0.144788, 'loss_vowel': 0.111598, 'loss_consonant': 0.085749}\n",
      "   48 | 0.000304 | 160512/160596 | 3.8160 | 2.7455 |\n",
      "val: {'recall': 0.994348, 'recall_grapheme': 0.992112, 'recall_vowel': 0.996313, 'recall_consonant': 0.996856, 'acc_grapheme': 0.99262, 'acc_vowel': 0.996819, 'acc_consonant': 0.997043, 'loss_grapheme': 0.164834, 'loss_vowel': 0.146093, 'loss_consonant': 0.096764}\n",
      "   49 | 0.000300 | 160512/160596 | 1.3015 | 2.8182 |\n",
      "val: {'recall': 0.99403, 'recall_grapheme': 0.991936, 'recall_vowel': 0.995408, 'recall_consonant': 0.99684, 'acc_grapheme': 0.992844, 'acc_vowel': 0.996322, 'acc_consonant': 0.99677, 'loss_grapheme': 0.114358, 'loss_vowel': 0.103751, 'loss_consonant': 0.071146}\n",
      "   50 | 0.000296 | 160512/160596 | 3.6479 | 2.7274 |\n",
      "val: {'recall': 0.994302, 'recall_grapheme': 0.991947, 'recall_vowel': 0.997362, 'recall_consonant': 0.995952, 'acc_grapheme': 0.992247, 'acc_vowel': 0.99672, 'acc_consonant': 0.996621, 'loss_grapheme': 0.132813, 'loss_vowel': 0.11243, 'loss_consonant': 0.085394}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 0.000293 | 160512/160596 | 0.4082 | 2.7416 |\n",
      "val: {'recall': 0.995864, 'recall_grapheme': 0.994278, 'recall_vowel': 0.997531, 'recall_consonant': 0.997367, 'acc_grapheme': 0.994036, 'acc_vowel': 0.99759, 'acc_consonant': 0.997292, 'loss_grapheme': 0.138626, 'loss_vowel': 0.116432, 'loss_consonant': 0.079644}\n",
      "   52 | 0.000289 | 160512/160596 | 2.5249 | 2.6724 |\n",
      "val: {'recall': 0.994808, 'recall_grapheme': 0.993157, 'recall_vowel': 0.9971, 'recall_consonant': 0.995817, 'acc_grapheme': 0.992819, 'acc_vowel': 0.997118, 'acc_consonant': 0.997366, 'loss_grapheme': 0.125815, 'loss_vowel': 0.125438, 'loss_consonant': 0.081933}\n",
      "   53 | 0.000285 | 160512/160596 | 0.6594 | 2.8468 |\n",
      "val: {'recall': 0.993904, 'recall_grapheme': 0.993003, 'recall_vowel': 0.996837, 'recall_consonant': 0.992774, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997242, 'acc_consonant': 0.997217, 'loss_grapheme': 0.146773, 'loss_vowel': 0.130469, 'loss_consonant': 0.090217}\n",
      "   54 | 0.000281 | 160512/160596 | 3.1429 | 2.7142 |\n",
      "val: {'recall': 0.994319, 'recall_grapheme': 0.992176, 'recall_vowel': 0.997417, 'recall_consonant': 0.995507, 'acc_grapheme': 0.993042, 'acc_vowel': 0.997341, 'acc_consonant': 0.997441, 'loss_grapheme': 0.107605, 'loss_vowel': 0.094513, 'loss_consonant': 0.065363}\n",
      "   55 | 0.000278 | 160512/160596 | 3.3763 | 2.8285 |\n",
      "val: {'recall': 0.993825, 'recall_grapheme': 0.990809, 'recall_vowel': 0.996673, 'recall_consonant': 0.997009, 'acc_grapheme': 0.991427, 'acc_vowel': 0.99667, 'acc_consonant': 0.996645, 'loss_grapheme': 0.14055, 'loss_vowel': 0.122921, 'loss_consonant': 0.088234}\n",
      "   56 | 0.000274 | 160512/160596 | 2.5072 | 2.7793 |\n",
      "val: {'recall': 0.993775, 'recall_grapheme': 0.992008, 'recall_vowel': 0.995905, 'recall_consonant': 0.99518, 'acc_grapheme': 0.992446, 'acc_vowel': 0.996273, 'acc_consonant': 0.996347, 'loss_grapheme': 0.147899, 'loss_vowel': 0.136309, 'loss_consonant': 0.09471}\n",
      "   57 | 0.000270 | 160512/160596 | 2.1536 | 2.7287 |\n",
      "val: {'recall': 0.995108, 'recall_grapheme': 0.992943, 'recall_vowel': 0.997264, 'recall_consonant': 0.997283, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997515, 'acc_consonant': 0.99749, 'loss_grapheme': 0.145532, 'loss_vowel': 0.134799, 'loss_consonant': 0.08911}\n",
      "   58 | 0.000266 | 160512/160596 | 2.9276 | 2.7621 |\n",
      "val: {'recall': 0.994642, 'recall_grapheme': 0.992446, 'recall_vowel': 0.997154, 'recall_consonant': 0.996522, 'acc_grapheme': 0.993042, 'acc_vowel': 0.99754, 'acc_consonant': 0.997142, 'loss_grapheme': 0.114138, 'loss_vowel': 0.105801, 'loss_consonant': 0.076828}\n",
      "   59 | 0.000262 | 160512/160596 | 2.7105 | 2.8064 |\n",
      "val: {'recall': 0.994619, 'recall_grapheme': 0.99225, 'recall_vowel': 0.996902, 'recall_consonant': 0.997076, 'acc_grapheme': 0.992943, 'acc_vowel': 0.997441, 'acc_consonant': 0.99754, 'loss_grapheme': 0.091004, 'loss_vowel': 0.074644, 'loss_consonant': 0.058738}\n",
      "   60 | 0.000258 | 160512/160596 | 2.6524 | 2.8154 |\n",
      "val: {'recall': 0.994607, 'recall_grapheme': 0.992777, 'recall_vowel': 0.997164, 'recall_consonant': 0.995712, 'acc_grapheme': 0.993738, 'acc_vowel': 0.997316, 'acc_consonant': 0.997018, 'loss_grapheme': 0.117661, 'loss_vowel': 0.097615, 'loss_consonant': 0.076278}\n",
      "   61 | 0.000254 | 160512/160596 | 2.3229 | 2.7258 |\n",
      "val: {'recall': 0.994596, 'recall_grapheme': 0.992047, 'recall_vowel': 0.997185, 'recall_consonant': 0.997106, 'acc_grapheme': 0.992844, 'acc_vowel': 0.99749, 'acc_consonant': 0.997292, 'loss_grapheme': 0.096039, 'loss_vowel': 0.083421, 'loss_consonant': 0.072615}\n",
      "   62 | 0.000250 | 160512/160596 | 2.8720 | 2.7136 |\n",
      "val: {'recall': 0.993913, 'recall_grapheme': 0.991235, 'recall_vowel': 0.99682, 'recall_consonant': 0.996364, 'acc_grapheme': 0.992272, 'acc_vowel': 0.996894, 'acc_consonant': 0.996844, 'loss_grapheme': 0.128174, 'loss_vowel': 0.110771, 'loss_consonant': 0.084724}\n",
      "   63 | 0.000246 | 160512/160596 | 2.9961 | 2.6420 |\n",
      "val: {'recall': 0.994263, 'recall_grapheme': 0.992942, 'recall_vowel': 0.997048, 'recall_consonant': 0.994122, 'acc_grapheme': 0.993639, 'acc_vowel': 0.99754, 'acc_consonant': 0.997316, 'loss_grapheme': 0.10867, 'loss_vowel': 0.100138, 'loss_consonant': 0.071236}\n",
      "   64 | 0.000242 | 160512/160596 | 1.7933 | 2.7165 |\n",
      "val: {'recall': 0.996269, 'recall_grapheme': 0.994548, 'recall_vowel': 0.998261, 'recall_consonant': 0.99772, 'acc_grapheme': 0.994906, 'acc_vowel': 0.998385, 'acc_consonant': 0.998136, 'loss_grapheme': 0.121735, 'loss_vowel': 0.100384, 'loss_consonant': 0.072197}\n",
      "   65 | 0.000237 | 160512/160596 | 2.6338 | 2.6512 |\n",
      "val: {'recall': 0.99465, 'recall_grapheme': 0.993493, 'recall_vowel': 0.997414, 'recall_consonant': 0.994199, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997813, 'acc_consonant': 0.997366, 'loss_grapheme': 0.134881, 'loss_vowel': 0.098112, 'loss_consonant': 0.076115}\n",
      "   66 | 0.000233 | 160512/160596 | 3.4056 | 2.7086 |\n",
      "val: {'recall': 0.995809, 'recall_grapheme': 0.994274, 'recall_vowel': 0.997457, 'recall_consonant': 0.99723, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997987, 'acc_consonant': 0.997689, 'loss_grapheme': 0.132573, 'loss_vowel': 0.097195, 'loss_consonant': 0.072341}\n",
      "   67 | 0.000229 | 160512/160596 | 3.3833 | 2.7648 |\n",
      "val: {'recall': 0.993717, 'recall_grapheme': 0.991293, 'recall_vowel': 0.995696, 'recall_consonant': 0.996587, 'acc_grapheme': 0.992173, 'acc_vowel': 0.996645, 'acc_consonant': 0.99672, 'loss_grapheme': 0.130125, 'loss_vowel': 0.121195, 'loss_consonant': 0.089604}\n",
      "   68 | 0.000225 | 160512/160596 | 3.2145 | 2.7162 |\n",
      "val: {'recall': 0.994835, 'recall_grapheme': 0.99299, 'recall_vowel': 0.996563, 'recall_consonant': 0.996797, 'acc_grapheme': 0.99349, 'acc_vowel': 0.997142, 'acc_consonant': 0.997391, 'loss_grapheme': 0.104761, 'loss_vowel': 0.091868, 'loss_consonant': 0.067028}\n",
      "   69 | 0.000221 | 160512/160596 | 3.6621 | 2.6856 |\n",
      "val: {'recall': 0.991073, 'recall_grapheme': 0.98792, 'recall_vowel': 0.994326, 'recall_consonant': 0.994124, 'acc_grapheme': 0.989166, 'acc_vowel': 0.995328, 'acc_consonant': 0.995378, 'loss_grapheme': 0.140414, 'loss_vowel': 0.134982, 'loss_consonant': 0.095372}\n",
      "   70 | 0.000217 | 160512/160596 | 3.1710 | 2.7834 |\n",
      "val: {'recall': 0.993904, 'recall_grapheme': 0.991694, 'recall_vowel': 0.996439, 'recall_consonant': 0.995788, 'acc_grapheme': 0.992769, 'acc_vowel': 0.997217, 'acc_consonant': 0.996695, 'loss_grapheme': 0.099563, 'loss_vowel': 0.085563, 'loss_consonant': 0.070409}\n",
      "   71 | 0.000213 | 160512/160596 | 3.1551 | 2.6589 |\n",
      "val: {'recall': 0.994399, 'recall_grapheme': 0.992275, 'recall_vowel': 0.996667, 'recall_consonant': 0.996378, 'acc_grapheme': 0.992744, 'acc_vowel': 0.997167, 'acc_consonant': 0.997043, 'loss_grapheme': 0.10548, 'loss_vowel': 0.102485, 'loss_consonant': 0.073064}\n",
      "   72 | 0.000208 | 160512/160596 | 3.6078 | 2.7248 |\n",
      "val: {'recall': 0.994718, 'recall_grapheme': 0.993061, 'recall_vowel': 0.996871, 'recall_consonant': 0.995882, 'acc_grapheme': 0.993142, 'acc_vowel': 0.997416, 'acc_consonant': 0.997167, 'loss_grapheme': 0.086518, 'loss_vowel': 0.069713, 'loss_consonant': 0.055815}\n",
      "   73 | 0.000204 | 160512/160596 | 2.7186 | 2.6747 |\n",
      "val: {'recall': 0.993526, 'recall_grapheme': 0.990766, 'recall_vowel': 0.996167, 'recall_consonant': 0.996406, 'acc_grapheme': 0.991079, 'acc_vowel': 0.996621, 'acc_consonant': 0.99667, 'loss_grapheme': 0.121031, 'loss_vowel': 0.110234, 'loss_consonant': 0.080762}\n",
      "   74 | 0.000200 | 160512/160596 | 3.4359 | 2.6367 |\n",
      "val: {'recall': 0.995702, 'recall_grapheme': 0.994281, 'recall_vowel': 0.997157, 'recall_consonant': 0.997087, 'acc_grapheme': 0.994384, 'acc_vowel': 0.997441, 'acc_consonant': 0.997938, 'loss_grapheme': 0.120268, 'loss_vowel': 0.106266, 'loss_consonant': 0.079106}\n",
      "   75 | 0.000196 | 160512/160596 | 3.5617 | 2.7300 |\n",
      "val: {'recall': 0.994636, 'recall_grapheme': 0.992417, 'recall_vowel': 0.996444, 'recall_consonant': 0.997266, 'acc_grapheme': 0.993192, 'acc_vowel': 0.997068, 'acc_consonant': 0.997018, 'loss_grapheme': 0.093236, 'loss_vowel': 0.081787, 'loss_consonant': 0.064751}\n",
      "   76 | 0.000192 | 160512/160596 | 2.4210 | 2.7144 |\n",
      "val: {'recall': 0.99385, 'recall_grapheme': 0.99151, 'recall_vowel': 0.996953, 'recall_consonant': 0.995427, 'acc_grapheme': 0.992421, 'acc_vowel': 0.997167, 'acc_consonant': 0.996919, 'loss_grapheme': 0.107241, 'loss_vowel': 0.087986, 'loss_consonant': 0.071093}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 | 0.000187 | 160512/160596 | 3.4715 | 2.7270 |\n",
      "val: {'recall': 0.994451, 'recall_grapheme': 0.992321, 'recall_vowel': 0.996411, 'recall_consonant': 0.996752, 'acc_grapheme': 0.992595, 'acc_vowel': 0.997043, 'acc_consonant': 0.997068, 'loss_grapheme': 0.10043, 'loss_vowel': 0.083092, 'loss_consonant': 0.068987}\n",
      "   78 | 0.000183 | 160512/160596 | 2.7104 | 2.5906 |\n",
      "val: {'recall': 0.993042, 'recall_grapheme': 0.990616, 'recall_vowel': 0.99526, 'recall_consonant': 0.995675, 'acc_grapheme': 0.991552, 'acc_vowel': 0.996621, 'acc_consonant': 0.996273, 'loss_grapheme': 0.075243, 'loss_vowel': 0.0668, 'loss_consonant': 0.054329}\n",
      "   79 | 0.000179 | 160512/160596 | 3.0923 | 2.6513 |\n",
      "val: {'recall': 0.995421, 'recall_grapheme': 0.993855, 'recall_vowel': 0.996793, 'recall_consonant': 0.997182, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997565, 'acc_consonant': 0.997913, 'loss_grapheme': 0.099417, 'loss_vowel': 0.084683, 'loss_consonant': 0.062864}\n",
      "   80 | 0.000175 | 160512/160596 | 3.1681 | 2.5949 |\n",
      "val: {'recall': 0.994872, 'recall_grapheme': 0.993338, 'recall_vowel': 0.997035, 'recall_consonant': 0.995776, 'acc_grapheme': 0.993862, 'acc_vowel': 0.997813, 'acc_consonant': 0.997639, 'loss_grapheme': 0.08413, 'loss_vowel': 0.060005, 'loss_consonant': 0.053361}\n",
      "   81 | 0.000171 | 160512/160596 | 2.8381 | 2.6696 |\n",
      "val: {'recall': 0.994405, 'recall_grapheme': 0.992801, 'recall_vowel': 0.996614, 'recall_consonant': 0.995404, 'acc_grapheme': 0.993192, 'acc_vowel': 0.997192, 'acc_consonant': 0.997366, 'loss_grapheme': 0.107133, 'loss_vowel': 0.093339, 'loss_consonant': 0.068454}\n",
      "   82 | 0.000167 | 160512/160596 | 2.8130 | 2.6758 |\n",
      "val: {'recall': 0.993244, 'recall_grapheme': 0.991427, 'recall_vowel': 0.994943, 'recall_consonant': 0.99518, 'acc_grapheme': 0.99185, 'acc_vowel': 0.996322, 'acc_consonant': 0.996198, 'loss_grapheme': 0.078102, 'loss_vowel': 0.072919, 'loss_consonant': 0.05833}\n",
      "   83 | 0.000163 | 160512/160596 | 3.6563 | 2.6931 |\n",
      "val: {'recall': 0.994332, 'recall_grapheme': 0.992027, 'recall_vowel': 0.996136, 'recall_consonant': 0.99714, 'acc_grapheme': 0.992521, 'acc_vowel': 0.996447, 'acc_consonant': 0.996968, 'loss_grapheme': 0.086983, 'loss_vowel': 0.075866, 'loss_consonant': 0.05904}\n",
      "   84 | 0.000158 | 160512/160596 | 3.5530 | 2.6441 |\n",
      "val: {'recall': 0.99532, 'recall_grapheme': 0.994102, 'recall_vowel': 0.997607, 'recall_consonant': 0.995469, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997938, 'acc_consonant': 0.998186, 'loss_grapheme': 0.109264, 'loss_vowel': 0.093232, 'loss_consonant': 0.069734}\n",
      "   85 | 0.000154 | 160512/160596 | 1.2262 | 2.6680 |\n",
      "val: {'recall': 0.995085, 'recall_grapheme': 0.993272, 'recall_vowel': 0.99684, 'recall_consonant': 0.996956, 'acc_grapheme': 0.99349, 'acc_vowel': 0.997366, 'acc_consonant': 0.997565, 'loss_grapheme': 0.09048, 'loss_vowel': 0.069201, 'loss_consonant': 0.056402}\n",
      "   86 | 0.000150 | 160512/160596 | 0.3932 | 2.6813 |\n",
      "val: {'recall': 0.995281, 'recall_grapheme': 0.993696, 'recall_vowel': 0.997709, 'recall_consonant': 0.996023, 'acc_grapheme': 0.994061, 'acc_vowel': 0.998012, 'acc_consonant': 0.997938, 'loss_grapheme': 0.112518, 'loss_vowel': 0.092623, 'loss_consonant': 0.066801}\n",
      "   87 | 0.000146 | 160512/160596 | 1.6294 | 2.5864 |\n",
      "val: {'recall': 0.995766, 'recall_grapheme': 0.994364, 'recall_vowel': 0.997169, 'recall_consonant': 0.997166, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997938, 'acc_consonant': 0.997664, 'loss_grapheme': 0.096586, 'loss_vowel': 0.081218, 'loss_consonant': 0.063006}\n",
      "   88 | 0.000142 | 160512/160596 | 3.4954 | 2.6380 |\n",
      "val: {'recall': 0.995067, 'recall_grapheme': 0.994003, 'recall_vowel': 0.996983, 'recall_consonant': 0.995278, 'acc_grapheme': 0.993862, 'acc_vowel': 0.997913, 'acc_consonant': 0.99749, 'loss_grapheme': 0.073998, 'loss_vowel': 0.062505, 'loss_consonant': 0.051092}\n",
      "   89 | 0.000138 | 160512/160596 | 3.3267 | 2.5805 |\n",
      "val: {'recall': 0.995064, 'recall_grapheme': 0.993344, 'recall_vowel': 0.997351, 'recall_consonant': 0.996217, 'acc_grapheme': 0.993838, 'acc_vowel': 0.997962, 'acc_consonant': 0.99759, 'loss_grapheme': 0.109432, 'loss_vowel': 0.093792, 'loss_consonant': 0.069196}\n",
      "   90 | 0.000134 | 160512/160596 | 2.3099 | 2.6515 |\n",
      "val: {'recall': 0.994819, 'recall_grapheme': 0.992878, 'recall_vowel': 0.997214, 'recall_consonant': 0.996307, 'acc_grapheme': 0.993092, 'acc_vowel': 0.997689, 'acc_consonant': 0.997416, 'loss_grapheme': 0.10212, 'loss_vowel': 0.090948, 'loss_consonant': 0.069984}\n",
      "   91 | 0.000130 | 160512/160596 | 2.7720 | 2.5830 |\n",
      "val: {'recall': 0.99479, 'recall_grapheme': 0.992704, 'recall_vowel': 0.997003, 'recall_consonant': 0.99675, 'acc_grapheme': 0.99349, 'acc_vowel': 0.99749, 'acc_consonant': 0.99754, 'loss_grapheme': 0.085615, 'loss_vowel': 0.073479, 'loss_consonant': 0.055918}\n",
      "   92 | 0.000126 | 160512/160596 | 3.0609 | 2.6892 |\n",
      "val: {'recall': 0.995515, 'recall_grapheme': 0.994001, 'recall_vowel': 0.99678, 'recall_consonant': 0.997277, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997565, 'acc_consonant': 0.997888, 'loss_grapheme': 0.110757, 'loss_vowel': 0.085138, 'loss_consonant': 0.06264}\n",
      "   93 | 0.000123 | 160512/160596 | 2.7490 | 2.6270 |\n",
      "val: {'recall': 0.99592, 'recall_grapheme': 0.994584, 'recall_vowel': 0.997352, 'recall_consonant': 0.997161, 'acc_grapheme': 0.994856, 'acc_vowel': 0.998012, 'acc_consonant': 0.997938, 'loss_grapheme': 0.082146, 'loss_vowel': 0.064981, 'loss_consonant': 0.04814}\n",
      "   94 | 0.000119 | 160512/160596 | 2.6486 | 2.6744 |\n",
      "val: {'recall': 0.995003, 'recall_grapheme': 0.9931, 'recall_vowel': 0.996935, 'recall_consonant': 0.996876, 'acc_grapheme': 0.993589, 'acc_vowel': 0.99749, 'acc_consonant': 0.997565, 'loss_grapheme': 0.071022, 'loss_vowel': 0.057555, 'loss_consonant': 0.049021}\n",
      "   95 | 0.000115 | 160512/160596 | 2.8035 | 2.6834 |\n",
      "val: {'recall': 0.995168, 'recall_grapheme': 0.993162, 'recall_vowel': 0.996829, 'recall_consonant': 0.997518, 'acc_grapheme': 0.993763, 'acc_vowel': 0.99759, 'acc_consonant': 0.997664, 'loss_grapheme': 0.089464, 'loss_vowel': 0.079986, 'loss_consonant': 0.061381}\n",
      "   96 | 0.000111 | 160512/160596 | 3.0004 | 2.6162 |\n",
      "val: {'recall': 0.995703, 'recall_grapheme': 0.993884, 'recall_vowel': 0.997436, 'recall_consonant': 0.997608, 'acc_grapheme': 0.99431, 'acc_vowel': 0.997962, 'acc_consonant': 0.997938, 'loss_grapheme': 0.109305, 'loss_vowel': 0.091128, 'loss_consonant': 0.065647}\n",
      "   97 | 0.000107 | 160512/160596 | 1.8492 | 2.5901 |\n",
      "val: {'recall': 0.994367, 'recall_grapheme': 0.992262, 'recall_vowel': 0.996967, 'recall_consonant': 0.995976, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997416, 'acc_consonant': 0.997267, 'loss_grapheme': 0.080562, 'loss_vowel': 0.063212, 'loss_consonant': 0.050632}\n",
      "   98 | 0.000104 | 160512/160596 | 3.0439 | 2.6036 |\n",
      "val: {'recall': 0.995262, 'recall_grapheme': 0.993421, 'recall_vowel': 0.997016, 'recall_consonant': 0.997189, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997565, 'acc_consonant': 0.997913, 'loss_grapheme': 0.102243, 'loss_vowel': 0.085764, 'loss_consonant': 0.064995}\n",
      "   99 | 0.000100 | 160512/160596 | 2.4800 | 2.6121 |\n",
      "val: {'recall': 0.995402, 'recall_grapheme': 0.993764, 'recall_vowel': 0.997053, 'recall_consonant': 0.997028, 'acc_grapheme': 0.99431, 'acc_vowel': 0.997764, 'acc_consonant': 0.998037, 'loss_grapheme': 0.08925, 'loss_vowel': 0.073581, 'loss_consonant': 0.055689}\n",
      "  100 | 0.000096 | 160512/160596 | 2.9042 | 2.6581 |\n",
      "val: {'recall': 0.995419, 'recall_grapheme': 0.993665, 'recall_vowel': 0.997256, 'recall_consonant': 0.997091, 'acc_grapheme': 0.994036, 'acc_vowel': 0.997863, 'acc_consonant': 0.997987, 'loss_grapheme': 0.072969, 'loss_vowel': 0.056173, 'loss_consonant': 0.046129}\n",
      "  101 | 0.000093 | 160512/160596 | 2.5890 | 2.6025 |\n",
      "val: {'recall': 0.995834, 'recall_grapheme': 0.994216, 'recall_vowel': 0.997653, 'recall_consonant': 0.997253, 'acc_grapheme': 0.994881, 'acc_vowel': 0.998112, 'acc_consonant': 0.998062, 'loss_grapheme': 0.096665, 'loss_vowel': 0.072081, 'loss_consonant': 0.059366}\n",
      "  102 | 0.000089 | 160512/160596 | 2.8451 | 2.6278 |\n",
      "val: {'recall': 0.995466, 'recall_grapheme': 0.993654, 'recall_vowel': 0.997631, 'recall_consonant': 0.996927, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997962, 'acc_consonant': 0.998161, 'loss_grapheme': 0.097812, 'loss_vowel': 0.080211, 'loss_consonant': 0.063829}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 0.000086 | 160512/160596 | 3.4126 | 2.5433 |\n",
      "val: {'recall': 0.995634, 'recall_grapheme': 0.994052, 'recall_vowel': 0.997288, 'recall_consonant': 0.997144, 'acc_grapheme': 0.994384, 'acc_vowel': 0.997888, 'acc_consonant': 0.997962, 'loss_grapheme': 0.092098, 'loss_vowel': 0.074394, 'loss_consonant': 0.058841}\n",
      "  104 | 0.000082 | 160512/160596 | 2.5624 | 2.6192 |\n",
      "val: {'recall': 0.994972, 'recall_grapheme': 0.993398, 'recall_vowel': 0.996869, 'recall_consonant': 0.996222, 'acc_grapheme': 0.99339, 'acc_vowel': 0.997515, 'acc_consonant': 0.997391, 'loss_grapheme': 0.072817, 'loss_vowel': 0.05912, 'loss_consonant': 0.051929}\n",
      "  105 | 0.000079 | 160512/160596 | 2.6586 | 2.6816 |\n",
      "val: {'recall': 0.995759, 'recall_grapheme': 0.99426, 'recall_vowel': 0.99754, 'recall_consonant': 0.996975, 'acc_grapheme': 0.994782, 'acc_vowel': 0.998211, 'acc_consonant': 0.998211, 'loss_grapheme': 0.093794, 'loss_vowel': 0.076679, 'loss_consonant': 0.056322}\n",
      "  106 | 0.000076 | 160512/160596 | 3.1646 | 2.6480 |\n",
      "val: {'recall': 0.995361, 'recall_grapheme': 0.993551, 'recall_vowel': 0.997526, 'recall_consonant': 0.996817, 'acc_grapheme': 0.994409, 'acc_vowel': 0.998012, 'acc_consonant': 0.998087, 'loss_grapheme': 0.080881, 'loss_vowel': 0.064584, 'loss_consonant': 0.050464}\n",
      "  107 | 0.000073 | 160512/160596 | 3.2449 | 2.5899 |\n",
      "val: {'recall': 0.995888, 'recall_grapheme': 0.994295, 'recall_vowel': 0.997602, 'recall_consonant': 0.997361, 'acc_grapheme': 0.994558, 'acc_vowel': 0.998062, 'acc_consonant': 0.998037, 'loss_grapheme': 0.09547, 'loss_vowel': 0.085683, 'loss_consonant': 0.061172}\n",
      "  108 | 0.000069 | 160512/160596 | 1.1623 | 2.5742 |\n",
      "val: {'recall': 0.995913, 'recall_grapheme': 0.994531, 'recall_vowel': 0.997632, 'recall_consonant': 0.996957, 'acc_grapheme': 0.994981, 'acc_vowel': 0.998186, 'acc_consonant': 0.998459, 'loss_grapheme': 0.101332, 'loss_vowel': 0.08287, 'loss_consonant': 0.061315}\n",
      "  109 | 0.000066 | 160512/160596 | 2.8579 | 2.6139 |\n",
      "val: {'recall': 0.995506, 'recall_grapheme': 0.99362, 'recall_vowel': 0.997446, 'recall_consonant': 0.997337, 'acc_grapheme': 0.994359, 'acc_vowel': 0.998112, 'acc_consonant': 0.998087, 'loss_grapheme': 0.08745, 'loss_vowel': 0.075832, 'loss_consonant': 0.058303}\n",
      "  110 | 0.000063 | 160512/160596 | 2.8768 | 2.4987 |\n",
      "val: {'recall': 0.995919, 'recall_grapheme': 0.994457, 'recall_vowel': 0.997509, 'recall_consonant': 0.997256, 'acc_grapheme': 0.994658, 'acc_vowel': 0.998037, 'acc_consonant': 0.997863, 'loss_grapheme': 0.089897, 'loss_vowel': 0.081583, 'loss_consonant': 0.061861}\n",
      "  111 | 0.000060 | 160512/160596 | 3.1760 | 2.5167 |\n",
      "val: {'recall': 0.995349, 'recall_grapheme': 0.993581, 'recall_vowel': 0.99707, 'recall_consonant': 0.997166, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997788, 'acc_consonant': 0.997838, 'loss_grapheme': 0.069836, 'loss_vowel': 0.057896, 'loss_consonant': 0.046747}\n",
      "  112 | 0.000057 | 160512/160596 | 2.1121 | 2.6398 |\n",
      "val: {'recall': 0.995815, 'recall_grapheme': 0.994159, 'recall_vowel': 0.997725, 'recall_consonant': 0.997215, 'acc_grapheme': 0.994285, 'acc_vowel': 0.997987, 'acc_consonant': 0.998012, 'loss_grapheme': 0.085069, 'loss_vowel': 0.070944, 'loss_consonant': 0.053687}\n",
      "  113 | 0.000054 | 160512/160596 | 3.5433 | 2.5360 |\n",
      "val: {'recall': 0.994698, 'recall_grapheme': 0.992726, 'recall_vowel': 0.996773, 'recall_consonant': 0.996565, 'acc_grapheme': 0.993216, 'acc_vowel': 0.99754, 'acc_consonant': 0.997341, 'loss_grapheme': 0.064534, 'loss_vowel': 0.049829, 'loss_consonant': 0.04509}\n",
      "  114 | 0.000051 | 160512/160596 | 0.8014 | 2.6169 |\n",
      "val: {'recall': 0.995546, 'recall_grapheme': 0.993966, 'recall_vowel': 0.997725, 'recall_consonant': 0.996528, 'acc_grapheme': 0.99426, 'acc_vowel': 0.998136, 'acc_consonant': 0.997913, 'loss_grapheme': 0.07461, 'loss_vowel': 0.054901, 'loss_consonant': 0.043306}\n",
      "  115 | 0.000049 | 160512/160596 | 2.1233 | 2.6171 |\n",
      "val: {'recall': 0.995949, 'recall_grapheme': 0.994466, 'recall_vowel': 0.997456, 'recall_consonant': 0.997406, 'acc_grapheme': 0.994732, 'acc_vowel': 0.998012, 'acc_consonant': 0.998211, 'loss_grapheme': 0.083315, 'loss_vowel': 0.063453, 'loss_consonant': 0.050349}\n",
      "  116 | 0.000046 | 160512/160596 | 2.6245 | 2.5399 |\n",
      "val: {'recall': 0.995587, 'recall_grapheme': 0.993995, 'recall_vowel': 0.997786, 'recall_consonant': 0.996574, 'acc_grapheme': 0.994409, 'acc_vowel': 0.998161, 'acc_consonant': 0.997962, 'loss_grapheme': 0.090928, 'loss_vowel': 0.077464, 'loss_consonant': 0.059219}\n",
      "  117 | 0.000043 | 160512/160596 | 3.3819 | 2.6356 |\n",
      "val: {'recall': 0.994592, 'recall_grapheme': 0.992564, 'recall_vowel': 0.997209, 'recall_consonant': 0.99603, 'acc_grapheme': 0.992943, 'acc_vowel': 0.997739, 'acc_consonant': 0.997267, 'loss_grapheme': 0.071164, 'loss_vowel': 0.059159, 'loss_consonant': 0.048802}\n",
      "  118 | 0.000041 | 160512/160596 | 3.3336 | 2.5574 |\n",
      "val: {'recall': 0.995205, 'recall_grapheme': 0.993279, 'recall_vowel': 0.997714, 'recall_consonant': 0.996549, 'acc_grapheme': 0.993813, 'acc_vowel': 0.997938, 'acc_consonant': 0.997764, 'loss_grapheme': 0.087149, 'loss_vowel': 0.072581, 'loss_consonant': 0.055554}\n",
      "  119 | 0.000038 | 160512/160596 | 2.9460 | 2.5166 |\n",
      "val: {'recall': 0.995998, 'recall_grapheme': 0.994396, 'recall_vowel': 0.997962, 'recall_consonant': 0.997236, 'acc_grapheme': 0.994583, 'acc_vowel': 0.998211, 'acc_consonant': 0.998012, 'loss_grapheme': 0.081199, 'loss_vowel': 0.067335, 'loss_consonant': 0.051653}\n",
      "  120 | 0.000036 | 160512/160596 | 2.8632 | 2.5743 |\n",
      "val: {'recall': 0.994596, 'recall_grapheme': 0.99271, 'recall_vowel': 0.996823, 'recall_consonant': 0.996142, 'acc_grapheme': 0.99344, 'acc_vowel': 0.997664, 'acc_consonant': 0.99754, 'loss_grapheme': 0.055232, 'loss_vowel': 0.041984, 'loss_consonant': 0.035051}\n",
      "  121 | 0.000033 | 160512/160596 | 2.1853 | 2.4916 |\n",
      "val: {'recall': 0.994554, 'recall_grapheme': 0.99291, 'recall_vowel': 0.996682, 'recall_consonant': 0.995713, 'acc_grapheme': 0.993316, 'acc_vowel': 0.99759, 'acc_consonant': 0.997142, 'loss_grapheme': 0.048509, 'loss_vowel': 0.039726, 'loss_consonant': 0.034793}\n",
      "  122 | 0.000031 | 160512/160596 | 3.3160 | 2.5484 |\n",
      "val: {'recall': 0.994856, 'recall_grapheme': 0.992983, 'recall_vowel': 0.997306, 'recall_consonant': 0.996152, 'acc_grapheme': 0.993564, 'acc_vowel': 0.997764, 'acc_consonant': 0.997465, 'loss_grapheme': 0.068927, 'loss_vowel': 0.059277, 'loss_consonant': 0.047098}\n",
      "  123 | 0.000029 | 160512/160596 | 3.2132 | 2.5337 |\n",
      "val: {'recall': 0.996315, 'recall_grapheme': 0.994926, 'recall_vowel': 0.997997, 'recall_consonant': 0.997409, 'acc_grapheme': 0.995254, 'acc_vowel': 0.998261, 'acc_consonant': 0.998385, 'loss_grapheme': 0.086899, 'loss_vowel': 0.075181, 'loss_consonant': 0.05642}\n",
      "  124 | 0.000027 | 160512/160596 | 2.5241 | 2.4684 |\n",
      "val: {'recall': 0.995373, 'recall_grapheme': 0.993781, 'recall_vowel': 0.997385, 'recall_consonant': 0.996543, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997987, 'acc_consonant': 0.997863, 'loss_grapheme': 0.069532, 'loss_vowel': 0.057043, 'loss_consonant': 0.044622}\n",
      "  125 | 0.000025 | 160512/160596 | 1.3524 | 2.5361 |\n",
      "val: {'recall': 0.996365, 'recall_grapheme': 0.995025, 'recall_vowel': 0.997903, 'recall_consonant': 0.997507, 'acc_grapheme': 0.995304, 'acc_vowel': 0.998261, 'acc_consonant': 0.998435, 'loss_grapheme': 0.080082, 'loss_vowel': 0.064785, 'loss_consonant': 0.048041}\n",
      "  126 | 0.000023 | 160512/160596 | 1.6247 | 2.5775 |\n",
      "val: {'recall': 0.995216, 'recall_grapheme': 0.993264, 'recall_vowel': 0.997366, 'recall_consonant': 0.99697, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997888, 'acc_consonant': 0.997764, 'loss_grapheme': 0.066645, 'loss_vowel': 0.056738, 'loss_consonant': 0.04347}\n",
      "  127 | 0.000021 | 160512/160596 | 2.7859 | 2.4866 |\n",
      "val: {'recall': 0.994719, 'recall_grapheme': 0.992951, 'recall_vowel': 0.996932, 'recall_consonant': 0.996042, 'acc_grapheme': 0.993018, 'acc_vowel': 0.997714, 'acc_consonant': 0.997242, 'loss_grapheme': 0.063221, 'loss_vowel': 0.05193, 'loss_consonant': 0.043131}\n",
      "  128 | 0.000019 | 160512/160596 | 2.9764 | 2.6006 |\n",
      "val: {'recall': 0.995552, 'recall_grapheme': 0.993985, 'recall_vowel': 0.997555, 'recall_consonant': 0.996682, 'acc_grapheme': 0.994384, 'acc_vowel': 0.998012, 'acc_consonant': 0.997938, 'loss_grapheme': 0.086288, 'loss_vowel': 0.074944, 'loss_consonant': 0.056003}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  129 | 0.000017 | 160512/160596 | 2.8139 | 2.5360 |\n",
      "val: {'recall': 0.99589, 'recall_grapheme': 0.994318, 'recall_vowel': 0.997794, 'recall_consonant': 0.997128, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998087, 'acc_consonant': 0.998012, 'loss_grapheme': 0.084292, 'loss_vowel': 0.070467, 'loss_consonant': 0.054091}\n",
      "  130 | 0.000016 | 160512/160596 | 2.5479 | 2.6107 |\n",
      "val: {'recall': 0.995545, 'recall_grapheme': 0.99391, 'recall_vowel': 0.997492, 'recall_consonant': 0.996867, 'acc_grapheme': 0.994409, 'acc_vowel': 0.998112, 'acc_consonant': 0.998161, 'loss_grapheme': 0.08089, 'loss_vowel': 0.069069, 'loss_consonant': 0.051299}\n",
      "  131 | 0.000014 | 160512/160596 | 0.6234 | 2.5317 |\n",
      "val: {'recall': 0.995621, 'recall_grapheme': 0.99387, 'recall_vowel': 0.997379, 'recall_consonant': 0.997367, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997938, 'acc_consonant': 0.998062, 'loss_grapheme': 0.083018, 'loss_vowel': 0.068858, 'loss_consonant': 0.051825}\n",
      "  132 | 0.000013 | 160512/160596 | 3.1110 | 2.5151 |\n",
      "val: {'recall': 0.995059, 'recall_grapheme': 0.993427, 'recall_vowel': 0.997178, 'recall_consonant': 0.996204, 'acc_grapheme': 0.993738, 'acc_vowel': 0.997788, 'acc_consonant': 0.997366, 'loss_grapheme': 0.073594, 'loss_vowel': 0.061502, 'loss_consonant': 0.049507}\n",
      "  133 | 0.000011 | 160512/160596 | 2.8781 | 2.6498 |\n",
      "val: {'recall': 0.99544, 'recall_grapheme': 0.993988, 'recall_vowel': 0.997222, 'recall_consonant': 0.996563, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997938, 'acc_consonant': 0.997888, 'loss_grapheme': 0.074355, 'loss_vowel': 0.062638, 'loss_consonant': 0.049974}\n",
      "  134 | 0.000010 | 160512/160596 | 2.5820 | 2.6001 |\n",
      "val: {'recall': 0.995467, 'recall_grapheme': 0.993972, 'recall_vowel': 0.997396, 'recall_consonant': 0.996529, 'acc_grapheme': 0.994384, 'acc_vowel': 0.998112, 'acc_consonant': 0.997863, 'loss_grapheme': 0.073687, 'loss_vowel': 0.060511, 'loss_consonant': 0.048332}\n",
      "  135 | 0.000009 | 160512/160596 | 1.8162 | 2.4360 |\n",
      "val: {'recall': 0.995575, 'recall_grapheme': 0.994133, 'recall_vowel': 0.997404, 'recall_consonant': 0.996631, 'acc_grapheme': 0.994484, 'acc_vowel': 0.998087, 'acc_consonant': 0.997813, 'loss_grapheme': 0.07651, 'loss_vowel': 0.065932, 'loss_consonant': 0.051159}\n",
      "  136 | 0.000007 | 160512/160596 | 2.6296 | 2.5300 |\n",
      "val: {'recall': 0.995655, 'recall_grapheme': 0.99414, 'recall_vowel': 0.997599, 'recall_consonant': 0.996743, 'acc_grapheme': 0.994359, 'acc_vowel': 0.998161, 'acc_consonant': 0.998012, 'loss_grapheme': 0.069412, 'loss_vowel': 0.056452, 'loss_consonant': 0.045429}\n",
      "  137 | 0.000006 | 160512/160596 | 3.0830 | 2.5003 |\n",
      "val: {'recall': 0.995383, 'recall_grapheme': 0.993836, 'recall_vowel': 0.997494, 'recall_consonant': 0.996367, 'acc_grapheme': 0.994161, 'acc_vowel': 0.998062, 'acc_consonant': 0.997764, 'loss_grapheme': 0.069209, 'loss_vowel': 0.054203, 'loss_consonant': 0.044044}\n",
      "  138 | 0.000005 | 160512/160596 | 2.9111 | 2.5338 |\n",
      "val: {'recall': 0.99551, 'recall_grapheme': 0.993975, 'recall_vowel': 0.997464, 'recall_consonant': 0.996626, 'acc_grapheme': 0.994384, 'acc_vowel': 0.998062, 'acc_consonant': 0.997962, 'loss_grapheme': 0.08518, 'loss_vowel': 0.072587, 'loss_consonant': 0.056406}\n",
      "  139 | 0.000004 | 160512/160596 | 2.6521 | 2.5417 |\n",
      "val: {'recall': 0.99555, 'recall_grapheme': 0.994014, 'recall_vowel': 0.997504, 'recall_consonant': 0.996667, 'acc_grapheme': 0.994285, 'acc_vowel': 0.998012, 'acc_consonant': 0.997863, 'loss_grapheme': 0.070219, 'loss_vowel': 0.057617, 'loss_consonant': 0.046811}\n",
      "  140 | 0.000004 | 160512/160596 | 2.6249 | 2.4540 |\n",
      "val: {'recall': 0.995865, 'recall_grapheme': 0.994543, 'recall_vowel': 0.99765, 'recall_consonant': 0.996723, 'acc_grapheme': 0.994832, 'acc_vowel': 0.998161, 'acc_consonant': 0.998161, 'loss_grapheme': 0.073789, 'loss_vowel': 0.059866, 'loss_consonant': 0.046525}\n",
      "  141 | 0.000003 | 160512/160596 | 3.2642 | 2.5858 |\n",
      "val: {'recall': 0.995324, 'recall_grapheme': 0.99371, 'recall_vowel': 0.997354, 'recall_consonant': 0.996522, 'acc_grapheme': 0.994136, 'acc_vowel': 0.998012, 'acc_consonant': 0.997714, 'loss_grapheme': 0.072719, 'loss_vowel': 0.060128, 'loss_consonant': 0.049209}\n",
      "  142 | 0.000002 | 160512/160596 | 1.1455 | 2.4948 |\n",
      "val: {'recall': 0.995915, 'recall_grapheme': 0.994535, 'recall_vowel': 0.997706, 'recall_consonant': 0.996884, 'acc_grapheme': 0.994881, 'acc_vowel': 0.998186, 'acc_consonant': 0.998236, 'loss_grapheme': 0.088431, 'loss_vowel': 0.074547, 'loss_consonant': 0.056087}\n",
      "  143 | 0.000002 | 160512/160596 | 3.4009 | 2.5429 |\n",
      "val: {'recall': 0.995886, 'recall_grapheme': 0.994512, 'recall_vowel': 0.997654, 'recall_consonant': 0.996867, 'acc_grapheme': 0.994757, 'acc_vowel': 0.998261, 'acc_consonant': 0.998186, 'loss_grapheme': 0.081855, 'loss_vowel': 0.067402, 'loss_consonant': 0.052368}\n",
      "  144 | 0.000001 | 160512/160596 | 2.6605 | 2.4985 |\n",
      "val: {'recall': 0.995519, 'recall_grapheme': 0.994029, 'recall_vowel': 0.997366, 'recall_consonant': 0.996652, 'acc_grapheme': 0.99426, 'acc_vowel': 0.998062, 'acc_consonant': 0.997962, 'loss_grapheme': 0.0785, 'loss_vowel': 0.065764, 'loss_consonant': 0.053129}\n",
      "  145 | 0.000001 | 160512/160596 | 2.7986 | 2.4764 |\n",
      "val: {'recall': 0.99604, 'recall_grapheme': 0.99475, 'recall_vowel': 0.997857, 'recall_consonant': 0.996805, 'acc_grapheme': 0.994931, 'acc_vowel': 0.998236, 'acc_consonant': 0.998186, 'loss_grapheme': 0.070161, 'loss_vowel': 0.052213, 'loss_consonant': 0.0419}\n",
      "  146 | 0.000000 | 160512/160596 | 3.1251 | 2.4997 |\n",
      "val: {'recall': 0.995561, 'recall_grapheme': 0.993912, 'recall_vowel': 0.997613, 'recall_consonant': 0.996805, 'acc_grapheme': 0.99421, 'acc_vowel': 0.998161, 'acc_consonant': 0.998012, 'loss_grapheme': 0.079532, 'loss_vowel': 0.065047, 'loss_consonant': 0.051482}\n",
      "  147 | 0.000000 | 160512/160596 | 2.4057 | 2.5627 |\n",
      "val: {'recall': 0.995564, 'recall_grapheme': 0.994052, 'recall_vowel': 0.997623, 'recall_consonant': 0.996529, 'acc_grapheme': 0.994285, 'acc_vowel': 0.998186, 'acc_consonant': 0.997863, 'loss_grapheme': 0.069687, 'loss_vowel': 0.056234, 'loss_consonant': 0.045711}\n",
      "  148 | 0.000000 | 160512/160596 | 2.3057 | 2.5075 |\n",
      "val: {'recall': 0.995721, 'recall_grapheme': 0.994404, 'recall_vowel': 0.997441, 'recall_consonant': 0.996634, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998136, 'acc_consonant': 0.997987, 'loss_grapheme': 0.064661, 'loss_vowel': 0.049853, 'loss_consonant': 0.041149}\n",
      "  149 | 0.000000 | 160512/160596 | 2.0749 | 2.5204 |\n",
      "val: {'recall': 0.995998, 'recall_grapheme': 0.994591, 'recall_vowel': 0.997912, 'recall_consonant': 0.996899, 'acc_grapheme': 0.99503, 'acc_vowel': 0.998211, 'acc_consonant': 0.998285, 'loss_grapheme': 0.082582, 'loss_vowel': 0.070479, 'loss_consonant': 0.051086}\n",
      "CYCLE: 2\n",
      "{'recall': 0.995998, 'recall_grapheme': 0.994591, 'recall_vowel': 0.997912, 'recall_consonant': 0.996899, 'acc_grapheme': 0.99503, 'acc_vowel': 0.998211, 'acc_consonant': 0.998285, 'loss_grapheme': 0.082582, 'loss_vowel': 0.070479, 'loss_consonant': 0.051086}\n",
      "    0 | 0.000040 | 160512/160596 | 2.7217 | 2.5038 |\n",
      "val: {'recall': 0.995472, 'recall_grapheme': 0.993833, 'recall_vowel': 0.99748, 'recall_consonant': 0.996742, 'acc_grapheme': 0.994136, 'acc_vowel': 0.998136, 'acc_consonant': 0.997962, 'loss_grapheme': 0.083918, 'loss_vowel': 0.068123, 'loss_consonant': 0.054001}\n",
      "    1 | 0.000080 | 160512/160596 | 2.3356 | 2.4746 |\n",
      "val: {'recall': 0.995439, 'recall_grapheme': 0.993978, 'recall_vowel': 0.997723, 'recall_consonant': 0.996077, 'acc_grapheme': 0.994384, 'acc_vowel': 0.998161, 'acc_consonant': 0.998211, 'loss_grapheme': 0.082421, 'loss_vowel': 0.06863, 'loss_consonant': 0.051453}\n",
      "    2 | 0.000120 | 160512/160596 | 2.8661 | 2.4812 |\n",
      "val: {'recall': 0.99594, 'recall_grapheme': 0.994312, 'recall_vowel': 0.997777, 'recall_consonant': 0.997358, 'acc_grapheme': 0.994881, 'acc_vowel': 0.998087, 'acc_consonant': 0.998112, 'loss_grapheme': 0.091291, 'loss_vowel': 0.081118, 'loss_consonant': 0.059098}\n",
      "    3 | 0.000160 | 160512/160596 | 3.1287 | 2.5788 |\n",
      "val: {'recall': 0.9933, 'recall_grapheme': 0.990944, 'recall_vowel': 0.996391, 'recall_consonant': 0.994922, 'acc_grapheme': 0.991626, 'acc_vowel': 0.996919, 'acc_consonant': 0.996397, 'loss_grapheme': 0.103281, 'loss_vowel': 0.096074, 'loss_consonant': 0.07557}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 | 0.000199 | 160512/160596 | 3.2430 | 2.6409 |\n",
      "val: {'recall': 0.994975, 'recall_grapheme': 0.992926, 'recall_vowel': 0.997233, 'recall_consonant': 0.996815, 'acc_grapheme': 0.993564, 'acc_vowel': 0.997863, 'acc_consonant': 0.997813, 'loss_grapheme': 0.097662, 'loss_vowel': 0.077484, 'loss_consonant': 0.065074}\n",
      "    5 | 0.000239 | 160512/160596 | 3.4410 | 2.6784 |\n",
      "val: {'recall': 0.9944, 'recall_grapheme': 0.992229, 'recall_vowel': 0.996443, 'recall_consonant': 0.996701, 'acc_grapheme': 0.992918, 'acc_vowel': 0.997093, 'acc_consonant': 0.997465, 'loss_grapheme': 0.102694, 'loss_vowel': 0.078459, 'loss_consonant': 0.060353}\n",
      "    6 | 0.000278 | 160512/160596 | 3.3723 | 2.6678 |\n",
      "val: {'recall': 0.993575, 'recall_grapheme': 0.991454, 'recall_vowel': 0.995752, 'recall_consonant': 0.995637, 'acc_grapheme': 0.991825, 'acc_vowel': 0.996944, 'acc_consonant': 0.99672, 'loss_grapheme': 0.079037, 'loss_vowel': 0.064861, 'loss_consonant': 0.055288}\n",
      "    7 | 0.000318 | 160512/160596 | 1.9315 | 2.6789 |\n",
      "val: {'recall': 0.994887, 'recall_grapheme': 0.99298, 'recall_vowel': 0.997155, 'recall_consonant': 0.996433, 'acc_grapheme': 0.993192, 'acc_vowel': 0.997689, 'acc_consonant': 0.99759, 'loss_grapheme': 0.134221, 'loss_vowel': 0.116989, 'loss_consonant': 0.082052}\n",
      "    8 | 0.000357 | 160512/160596 | 1.8471 | 2.6339 |\n",
      "val: {'recall': 0.995679, 'recall_grapheme': 0.994414, 'recall_vowel': 0.997453, 'recall_consonant': 0.996436, 'acc_grapheme': 0.994608, 'acc_vowel': 0.997788, 'acc_consonant': 0.998136, 'loss_grapheme': 0.143584, 'loss_vowel': 0.118373, 'loss_consonant': 0.079149}\n",
      "    9 | 0.000395 | 160512/160596 | 2.6650 | 2.6492 |\n",
      "val: {'recall': 0.994409, 'recall_grapheme': 0.992932, 'recall_vowel': 0.996245, 'recall_consonant': 0.995527, 'acc_grapheme': 0.993515, 'acc_vowel': 0.99754, 'acc_consonant': 0.99749, 'loss_grapheme': 0.116457, 'loss_vowel': 0.086394, 'loss_consonant': 0.06159}\n",
      "   10 | 0.000395 | 160512/160596 | 0.4566 | 2.7562 |\n",
      "val: {'recall': 0.991907, 'recall_grapheme': 0.988238, 'recall_vowel': 0.995197, 'recall_consonant': 0.995956, 'acc_grapheme': 0.989116, 'acc_vowel': 0.994583, 'acc_consonant': 0.996248, 'loss_grapheme': 0.109887, 'loss_vowel': 0.086489, 'loss_consonant': 0.063686}\n",
      "   11 | 0.000394 | 160512/160596 | 2.1568 | 2.6695 |\n",
      "val: {'recall': 0.992449, 'recall_grapheme': 0.990214, 'recall_vowel': 0.995436, 'recall_consonant': 0.993932, 'acc_grapheme': 0.991005, 'acc_vowel': 0.995602, 'acc_consonant': 0.99595, 'loss_grapheme': 0.066681, 'loss_vowel': 0.050289, 'loss_consonant': 0.045331}\n",
      "   12 | 0.000393 | 160512/160596 | 2.8170 | 2.6743 |\n",
      "val: {'recall': 0.99429, 'recall_grapheme': 0.991808, 'recall_vowel': 0.996103, 'recall_consonant': 0.997441, 'acc_grapheme': 0.992471, 'acc_vowel': 0.996944, 'acc_consonant': 0.997714, 'loss_grapheme': 0.124346, 'loss_vowel': 0.101169, 'loss_consonant': 0.071879}\n",
      "   13 | 0.000391 | 160512/160596 | 3.7093 | 2.7337 |\n",
      "val: {'recall': 0.99216, 'recall_grapheme': 0.990752, 'recall_vowel': 0.995515, 'recall_consonant': 0.991621, 'acc_grapheme': 0.990732, 'acc_vowel': 0.996347, 'acc_consonant': 0.996148, 'loss_grapheme': 0.078446, 'loss_vowel': 0.060728, 'loss_consonant': 0.057775}\n",
      "   14 | 0.000390 | 160512/160596 | 3.0242 | 2.7736 |\n",
      "val: {'recall': 0.991083, 'recall_grapheme': 0.989545, 'recall_vowel': 0.993879, 'recall_consonant': 0.991364, 'acc_grapheme': 0.989489, 'acc_vowel': 0.995353, 'acc_consonant': 0.995055, 'loss_grapheme': 0.068497, 'loss_vowel': 0.056967, 'loss_consonant': 0.04963}\n",
      "   15 | 0.000389 | 160512/160596 | 3.1827 | 2.7430 |\n",
      "val: {'recall': 0.991982, 'recall_grapheme': 0.990089, 'recall_vowel': 0.994458, 'recall_consonant': 0.993293, 'acc_grapheme': 0.990533, 'acc_vowel': 0.994956, 'acc_consonant': 0.995652, 'loss_grapheme': 0.089206, 'loss_vowel': 0.080078, 'loss_consonant': 0.062086}\n",
      "   16 | 0.000387 | 160512/160596 | 3.4127 | 2.7280 |\n",
      "val: {'recall': 0.994109, 'recall_grapheme': 0.991566, 'recall_vowel': 0.996781, 'recall_consonant': 0.996525, 'acc_grapheme': 0.9918, 'acc_vowel': 0.996645, 'acc_consonant': 0.997391, 'loss_grapheme': 0.115495, 'loss_vowel': 0.086069, 'loss_consonant': 0.06358}\n",
      "   17 | 0.000386 | 160512/160596 | 2.9920 | 2.7897 |\n",
      "val: {'recall': 0.992546, 'recall_grapheme': 0.989838, 'recall_vowel': 0.995847, 'recall_consonant': 0.994661, 'acc_grapheme': 0.991303, 'acc_vowel': 0.996447, 'acc_consonant': 0.996844, 'loss_grapheme': 0.090782, 'loss_vowel': 0.07522, 'loss_consonant': 0.05687}\n",
      "   18 | 0.000384 | 160512/160596 | 1.0853 | 2.6743 |\n",
      "val: {'recall': 0.995334, 'recall_grapheme': 0.993528, 'recall_vowel': 0.997746, 'recall_consonant': 0.996533, 'acc_grapheme': 0.994061, 'acc_vowel': 0.998087, 'acc_consonant': 0.997739, 'loss_grapheme': 0.078299, 'loss_vowel': 0.062509, 'loss_consonant': 0.043863}\n",
      "   19 | 0.000383 | 160512/160596 | 2.7449 | 2.7913 |\n",
      "val: {'recall': 0.995674, 'recall_grapheme': 0.994096, 'recall_vowel': 0.997692, 'recall_consonant': 0.996813, 'acc_grapheme': 0.995204, 'acc_vowel': 0.997888, 'acc_consonant': 0.998435, 'loss_grapheme': 0.101088, 'loss_vowel': 0.069972, 'loss_consonant': 0.053667}\n",
      "   20 | 0.000381 | 160512/160596 | 3.4395 | 2.7431 |\n",
      "val: {'recall': 0.994357, 'recall_grapheme': 0.992562, 'recall_vowel': 0.996466, 'recall_consonant': 0.995838, 'acc_grapheme': 0.993092, 'acc_vowel': 0.997068, 'acc_consonant': 0.997391, 'loss_grapheme': 0.103054, 'loss_vowel': 0.084101, 'loss_consonant': 0.059331}\n",
      "   21 | 0.000379 | 160512/160596 | 2.7985 | 2.7248 |\n",
      "val: {'recall': 0.991487, 'recall_grapheme': 0.988971, 'recall_vowel': 0.995695, 'recall_consonant': 0.99231, 'acc_grapheme': 0.989589, 'acc_vowel': 0.996148, 'acc_consonant': 0.99585, 'loss_grapheme': 0.09531, 'loss_vowel': 0.072927, 'loss_consonant': 0.055147}\n",
      "   22 | 0.000377 | 160512/160596 | 2.3639 | 2.6803 |\n",
      "val: {'recall': 0.993491, 'recall_grapheme': 0.991643, 'recall_vowel': 0.996153, 'recall_consonant': 0.994524, 'acc_grapheme': 0.9918, 'acc_vowel': 0.99667, 'acc_consonant': 0.996596, 'loss_grapheme': 0.066363, 'loss_vowel': 0.049977, 'loss_consonant': 0.040229}\n",
      "   23 | 0.000375 | 160512/160596 | 3.4675 | 2.6996 |\n",
      "val: {'recall': 0.993919, 'recall_grapheme': 0.991683, 'recall_vowel': 0.996035, 'recall_consonant': 0.996274, 'acc_grapheme': 0.991129, 'acc_vowel': 0.99672, 'acc_consonant': 0.996968, 'loss_grapheme': 0.07208, 'loss_vowel': 0.05104, 'loss_consonant': 0.040369}\n",
      "   24 | 0.000373 | 160512/160596 | 3.1009 | 2.7523 |\n",
      "val: {'recall': 0.993601, 'recall_grapheme': 0.991437, 'recall_vowel': 0.996101, 'recall_consonant': 0.995429, 'acc_grapheme': 0.99185, 'acc_vowel': 0.996322, 'acc_consonant': 0.996496, 'loss_grapheme': 0.076662, 'loss_vowel': 0.068092, 'loss_consonant': 0.05021}\n",
      "   25 | 0.000371 | 160512/160596 | 2.1416 | 2.6061 |\n",
      "val: {'recall': 0.994647, 'recall_grapheme': 0.992357, 'recall_vowel': 0.996983, 'recall_consonant': 0.996892, 'acc_grapheme': 0.993142, 'acc_vowel': 0.997118, 'acc_consonant': 0.997391, 'loss_grapheme': 0.088095, 'loss_vowel': 0.066611, 'loss_consonant': 0.050726}\n",
      "   26 | 0.000369 | 160512/160596 | 2.6157 | 2.7317 |\n",
      "val: {'recall': 0.994769, 'recall_grapheme': 0.992773, 'recall_vowel': 0.996842, 'recall_consonant': 0.996691, 'acc_grapheme': 0.992918, 'acc_vowel': 0.996819, 'acc_consonant': 0.997217, 'loss_grapheme': 0.101722, 'loss_vowel': 0.092849, 'loss_consonant': 0.061104}\n",
      "   27 | 0.000367 | 160512/160596 | 1.7281 | 2.7488 |\n",
      "val: {'recall': 0.99473, 'recall_grapheme': 0.993081, 'recall_vowel': 0.997185, 'recall_consonant': 0.995573, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997639, 'acc_consonant': 0.997465, 'loss_grapheme': 0.10718, 'loss_vowel': 0.094677, 'loss_consonant': 0.069511}\n",
      "   28 | 0.000364 | 160512/160596 | 2.3112 | 2.7308 |\n",
      "val: {'recall': 0.993905, 'recall_grapheme': 0.991388, 'recall_vowel': 0.99677, 'recall_consonant': 0.996073, 'acc_grapheme': 0.991229, 'acc_vowel': 0.996795, 'acc_consonant': 0.996968, 'loss_grapheme': 0.11176, 'loss_vowel': 0.091825, 'loss_consonant': 0.068226}\n",
      "   29 | 0.000362 | 160512/160596 | 3.7012 | 2.6688 |\n",
      "val: {'recall': 0.995168, 'recall_grapheme': 0.993647, 'recall_vowel': 0.996977, 'recall_consonant': 0.996401, 'acc_grapheme': 0.993142, 'acc_vowel': 0.997391, 'acc_consonant': 0.996993, 'loss_grapheme': 0.077779, 'loss_vowel': 0.055259, 'loss_consonant': 0.042458}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 0.000359 | 160512/160596 | 3.2886 | 2.6877 |\n",
      "val: {'recall': 0.99443, 'recall_grapheme': 0.992132, 'recall_vowel': 0.996809, 'recall_consonant': 0.996646, 'acc_grapheme': 0.993018, 'acc_vowel': 0.997316, 'acc_consonant': 0.997615, 'loss_grapheme': 0.109324, 'loss_vowel': 0.091417, 'loss_consonant': 0.068255}\n",
      "   31 | 0.000357 | 160512/160596 | 1.2234 | 2.7205 |\n",
      "val: {'recall': 0.993914, 'recall_grapheme': 0.992395, 'recall_vowel': 0.995682, 'recall_consonant': 0.995182, 'acc_grapheme': 0.992198, 'acc_vowel': 0.996571, 'acc_consonant': 0.996968, 'loss_grapheme': 0.092065, 'loss_vowel': 0.072639, 'loss_consonant': 0.059731}\n",
      "   32 | 0.000354 | 160512/160596 | 2.7971 | 2.6335 |\n",
      "val: {'recall': 0.994305, 'recall_grapheme': 0.99225, 'recall_vowel': 0.995968, 'recall_consonant': 0.99675, 'acc_grapheme': 0.992098, 'acc_vowel': 0.997093, 'acc_consonant': 0.997366, 'loss_grapheme': 0.0896, 'loss_vowel': 0.068984, 'loss_consonant': 0.054972}\n",
      "   33 | 0.000351 | 160512/160596 | 3.6367 | 2.6839 |\n",
      "val: {'recall': 0.994496, 'recall_grapheme': 0.992777, 'recall_vowel': 0.997302, 'recall_consonant': 0.995128, 'acc_grapheme': 0.993539, 'acc_vowel': 0.99759, 'acc_consonant': 0.997664, 'loss_grapheme': 0.086351, 'loss_vowel': 0.071262, 'loss_consonant': 0.05594}\n",
      "   34 | 0.000349 | 160512/160596 | 3.5806 | 2.6463 |\n",
      "val: {'recall': 0.995334, 'recall_grapheme': 0.993612, 'recall_vowel': 0.99709, 'recall_consonant': 0.997023, 'acc_grapheme': 0.994036, 'acc_vowel': 0.99749, 'acc_consonant': 0.997813, 'loss_grapheme': 0.0646, 'loss_vowel': 0.051348, 'loss_consonant': 0.04029}\n",
      "   35 | 0.000346 | 160512/160596 | 1.4299 | 2.5861 |\n",
      "val: {'recall': 0.995623, 'recall_grapheme': 0.994274, 'recall_vowel': 0.997394, 'recall_consonant': 0.996551, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997639, 'acc_consonant': 0.99759, 'loss_grapheme': 0.074692, 'loss_vowel': 0.064031, 'loss_consonant': 0.045881}\n",
      "   37 | 0.000340 | 160512/160596 | 3.1238 | 2.5926 |\n",
      "val: {'recall': 0.995385, 'recall_grapheme': 0.993599, 'recall_vowel': 0.996999, 'recall_consonant': 0.997345, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997465, 'acc_consonant': 0.998087, 'loss_grapheme': 0.14758, 'loss_vowel': 0.141716, 'loss_consonant': 0.097873}\n",
      "   38 | 0.000337 | 160512/160596 | 3.1090 | 2.6626 |\n",
      "val: {'recall': 0.995646, 'recall_grapheme': 0.994226, 'recall_vowel': 0.997105, 'recall_consonant': 0.997029, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997441, 'acc_consonant': 0.997739, 'loss_grapheme': 0.098556, 'loss_vowel': 0.08547, 'loss_consonant': 0.059338}\n",
      "   39 | 0.000334 | 160512/160596 | 3.0752 | 2.6504 |\n",
      "val: {'recall': 0.994511, 'recall_grapheme': 0.992883, 'recall_vowel': 0.996942, 'recall_consonant': 0.995334, 'acc_grapheme': 0.992993, 'acc_vowel': 0.997142, 'acc_consonant': 0.997316, 'loss_grapheme': 0.10918, 'loss_vowel': 0.093842, 'loss_consonant': 0.064619}\n",
      "   40 | 0.000331 | 160512/160596 | 3.1712 | 2.6353 |\n",
      "val: {'recall': 0.994112, 'recall_grapheme': 0.9923, 'recall_vowel': 0.99632, 'recall_consonant': 0.995528, 'acc_grapheme': 0.993067, 'acc_vowel': 0.997043, 'acc_consonant': 0.997391, 'loss_grapheme': 0.078739, 'loss_vowel': 0.067071, 'loss_consonant': 0.045242}\n",
      "   41 | 0.000328 | 160512/160596 | 1.9300 | 2.6700 |\n",
      "val: {'recall': 0.994594, 'recall_grapheme': 0.992885, 'recall_vowel': 0.99738, 'recall_consonant': 0.995227, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997118, 'acc_consonant': 0.997639, 'loss_grapheme': 0.082496, 'loss_vowel': 0.069726, 'loss_consonant': 0.050092}\n",
      "   42 | 0.000324 | 160512/160596 | 2.0395 | 2.6664 |\n",
      "val: {'recall': 0.995273, 'recall_grapheme': 0.993901, 'recall_vowel': 0.996223, 'recall_consonant': 0.997068, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997068, 'acc_consonant': 0.997664, 'loss_grapheme': 0.106432, 'loss_vowel': 0.087258, 'loss_consonant': 0.062832}\n",
      "   43 | 0.000321 | 160512/160596 | 2.4935 | 2.6433 |\n",
      "val: {'recall': 0.994539, 'recall_grapheme': 0.993251, 'recall_vowel': 0.996455, 'recall_consonant': 0.9952, 'acc_grapheme': 0.993266, 'acc_vowel': 0.997093, 'acc_consonant': 0.997167, 'loss_grapheme': 0.096087, 'loss_vowel': 0.081429, 'loss_consonant': 0.058943}\n",
      "   44 | 0.000318 | 160512/160596 | 3.2946 | 2.7018 |\n",
      "val: {'recall': 0.978272, 'recall_grapheme': 0.980476, 'recall_vowel': 0.985378, 'recall_consonant': 0.966756, 'acc_grapheme': 0.982358, 'acc_vowel': 0.986979, 'acc_consonant': 0.99021, 'loss_grapheme': 0.154395, 'loss_vowel': 0.133039, 'loss_consonant': 0.098506}\n",
      "   45 | 0.000314 | 160512/160596 | 2.8135 | 2.6006 |\n",
      "val: {'recall': 0.995131, 'recall_grapheme': 0.993614, 'recall_vowel': 0.996875, 'recall_consonant': 0.996422, 'acc_grapheme': 0.993813, 'acc_vowel': 0.997142, 'acc_consonant': 0.997217, 'loss_grapheme': 0.071636, 'loss_vowel': 0.05526, 'loss_consonant': 0.044362}\n",
      "   46 | 0.000311 | 160512/160596 | 1.8870 | 2.6946 |\n",
      "val: {'recall': 0.994162, 'recall_grapheme': 0.992152, 'recall_vowel': 0.996701, 'recall_consonant': 0.995643, 'acc_grapheme': 0.993167, 'acc_vowel': 0.997093, 'acc_consonant': 0.997292, 'loss_grapheme': 0.061305, 'loss_vowel': 0.044229, 'loss_consonant': 0.037347}\n",
      "   47 | 0.000307 | 160512/160596 | 2.8967 | 2.4526 |\n",
      "val: {'recall': 0.995552, 'recall_grapheme': 0.993712, 'recall_vowel': 0.997697, 'recall_consonant': 0.997088, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997913, 'acc_consonant': 0.997813, 'loss_grapheme': 0.068704, 'loss_vowel': 0.048766, 'loss_consonant': 0.040314}\n",
      "   48 | 0.000304 | 160512/160596 | 2.8481 | 2.6450 |\n",
      "val: {'recall': 0.994969, 'recall_grapheme': 0.993594, 'recall_vowel': 0.997327, 'recall_consonant': 0.995361, 'acc_grapheme': 0.993912, 'acc_vowel': 0.99754, 'acc_consonant': 0.997987, 'loss_grapheme': 0.08069, 'loss_vowel': 0.07081, 'loss_consonant': 0.053632}\n",
      "   49 | 0.000300 | 160512/160596 | 1.5324 | 2.5800 |\n",
      "val: {'recall': 0.994995, 'recall_grapheme': 0.993728, 'recall_vowel': 0.997253, 'recall_consonant': 0.995272, 'acc_grapheme': 0.993689, 'acc_vowel': 0.99749, 'acc_consonant': 0.997714, 'loss_grapheme': 0.081479, 'loss_vowel': 0.057401, 'loss_consonant': 0.0463}\n",
      "   50 | 0.000296 | 160512/160596 | 3.0717 | 2.4452 |\n",
      "val: {'recall': 0.995544, 'recall_grapheme': 0.994555, 'recall_vowel': 0.997423, 'recall_consonant': 0.995643, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997565, 'acc_consonant': 0.997689, 'loss_grapheme': 0.072202, 'loss_vowel': 0.055282, 'loss_consonant': 0.042981}\n",
      "   51 | 0.000293 | 160512/160596 | 2.6331 | 2.5695 |\n",
      "val: {'recall': 0.994384, 'recall_grapheme': 0.992746, 'recall_vowel': 0.997487, 'recall_consonant': 0.994557, 'acc_grapheme': 0.993365, 'acc_vowel': 0.997838, 'acc_consonant': 0.99759, 'loss_grapheme': 0.082482, 'loss_vowel': 0.069617, 'loss_consonant': 0.051057}\n",
      "   52 | 0.000289 | 160512/160596 | 2.4013 | 2.5789 |\n",
      "val: {'recall': 0.995228, 'recall_grapheme': 0.994061, 'recall_vowel': 0.996995, 'recall_consonant': 0.995794, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997465, 'acc_consonant': 0.997639, 'loss_grapheme': 0.085732, 'loss_vowel': 0.072157, 'loss_consonant': 0.05535}\n",
      "   53 | 0.000285 | 160512/160596 | 3.0872 | 2.7018 |\n",
      "val: {'recall': 0.994108, 'recall_grapheme': 0.991888, 'recall_vowel': 0.996227, 'recall_consonant': 0.996428, 'acc_grapheme': 0.992123, 'acc_vowel': 0.996447, 'acc_consonant': 0.996894, 'loss_grapheme': 0.11379, 'loss_vowel': 0.099718, 'loss_consonant': 0.071545}\n",
      "   54 | 0.000281 | 160512/160596 | 2.3414 | 2.5746 |\n",
      "val: {'recall': 0.994019, 'recall_grapheme': 0.992019, 'recall_vowel': 0.99695, 'recall_consonant': 0.995089, 'acc_grapheme': 0.99257, 'acc_vowel': 0.996968, 'acc_consonant': 0.99754, 'loss_grapheme': 0.076922, 'loss_vowel': 0.058091, 'loss_consonant': 0.041498}\n",
      "   55 | 0.000278 | 160512/160596 | 1.2765 | 2.4866 |\n",
      "val: {'recall': 0.994362, 'recall_grapheme': 0.992775, 'recall_vowel': 0.996964, 'recall_consonant': 0.994932, 'acc_grapheme': 0.992222, 'acc_vowel': 0.996894, 'acc_consonant': 0.997217, 'loss_grapheme': 0.074356, 'loss_vowel': 0.064923, 'loss_consonant': 0.04718}\n",
      "   56 | 0.000274 | 160512/160596 | 3.6424 | 2.6133 |\n",
      "val: {'recall': 0.994831, 'recall_grapheme': 0.994282, 'recall_vowel': 0.997522, 'recall_consonant': 0.993236, 'acc_grapheme': 0.993515, 'acc_vowel': 0.99754, 'acc_consonant': 0.997664, 'loss_grapheme': 0.078667, 'loss_vowel': 0.063911, 'loss_consonant': 0.049574}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   57 | 0.000270 | 160512/160596 | 2.3736 | 2.6065 |\n",
      "val: {'recall': 0.993649, 'recall_grapheme': 0.993496, 'recall_vowel': 0.996746, 'recall_consonant': 0.990858, 'acc_grapheme': 0.99339, 'acc_vowel': 0.997441, 'acc_consonant': 0.99754, 'loss_grapheme': 0.097688, 'loss_vowel': 0.078026, 'loss_consonant': 0.05184}\n",
      "   58 | 0.000266 | 160512/160596 | 3.0683 | 2.5878 |\n",
      "val: {'recall': 0.994694, 'recall_grapheme': 0.993479, 'recall_vowel': 0.996953, 'recall_consonant': 0.994864, 'acc_grapheme': 0.993639, 'acc_vowel': 0.997118, 'acc_consonant': 0.99754, 'loss_grapheme': 0.077272, 'loss_vowel': 0.065965, 'loss_consonant': 0.04952}\n",
      "   59 | 0.000262 | 160512/160596 | 2.4986 | 2.5519 |\n",
      "val: {'recall': 0.995456, 'recall_grapheme': 0.994173, 'recall_vowel': 0.996999, 'recall_consonant': 0.996477, 'acc_grapheme': 0.994409, 'acc_vowel': 0.997938, 'acc_consonant': 0.997938, 'loss_grapheme': 0.108539, 'loss_vowel': 0.089925, 'loss_consonant': 0.059481}\n",
      "   60 | 0.000258 | 160512/160596 | 2.7462 | 2.5025 |\n",
      "val: {'recall': 0.994895, 'recall_grapheme': 0.993603, 'recall_vowel': 0.997104, 'recall_consonant': 0.995272, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997639, 'acc_consonant': 0.997813, 'loss_grapheme': 0.052349, 'loss_vowel': 0.036329, 'loss_consonant': 0.029186}\n",
      "   61 | 0.000254 | 160512/160596 | 3.1859 | 2.5926 |\n",
      "val: {'recall': 0.994542, 'recall_grapheme': 0.992582, 'recall_vowel': 0.996453, 'recall_consonant': 0.99655, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997118, 'acc_consonant': 0.997267, 'loss_grapheme': 0.086329, 'loss_vowel': 0.076512, 'loss_consonant': 0.057414}\n",
      "   62 | 0.000250 | 160512/160596 | 3.1726 | 2.5058 |\n",
      "val: {'recall': 0.994545, 'recall_grapheme': 0.993099, 'recall_vowel': 0.997083, 'recall_consonant': 0.994899, 'acc_grapheme': 0.992794, 'acc_vowel': 0.997217, 'acc_consonant': 0.997292, 'loss_grapheme': 0.071256, 'loss_vowel': 0.055941, 'loss_consonant': 0.043961}\n",
      "   63 | 0.000246 | 160512/160596 | 3.0659 | 2.5266 |\n",
      "val: {'recall': 0.994867, 'recall_grapheme': 0.992662, 'recall_vowel': 0.996907, 'recall_consonant': 0.997237, 'acc_grapheme': 0.992769, 'acc_vowel': 0.997267, 'acc_consonant': 0.997465, 'loss_grapheme': 0.094558, 'loss_vowel': 0.081885, 'loss_consonant': 0.056126}\n",
      "   64 | 0.000242 | 160512/160596 | 2.5923 | 2.5273 |\n",
      "val: {'recall': 0.993721, 'recall_grapheme': 0.992227, 'recall_vowel': 0.99659, 'recall_consonant': 0.993839, 'acc_grapheme': 0.991999, 'acc_vowel': 0.996968, 'acc_consonant': 0.997391, 'loss_grapheme': 0.058509, 'loss_vowel': 0.041625, 'loss_consonant': 0.032166}\n",
      "   65 | 0.000237 | 160512/160596 | 3.3774 | 2.6628 |\n",
      "val: {'recall': 0.994066, 'recall_grapheme': 0.992628, 'recall_vowel': 0.996075, 'recall_consonant': 0.994935, 'acc_grapheme': 0.99267, 'acc_vowel': 0.996223, 'acc_consonant': 0.997142, 'loss_grapheme': 0.063889, 'loss_vowel': 0.052861, 'loss_consonant': 0.041693}\n",
      "   66 | 0.000233 | 160512/160596 | 1.0651 | 2.6283 |\n",
      "val: {'recall': 0.995002, 'recall_grapheme': 0.993967, 'recall_vowel': 0.996719, 'recall_consonant': 0.995354, 'acc_grapheme': 0.993862, 'acc_vowel': 0.997565, 'acc_consonant': 0.997888, 'loss_grapheme': 0.066191, 'loss_vowel': 0.051209, 'loss_consonant': 0.040753}\n",
      "   67 | 0.000229 | 160512/160596 | 2.8452 | 2.5318 |\n",
      "val: {'recall': 0.994919, 'recall_grapheme': 0.993494, 'recall_vowel': 0.997454, 'recall_consonant': 0.995236, 'acc_grapheme': 0.993365, 'acc_vowel': 0.997838, 'acc_consonant': 0.997465, 'loss_grapheme': 0.069052, 'loss_vowel': 0.051303, 'loss_consonant': 0.039292}\n",
      "   68 | 0.000225 | 160512/160596 | 3.5436 | 2.5632 |\n",
      "val: {'recall': 0.994883, 'recall_grapheme': 0.993651, 'recall_vowel': 0.997784, 'recall_consonant': 0.994444, 'acc_grapheme': 0.994459, 'acc_vowel': 0.998037, 'acc_consonant': 0.998136, 'loss_grapheme': 0.073711, 'loss_vowel': 0.059207, 'loss_consonant': 0.043642}\n",
      "   69 | 0.000221 | 160512/160596 | 2.4348 | 2.4913 |\n",
      "val: {'recall': 0.994907, 'recall_grapheme': 0.993222, 'recall_vowel': 0.997, 'recall_consonant': 0.996186, 'acc_grapheme': 0.993167, 'acc_vowel': 0.997316, 'acc_consonant': 0.99749, 'loss_grapheme': 0.060655, 'loss_vowel': 0.051061, 'loss_consonant': 0.03582}\n",
      "   70 | 0.000217 | 160512/160596 | 3.3041 | 2.5612 |\n",
      "val: {'recall': 0.995484, 'recall_grapheme': 0.994377, 'recall_vowel': 0.997651, 'recall_consonant': 0.995532, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997888, 'acc_consonant': 0.997888, 'loss_grapheme': 0.056324, 'loss_vowel': 0.04454, 'loss_consonant': 0.036952}\n",
      "   71 | 0.000213 | 160512/160596 | 2.8351 | 2.5498 |\n",
      "val: {'recall': 0.994722, 'recall_grapheme': 0.993968, 'recall_vowel': 0.996812, 'recall_consonant': 0.99414, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997689, 'acc_consonant': 0.997863, 'loss_grapheme': 0.105401, 'loss_vowel': 0.101976, 'loss_consonant': 0.070421}\n",
      "   72 | 0.000208 | 160512/160596 | 2.8751 | 2.5227 |\n",
      "val: {'recall': 0.99587, 'recall_grapheme': 0.994446, 'recall_vowel': 0.997333, 'recall_consonant': 0.997258, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997938, 'acc_consonant': 0.998136, 'loss_grapheme': 0.057912, 'loss_vowel': 0.043252, 'loss_consonant': 0.036043}\n",
      "   73 | 0.000204 | 160512/160596 | 2.7537 | 2.5768 |\n",
      "val: {'recall': 0.996105, 'recall_grapheme': 0.99563, 'recall_vowel': 0.997358, 'recall_consonant': 0.9958, 'acc_grapheme': 0.995453, 'acc_vowel': 0.997913, 'acc_consonant': 0.998037, 'loss_grapheme': 0.080059, 'loss_vowel': 0.060902, 'loss_consonant': 0.046816}\n",
      "###>>>>> saved\n",
      "   74 | 0.000200 | 160512/160596 | 2.5771 | 2.5086 |\n",
      "val: {'recall': 0.995585, 'recall_grapheme': 0.994732, 'recall_vowel': 0.99717, 'recall_consonant': 0.995705, 'acc_grapheme': 0.99508, 'acc_vowel': 0.997863, 'acc_consonant': 0.998112, 'loss_grapheme': 0.065563, 'loss_vowel': 0.049748, 'loss_consonant': 0.039127}\n",
      "   75 | 0.000196 | 160512/160596 | 3.2284 | 2.4645 |\n",
      "val: {'recall': 0.993762, 'recall_grapheme': 0.992198, 'recall_vowel': 0.996962, 'recall_consonant': 0.99369, 'acc_grapheme': 0.992744, 'acc_vowel': 0.997441, 'acc_consonant': 0.997366, 'loss_grapheme': 0.07266, 'loss_vowel': 0.061473, 'loss_consonant': 0.042907}\n",
      "   76 | 0.000192 | 160512/160596 | 3.2563 | 2.5118 |\n",
      "val: {'recall': 0.994404, 'recall_grapheme': 0.993423, 'recall_vowel': 0.997023, 'recall_consonant': 0.993749, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997739, 'acc_consonant': 0.997639, 'loss_grapheme': 0.049041, 'loss_vowel': 0.037224, 'loss_consonant': 0.029857}\n",
      "   77 | 0.000187 | 160512/160596 | 2.1691 | 2.5747 |\n",
      "val: {'recall': 0.995976, 'recall_grapheme': 0.995019, 'recall_vowel': 0.997064, 'recall_consonant': 0.996803, 'acc_grapheme': 0.994633, 'acc_vowel': 0.997813, 'acc_consonant': 0.998236, 'loss_grapheme': 0.055118, 'loss_vowel': 0.040354, 'loss_consonant': 0.03264}\n",
      "   78 | 0.000183 | 160512/160596 | 2.8132 | 2.4757 |\n",
      "val: {'recall': 0.995514, 'recall_grapheme': 0.9941, 'recall_vowel': 0.997381, 'recall_consonant': 0.996477, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997714, 'acc_consonant': 0.997689, 'loss_grapheme': 0.06837, 'loss_vowel': 0.060288, 'loss_consonant': 0.046242}\n",
      "   79 | 0.000179 | 160512/160596 | 3.1965 | 2.4559 |\n",
      "val: {'recall': 0.994574, 'recall_grapheme': 0.993763, 'recall_vowel': 0.996322, 'recall_consonant': 0.994451, 'acc_grapheme': 0.993589, 'acc_vowel': 0.997267, 'acc_consonant': 0.997615, 'loss_grapheme': 0.079788, 'loss_vowel': 0.073445, 'loss_consonant': 0.051224}\n",
      "   80 | 0.000175 | 160512/160596 | 2.9704 | 2.5256 |\n",
      "val: {'recall': 0.99518, 'recall_grapheme': 0.993935, 'recall_vowel': 0.997384, 'recall_consonant': 0.995464, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997639, 'acc_consonant': 0.997938, 'loss_grapheme': 0.078003, 'loss_vowel': 0.066258, 'loss_consonant': 0.04424}\n",
      "   81 | 0.000171 | 160512/160596 | 2.5761 | 2.5434 |\n",
      "val: {'recall': 0.995309, 'recall_grapheme': 0.99434, 'recall_vowel': 0.99718, 'recall_consonant': 0.995375, 'acc_grapheme': 0.994558, 'acc_vowel': 0.99759, 'acc_consonant': 0.998037, 'loss_grapheme': 0.054569, 'loss_vowel': 0.044153, 'loss_consonant': 0.033948}\n",
      "   82 | 0.000167 | 160512/160596 | 2.7076 | 2.5333 |\n",
      "val: {'recall': 0.995265, 'recall_grapheme': 0.99438, 'recall_vowel': 0.997305, 'recall_consonant': 0.994995, 'acc_grapheme': 0.994185, 'acc_vowel': 0.997689, 'acc_consonant': 0.997639, 'loss_grapheme': 0.046046, 'loss_vowel': 0.032363, 'loss_consonant': 0.02588}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 0.000163 | 160512/160596 | 2.3558 | 2.5043 |\n",
      "val: {'recall': 0.99629, 'recall_grapheme': 0.995616, 'recall_vowel': 0.997859, 'recall_consonant': 0.99607, 'acc_grapheme': 0.995204, 'acc_vowel': 0.998211, 'acc_consonant': 0.99841, 'loss_grapheme': 0.044234, 'loss_vowel': 0.031369, 'loss_consonant': 0.023754}\n",
      "###>>>>> saved\n",
      "   84 | 0.000158 | 160512/160596 | 3.2219 | 2.5181 |\n",
      "val: {'recall': 0.996175, 'recall_grapheme': 0.995697, 'recall_vowel': 0.997772, 'recall_consonant': 0.995535, 'acc_grapheme': 0.995378, 'acc_vowel': 0.998285, 'acc_consonant': 0.998186, 'loss_grapheme': 0.054106, 'loss_vowel': 0.040695, 'loss_consonant': 0.030917}\n",
      "   85 | 0.000154 | 160512/160596 | 3.1306 | 2.5137 |\n",
      "val: {'recall': 0.994964, 'recall_grapheme': 0.993673, 'recall_vowel': 0.996885, 'recall_consonant': 0.995626, 'acc_grapheme': 0.993018, 'acc_vowel': 0.997018, 'acc_consonant': 0.997391, 'loss_grapheme': 0.066877, 'loss_vowel': 0.055273, 'loss_consonant': 0.040667}\n",
      "   86 | 0.000150 | 160512/160596 | 2.2868 | 2.5135 |\n",
      "val: {'recall': 0.995334, 'recall_grapheme': 0.994414, 'recall_vowel': 0.997289, 'recall_consonant': 0.995218, 'acc_grapheme': 0.99431, 'acc_vowel': 0.997863, 'acc_consonant': 0.997838, 'loss_grapheme': 0.0683, 'loss_vowel': 0.056351, 'loss_consonant': 0.042272}\n",
      "   87 | 0.000146 | 160512/160596 | 1.9225 | 2.4709 |\n",
      "val: {'recall': 0.994575, 'recall_grapheme': 0.993159, 'recall_vowel': 0.996265, 'recall_consonant': 0.995717, 'acc_grapheme': 0.992844, 'acc_vowel': 0.996944, 'acc_consonant': 0.99759, 'loss_grapheme': 0.072855, 'loss_vowel': 0.057533, 'loss_consonant': 0.043011}\n",
      "   88 | 0.000142 | 160512/160596 | 2.9970 | 2.5057 |\n",
      "val: {'recall': 0.995285, 'recall_grapheme': 0.994178, 'recall_vowel': 0.996874, 'recall_consonant': 0.995911, 'acc_grapheme': 0.993838, 'acc_vowel': 0.997316, 'acc_consonant': 0.997664, 'loss_grapheme': 0.071417, 'loss_vowel': 0.061167, 'loss_consonant': 0.043495}\n",
      "   89 | 0.000138 | 160512/160596 | 2.7819 | 2.5576 |\n",
      "val: {'recall': 0.994278, 'recall_grapheme': 0.993377, 'recall_vowel': 0.996383, 'recall_consonant': 0.993976, 'acc_grapheme': 0.992993, 'acc_vowel': 0.997167, 'acc_consonant': 0.997341, 'loss_grapheme': 0.054382, 'loss_vowel': 0.043019, 'loss_consonant': 0.032645}\n",
      "   90 | 0.000134 | 160512/160596 | 0.3311 | 2.5050 |\n",
      "val: {'recall': 0.995941, 'recall_grapheme': 0.995432, 'recall_vowel': 0.99728, 'recall_consonant': 0.995622, 'acc_grapheme': 0.994906, 'acc_vowel': 0.998012, 'acc_consonant': 0.998087, 'loss_grapheme': 0.074321, 'loss_vowel': 0.065681, 'loss_consonant': 0.046899}\n",
      "   91 | 0.000130 | 160512/160596 | 2.5203 | 2.5353 |\n",
      "val: {'recall': 0.995282, 'recall_grapheme': 0.994559, 'recall_vowel': 0.996754, 'recall_consonant': 0.995254, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997267, 'acc_consonant': 0.997316, 'loss_grapheme': 0.05799, 'loss_vowel': 0.048976, 'loss_consonant': 0.037287}\n",
      "   92 | 0.000126 | 160512/160596 | 2.0877 | 2.5317 |\n",
      "val: {'recall': 0.995608, 'recall_grapheme': 0.994804, 'recall_vowel': 0.997261, 'recall_consonant': 0.995564, 'acc_grapheme': 0.994558, 'acc_vowel': 0.997764, 'acc_consonant': 0.997913, 'loss_grapheme': 0.048477, 'loss_vowel': 0.036019, 'loss_consonant': 0.0281}\n",
      "   93 | 0.000123 | 160512/160596 | 2.7342 | 2.4987 |\n",
      "val: {'recall': 0.996363, 'recall_grapheme': 0.995761, 'recall_vowel': 0.998196, 'recall_consonant': 0.995735, 'acc_grapheme': 0.995502, 'acc_vowel': 0.998435, 'acc_consonant': 0.998385, 'loss_grapheme': 0.065712, 'loss_vowel': 0.052899, 'loss_consonant': 0.038233}\n",
      "###>>>>> saved\n",
      "   94 | 0.000119 | 160512/160596 | 3.1966 | 2.5399 |\n",
      "val: {'recall': 0.995125, 'recall_grapheme': 0.99388, 'recall_vowel': 0.997312, 'recall_consonant': 0.995429, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997938, 'acc_consonant': 0.997863, 'loss_grapheme': 0.061738, 'loss_vowel': 0.052152, 'loss_consonant': 0.037859}\n",
      "   95 | 0.000115 | 160512/160596 | 3.0016 | 2.5102 |\n",
      "val: {'recall': 0.995357, 'recall_grapheme': 0.994477, 'recall_vowel': 0.997135, 'recall_consonant': 0.99534, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997739, 'acc_consonant': 0.997739, 'loss_grapheme': 0.058695, 'loss_vowel': 0.046157, 'loss_consonant': 0.036119}\n",
      "   96 | 0.000111 | 160512/160596 | 3.0871 | 2.4465 |\n",
      "val: {'recall': 0.995646, 'recall_grapheme': 0.994804, 'recall_vowel': 0.997622, 'recall_consonant': 0.995356, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997888, 'acc_consonant': 0.997838, 'loss_grapheme': 0.041065, 'loss_vowel': 0.027344, 'loss_consonant': 0.023892}\n",
      "   97 | 0.000107 | 160512/160596 | 2.5229 | 2.4903 |\n",
      "val: {'recall': 0.995983, 'recall_grapheme': 0.994966, 'recall_vowel': 0.99787, 'recall_consonant': 0.996131, 'acc_grapheme': 0.994707, 'acc_vowel': 0.998161, 'acc_consonant': 0.998062, 'loss_grapheme': 0.062296, 'loss_vowel': 0.04581, 'loss_consonant': 0.034964}\n",
      "   98 | 0.000104 | 160512/160596 | 3.0549 | 2.5576 |\n",
      "val: {'recall': 0.995359, 'recall_grapheme': 0.994229, 'recall_vowel': 0.997589, 'recall_consonant': 0.99539, 'acc_grapheme': 0.993962, 'acc_vowel': 0.998037, 'acc_consonant': 0.997739, 'loss_grapheme': 0.042974, 'loss_vowel': 0.029338, 'loss_consonant': 0.02375}\n",
      "   99 | 0.000100 | 160512/160596 | 2.7959 | 2.4935 |\n",
      "val: {'recall': 0.99542, 'recall_grapheme': 0.994503, 'recall_vowel': 0.997086, 'recall_consonant': 0.995588, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997987, 'acc_consonant': 0.998186, 'loss_grapheme': 0.056981, 'loss_vowel': 0.045822, 'loss_consonant': 0.034845}\n",
      "  100 | 0.000096 | 160512/160596 | 2.7133 | 2.4750 |\n",
      "val: {'recall': 0.995709, 'recall_grapheme': 0.994652, 'recall_vowel': 0.997737, 'recall_consonant': 0.995797, 'acc_grapheme': 0.994285, 'acc_vowel': 0.998161, 'acc_consonant': 0.998211, 'loss_grapheme': 0.041695, 'loss_vowel': 0.030879, 'loss_consonant': 0.024723}\n",
      "  101 | 0.000093 | 160512/160596 | 3.5597 | 2.4905 |\n",
      "val: {'recall': 0.995159, 'recall_grapheme': 0.993825, 'recall_vowel': 0.997348, 'recall_consonant': 0.995637, 'acc_grapheme': 0.994185, 'acc_vowel': 0.997664, 'acc_consonant': 0.998012, 'loss_grapheme': 0.06948, 'loss_vowel': 0.059191, 'loss_consonant': 0.042961}\n",
      "  102 | 0.000089 | 160512/160596 | 3.1335 | 2.4303 |\n",
      "val: {'recall': 0.995236, 'recall_grapheme': 0.993906, 'recall_vowel': 0.997256, 'recall_consonant': 0.995874, 'acc_grapheme': 0.994185, 'acc_vowel': 0.997465, 'acc_consonant': 0.997913, 'loss_grapheme': 0.043637, 'loss_vowel': 0.033469, 'loss_consonant': 0.025062}\n",
      "  103 | 0.000086 | 160512/160596 | 0.9730 | 2.4096 |\n",
      "val: {'recall': 0.996628, 'recall_grapheme': 0.996228, 'recall_vowel': 0.998223, 'recall_consonant': 0.995833, 'acc_grapheme': 0.996298, 'acc_vowel': 0.998559, 'acc_consonant': 0.998484, 'loss_grapheme': 0.051558, 'loss_vowel': 0.042147, 'loss_consonant': 0.033421}\n",
      "###>>>>> saved\n",
      "  104 | 0.000082 | 160512/160596 | 0.3903 | 2.5232 |\n",
      "val: {'recall': 0.996043, 'recall_grapheme': 0.99529, 'recall_vowel': 0.997862, 'recall_consonant': 0.995729, 'acc_grapheme': 0.995527, 'acc_vowel': 0.998335, 'acc_consonant': 0.998285, 'loss_grapheme': 0.064465, 'loss_vowel': 0.052176, 'loss_consonant': 0.038672}\n",
      "  105 | 0.000079 | 160512/160596 | 2.6866 | 2.4815 |\n",
      "val: {'recall': 0.995947, 'recall_grapheme': 0.994987, 'recall_vowel': 0.998112, 'recall_consonant': 0.995703, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998211, 'acc_consonant': 0.998087, 'loss_grapheme': 0.047619, 'loss_vowel': 0.037813, 'loss_consonant': 0.029848}\n",
      "  106 | 0.000076 | 160512/160596 | 1.9321 | 2.4899 |\n",
      "val: {'recall': 0.996392, 'recall_grapheme': 0.995927, 'recall_vowel': 0.998077, 'recall_consonant': 0.995637, 'acc_grapheme': 0.995627, 'acc_vowel': 0.998435, 'acc_consonant': 0.998161, 'loss_grapheme': 0.062895, 'loss_vowel': 0.052722, 'loss_consonant': 0.040455}\n",
      "  107 | 0.000073 | 160512/160596 | 2.4583 | 2.4696 |\n",
      "val: {'recall': 0.995797, 'recall_grapheme': 0.994877, 'recall_vowel': 0.997752, 'recall_consonant': 0.99568, 'acc_grapheme': 0.994856, 'acc_vowel': 0.998186, 'acc_consonant': 0.997987, 'loss_grapheme': 0.063576, 'loss_vowel': 0.055325, 'loss_consonant': 0.041709}\n",
      "  108 | 0.000069 | 160512/160596 | 2.5784 | 2.5027 |\n",
      "val: {'recall': 0.994986, 'recall_grapheme': 0.993523, 'recall_vowel': 0.997157, 'recall_consonant': 0.995743, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997292, 'acc_consonant': 0.99749, 'loss_grapheme': 0.048126, 'loss_vowel': 0.036357, 'loss_consonant': 0.028684}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  109 | 0.000066 | 160512/160596 | 2.7923 | 2.4014 |\n",
      "val: {'recall': 0.995748, 'recall_grapheme': 0.994853, 'recall_vowel': 0.997682, 'recall_consonant': 0.995606, 'acc_grapheme': 0.994832, 'acc_vowel': 0.998161, 'acc_consonant': 0.998087, 'loss_grapheme': 0.070898, 'loss_vowel': 0.061281, 'loss_consonant': 0.044986}\n",
      "  110 | 0.000063 | 160512/160596 | 2.6656 | 2.4247 |\n",
      "val: {'recall': 0.995728, 'recall_grapheme': 0.994878, 'recall_vowel': 0.997468, 'recall_consonant': 0.995686, 'acc_grapheme': 0.995055, 'acc_vowel': 0.998136, 'acc_consonant': 0.998236, 'loss_grapheme': 0.059392, 'loss_vowel': 0.050205, 'loss_consonant': 0.038054}\n",
      "  111 | 0.000060 | 160512/160596 | 2.3770 | 2.4614 |\n",
      "val: {'recall': 0.996089, 'recall_grapheme': 0.995381, 'recall_vowel': 0.997904, 'recall_consonant': 0.995689, 'acc_grapheme': 0.995328, 'acc_vowel': 0.99836, 'acc_consonant': 0.998261, 'loss_grapheme': 0.057588, 'loss_vowel': 0.045666, 'loss_consonant': 0.034375}\n",
      "  112 | 0.000057 | 160512/160596 | 1.7868 | 2.4836 |\n",
      "val: {'recall': 0.995387, 'recall_grapheme': 0.994274, 'recall_vowel': 0.997482, 'recall_consonant': 0.995519, 'acc_grapheme': 0.99431, 'acc_vowel': 0.998037, 'acc_consonant': 0.997888, 'loss_grapheme': 0.059947, 'loss_vowel': 0.048691, 'loss_consonant': 0.037181}\n",
      "  113 | 0.000054 | 160512/160596 | 2.6930 | 2.4388 |\n",
      "val: {'recall': 0.995359, 'recall_grapheme': 0.99428, 'recall_vowel': 0.997502, 'recall_consonant': 0.995375, 'acc_grapheme': 0.99426, 'acc_vowel': 0.998062, 'acc_consonant': 0.997764, 'loss_grapheme': 0.05851, 'loss_vowel': 0.048609, 'loss_consonant': 0.036199}\n",
      "  114 | 0.000051 | 160512/160596 | 2.6448 | 2.4221 |\n",
      "val: {'recall': 0.995513, 'recall_grapheme': 0.994577, 'recall_vowel': 0.997502, 'recall_consonant': 0.995396, 'acc_grapheme': 0.994931, 'acc_vowel': 0.997938, 'acc_consonant': 0.998112, 'loss_grapheme': 0.047791, 'loss_vowel': 0.037656, 'loss_consonant': 0.028724}\n",
      "  115 | 0.000049 | 160512/160596 | 2.4354 | 2.3563 |\n",
      "val: {'recall': 0.9954, 'recall_grapheme': 0.994361, 'recall_vowel': 0.997615, 'recall_consonant': 0.995265, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997962, 'acc_consonant': 0.997863, 'loss_grapheme': 0.042237, 'loss_vowel': 0.030795, 'loss_consonant': 0.024613}\n",
      "  116 | 0.000046 | 160512/160596 | 2.6014 | 2.3710 |\n",
      "val: {'recall': 0.995817, 'recall_grapheme': 0.994708, 'recall_vowel': 0.998136, 'recall_consonant': 0.995718, 'acc_grapheme': 0.994956, 'acc_vowel': 0.998261, 'acc_consonant': 0.998186, 'loss_grapheme': 0.050486, 'loss_vowel': 0.037822, 'loss_consonant': 0.029431}\n",
      "  117 | 0.000043 | 160512/160596 | 2.5965 | 2.4305 |\n",
      "val: {'recall': 0.996061, 'recall_grapheme': 0.995206, 'recall_vowel': 0.998023, 'recall_consonant': 0.995809, 'acc_grapheme': 0.99508, 'acc_vowel': 0.998285, 'acc_consonant': 0.99831, 'loss_grapheme': 0.062511, 'loss_vowel': 0.045784, 'loss_consonant': 0.037019}\n",
      "  118 | 0.000041 | 160512/160596 | 1.7306 | 2.4790 |\n",
      "val: {'recall': 0.994845, 'recall_grapheme': 0.993423, 'recall_vowel': 0.996919, 'recall_consonant': 0.995616, 'acc_grapheme': 0.993465, 'acc_vowel': 0.99749, 'acc_consonant': 0.997515, 'loss_grapheme': 0.045505, 'loss_vowel': 0.033605, 'loss_consonant': 0.02675}\n",
      "  119 | 0.000038 | 160512/160596 | 2.9339 | 2.4228 |\n",
      "val: {'recall': 0.995449, 'recall_grapheme': 0.994314, 'recall_vowel': 0.997257, 'recall_consonant': 0.99591, 'acc_grapheme': 0.994359, 'acc_vowel': 0.997788, 'acc_consonant': 0.997838, 'loss_grapheme': 0.045441, 'loss_vowel': 0.032167, 'loss_consonant': 0.02667}\n",
      "  120 | 0.000036 | 160512/160596 | 1.2262 | 2.4396 |\n",
      "val: {'recall': 0.996663, 'recall_grapheme': 0.996368, 'recall_vowel': 0.998027, 'recall_consonant': 0.995889, 'acc_grapheme': 0.995925, 'acc_vowel': 0.998459, 'acc_consonant': 0.998435, 'loss_grapheme': 0.064669, 'loss_vowel': 0.049119, 'loss_consonant': 0.036504}\n",
      "###>>>>> saved\n",
      "  121 | 0.000033 | 160512/160596 | 2.1280 | 2.4137 |\n",
      "val: {'recall': 0.996159, 'recall_grapheme': 0.99555, 'recall_vowel': 0.997582, 'recall_consonant': 0.995955, 'acc_grapheme': 0.995105, 'acc_vowel': 0.998087, 'acc_consonant': 0.998037, 'loss_grapheme': 0.045998, 'loss_vowel': 0.035229, 'loss_consonant': 0.028114}\n",
      "  122 | 0.000031 | 160512/160596 | 2.5166 | 2.4176 |\n",
      "val: {'recall': 0.996378, 'recall_grapheme': 0.995881, 'recall_vowel': 0.998044, 'recall_consonant': 0.995706, 'acc_grapheme': 0.995602, 'acc_vowel': 0.998435, 'acc_consonant': 0.99831, 'loss_grapheme': 0.061401, 'loss_vowel': 0.044539, 'loss_consonant': 0.033112}\n",
      "  123 | 0.000029 | 160512/160596 | 2.4346 | 2.4444 |\n",
      "val: {'recall': 0.995992, 'recall_grapheme': 0.995214, 'recall_vowel': 0.997971, 'recall_consonant': 0.995569, 'acc_grapheme': 0.995403, 'acc_vowel': 0.998285, 'acc_consonant': 0.998186, 'loss_grapheme': 0.055409, 'loss_vowel': 0.04535, 'loss_consonant': 0.035148}\n",
      "  124 | 0.000027 | 160512/160596 | 2.4712 | 2.3704 |\n",
      "val: {'recall': 0.996138, 'recall_grapheme': 0.99559, 'recall_vowel': 0.997975, 'recall_consonant': 0.995398, 'acc_grapheme': 0.995652, 'acc_vowel': 0.998335, 'acc_consonant': 0.998161, 'loss_grapheme': 0.057737, 'loss_vowel': 0.049254, 'loss_consonant': 0.037102}\n",
      "  125 | 0.000025 | 160512/160596 | 2.8481 | 2.3949 |\n",
      "val: {'recall': 0.996176, 'recall_grapheme': 0.995597, 'recall_vowel': 0.997828, 'recall_consonant': 0.995685, 'acc_grapheme': 0.995502, 'acc_vowel': 0.998236, 'acc_consonant': 0.998335, 'loss_grapheme': 0.051403, 'loss_vowel': 0.039429, 'loss_consonant': 0.029779}\n",
      "  126 | 0.000023 | 160512/160596 | 1.0014 | 2.4762 |\n",
      "val: {'recall': 0.99604, 'recall_grapheme': 0.995337, 'recall_vowel': 0.997841, 'recall_consonant': 0.995647, 'acc_grapheme': 0.995204, 'acc_vowel': 0.998186, 'acc_consonant': 0.998136, 'loss_grapheme': 0.070413, 'loss_vowel': 0.058378, 'loss_consonant': 0.043575}\n",
      "  127 | 0.000021 | 160512/160596 | 2.4763 | 2.4364 |\n",
      "val: {'recall': 0.995822, 'recall_grapheme': 0.994712, 'recall_vowel': 0.99802, 'recall_consonant': 0.995842, 'acc_grapheme': 0.994782, 'acc_vowel': 0.998161, 'acc_consonant': 0.997938, 'loss_grapheme': 0.04422, 'loss_vowel': 0.032941, 'loss_consonant': 0.026228}\n",
      "  128 | 0.000019 | 160512/160596 | 1.8364 | 2.4911 |\n",
      "val: {'recall': 0.995702, 'recall_grapheme': 0.994801, 'recall_vowel': 0.997697, 'recall_consonant': 0.995511, 'acc_grapheme': 0.994931, 'acc_vowel': 0.998136, 'acc_consonant': 0.998087, 'loss_grapheme': 0.053225, 'loss_vowel': 0.042038, 'loss_consonant': 0.032431}\n",
      "  129 | 0.000017 | 160512/160596 | 2.2552 | 2.4049 |\n",
      "val: {'recall': 0.995898, 'recall_grapheme': 0.995017, 'recall_vowel': 0.998073, 'recall_consonant': 0.995485, 'acc_grapheme': 0.99508, 'acc_vowel': 0.998236, 'acc_consonant': 0.998062, 'loss_grapheme': 0.045005, 'loss_vowel': 0.034575, 'loss_consonant': 0.027415}\n",
      "  130 | 0.000016 | 160512/160596 | 1.0346 | 2.4836 |\n",
      "val: {'recall': 0.996206, 'recall_grapheme': 0.995449, 'recall_vowel': 0.998245, 'recall_consonant': 0.99568, 'acc_grapheme': 0.995627, 'acc_vowel': 0.998435, 'acc_consonant': 0.99836, 'loss_grapheme': 0.051495, 'loss_vowel': 0.041467, 'loss_consonant': 0.031557}\n",
      "  131 | 0.000014 | 160512/160596 | 2.8961 | 2.5146 |\n",
      "val: {'recall': 0.995642, 'recall_grapheme': 0.994696, 'recall_vowel': 0.997719, 'recall_consonant': 0.995457, 'acc_grapheme': 0.994807, 'acc_vowel': 0.998087, 'acc_consonant': 0.997962, 'loss_grapheme': 0.058412, 'loss_vowel': 0.046992, 'loss_consonant': 0.035602}\n",
      "  132 | 0.000013 | 160512/160596 | 2.3716 | 2.4510 |\n",
      "val: {'recall': 0.996006, 'recall_grapheme': 0.995281, 'recall_vowel': 0.998005, 'recall_consonant': 0.995458, 'acc_grapheme': 0.995453, 'acc_vowel': 0.998335, 'acc_consonant': 0.998136, 'loss_grapheme': 0.056365, 'loss_vowel': 0.045699, 'loss_consonant': 0.035113}\n",
      "  133 | 0.000011 | 160512/160596 | 2.0731 | 2.3963 |\n",
      "val: {'recall': 0.996352, 'recall_grapheme': 0.995756, 'recall_vowel': 0.998314, 'recall_consonant': 0.995584, 'acc_grapheme': 0.995825, 'acc_vowel': 0.998534, 'acc_consonant': 0.998285, 'loss_grapheme': 0.065474, 'loss_vowel': 0.051958, 'loss_consonant': 0.038987}\n",
      "  134 | 0.000010 | 160512/160596 | 2.4008 | 2.4489 |\n",
      "val: {'recall': 0.995697, 'recall_grapheme': 0.994876, 'recall_vowel': 0.997763, 'recall_consonant': 0.995271, 'acc_grapheme': 0.994981, 'acc_vowel': 0.998161, 'acc_consonant': 0.997938, 'loss_grapheme': 0.043621, 'loss_vowel': 0.033373, 'loss_consonant': 0.02637}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  135 | 0.000009 | 160512/160596 | 2.9291 | 2.3746 |\n",
      "val: {'recall': 0.995782, 'recall_grapheme': 0.994889, 'recall_vowel': 0.997947, 'recall_consonant': 0.995405, 'acc_grapheme': 0.99508, 'acc_vowel': 0.99831, 'acc_consonant': 0.998037, 'loss_grapheme': 0.052319, 'loss_vowel': 0.041142, 'loss_consonant': 0.031809}\n",
      "  136 | 0.000007 | 160512/160596 | 0.4854 | 2.4913 |\n",
      "val: {'recall': 0.996287, 'recall_grapheme': 0.995737, 'recall_vowel': 0.998156, 'recall_consonant': 0.995517, 'acc_grapheme': 0.995751, 'acc_vowel': 0.998459, 'acc_consonant': 0.998285, 'loss_grapheme': 0.062107, 'loss_vowel': 0.049165, 'loss_consonant': 0.036187}\n",
      "  137 | 0.000006 | 160512/160596 | 2.4149 | 2.4376 |\n",
      "val: {'recall': 0.995406, 'recall_grapheme': 0.994094, 'recall_vowel': 0.997632, 'recall_consonant': 0.995806, 'acc_grapheme': 0.994185, 'acc_vowel': 0.997938, 'acc_consonant': 0.997764, 'loss_grapheme': 0.042492, 'loss_vowel': 0.031478, 'loss_consonant': 0.025419}\n",
      "  138 | 0.000005 | 160512/160596 | 1.7052 | 2.3806 |\n",
      "val: {'recall': 0.996498, 'recall_grapheme': 0.995822, 'recall_vowel': 0.998427, 'recall_consonant': 0.995923, 'acc_grapheme': 0.99585, 'acc_vowel': 0.998584, 'acc_consonant': 0.998484, 'loss_grapheme': 0.055784, 'loss_vowel': 0.0457, 'loss_consonant': 0.034942}\n",
      "  139 | 0.000004 | 160512/160596 | 2.4901 | 2.3361 |\n",
      "val: {'recall': 0.996163, 'recall_grapheme': 0.995493, 'recall_vowel': 0.998091, 'recall_consonant': 0.995576, 'acc_grapheme': 0.995353, 'acc_vowel': 0.998385, 'acc_consonant': 0.998261, 'loss_grapheme': 0.049635, 'loss_vowel': 0.037852, 'loss_consonant': 0.029666}\n",
      "  140 | 0.000004 | 160512/160596 | 0.7995 | 2.4431 |\n",
      "val: {'recall': 0.995801, 'recall_grapheme': 0.994838, 'recall_vowel': 0.998049, 'recall_consonant': 0.99548, 'acc_grapheme': 0.99513, 'acc_vowel': 0.998335, 'acc_consonant': 0.998012, 'loss_grapheme': 0.055901, 'loss_vowel': 0.045291, 'loss_consonant': 0.035012}\n",
      "  141 | 0.000003 | 160512/160596 | 2.7288 | 2.3997 |\n",
      "val: {'recall': 0.995955, 'recall_grapheme': 0.995173, 'recall_vowel': 0.997881, 'recall_consonant': 0.995595, 'acc_grapheme': 0.995204, 'acc_vowel': 0.99831, 'acc_consonant': 0.998136, 'loss_grapheme': 0.052951, 'loss_vowel': 0.041235, 'loss_consonant': 0.032013}\n",
      "  142 | 0.000002 | 160512/160596 | 3.4209 | 2.3774 |\n",
      "val: {'recall': 0.995912, 'recall_grapheme': 0.995128, 'recall_vowel': 0.997748, 'recall_consonant': 0.995642, 'acc_grapheme': 0.995155, 'acc_vowel': 0.998236, 'acc_consonant': 0.998186, 'loss_grapheme': 0.054585, 'loss_vowel': 0.042109, 'loss_consonant': 0.032586}\n",
      "  143 | 0.000002 | 160512/160596 | 2.0229 | 2.4601 |\n",
      "val: {'recall': 0.996024, 'recall_grapheme': 0.99519, 'recall_vowel': 0.998125, 'recall_consonant': 0.995592, 'acc_grapheme': 0.995353, 'acc_vowel': 0.998385, 'acc_consonant': 0.998236, 'loss_grapheme': 0.05119, 'loss_vowel': 0.040617, 'loss_consonant': 0.031369}\n",
      "  144 | 0.000001 | 160512/160596 | 2.4393 | 2.4446 |\n",
      "val: {'recall': 0.995506, 'recall_grapheme': 0.994644, 'recall_vowel': 0.997461, 'recall_consonant': 0.995275, 'acc_grapheme': 0.994558, 'acc_vowel': 0.998012, 'acc_consonant': 0.997913, 'loss_grapheme': 0.035076, 'loss_vowel': 0.024138, 'loss_consonant': 0.019807}\n",
      "  145 | 0.000001 | 160512/160596 | 3.3220 | 2.4207 |\n",
      "val: {'recall': 0.99572, 'recall_grapheme': 0.994881, 'recall_vowel': 0.997685, 'recall_consonant': 0.995434, 'acc_grapheme': 0.995179, 'acc_vowel': 0.998112, 'acc_consonant': 0.998012, 'loss_grapheme': 0.05584, 'loss_vowel': 0.045557, 'loss_consonant': 0.034605}\n",
      "  146 | 0.000000 | 160512/160596 | 2.5203 | 2.4440 |\n",
      "val: {'recall': 0.995344, 'recall_grapheme': 0.993998, 'recall_vowel': 0.997561, 'recall_consonant': 0.99582, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997838, 'acc_consonant': 0.997813, 'loss_grapheme': 0.041884, 'loss_vowel': 0.029578, 'loss_consonant': 0.023794}\n",
      "  147 | 0.000000 | 160512/160596 | 2.3778 | 2.4216 |\n",
      "val: {'recall': 0.996493, 'recall_grapheme': 0.995926, 'recall_vowel': 0.998444, 'recall_consonant': 0.995676, 'acc_grapheme': 0.996024, 'acc_vowel': 0.998584, 'acc_consonant': 0.998459, 'loss_grapheme': 0.060035, 'loss_vowel': 0.047148, 'loss_consonant': 0.0358}\n",
      "  148 | 0.000000 | 160512/160596 | 2.4091 | 2.5144 |\n",
      "val: {'recall': 0.995458, 'recall_grapheme': 0.994307, 'recall_vowel': 0.997681, 'recall_consonant': 0.995535, 'acc_grapheme': 0.994235, 'acc_vowel': 0.997863, 'acc_consonant': 0.997962, 'loss_grapheme': 0.041636, 'loss_vowel': 0.032205, 'loss_consonant': 0.025181}\n",
      "  149 | 0.000000 | 160512/160596 | 2.5006 | 2.4870 |\n",
      "val: {'recall': 0.99546, 'recall_grapheme': 0.994608, 'recall_vowel': 0.997417, 'recall_consonant': 0.995205, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997938, 'acc_consonant': 0.997863, 'loss_grapheme': 0.04044, 'loss_vowel': 0.029124, 'loss_consonant': 0.023564}\n",
      "CYCLE: 3\n",
      "{'recall': 0.99546, 'recall_grapheme': 0.994608, 'recall_vowel': 0.997417, 'recall_consonant': 0.995205, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997938, 'acc_consonant': 0.997863, 'loss_grapheme': 0.04044, 'loss_vowel': 0.029124, 'loss_consonant': 0.023564}\n",
      "    0 | 0.000040 | 160512/160596 | 1.0082 | 2.4688 |\n",
      "val: {'recall': 0.996413, 'recall_grapheme': 0.995757, 'recall_vowel': 0.998418, 'recall_consonant': 0.995719, 'acc_grapheme': 0.995875, 'acc_vowel': 0.998534, 'acc_consonant': 0.998285, 'loss_grapheme': 0.050304, 'loss_vowel': 0.037896, 'loss_consonant': 0.029316}\n",
      "###>>>>> saved\n",
      "    1 | 0.000080 | 160512/160596 | 2.1900 | 2.4933 |\n",
      "val: {'recall': 0.99606, 'recall_grapheme': 0.995541, 'recall_vowel': 0.997651, 'recall_consonant': 0.995509, 'acc_grapheme': 0.995155, 'acc_vowel': 0.998087, 'acc_consonant': 0.998161, 'loss_grapheme': 0.043254, 'loss_vowel': 0.031407, 'loss_consonant': 0.024906}\n",
      "    2 | 0.000120 | 160512/160596 | 2.3260 | 2.4741 |\n",
      "val: {'recall': 0.996625, 'recall_grapheme': 0.995784, 'recall_vowel': 0.99789, 'recall_consonant': 0.997043, 'acc_grapheme': 0.995676, 'acc_vowel': 0.99836, 'acc_consonant': 0.998385, 'loss_grapheme': 0.071914, 'loss_vowel': 0.059555, 'loss_consonant': 0.042136}\n",
      "###>>>>> saved\n",
      "    3 | 0.000160 | 160512/160596 | 2.7313 | 2.4303 |\n",
      "val: {'recall': 0.995846, 'recall_grapheme': 0.995027, 'recall_vowel': 0.997676, 'recall_consonant': 0.995654, 'acc_grapheme': 0.994856, 'acc_vowel': 0.998186, 'acc_consonant': 0.998062, 'loss_grapheme': 0.05493, 'loss_vowel': 0.040226, 'loss_consonant': 0.036159}\n",
      "    4 | 0.000199 | 160512/160596 | 2.5525 | 2.4695 |\n",
      "val: {'recall': 0.995294, 'recall_grapheme': 0.994076, 'recall_vowel': 0.99764, 'recall_consonant': 0.995382, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997962, 'acc_consonant': 0.997764, 'loss_grapheme': 0.051593, 'loss_vowel': 0.037526, 'loss_consonant': 0.029516}\n",
      "    5 | 0.000239 | 160512/160596 | 2.9780 | 2.5339 |\n",
      "val: {'recall': 0.99573, 'recall_grapheme': 0.995108, 'recall_vowel': 0.997444, 'recall_consonant': 0.99526, 'acc_grapheme': 0.995105, 'acc_vowel': 0.997913, 'acc_consonant': 0.998087, 'loss_grapheme': 0.058998, 'loss_vowel': 0.050955, 'loss_consonant': 0.039584}\n",
      "    6 | 0.000278 | 160512/160596 | 3.1511 | 2.5182 |\n",
      "val: {'recall': 0.993797, 'recall_grapheme': 0.992572, 'recall_vowel': 0.995859, 'recall_consonant': 0.994183, 'acc_grapheme': 0.992471, 'acc_vowel': 0.996968, 'acc_consonant': 0.997118, 'loss_grapheme': 0.036499, 'loss_vowel': 0.023036, 'loss_consonant': 0.020287}\n",
      "    7 | 0.000318 | 160512/160596 | 2.7213 | 2.6193 |\n",
      "val: {'recall': 0.994144, 'recall_grapheme': 0.993212, 'recall_vowel': 0.997222, 'recall_consonant': 0.992931, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997465, 'acc_consonant': 0.997018, 'loss_grapheme': 0.072097, 'loss_vowel': 0.053678, 'loss_consonant': 0.042387}\n",
      "    8 | 0.000357 | 160512/160596 | 2.2274 | 2.5713 |\n",
      "val: {'recall': 0.991929, 'recall_grapheme': 0.989263, 'recall_vowel': 0.995572, 'recall_consonant': 0.99362, 'acc_grapheme': 0.989936, 'acc_vowel': 0.996198, 'acc_consonant': 0.9959, 'loss_grapheme': 0.050532, 'loss_vowel': 0.029398, 'loss_consonant': 0.02555}\n",
      "    9 | 0.000395 | 160512/160596 | 2.7840 | 2.5975 |\n",
      "val: {'recall': 0.994873, 'recall_grapheme': 0.993123, 'recall_vowel': 0.997167, 'recall_consonant': 0.996079, 'acc_grapheme': 0.993589, 'acc_vowel': 0.997441, 'acc_consonant': 0.99754, 'loss_grapheme': 0.079884, 'loss_vowel': 0.05532, 'loss_consonant': 0.046624}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 | 0.000395 | 160512/160596 | 1.3006 | 2.5859 |\n",
      "val: {'recall': 0.994473, 'recall_grapheme': 0.993137, 'recall_vowel': 0.997218, 'recall_consonant': 0.994399, 'acc_grapheme': 0.993266, 'acc_vowel': 0.997465, 'acc_consonant': 0.997292, 'loss_grapheme': 0.073468, 'loss_vowel': 0.045225, 'loss_consonant': 0.034475}\n",
      "   11 | 0.000394 | 160512/160596 | 2.8290 | 2.5688 |\n",
      "val: {'recall': 0.995097, 'recall_grapheme': 0.994265, 'recall_vowel': 0.997337, 'recall_consonant': 0.994521, 'acc_grapheme': 0.994086, 'acc_vowel': 0.997863, 'acc_consonant': 0.997341, 'loss_grapheme': 0.048957, 'loss_vowel': 0.036477, 'loss_consonant': 0.030719}\n",
      "   12 | 0.000393 | 160512/160596 | 3.1117 | 2.5254 |\n",
      "val: {'recall': 0.994089, 'recall_grapheme': 0.992693, 'recall_vowel': 0.996719, 'recall_consonant': 0.994253, 'acc_grapheme': 0.992893, 'acc_vowel': 0.996968, 'acc_consonant': 0.996944, 'loss_grapheme': 0.070029, 'loss_vowel': 0.052624, 'loss_consonant': 0.041337}\n",
      "   13 | 0.000391 | 160512/160596 | 2.8474 | 2.5554 |\n",
      "val: {'recall': 0.993746, 'recall_grapheme': 0.992233, 'recall_vowel': 0.995828, 'recall_consonant': 0.994689, 'acc_grapheme': 0.992719, 'acc_vowel': 0.996944, 'acc_consonant': 0.996968, 'loss_grapheme': 0.050201, 'loss_vowel': 0.036976, 'loss_consonant': 0.026914}\n",
      "   14 | 0.000390 | 160512/160596 | 3.0159 | 2.6257 |\n",
      "val: {'recall': 0.995076, 'recall_grapheme': 0.993769, 'recall_vowel': 0.997131, 'recall_consonant': 0.995635, 'acc_grapheme': 0.993962, 'acc_vowel': 0.997664, 'acc_consonant': 0.997441, 'loss_grapheme': 0.097314, 'loss_vowel': 0.085597, 'loss_consonant': 0.05749}\n",
      "   15 | 0.000389 | 160512/160596 | 2.7995 | 2.5265 |\n",
      "val: {'recall': 0.9945, 'recall_grapheme': 0.992901, 'recall_vowel': 0.996577, 'recall_consonant': 0.995622, 'acc_grapheme': 0.993142, 'acc_vowel': 0.997292, 'acc_consonant': 0.997093, 'loss_grapheme': 0.062041, 'loss_vowel': 0.048658, 'loss_consonant': 0.038143}\n",
      "   16 | 0.000387 | 160512/160596 | 2.6568 | 2.6298 |\n",
      "val: {'recall': 0.992604, 'recall_grapheme': 0.990442, 'recall_vowel': 0.995238, 'recall_consonant': 0.994296, 'acc_grapheme': 0.990558, 'acc_vowel': 0.995676, 'acc_consonant': 0.996099, 'loss_grapheme': 0.060913, 'loss_vowel': 0.046259, 'loss_consonant': 0.03705}\n",
      "   17 | 0.000386 | 160512/160596 | 3.2621 | 2.6997 |\n",
      "val: {'recall': 0.992414, 'recall_grapheme': 0.99003, 'recall_vowel': 0.996259, 'recall_consonant': 0.993335, 'acc_grapheme': 0.991079, 'acc_vowel': 0.99672, 'acc_consonant': 0.996695, 'loss_grapheme': 0.07961, 'loss_vowel': 0.058151, 'loss_consonant': 0.04256}\n",
      "   18 | 0.000384 | 160512/160596 | 3.3882 | 2.5037 |\n",
      "val: {'recall': 0.995117, 'recall_grapheme': 0.994248, 'recall_vowel': 0.996527, 'recall_consonant': 0.995443, 'acc_grapheme': 0.993515, 'acc_vowel': 0.997093, 'acc_consonant': 0.997664, 'loss_grapheme': 0.06396, 'loss_vowel': 0.050691, 'loss_consonant': 0.038223}\n",
      "   19 | 0.000383 | 160512/160596 | 3.3083 | 2.5103 |\n",
      "val: {'recall': 0.995416, 'recall_grapheme': 0.993684, 'recall_vowel': 0.997358, 'recall_consonant': 0.996939, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997391, 'acc_consonant': 0.997341, 'loss_grapheme': 0.131269, 'loss_vowel': 0.131494, 'loss_consonant': 0.082984}\n",
      "   20 | 0.000381 | 160512/160596 | 2.6213 | 2.5682 |\n",
      "val: {'recall': 0.993192, 'recall_grapheme': 0.990719, 'recall_vowel': 0.995101, 'recall_consonant': 0.996227, 'acc_grapheme': 0.991527, 'acc_vowel': 0.996173, 'acc_consonant': 0.996571, 'loss_grapheme': 0.058773, 'loss_vowel': 0.041673, 'loss_consonant': 0.031543}\n",
      "   21 | 0.000379 | 160512/160596 | 2.0057 | 2.6104 |\n",
      "val: {'recall': 0.992351, 'recall_grapheme': 0.99085, 'recall_vowel': 0.995345, 'recall_consonant': 0.992357, 'acc_grapheme': 0.991427, 'acc_vowel': 0.996124, 'acc_consonant': 0.996024, 'loss_grapheme': 0.087723, 'loss_vowel': 0.070304, 'loss_consonant': 0.049581}\n",
      "   22 | 0.000377 | 160512/160596 | 2.2402 | 2.5335 |\n",
      "val: {'recall': 0.994793, 'recall_grapheme': 0.993403, 'recall_vowel': 0.996133, 'recall_consonant': 0.996233, 'acc_grapheme': 0.992769, 'acc_vowel': 0.996645, 'acc_consonant': 0.996521, 'loss_grapheme': 0.111539, 'loss_vowel': 0.100207, 'loss_consonant': 0.065741}\n",
      "   23 | 0.000375 | 160512/160596 | 2.8415 | 2.5572 |\n",
      "val: {'recall': 0.994584, 'recall_grapheme': 0.992932, 'recall_vowel': 0.996003, 'recall_consonant': 0.996468, 'acc_grapheme': 0.992073, 'acc_vowel': 0.996422, 'acc_consonant': 0.996795, 'loss_grapheme': 0.078197, 'loss_vowel': 0.061361, 'loss_consonant': 0.04479}\n",
      "   24 | 0.000373 | 160512/160596 | 1.7970 | 2.6051 |\n",
      "val: {'recall': 0.995016, 'recall_grapheme': 0.99359, 'recall_vowel': 0.996775, 'recall_consonant': 0.99611, 'acc_grapheme': 0.99339, 'acc_vowel': 0.997217, 'acc_consonant': 0.99759, 'loss_grapheme': 0.065141, 'loss_vowel': 0.054993, 'loss_consonant': 0.035267}\n",
      "   25 | 0.000371 | 160512/160596 | 2.9889 | 2.5387 |\n",
      "val: {'recall': 0.994731, 'recall_grapheme': 0.993205, 'recall_vowel': 0.996937, 'recall_consonant': 0.995579, 'acc_grapheme': 0.99339, 'acc_vowel': 0.997292, 'acc_consonant': 0.997391, 'loss_grapheme': 0.054429, 'loss_vowel': 0.040596, 'loss_consonant': 0.029427}\n",
      "   26 | 0.000369 | 160512/160596 | 2.7747 | 2.5672 |\n",
      "val: {'recall': 0.994156, 'recall_grapheme': 0.992384, 'recall_vowel': 0.996726, 'recall_consonant': 0.99513, 'acc_grapheme': 0.992545, 'acc_vowel': 0.997192, 'acc_consonant': 0.997192, 'loss_grapheme': 0.090182, 'loss_vowel': 0.069648, 'loss_consonant': 0.051127}\n",
      "   27 | 0.000367 | 160512/160596 | 3.3714 | 2.5492 |\n",
      "val: {'recall': 0.994915, 'recall_grapheme': 0.993393, 'recall_vowel': 0.997165, 'recall_consonant': 0.995707, 'acc_grapheme': 0.993589, 'acc_vowel': 0.997441, 'acc_consonant': 0.99759, 'loss_grapheme': 0.082542, 'loss_vowel': 0.072648, 'loss_consonant': 0.052488}\n",
      "   28 | 0.000364 | 160512/160596 | 1.2792 | 2.4928 |\n",
      "val: {'recall': 0.995042, 'recall_grapheme': 0.993387, 'recall_vowel': 0.997241, 'recall_consonant': 0.996154, 'acc_grapheme': 0.994235, 'acc_vowel': 0.997565, 'acc_consonant': 0.99754, 'loss_grapheme': 0.061541, 'loss_vowel': 0.046931, 'loss_consonant': 0.036836}\n",
      "   29 | 0.000362 | 160512/160596 | 0.5037 | 2.5856 |\n",
      "val: {'recall': 0.995119, 'recall_grapheme': 0.993492, 'recall_vowel': 0.99755, 'recall_consonant': 0.995941, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997987, 'acc_consonant': 0.997788, 'loss_grapheme': 0.096581, 'loss_vowel': 0.07959, 'loss_consonant': 0.05443}\n",
      "   30 | 0.000359 | 160512/160596 | 3.4104 | 2.5736 |\n",
      "val: {'recall': 0.992191, 'recall_grapheme': 0.98982, 'recall_vowel': 0.99588, 'recall_consonant': 0.993243, 'acc_grapheme': 0.990433, 'acc_vowel': 0.996049, 'acc_consonant': 0.996074, 'loss_grapheme': 0.061358, 'loss_vowel': 0.048546, 'loss_consonant': 0.033894}\n",
      "   31 | 0.000357 | 160512/160596 | 3.8653 | 2.5711 |\n",
      "val: {'recall': 0.995241, 'recall_grapheme': 0.994363, 'recall_vowel': 0.997401, 'recall_consonant': 0.994837, 'acc_grapheme': 0.994359, 'acc_vowel': 0.997863, 'acc_consonant': 0.997664, 'loss_grapheme': 0.072521, 'loss_vowel': 0.062435, 'loss_consonant': 0.043776}\n",
      "   32 | 0.000354 | 160512/160596 | 1.6811 | 2.5363 |\n",
      "val: {'recall': 0.993834, 'recall_grapheme': 0.992173, 'recall_vowel': 0.996545, 'recall_consonant': 0.994445, 'acc_grapheme': 0.99267, 'acc_vowel': 0.996844, 'acc_consonant': 0.996993, 'loss_grapheme': 0.064532, 'loss_vowel': 0.047024, 'loss_consonant': 0.038141}\n",
      "   33 | 0.000351 | 160512/160596 | 1.5080 | 2.5885 |\n",
      "val: {'recall': 0.994868, 'recall_grapheme': 0.993508, 'recall_vowel': 0.996932, 'recall_consonant': 0.995524, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997441, 'acc_consonant': 0.99754, 'loss_grapheme': 0.063378, 'loss_vowel': 0.048765, 'loss_consonant': 0.036657}\n",
      "   34 | 0.000349 | 160512/160596 | 2.7966 | 2.5222 |"
     ]
    }
   ],
   "source": [
    "train(args, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.997662, 'recall_grapheme': 0.997015, 'recall_vowel': 0.998562, 'recall_consonant': 0.998055, 'acc_grapheme': 0.996397, 'acc_vowel': 0.998484, 'acc_consonant': 0.998758, 'loss_grapheme': 0.020853, 'loss_vowel': 0.012834, 'loss_consonant': 0.009888}\n",
      "    0 | 0.000001 | 153600/160596 | 1.4446 | 0.9656 |\n",
      "val: {'recall': 0.99721, 'recall_grapheme': 0.996408, 'recall_vowel': 0.998129, 'recall_consonant': 0.997894, 'acc_grapheme': 0.995751, 'acc_vowel': 0.998261, 'acc_consonant': 0.998559, 'loss_grapheme': 0.035584, 'loss_vowel': 0.026779, 'loss_consonant': 0.018523}\n",
      "    1 | 0.000003 | 146688/160596 | 0.0003 | 0.9426 |\n",
      "val: {'recall': 0.996978, 'recall_grapheme': 0.996377, 'recall_vowel': 0.998253, 'recall_consonant': 0.996908, 'acc_grapheme': 0.996024, 'acc_vowel': 0.99841, 'acc_consonant': 0.998758, 'loss_grapheme': 0.02673, 'loss_vowel': 0.017341, 'loss_consonant': 0.011721}\n",
      "    2 | 0.000008 | 139776/160596 | 2.2016 | 1.0837 |\n",
      "val: {'recall': 0.996654, 'recall_grapheme': 0.995485, 'recall_vowel': 0.997848, 'recall_consonant': 0.9978, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998136, 'acc_consonant': 0.998261, 'loss_grapheme': 0.077165, 'loss_vowel': 0.052803, 'loss_consonant': 0.031131}\n",
      "    3 | 0.000015 | 132864/160596 | 0.0016 | 0.9146 |\n",
      "val: {'recall': 0.996924, 'recall_grapheme': 0.995914, 'recall_vowel': 0.997884, 'recall_consonant': 0.997985, 'acc_grapheme': 0.995577, 'acc_vowel': 0.998161, 'acc_consonant': 0.998335, 'loss_grapheme': 0.038599, 'loss_vowel': 0.02512, 'loss_consonant': 0.015468}\n",
      "    4 | 0.000026 | 125952/160596 | 2.1179 | 0.9482 |\n",
      "val: {'recall': 0.996378, 'recall_grapheme': 0.995236, 'recall_vowel': 0.997775, 'recall_consonant': 0.997266, 'acc_grapheme': 0.994335, 'acc_vowel': 0.998062, 'acc_consonant': 0.998261, 'loss_grapheme': 0.045956, 'loss_vowel': 0.030082, 'loss_consonant': 0.018945}\n",
      "    5 | 0.000038 | 119040/160596 | 1.5685 | 1.0479 |\n",
      "val: {'recall': 0.995807, 'recall_grapheme': 0.994417, 'recall_vowel': 0.997479, 'recall_consonant': 0.996915, 'acc_grapheme': 0.993912, 'acc_vowel': 0.997863, 'acc_consonant': 0.997962, 'loss_grapheme': 0.051335, 'loss_vowel': 0.035933, 'loss_consonant': 0.023057}\n",
      "    6 | 0.000050 | 112128/160596 | 2.3612 | 1.1071 |\n",
      "val: {'recall': 0.995804, 'recall_grapheme': 0.994389, 'recall_vowel': 0.99743, 'recall_consonant': 0.99701, 'acc_grapheme': 0.99421, 'acc_vowel': 0.997664, 'acc_consonant': 0.997938, 'loss_grapheme': 0.034911, 'loss_vowel': 0.019947, 'loss_consonant': 0.013827}\n",
      "    7 | 0.000063 | 105216/160596 | 0.0150 | 0.8922 |\n",
      "val: {'recall': 0.996128, 'recall_grapheme': 0.994843, 'recall_vowel': 0.997582, 'recall_consonant': 0.997245, 'acc_grapheme': 0.994136, 'acc_vowel': 0.998062, 'acc_consonant': 0.997838, 'loss_grapheme': 0.032961, 'loss_vowel': 0.019604, 'loss_consonant': 0.013704}\n",
      "    8 | 0.000075 | 098304/160596 | 2.4333 | 1.0116 |\n",
      "val: {'recall': 0.99581, 'recall_grapheme': 0.994465, 'recall_vowel': 0.997093, 'recall_consonant': 0.997218, 'acc_grapheme': 0.993639, 'acc_vowel': 0.997565, 'acc_consonant': 0.997664, 'loss_grapheme': 0.050414, 'loss_vowel': 0.032681, 'loss_consonant': 0.0197}\n",
      "    9 | 0.000086 | 091392/160596 | 1.1888 | 1.1131 |\n",
      "val: {'recall': 0.995124, 'recall_grapheme': 0.993486, 'recall_vowel': 0.99701, 'recall_consonant': 0.996513, 'acc_grapheme': 0.99257, 'acc_vowel': 0.997416, 'acc_consonant': 0.997366, 'loss_grapheme': 0.064794, 'loss_vowel': 0.042811, 'loss_consonant': 0.026922}\n",
      "   10 | 0.000093 | 084480/160596 | 1.8024 | 1.0345 |\n",
      "val: {'recall': 0.992842, 'recall_grapheme': 0.989756, 'recall_vowel': 0.99555, 'recall_consonant': 0.996307, 'acc_grapheme': 0.99098, 'acc_vowel': 0.996148, 'acc_consonant': 0.996322, 'loss_grapheme': 0.078752, 'loss_vowel': 0.053023, 'loss_consonant': 0.032966}\n",
      "   11 | 0.000098 | 077568/160596 | 2.4720 | 1.1585 |\n",
      "val: {'recall': 0.994889, 'recall_grapheme': 0.992744, 'recall_vowel': 0.996733, 'recall_consonant': 0.997335, 'acc_grapheme': 0.992421, 'acc_vowel': 0.997391, 'acc_consonant': 0.997267, 'loss_grapheme': 0.040949, 'loss_vowel': 0.025682, 'loss_consonant': 0.019117}\n",
      "   12 | 0.000100 | 070656/160596 | 1.2771 | 1.2080 |\n",
      "val: {'recall': 0.991742, 'recall_grapheme': 0.98903, 'recall_vowel': 0.994744, 'recall_consonant': 0.994164, 'acc_grapheme': 0.989166, 'acc_vowel': 0.9959, 'acc_consonant': 0.995353, 'loss_grapheme': 0.057679, 'loss_vowel': 0.03692, 'loss_consonant': 0.0312}\n",
      "   13 | 0.000098 | 063744/160596 | 1.6442 | 0.9063 |\n",
      "val: {'recall': 0.995075, 'recall_grapheme': 0.993331, 'recall_vowel': 0.997132, 'recall_consonant': 0.996504, 'acc_grapheme': 0.993415, 'acc_vowel': 0.997515, 'acc_consonant': 0.997366, 'loss_grapheme': 0.068795, 'loss_vowel': 0.037515, 'loss_consonant': 0.025269}\n",
      "   14 | 0.000093 | 056832/160596 | 2.0838 | 0.9192 |\n",
      "val: {'recall': 0.994824, 'recall_grapheme': 0.993112, 'recall_vowel': 0.996423, 'recall_consonant': 0.99665, 'acc_grapheme': 0.993042, 'acc_vowel': 0.997018, 'acc_consonant': 0.996894, 'loss_grapheme': 0.048797, 'loss_vowel': 0.036873, 'loss_consonant': 0.025488}\n",
      "   15 | 0.000086 | 049920/160596 | 0.6911 | 0.9841 |\n",
      "val: {'recall': 0.99554, 'recall_grapheme': 0.99441, 'recall_vowel': 0.996872, 'recall_consonant': 0.996469, 'acc_grapheme': 0.994508, 'acc_vowel': 0.997391, 'acc_consonant': 0.997441, 'loss_grapheme': 0.033885, 'loss_vowel': 0.018649, 'loss_consonant': 0.0146}\n",
      "   16 | 0.000075 | 043008/160596 | 0.0038 | 0.9497 |\n",
      "val: {'recall': 0.994634, 'recall_grapheme': 0.992874, 'recall_vowel': 0.995454, 'recall_consonant': 0.997335, 'acc_grapheme': 0.99257, 'acc_vowel': 0.996968, 'acc_consonant': 0.997068, 'loss_grapheme': 0.038381, 'loss_vowel': 0.020663, 'loss_consonant': 0.016488}\n",
      "   17 | 0.000063 | 036096/160596 | 2.5681 | 0.9856 |\n",
      "val: {'recall': 0.995994, 'recall_grapheme': 0.994645, 'recall_vowel': 0.997031, 'recall_consonant': 0.997655, 'acc_grapheme': 0.99431, 'acc_vowel': 0.997515, 'acc_consonant': 0.997863, 'loss_grapheme': 0.041613, 'loss_vowel': 0.024687, 'loss_consonant': 0.015536}\n",
      "   18 | 0.000051 | 029184/160596 | 1.2529 | 1.2943 |\n",
      "val: {'recall': 0.994871, 'recall_grapheme': 0.992849, 'recall_vowel': 0.997083, 'recall_consonant': 0.996702, 'acc_grapheme': 0.993042, 'acc_vowel': 0.99754, 'acc_consonant': 0.997689, 'loss_grapheme': 0.05621, 'loss_vowel': 0.035765, 'loss_consonant': 0.024142}\n",
      "   19 | 0.000038 | 022272/160596 | 1.9300 | 1.1219 |\n",
      "val: {'recall': 0.995641, 'recall_grapheme': 0.993844, 'recall_vowel': 0.997422, 'recall_consonant': 0.997453, 'acc_grapheme': 0.993539, 'acc_vowel': 0.997838, 'acc_consonant': 0.997987, 'loss_grapheme': 0.05348, 'loss_vowel': 0.033281, 'loss_consonant': 0.021696}\n",
      "   20 | 0.000026 | 015360/160596 | 1.4464 | 1.2543 |\n",
      "val: {'recall': 0.996209, 'recall_grapheme': 0.994884, 'recall_vowel': 0.99733, 'recall_consonant': 0.99774, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997913, 'acc_consonant': 0.998037, 'loss_grapheme': 0.057515, 'loss_vowel': 0.040231, 'loss_consonant': 0.025945}\n",
      "   21 | 0.000015 | 008448/160596 | 0.0017 | 0.4330 |\n",
      "val: {'recall': 0.996866, 'recall_grapheme': 0.996001, 'recall_vowel': 0.997389, 'recall_consonant': 0.998073, 'acc_grapheme': 0.995279, 'acc_vowel': 0.998236, 'acc_consonant': 0.99836, 'loss_grapheme': 0.019973, 'loss_vowel': 0.008795, 'loss_consonant': 0.007538}\n",
      "   22 | 0.000008 | 001536/160596 | 1.7796 | 0.8912 |\n",
      "val: {'recall': 0.996182, 'recall_grapheme': 0.995224, 'recall_vowel': 0.997055, 'recall_consonant': 0.997227, 'acc_grapheme': 0.99431, 'acc_vowel': 0.998012, 'acc_consonant': 0.998012, 'loss_grapheme': 0.03198, 'loss_vowel': 0.01965, 'loss_consonant': 0.013992}\n",
      "   22 | 0.000003 | 155136/160596 | 1.9170 | 1.1634 |\n",
      "val: {'recall': 0.995465, 'recall_grapheme': 0.994156, 'recall_vowel': 0.996531, 'recall_consonant': 0.997017, 'acc_grapheme': 0.993564, 'acc_vowel': 0.99754, 'acc_consonant': 0.997689, 'loss_grapheme': 0.065856, 'loss_vowel': 0.046143, 'loss_consonant': 0.030053}\n",
      "   23 | 0.000001 | 148224/160596 | 1.8931 | 0.9681 |\n",
      "val: {'recall': 0.995888, 'recall_grapheme': 0.994668, 'recall_vowel': 0.997032, 'recall_consonant': 0.997183, 'acc_grapheme': 0.993912, 'acc_vowel': 0.997962, 'acc_consonant': 0.997913, 'loss_grapheme': 0.032635, 'loss_vowel': 0.019575, 'loss_consonant': 0.014321}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 0.000003 | 141312/160596 | 0.0016 | 0.8818 |\n",
      "val: {'recall': 0.996344, 'recall_grapheme': 0.995153, 'recall_vowel': 0.997321, 'recall_consonant': 0.997749, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997888, 'acc_consonant': 0.998112, 'loss_grapheme': 0.034706, 'loss_vowel': 0.021441, 'loss_consonant': 0.014329}\n",
      "   25 | 0.000008 | 134400/160596 | 2.5486 | 0.8915 |\n",
      "val: {'recall': 0.995837, 'recall_grapheme': 0.994888, 'recall_vowel': 0.99658, 'recall_consonant': 0.996992, 'acc_grapheme': 0.994086, 'acc_vowel': 0.997813, 'acc_consonant': 0.997788, 'loss_grapheme': 0.031059, 'loss_vowel': 0.01747, 'loss_consonant': 0.013197}\n",
      "   26 | 0.000015 | 127488/160596 | 0.0078 | 0.9009 |\n",
      "val: {'recall': 0.996001, 'recall_grapheme': 0.994741, 'recall_vowel': 0.997254, 'recall_consonant': 0.997269, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997962, 'acc_consonant': 0.998037, 'loss_grapheme': 0.026482, 'loss_vowel': 0.012969, 'loss_consonant': 0.010198}\n",
      "   27 | 0.000026 | 120576/160596 | 0.4286 | 0.8478 |\n",
      "val: {'recall': 0.996316, 'recall_grapheme': 0.995384, 'recall_vowel': 0.997163, 'recall_consonant': 0.997334, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997938, 'acc_consonant': 0.998261, 'loss_grapheme': 0.025818, 'loss_vowel': 0.012824, 'loss_consonant': 0.009474}\n",
      "   28 | 0.000038 | 113664/160596 | 0.0104 | 0.9464 |\n",
      "val: {'recall': 0.995813, 'recall_grapheme': 0.994247, 'recall_vowel': 0.997163, 'recall_consonant': 0.997593, 'acc_grapheme': 0.993962, 'acc_vowel': 0.997689, 'acc_consonant': 0.997938, 'loss_grapheme': 0.037617, 'loss_vowel': 0.022057, 'loss_consonant': 0.015113}\n",
      "   29 | 0.000050 | 106752/160596 | 0.0069 | 1.0586 |\n",
      "val: {'recall': 0.99597, 'recall_grapheme': 0.994766, 'recall_vowel': 0.997289, 'recall_consonant': 0.997059, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997888, 'acc_consonant': 0.997739, 'loss_grapheme': 0.034702, 'loss_vowel': 0.021562, 'loss_consonant': 0.016014}\n",
      "   30 | 0.000063 | 099840/160596 | 0.0044 | 0.8938 |\n",
      "val: {'recall': 0.996035, 'recall_grapheme': 0.994586, 'recall_vowel': 0.997246, 'recall_consonant': 0.997722, 'acc_grapheme': 0.993912, 'acc_vowel': 0.997863, 'acc_consonant': 0.997764, 'loss_grapheme': 0.038238, 'loss_vowel': 0.020118, 'loss_consonant': 0.014677}\n",
      "   31 | 0.000075 | 092928/160596 | 0.0098 | 0.8354 |\n",
      "val: {'recall': 0.995979, 'recall_grapheme': 0.99472, 'recall_vowel': 0.996883, 'recall_consonant': 0.997595, 'acc_grapheme': 0.994012, 'acc_vowel': 0.997764, 'acc_consonant': 0.997515, 'loss_grapheme': 0.025415, 'loss_vowel': 0.009731, 'loss_consonant': 0.01051}\n",
      "   32 | 0.000086 | 086016/160596 | 0.2941 | 1.0335 |\n",
      "val: {'recall': 0.996008, 'recall_grapheme': 0.994575, 'recall_vowel': 0.996753, 'recall_consonant': 0.99813, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997764, 'acc_consonant': 0.997764, 'loss_grapheme': 0.038594, 'loss_vowel': 0.02371, 'loss_consonant': 0.015153}\n",
      "   33 | 0.000093 | 079104/160596 | 1.4509 | 1.0953 |\n",
      "val: {'recall': 0.991496, 'recall_grapheme': 0.989244, 'recall_vowel': 0.994711, 'recall_consonant': 0.992784, 'acc_grapheme': 0.988942, 'acc_vowel': 0.99585, 'acc_consonant': 0.995751, 'loss_grapheme': 0.114872, 'loss_vowel': 0.061235, 'loss_consonant': 0.044041}\n",
      "   34 | 0.000098 | 072192/160596 | 1.4406 | 1.0177 |\n",
      "val: {'recall': 0.995911, 'recall_grapheme': 0.994131, 'recall_vowel': 0.997636, 'recall_consonant': 0.997744, 'acc_grapheme': 0.994136, 'acc_vowel': 0.998087, 'acc_consonant': 0.997913, 'loss_grapheme': 0.041429, 'loss_vowel': 0.021591, 'loss_consonant': 0.014962}\n",
      "   35 | 0.000100 | 065280/160596 | 1.7697 | 0.6844 |\n",
      "val: {'recall': 0.995802, 'recall_grapheme': 0.994403, 'recall_vowel': 0.997142, 'recall_consonant': 0.997262, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997714, 'acc_consonant': 0.997764, 'loss_grapheme': 0.028664, 'loss_vowel': 0.014362, 'loss_consonant': 0.011542}\n",
      "   36 | 0.000098 | 058368/160596 | 2.6673 | 1.0800 |\n",
      "val: {'recall': 0.99525, 'recall_grapheme': 0.993526, 'recall_vowel': 0.996349, 'recall_consonant': 0.9976, 'acc_grapheme': 0.992521, 'acc_vowel': 0.997341, 'acc_consonant': 0.997391, 'loss_grapheme': 0.103488, 'loss_vowel': 0.055973, 'loss_consonant': 0.034023}\n",
      "   37 | 0.000093 | 051456/160596 | 0.0081 | 0.9497 |\n",
      "val: {'recall': 0.995589, 'recall_grapheme': 0.993944, 'recall_vowel': 0.997268, 'recall_consonant': 0.997199, 'acc_grapheme': 0.993713, 'acc_vowel': 0.997689, 'acc_consonant': 0.998062, 'loss_grapheme': 0.044171, 'loss_vowel': 0.02657, 'loss_consonant': 0.01741}\n",
      "   38 | 0.000086 | 044544/160596 | 0.0034 | 0.8465 |\n",
      "val: {'recall': 0.994314, 'recall_grapheme': 0.993033, 'recall_vowel': 0.996874, 'recall_consonant': 0.994317, 'acc_grapheme': 0.992744, 'acc_vowel': 0.997267, 'acc_consonant': 0.997267, 'loss_grapheme': 0.043618, 'loss_vowel': 0.026066, 'loss_consonant': 0.018467}\n",
      "   39 | 0.000075 | 037632/160596 | 0.0024 | 0.9551 |\n",
      "val: {'recall': 0.995897, 'recall_grapheme': 0.994414, 'recall_vowel': 0.997361, 'recall_consonant': 0.997401, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997838, 'acc_consonant': 0.998012, 'loss_grapheme': 0.030637, 'loss_vowel': 0.017003, 'loss_consonant': 0.012027}\n",
      "   40 | 0.000063 | 030720/160596 | 0.0080 | 0.8754 |\n",
      "val: {'recall': 0.996153, 'recall_grapheme': 0.994541, 'recall_vowel': 0.997617, 'recall_consonant': 0.997914, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997913, 'acc_consonant': 0.997615, 'loss_grapheme': 0.032582, 'loss_vowel': 0.015462, 'loss_consonant': 0.013298}\n",
      "   41 | 0.000051 | 023808/160596 | 2.0360 | 1.0825 |\n",
      "val: {'recall': 0.995789, 'recall_grapheme': 0.993971, 'recall_vowel': 0.997345, 'recall_consonant': 0.997867, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997764, 'acc_consonant': 0.997987, 'loss_grapheme': 0.046084, 'loss_vowel': 0.027521, 'loss_consonant': 0.018959}\n",
      "   42 | 0.000038 | 016896/160596 | 0.0039 | 0.6861 |\n",
      "val: {'recall': 0.996535, 'recall_grapheme': 0.995536, 'recall_vowel': 0.997722, 'recall_consonant': 0.997346, 'acc_grapheme': 0.995155, 'acc_vowel': 0.998136, 'acc_consonant': 0.998161, 'loss_grapheme': 0.025207, 'loss_vowel': 0.012109, 'loss_consonant': 0.009378}\n",
      "   43 | 0.000026 | 009984/160596 | 1.6861 | 0.7817 |\n",
      "val: {'recall': 0.996347, 'recall_grapheme': 0.995257, 'recall_vowel': 0.997707, 'recall_consonant': 0.99717, 'acc_grapheme': 0.995105, 'acc_vowel': 0.998136, 'acc_consonant': 0.998087, 'loss_grapheme': 0.027501, 'loss_vowel': 0.013859, 'loss_consonant': 0.010162}\n",
      "   44 | 0.000015 | 003072/160596 | 0.0008 | 1.0968 |\n",
      "val: {'recall': 0.996745, 'recall_grapheme': 0.995564, 'recall_vowel': 0.998059, 'recall_consonant': 0.997792, 'acc_grapheme': 0.995179, 'acc_vowel': 0.99841, 'acc_consonant': 0.998211, 'loss_grapheme': 0.023996, 'loss_vowel': 0.010887, 'loss_consonant': 0.008736}\n",
      "   44 | 0.000008 | 156672/160596 | 0.0020 | 0.9933 |\n",
      "val: {'recall': 0.996324, 'recall_grapheme': 0.994968, 'recall_vowel': 0.997775, 'recall_consonant': 0.997585, 'acc_grapheme': 0.994484, 'acc_vowel': 0.998012, 'acc_consonant': 0.998037, 'loss_grapheme': 0.032712, 'loss_vowel': 0.0179, 'loss_consonant': 0.012895}\n",
      "   45 | 0.000003 | 149760/160596 | 1.5033 | 0.9876 |\n",
      "val: {'recall': 0.995032, 'recall_grapheme': 0.993643, 'recall_vowel': 0.996917, 'recall_consonant': 0.995926, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997515, 'acc_consonant': 0.998012, 'loss_grapheme': 0.057389, 'loss_vowel': 0.032949, 'loss_consonant': 0.021784}\n",
      "   46 | 0.000001 | 142848/160596 | 0.0055 | 0.9610 |\n",
      "val: {'recall': 0.995942, 'recall_grapheme': 0.994265, 'recall_vowel': 0.997538, 'recall_consonant': 0.997699, 'acc_grapheme': 0.994359, 'acc_vowel': 0.997913, 'acc_consonant': 0.997913, 'loss_grapheme': 0.037488, 'loss_vowel': 0.021237, 'loss_consonant': 0.014674}\n",
      "   47 | 0.000003 | 135936/160596 | 0.0014 | 1.0228 |\n",
      "val: {'recall': 0.995966, 'recall_grapheme': 0.994407, 'recall_vowel': 0.997479, 'recall_consonant': 0.99757, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997987, 'acc_consonant': 0.997913, 'loss_grapheme': 0.043092, 'loss_vowel': 0.024497, 'loss_consonant': 0.016795}\n",
      "   48 | 0.000008 | 129024/160596 | 0.0091 | 0.8814 |\n",
      "val: {'recall': 0.996778, 'recall_grapheme': 0.995418, 'recall_vowel': 0.998376, 'recall_consonant': 0.997901, 'acc_grapheme': 0.995155, 'acc_vowel': 0.998559, 'acc_consonant': 0.998335, 'loss_grapheme': 0.027583, 'loss_vowel': 0.015253, 'loss_consonant': 0.011199}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 0.000015 | 122112/160596 | 0.0052 | 0.8903 |\n",
      "val: {'recall': 0.996326, 'recall_grapheme': 0.99521, 'recall_vowel': 0.997815, 'recall_consonant': 0.99707, 'acc_grapheme': 0.994956, 'acc_vowel': 0.998112, 'acc_consonant': 0.998136, 'loss_grapheme': 0.024882, 'loss_vowel': 0.011913, 'loss_consonant': 0.00914}\n",
      "   50 | 0.000026 | 115200/160596 | 1.7909 | 0.8895 |\n",
      "val: {'recall': 0.996179, 'recall_grapheme': 0.994923, 'recall_vowel': 0.997317, 'recall_consonant': 0.997551, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998037, 'acc_consonant': 0.998136, 'loss_grapheme': 0.03195, 'loss_vowel': 0.017314, 'loss_consonant': 0.012171}\n",
      "   51 | 0.000038 | 108288/160596 | 2.9374 | 1.1017 |\n",
      "val: {'recall': 0.99492, 'recall_grapheme': 0.99313, 'recall_vowel': 0.996908, 'recall_consonant': 0.996512, 'acc_grapheme': 0.993142, 'acc_vowel': 0.997615, 'acc_consonant': 0.997416, 'loss_grapheme': 0.042615, 'loss_vowel': 0.029905, 'loss_consonant': 0.022156}\n",
      "   52 | 0.000051 | 101376/160596 | 0.0255 | 1.0246 |\n",
      "val: {'recall': 0.995853, 'recall_grapheme': 0.994171, 'recall_vowel': 0.997484, 'recall_consonant': 0.997586, 'acc_grapheme': 0.993987, 'acc_vowel': 0.998136, 'acc_consonant': 0.997938, 'loss_grapheme': 0.039374, 'loss_vowel': 0.022352, 'loss_consonant': 0.015365}\n",
      "   53 | 0.000063 | 094464/160596 | 0.1464 | 1.0175 |\n",
      "val: {'recall': 0.996593, 'recall_grapheme': 0.995489, 'recall_vowel': 0.997554, 'recall_consonant': 0.997841, 'acc_grapheme': 0.995453, 'acc_vowel': 0.998112, 'acc_consonant': 0.99831, 'loss_grapheme': 0.029082, 'loss_vowel': 0.016985, 'loss_consonant': 0.011311}\n",
      "   54 | 0.000075 | 087552/160596 | 1.5184 | 1.0013 |\n",
      "val: {'recall': 0.995386, 'recall_grapheme': 0.993781, 'recall_vowel': 0.997068, 'recall_consonant': 0.996912, 'acc_grapheme': 0.993639, 'acc_vowel': 0.997788, 'acc_consonant': 0.99759, 'loss_grapheme': 0.036152, 'loss_vowel': 0.020991, 'loss_consonant': 0.014623}\n",
      "   55 | 0.000086 | 080640/160596 | 1.4807 | 0.9442 |\n",
      "val: {'recall': 0.995644, 'recall_grapheme': 0.994045, 'recall_vowel': 0.997117, 'recall_consonant': 0.997369, 'acc_grapheme': 0.993937, 'acc_vowel': 0.99759, 'acc_consonant': 0.99754, 'loss_grapheme': 0.034661, 'loss_vowel': 0.019096, 'loss_consonant': 0.0136}\n",
      "   56 | 0.000093 | 073728/160596 | 0.0159 | 0.8612 |\n",
      "val: {'recall': 0.996497, 'recall_grapheme': 0.995225, 'recall_vowel': 0.997367, 'recall_consonant': 0.998172, 'acc_grapheme': 0.995328, 'acc_vowel': 0.997888, 'acc_consonant': 0.997938, 'loss_grapheme': 0.026207, 'loss_vowel': 0.016544, 'loss_consonant': 0.011269}\n",
      "   57 | 0.000098 | 066816/160596 | 0.0151 | 0.9071 |\n",
      "val: {'recall': 0.995082, 'recall_grapheme': 0.993211, 'recall_vowel': 0.99692, 'recall_consonant': 0.996986, 'acc_grapheme': 0.993539, 'acc_vowel': 0.997639, 'acc_consonant': 0.997639, 'loss_grapheme': 0.03611, 'loss_vowel': 0.019226, 'loss_consonant': 0.013507}\n",
      "   58 | 0.000100 | 059904/160596 | 0.0032 | 1.0271 |\n",
      "val: {'recall': 0.994885, 'recall_grapheme': 0.993123, 'recall_vowel': 0.996971, 'recall_consonant': 0.996322, 'acc_grapheme': 0.99339, 'acc_vowel': 0.997515, 'acc_consonant': 0.997242, 'loss_grapheme': 0.034144, 'loss_vowel': 0.015475, 'loss_consonant': 0.013888}\n",
      "   59 | 0.000098 | 052992/160596 | 0.0062 | 1.1017 |\n",
      "val: {'recall': 0.99419, 'recall_grapheme': 0.992149, 'recall_vowel': 0.996146, 'recall_consonant': 0.996316, 'acc_grapheme': 0.992173, 'acc_vowel': 0.996745, 'acc_consonant': 0.996819, 'loss_grapheme': 0.036585, 'loss_vowel': 0.017999, 'loss_consonant': 0.014516}\n",
      "   60 | 0.000093 | 046080/160596 | 0.0088 | 1.2027 |\n",
      "val: {'recall': 0.995986, 'recall_grapheme': 0.994695, 'recall_vowel': 0.996669, 'recall_consonant': 0.997885, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997465, 'acc_consonant': 0.997739, 'loss_grapheme': 0.029057, 'loss_vowel': 0.013978, 'loss_consonant': 0.011082}\n",
      "   61 | 0.000086 | 039168/160596 | 0.0795 | 0.9107 |\n",
      "val: {'recall': 0.99524, 'recall_grapheme': 0.993676, 'recall_vowel': 0.99622, 'recall_consonant': 0.997389, 'acc_grapheme': 0.993813, 'acc_vowel': 0.997391, 'acc_consonant': 0.997565, 'loss_grapheme': 0.035057, 'loss_vowel': 0.019807, 'loss_consonant': 0.015672}\n",
      "   62 | 0.000075 | 032256/160596 | 0.0085 | 0.8198 |\n",
      "val: {'recall': 0.995736, 'recall_grapheme': 0.994827, 'recall_vowel': 0.99717, 'recall_consonant': 0.99612, 'acc_grapheme': 0.994409, 'acc_vowel': 0.997739, 'acc_consonant': 0.997714, 'loss_grapheme': 0.026926, 'loss_vowel': 0.013174, 'loss_consonant': 0.010006}\n",
      "   63 | 0.000063 | 025344/160596 | 0.0111 | 0.9423 |\n",
      "val: {'recall': 0.996175, 'recall_grapheme': 0.994868, 'recall_vowel': 0.997214, 'recall_consonant': 0.997749, 'acc_grapheme': 0.994086, 'acc_vowel': 0.997938, 'acc_consonant': 0.998112, 'loss_grapheme': 0.030701, 'loss_vowel': 0.015829, 'loss_consonant': 0.012403}\n",
      "   64 | 0.000051 | 018432/160596 | 0.0009 | 1.2308 |\n",
      "val: {'recall': 0.995305, 'recall_grapheme': 0.993743, 'recall_vowel': 0.996885, 'recall_consonant': 0.99685, 'acc_grapheme': 0.993912, 'acc_vowel': 0.998037, 'acc_consonant': 0.997962, 'loss_grapheme': 0.035897, 'loss_vowel': 0.020766, 'loss_consonant': 0.016136}\n",
      "   65 | 0.000038 | 011520/160596 | 0.4908 | 1.0446 |\n",
      "val: {'recall': 0.996678, 'recall_grapheme': 0.995621, 'recall_vowel': 0.997783, 'recall_consonant': 0.997685, 'acc_grapheme': 0.99503, 'acc_vowel': 0.998087, 'acc_consonant': 0.997913, 'loss_grapheme': 0.035522, 'loss_vowel': 0.021644, 'loss_consonant': 0.015899}\n",
      "   66 | 0.000026 | 004608/160596 | 0.0012 | 0.8405 |\n",
      "val: {'recall': 0.996112, 'recall_grapheme': 0.995049, 'recall_vowel': 0.9968, 'recall_consonant': 0.997549, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997938, 'acc_consonant': 0.998062, 'loss_grapheme': 0.02921, 'loss_vowel': 0.016223, 'loss_consonant': 0.01237}\n",
      "   66 | 0.000015 | 158208/160596 | 0.0024 | 0.9813 |\n",
      "val: {'recall': 0.996569, 'recall_grapheme': 0.995428, 'recall_vowel': 0.997145, 'recall_consonant': 0.998276, 'acc_grapheme': 0.995055, 'acc_vowel': 0.998136, 'acc_consonant': 0.998261, 'loss_grapheme': 0.020951, 'loss_vowel': 0.009393, 'loss_consonant': 0.007624}\n",
      "   67 | 0.000008 | 151296/160596 | 0.0039 | 0.9582 |\n",
      "val: {'recall': 0.996475, 'recall_grapheme': 0.995317, 'recall_vowel': 0.997549, 'recall_consonant': 0.997718, 'acc_grapheme': 0.99508, 'acc_vowel': 0.998261, 'acc_consonant': 0.998211, 'loss_grapheme': 0.022083, 'loss_vowel': 0.010282, 'loss_consonant': 0.008176}\n",
      "   68 | 0.000003 | 144384/160596 | 0.0012 | 0.9854 |\n",
      "val: {'recall': 0.996772, 'recall_grapheme': 0.995753, 'recall_vowel': 0.997563, 'recall_consonant': 0.998021, 'acc_grapheme': 0.995428, 'acc_vowel': 0.998236, 'acc_consonant': 0.998484, 'loss_grapheme': 0.018362, 'loss_vowel': 0.007859, 'loss_consonant': 0.006287}\n",
      "   69 | 0.000001 | 137472/160596 | 1.4791 | 0.9084 |\n",
      "val: {'recall': 0.996187, 'recall_grapheme': 0.994942, 'recall_vowel': 0.997381, 'recall_consonant': 0.997482, 'acc_grapheme': 0.994409, 'acc_vowel': 0.998112, 'acc_consonant': 0.998037, 'loss_grapheme': 0.032713, 'loss_vowel': 0.017725, 'loss_consonant': 0.012558}\n",
      "   70 | 0.000003 | 130560/160596 | 0.0034 | 0.8595 |\n",
      "val: {'recall': 0.997053, 'recall_grapheme': 0.995896, 'recall_vowel': 0.997822, 'recall_consonant': 0.998597, 'acc_grapheme': 0.995701, 'acc_vowel': 0.99831, 'acc_consonant': 0.998608, 'loss_grapheme': 0.017543, 'loss_vowel': 0.00798, 'loss_consonant': 0.006428}\n",
      "   71 | 0.000008 | 123648/160596 | 2.0626 | 0.9511 |\n",
      "val: {'recall': 0.99638, 'recall_grapheme': 0.995211, 'recall_vowel': 0.997423, 'recall_consonant': 0.997675, 'acc_grapheme': 0.994856, 'acc_vowel': 0.998112, 'acc_consonant': 0.998161, 'loss_grapheme': 0.025823, 'loss_vowel': 0.013182, 'loss_consonant': 0.010211}\n",
      "   72 | 0.000015 | 116736/160596 | 1.8229 | 0.8765 |\n",
      "val: {'recall': 0.996151, 'recall_grapheme': 0.995044, 'recall_vowel': 0.99707, 'recall_consonant': 0.997447, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997962, 'acc_consonant': 0.997888, 'loss_grapheme': 0.028043, 'loss_vowel': 0.014739, 'loss_consonant': 0.011822}\n",
      "   73 | 0.000026 | 109824/160596 | 2.7907 | 1.1028 |\n",
      "val: {'recall': 0.995218, 'recall_grapheme': 0.99351, 'recall_vowel': 0.99646, 'recall_consonant': 0.997392, 'acc_grapheme': 0.993266, 'acc_vowel': 0.997714, 'acc_consonant': 0.997764, 'loss_grapheme': 0.04008, 'loss_vowel': 0.024263, 'loss_consonant': 0.017053}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 0.000038 | 102912/160596 | 0.3834 | 0.9381 |\n",
      "val: {'recall': 0.996322, 'recall_grapheme': 0.994912, 'recall_vowel': 0.997788, 'recall_consonant': 0.997677, 'acc_grapheme': 0.994707, 'acc_vowel': 0.998112, 'acc_consonant': 0.998012, 'loss_grapheme': 0.034844, 'loss_vowel': 0.019049, 'loss_consonant': 0.012451}\n",
      "   75 | 0.000051 | 096000/160596 | 1.0288 | 1.1886 |\n",
      "val: {'recall': 0.995866, 'recall_grapheme': 0.994131, 'recall_vowel': 0.997229, 'recall_consonant': 0.997973, 'acc_grapheme': 0.993763, 'acc_vowel': 0.997664, 'acc_consonant': 0.997714, 'loss_grapheme': 0.036802, 'loss_vowel': 0.021659, 'loss_consonant': 0.01456}\n",
      "   76 | 0.000063 | 089088/160596 | 1.6046 | 1.0469 |\n",
      "val: {'recall': 0.995025, 'recall_grapheme': 0.993019, 'recall_vowel': 0.997337, 'recall_consonant': 0.996724, 'acc_grapheme': 0.993614, 'acc_vowel': 0.997813, 'acc_consonant': 0.997714, 'loss_grapheme': 0.057468, 'loss_vowel': 0.037118, 'loss_consonant': 0.023561}\n",
      "   77 | 0.000075 | 082176/160596 | 1.3180 | 1.0522 |\n",
      "val: {'recall': 0.995363, 'recall_grapheme': 0.993605, 'recall_vowel': 0.997108, 'recall_consonant': 0.997134, 'acc_grapheme': 0.993589, 'acc_vowel': 0.997689, 'acc_consonant': 0.997813, 'loss_grapheme': 0.051093, 'loss_vowel': 0.026831, 'loss_consonant': 0.020354}\n",
      "   78 | 0.000086 | 075264/160596 | 0.0123 | 1.0469 |\n",
      "val: {'recall': 0.995475, 'recall_grapheme': 0.994225, 'recall_vowel': 0.997126, 'recall_consonant': 0.996325, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997813, 'acc_consonant': 0.997018, 'loss_grapheme': 0.029347, 'loss_vowel': 0.010757, 'loss_consonant': 0.010965}\n",
      "   79 | 0.000093 | 068352/160596 | 0.0103 | 0.8809 |\n",
      "val: {'recall': 0.995334, 'recall_grapheme': 0.993925, 'recall_vowel': 0.996088, 'recall_consonant': 0.997399, 'acc_grapheme': 0.993813, 'acc_vowel': 0.997465, 'acc_consonant': 0.997888, 'loss_grapheme': 0.035509, 'loss_vowel': 0.018812, 'loss_consonant': 0.014528}\n",
      "   80 | 0.000098 | 061440/160596 | 0.0030 | 1.1173 |\n",
      "val: {'recall': 0.994948, 'recall_grapheme': 0.992636, 'recall_vowel': 0.996935, 'recall_consonant': 0.997584, 'acc_grapheme': 0.993614, 'acc_vowel': 0.997565, 'acc_consonant': 0.997639, 'loss_grapheme': 0.057034, 'loss_vowel': 0.027789, 'loss_consonant': 0.018521}\n",
      "   81 | 0.000100 | 054528/160596 | 0.3903 | 0.8719 |\n",
      "val: {'recall': 0.994577, 'recall_grapheme': 0.992786, 'recall_vowel': 0.997448, 'recall_consonant': 0.99529, 'acc_grapheme': 0.993192, 'acc_vowel': 0.997739, 'acc_consonant': 0.997441, 'loss_grapheme': 0.044895, 'loss_vowel': 0.022323, 'loss_consonant': 0.017515}\n",
      "   82 | 0.000098 | 047616/160596 | 0.0079 | 1.1336 |\n",
      "val: {'recall': 0.995269, 'recall_grapheme': 0.993424, 'recall_vowel': 0.996795, 'recall_consonant': 0.997432, 'acc_grapheme': 0.993316, 'acc_vowel': 0.997565, 'acc_consonant': 0.997962, 'loss_grapheme': 0.050212, 'loss_vowel': 0.032803, 'loss_consonant': 0.018993}\n",
      "   83 | 0.000093 | 040704/160596 | 1.8504 | 1.1614 |\n",
      "val: {'recall': 0.994886, 'recall_grapheme': 0.992827, 'recall_vowel': 0.996376, 'recall_consonant': 0.997515, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997118, 'acc_consonant': 0.997615, 'loss_grapheme': 0.034498, 'loss_vowel': 0.019925, 'loss_consonant': 0.014075}\n",
      "   84 | 0.000086 | 033792/160596 | 2.0181 | 0.7933 |\n",
      "val: {'recall': 0.994869, 'recall_grapheme': 0.992822, 'recall_vowel': 0.997159, 'recall_consonant': 0.996673, 'acc_grapheme': 0.993738, 'acc_vowel': 0.99759, 'acc_consonant': 0.997615, 'loss_grapheme': 0.031719, 'loss_vowel': 0.018985, 'loss_consonant': 0.014381}\n",
      "   85 | 0.000075 | 026880/160596 | 2.9641 | 1.2173 |\n",
      "val: {'recall': 0.994503, 'recall_grapheme': 0.992554, 'recall_vowel': 0.996499, 'recall_consonant': 0.996405, 'acc_grapheme': 0.992769, 'acc_vowel': 0.997167, 'acc_consonant': 0.997391, 'loss_grapheme': 0.049541, 'loss_vowel': 0.034328, 'loss_consonant': 0.023158}\n",
      "   86 | 0.000063 | 019968/160596 | 0.0112 | 0.8026 |\n",
      "val: {'recall': 0.994506, 'recall_grapheme': 0.991948, 'recall_vowel': 0.99692, 'recall_consonant': 0.997208, 'acc_grapheme': 0.992247, 'acc_vowel': 0.997441, 'acc_consonant': 0.997192, 'loss_grapheme': 0.036875, 'loss_vowel': 0.018782, 'loss_consonant': 0.014429}\n",
      "   87 | 0.000051 | 013056/160596 | 1.7025 | 1.1787 |\n",
      "val: {'recall': 0.994466, 'recall_grapheme': 0.992531, 'recall_vowel': 0.996407, 'recall_consonant': 0.996397, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997192, 'acc_consonant': 0.997267, 'loss_grapheme': 0.05143, 'loss_vowel': 0.032137, 'loss_consonant': 0.023383}\n",
      "   88 | 0.000038 | 006144/160596 | 0.0033 | 0.6637 |\n",
      "val: {'recall': 0.996159, 'recall_grapheme': 0.995027, 'recall_vowel': 0.997285, 'recall_consonant': 0.997299, 'acc_grapheme': 0.99508, 'acc_vowel': 0.998037, 'acc_consonant': 0.998285, 'loss_grapheme': 0.022038, 'loss_vowel': 0.009819, 'loss_consonant': 0.008024}\n",
      "   88 | 0.000026 | 159744/160596 | 0.0012 | 0.9675 |\n",
      "val: {'recall': 0.99582, 'recall_grapheme': 0.994214, 'recall_vowel': 0.997615, 'recall_consonant': 0.997236, 'acc_grapheme': 0.994658, 'acc_vowel': 0.997962, 'acc_consonant': 0.998136, 'loss_grapheme': 0.029111, 'loss_vowel': 0.014904, 'loss_consonant': 0.011293}\n",
      "   89 | 0.000015 | 152832/160596 | 0.0023 | 0.9198 |\n",
      "val: {'recall': 0.995916, 'recall_grapheme': 0.99444, 'recall_vowel': 0.997581, 'recall_consonant': 0.997202, 'acc_grapheme': 0.994707, 'acc_vowel': 0.998037, 'acc_consonant': 0.998037, 'loss_grapheme': 0.028522, 'loss_vowel': 0.014908, 'loss_consonant': 0.011629}\n",
      "   90 | 0.000008 | 145920/160596 | 2.0285 | 0.9250 |\n",
      "val: {'recall': 0.996085, 'recall_grapheme': 0.994515, 'recall_vowel': 0.997828, 'recall_consonant': 0.997481, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998062, 'acc_consonant': 0.998261, 'loss_grapheme': 0.024956, 'loss_vowel': 0.012505, 'loss_consonant': 0.01006}\n",
      "   91 | 0.000003 | 139008/160596 | 1.8618 | 1.1019 |\n",
      "val: {'recall': 0.995384, 'recall_grapheme': 0.993914, 'recall_vowel': 0.996947, 'recall_consonant': 0.996763, 'acc_grapheme': 0.99421, 'acc_vowel': 0.997739, 'acc_consonant': 0.998012, 'loss_grapheme': 0.030457, 'loss_vowel': 0.015734, 'loss_consonant': 0.012499}\n",
      "   92 | 0.000001 | 132096/160596 | 0.0044 | 0.9871 |\n",
      "val: {'recall': 0.995547, 'recall_grapheme': 0.993998, 'recall_vowel': 0.997036, 'recall_consonant': 0.997156, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997714, 'acc_consonant': 0.997888, 'loss_grapheme': 0.031949, 'loss_vowel': 0.017603, 'loss_consonant': 0.013383}\n",
      "   93 | 0.000003 | 125184/160596 | 1.7637 | 0.9686 |\n",
      "val: {'recall': 0.995896, 'recall_grapheme': 0.994378, 'recall_vowel': 0.997427, 'recall_consonant': 0.997399, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997888, 'acc_consonant': 0.998037, 'loss_grapheme': 0.030934, 'loss_vowel': 0.016966, 'loss_consonant': 0.012462}\n",
      "   94 | 0.000008 | 118272/160596 | 1.2775 | 0.8947 |\n",
      "val: {'recall': 0.996003, 'recall_grapheme': 0.994558, 'recall_vowel': 0.997465, 'recall_consonant': 0.997432, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997962, 'acc_consonant': 0.998261, 'loss_grapheme': 0.024729, 'loss_vowel': 0.011566, 'loss_consonant': 0.00928}\n",
      "   95 | 0.000015 | 111360/160596 | 0.4328 | 1.0014 |\n",
      "val: {'recall': 0.995975, 'recall_grapheme': 0.994542, 'recall_vowel': 0.99752, 'recall_consonant': 0.997295, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997987, 'acc_consonant': 0.998186, 'loss_grapheme': 0.050409, 'loss_vowel': 0.030536, 'loss_consonant': 0.019567}\n",
      "   96 | 0.000026 | 104448/160596 | 1.5110 | 1.0363 |\n",
      "val: {'recall': 0.996172, 'recall_grapheme': 0.994598, 'recall_vowel': 0.997824, 'recall_consonant': 0.997667, 'acc_grapheme': 0.994658, 'acc_vowel': 0.998112, 'acc_consonant': 0.998161, 'loss_grapheme': 0.032358, 'loss_vowel': 0.018411, 'loss_consonant': 0.01347}\n",
      "   97 | 0.000038 | 097536/160596 | 1.1214 | 0.8861 |\n",
      "val: {'recall': 0.995686, 'recall_grapheme': 0.994248, 'recall_vowel': 0.996685, 'recall_consonant': 0.997564, 'acc_grapheme': 0.994508, 'acc_vowel': 0.997863, 'acc_consonant': 0.998112, 'loss_grapheme': 0.028114, 'loss_vowel': 0.014393, 'loss_consonant': 0.010777}\n",
      "   98 | 0.000050 | 090624/160596 | 0.6691 | 1.0095 |\n",
      "val: {'recall': 0.995901, 'recall_grapheme': 0.994411, 'recall_vowel': 0.997136, 'recall_consonant': 0.997648, 'acc_grapheme': 0.994012, 'acc_vowel': 0.997788, 'acc_consonant': 0.998062, 'loss_grapheme': 0.039354, 'loss_vowel': 0.02036, 'loss_consonant': 0.014169}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99 | 0.000063 | 083712/160596 | 0.8658 | 0.8452 |\n",
      "val: {'recall': 0.995913, 'recall_grapheme': 0.994951, 'recall_vowel': 0.996933, 'recall_consonant': 0.996816, 'acc_grapheme': 0.994707, 'acc_vowel': 0.998062, 'acc_consonant': 0.997962, 'loss_grapheme': 0.02491, 'loss_vowel': 0.010231, 'loss_consonant': 0.00909}\n",
      "  100 | 0.000075 | 076800/160596 | 0.0090 | 1.0329 |\n",
      "val: {'recall': 0.995468, 'recall_grapheme': 0.993822, 'recall_vowel': 0.99734, 'recall_consonant': 0.996886, 'acc_grapheme': 0.993912, 'acc_vowel': 0.997788, 'acc_consonant': 0.997764, 'loss_grapheme': 0.038115, 'loss_vowel': 0.023456, 'loss_consonant': 0.016523}\n",
      "  101 | 0.000086 | 069888/160596 | 0.0022 | 0.9838 |\n",
      "val: {'recall': 0.995076, 'recall_grapheme': 0.993599, 'recall_vowel': 0.996583, 'recall_consonant': 0.996525, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997441, 'acc_consonant': 0.997664, 'loss_grapheme': 0.041703, 'loss_vowel': 0.023968, 'loss_consonant': 0.01549}\n",
      "  102 | 0.000093 | 062976/160596 | 2.5671 | 1.2142 |\n",
      "val: {'recall': 0.994872, 'recall_grapheme': 0.99333, 'recall_vowel': 0.996503, 'recall_consonant': 0.996326, 'acc_grapheme': 0.993316, 'acc_vowel': 0.997639, 'acc_consonant': 0.997316, 'loss_grapheme': 0.037311, 'loss_vowel': 0.020321, 'loss_consonant': 0.015914}\n",
      "  103 | 0.000098 | 056064/160596 | 2.4785 | 0.9947 |\n",
      "val: {'recall': 0.995356, 'recall_grapheme': 0.993329, 'recall_vowel': 0.997114, 'recall_consonant': 0.997651, 'acc_grapheme': 0.993415, 'acc_vowel': 0.997664, 'acc_consonant': 0.997764, 'loss_grapheme': 0.037835, 'loss_vowel': 0.020026, 'loss_consonant': 0.01433}\n",
      "  104 | 0.000100 | 049152/160596 | 0.0038 | 1.1921 |\n",
      "val: {'recall': 0.994282, 'recall_grapheme': 0.992192, 'recall_vowel': 0.996379, 'recall_consonant': 0.996363, 'acc_grapheme': 0.992645, 'acc_vowel': 0.996869, 'acc_consonant': 0.997068, 'loss_grapheme': 0.056363, 'loss_vowel': 0.034464, 'loss_consonant': 0.022103}\n",
      "  105 | 0.000098 | 042240/160596 | 2.2207 | 1.0900 |\n",
      "val: {'recall': 0.994855, 'recall_grapheme': 0.992783, 'recall_vowel': 0.997052, 'recall_consonant': 0.996803, 'acc_grapheme': 0.993067, 'acc_vowel': 0.997465, 'acc_consonant': 0.997416, 'loss_grapheme': 0.052333, 'loss_vowel': 0.031046, 'loss_consonant': 0.021514}\n",
      "  106 | 0.000093 | 035328/160596 | 1.4502 | 0.8062 |\n",
      "val: {'recall': 0.994859, 'recall_grapheme': 0.992915, 'recall_vowel': 0.997031, 'recall_consonant': 0.996574, 'acc_grapheme': 0.992819, 'acc_vowel': 0.997416, 'acc_consonant': 0.99754, 'loss_grapheme': 0.056153, 'loss_vowel': 0.031955, 'loss_consonant': 0.025202}\n",
      "  107 | 0.000086 | 028416/160596 | 0.8969 | 1.0495 |\n",
      "val: {'recall': 0.994155, 'recall_grapheme': 0.991615, 'recall_vowel': 0.996091, 'recall_consonant': 0.997299, 'acc_grapheme': 0.992123, 'acc_vowel': 0.996869, 'acc_consonant': 0.997167, 'loss_grapheme': 0.078147, 'loss_vowel': 0.035391, 'loss_consonant': 0.029132}\n",
      "  108 | 0.000075 | 021504/160596 | 0.0044 | 1.4032 |\n",
      "val: {'recall': 0.995345, 'recall_grapheme': 0.993558, 'recall_vowel': 0.996401, 'recall_consonant': 0.99786, 'acc_grapheme': 0.99339, 'acc_vowel': 0.997416, 'acc_consonant': 0.998037, 'loss_grapheme': 0.071595, 'loss_vowel': 0.044569, 'loss_consonant': 0.031628}\n",
      "  109 | 0.000063 | 014592/160596 | 0.0175 | 0.8759 |\n",
      "val: {'recall': 0.99622, 'recall_grapheme': 0.994896, 'recall_vowel': 0.997531, 'recall_consonant': 0.997555, 'acc_grapheme': 0.994906, 'acc_vowel': 0.997962, 'acc_consonant': 0.998062, 'loss_grapheme': 0.027863, 'loss_vowel': 0.016417, 'loss_consonant': 0.01137}\n",
      "  110 | 0.000050 | 007680/160596 | 1.5826 | 0.8890 |\n",
      "val: {'recall': 0.99588, 'recall_grapheme': 0.994171, 'recall_vowel': 0.997308, 'recall_consonant': 0.997872, 'acc_grapheme': 0.994881, 'acc_vowel': 0.997938, 'acc_consonant': 0.998112, 'loss_grapheme': 0.0252, 'loss_vowel': 0.014112, 'loss_consonant': 0.010987}\n",
      "  111 | 0.000038 | 000768/160596 | 1.6760 | 1.6760 |\n",
      "val: {'recall': 0.996194, 'recall_grapheme': 0.994763, 'recall_vowel': 0.997343, 'recall_consonant': 0.997908, 'acc_grapheme': 0.99503, 'acc_vowel': 0.997962, 'acc_consonant': 0.998186, 'loss_grapheme': 0.031277, 'loss_vowel': 0.016544, 'loss_consonant': 0.012418}\n",
      "  111 | 0.000026 | 154368/160596 | 1.6740 | 1.0114 |\n",
      "val: {'recall': 0.996453, 'recall_grapheme': 0.995179, 'recall_vowel': 0.997539, 'recall_consonant': 0.997914, 'acc_grapheme': 0.99508, 'acc_vowel': 0.998037, 'acc_consonant': 0.998211, 'loss_grapheme': 0.02707, 'loss_vowel': 0.015213, 'loss_consonant': 0.011285}\n",
      "  112 | 0.000015 | 147456/160596 | 2.8882 | 1.0579 |\n",
      "val: {'recall': 0.996298, 'recall_grapheme': 0.994971, 'recall_vowel': 0.997401, 'recall_consonant': 0.997849, 'acc_grapheme': 0.994608, 'acc_vowel': 0.998037, 'acc_consonant': 0.998186, 'loss_grapheme': 0.024201, 'loss_vowel': 0.011566, 'loss_consonant': 0.009239}\n",
      "  113 | 0.000008 | 140544/160596 | 1.8370 | 0.9441 |\n",
      "val: {'recall': 0.996457, 'recall_grapheme': 0.995237, 'recall_vowel': 0.997529, 'recall_consonant': 0.997825, 'acc_grapheme': 0.995229, 'acc_vowel': 0.998161, 'acc_consonant': 0.99831, 'loss_grapheme': 0.020964, 'loss_vowel': 0.010858, 'loss_consonant': 0.008433}\n",
      "  114 | 0.000003 | 133632/160596 | 1.9896 | 1.0292 |\n",
      "val: {'recall': 0.996191, 'recall_grapheme': 0.994833, 'recall_vowel': 0.997341, 'recall_consonant': 0.997756, 'acc_grapheme': 0.994732, 'acc_vowel': 0.997987, 'acc_consonant': 0.998261, 'loss_grapheme': 0.026531, 'loss_vowel': 0.014378, 'loss_consonant': 0.010939}\n",
      "  115 | 0.000001 | 126720/160596 | 0.0008 | 0.9647 |\n",
      "val: {'recall': 0.996888, 'recall_grapheme': 0.996041, 'recall_vowel': 0.997536, 'recall_consonant': 0.997934, 'acc_grapheme': 0.995527, 'acc_vowel': 0.998211, 'acc_consonant': 0.998435, 'loss_grapheme': 0.019545, 'loss_vowel': 0.008998, 'loss_consonant': 0.006962}\n",
      "  116 | 0.000003 | 119808/160596 | 1.8599 | 1.0980 |\n",
      "val: {'recall': 0.996691, 'recall_grapheme': 0.995437, 'recall_vowel': 0.997978, 'recall_consonant': 0.99791, 'acc_grapheme': 0.995328, 'acc_vowel': 0.99841, 'acc_consonant': 0.998459, 'loss_grapheme': 0.028003, 'loss_vowel': 0.017077, 'loss_consonant': 0.012309}\n",
      "  117 | 0.000008 | 112896/160596 | 1.7710 | 0.9707 |\n",
      "val: {'recall': 0.995878, 'recall_grapheme': 0.994805, 'recall_vowel': 0.997235, 'recall_consonant': 0.99667, 'acc_grapheme': 0.994558, 'acc_vowel': 0.997888, 'acc_consonant': 0.998087, 'loss_grapheme': 0.026535, 'loss_vowel': 0.014918, 'loss_consonant': 0.011295}\n",
      "  118 | 0.000015 | 105984/160596 | 0.0007 | 1.0425 |\n",
      "val: {'recall': 0.995766, 'recall_grapheme': 0.994247, 'recall_vowel': 0.996988, 'recall_consonant': 0.997584, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997764, 'acc_consonant': 0.998037, 'loss_grapheme': 0.026262, 'loss_vowel': 0.012468, 'loss_consonant': 0.00978}\n",
      "  119 | 0.000026 | 099072/160596 | 1.7200 | 1.0477 |\n",
      "val: {'recall': 0.995771, 'recall_grapheme': 0.994529, 'recall_vowel': 0.997231, 'recall_consonant': 0.996794, 'acc_grapheme': 0.994508, 'acc_vowel': 0.997962, 'acc_consonant': 0.998136, 'loss_grapheme': 0.027637, 'loss_vowel': 0.013964, 'loss_consonant': 0.01096}\n",
      "  120 | 0.000038 | 069120/160596 | 1.8198 | 0.9262 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-096d5f7828ea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.996988, 'recall_grapheme': 0.996238, 'recall_vowel': 0.99774, 'recall_consonant': 0.997735, 'acc_grapheme': 0.995254, 'acc_vowel': 0.998161, 'acc_consonant': 0.998136, 'loss_grapheme': 0.022178, 'loss_vowel': 0.010151, 'loss_consonant': 0.008258}\n",
      "    0 | 0.000001 | 153600/160596 | 0.0004 | 1.0279 |\n",
      "val: {'recall': 0.996261, 'recall_grapheme': 0.995071, 'recall_vowel': 0.997409, 'recall_consonant': 0.997492, 'acc_grapheme': 0.994036, 'acc_vowel': 0.997863, 'acc_consonant': 0.998037, 'loss_grapheme': 0.055595, 'loss_vowel': 0.033633, 'loss_consonant': 0.020962}\n",
      "    1 | 0.000003 | 146688/160596 | 2.1166 | 1.0477 |\n",
      "val: {'recall': 0.996363, 'recall_grapheme': 0.995294, 'recall_vowel': 0.997246, 'recall_consonant': 0.997619, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997888, 'acc_consonant': 0.998012, 'loss_grapheme': 0.042929, 'loss_vowel': 0.027253, 'loss_consonant': 0.017694}\n",
      "    2 | 0.000008 | 139776/160596 | 1.2467 | 0.8781 |\n",
      "val: {'recall': 0.996636, 'recall_grapheme': 0.995566, 'recall_vowel': 0.997721, 'recall_consonant': 0.997692, 'acc_grapheme': 0.994931, 'acc_vowel': 0.998161, 'acc_consonant': 0.998161, 'loss_grapheme': 0.052111, 'loss_vowel': 0.033459, 'loss_consonant': 0.019917}\n",
      "    3 | 0.000015 | 132864/160596 | 1.7612 | 0.9458 |\n",
      "val: {'recall': 0.996326, 'recall_grapheme': 0.995096, 'recall_vowel': 0.997599, 'recall_consonant': 0.997513, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997838, 'acc_consonant': 0.997913, 'loss_grapheme': 0.063094, 'loss_vowel': 0.036745, 'loss_consonant': 0.02321}\n",
      "    4 | 0.000026 | 125952/160596 | 1.6026 | 0.9375 |\n",
      "val: {'recall': 0.996384, 'recall_grapheme': 0.995343, 'recall_vowel': 0.99733, 'recall_consonant': 0.99752, 'acc_grapheme': 0.994136, 'acc_vowel': 0.998012, 'acc_consonant': 0.998112, 'loss_grapheme': 0.039995, 'loss_vowel': 0.025079, 'loss_consonant': 0.015884}\n",
      "    5 | 0.000038 | 119040/160596 | 2.2020 | 0.9355 |\n",
      "val: {'recall': 0.995353, 'recall_grapheme': 0.993624, 'recall_vowel': 0.996623, 'recall_consonant': 0.997539, 'acc_grapheme': 0.992595, 'acc_vowel': 0.997192, 'acc_consonant': 0.997615, 'loss_grapheme': 0.069426, 'loss_vowel': 0.049284, 'loss_consonant': 0.03245}\n",
      "    6 | 0.000050 | 112128/160596 | 0.0176 | 0.9260 |\n",
      "val: {'recall': 0.995622, 'recall_grapheme': 0.994057, 'recall_vowel': 0.997112, 'recall_consonant': 0.99726, 'acc_grapheme': 0.993738, 'acc_vowel': 0.997316, 'acc_consonant': 0.997664, 'loss_grapheme': 0.064017, 'loss_vowel': 0.042282, 'loss_consonant': 0.024276}\n",
      "    7 | 0.000063 | 105216/160596 | 0.0093 | 1.0370 |\n",
      "val: {'recall': 0.995136, 'recall_grapheme': 0.993528, 'recall_vowel': 0.997158, 'recall_consonant': 0.996332, 'acc_grapheme': 0.99257, 'acc_vowel': 0.997416, 'acc_consonant': 0.997267, 'loss_grapheme': 0.040851, 'loss_vowel': 0.021518, 'loss_consonant': 0.016503}\n",
      "    8 | 0.000075 | 098304/160596 | 2.0908 | 1.0738 |\n",
      "val: {'recall': 0.994941, 'recall_grapheme': 0.993649, 'recall_vowel': 0.997185, 'recall_consonant': 0.99528, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997515, 'acc_consonant': 0.997167, 'loss_grapheme': 0.085918, 'loss_vowel': 0.052338, 'loss_consonant': 0.032265}\n",
      "    9 | 0.000086 | 091392/160596 | 0.0052 | 1.1605 |\n",
      "val: {'recall': 0.99484, 'recall_grapheme': 0.9931, 'recall_vowel': 0.99697, 'recall_consonant': 0.996191, 'acc_grapheme': 0.992943, 'acc_vowel': 0.997142, 'acc_consonant': 0.99754, 'loss_grapheme': 0.048472, 'loss_vowel': 0.026308, 'loss_consonant': 0.017699}\n",
      "   10 | 0.000093 | 084480/160596 | 1.6412 | 0.9828 |\n",
      "val: {'recall': 0.995446, 'recall_grapheme': 0.993578, 'recall_vowel': 0.99725, 'recall_consonant': 0.997376, 'acc_grapheme': 0.992744, 'acc_vowel': 0.997565, 'acc_consonant': 0.997863, 'loss_grapheme': 0.055827, 'loss_vowel': 0.030401, 'loss_consonant': 0.019926}\n",
      "   11 | 0.000098 | 077568/160596 | 0.8695 | 1.1452 |\n",
      "val: {'recall': 0.989898, 'recall_grapheme': 0.986916, 'recall_vowel': 0.993319, 'recall_consonant': 0.992442, 'acc_grapheme': 0.986159, 'acc_vowel': 0.994459, 'acc_consonant': 0.994906, 'loss_grapheme': 0.125362, 'loss_vowel': 0.074944, 'loss_consonant': 0.051344}\n",
      "   12 | 0.000100 | 070656/160596 | 1.4772 | 0.9233 |\n",
      "val: {'recall': 0.9946, 'recall_grapheme': 0.992673, 'recall_vowel': 0.996419, 'recall_consonant': 0.996634, 'acc_grapheme': 0.992049, 'acc_vowel': 0.997292, 'acc_consonant': 0.997267, 'loss_grapheme': 0.050617, 'loss_vowel': 0.026939, 'loss_consonant': 0.019946}\n",
      "   13 | 0.000098 | 063744/160596 | 3.3960 | 1.1455 |\n",
      "val: {'recall': 0.992508, 'recall_grapheme': 0.989267, 'recall_vowel': 0.995474, 'recall_consonant': 0.996024, 'acc_grapheme': 0.989663, 'acc_vowel': 0.996074, 'acc_consonant': 0.996397, 'loss_grapheme': 0.061539, 'loss_vowel': 0.037279, 'loss_consonant': 0.02739}\n",
      "   14 | 0.000093 | 056832/160596 | 0.0184 | 1.2753 |\n",
      "val: {'recall': 0.995205, 'recall_grapheme': 0.992859, 'recall_vowel': 0.997787, 'recall_consonant': 0.997315, 'acc_grapheme': 0.993117, 'acc_vowel': 0.997888, 'acc_consonant': 0.997689, 'loss_grapheme': 0.062779, 'loss_vowel': 0.036476, 'loss_consonant': 0.023151}\n",
      "   15 | 0.000086 | 049920/160596 | 0.0116 | 0.9014 |\n",
      "val: {'recall': 0.995962, 'recall_grapheme': 0.994713, 'recall_vowel': 0.997449, 'recall_consonant': 0.996973, 'acc_grapheme': 0.994384, 'acc_vowel': 0.997764, 'acc_consonant': 0.997788, 'loss_grapheme': 0.029265, 'loss_vowel': 0.015714, 'loss_consonant': 0.012176}\n",
      "   16 | 0.000075 | 043008/160596 | 3.4150 | 1.0314 |\n",
      "val: {'recall': 0.995485, 'recall_grapheme': 0.993734, 'recall_vowel': 0.996972, 'recall_consonant': 0.9975, 'acc_grapheme': 0.993813, 'acc_vowel': 0.99749, 'acc_consonant': 0.997341, 'loss_grapheme': 0.037746, 'loss_vowel': 0.022053, 'loss_consonant': 0.016518}\n",
      "   17 | 0.000063 | 036096/160596 | 0.0093 | 0.8280 |\n",
      "val: {'recall': 0.995979, 'recall_grapheme': 0.994744, 'recall_vowel': 0.996783, 'recall_consonant': 0.997644, 'acc_grapheme': 0.994285, 'acc_vowel': 0.997441, 'acc_consonant': 0.997465, 'loss_grapheme': 0.037609, 'loss_vowel': 0.021063, 'loss_consonant': 0.015482}\n",
      "   18 | 0.000051 | 029184/160596 | 1.6587 | 0.7453 |\n",
      "val: {'recall': 0.996701, 'recall_grapheme': 0.995866, 'recall_vowel': 0.997563, 'recall_consonant': 0.997509, 'acc_grapheme': 0.995229, 'acc_vowel': 0.997913, 'acc_consonant': 0.998037, 'loss_grapheme': 0.029854, 'loss_vowel': 0.016825, 'loss_consonant': 0.012555}\n",
      "   19 | 0.000038 | 022272/160596 | 0.0134 | 1.0186 |\n",
      "val: {'recall': 0.996452, 'recall_grapheme': 0.995393, 'recall_vowel': 0.997341, 'recall_consonant': 0.997682, 'acc_grapheme': 0.994732, 'acc_vowel': 0.997913, 'acc_consonant': 0.997987, 'loss_grapheme': 0.041475, 'loss_vowel': 0.024271, 'loss_consonant': 0.016101}\n",
      "   20 | 0.000026 | 015360/160596 | 2.1465 | 1.1651 |\n",
      "val: {'recall': 0.99556, 'recall_grapheme': 0.994512, 'recall_vowel': 0.996731, 'recall_consonant': 0.996486, 'acc_grapheme': 0.994558, 'acc_vowel': 0.99749, 'acc_consonant': 0.997788, 'loss_grapheme': 0.04713, 'loss_vowel': 0.028476, 'loss_consonant': 0.021627}\n",
      "   21 | 0.000015 | 008448/160596 | 1.9669 | 1.4140 |\n",
      "val: {'recall': 0.995688, 'recall_grapheme': 0.994252, 'recall_vowel': 0.997278, 'recall_consonant': 0.996969, 'acc_grapheme': 0.993962, 'acc_vowel': 0.997639, 'acc_consonant': 0.997913, 'loss_grapheme': 0.075917, 'loss_vowel': 0.04501, 'loss_consonant': 0.030467}\n",
      "   22 | 0.000008 | 001536/160596 | 2.8407 | 2.3750 |\n",
      "val: {'recall': 0.99582, 'recall_grapheme': 0.99452, 'recall_vowel': 0.997273, 'recall_consonant': 0.996967, 'acc_grapheme': 0.994384, 'acc_vowel': 0.997689, 'acc_consonant': 0.997888, 'loss_grapheme': 0.067621, 'loss_vowel': 0.038496, 'loss_consonant': 0.02604}\n",
      "   22 | 0.000003 | 155136/160596 | 1.7506 | 0.9467 |\n",
      "val: {'recall': 0.996577, 'recall_grapheme': 0.99574, 'recall_vowel': 0.997598, 'recall_consonant': 0.997228, 'acc_grapheme': 0.99508, 'acc_vowel': 0.997888, 'acc_consonant': 0.998186, 'loss_grapheme': 0.045077, 'loss_vowel': 0.028098, 'loss_consonant': 0.018578}\n",
      "   23 | 0.000001 | 148224/160596 | 3.0962 | 0.9548 |\n",
      "val: {'recall': 0.996435, 'recall_grapheme': 0.995417, 'recall_vowel': 0.99724, 'recall_consonant': 0.997664, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997664, 'acc_consonant': 0.998037, 'loss_grapheme': 0.038144, 'loss_vowel': 0.024292, 'loss_consonant': 0.017128}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 0.000003 | 141312/160596 | 2.0666 | 0.9990 |\n",
      "val: {'recall': 0.996368, 'recall_grapheme': 0.995275, 'recall_vowel': 0.997307, 'recall_consonant': 0.997614, 'acc_grapheme': 0.995155, 'acc_vowel': 0.997739, 'acc_consonant': 0.998136, 'loss_grapheme': 0.052939, 'loss_vowel': 0.031463, 'loss_consonant': 0.020814}\n",
      "   25 | 0.000008 | 134400/160596 | 0.0072 | 1.0217 |\n",
      "val: {'recall': 0.997029, 'recall_grapheme': 0.996288, 'recall_vowel': 0.99753, 'recall_consonant': 0.99801, 'acc_grapheme': 0.995652, 'acc_vowel': 0.997938, 'acc_consonant': 0.998385, 'loss_grapheme': 0.023453, 'loss_vowel': 0.012796, 'loss_consonant': 0.009681}\n",
      "** saved\n",
      "   26 | 0.000015 | 127488/160596 | 0.0093 | 0.9958 |\n",
      "val: {'recall': 0.99685, 'recall_grapheme': 0.995877, 'recall_vowel': 0.997737, 'recall_consonant': 0.997908, 'acc_grapheme': 0.995478, 'acc_vowel': 0.998062, 'acc_consonant': 0.99836, 'loss_grapheme': 0.024279, 'loss_vowel': 0.012967, 'loss_consonant': 0.009594}\n",
      "   27 | 0.000026 | 120576/160596 | 2.4947 | 1.0253 |\n",
      "val: {'recall': 0.996044, 'recall_grapheme': 0.994833, 'recall_vowel': 0.99754, 'recall_consonant': 0.996968, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997664, 'acc_consonant': 0.997739, 'loss_grapheme': 0.046887, 'loss_vowel': 0.028636, 'loss_consonant': 0.020344}\n",
      "   28 | 0.000038 | 113664/160596 | 0.0145 | 0.8197 |\n",
      "val: {'recall': 0.997009, 'recall_grapheme': 0.996135, 'recall_vowel': 0.99782, 'recall_consonant': 0.997946, 'acc_grapheme': 0.995776, 'acc_vowel': 0.998112, 'acc_consonant': 0.99836, 'loss_grapheme': 0.022704, 'loss_vowel': 0.01179, 'loss_consonant': 0.008437}\n",
      "   29 | 0.000050 | 106752/160596 | 2.3044 | 1.0562 |\n",
      "val: {'recall': 0.995074, 'recall_grapheme': 0.993593, 'recall_vowel': 0.996716, 'recall_consonant': 0.996393, 'acc_grapheme': 0.993266, 'acc_vowel': 0.997465, 'acc_consonant': 0.997416, 'loss_grapheme': 0.047196, 'loss_vowel': 0.028608, 'loss_consonant': 0.020209}\n",
      "   30 | 0.000063 | 099840/160596 | 0.0157 | 0.9770 |\n",
      "val: {'recall': 0.996124, 'recall_grapheme': 0.994727, 'recall_vowel': 0.997097, 'recall_consonant': 0.997946, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997639, 'acc_consonant': 0.998236, 'loss_grapheme': 0.032517, 'loss_vowel': 0.020323, 'loss_consonant': 0.01349}\n",
      "   31 | 0.000075 | 092928/160596 | 1.8451 | 1.0712 |\n",
      "val: {'recall': 0.994832, 'recall_grapheme': 0.99317, 'recall_vowel': 0.996374, 'recall_consonant': 0.996612, 'acc_grapheme': 0.993365, 'acc_vowel': 0.997167, 'acc_consonant': 0.997788, 'loss_grapheme': 0.055642, 'loss_vowel': 0.034398, 'loss_consonant': 0.023127}\n",
      "   32 | 0.000086 | 086016/160596 | 1.4053 | 1.1830 |\n",
      "val: {'recall': 0.995412, 'recall_grapheme': 0.993283, 'recall_vowel': 0.996996, 'recall_consonant': 0.998086, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997267, 'acc_consonant': 0.997863, 'loss_grapheme': 0.072996, 'loss_vowel': 0.040594, 'loss_consonant': 0.027622}\n",
      "   33 | 0.000093 | 079104/160596 | 2.1188 | 1.1169 |\n",
      "val: {'recall': 0.996071, 'recall_grapheme': 0.994855, 'recall_vowel': 0.996802, 'recall_consonant': 0.997771, 'acc_grapheme': 0.993838, 'acc_vowel': 0.997441, 'acc_consonant': 0.997391, 'loss_grapheme': 0.059097, 'loss_vowel': 0.036795, 'loss_consonant': 0.023811}\n",
      "   34 | 0.000098 | 072192/160596 | 0.0077 | 1.0690 |\n",
      "val: {'recall': 0.994552, 'recall_grapheme': 0.992768, 'recall_vowel': 0.995829, 'recall_consonant': 0.99684, 'acc_grapheme': 0.992073, 'acc_vowel': 0.996795, 'acc_consonant': 0.997068, 'loss_grapheme': 0.081722, 'loss_vowel': 0.046766, 'loss_consonant': 0.032498}\n",
      "   35 | 0.000100 | 065280/160596 | 1.4616 | 1.1108 |\n",
      "val: {'recall': 0.99561, 'recall_grapheme': 0.993895, 'recall_vowel': 0.997003, 'recall_consonant': 0.997647, 'acc_grapheme': 0.992893, 'acc_vowel': 0.997142, 'acc_consonant': 0.997292, 'loss_grapheme': 0.067995, 'loss_vowel': 0.043219, 'loss_consonant': 0.027424}\n",
      "   36 | 0.000098 | 058368/160596 | 0.0035 | 0.8987 |\n",
      "val: {'recall': 0.996126, 'recall_grapheme': 0.99452, 'recall_vowel': 0.997961, 'recall_consonant': 0.997505, 'acc_grapheme': 0.994459, 'acc_vowel': 0.997764, 'acc_consonant': 0.997018, 'loss_grapheme': 0.029372, 'loss_vowel': 0.015684, 'loss_consonant': 0.014192}\n",
      "   37 | 0.000093 | 051456/160596 | 1.8208 | 1.1452 |\n",
      "val: {'recall': 0.994643, 'recall_grapheme': 0.992366, 'recall_vowel': 0.996165, 'recall_consonant': 0.997675, 'acc_grapheme': 0.992918, 'acc_vowel': 0.996993, 'acc_consonant': 0.997217, 'loss_grapheme': 0.105526, 'loss_vowel': 0.065246, 'loss_consonant': 0.037837}\n",
      "   38 | 0.000086 | 044544/160596 | 0.0091 | 1.0121 |\n",
      "val: {'recall': 0.995815, 'recall_grapheme': 0.994634, 'recall_vowel': 0.99744, 'recall_consonant': 0.996554, 'acc_grapheme': 0.994583, 'acc_vowel': 0.997913, 'acc_consonant': 0.997714, 'loss_grapheme': 0.026895, 'loss_vowel': 0.015137, 'loss_consonant': 0.011898}\n",
      "   39 | 0.000075 | 037632/160596 | 0.0070 | 1.1415 |\n",
      "val: {'recall': 0.996183, 'recall_grapheme': 0.995146, 'recall_vowel': 0.997271, 'recall_consonant': 0.997169, 'acc_grapheme': 0.994583, 'acc_vowel': 0.99759, 'acc_consonant': 0.997689, 'loss_grapheme': 0.033581, 'loss_vowel': 0.018985, 'loss_consonant': 0.01302}\n",
      "   40 | 0.000063 | 030720/160596 | 2.1405 | 0.8507 |\n",
      "val: {'recall': 0.995701, 'recall_grapheme': 0.994539, 'recall_vowel': 0.99762, 'recall_consonant': 0.996106, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997788, 'acc_consonant': 0.997664, 'loss_grapheme': 0.046864, 'loss_vowel': 0.028867, 'loss_consonant': 0.018756}\n",
      "   41 | 0.000051 | 023808/160596 | 1.9232 | 0.9396 |\n",
      "val: {'recall': 0.996158, 'recall_grapheme': 0.995067, 'recall_vowel': 0.997178, 'recall_consonant': 0.99732, 'acc_grapheme': 0.994533, 'acc_vowel': 0.997863, 'acc_consonant': 0.997888, 'loss_grapheme': 0.035376, 'loss_vowel': 0.020319, 'loss_consonant': 0.014483}\n",
      "   42 | 0.000038 | 016896/160596 | 0.0160 | 0.6773 |\n",
      "val: {'recall': 0.997093, 'recall_grapheme': 0.995997, 'recall_vowel': 0.99794, 'recall_consonant': 0.99844, 'acc_grapheme': 0.995453, 'acc_vowel': 0.998161, 'acc_consonant': 0.998435, 'loss_grapheme': 0.021392, 'loss_vowel': 0.010026, 'loss_consonant': 0.007461}\n",
      "** saved\n",
      "   43 | 0.000026 | 009984/160596 | 0.0031 | 0.9396 |\n",
      "val: {'recall': 0.997067, 'recall_grapheme': 0.996192, 'recall_vowel': 0.99796, 'recall_consonant': 0.997925, 'acc_grapheme': 0.995527, 'acc_vowel': 0.998112, 'acc_consonant': 0.99831, 'loss_grapheme': 0.029587, 'loss_vowel': 0.016137, 'loss_consonant': 0.011433}\n",
      "   44 | 0.000015 | 003072/160596 | 0.0024 | 0.8418 |\n",
      "val: {'recall': 0.996619, 'recall_grapheme': 0.995493, 'recall_vowel': 0.997621, 'recall_consonant': 0.997868, 'acc_grapheme': 0.994732, 'acc_vowel': 0.997913, 'acc_consonant': 0.998161, 'loss_grapheme': 0.032221, 'loss_vowel': 0.018782, 'loss_consonant': 0.013401}\n",
      "   44 | 0.000008 | 156672/160596 | 2.0617 | 1.0525 |\n",
      "val: {'recall': 0.99635, 'recall_grapheme': 0.995246, 'recall_vowel': 0.997644, 'recall_consonant': 0.997263, 'acc_grapheme': 0.994658, 'acc_vowel': 0.997938, 'acc_consonant': 0.998037, 'loss_grapheme': 0.039453, 'loss_vowel': 0.026587, 'loss_consonant': 0.018193}\n",
      "   45 | 0.000003 | 149760/160596 | 0.0078 | 0.9996 |\n",
      "val: {'recall': 0.996909, 'recall_grapheme': 0.995868, 'recall_vowel': 0.997998, 'recall_consonant': 0.997901, 'acc_grapheme': 0.995378, 'acc_vowel': 0.998186, 'acc_consonant': 0.998335, 'loss_grapheme': 0.023935, 'loss_vowel': 0.013151, 'loss_consonant': 0.00947}\n",
      "   46 | 0.000001 | 142848/160596 | 1.4272 | 0.9012 |\n",
      "val: {'recall': 0.996316, 'recall_grapheme': 0.995179, 'recall_vowel': 0.997577, 'recall_consonant': 0.997326, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997764, 'acc_consonant': 0.997962, 'loss_grapheme': 0.038027, 'loss_vowel': 0.024259, 'loss_consonant': 0.016588}\n",
      "   47 | 0.000003 | 135936/160596 | 2.9807 | 0.9739 |\n",
      "val: {'recall': 0.995715, 'recall_grapheme': 0.994245, 'recall_vowel': 0.997276, 'recall_consonant': 0.997093, 'acc_grapheme': 0.993564, 'acc_vowel': 0.997714, 'acc_consonant': 0.997664, 'loss_grapheme': 0.039973, 'loss_vowel': 0.028079, 'loss_consonant': 0.019921}\n",
      "   48 | 0.000008 | 129024/160596 | 0.2327 | 1.0162 |\n",
      "val: {'recall': 0.996629, 'recall_grapheme': 0.995471, 'recall_vowel': 0.997573, 'recall_consonant': 0.998004, 'acc_grapheme': 0.994981, 'acc_vowel': 0.997863, 'acc_consonant': 0.99831, 'loss_grapheme': 0.058366, 'loss_vowel': 0.03828, 'loss_consonant': 0.022357}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 | 0.000015 | 122112/160596 | 2.3226 | 0.9520 |\n",
      "val: {'recall': 0.996397, 'recall_grapheme': 0.99525, 'recall_vowel': 0.997336, 'recall_consonant': 0.997752, 'acc_grapheme': 0.994782, 'acc_vowel': 0.997938, 'acc_consonant': 0.998136, 'loss_grapheme': 0.025054, 'loss_vowel': 0.012843, 'loss_consonant': 0.00948}\n",
      "   50 | 0.000026 | 115200/160596 | 0.8201 | 0.9728 |\n",
      "val: {'recall': 0.996282, 'recall_grapheme': 0.99503, 'recall_vowel': 0.997345, 'recall_consonant': 0.997724, 'acc_grapheme': 0.994633, 'acc_vowel': 0.997838, 'acc_consonant': 0.998037, 'loss_grapheme': 0.033476, 'loss_vowel': 0.019314, 'loss_consonant': 0.013521}\n",
      "   51 | 0.000038 | 108288/160596 | 0.0026 | 1.0012 |\n",
      "val: {'recall': 0.995873, 'recall_grapheme': 0.994213, 'recall_vowel': 0.997306, 'recall_consonant': 0.997761, 'acc_grapheme': 0.994036, 'acc_vowel': 0.997913, 'acc_consonant': 0.998062, 'loss_grapheme': 0.03212, 'loss_vowel': 0.018114, 'loss_consonant': 0.012488}\n",
      "   52 | 0.000051 | 101376/160596 | 1.5500 | 0.9813 |\n",
      "val: {'recall': 0.995718, 'recall_grapheme': 0.994364, 'recall_vowel': 0.996524, 'recall_consonant': 0.997622, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997416, 'acc_consonant': 0.998037, 'loss_grapheme': 0.085669, 'loss_vowel': 0.043621, 'loss_consonant': 0.028059}\n",
      "   53 | 0.000063 | 094464/160596 | 0.3510 | 1.0388 |\n",
      "val: {'recall': 0.996111, 'recall_grapheme': 0.994967, 'recall_vowel': 0.997082, 'recall_consonant': 0.99743, 'acc_grapheme': 0.994608, 'acc_vowel': 0.998012, 'acc_consonant': 0.997863, 'loss_grapheme': 0.040547, 'loss_vowel': 0.023827, 'loss_consonant': 0.017288}\n",
      "   54 | 0.000075 | 087552/160596 | 2.2423 | 1.0598 |\n",
      "val: {'recall': 0.995439, 'recall_grapheme': 0.993458, 'recall_vowel': 0.997265, 'recall_consonant': 0.997578, 'acc_grapheme': 0.993788, 'acc_vowel': 0.997615, 'acc_consonant': 0.997441, 'loss_grapheme': 0.062278, 'loss_vowel': 0.039384, 'loss_consonant': 0.024087}\n",
      "   55 | 0.000086 | 080640/160596 | 0.0209 | 1.0887 |\n",
      "val: {'recall': 0.995759, 'recall_grapheme': 0.995461, 'recall_vowel': 0.997073, 'recall_consonant': 0.995043, 'acc_grapheme': 0.994931, 'acc_vowel': 0.997788, 'acc_consonant': 0.997391, 'loss_grapheme': 0.025003, 'loss_vowel': 0.013317, 'loss_consonant': 0.01113}\n",
      "   56 | 0.000093 | 073728/160596 | 1.7818 | 1.0329 |\n",
      "val: {'recall': 0.994241, 'recall_grapheme': 0.992315, 'recall_vowel': 0.995531, 'recall_consonant': 0.996804, 'acc_grapheme': 0.991452, 'acc_vowel': 0.996844, 'acc_consonant': 0.997043, 'loss_grapheme': 0.205215, 'loss_vowel': 0.0936, 'loss_consonant': 0.055987}\n",
      "   57 | 0.000098 | 066816/160596 | 0.0274 | 1.1598 |\n",
      "val: {'recall': 0.994275, 'recall_grapheme': 0.992131, 'recall_vowel': 0.996178, 'recall_consonant': 0.99666, 'acc_grapheme': 0.992222, 'acc_vowel': 0.996546, 'acc_consonant': 0.996869, 'loss_grapheme': 0.055499, 'loss_vowel': 0.039051, 'loss_consonant': 0.023844}\n",
      "   58 | 0.000100 | 059904/160596 | 2.0076 | 1.1798 |\n",
      "val: {'recall': 0.994514, 'recall_grapheme': 0.991842, 'recall_vowel': 0.996716, 'recall_consonant': 0.997654, 'acc_grapheme': 0.992297, 'acc_vowel': 0.997118, 'acc_consonant': 0.997142, 'loss_grapheme': 0.115733, 'loss_vowel': 0.072016, 'loss_consonant': 0.043882}\n",
      "   59 | 0.000098 | 052992/160596 | 1.9954 | 1.0536 |\n",
      "val: {'recall': 0.994767, 'recall_grapheme': 0.992346, 'recall_vowel': 0.997603, 'recall_consonant': 0.996773, 'acc_grapheme': 0.992496, 'acc_vowel': 0.997689, 'acc_consonant': 0.996919, 'loss_grapheme': 0.040688, 'loss_vowel': 0.024375, 'loss_consonant': 0.017785}\n",
      "   60 | 0.000093 | 046080/160596 | 0.0120 | 1.0744 |\n",
      "val: {'recall': 0.994196, 'recall_grapheme': 0.992554, 'recall_vowel': 0.995301, 'recall_consonant': 0.996377, 'acc_grapheme': 0.992098, 'acc_vowel': 0.996645, 'acc_consonant': 0.996819, 'loss_grapheme': 0.046, 'loss_vowel': 0.025116, 'loss_consonant': 0.018049}\n",
      "   61 | 0.000086 | 039168/160596 | 0.0061 | 0.9562 |\n",
      "val: {'recall': 0.995919, 'recall_grapheme': 0.994577, 'recall_vowel': 0.996821, 'recall_consonant': 0.997701, 'acc_grapheme': 0.994012, 'acc_vowel': 0.997615, 'acc_consonant': 0.997788, 'loss_grapheme': 0.033429, 'loss_vowel': 0.01822, 'loss_consonant': 0.014051}\n",
      "   62 | 0.000075 | 032256/160596 | 1.7610 | 0.9489 |\n",
      "val: {'recall': 0.995439, 'recall_grapheme': 0.993723, 'recall_vowel': 0.996833, 'recall_consonant': 0.997478, 'acc_grapheme': 0.993589, 'acc_vowel': 0.997416, 'acc_consonant': 0.997441, 'loss_grapheme': 0.05954, 'loss_vowel': 0.038953, 'loss_consonant': 0.023167}\n",
      "   63 | 0.000063 | 025344/160596 | 2.8967 | 1.4324 |\n",
      "val: {'recall': 0.994197, 'recall_grapheme': 0.991665, 'recall_vowel': 0.99698, 'recall_consonant': 0.99648, 'acc_grapheme': 0.992247, 'acc_vowel': 0.997068, 'acc_consonant': 0.996944, 'loss_grapheme': 0.101308, 'loss_vowel': 0.060585, 'loss_consonant': 0.042667}\n",
      "   64 | 0.000051 | 018432/160596 | 0.8976 | 1.1658 |\n",
      "val: {'recall': 0.996001, 'recall_grapheme': 0.994799, 'recall_vowel': 0.997293, 'recall_consonant': 0.997114, 'acc_grapheme': 0.993813, 'acc_vowel': 0.997714, 'acc_consonant': 0.997416, 'loss_grapheme': 0.056192, 'loss_vowel': 0.035828, 'loss_consonant': 0.023333}\n",
      "   65 | 0.000038 | 011520/160596 | 2.1037 | 0.8160 |\n",
      "val: {'recall': 0.996076, 'recall_grapheme': 0.994596, 'recall_vowel': 0.997727, 'recall_consonant': 0.997386, 'acc_grapheme': 0.994682, 'acc_vowel': 0.998136, 'acc_consonant': 0.997764, 'loss_grapheme': 0.03336, 'loss_vowel': 0.018819, 'loss_consonant': 0.014102}\n",
      "   66 | 0.000026 | 004608/160596 | 0.0023 | 1.1972 |\n",
      "val: {'recall': 0.995934, 'recall_grapheme': 0.994544, 'recall_vowel': 0.99725, 'recall_consonant': 0.9974, 'acc_grapheme': 0.994533, 'acc_vowel': 0.998136, 'acc_consonant': 0.997813, 'loss_grapheme': 0.038414, 'loss_vowel': 0.022171, 'loss_consonant': 0.016171}\n",
      "   66 | 0.000015 | 158208/160596 | 0.9957 | 0.8703 |\n",
      "val: {'recall': 0.996163, 'recall_grapheme': 0.995118, 'recall_vowel': 0.997457, 'recall_consonant': 0.996958, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997987, 'acc_consonant': 0.997788, 'loss_grapheme': 0.026992, 'loss_vowel': 0.013841, 'loss_consonant': 0.011119}\n",
      "   67 | 0.000008 | 151296/160596 | 2.1655 | 0.9987 |\n",
      "val: {'recall': 0.996454, 'recall_grapheme': 0.995184, 'recall_vowel': 0.997769, 'recall_consonant': 0.997678, 'acc_grapheme': 0.994807, 'acc_vowel': 0.998236, 'acc_consonant': 0.998062, 'loss_grapheme': 0.034117, 'loss_vowel': 0.020837, 'loss_consonant': 0.014779}\n",
      "   68 | 0.000003 | 144384/160596 | 1.5661 | 1.0036 |\n",
      "val: {'recall': 0.996359, 'recall_grapheme': 0.995074, 'recall_vowel': 0.997793, 'recall_consonant': 0.997492, 'acc_grapheme': 0.994682, 'acc_vowel': 0.998161, 'acc_consonant': 0.997838, 'loss_grapheme': 0.040944, 'loss_vowel': 0.026002, 'loss_consonant': 0.017836}\n",
      "   69 | 0.000001 | 137472/160596 | 1.6218 | 0.9711 |\n",
      "val: {'recall': 0.99608, 'recall_grapheme': 0.994605, 'recall_vowel': 0.997331, 'recall_consonant': 0.997778, 'acc_grapheme': 0.994682, 'acc_vowel': 0.998012, 'acc_consonant': 0.998136, 'loss_grapheme': 0.040492, 'loss_vowel': 0.024706, 'loss_consonant': 0.016779}\n",
      "   70 | 0.000003 | 130560/160596 | 2.4502 | 1.0500 |\n",
      "val: {'recall': 0.996569, 'recall_grapheme': 0.995784, 'recall_vowel': 0.99763, 'recall_consonant': 0.99708, 'acc_grapheme': 0.995055, 'acc_vowel': 0.998186, 'acc_consonant': 0.997987, 'loss_grapheme': 0.026567, 'loss_vowel': 0.015019, 'loss_consonant': 0.011864}\n",
      "   71 | 0.000008 | 123648/160596 | 0.0009 | 0.9548 |\n",
      "val: {'recall': 0.996906, 'recall_grapheme': 0.995999, 'recall_vowel': 0.997888, 'recall_consonant': 0.997738, 'acc_grapheme': 0.995328, 'acc_vowel': 0.998385, 'acc_consonant': 0.998136, 'loss_grapheme': 0.022755, 'loss_vowel': 0.011004, 'loss_consonant': 0.009202}\n",
      "   72 | 0.000015 | 116736/160596 | 0.0065 | 0.9588 |\n",
      "val: {'recall': 0.996622, 'recall_grapheme': 0.995752, 'recall_vowel': 0.997396, 'recall_consonant': 0.997589, 'acc_grapheme': 0.99503, 'acc_vowel': 0.998087, 'acc_consonant': 0.997987, 'loss_grapheme': 0.029427, 'loss_vowel': 0.016319, 'loss_consonant': 0.012373}\n",
      "   73 | 0.000026 | 109824/160596 | 1.8127 | 0.8735 |\n",
      "val: {'recall': 0.996415, 'recall_grapheme': 0.995227, 'recall_vowel': 0.997568, 'recall_consonant': 0.997638, 'acc_grapheme': 0.994732, 'acc_vowel': 0.998186, 'acc_consonant': 0.998012, 'loss_grapheme': 0.033584, 'loss_vowel': 0.020442, 'loss_consonant': 0.014538}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 | 0.000038 | 102912/160596 | 1.2997 | 0.9296 |\n",
      "val: {'recall': 0.996029, 'recall_grapheme': 0.994687, 'recall_vowel': 0.997083, 'recall_consonant': 0.997658, 'acc_grapheme': 0.994086, 'acc_vowel': 0.997863, 'acc_consonant': 0.997913, 'loss_grapheme': 0.029208, 'loss_vowel': 0.014379, 'loss_consonant': 0.011922}\n",
      "   75 | 0.000051 | 096000/160596 | 0.0292 | 0.9989 |\n",
      "val: {'recall': 0.995316, 'recall_grapheme': 0.993807, 'recall_vowel': 0.996855, 'recall_consonant': 0.996795, 'acc_grapheme': 0.993589, 'acc_vowel': 0.997565, 'acc_consonant': 0.99749, 'loss_grapheme': 0.034512, 'loss_vowel': 0.018202, 'loss_consonant': 0.014359}\n",
      "   76 | 0.000063 | 089088/160596 | 1.7036 | 0.9700 |\n",
      "val: {'recall': 0.994697, 'recall_grapheme': 0.992385, 'recall_vowel': 0.997112, 'recall_consonant': 0.996907, 'acc_grapheme': 0.992769, 'acc_vowel': 0.99759, 'acc_consonant': 0.997441, 'loss_grapheme': 0.043566, 'loss_vowel': 0.027106, 'loss_consonant': 0.017781}\n",
      "   77 | 0.000075 | 082176/160596 | 0.0129 | 0.8682 |\n",
      "val: {'recall': 0.996385, 'recall_grapheme': 0.994821, 'recall_vowel': 0.998133, 'recall_consonant': 0.997766, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997987, 'acc_consonant': 0.998136, 'loss_grapheme': 0.030082, 'loss_vowel': 0.015459, 'loss_consonant': 0.011377}\n",
      "   78 | 0.000086 | 075264/160596 | 0.0190 | 1.1343 |\n",
      "val: {'recall': 0.995281, 'recall_grapheme': 0.993998, 'recall_vowel': 0.99664, 'recall_consonant': 0.996491, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997242, 'acc_consonant': 0.997267, 'loss_grapheme': 0.050591, 'loss_vowel': 0.029492, 'loss_consonant': 0.020012}\n",
      "   79 | 0.000093 | 068352/160596 | 2.3193 | 0.9019 |\n",
      "val: {'recall': 0.993762, 'recall_grapheme': 0.991323, 'recall_vowel': 0.996404, 'recall_consonant': 0.995997, 'acc_grapheme': 0.991378, 'acc_vowel': 0.997118, 'acc_consonant': 0.997043, 'loss_grapheme': 0.05554, 'loss_vowel': 0.027459, 'loss_consonant': 0.020713}\n",
      "   80 | 0.000098 | 061440/160596 | 0.0070 | 0.9162 |\n",
      "val: {'recall': 0.993839, 'recall_grapheme': 0.991414, 'recall_vowel': 0.996447, 'recall_consonant': 0.996082, 'acc_grapheme': 0.991651, 'acc_vowel': 0.996496, 'acc_consonant': 0.996645, 'loss_grapheme': 0.049763, 'loss_vowel': 0.029246, 'loss_consonant': 0.025101}\n",
      "   81 | 0.000100 | 054528/160596 | 1.3076 | 0.9601 |\n",
      "val: {'recall': 0.994443, 'recall_grapheme': 0.992043, 'recall_vowel': 0.996572, 'recall_consonant': 0.997116, 'acc_grapheme': 0.99262, 'acc_vowel': 0.99749, 'acc_consonant': 0.997341, 'loss_grapheme': 0.071002, 'loss_vowel': 0.041751, 'loss_consonant': 0.025882}\n",
      "   82 | 0.000098 | 047616/160596 | 0.0103 | 1.0786 |\n",
      "val: {'recall': 0.995349, 'recall_grapheme': 0.99366, 'recall_vowel': 0.997485, 'recall_consonant': 0.996589, 'acc_grapheme': 0.993564, 'acc_vowel': 0.997689, 'acc_consonant': 0.997316, 'loss_grapheme': 0.048167, 'loss_vowel': 0.027375, 'loss_consonant': 0.020636}\n",
      "   83 | 0.000093 | 040704/160596 | 2.1167 | 0.9277 |\n",
      "val: {'recall': 0.995315, 'recall_grapheme': 0.994052, 'recall_vowel': 0.997277, 'recall_consonant': 0.99588, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997739, 'acc_consonant': 0.997689, 'loss_grapheme': 0.032986, 'loss_vowel': 0.018482, 'loss_consonant': 0.01469}\n",
      "   84 | 0.000086 | 033792/160596 | 1.8240 | 0.7068 |\n",
      "val: {'recall': 0.996075, 'recall_grapheme': 0.994859, 'recall_vowel': 0.997275, 'recall_consonant': 0.997307, 'acc_grapheme': 0.994508, 'acc_vowel': 0.997639, 'acc_consonant': 0.997938, 'loss_grapheme': 0.032169, 'loss_vowel': 0.017951, 'loss_consonant': 0.011724}\n",
      "   85 | 0.000075 | 026880/160596 | 1.6754 | 0.7757 |\n",
      "val: {'recall': 0.995545, 'recall_grapheme': 0.994195, 'recall_vowel': 0.997347, 'recall_consonant': 0.996443, 'acc_grapheme': 0.994036, 'acc_vowel': 0.997739, 'acc_consonant': 0.997863, 'loss_grapheme': 0.04189, 'loss_vowel': 0.025346, 'loss_consonant': 0.017002}\n",
      "   86 | 0.000063 | 019968/160596 | 0.0095 | 0.8867 |\n",
      "val: {'recall': 0.996428, 'recall_grapheme': 0.995195, 'recall_vowel': 0.997882, 'recall_consonant': 0.997438, 'acc_grapheme': 0.994732, 'acc_vowel': 0.997938, 'acc_consonant': 0.997962, 'loss_grapheme': 0.02662, 'loss_vowel': 0.01348, 'loss_consonant': 0.01075}\n",
      "   87 | 0.000051 | 013056/160596 | 1.8827 | 1.2278 |\n",
      "val: {'recall': 0.995635, 'recall_grapheme': 0.994235, 'recall_vowel': 0.996918, 'recall_consonant': 0.997154, 'acc_grapheme': 0.993962, 'acc_vowel': 0.997341, 'acc_consonant': 0.997689, 'loss_grapheme': 0.092805, 'loss_vowel': 0.056903, 'loss_consonant': 0.033373}\n",
      "   88 | 0.000038 | 006144/160596 | 0.0051 | 0.5085 |\n",
      "val: {'recall': 0.996441, 'recall_grapheme': 0.995259, 'recall_vowel': 0.997884, 'recall_consonant': 0.997364, 'acc_grapheme': 0.99513, 'acc_vowel': 0.998012, 'acc_consonant': 0.998211, 'loss_grapheme': 0.026302, 'loss_vowel': 0.015615, 'loss_consonant': 0.010846}\n",
      "   88 | 0.000026 | 159744/160596 | 1.4431 | 0.9754 |\n",
      "val: {'recall': 0.996112, 'recall_grapheme': 0.995106, 'recall_vowel': 0.997276, 'recall_consonant': 0.99696, 'acc_grapheme': 0.994508, 'acc_vowel': 0.997913, 'acc_consonant': 0.998087, 'loss_grapheme': 0.028078, 'loss_vowel': 0.014831, 'loss_consonant': 0.010771}\n",
      "   89 | 0.000015 | 152832/160596 | 2.0302 | 1.1366 |\n",
      "val: {'recall': 0.995347, 'recall_grapheme': 0.993798, 'recall_vowel': 0.997408, 'recall_consonant': 0.996385, 'acc_grapheme': 0.993887, 'acc_vowel': 0.997888, 'acc_consonant': 0.997962, 'loss_grapheme': 0.053632, 'loss_vowel': 0.035751, 'loss_consonant': 0.023581}\n",
      "   90 | 0.000008 | 145920/160596 | 0.0024 | 0.9829 |\n",
      "val: {'recall': 0.996163, 'recall_grapheme': 0.994946, 'recall_vowel': 0.997529, 'recall_consonant': 0.997231, 'acc_grapheme': 0.994931, 'acc_vowel': 0.997863, 'acc_consonant': 0.998261, 'loss_grapheme': 0.037781, 'loss_vowel': 0.02394, 'loss_consonant': 0.015331}\n",
      "   91 | 0.000003 | 139008/160596 | 1.9399 | 1.0545 |\n",
      "val: {'recall': 0.996421, 'recall_grapheme': 0.995417, 'recall_vowel': 0.997721, 'recall_consonant': 0.997127, 'acc_grapheme': 0.99508, 'acc_vowel': 0.998136, 'acc_consonant': 0.998186, 'loss_grapheme': 0.032776, 'loss_vowel': 0.020213, 'loss_consonant': 0.013138}\n",
      "   92 | 0.000001 | 132096/160596 | 2.3753 | 0.9982 |\n",
      "val: {'recall': 0.996135, 'recall_grapheme': 0.995131, 'recall_vowel': 0.99772, 'recall_consonant': 0.996558, 'acc_grapheme': 0.994658, 'acc_vowel': 0.998161, 'acc_consonant': 0.998012, 'loss_grapheme': 0.037143, 'loss_vowel': 0.024469, 'loss_consonant': 0.016857}\n",
      "   93 | 0.000003 | 125184/160596 | 1.5730 | 0.9313 |\n",
      "val: {'recall': 0.996313, 'recall_grapheme': 0.995175, 'recall_vowel': 0.997522, 'recall_consonant': 0.997382, 'acc_grapheme': 0.994658, 'acc_vowel': 0.997913, 'acc_consonant': 0.997938, 'loss_grapheme': 0.04179, 'loss_vowel': 0.026432, 'loss_consonant': 0.017405}\n",
      "   94 | 0.000008 | 118272/160596 | 1.6247 | 1.0599 |\n",
      "val: {'recall': 0.996292, 'recall_grapheme': 0.994862, 'recall_vowel': 0.997725, 'recall_consonant': 0.997721, 'acc_grapheme': 0.994633, 'acc_vowel': 0.998062, 'acc_consonant': 0.998087, 'loss_grapheme': 0.033884, 'loss_vowel': 0.020623, 'loss_consonant': 0.014664}\n",
      "   95 | 0.000015 | 111360/160596 | 1.8460 | 1.0878 |\n",
      "val: {'recall': 0.996277, 'recall_grapheme': 0.99501, 'recall_vowel': 0.997515, 'recall_consonant': 0.997573, 'acc_grapheme': 0.994956, 'acc_vowel': 0.997962, 'acc_consonant': 0.998161, 'loss_grapheme': 0.03398, 'loss_vowel': 0.019375, 'loss_consonant': 0.013198}\n",
      "   96 | 0.000026 | 104448/160596 | 0.0017 | 0.9322 |\n",
      "val: {'recall': 0.996634, 'recall_grapheme': 0.99556, 'recall_vowel': 0.997981, 'recall_consonant': 0.997434, 'acc_grapheme': 0.99513, 'acc_vowel': 0.998285, 'acc_consonant': 0.998459, 'loss_grapheme': 0.022775, 'loss_vowel': 0.011034, 'loss_consonant': 0.0079}\n",
      "   97 | 0.000038 | 097536/160596 | 2.5059 | 1.1626 |\n",
      "val: {'recall': 0.995868, 'recall_grapheme': 0.9945, 'recall_vowel': 0.99745, 'recall_consonant': 0.99702, 'acc_grapheme': 0.994136, 'acc_vowel': 0.997888, 'acc_consonant': 0.998112, 'loss_grapheme': 0.047001, 'loss_vowel': 0.026018, 'loss_consonant': 0.016789}\n",
      "   98 | 0.000050 | 090624/160596 | 3.2420 | 0.9697 |\n",
      "val: {'recall': 0.996452, 'recall_grapheme': 0.995207, 'recall_vowel': 0.997559, 'recall_consonant': 0.997835, 'acc_grapheme': 0.995005, 'acc_vowel': 0.998161, 'acc_consonant': 0.998484, 'loss_grapheme': 0.031948, 'loss_vowel': 0.018621, 'loss_consonant': 0.012014}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99 | 0.000063 | 083712/160596 | 0.0032 | 0.9283 |\n",
      "val: {'recall': 0.995798, 'recall_grapheme': 0.993975, 'recall_vowel': 0.997676, 'recall_consonant': 0.997567, 'acc_grapheme': 0.993887, 'acc_vowel': 0.997938, 'acc_consonant': 0.998037, 'loss_grapheme': 0.03879, 'loss_vowel': 0.021083, 'loss_consonant': 0.013372}\n",
      "  100 | 0.000075 | 076800/160596 | 0.0013 | 1.0293 |\n",
      "val: {'recall': 0.994072, 'recall_grapheme': 0.991287, 'recall_vowel': 0.997061, 'recall_consonant': 0.996655, 'acc_grapheme': 0.991999, 'acc_vowel': 0.997068, 'acc_consonant': 0.997465, 'loss_grapheme': 0.068855, 'loss_vowel': 0.047148, 'loss_consonant': 0.030391}\n",
      "  101 | 0.000086 | 069888/160596 | 0.0044 | 1.0754 |\n",
      "val: {'recall': 0.995593, 'recall_grapheme': 0.993741, 'recall_vowel': 0.997399, 'recall_consonant': 0.997492, 'acc_grapheme': 0.99344, 'acc_vowel': 0.99749, 'acc_consonant': 0.997565, 'loss_grapheme': 0.039439, 'loss_vowel': 0.022155, 'loss_consonant': 0.015047}\n",
      "  102 | 0.000093 | 062976/160596 | 0.0081 | 0.7871 |\n",
      "val: {'recall': 0.995462, 'recall_grapheme': 0.99363, 'recall_vowel': 0.997619, 'recall_consonant': 0.996968, 'acc_grapheme': 0.993564, 'acc_vowel': 0.997441, 'acc_consonant': 0.997465, 'loss_grapheme': 0.035334, 'loss_vowel': 0.017197, 'loss_consonant': 0.013509}\n",
      "  103 | 0.000098 | 056064/160596 | 0.0050 | 1.0231 |\n",
      "val: {'recall': 0.995937, 'recall_grapheme': 0.994517, 'recall_vowel': 0.997679, 'recall_consonant': 0.997033, 'acc_grapheme': 0.99421, 'acc_vowel': 0.997938, 'acc_consonant': 0.997764, 'loss_grapheme': 0.039488, 'loss_vowel': 0.023032, 'loss_consonant': 0.016106}\n",
      "  104 | 0.000100 | 049152/160596 | 3.2935 | 1.2283 |\n",
      "val: {'recall': 0.994815, 'recall_grapheme': 0.992782, 'recall_vowel': 0.996564, 'recall_consonant': 0.997132, 'acc_grapheme': 0.992446, 'acc_vowel': 0.997167, 'acc_consonant': 0.997366, 'loss_grapheme': 0.060115, 'loss_vowel': 0.035437, 'loss_consonant': 0.02299}\n",
      "  105 | 0.000098 | 042240/160596 | 1.8280 | 1.2069 |\n",
      "val: {'recall': 0.995438, 'recall_grapheme': 0.99351, 'recall_vowel': 0.997133, 'recall_consonant': 0.997599, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997441, 'acc_consonant': 0.997515, 'loss_grapheme': 0.072484, 'loss_vowel': 0.05713, 'loss_consonant': 0.034728}\n",
      "  106 | 0.000093 | 035328/160596 | 0.0151 | 0.9468 |\n",
      "val: {'recall': 0.99616, 'recall_grapheme': 0.994578, 'recall_vowel': 0.997432, 'recall_consonant': 0.998054, 'acc_grapheme': 0.994384, 'acc_vowel': 0.997689, 'acc_consonant': 0.997764, 'loss_grapheme': 0.028696, 'loss_vowel': 0.014726, 'loss_consonant': 0.010961}\n",
      "  107 | 0.000086 | 028416/160596 | 1.3531 | 1.1763 |\n",
      "val: {'recall': 0.994465, 'recall_grapheme': 0.99234, 'recall_vowel': 0.996926, 'recall_consonant': 0.996252, 'acc_grapheme': 0.992347, 'acc_vowel': 0.997441, 'acc_consonant': 0.997441, 'loss_grapheme': 0.091839, 'loss_vowel': 0.05415, 'loss_consonant': 0.040889}\n",
      "  108 | 0.000075 | 021504/160596 | 0.6719 | 0.6353 |\n",
      "val: {'recall': 0.995985, 'recall_grapheme': 0.994681, 'recall_vowel': 0.997726, 'recall_consonant': 0.996854, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997764, 'acc_consonant': 0.997863, 'loss_grapheme': 0.028741, 'loss_vowel': 0.014071, 'loss_consonant': 0.010251}\n",
      "  109 | 0.000063 | 014592/160596 | 2.1323 | 1.2081 |\n",
      "val: {'recall': 0.995354, 'recall_grapheme': 0.993872, 'recall_vowel': 0.997005, 'recall_consonant': 0.996665, 'acc_grapheme': 0.99349, 'acc_vowel': 0.997615, 'acc_consonant': 0.997639, 'loss_grapheme': 0.045329, 'loss_vowel': 0.028589, 'loss_consonant': 0.019427}\n",
      "  110 | 0.000050 | 007680/160596 | 2.3723 | 0.8604 |\n",
      "val: {'recall': 0.996247, 'recall_grapheme': 0.995111, 'recall_vowel': 0.99723, 'recall_consonant': 0.997534, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997739, 'acc_consonant': 0.998062, 'loss_grapheme': 0.02866, 'loss_vowel': 0.013725, 'loss_consonant': 0.010985}\n",
      "  111 | 0.000038 | 000768/160596 | 0.0102 | 0.0102 |\n",
      "val: {'recall': 0.996526, 'recall_grapheme': 0.995761, 'recall_vowel': 0.997574, 'recall_consonant': 0.997006, 'acc_grapheme': 0.994533, 'acc_vowel': 0.998012, 'acc_consonant': 0.998062, 'loss_grapheme': 0.026397, 'loss_vowel': 0.012417, 'loss_consonant': 0.009388}\n",
      "  111 | 0.000026 | 154368/160596 | 2.2891 | 1.0709 |\n",
      "val: {'recall': 0.996167, 'recall_grapheme': 0.995092, 'recall_vowel': 0.997516, 'recall_consonant': 0.996965, 'acc_grapheme': 0.99421, 'acc_vowel': 0.998012, 'acc_consonant': 0.997788, 'loss_grapheme': 0.031296, 'loss_vowel': 0.016032, 'loss_consonant': 0.013002}\n",
      "  112 | 0.000015 | 147456/160596 | 1.5618 | 1.0812 |\n",
      "val: {'recall': 0.995956, 'recall_grapheme': 0.994356, 'recall_vowel': 0.997478, 'recall_consonant': 0.997635, 'acc_grapheme': 0.993788, 'acc_vowel': 0.997838, 'acc_consonant': 0.997962, 'loss_grapheme': 0.037463, 'loss_vowel': 0.022485, 'loss_consonant': 0.01589}\n",
      "  113 | 0.000008 | 140544/160596 | 0.0012 | 1.0589 |\n",
      "val: {'recall': 0.996829, 'recall_grapheme': 0.995894, 'recall_vowel': 0.998022, 'recall_consonant': 0.997505, 'acc_grapheme': 0.994956, 'acc_vowel': 0.99831, 'acc_consonant': 0.998335, 'loss_grapheme': 0.022509, 'loss_vowel': 0.009057, 'loss_consonant': 0.007802}\n",
      "  114 | 0.000003 | 133632/160596 | 0.0035 | 1.0766 |\n",
      "val: {'recall': 0.995111, 'recall_grapheme': 0.993456, 'recall_vowel': 0.996842, 'recall_consonant': 0.996689, 'acc_grapheme': 0.993167, 'acc_vowel': 0.99754, 'acc_consonant': 0.997565, 'loss_grapheme': 0.047096, 'loss_vowel': 0.029055, 'loss_consonant': 0.021004}\n",
      "  115 | 0.000001 | 126720/160596 | 0.4420 | 0.8664 |\n",
      "val: {'recall': 0.996054, 'recall_grapheme': 0.994717, 'recall_vowel': 0.997589, 'recall_consonant': 0.997192, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997913, 'acc_consonant': 0.998062, 'loss_grapheme': 0.04053, 'loss_vowel': 0.022991, 'loss_consonant': 0.015839}\n",
      "  116 | 0.000003 | 119808/160596 | 0.9195 | 1.0515 |\n",
      "val: {'recall': 0.995617, 'recall_grapheme': 0.994195, 'recall_vowel': 0.997079, 'recall_consonant': 0.996998, 'acc_grapheme': 0.993738, 'acc_vowel': 0.997515, 'acc_consonant': 0.997788, 'loss_grapheme': 0.053538, 'loss_vowel': 0.033437, 'loss_consonant': 0.023833}\n",
      "  117 | 0.000008 | 112896/160596 | 1.2288 | 0.9540 |\n",
      "val: {'recall': 0.995963, 'recall_grapheme': 0.99469, 'recall_vowel': 0.997351, 'recall_consonant': 0.99712, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997913, 'acc_consonant': 0.997962, 'loss_grapheme': 0.035697, 'loss_vowel': 0.019213, 'loss_consonant': 0.013763}\n",
      "  118 | 0.000015 | 105984/160596 | 0.0005 | 1.0249 |\n",
      "val: {'recall': 0.996182, 'recall_grapheme': 0.994862, 'recall_vowel': 0.997685, 'recall_consonant': 0.997321, 'acc_grapheme': 0.994235, 'acc_vowel': 0.998136, 'acc_consonant': 0.998136, 'loss_grapheme': 0.046634, 'loss_vowel': 0.03106, 'loss_consonant': 0.020673}\n",
      "  119 | 0.000026 | 099072/160596 | 0.3320 | 1.0758 |\n",
      "val: {'recall': 0.996221, 'recall_grapheme': 0.994751, 'recall_vowel': 0.99789, 'recall_consonant': 0.997489, 'acc_grapheme': 0.99426, 'acc_vowel': 0.998087, 'acc_consonant': 0.997938, 'loss_grapheme': 0.036753, 'loss_vowel': 0.021824, 'loss_consonant': 0.014868}\n",
      "  120 | 0.000038 | 092160/160596 | 0.0049 | 0.9259 |\n",
      "val: {'recall': 0.99678, 'recall_grapheme': 0.995657, 'recall_vowel': 0.997856, 'recall_consonant': 0.99795, 'acc_grapheme': 0.994782, 'acc_vowel': 0.998136, 'acc_consonant': 0.998285, 'loss_grapheme': 0.023207, 'loss_vowel': 0.010238, 'loss_consonant': 0.007987}\n",
      "  121 | 0.000050 | 085248/160596 | 1.8422 | 1.0369 |\n",
      "val: {'recall': 0.995703, 'recall_grapheme': 0.994149, 'recall_vowel': 0.997294, 'recall_consonant': 0.99722, 'acc_grapheme': 0.993813, 'acc_vowel': 0.997565, 'acc_consonant': 0.99754, 'loss_grapheme': 0.06325, 'loss_vowel': 0.036563, 'loss_consonant': 0.02226}\n",
      "  122 | 0.000063 | 078336/160596 | 2.2587 | 0.9956 |\n",
      "val: {'recall': 0.995092, 'recall_grapheme': 0.993343, 'recall_vowel': 0.99716, 'recall_consonant': 0.996521, 'acc_grapheme': 0.993142, 'acc_vowel': 0.99759, 'acc_consonant': 0.997366, 'loss_grapheme': 0.041498, 'loss_vowel': 0.024809, 'loss_consonant': 0.019022}\n",
      "  123 | 0.000075 | 071424/160596 | 2.3789 | 0.8149 |\n",
      "val: {'recall': 0.996125, 'recall_grapheme': 0.99474, 'recall_vowel': 0.997452, 'recall_consonant': 0.997569, 'acc_grapheme': 0.994707, 'acc_vowel': 0.997913, 'acc_consonant': 0.997913, 'loss_grapheme': 0.027082, 'loss_vowel': 0.014554, 'loss_consonant': 0.01121}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  124 | 0.000086 | 064512/160596 | 2.3480 | 1.0901 |\n",
      "val: {'recall': 0.994852, 'recall_grapheme': 0.993261, 'recall_vowel': 0.996844, 'recall_consonant': 0.996043, 'acc_grapheme': 0.992794, 'acc_vowel': 0.99754, 'acc_consonant': 0.997366, 'loss_grapheme': 0.058023, 'loss_vowel': 0.044425, 'loss_consonant': 0.027339}\n",
      "  125 | 0.000093 | 057600/160596 | 0.0134 | 1.0411 |\n",
      "val: {'recall': 0.995032, 'recall_grapheme': 0.993427, 'recall_vowel': 0.996918, 'recall_consonant': 0.996359, 'acc_grapheme': 0.993192, 'acc_vowel': 0.997391, 'acc_consonant': 0.997465, 'loss_grapheme': 0.044581, 'loss_vowel': 0.025998, 'loss_consonant': 0.019002}\n",
      "  126 | 0.000098 | 050688/160596 | 1.2189 | 0.8846 |\n",
      "val: {'recall': 0.994566, 'recall_grapheme': 0.99286, 'recall_vowel': 0.996565, 'recall_consonant': 0.995978, 'acc_grapheme': 0.993092, 'acc_vowel': 0.997316, 'acc_consonant': 0.996894, 'loss_grapheme': 0.103283, 'loss_vowel': 0.05746, 'loss_consonant': 0.033882}\n",
      "  127 | 0.000100 | 043776/160596 | 0.0178 | 1.1014 |\n",
      "val: {'recall': 0.996082, 'recall_grapheme': 0.994784, 'recall_vowel': 0.997581, 'recall_consonant': 0.99718, 'acc_grapheme': 0.994434, 'acc_vowel': 0.998136, 'acc_consonant': 0.997913, 'loss_grapheme': 0.039713, 'loss_vowel': 0.02034, 'loss_consonant': 0.016135}\n",
      "  128 | 0.000098 | 036864/160596 | 0.0072 | 0.8440 |\n",
      "val: {'recall': 0.995587, 'recall_grapheme': 0.993505, 'recall_vowel': 0.99797, 'recall_consonant': 0.997366, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997689, 'acc_consonant': 0.997739, 'loss_grapheme': 0.056034, 'loss_vowel': 0.028939, 'loss_consonant': 0.018976}\n",
      "  129 | 0.000093 | 029952/160596 | 0.0022 | 0.8018 |\n",
      "val: {'recall': 0.996035, 'recall_grapheme': 0.995161, 'recall_vowel': 0.997122, 'recall_consonant': 0.996696, 'acc_grapheme': 0.99431, 'acc_vowel': 0.997838, 'acc_consonant': 0.997813, 'loss_grapheme': 0.027299, 'loss_vowel': 0.013822, 'loss_consonant': 0.010949}\n",
      "  130 | 0.000086 | 023040/160596 | 2.9588 | 1.0012 |\n",
      "val: {'recall': 0.995616, 'recall_grapheme': 0.993779, 'recall_vowel': 0.997608, 'recall_consonant': 0.997299, 'acc_grapheme': 0.992844, 'acc_vowel': 0.997813, 'acc_consonant': 0.997714, 'loss_grapheme': 0.041538, 'loss_vowel': 0.02092, 'loss_consonant': 0.016831}\n",
      "  131 | 0.000075 | 016128/160596 | 0.0082 | 0.7298 |\n",
      "val: {'recall': 0.996758, 'recall_grapheme': 0.995938, 'recall_vowel': 0.997992, 'recall_consonant': 0.997165, 'acc_grapheme': 0.99503, 'acc_vowel': 0.997888, 'acc_consonant': 0.997938, 'loss_grapheme': 0.024543, 'loss_vowel': 0.011671, 'loss_consonant': 0.009922}\n",
      "  132 | 0.000063 | 009216/160596 | 2.2957 | 1.3479 |\n",
      "val: {'recall': 0.995164, 'recall_grapheme': 0.993267, 'recall_vowel': 0.996929, 'recall_consonant': 0.997192, 'acc_grapheme': 0.992372, 'acc_vowel': 0.997192, 'acc_consonant': 0.997118, 'loss_grapheme': 0.071764, 'loss_vowel': 0.042195, 'loss_consonant': 0.030495}\n",
      "  133 | 0.000050 | 002304/160596 | 0.0009 | 0.4997 |\n",
      "val: {'recall': 0.995948, 'recall_grapheme': 0.994862, 'recall_vowel': 0.996863, 'recall_consonant': 0.997204, 'acc_grapheme': 0.994235, 'acc_vowel': 0.997739, 'acc_consonant': 0.997615, 'loss_grapheme': 0.044718, 'loss_vowel': 0.027319, 'loss_consonant': 0.018206}\n",
      "  133 | 0.000038 | 109056/160596 | 0.0011 | 1.0476 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-6caf23ca3f59>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.996594, 'recall_grapheme': 0.995644, 'recall_vowel': 0.997221, 'recall_consonant': 0.997868, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997888, 'acc_consonant': 0.998037, 'loss_grapheme': 0.04701, 'loss_vowel': 0.031229, 'loss_consonant': 0.019246}\n",
      "    0 | 0.000050 | 153600/160596 | 2.9915 | 0.9949 |\n",
      "val: {'recall': 0.995376, 'recall_grapheme': 0.993672, 'recall_vowel': 0.996709, 'recall_consonant': 0.99745, 'acc_grapheme': 0.992545, 'acc_vowel': 0.997167, 'acc_consonant': 0.997465, 'loss_grapheme': 0.065048, 'loss_vowel': 0.045178, 'loss_consonant': 0.028609}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000049 | 146688/160596 | 2.7502 | 0.9795 |\n",
      "val: {'recall': 0.995199, 'recall_grapheme': 0.993832, 'recall_vowel': 0.996334, 'recall_consonant': 0.996799, 'acc_grapheme': 0.993117, 'acc_vowel': 0.997093, 'acc_consonant': 0.997217, 'loss_grapheme': 0.070144, 'loss_vowel': 0.042003, 'loss_consonant': 0.029556}\n",
      "    2 | 0.000047 | 139776/160596 | 0.9920 | 1.1780 |\n",
      "val: {'recall': 0.996026, 'recall_grapheme': 0.994619, 'recall_vowel': 0.997464, 'recall_consonant': 0.997399, 'acc_grapheme': 0.99431, 'acc_vowel': 0.997913, 'acc_consonant': 0.997813, 'loss_grapheme': 0.079974, 'loss_vowel': 0.048938, 'loss_consonant': 0.029277}\n",
      "    3 | 0.000043 | 132864/160596 | 1.9856 | 0.9920 |\n",
      "val: {'recall': 0.995362, 'recall_grapheme': 0.994091, 'recall_vowel': 0.996464, 'recall_consonant': 0.9968, 'acc_grapheme': 0.993266, 'acc_vowel': 0.99754, 'acc_consonant': 0.997689, 'loss_grapheme': 0.047206, 'loss_vowel': 0.03002, 'loss_consonant': 0.02143}\n",
      "    4 | 0.000038 | 125952/160596 | 1.1945 | 1.0106 |\n",
      "val: {'recall': 0.996146, 'recall_grapheme': 0.994937, 'recall_vowel': 0.997173, 'recall_consonant': 0.997538, 'acc_grapheme': 0.994185, 'acc_vowel': 0.997739, 'acc_consonant': 0.997788, 'loss_grapheme': 0.04326, 'loss_vowel': 0.02751, 'loss_consonant': 0.017942}\n",
      "    5 | 0.000032 | 119040/160596 | 2.3804 | 0.9627 |\n",
      "val: {'recall': 0.996398, 'recall_grapheme': 0.995686, 'recall_vowel': 0.997156, 'recall_consonant': 0.997064, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997764, 'acc_consonant': 0.998037, 'loss_grapheme': 0.03648, 'loss_vowel': 0.022747, 'loss_consonant': 0.015475}\n",
      "    6 | 0.000026 | 112128/160596 | 2.7463 | 1.1509 |\n",
      "val: {'recall': 0.994918, 'recall_grapheme': 0.993278, 'recall_vowel': 0.9964, 'recall_consonant': 0.996717, 'acc_grapheme': 0.992446, 'acc_vowel': 0.997292, 'acc_consonant': 0.99749, 'loss_grapheme': 0.052914, 'loss_vowel': 0.036392, 'loss_consonant': 0.024352}\n",
      "    7 | 0.000020 | 105216/160596 | 1.4413 | 1.0639 |\n",
      "val: {'recall': 0.995543, 'recall_grapheme': 0.993734, 'recall_vowel': 0.997287, 'recall_consonant': 0.997416, 'acc_grapheme': 0.993291, 'acc_vowel': 0.997714, 'acc_consonant': 0.997515, 'loss_grapheme': 0.065063, 'loss_vowel': 0.043389, 'loss_consonant': 0.026819}\n",
      "    8 | 0.000014 | 098304/160596 | 1.8653 | 0.9868 |\n",
      "val: {'recall': 0.996179, 'recall_grapheme': 0.99503, 'recall_vowel': 0.997259, 'recall_consonant': 0.997397, 'acc_grapheme': 0.993937, 'acc_vowel': 0.997739, 'acc_consonant': 0.997863, 'loss_grapheme': 0.032189, 'loss_vowel': 0.018232, 'loss_consonant': 0.013625}\n",
      "    9 | 0.000009 | 091392/160596 | 0.0015 | 0.8303 |\n",
      "val: {'recall': 0.996512, 'recall_grapheme': 0.995318, 'recall_vowel': 0.997594, 'recall_consonant': 0.997819, 'acc_grapheme': 0.994608, 'acc_vowel': 0.997938, 'acc_consonant': 0.998136, 'loss_grapheme': 0.037094, 'loss_vowel': 0.022263, 'loss_consonant': 0.01521}\n",
      "   10 | 0.000005 | 084480/160596 | 2.3482 | 0.9840 |\n",
      "val: {'recall': 0.996478, 'recall_grapheme': 0.995549, 'recall_vowel': 0.997127, 'recall_consonant': 0.997689, 'acc_grapheme': 0.994359, 'acc_vowel': 0.997888, 'acc_consonant': 0.997938, 'loss_grapheme': 0.034366, 'loss_vowel': 0.018935, 'loss_consonant': 0.013952}\n",
      "   11 | 0.000003 | 077568/160596 | 0.0052 | 1.0482 |\n",
      "val: {'recall': 0.996447, 'recall_grapheme': 0.995503, 'recall_vowel': 0.997094, 'recall_consonant': 0.997689, 'acc_grapheme': 0.994409, 'acc_vowel': 0.997863, 'acc_consonant': 0.997938, 'loss_grapheme': 0.028999, 'loss_vowel': 0.014829, 'loss_consonant': 0.011463}\n",
      "   12 | 0.000002 | 070656/160596 | 1.2641 | 1.1046 |\n",
      "val: {'recall': 0.996319, 'recall_grapheme': 0.995443, 'recall_vowel': 0.996854, 'recall_consonant': 0.997537, 'acc_grapheme': 0.99421, 'acc_vowel': 0.997813, 'acc_consonant': 0.997863, 'loss_grapheme': 0.047461, 'loss_vowel': 0.030406, 'loss_consonant': 0.021443}\n",
      "   13 | 0.000003 | 063744/160596 | 0.0039 | 1.0153 |\n",
      "val: {'recall': 0.996538, 'recall_grapheme': 0.99536, 'recall_vowel': 0.997627, 'recall_consonant': 0.997807, 'acc_grapheme': 0.994881, 'acc_vowel': 0.997987, 'acc_consonant': 0.998112, 'loss_grapheme': 0.041751, 'loss_vowel': 0.024977, 'loss_consonant': 0.017094}\n",
      "   14 | 0.000005 | 056832/160596 | 0.0035 | 0.8072 |\n",
      "val: {'recall': 0.996988, 'recall_grapheme': 0.996238, 'recall_vowel': 0.99774, 'recall_consonant': 0.997735, 'acc_grapheme': 0.995254, 'acc_vowel': 0.998161, 'acc_consonant': 0.998136, 'loss_grapheme': 0.022178, 'loss_vowel': 0.010151, 'loss_consonant': 0.008258}\n",
      "** saved\n",
      "   15 | 0.000009 | 049920/160596 | 0.0119 | 0.7975 |\n",
      "val: {'recall': 0.996447, 'recall_grapheme': 0.995145, 'recall_vowel': 0.997562, 'recall_consonant': 0.997937, 'acc_grapheme': 0.994484, 'acc_vowel': 0.998037, 'acc_consonant': 0.998211, 'loss_grapheme': 0.03624, 'loss_vowel': 0.0216, 'loss_consonant': 0.014993}\n",
      "   16 | 0.000014 | 043008/160596 | 0.8056 | 1.1378 |\n",
      "val: {'recall': 0.996395, 'recall_grapheme': 0.995241, 'recall_vowel': 0.997521, 'recall_consonant': 0.997579, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997863, 'acc_consonant': 0.997913, 'loss_grapheme': 0.047343, 'loss_vowel': 0.031036, 'loss_consonant': 0.020133}\n",
      "   17 | 0.000020 | 036096/160596 | 0.0019 | 0.9046 |\n",
      "val: {'recall': 0.99549, 'recall_grapheme': 0.994443, 'recall_vowel': 0.99634, 'recall_consonant': 0.996737, 'acc_grapheme': 0.993117, 'acc_vowel': 0.997267, 'acc_consonant': 0.997515, 'loss_grapheme': 0.033233, 'loss_vowel': 0.017362, 'loss_consonant': 0.014461}\n",
      "   18 | 0.000026 | 029184/160596 | 0.0041 | 0.7760 |\n",
      "val: {'recall': 0.996478, 'recall_grapheme': 0.995334, 'recall_vowel': 0.997626, 'recall_consonant': 0.997617, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997938, 'acc_consonant': 0.997962, 'loss_grapheme': 0.043439, 'loss_vowel': 0.025459, 'loss_consonant': 0.017467}\n",
      "   19 | 0.000032 | 022272/160596 | 2.1514 | 1.3442 |\n",
      "val: {'recall': 0.995385, 'recall_grapheme': 0.99416, 'recall_vowel': 0.996871, 'recall_consonant': 0.996349, 'acc_grapheme': 0.993614, 'acc_vowel': 0.997515, 'acc_consonant': 0.997639, 'loss_grapheme': 0.080928, 'loss_vowel': 0.052035, 'loss_consonant': 0.035363}\n",
      "   20 | 0.000038 | 015360/160596 | 0.0143 | 0.9555 |\n",
      "val: {'recall': 0.996068, 'recall_grapheme': 0.994395, 'recall_vowel': 0.997844, 'recall_consonant': 0.997636, 'acc_grapheme': 0.994409, 'acc_vowel': 0.998062, 'acc_consonant': 0.997838, 'loss_grapheme': 0.031327, 'loss_vowel': 0.015418, 'loss_consonant': 0.011822}\n",
      "   21 | 0.000043 | 008448/160596 | 2.6577 | 1.0225 |\n",
      "val: {'recall': 0.995649, 'recall_grapheme': 0.994459, 'recall_vowel': 0.996548, 'recall_consonant': 0.997129, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997391, 'acc_consonant': 0.997813, 'loss_grapheme': 0.040247, 'loss_vowel': 0.023227, 'loss_consonant': 0.01635}\n",
      "   22 | 0.000047 | 001536/160596 | 0.0015 | 0.0024 |\n",
      "val: {'recall': 0.99615, 'recall_grapheme': 0.994969, 'recall_vowel': 0.997137, 'recall_consonant': 0.997524, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997838, 'acc_consonant': 0.997788, 'loss_grapheme': 0.035769, 'loss_vowel': 0.018546, 'loss_consonant': 0.014105}\n",
      "   22 | 0.000049 | 155136/160596 | 0.0029 | 0.9401 |\n",
      "val: {'recall': 0.996704, 'recall_grapheme': 0.995718, 'recall_vowel': 0.997681, 'recall_consonant': 0.997699, 'acc_grapheme': 0.994856, 'acc_vowel': 0.998087, 'acc_consonant': 0.998012, 'loss_grapheme': 0.022951, 'loss_vowel': 0.010111, 'loss_consonant': 0.008893}\n",
      "   23 | 0.000050 | 148224/160596 | 1.9802 | 0.8842 |\n",
      "val: {'recall': 0.996359, 'recall_grapheme': 0.99549, 'recall_vowel': 0.996824, 'recall_consonant': 0.997632, 'acc_grapheme': 0.994881, 'acc_vowel': 0.997788, 'acc_consonant': 0.997838, 'loss_grapheme': 0.027956, 'loss_vowel': 0.014726, 'loss_consonant': 0.011276}\n",
      "   24 | 0.000049 | 141312/160596 | 1.8175 | 1.0094 |\n",
      "val: {'recall': 0.994546, 'recall_grapheme': 0.992173, 'recall_vowel': 0.996726, 'recall_consonant': 0.997114, 'acc_grapheme': 0.992769, 'acc_vowel': 0.997391, 'acc_consonant': 0.997292, 'loss_grapheme': 0.039468, 'loss_vowel': 0.021231, 'loss_consonant': 0.017302}\n",
      "   25 | 0.000047 | 134400/160596 | 2.0092 | 0.9539 |\n",
      "val: {'recall': 0.995546, 'recall_grapheme': 0.994336, 'recall_vowel': 0.996692, 'recall_consonant': 0.99682, 'acc_grapheme': 0.994111, 'acc_vowel': 0.99759, 'acc_consonant': 0.997838, 'loss_grapheme': 0.026986, 'loss_vowel': 0.013447, 'loss_consonant': 0.009841}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 0.000043 | 127488/160596 | 0.3480 | 0.9857 |\n",
      "val: {'recall': 0.996106, 'recall_grapheme': 0.995074, 'recall_vowel': 0.996828, 'recall_consonant': 0.997447, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997664, 'acc_consonant': 0.997863, 'loss_grapheme': 0.04099, 'loss_vowel': 0.025943, 'loss_consonant': 0.017605}\n",
      "   27 | 0.000038 | 120576/160596 | 1.9621 | 1.0447 |\n",
      "val: {'recall': 0.995938, 'recall_grapheme': 0.994672, 'recall_vowel': 0.996948, 'recall_consonant': 0.99746, 'acc_grapheme': 0.994061, 'acc_vowel': 0.99754, 'acc_consonant': 0.997863, 'loss_grapheme': 0.037164, 'loss_vowel': 0.024009, 'loss_consonant': 0.017022}\n",
      "   28 | 0.000032 | 113664/160596 | 2.1776 | 0.9960 |\n",
      "val: {'recall': 0.996103, 'recall_grapheme': 0.994855, 'recall_vowel': 0.997058, 'recall_consonant': 0.997644, 'acc_grapheme': 0.994484, 'acc_vowel': 0.997863, 'acc_consonant': 0.997913, 'loss_grapheme': 0.040958, 'loss_vowel': 0.026224, 'loss_consonant': 0.01789}\n",
      "   29 | 0.000026 | 106752/160596 | 0.0052 | 0.9629 |\n",
      "val: {'recall': 0.995394, 'recall_grapheme': 0.994254, 'recall_vowel': 0.997216, 'recall_consonant': 0.995852, 'acc_grapheme': 0.994061, 'acc_vowel': 0.997739, 'acc_consonant': 0.997838, 'loss_grapheme': 0.041315, 'loss_vowel': 0.026099, 'loss_consonant': 0.018736}\n",
      "   30 | 0.000020 | 099840/160596 | 1.9039 | 0.8034 |\n",
      "val: {'recall': 0.996277, 'recall_grapheme': 0.995326, 'recall_vowel': 0.996921, 'recall_consonant': 0.997536, 'acc_grapheme': 0.994558, 'acc_vowel': 0.997689, 'acc_consonant': 0.997813, 'loss_grapheme': 0.026488, 'loss_vowel': 0.014539, 'loss_consonant': 0.011016}\n",
      "   31 | 0.000014 | 092928/160596 | 0.0152 | 1.0378 |\n",
      "val: {'recall': 0.996034, 'recall_grapheme': 0.994987, 'recall_vowel': 0.996657, 'recall_consonant': 0.997506, 'acc_grapheme': 0.994359, 'acc_vowel': 0.997664, 'acc_consonant': 0.997913, 'loss_grapheme': 0.029372, 'loss_vowel': 0.016544, 'loss_consonant': 0.012526}\n",
      "   32 | 0.000009 | 086016/160596 | 0.0011 | 1.1067 |\n",
      "val: {'recall': 0.996051, 'recall_grapheme': 0.994825, 'recall_vowel': 0.997159, 'recall_consonant': 0.997394, 'acc_grapheme': 0.994359, 'acc_vowel': 0.997764, 'acc_consonant': 0.997863, 'loss_grapheme': 0.063607, 'loss_vowel': 0.039089, 'loss_consonant': 0.025955}\n",
      "   33 | 0.000005 | 079104/160596 | 0.0022 | 1.0041 |\n",
      "val: {'recall': 0.996535, 'recall_grapheme': 0.995388, 'recall_vowel': 0.997591, 'recall_consonant': 0.997773, 'acc_grapheme': 0.994856, 'acc_vowel': 0.998112, 'acc_consonant': 0.998087, 'loss_grapheme': 0.028314, 'loss_vowel': 0.015972, 'loss_consonant': 0.012257}\n",
      "   34 | 0.000003 | 072192/160596 | 0.9916 | 1.0326 |\n",
      "val: {'recall': 0.99632, 'recall_grapheme': 0.995175, 'recall_vowel': 0.997377, 'recall_consonant': 0.997551, 'acc_grapheme': 0.994583, 'acc_vowel': 0.997962, 'acc_consonant': 0.997913, 'loss_grapheme': 0.04554, 'loss_vowel': 0.027191, 'loss_consonant': 0.018804}\n",
      "   35 | 0.000002 | 065280/160596 | 1.8838 | 0.9883 |\n",
      "val: {'recall': 0.99596, 'recall_grapheme': 0.994653, 'recall_vowel': 0.997091, 'recall_consonant': 0.997441, 'acc_grapheme': 0.994161, 'acc_vowel': 0.997788, 'acc_consonant': 0.997813, 'loss_grapheme': 0.082572, 'loss_vowel': 0.048848, 'loss_consonant': 0.033993}\n",
      "   36 | 0.000003 | 058368/160596 | 1.3525 | 0.9040 |\n",
      "val: {'recall': 0.996241, 'recall_grapheme': 0.994927, 'recall_vowel': 0.997559, 'recall_consonant': 0.997554, 'acc_grapheme': 0.994633, 'acc_vowel': 0.997987, 'acc_consonant': 0.997938, 'loss_grapheme': 0.051903, 'loss_vowel': 0.03132, 'loss_consonant': 0.020938}\n",
      "   37 | 0.000005 | 051456/160596 | 2.0889 | 0.8512 |\n",
      "val: {'recall': 0.995991, 'recall_grapheme': 0.994871, 'recall_vowel': 0.996713, 'recall_consonant': 0.997511, 'acc_grapheme': 0.994335, 'acc_vowel': 0.997664, 'acc_consonant': 0.997739, 'loss_grapheme': 0.033068, 'loss_vowel': 0.018668, 'loss_consonant': 0.01475}\n",
      "   38 | 0.000009 | 044544/160596 | 1.2973 | 1.1515 |\n",
      "val: {'recall': 0.995759, 'recall_grapheme': 0.994315, 'recall_vowel': 0.99689, 'recall_consonant': 0.997516, 'acc_grapheme': 0.993987, 'acc_vowel': 0.997639, 'acc_consonant': 0.997938, 'loss_grapheme': 0.098008, 'loss_vowel': 0.061518, 'loss_consonant': 0.040171}\n",
      "   39 | 0.000014 | 037632/160596 | 1.1312 | 1.0164 |\n",
      "val: {'recall': 0.996051, 'recall_grapheme': 0.99466, 'recall_vowel': 0.997386, 'recall_consonant': 0.997499, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997913, 'acc_consonant': 0.997913, 'loss_grapheme': 0.069458, 'loss_vowel': 0.041033, 'loss_consonant': 0.027037}\n",
      "   40 | 0.000020 | 030720/160596 | 1.7893 | 1.1578 |\n",
      "val: {'recall': 0.996131, 'recall_grapheme': 0.994883, 'recall_vowel': 0.997291, 'recall_consonant': 0.997469, 'acc_grapheme': 0.99421, 'acc_vowel': 0.997863, 'acc_consonant': 0.997863, 'loss_grapheme': 0.06726, 'loss_vowel': 0.041993, 'loss_consonant': 0.02843}\n",
      "   41 | 0.000026 | 023808/160596 | 2.3230 | 1.0939 |\n",
      "val: {'recall': 0.995883, 'recall_grapheme': 0.994799, 'recall_vowel': 0.996677, 'recall_consonant': 0.997257, 'acc_grapheme': 0.993415, 'acc_vowel': 0.997565, 'acc_consonant': 0.997714, 'loss_grapheme': 0.041172, 'loss_vowel': 0.024896, 'loss_consonant': 0.018627}\n",
      "   42 | 0.000032 | 016896/160596 | 0.0038 | 0.9353 |\n",
      "val: {'recall': 0.996038, 'recall_grapheme': 0.995158, 'recall_vowel': 0.996737, 'recall_consonant': 0.997097, 'acc_grapheme': 0.994434, 'acc_vowel': 0.997813, 'acc_consonant': 0.997938, 'loss_grapheme': 0.043424, 'loss_vowel': 0.027016, 'loss_consonant': 0.018281}\n",
      "   43 | 0.000038 | 009984/160596 | 0.0134 | 0.9184 |\n",
      "val: {'recall': 0.995665, 'recall_grapheme': 0.994424, 'recall_vowel': 0.996189, 'recall_consonant': 0.99762, 'acc_grapheme': 0.993639, 'acc_vowel': 0.997242, 'acc_consonant': 0.997664, 'loss_grapheme': 0.03199, 'loss_vowel': 0.014095, 'loss_consonant': 0.012576}\n",
      "   43 | 0.000043 | 094464/160596 | 2.4350 | 0.9500 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-96cb3a1b9641>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbbx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbby2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbby1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# grid mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.996243, 'recall_grapheme': 0.9952, 'recall_vowel': 0.9978, 'recall_consonant': 0.996773, 'acc_grapheme': 0.994682, 'acc_vowel': 0.998037, 'acc_consonant': 0.99831, 'loss_grapheme': 0.038524, 'loss_vowel': 0.023072, 'loss_consonant': 0.015039}\n",
      "    0 | 0.000050 | 153600/160596 | 0.0004 | 1.0014 |\n",
      "val: {'recall': 0.99648, 'recall_grapheme': 0.995899, 'recall_vowel': 0.997387, 'recall_consonant': 0.996733, 'acc_grapheme': 0.995279, 'acc_vowel': 0.997962, 'acc_consonant': 0.998087, 'loss_grapheme': 0.024084, 'loss_vowel': 0.012797, 'loss_consonant': 0.01014}\n",
      "** saved\n",
      "    1 | 0.000049 | 146688/160596 | 1.0808 | 0.9460 |\n",
      "val: {'recall': 0.995629, 'recall_grapheme': 0.994899, 'recall_vowel': 0.997073, 'recall_consonant': 0.995644, 'acc_grapheme': 0.994111, 'acc_vowel': 0.997639, 'acc_consonant': 0.997764, 'loss_grapheme': 0.05105, 'loss_vowel': 0.033326, 'loss_consonant': 0.02077}\n",
      "    2 | 0.000047 | 139776/160596 | 3.1113 | 1.1620 |\n",
      "val: {'recall': 0.996102, 'recall_grapheme': 0.995232, 'recall_vowel': 0.997385, 'recall_consonant': 0.996557, 'acc_grapheme': 0.994533, 'acc_vowel': 0.998037, 'acc_consonant': 0.998112, 'loss_grapheme': 0.036508, 'loss_vowel': 0.022371, 'loss_consonant': 0.015776}\n",
      "    3 | 0.000043 | 132864/160596 | 1.7434 | 1.0202 |\n",
      "val: {'recall': 0.996096, 'recall_grapheme': 0.99513, 'recall_vowel': 0.996739, 'recall_consonant': 0.997384, 'acc_grapheme': 0.994682, 'acc_vowel': 0.997689, 'acc_consonant': 0.997962, 'loss_grapheme': 0.040257, 'loss_vowel': 0.02531, 'loss_consonant': 0.016087}\n",
      "    4 | 0.000038 | 125952/160596 | 2.2502 | 0.9600 |\n",
      "val: {'recall': 0.995818, 'recall_grapheme': 0.994651, 'recall_vowel': 0.997077, 'recall_consonant': 0.996894, 'acc_grapheme': 0.993788, 'acc_vowel': 0.997689, 'acc_consonant': 0.997838, 'loss_grapheme': 0.044479, 'loss_vowel': 0.028938, 'loss_consonant': 0.019765}\n",
      "    5 | 0.000032 | 119040/160596 | 1.6198 | 1.0147 |\n",
      "val: {'recall': 0.99515, 'recall_grapheme': 0.993905, 'recall_vowel': 0.996808, 'recall_consonant': 0.99598, 'acc_grapheme': 0.993241, 'acc_vowel': 0.997391, 'acc_consonant': 0.997639, 'loss_grapheme': 0.133163, 'loss_vowel': 0.080796, 'loss_consonant': 0.046377}\n",
      "    6 | 0.000026 | 112128/160596 | 1.2226 | 0.9328 |\n",
      "val: {'recall': 0.995725, 'recall_grapheme': 0.994349, 'recall_vowel': 0.996713, 'recall_consonant': 0.99749, 'acc_grapheme': 0.993912, 'acc_vowel': 0.997391, 'acc_consonant': 0.997788, 'loss_grapheme': 0.071275, 'loss_vowel': 0.044977, 'loss_consonant': 0.026711}\n",
      "    7 | 0.000020 | 105216/160596 | 0.0080 | 1.0579 |\n",
      "val: {'recall': 0.994924, 'recall_grapheme': 0.993361, 'recall_vowel': 0.996183, 'recall_consonant': 0.996792, 'acc_grapheme': 0.992869, 'acc_vowel': 0.997118, 'acc_consonant': 0.997515, 'loss_grapheme': 0.049389, 'loss_vowel': 0.034983, 'loss_consonant': 0.023772}\n",
      "    8 | 0.000014 | 098304/160596 | 1.1105 | 0.9590 |\n",
      "val: {'recall': 0.996139, 'recall_grapheme': 0.994809, 'recall_vowel': 0.997137, 'recall_consonant': 0.997801, 'acc_grapheme': 0.994359, 'acc_vowel': 0.997838, 'acc_consonant': 0.998087, 'loss_grapheme': 0.043331, 'loss_vowel': 0.028084, 'loss_consonant': 0.018915}\n",
      "    9 | 0.000009 | 091392/160596 | 2.1100 | 0.9620 |\n",
      "val: {'recall': 0.995674, 'recall_grapheme': 0.994195, 'recall_vowel': 0.997114, 'recall_consonant': 0.997192, 'acc_grapheme': 0.993689, 'acc_vowel': 0.99754, 'acc_consonant': 0.997838, 'loss_grapheme': 0.092852, 'loss_vowel': 0.060817, 'loss_consonant': 0.037466}\n",
      "   10 | 0.000005 | 084480/160596 | 1.2523 | 1.0401 |\n",
      "val: {'recall': 0.996446, 'recall_grapheme': 0.995408, 'recall_vowel': 0.997154, 'recall_consonant': 0.997816, 'acc_grapheme': 0.994633, 'acc_vowel': 0.997863, 'acc_consonant': 0.998136, 'loss_grapheme': 0.036571, 'loss_vowel': 0.022166, 'loss_consonant': 0.015772}\n",
      "   11 | 0.000003 | 077568/160596 | 2.1693 | 0.9032 |\n",
      "val: {'recall': 0.996009, 'recall_grapheme': 0.994617, 'recall_vowel': 0.997107, 'recall_consonant': 0.997695, 'acc_grapheme': 0.994086, 'acc_vowel': 0.997788, 'acc_consonant': 0.997987, 'loss_grapheme': 0.056136, 'loss_vowel': 0.036107, 'loss_consonant': 0.023255}\n",
      "   12 | 0.000002 | 070656/160596 | 0.9356 | 1.0198 |\n",
      "val: {'recall': 0.996001, 'recall_grapheme': 0.99448, 'recall_vowel': 0.997258, 'recall_consonant': 0.997786, 'acc_grapheme': 0.994409, 'acc_vowel': 0.997938, 'acc_consonant': 0.997938, 'loss_grapheme': 0.038061, 'loss_vowel': 0.02274, 'loss_consonant': 0.016062}\n",
      "   13 | 0.000003 | 063744/160596 | 0.0052 | 0.9346 |\n",
      "val: {'recall': 0.996141, 'recall_grapheme': 0.995157, 'recall_vowel': 0.996931, 'recall_consonant': 0.997317, 'acc_grapheme': 0.994558, 'acc_vowel': 0.997863, 'acc_consonant': 0.997987, 'loss_grapheme': 0.026698, 'loss_vowel': 0.013996, 'loss_consonant': 0.011245}\n",
      "   14 | 0.000005 | 056832/160596 | 0.0078 | 0.9429 |\n",
      "val: {'recall': 0.99617, 'recall_grapheme': 0.995095, 'recall_vowel': 0.997273, 'recall_consonant': 0.997218, 'acc_grapheme': 0.99426, 'acc_vowel': 0.997938, 'acc_consonant': 0.998062, 'loss_grapheme': 0.050604, 'loss_vowel': 0.034306, 'loss_consonant': 0.022663}\n",
      "   15 | 0.000009 | 049920/160596 | 0.0028 | 0.8558 |\n",
      "val: {'recall': 0.996594, 'recall_grapheme': 0.995644, 'recall_vowel': 0.997221, 'recall_consonant': 0.997868, 'acc_grapheme': 0.994757, 'acc_vowel': 0.997888, 'acc_consonant': 0.998037, 'loss_grapheme': 0.04701, 'loss_vowel': 0.031229, 'loss_consonant': 0.019246}\n",
      "** saved\n",
      "   16 | 0.000014 | 043008/160596 | 1.2640 | 0.9654 |\n",
      "val: {'recall': 0.995175, 'recall_grapheme': 0.9934, 'recall_vowel': 0.99678, 'recall_consonant': 0.99712, 'acc_grapheme': 0.993316, 'acc_vowel': 0.99754, 'acc_consonant': 0.997714, 'loss_grapheme': 0.053589, 'loss_vowel': 0.037985, 'loss_consonant': 0.024951}\n",
      "   17 | 0.000020 | 036096/160596 | 2.0217 | 1.1519 |\n",
      "val: {'recall': 0.995586, 'recall_grapheme': 0.99422, 'recall_vowel': 0.997003, 'recall_consonant': 0.9969, 'acc_grapheme': 0.993465, 'acc_vowel': 0.997714, 'acc_consonant': 0.998012, 'loss_grapheme': 0.038088, 'loss_vowel': 0.022664, 'loss_consonant': 0.016779}\n",
      "   17 | 0.000026 | 160512/160596 | 1.5071 | 1.0746 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fb3a5f35840>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chec/anaconda3/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 92078, 92079, 92080, 92081) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-96cb3a1b9641>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mtrain_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 92078, 92079, 92080, 92081) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
