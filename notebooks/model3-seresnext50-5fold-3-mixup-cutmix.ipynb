{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/chec/data/bengali': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/chicm/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        #if self.train_mode:\n",
    "        #    augs = get_train_augs()\n",
    "        #    img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401002175730606"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model3_se_resnext50_fold3_mixup_cutmix.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 1e-4\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.1\n",
    "args.patience = 0\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160716, 5) (40124, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model3_se_resnext50_fold3_mixup_cutmix.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model3_se_resnext50_fold3_mixup_cutmix.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.981922, 'recall_grapheme': 0.972954, 'recall_vowel': 0.990326, 'recall_consonant': 0.991452, 'acc_grapheme': 0.970541, 'acc_vowel': 0.991252, 'acc_consonant': 0.990554, 'loss_grapheme': 0.244743, 'loss_vowel': 0.186267, 'loss_consonant': 0.128829}\n",
      "    1 | 0.000100 | 045056/160716 | 3.3105 | 2.4291 |\n",
      "val: {'recall': 0.981014, 'recall_grapheme': 0.970919, 'recall_vowel': 0.990039, 'recall_consonant': 0.992181, 'acc_grapheme': 0.969594, 'acc_vowel': 0.991327, 'acc_consonant': 0.990679, 'loss_grapheme': 0.25883, 'loss_vowel': 0.197755, 'loss_consonant': 0.132872}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:113: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000098 | 090112/160716 | 2.1202 | 2.4000 |\n",
      "val: {'recall': 0.981567, 'recall_grapheme': 0.971812, 'recall_vowel': 0.990692, 'recall_consonant': 0.991952, 'acc_grapheme': 0.970616, 'acc_vowel': 0.991601, 'acc_consonant': 0.990953, 'loss_grapheme': 0.231411, 'loss_vowel': 0.17915, 'loss_consonant': 0.124251}\n",
      "    3 | 0.000093 | 135168/160716 | 1.3842 | 2.3099 |\n",
      "val: {'recall': 0.98127, 'recall_grapheme': 0.971579, 'recall_vowel': 0.990449, 'recall_consonant': 0.991472, 'acc_grapheme': 0.969868, 'acc_vowel': 0.991676, 'acc_consonant': 0.990305, 'loss_grapheme': 0.254598, 'loss_vowel': 0.181791, 'loss_consonant': 0.123006}\n",
      "    5 | 0.000086 | 020480/160716 | 1.1154 | 2.2862 |\n",
      "val: {'recall': 0.981374, 'recall_grapheme': 0.972035, 'recall_vowel': 0.990117, 'recall_consonant': 0.991311, 'acc_grapheme': 0.970167, 'acc_vowel': 0.991352, 'acc_consonant': 0.990953, 'loss_grapheme': 0.249106, 'loss_vowel': 0.187329, 'loss_consonant': 0.12742}\n",
      "    6 | 0.000075 | 065536/160716 | 2.1599 | 2.3773 |\n",
      "val: {'recall': 0.982047, 'recall_grapheme': 0.973114, 'recall_vowel': 0.990546, 'recall_consonant': 0.991414, 'acc_grapheme': 0.970865, 'acc_vowel': 0.991726, 'acc_consonant': 0.990853, 'loss_grapheme': 0.31007, 'loss_vowel': 0.25183, 'loss_consonant': 0.167677}\n",
      "** saved\n",
      "    7 | 0.000063 | 110592/160716 | 1.4248 | 2.4092 |\n",
      "val: {'recall': 0.981845, 'recall_grapheme': 0.972871, 'recall_vowel': 0.990391, 'recall_consonant': 0.991246, 'acc_grapheme': 0.970591, 'acc_vowel': 0.991526, 'acc_consonant': 0.990579, 'loss_grapheme': 0.240142, 'loss_vowel': 0.195089, 'loss_consonant': 0.123498}\n",
      "    8 | 0.000050 | 155648/160716 | 1.7324 | 2.4339 |\n",
      "val: {'recall': 0.981746, 'recall_grapheme': 0.972012, 'recall_vowel': 0.991238, 'recall_consonant': 0.991724, 'acc_grapheme': 0.970591, 'acc_vowel': 0.992025, 'acc_consonant': 0.990729, 'loss_grapheme': 0.276651, 'loss_vowel': 0.22839, 'loss_consonant': 0.147513}\n",
      "   10 | 0.000038 | 040960/160716 | 2.5175 | 2.3572 |\n",
      "val: {'recall': 0.981602, 'recall_grapheme': 0.972227, 'recall_vowel': 0.990601, 'recall_consonant': 0.991354, 'acc_grapheme': 0.970093, 'acc_vowel': 0.991825, 'acc_consonant': 0.991103, 'loss_grapheme': 0.269304, 'loss_vowel': 0.218661, 'loss_consonant': 0.137249}\n",
      "   11 | 0.000026 | 086016/160716 | 2.8761 | 2.1948 |\n",
      "val: {'recall': 0.981595, 'recall_grapheme': 0.972087, 'recall_vowel': 0.990651, 'recall_consonant': 0.991555, 'acc_grapheme': 0.970342, 'acc_vowel': 0.991925, 'acc_consonant': 0.990978, 'loss_grapheme': 0.269324, 'loss_vowel': 0.224024, 'loss_consonant': 0.144363}\n",
      "   12 | 0.000015 | 131072/160716 | 0.4203 | 2.3229 |\n",
      "val: {'recall': 0.981886, 'recall_grapheme': 0.972618, 'recall_vowel': 0.990896, 'recall_consonant': 0.991412, 'acc_grapheme': 0.970915, 'acc_vowel': 0.992099, 'acc_consonant': 0.991352, 'loss_grapheme': 0.226271, 'loss_vowel': 0.16492, 'loss_consonant': 0.1095}\n",
      "   14 | 0.000008 | 016384/160716 | 3.5326 | 2.6417 |\n",
      "val: {'recall': 0.981985, 'recall_grapheme': 0.97312, 'recall_vowel': 0.990292, 'recall_consonant': 0.991408, 'acc_grapheme': 0.970766, 'acc_vowel': 0.991825, 'acc_consonant': 0.990903, 'loss_grapheme': 0.275284, 'loss_vowel': 0.228095, 'loss_consonant': 0.14938}\n",
      "   15 | 0.000003 | 061440/160716 | 2.6380 | 2.1335 |\n",
      "val: {'recall': 0.981977, 'recall_grapheme': 0.973104, 'recall_vowel': 0.990496, 'recall_consonant': 0.991204, 'acc_grapheme': 0.970641, 'acc_vowel': 0.99195, 'acc_consonant': 0.991177, 'loss_grapheme': 0.21942, 'loss_vowel': 0.170366, 'loss_consonant': 0.113454}\n",
      "   16 | 0.000001 | 106496/160716 | 1.5074 | 2.4104 |\n",
      "val: {'recall': 0.981676, 'recall_grapheme': 0.972412, 'recall_vowel': 0.990392, 'recall_consonant': 0.991489, 'acc_grapheme': 0.970167, 'acc_vowel': 0.991751, 'acc_consonant': 0.990804, 'loss_grapheme': 0.268184, 'loss_vowel': 0.217376, 'loss_consonant': 0.141783}\n",
      "   17 | 0.000003 | 151552/160716 | 4.7628 | 2.3833 |\n",
      "val: {'recall': 0.982034, 'recall_grapheme': 0.972996, 'recall_vowel': 0.990887, 'recall_consonant': 0.991256, 'acc_grapheme': 0.970741, 'acc_vowel': 0.991925, 'acc_consonant': 0.990629, 'loss_grapheme': 0.277349, 'loss_vowel': 0.226291, 'loss_consonant': 0.147743}\n",
      "   19 | 0.000008 | 036864/160716 | 3.1696 | 2.1936 |\n",
      "val: {'recall': 0.982058, 'recall_grapheme': 0.97315, 'recall_vowel': 0.990546, 'recall_consonant': 0.991384, 'acc_grapheme': 0.970292, 'acc_vowel': 0.991751, 'acc_consonant': 0.991028, 'loss_grapheme': 0.253245, 'loss_vowel': 0.206851, 'loss_consonant': 0.132995}\n",
      "** saved\n",
      "   20 | 0.000015 | 081920/160716 | 3.8465 | 2.3144 |\n",
      "val: {'recall': 0.982224, 'recall_grapheme': 0.973145, 'recall_vowel': 0.991075, 'recall_consonant': 0.99153, 'acc_grapheme': 0.970616, 'acc_vowel': 0.9919, 'acc_consonant': 0.990878, 'loss_grapheme': 0.302079, 'loss_vowel': 0.238868, 'loss_consonant': 0.15328}\n",
      "** saved\n",
      "   21 | 0.000026 | 126976/160716 | 4.0681 | 2.5073 |\n",
      "val: {'recall': 0.982051, 'recall_grapheme': 0.97309, 'recall_vowel': 0.990171, 'recall_consonant': 0.991851, 'acc_grapheme': 0.970467, 'acc_vowel': 0.991277, 'acc_consonant': 0.990779, 'loss_grapheme': 0.398213, 'loss_vowel': 0.33138, 'loss_consonant': 0.210232}\n",
      "   23 | 0.000038 | 012288/160716 | 3.2900 | 2.4103 |\n",
      "val: {'recall': 0.982026, 'recall_grapheme': 0.973018, 'recall_vowel': 0.990334, 'recall_consonant': 0.991732, 'acc_grapheme': 0.970417, 'acc_vowel': 0.9918, 'acc_consonant': 0.991053, 'loss_grapheme': 0.259553, 'loss_vowel': 0.219171, 'loss_consonant': 0.152586}\n",
      "   24 | 0.000050 | 057344/160716 | 0.4780 | 2.3192 |\n",
      "val: {'recall': 0.981801, 'recall_grapheme': 0.972723, 'recall_vowel': 0.990785, 'recall_consonant': 0.990975, 'acc_grapheme': 0.970417, 'acc_vowel': 0.9918, 'acc_consonant': 0.990853, 'loss_grapheme': 0.246327, 'loss_vowel': 0.19284, 'loss_consonant': 0.124452}\n",
      "   25 | 0.000063 | 102400/160716 | 1.9144 | 2.3071 |\n",
      "val: {'recall': 0.98147, 'recall_grapheme': 0.971668, 'recall_vowel': 0.990614, 'recall_consonant': 0.991931, 'acc_grapheme': 0.969943, 'acc_vowel': 0.991875, 'acc_consonant': 0.990828, 'loss_grapheme': 0.252599, 'loss_vowel': 0.202746, 'loss_consonant': 0.135843}\n",
      "   26 | 0.000075 | 147456/160716 | 1.5195 | 2.2779 |\n",
      "val: {'recall': 0.982358, 'recall_grapheme': 0.973812, 'recall_vowel': 0.990692, 'recall_consonant': 0.991115, 'acc_grapheme': 0.970666, 'acc_vowel': 0.991825, 'acc_consonant': 0.990828, 'loss_grapheme': 0.250641, 'loss_vowel': 0.2141, 'loss_consonant': 0.136447}\n",
      "** saved\n",
      "   28 | 0.000086 | 032768/160716 | 2.0422 | 2.3417 |\n",
      "val: {'recall': 0.981587, 'recall_grapheme': 0.972385, 'recall_vowel': 0.990706, 'recall_consonant': 0.990871, 'acc_grapheme': 0.970317, 'acc_vowel': 0.991775, 'acc_consonant': 0.990604, 'loss_grapheme': 0.249569, 'loss_vowel': 0.217491, 'loss_consonant': 0.132675}\n",
      "   29 | 0.000093 | 077824/160716 | 2.8622 | 2.1992 |\n",
      "val: {'recall': 0.981617, 'recall_grapheme': 0.972943, 'recall_vowel': 0.990942, 'recall_consonant': 0.989637, 'acc_grapheme': 0.970292, 'acc_vowel': 0.991825, 'acc_consonant': 0.990903, 'loss_grapheme': 0.264295, 'loss_vowel': 0.213201, 'loss_consonant': 0.132381}\n",
      "   30 | 0.000098 | 122880/160716 | 1.8970 | 2.2496 |\n",
      "val: {'recall': 0.981991, 'recall_grapheme': 0.973183, 'recall_vowel': 0.990405, 'recall_consonant': 0.991195, 'acc_grapheme': 0.97099, 'acc_vowel': 0.991775, 'acc_consonant': 0.990878, 'loss_grapheme': 0.216718, 'loss_vowel': 0.167487, 'loss_consonant': 0.117717}\n",
      "   32 | 0.000100 | 008192/160716 | 4.3630 | 2.5258 |\n",
      "val: {'recall': 0.98188, 'recall_grapheme': 0.9725, 'recall_vowel': 0.990667, 'recall_consonant': 0.991853, 'acc_grapheme': 0.971065, 'acc_vowel': 0.991676, 'acc_consonant': 0.990779, 'loss_grapheme': 0.267012, 'loss_vowel': 0.235293, 'loss_consonant': 0.15463}\n",
      "   33 | 0.000098 | 053248/160716 | 3.1658 | 2.1958 |\n",
      "val: {'recall': 0.981571, 'recall_grapheme': 0.972836, 'recall_vowel': 0.990613, 'recall_consonant': 0.99, 'acc_grapheme': 0.97094, 'acc_vowel': 0.9919, 'acc_consonant': 0.991252, 'loss_grapheme': 0.226602, 'loss_vowel': 0.178518, 'loss_consonant': 0.117299}\n",
      "   34 | 0.000093 | 098304/160716 | 1.9462 | 2.3980 |\n",
      "val: {'recall': 0.981518, 'recall_grapheme': 0.972527, 'recall_vowel': 0.990801, 'recall_consonant': 0.990218, 'acc_grapheme': 0.970367, 'acc_vowel': 0.992075, 'acc_consonant': 0.990928, 'loss_grapheme': 0.272048, 'loss_vowel': 0.226826, 'loss_consonant': 0.155526}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000086 | 143360/160716 | 3.7445 | 2.4190 |\n",
      "val: {'recall': 0.982269, 'recall_grapheme': 0.973087, 'recall_vowel': 0.991534, 'recall_consonant': 0.991367, 'acc_grapheme': 0.97089, 'acc_vowel': 0.991975, 'acc_consonant': 0.990804, 'loss_grapheme': 0.267967, 'loss_vowel': 0.211621, 'loss_consonant': 0.140944}\n",
      "   37 | 0.000075 | 028672/160716 | 1.3459 | 2.0842 |\n",
      "val: {'recall': 0.981594, 'recall_grapheme': 0.97217, 'recall_vowel': 0.990823, 'recall_consonant': 0.991213, 'acc_grapheme': 0.971139, 'acc_vowel': 0.991925, 'acc_consonant': 0.990928, 'loss_grapheme': 0.229669, 'loss_vowel': 0.191334, 'loss_consonant': 0.118933}\n",
      "   38 | 0.000063 | 073728/160716 | 3.9173 | 2.2130 |\n",
      "val: {'recall': 0.982227, 'recall_grapheme': 0.973924, 'recall_vowel': 0.991364, 'recall_consonant': 0.989698, 'acc_grapheme': 0.971887, 'acc_vowel': 0.99195, 'acc_consonant': 0.991277, 'loss_grapheme': 0.202771, 'loss_vowel': 0.150984, 'loss_consonant': 0.106874}\n",
      "   39 | 0.000051 | 118784/160716 | 1.5995 | 2.3431 |\n",
      "val: {'recall': 0.982336, 'recall_grapheme': 0.973143, 'recall_vowel': 0.991091, 'recall_consonant': 0.991967, 'acc_grapheme': 0.971314, 'acc_vowel': 0.991975, 'acc_consonant': 0.991028, 'loss_grapheme': 0.290659, 'loss_vowel': 0.264846, 'loss_consonant': 0.16804}\n",
      "   41 | 0.000038 | 004096/160716 | 1.5580 | 2.1377 |\n",
      "val: {'recall': 0.982154, 'recall_grapheme': 0.973362, 'recall_vowel': 0.99123, 'recall_consonant': 0.990661, 'acc_grapheme': 0.971688, 'acc_vowel': 0.992099, 'acc_consonant': 0.991551, 'loss_grapheme': 0.24661, 'loss_vowel': 0.205119, 'loss_consonant': 0.136083}\n",
      "   42 | 0.000026 | 049152/160716 | 3.1550 | 2.1685 |\n",
      "val: {'recall': 0.982266, 'recall_grapheme': 0.973065, 'recall_vowel': 0.991174, 'recall_consonant': 0.991758, 'acc_grapheme': 0.971339, 'acc_vowel': 0.992025, 'acc_consonant': 0.991227, 'loss_grapheme': 0.263902, 'loss_vowel': 0.227051, 'loss_consonant': 0.143743}\n",
      "   43 | 0.000015 | 094208/160716 | 0.9974 | 2.3130 |\n",
      "val: {'recall': 0.981945, 'recall_grapheme': 0.973098, 'recall_vowel': 0.991136, 'recall_consonant': 0.990447, 'acc_grapheme': 0.971787, 'acc_vowel': 0.992324, 'acc_consonant': 0.991427, 'loss_grapheme': 0.210955, 'loss_vowel': 0.157258, 'loss_consonant': 0.112738}\n",
      "   44 | 0.000008 | 139264/160716 | 2.4744 | 2.3991 |\n",
      "val: {'recall': 0.982764, 'recall_grapheme': 0.974003, 'recall_vowel': 0.991218, 'recall_consonant': 0.99183, 'acc_grapheme': 0.971513, 'acc_vowel': 0.992099, 'acc_consonant': 0.991352, 'loss_grapheme': 0.250095, 'loss_vowel': 0.201656, 'loss_consonant': 0.132189}\n",
      "** saved\n",
      "   46 | 0.000003 | 024576/160716 | 1.0114 | 2.1066 |\n",
      "val: {'recall': 0.982292, 'recall_grapheme': 0.974164, 'recall_vowel': 0.990828, 'recall_consonant': 0.990014, 'acc_grapheme': 0.971937, 'acc_vowel': 0.992199, 'acc_consonant': 0.991551, 'loss_grapheme': 0.209316, 'loss_vowel': 0.167172, 'loss_consonant': 0.113096}\n",
      "   47 | 0.000001 | 069632/160716 | 2.4447 | 2.4658 |\n",
      "val: {'recall': 0.982494, 'recall_grapheme': 0.973491, 'recall_vowel': 0.991247, 'recall_consonant': 0.991749, 'acc_grapheme': 0.971289, 'acc_vowel': 0.992099, 'acc_consonant': 0.991202, 'loss_grapheme': 0.283312, 'loss_vowel': 0.242958, 'loss_consonant': 0.15274}\n",
      "   48 | 0.000003 | 114688/160716 | 0.5060 | 2.1560 |\n",
      "val: {'recall': 0.982622, 'recall_grapheme': 0.97357, 'recall_vowel': 0.991375, 'recall_consonant': 0.991973, 'acc_grapheme': 0.971538, 'acc_vowel': 0.992324, 'acc_consonant': 0.991526, 'loss_grapheme': 0.249757, 'loss_vowel': 0.200507, 'loss_consonant': 0.134646}\n",
      "   49 | 0.000008 | 159744/160716 | 2.4458 | 2.2636 |\n",
      "val: {'recall': 0.982428, 'recall_grapheme': 0.973407, 'recall_vowel': 0.991287, 'recall_consonant': 0.991614, 'acc_grapheme': 0.971513, 'acc_vowel': 0.992299, 'acc_consonant': 0.991377, 'loss_grapheme': 0.240854, 'loss_vowel': 0.196082, 'loss_consonant': 0.127966}\n",
      "   51 | 0.000015 | 045056/160716 | 2.7734 | 2.3212 |\n",
      "val: {'recall': 0.982665, 'recall_grapheme': 0.973919, 'recall_vowel': 0.990954, 'recall_consonant': 0.991869, 'acc_grapheme': 0.972186, 'acc_vowel': 0.992025, 'acc_consonant': 0.991252, 'loss_grapheme': 0.273168, 'loss_vowel': 0.214427, 'loss_consonant': 0.137201}\n",
      "   52 | 0.000026 | 090112/160716 | 4.3444 | 2.4556 |\n",
      "val: {'recall': 0.982893, 'recall_grapheme': 0.973833, 'recall_vowel': 0.992096, 'recall_consonant': 0.99181, 'acc_grapheme': 0.972361, 'acc_vowel': 0.992448, 'acc_consonant': 0.991576, 'loss_grapheme': 0.244082, 'loss_vowel': 0.206178, 'loss_consonant': 0.134924}\n",
      "** saved\n",
      "   53 | 0.000038 | 135168/160716 | 4.0755 | 2.1447 |\n",
      "val: {'recall': 0.982104, 'recall_grapheme': 0.972805, 'recall_vowel': 0.991084, 'recall_consonant': 0.991723, 'acc_grapheme': 0.971588, 'acc_vowel': 0.992224, 'acc_consonant': 0.991402, 'loss_grapheme': 0.225939, 'loss_vowel': 0.165367, 'loss_consonant': 0.109948}\n",
      "   55 | 0.000051 | 020480/160716 | 2.2326 | 2.6536 |\n",
      "val: {'recall': 0.981945, 'recall_grapheme': 0.97288, 'recall_vowel': 0.990176, 'recall_consonant': 0.991842, 'acc_grapheme': 0.971538, 'acc_vowel': 0.991975, 'acc_consonant': 0.991377, 'loss_grapheme': 0.258177, 'loss_vowel': 0.226726, 'loss_consonant': 0.15238}\n",
      "   56 | 0.000063 | 065536/160716 | 4.0307 | 2.2576 |\n",
      "val: {'recall': 0.982062, 'recall_grapheme': 0.972727, 'recall_vowel': 0.991018, 'recall_consonant': 0.991775, 'acc_grapheme': 0.971364, 'acc_vowel': 0.992274, 'acc_consonant': 0.990903, 'loss_grapheme': 0.279175, 'loss_vowel': 0.238517, 'loss_consonant': 0.153595}\n",
      "   57 | 0.000075 | 110592/160716 | 2.1848 | 2.3722 |\n",
      "val: {'recall': 0.981736, 'recall_grapheme': 0.971721, 'recall_vowel': 0.99116, 'recall_consonant': 0.99234, 'acc_grapheme': 0.971538, 'acc_vowel': 0.992025, 'acc_consonant': 0.991352, 'loss_grapheme': 0.277603, 'loss_vowel': 0.234962, 'loss_consonant': 0.153362}\n",
      "   58 | 0.000086 | 155648/160716 | 2.0459 | 2.2879 |\n",
      "val: {'recall': 0.982005, 'recall_grapheme': 0.973831, 'recall_vowel': 0.990521, 'recall_consonant': 0.989835, 'acc_grapheme': 0.971962, 'acc_vowel': 0.992075, 'acc_consonant': 0.991402, 'loss_grapheme': 0.222077, 'loss_vowel': 0.182609, 'loss_consonant': 0.117522}\n",
      "   60 | 0.000093 | 040960/160716 | 2.1439 | 2.2103 |\n",
      "val: {'recall': 0.981492, 'recall_grapheme': 0.972351, 'recall_vowel': 0.991093, 'recall_consonant': 0.990173, 'acc_grapheme': 0.971314, 'acc_vowel': 0.992099, 'acc_consonant': 0.991402, 'loss_grapheme': 0.215526, 'loss_vowel': 0.171527, 'loss_consonant': 0.113922}\n",
      "   61 | 0.000098 | 086016/160716 | 3.5313 | 2.3543 |\n",
      "val: {'recall': 0.982371, 'recall_grapheme': 0.973125, 'recall_vowel': 0.990946, 'recall_consonant': 0.992289, 'acc_grapheme': 0.971538, 'acc_vowel': 0.99205, 'acc_consonant': 0.991078, 'loss_grapheme': 0.267655, 'loss_vowel': 0.203047, 'loss_consonant': 0.143814}\n",
      "   62 | 0.000100 | 131072/160716 | 1.8926 | 2.2944 |\n",
      "val: {'recall': 0.982605, 'recall_grapheme': 0.973435, 'recall_vowel': 0.991581, 'recall_consonant': 0.991967, 'acc_grapheme': 0.97104, 'acc_vowel': 0.99205, 'acc_consonant': 0.990704, 'loss_grapheme': 0.235859, 'loss_vowel': 0.173839, 'loss_consonant': 0.122483}\n",
      "   64 | 0.000098 | 016384/160716 | 1.9283 | 2.5322 |\n",
      "val: {'recall': 0.982382, 'recall_grapheme': 0.973015, 'recall_vowel': 0.991614, 'recall_consonant': 0.991885, 'acc_grapheme': 0.971713, 'acc_vowel': 0.992299, 'acc_consonant': 0.991526, 'loss_grapheme': 0.275584, 'loss_vowel': 0.213517, 'loss_consonant': 0.15678}\n",
      "   65 | 0.000093 | 061440/160716 | 0.3844 | 2.5243 |\n",
      "val: {'recall': 0.981872, 'recall_grapheme': 0.973511, 'recall_vowel': 0.990491, 'recall_consonant': 0.989975, 'acc_grapheme': 0.971787, 'acc_vowel': 0.992025, 'acc_consonant': 0.991202, 'loss_grapheme': 0.193844, 'loss_vowel': 0.137742, 'loss_consonant': 0.093248}\n",
      "   66 | 0.000086 | 106496/160716 | 2.1974 | 2.3609 |\n",
      "val: {'recall': 0.982484, 'recall_grapheme': 0.973779, 'recall_vowel': 0.990721, 'recall_consonant': 0.991656, 'acc_grapheme': 0.971364, 'acc_vowel': 0.992174, 'acc_consonant': 0.991701, 'loss_grapheme': 0.271702, 'loss_vowel': 0.235936, 'loss_consonant': 0.152791}\n",
      "   67 | 0.000075 | 151552/160716 | 2.0941 | 2.1282 |\n",
      "val: {'recall': 0.982627, 'recall_grapheme': 0.973432, 'recall_vowel': 0.991375, 'recall_consonant': 0.992268, 'acc_grapheme': 0.971962, 'acc_vowel': 0.992099, 'acc_consonant': 0.991452, 'loss_grapheme': 0.240401, 'loss_vowel': 0.192305, 'loss_consonant': 0.126346}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 0.000063 | 036864/160716 | 1.8926 | 2.2307 |\n",
      "val: {'recall': 0.982292, 'recall_grapheme': 0.973259, 'recall_vowel': 0.99104, 'recall_consonant': 0.991608, 'acc_grapheme': 0.971787, 'acc_vowel': 0.992174, 'acc_consonant': 0.991626, 'loss_grapheme': 0.252507, 'loss_vowel': 0.218798, 'loss_consonant': 0.14343}\n",
      "   70 | 0.000051 | 081920/160716 | 0.4905 | 2.2728 |\n",
      "val: {'recall': 0.982305, 'recall_grapheme': 0.973266, 'recall_vowel': 0.990895, 'recall_consonant': 0.991793, 'acc_grapheme': 0.971563, 'acc_vowel': 0.992025, 'acc_consonant': 0.991551, 'loss_grapheme': 0.240639, 'loss_vowel': 0.185396, 'loss_consonant': 0.123161}\n",
      "   71 | 0.000038 | 126976/160716 | 2.5124 | 2.1383 |\n",
      "val: {'recall': 0.982659, 'recall_grapheme': 0.973958, 'recall_vowel': 0.991068, 'recall_consonant': 0.99165, 'acc_grapheme': 0.971763, 'acc_vowel': 0.992099, 'acc_consonant': 0.991501, 'loss_grapheme': 0.213855, 'loss_vowel': 0.163778, 'loss_consonant': 0.108874}\n",
      "   73 | 0.000026 | 012288/160716 | 1.6310 | 2.1148 |\n",
      "val: {'recall': 0.98217, 'recall_grapheme': 0.97287, 'recall_vowel': 0.991229, 'recall_consonant': 0.991709, 'acc_grapheme': 0.971738, 'acc_vowel': 0.992299, 'acc_consonant': 0.991726, 'loss_grapheme': 0.227271, 'loss_vowel': 0.18435, 'loss_consonant': 0.11957}\n",
      "   74 | 0.000015 | 057344/160716 | 1.8885 | 2.2189 |\n",
      "val: {'recall': 0.982411, 'recall_grapheme': 0.973303, 'recall_vowel': 0.991077, 'recall_consonant': 0.991961, 'acc_grapheme': 0.971987, 'acc_vowel': 0.991975, 'acc_consonant': 0.991452, 'loss_grapheme': 0.255293, 'loss_vowel': 0.216775, 'loss_consonant': 0.145557}\n",
      "   74 | 0.000008 | 122880/160716 | 0.9353 | 2.2234 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-813ae6dcb078>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbbx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbby2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbby1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
