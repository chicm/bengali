{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pdb\n",
    "\n",
    "class Grid(object):\n",
    "    def __init__(self, d1, d2, rotate = 1, ratio = 0.5, mode=0, prob=1.):\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "        self.rotate = rotate\n",
    "        self.ratio = ratio\n",
    "        self.mode=mode\n",
    "        self.st_prob = self.prob = prob\n",
    "\n",
    "    def set_prob(self, epoch, max_epoch):\n",
    "        self.prob = self.st_prob * min(1, epoch / max_epoch)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.prob:\n",
    "            return img\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "        hh = int(1.5*h)\n",
    "        ww = int(1.5*w)\n",
    "        d = np.random.randint(self.d1, self.d2)\n",
    "        #d = self.d\n",
    "        self.l = int(d*self.ratio+0.5)\n",
    "        mask = np.ones((hh, ww), np.float32)\n",
    "        st_h = np.random.randint(d)\n",
    "        st_w = np.random.randint(d)\n",
    "        for i in range(-1, hh//d+1):\n",
    "                s = d*i + st_h\n",
    "                t = s+self.l\n",
    "                s = max(min(s, hh), 0)\n",
    "                t = max(min(t, hh), 0)\n",
    "                mask[s:t,:] *= 0\n",
    "        for i in range(-1, ww//d+1):\n",
    "                s = d*i + st_w\n",
    "                t = s+self.l\n",
    "                s = max(min(s, ww), 0)\n",
    "                t = max(min(t, ww), 0)\n",
    "                mask[:,s:t] *= 0\n",
    "        r = np.random.randint(self.rotate)\n",
    "        mask = Image.fromarray(np.uint8(mask))\n",
    "        mask = mask.rotate(r)\n",
    "        mask = np.asarray(mask)\n",
    "        mask = mask[(hh-h)//2:(hh-h)//2+h, (ww-w)//2:(ww-w)//2+w]\n",
    "\n",
    "        mask = torch.from_numpy(mask).float().cuda()\n",
    "        if self.mode == 1:\n",
    "            mask = 1-mask\n",
    "\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask \n",
    "\n",
    "        return img\n",
    "\n",
    "class GridMask(nn.Module):\n",
    "    def __init__(self, d1, d2, rotate = 1, ratio = 0.6, mode=1, prob=1.):\n",
    "        super(GridMask, self).__init__()\n",
    "        self.rotate = rotate\n",
    "        self.ratio = ratio\n",
    "        self.mode = mode\n",
    "        self.st_prob = prob\n",
    "        self.grid = Grid(d1, d2, rotate, ratio, mode, prob)\n",
    "\n",
    "    def set_prob(self, epoch, max_epoch):\n",
    "        self.grid.set_prob(epoch, max_epoch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training:\n",
    "            return x\n",
    "        n,c,h,w = x.size()\n",
    "        y = []\n",
    "        for i in range(n):\n",
    "            y.append(self.grid(x[i]))\n",
    "        y = torch.cat(y).view(n,c,h,w)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        #if self.train_mode:\n",
    "        #    augs = get_train_augs()\n",
    "        #    img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHEM = False\n",
    "def ohem_loss(cls_pred, cls_target, rate=0.5):\n",
    "    batch_size = cls_pred.size(0) \n",
    "    ohem_cls_loss = F.cross_entropy(cls_pred, cls_target, reduction='none', ignore_index=-1)\n",
    "\n",
    "    sorted_ohem_loss, idx = torch.sort(ohem_cls_loss, descending=True)\n",
    "    keep_num = min(sorted_ohem_loss.size()[0], int(batch_size*rate) )\n",
    "    if keep_num < sorted_ohem_loss.size()[0]:\n",
    "        keep_idx_cuda = idx[:keep_num]\n",
    "        ohem_cls_loss = ohem_cls_loss[keep_idx_cuda]\n",
    "    cls_loss = ohem_cls_loss.sum() / keep_num\n",
    "    return cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    if OHEM:\n",
    "        loss0 = ohem_loss(outputs[0], y_true[:, 0])\n",
    "        loss1 = ohem_loss(outputs[1], y_true[:, 1])\n",
    "        loss2 = ohem_loss(outputs[2], y_true[:, 2])\n",
    "    else:\n",
    "        loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "        loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "        loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3102954855210832"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from over9000.lookahead import Lookahead\n",
    "def LookaheadSGD(params, alpha=0.5, k=6, *args, **kwargs):\n",
    "     sgd = optim.SGD(params, *args, **kwargs)\n",
    "     return Lookahead(sgd, alpha, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam([{'params': model.parameters(), 'initial_lr': args.lr }], lr=args.lr, weight_decay=1e-5)\n",
    "        #optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = LookaheadSGD(\n",
    "            [{'params': model.parameters(), 'initial_lr': args.lr }],\n",
    "            lr=args.lr, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        #lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, args.t_max, eta_min=args.min_lr, last_epoch=args.t_max)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "    \n",
    "    grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "\n",
    "        grid.set_prob(epoch, args.st_epochs)\n",
    "\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.3:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            elif r > 0.6: # grid mask\n",
    "                img = grid(img)\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, targets)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model3_se_resnext50_fold1_mixup_cutmix_224_gridmask.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 1e-4\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.5\n",
    "args.patience = 5\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 768\n",
    "args.val_batch_size = 1024\n",
    "args.st_epochs = 1\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160635, 5) (40205, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model3_se_resnext50_fold1_mixup_cutmix_224_gridmask.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model3_se_resnext50_fold1_mixup_cutmix_224_gridmask.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.996536, 'recall_grapheme': 0.995104, 'recall_vowel': 0.998147, 'recall_consonant': 0.997787, 'acc_grapheme': 0.994702, 'acc_vowel': 0.998085, 'acc_consonant': 0.998508, 'loss_grapheme': 0.026128, 'loss_vowel': 0.015355, 'loss_consonant': 0.010569}\n",
      "    0 | 0.000001 | 153600/160635 | 1.9604 | 0.9943 |\n",
      "val: {'recall': 0.995378, 'recall_grapheme': 0.993289, 'recall_vowel': 0.997177, 'recall_consonant': 0.997756, 'acc_grapheme': 0.993334, 'acc_vowel': 0.997388, 'acc_consonant': 0.998085, 'loss_grapheme': 0.050876, 'loss_vowel': 0.039911, 'loss_consonant': 0.027875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000003 | 146688/160635 | 2.8515 | 0.9768 |\n",
      "val: {'recall': 0.996071, 'recall_grapheme': 0.994393, 'recall_vowel': 0.997736, 'recall_consonant': 0.997763, 'acc_grapheme': 0.994155, 'acc_vowel': 0.997811, 'acc_consonant': 0.998159, 'loss_grapheme': 0.038061, 'loss_vowel': 0.029167, 'loss_consonant': 0.019082}\n",
      "    2 | 0.000008 | 139776/160635 | 0.0052 | 1.0124 |\n",
      "val: {'recall': 0.995672, 'recall_grapheme': 0.9939, 'recall_vowel': 0.997243, 'recall_consonant': 0.997645, 'acc_grapheme': 0.993633, 'acc_vowel': 0.997463, 'acc_consonant': 0.998135, 'loss_grapheme': 0.038652, 'loss_vowel': 0.028081, 'loss_consonant': 0.018674}\n",
      "    3 | 0.000015 | 132096/160635 | 2.0825 | 1.1681 |"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.994437, 'recall_grapheme': 0.99255, 'recall_vowel': 0.996113, 'recall_consonant': 0.996534, 'acc_grapheme': 0.991643, 'acc_vowel': 0.996543, 'acc_consonant': 0.997463, 'loss_grapheme': 0.042325, 'loss_vowel': 0.026621, 'loss_consonant': 0.019315}\n",
      "    0 | 0.000100 | 153600/160635 | 0.0068 | 1.2476 |\n",
      "val: {'recall': 0.991259, 'recall_grapheme': 0.987884, 'recall_vowel': 0.994509, 'recall_consonant': 0.994759, 'acc_grapheme': 0.987041, 'acc_vowel': 0.9952, 'acc_consonant': 0.99617, 'loss_grapheme': 0.083335, 'loss_vowel': 0.048971, 'loss_consonant': 0.035815}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000098 | 146688/160635 | 1.3256 | 1.2112 |\n",
      "val: {'recall': 0.989781, 'recall_grapheme': 0.986392, 'recall_vowel': 0.99313, 'recall_consonant': 0.99321, 'acc_grapheme': 0.985698, 'acc_vowel': 0.994254, 'acc_consonant': 0.9951, 'loss_grapheme': 0.152745, 'loss_vowel': 0.106245, 'loss_consonant': 0.070814}\n",
      "    2 | 0.000093 | 139776/160635 | 0.0615 | 1.3192 |\n",
      "val: {'recall': 0.991795, 'recall_grapheme': 0.988969, 'recall_vowel': 0.993523, 'recall_consonant': 0.995718, 'acc_grapheme': 0.988111, 'acc_vowel': 0.99515, 'acc_consonant': 0.995971, 'loss_grapheme': 0.088764, 'loss_vowel': 0.067296, 'loss_consonant': 0.049089}\n",
      "    3 | 0.000086 | 132864/160635 | 2.6673 | 1.2214 |\n",
      "val: {'recall': 0.992205, 'recall_grapheme': 0.989505, 'recall_vowel': 0.994963, 'recall_consonant': 0.994849, 'acc_grapheme': 0.988907, 'acc_vowel': 0.995274, 'acc_consonant': 0.996443, 'loss_grapheme': 0.070851, 'loss_vowel': 0.051897, 'loss_consonant': 0.035}\n",
      "    4 | 0.000075 | 125952/160635 | 1.3082 | 1.2637 |\n",
      "val: {'recall': 0.991728, 'recall_grapheme': 0.988524, 'recall_vowel': 0.995048, 'recall_consonant': 0.994814, 'acc_grapheme': 0.988658, 'acc_vowel': 0.995598, 'acc_consonant': 0.996543, 'loss_grapheme': 0.05872, 'loss_vowel': 0.039543, 'loss_consonant': 0.028322}\n",
      "    5 | 0.000063 | 119040/160635 | 1.5210 | 1.2263 |\n",
      "val: {'recall': 0.992626, 'recall_grapheme': 0.99096, 'recall_vowel': 0.995729, 'recall_consonant': 0.992857, 'acc_grapheme': 0.989753, 'acc_vowel': 0.99607, 'acc_consonant': 0.996468, 'loss_grapheme': 0.091758, 'loss_vowel': 0.078417, 'loss_consonant': 0.053342}\n",
      "    6 | 0.000051 | 112128/160635 | 0.0445 | 1.3561 |\n",
      "val: {'recall': 0.992832, 'recall_grapheme': 0.990142, 'recall_vowel': 0.996205, 'recall_consonant': 0.994839, 'acc_grapheme': 0.989728, 'acc_vowel': 0.996045, 'acc_consonant': 0.996667, 'loss_grapheme': 0.097958, 'loss_vowel': 0.085486, 'loss_consonant': 0.058401}\n",
      "    7 | 0.000038 | 105216/160635 | 0.0534 | 1.2076 |\n",
      "val: {'recall': 0.993043, 'recall_grapheme': 0.991214, 'recall_vowel': 0.99513, 'recall_consonant': 0.994615, 'acc_grapheme': 0.990399, 'acc_vowel': 0.99612, 'acc_consonant': 0.996841, 'loss_grapheme': 0.060823, 'loss_vowel': 0.047667, 'loss_consonant': 0.035223}\n",
      "    8 | 0.000026 | 098304/160635 | 0.6070 | 1.0716 |\n",
      "val: {'recall': 0.993429, 'recall_grapheme': 0.991427, 'recall_vowel': 0.995712, 'recall_consonant': 0.995149, 'acc_grapheme': 0.991295, 'acc_vowel': 0.996418, 'acc_consonant': 0.99699, 'loss_grapheme': 0.065558, 'loss_vowel': 0.053848, 'loss_consonant': 0.035994}\n",
      "    9 | 0.000015 | 091392/160635 | 1.5981 | 1.2707 |\n",
      "val: {'recall': 0.993246, 'recall_grapheme': 0.991265, 'recall_vowel': 0.995505, 'recall_consonant': 0.994949, 'acc_grapheme': 0.990374, 'acc_vowel': 0.995996, 'acc_consonant': 0.996841, 'loss_grapheme': 0.090383, 'loss_vowel': 0.08083, 'loss_consonant': 0.051765}\n",
      "   10 | 0.000008 | 084480/160635 | 1.5002 | 1.2411 |\n",
      "val: {'recall': 0.993604, 'recall_grapheme': 0.991753, 'recall_vowel': 0.995751, 'recall_consonant': 0.995158, 'acc_grapheme': 0.991195, 'acc_vowel': 0.996195, 'acc_consonant': 0.997165, 'loss_grapheme': 0.058462, 'loss_vowel': 0.049244, 'loss_consonant': 0.032985}\n",
      "   11 | 0.000003 | 077568/160635 | 1.3984 | 0.9558 |\n",
      "val: {'recall': 0.994198, 'recall_grapheme': 0.992442, 'recall_vowel': 0.996181, 'recall_consonant': 0.995727, 'acc_grapheme': 0.991941, 'acc_vowel': 0.996667, 'acc_consonant': 0.997463, 'loss_grapheme': 0.053089, 'loss_vowel': 0.042962, 'loss_consonant': 0.029649}\n",
      "   12 | 0.000001 | 070656/160635 | 0.0229 | 1.1481 |\n",
      "val: {'recall': 0.994033, 'recall_grapheme': 0.99217, 'recall_vowel': 0.996287, 'recall_consonant': 0.995506, 'acc_grapheme': 0.991867, 'acc_vowel': 0.996418, 'acc_consonant': 0.997314, 'loss_grapheme': 0.054974, 'loss_vowel': 0.040961, 'loss_consonant': 0.028041}\n",
      "   13 | 0.000003 | 063744/160635 | 0.5517 | 1.2323 |\n",
      "val: {'recall': 0.993073, 'recall_grapheme': 0.990564, 'recall_vowel': 0.995971, 'recall_consonant': 0.995193, 'acc_grapheme': 0.990349, 'acc_vowel': 0.996244, 'acc_consonant': 0.997015, 'loss_grapheme': 0.086617, 'loss_vowel': 0.075098, 'loss_consonant': 0.049731}\n",
      "   14 | 0.000008 | 056832/160635 | 0.6622 | 1.2405 |\n",
      "val: {'recall': 0.993948, 'recall_grapheme': 0.991576, 'recall_vowel': 0.996002, 'recall_consonant': 0.996636, 'acc_grapheme': 0.991444, 'acc_vowel': 0.996294, 'acc_consonant': 0.997115, 'loss_grapheme': 0.065549, 'loss_vowel': 0.052574, 'loss_consonant': 0.033458}\n",
      "   15 | 0.000015 | 049920/160635 | 2.1096 | 1.1451 |\n",
      "val: {'recall': 0.992447, 'recall_grapheme': 0.989983, 'recall_vowel': 0.995483, 'recall_consonant': 0.994338, 'acc_grapheme': 0.990374, 'acc_vowel': 0.99602, 'acc_consonant': 0.996543, 'loss_grapheme': 0.083723, 'loss_vowel': 0.051954, 'loss_consonant': 0.039272}\n",
      "   16 | 0.000026 | 043008/160635 | 1.8827 | 1.0251 |\n",
      "val: {'recall': 0.993129, 'recall_grapheme': 0.990749, 'recall_vowel': 0.995681, 'recall_consonant': 0.995338, 'acc_grapheme': 0.990698, 'acc_vowel': 0.995846, 'acc_consonant': 0.996841, 'loss_grapheme': 0.081744, 'loss_vowel': 0.065711, 'loss_consonant': 0.044812}\n",
      "   17 | 0.000038 | 036096/160635 | 2.2645 | 0.9896 |\n",
      "val: {'recall': 0.993095, 'recall_grapheme': 0.990846, 'recall_vowel': 0.995673, 'recall_consonant': 0.995015, 'acc_grapheme': 0.990474, 'acc_vowel': 0.99602, 'acc_consonant': 0.996941, 'loss_grapheme': 0.061338, 'loss_vowel': 0.049799, 'loss_consonant': 0.035502}\n",
      "   18 | 0.000050 | 029184/160635 | 0.0393 | 1.1795 |\n",
      "val: {'recall': 0.992009, 'recall_grapheme': 0.989426, 'recall_vowel': 0.994491, 'recall_consonant': 0.994694, 'acc_grapheme': 0.988782, 'acc_vowel': 0.995523, 'acc_consonant': 0.996617, 'loss_grapheme': 0.055457, 'loss_vowel': 0.0391, 'loss_consonant': 0.026265}\n",
      "   19 | 0.000063 | 022272/160635 | 0.0300 | 1.0718 |\n",
      "val: {'recall': 0.993246, 'recall_grapheme': 0.990703, 'recall_vowel': 0.99575, 'recall_consonant': 0.995829, 'acc_grapheme': 0.9903, 'acc_vowel': 0.996269, 'acc_consonant': 0.996791, 'loss_grapheme': 0.056364, 'loss_vowel': 0.03548, 'loss_consonant': 0.025267}\n",
      "   20 | 0.000075 | 015360/160635 | 1.6740 | 1.1965 |\n",
      "val: {'recall': 0.992282, 'recall_grapheme': 0.989958, 'recall_vowel': 0.994228, 'recall_consonant': 0.994985, 'acc_grapheme': 0.988683, 'acc_vowel': 0.995175, 'acc_consonant': 0.995821, 'loss_grapheme': 0.08161, 'loss_vowel': 0.057464, 'loss_consonant': 0.044902}\n",
      "   21 | 0.000086 | 008448/160635 | 1.8967 | 1.4416 |\n",
      "val: {'recall': 0.990396, 'recall_grapheme': 0.987022, 'recall_vowel': 0.992893, 'recall_consonant': 0.994645, 'acc_grapheme': 0.98724, 'acc_vowel': 0.994677, 'acc_consonant': 0.995946, 'loss_grapheme': 0.093468, 'loss_vowel': 0.073726, 'loss_consonant': 0.048632}\n",
      "   22 | 0.000093 | 001536/160635 | 2.7760 | 2.5783 |\n",
      "val: {'recall': 0.992808, 'recall_grapheme': 0.990089, 'recall_vowel': 0.995502, 'recall_consonant': 0.995553, 'acc_grapheme': 0.988608, 'acc_vowel': 0.995647, 'acc_consonant': 0.996493, 'loss_grapheme': 0.126447, 'loss_vowel': 0.096081, 'loss_consonant': 0.059872}\n",
      "   22 | 0.000098 | 155136/160635 | 1.6945 | 1.3678 |\n",
      "val: {'recall': 0.988951, 'recall_grapheme': 0.986489, 'recall_vowel': 0.994606, 'recall_consonant': 0.988222, 'acc_grapheme': 0.984952, 'acc_vowel': 0.994503, 'acc_consonant': 0.994951, 'loss_grapheme': 0.12917, 'loss_vowel': 0.097073, 'loss_consonant': 0.066945}\n",
      "   23 | 0.000100 | 148224/160635 | 0.0659 | 1.2634 |\n",
      "val: {'recall': 0.992148, 'recall_grapheme': 0.988935, 'recall_vowel': 0.994388, 'recall_consonant': 0.996333, 'acc_grapheme': 0.988409, 'acc_vowel': 0.995175, 'acc_consonant': 0.996294, 'loss_grapheme': 0.095137, 'loss_vowel': 0.076366, 'loss_consonant': 0.053043}\n",
      "   24 | 0.000098 | 141312/160635 | 2.7818 | 1.2247 |\n",
      "val: {'recall': 0.992376, 'recall_grapheme': 0.99015, 'recall_vowel': 0.995286, 'recall_consonant': 0.99392, 'acc_grapheme': 0.988807, 'acc_vowel': 0.995846, 'acc_consonant': 0.996145, 'loss_grapheme': 0.069274, 'loss_vowel': 0.051436, 'loss_consonant': 0.038202}\n",
      "   25 | 0.000093 | 134400/160635 | 3.1449 | 1.3193 |\n",
      "val: {'recall': 0.99147, 'recall_grapheme': 0.988107, 'recall_vowel': 0.995035, 'recall_consonant': 0.994631, 'acc_grapheme': 0.987688, 'acc_vowel': 0.995498, 'acc_consonant': 0.995622, 'loss_grapheme': 0.125463, 'loss_vowel': 0.11421, 'loss_consonant': 0.073337}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 0.000086 | 127488/160635 | 3.3113 | 1.2203 |\n",
      "val: {'recall': 0.99167, 'recall_grapheme': 0.988377, 'recall_vowel': 0.994638, 'recall_consonant': 0.995286, 'acc_grapheme': 0.98821, 'acc_vowel': 0.995299, 'acc_consonant': 0.996244, 'loss_grapheme': 0.110479, 'loss_vowel': 0.095256, 'loss_consonant': 0.063847}\n",
      "   27 | 0.000075 | 120576/160635 | 0.0295 | 1.3093 |\n",
      "val: {'recall': 0.992301, 'recall_grapheme': 0.990159, 'recall_vowel': 0.995186, 'recall_consonant': 0.993699, 'acc_grapheme': 0.989529, 'acc_vowel': 0.995722, 'acc_consonant': 0.996717, 'loss_grapheme': 0.082857, 'loss_vowel': 0.072849, 'loss_consonant': 0.043882}\n",
      "   28 | 0.000063 | 113664/160635 | 1.9727 | 1.0804 |\n",
      "val: {'recall': 0.993166, 'recall_grapheme': 0.991169, 'recall_vowel': 0.994707, 'recall_consonant': 0.995617, 'acc_grapheme': 0.990847, 'acc_vowel': 0.995896, 'acc_consonant': 0.996468, 'loss_grapheme': 0.064883, 'loss_vowel': 0.049599, 'loss_consonant': 0.032962}\n",
      "   29 | 0.000051 | 106752/160635 | 1.6526 | 1.1816 |\n",
      "val: {'recall': 0.992119, 'recall_grapheme': 0.988884, 'recall_vowel': 0.995343, 'recall_consonant': 0.995367, 'acc_grapheme': 0.988235, 'acc_vowel': 0.995772, 'acc_consonant': 0.996244, 'loss_grapheme': 0.125211, 'loss_vowel': 0.111452, 'loss_consonant': 0.069936}\n",
      "   30 | 0.000038 | 099840/160635 | 1.4054 | 1.1702 |\n",
      "val: {'recall': 0.994278, 'recall_grapheme': 0.992223, 'recall_vowel': 0.996411, 'recall_consonant': 0.996257, 'acc_grapheme': 0.991394, 'acc_vowel': 0.996393, 'acc_consonant': 0.99704, 'loss_grapheme': 0.052597, 'loss_vowel': 0.040977, 'loss_consonant': 0.028216}\n",
      "   31 | 0.000026 | 092928/160635 | 1.9747 | 1.1238 |\n",
      "val: {'recall': 0.993897, 'recall_grapheme': 0.991581, 'recall_vowel': 0.996051, 'recall_consonant': 0.996376, 'acc_grapheme': 0.990897, 'acc_vowel': 0.996393, 'acc_consonant': 0.997314, 'loss_grapheme': 0.055537, 'loss_vowel': 0.045714, 'loss_consonant': 0.030828}\n",
      "   32 | 0.000015 | 086016/160635 | 0.4423 | 1.0838 |\n",
      "val: {'recall': 0.994285, 'recall_grapheme': 0.992005, 'recall_vowel': 0.996337, 'recall_consonant': 0.996794, 'acc_grapheme': 0.991966, 'acc_vowel': 0.996592, 'acc_consonant': 0.997413, 'loss_grapheme': 0.051484, 'loss_vowel': 0.042663, 'loss_consonant': 0.028649}\n",
      "   33 | 0.000008 | 079104/160635 | 1.6249 | 1.0806 |\n",
      "val: {'recall': 0.994458, 'recall_grapheme': 0.9923, 'recall_vowel': 0.996475, 'recall_consonant': 0.996756, 'acc_grapheme': 0.991792, 'acc_vowel': 0.996767, 'acc_consonant': 0.997413, 'loss_grapheme': 0.053901, 'loss_vowel': 0.043848, 'loss_consonant': 0.029409}\n",
      "** saved\n",
      "   34 | 0.000003 | 072192/160635 | 0.0126 | 1.1382 |\n",
      "val: {'recall': 0.993993, 'recall_grapheme': 0.991574, 'recall_vowel': 0.996174, 'recall_consonant': 0.996651, 'acc_grapheme': 0.991394, 'acc_vowel': 0.996418, 'acc_consonant': 0.997264, 'loss_grapheme': 0.055889, 'loss_vowel': 0.046702, 'loss_consonant': 0.031344}\n",
      "   35 | 0.000001 | 065280/160635 | 0.0294 | 1.0712 |\n",
      "val: {'recall': 0.994045, 'recall_grapheme': 0.991719, 'recall_vowel': 0.996127, 'recall_consonant': 0.996614, 'acc_grapheme': 0.991444, 'acc_vowel': 0.996418, 'acc_consonant': 0.997364, 'loss_grapheme': 0.057703, 'loss_vowel': 0.0487, 'loss_consonant': 0.032665}\n",
      "   36 | 0.000003 | 058368/160635 | 0.0109 | 1.2432 |\n",
      "val: {'recall': 0.994093, 'recall_grapheme': 0.991812, 'recall_vowel': 0.996015, 'recall_consonant': 0.996735, 'acc_grapheme': 0.991444, 'acc_vowel': 0.996369, 'acc_consonant': 0.997488, 'loss_grapheme': 0.058111, 'loss_vowel': 0.050509, 'loss_consonant': 0.034664}\n",
      "   37 | 0.000008 | 051456/160635 | 0.0231 | 1.2362 |\n",
      "val: {'recall': 0.994538, 'recall_grapheme': 0.992358, 'recall_vowel': 0.996445, 'recall_consonant': 0.996989, 'acc_grapheme': 0.992265, 'acc_vowel': 0.996767, 'acc_consonant': 0.997612, 'loss_grapheme': 0.045624, 'loss_vowel': 0.035368, 'loss_consonant': 0.024398}\n",
      "** saved\n",
      "   38 | 0.000015 | 044544/160635 | 0.0177 | 1.0118 |\n",
      "val: {'recall': 0.994761, 'recall_grapheme': 0.993057, 'recall_vowel': 0.996237, 'recall_consonant': 0.996692, 'acc_grapheme': 0.992439, 'acc_vowel': 0.996791, 'acc_consonant': 0.997687, 'loss_grapheme': 0.037217, 'loss_vowel': 0.023611, 'loss_consonant': 0.016376}\n",
      "** saved\n",
      "   39 | 0.000026 | 037632/160635 | 0.0121 | 0.8888 |\n",
      "val: {'recall': 0.994514, 'recall_grapheme': 0.992833, 'recall_vowel': 0.996564, 'recall_consonant': 0.995825, 'acc_grapheme': 0.992613, 'acc_vowel': 0.996742, 'acc_consonant': 0.997737, 'loss_grapheme': 0.038316, 'loss_vowel': 0.024725, 'loss_consonant': 0.017012}\n",
      "   40 | 0.000038 | 030720/160635 | 0.4988 | 1.2890 |\n",
      "val: {'recall': 0.99356, 'recall_grapheme': 0.99175, 'recall_vowel': 0.996344, 'recall_consonant': 0.994396, 'acc_grapheme': 0.991369, 'acc_vowel': 0.996617, 'acc_consonant': 0.997339, 'loss_grapheme': 0.059482, 'loss_vowel': 0.044178, 'loss_consonant': 0.03066}\n",
      "   41 | 0.000050 | 023808/160635 | 1.0883 | 0.7851 |\n",
      "val: {'recall': 0.994365, 'recall_grapheme': 0.992335, 'recall_vowel': 0.996555, 'recall_consonant': 0.996235, 'acc_grapheme': 0.991892, 'acc_vowel': 0.996518, 'acc_consonant': 0.99699, 'loss_grapheme': 0.050907, 'loss_vowel': 0.037863, 'loss_consonant': 0.024213}\n",
      "   42 | 0.000063 | 016896/160635 | 1.1601 | 1.1543 |\n",
      "val: {'recall': 0.993357, 'recall_grapheme': 0.990986, 'recall_vowel': 0.995784, 'recall_consonant': 0.995675, 'acc_grapheme': 0.990026, 'acc_vowel': 0.996393, 'acc_consonant': 0.996742, 'loss_grapheme': 0.053623, 'loss_vowel': 0.043402, 'loss_consonant': 0.027096}\n",
      "   43 | 0.000075 | 009984/160635 | 0.0332 | 0.6263 |\n",
      "val: {'recall': 0.993497, 'recall_grapheme': 0.992111, 'recall_vowel': 0.996315, 'recall_consonant': 0.993451, 'acc_grapheme': 0.991494, 'acc_vowel': 0.996369, 'acc_consonant': 0.996916, 'loss_grapheme': 0.040268, 'loss_vowel': 0.02439, 'loss_consonant': 0.017841}\n",
      "   44 | 0.000086 | 003072/160635 | 0.0339 | 0.8693 |\n",
      "val: {'recall': 0.993703, 'recall_grapheme': 0.991591, 'recall_vowel': 0.995904, 'recall_consonant': 0.995724, 'acc_grapheme': 0.99117, 'acc_vowel': 0.995871, 'acc_consonant': 0.996642, 'loss_grapheme': 0.071041, 'loss_vowel': 0.054862, 'loss_consonant': 0.037985}\n",
      "   44 | 0.000093 | 156672/160635 | 1.6309 | 1.1228 |\n",
      "val: {'recall': 0.993281, 'recall_grapheme': 0.991056, 'recall_vowel': 0.995854, 'recall_consonant': 0.99516, 'acc_grapheme': 0.990374, 'acc_vowel': 0.996095, 'acc_consonant': 0.996866, 'loss_grapheme': 0.064965, 'loss_vowel': 0.050243, 'loss_consonant': 0.033569}\n",
      "   45 | 0.000098 | 149760/160635 | 2.9374 | 1.2501 |\n",
      "val: {'recall': 0.993042, 'recall_grapheme': 0.990819, 'recall_vowel': 0.995961, 'recall_consonant': 0.994568, 'acc_grapheme': 0.989205, 'acc_vowel': 0.996269, 'acc_consonant': 0.996294, 'loss_grapheme': 0.082654, 'loss_vowel': 0.068815, 'loss_consonant': 0.040936}\n",
      "   46 | 0.000100 | 142848/160635 | 0.7410 | 1.3102 |\n",
      "val: {'recall': 0.992836, 'recall_grapheme': 0.990545, 'recall_vowel': 0.99564, 'recall_consonant': 0.994614, 'acc_grapheme': 0.989056, 'acc_vowel': 0.996045, 'acc_consonant': 0.996393, 'loss_grapheme': 0.086077, 'loss_vowel': 0.068101, 'loss_consonant': 0.044025}\n",
      "   47 | 0.000098 | 135936/160635 | 0.0497 | 1.1878 |\n",
      "val: {'recall': 0.993554, 'recall_grapheme': 0.991784, 'recall_vowel': 0.995162, 'recall_consonant': 0.995487, 'acc_grapheme': 0.991071, 'acc_vowel': 0.996045, 'acc_consonant': 0.996518, 'loss_grapheme': 0.051251, 'loss_vowel': 0.036859, 'loss_consonant': 0.025162}\n",
      "   48 | 0.000093 | 129024/160635 | 0.0210 | 1.2736 |\n",
      "val: {'recall': 0.993588, 'recall_grapheme': 0.991338, 'recall_vowel': 0.995835, 'recall_consonant': 0.995841, 'acc_grapheme': 0.991618, 'acc_vowel': 0.996393, 'acc_consonant': 0.997115, 'loss_grapheme': 0.045248, 'loss_vowel': 0.031922, 'loss_consonant': 0.021066}\n",
      "   49 | 0.000086 | 122112/160635 | 1.9753 | 1.2661 |\n",
      "val: {'recall': 0.992064, 'recall_grapheme': 0.989306, 'recall_vowel': 0.994443, 'recall_consonant': 0.995199, 'acc_grapheme': 0.988882, 'acc_vowel': 0.995299, 'acc_consonant': 0.99617, 'loss_grapheme': 0.085716, 'loss_vowel': 0.077947, 'loss_consonant': 0.049331}\n",
      "   50 | 0.000075 | 115200/160635 | 0.8144 | 1.0442 |\n",
      "val: {'recall': 0.99395, 'recall_grapheme': 0.991679, 'recall_vowel': 0.996386, 'recall_consonant': 0.996057, 'acc_grapheme': 0.990698, 'acc_vowel': 0.996767, 'acc_consonant': 0.996891, 'loss_grapheme': 0.064899, 'loss_vowel': 0.047491, 'loss_consonant': 0.033288}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 0.000063 | 108288/160635 | 2.0852 | 1.2369 |\n",
      "val: {'recall': 0.993453, 'recall_grapheme': 0.991519, 'recall_vowel': 0.995962, 'recall_consonant': 0.994811, 'acc_grapheme': 0.99117, 'acc_vowel': 0.996592, 'acc_consonant': 0.996941, 'loss_grapheme': 0.07984, 'loss_vowel': 0.068836, 'loss_consonant': 0.047099}\n",
      "   52 | 0.000051 | 101376/160635 | 2.4363 | 1.1049 |\n",
      "val: {'recall': 0.994352, 'recall_grapheme': 0.99271, 'recall_vowel': 0.996683, 'recall_consonant': 0.995305, 'acc_grapheme': 0.992066, 'acc_vowel': 0.996667, 'acc_consonant': 0.997214, 'loss_grapheme': 0.060999, 'loss_vowel': 0.049249, 'loss_consonant': 0.035083}\n",
      "   53 | 0.000038 | 094464/160635 | 1.6521 | 1.1654 |\n",
      "val: {'recall': 0.994866, 'recall_grapheme': 0.993003, 'recall_vowel': 0.996593, 'recall_consonant': 0.996867, 'acc_grapheme': 0.992488, 'acc_vowel': 0.996941, 'acc_consonant': 0.997687, 'loss_grapheme': 0.061912, 'loss_vowel': 0.050704, 'loss_consonant': 0.034829}\n",
      "** saved\n",
      "   54 | 0.000026 | 087552/160635 | 0.0084 | 1.1589 |\n",
      "val: {'recall': 0.994763, 'recall_grapheme': 0.99273, 'recall_vowel': 0.996978, 'recall_consonant': 0.996612, 'acc_grapheme': 0.992464, 'acc_vowel': 0.996966, 'acc_consonant': 0.997562, 'loss_grapheme': 0.063121, 'loss_vowel': 0.055072, 'loss_consonant': 0.037713}\n",
      "   55 | 0.000015 | 080640/160635 | 1.5387 | 1.0634 |\n",
      "val: {'recall': 0.995056, 'recall_grapheme': 0.99338, 'recall_vowel': 0.996751, 'recall_consonant': 0.996712, 'acc_grapheme': 0.992638, 'acc_vowel': 0.997065, 'acc_consonant': 0.997562, 'loss_grapheme': 0.066923, 'loss_vowel': 0.058976, 'loss_consonant': 0.039486}\n",
      "** saved\n",
      "   56 | 0.000008 | 073728/160635 | 2.4139 | 1.0256 |\n",
      "val: {'recall': 0.995026, 'recall_grapheme': 0.993294, 'recall_vowel': 0.996737, 'recall_consonant': 0.996779, 'acc_grapheme': 0.992538, 'acc_vowel': 0.99709, 'acc_consonant': 0.997538, 'loss_grapheme': 0.062485, 'loss_vowel': 0.057088, 'loss_consonant': 0.038746}\n",
      "   57 | 0.000003 | 066816/160635 | 2.7184 | 1.1148 |\n",
      "val: {'recall': 0.994541, 'recall_grapheme': 0.992681, 'recall_vowel': 0.996269, 'recall_consonant': 0.996535, 'acc_grapheme': 0.991991, 'acc_vowel': 0.996841, 'acc_consonant': 0.997314, 'loss_grapheme': 0.083336, 'loss_vowel': 0.078921, 'loss_consonant': 0.052608}\n",
      "   58 | 0.000001 | 059904/160635 | 2.1792 | 0.8964 |\n",
      "val: {'recall': 0.995216, 'recall_grapheme': 0.993618, 'recall_vowel': 0.996981, 'recall_consonant': 0.996648, 'acc_grapheme': 0.993011, 'acc_vowel': 0.997388, 'acc_consonant': 0.997637, 'loss_grapheme': 0.048537, 'loss_vowel': 0.038664, 'loss_consonant': 0.026902}\n",
      "** saved\n",
      "   59 | 0.000003 | 052992/160635 | 0.0071 | 1.3404 |\n",
      "val: {'recall': 0.994881, 'recall_grapheme': 0.993171, 'recall_vowel': 0.996782, 'recall_consonant': 0.9964, 'acc_grapheme': 0.992439, 'acc_vowel': 0.997165, 'acc_consonant': 0.997488, 'loss_grapheme': 0.085461, 'loss_vowel': 0.07446, 'loss_consonant': 0.050499}\n",
      "   60 | 0.000008 | 046080/160635 | 2.8618 | 1.2241 |\n",
      "val: {'recall': 0.994582, 'recall_grapheme': 0.992535, 'recall_vowel': 0.99653, 'recall_consonant': 0.996729, 'acc_grapheme': 0.991892, 'acc_vowel': 0.996941, 'acc_consonant': 0.997438, 'loss_grapheme': 0.092981, 'loss_vowel': 0.088157, 'loss_consonant': 0.058211}\n",
      "   61 | 0.000015 | 039168/160635 | 0.0180 | 0.9303 |\n",
      "val: {'recall': 0.995546, 'recall_grapheme': 0.993919, 'recall_vowel': 0.996941, 'recall_consonant': 0.997407, 'acc_grapheme': 0.993508, 'acc_vowel': 0.997364, 'acc_consonant': 0.998085, 'loss_grapheme': 0.040208, 'loss_vowel': 0.030571, 'loss_consonant': 0.020819}\n",
      "** saved\n",
      "   62 | 0.000026 | 032256/160635 | 0.0106 | 0.9048 |\n",
      "val: {'recall': 0.995341, 'recall_grapheme': 0.993648, 'recall_vowel': 0.997102, 'recall_consonant': 0.996966, 'acc_grapheme': 0.993135, 'acc_vowel': 0.997413, 'acc_consonant': 0.997836, 'loss_grapheme': 0.034546, 'loss_vowel': 0.020429, 'loss_consonant': 0.015201}\n",
      "   63 | 0.000038 | 025344/160635 | 0.0223 | 1.3570 |\n",
      "val: {'recall': 0.993295, 'recall_grapheme': 0.990955, 'recall_vowel': 0.995426, 'recall_consonant': 0.995842, 'acc_grapheme': 0.990225, 'acc_vowel': 0.996195, 'acc_consonant': 0.997239, 'loss_grapheme': 0.110516, 'loss_vowel': 0.103682, 'loss_consonant': 0.067049}\n",
      "   64 | 0.000051 | 018432/160635 | 0.0336 | 1.3042 |\n",
      "val: {'recall': 0.994264, 'recall_grapheme': 0.992309, 'recall_vowel': 0.995747, 'recall_consonant': 0.996692, 'acc_grapheme': 0.991444, 'acc_vowel': 0.996592, 'acc_consonant': 0.997165, 'loss_grapheme': 0.060026, 'loss_vowel': 0.046777, 'loss_consonant': 0.033152}\n",
      "   65 | 0.000063 | 011520/160635 | 2.5307 | 1.6700 |\n",
      "val: {'recall': 0.992572, 'recall_grapheme': 0.990032, 'recall_vowel': 0.994748, 'recall_consonant': 0.995475, 'acc_grapheme': 0.98923, 'acc_vowel': 0.99607, 'acc_consonant': 0.996692, 'loss_grapheme': 0.113017, 'loss_vowel': 0.089166, 'loss_consonant': 0.060757}\n",
      "   66 | 0.000075 | 004608/160635 | 0.0276 | 0.9811 |\n",
      "val: {'recall': 0.993132, 'recall_grapheme': 0.991069, 'recall_vowel': 0.996179, 'recall_consonant': 0.99421, 'acc_grapheme': 0.991021, 'acc_vowel': 0.996692, 'acc_consonant': 0.996841, 'loss_grapheme': 0.053282, 'loss_vowel': 0.043611, 'loss_consonant': 0.031057}\n",
      "   66 | 0.000086 | 158208/160635 | 0.7121 | 1.1864 |\n",
      "val: {'recall': 0.991698, 'recall_grapheme': 0.989289, 'recall_vowel': 0.995216, 'recall_consonant': 0.992998, 'acc_grapheme': 0.987066, 'acc_vowel': 0.9952, 'acc_consonant': 0.995772, 'loss_grapheme': 0.07665, 'loss_vowel': 0.049802, 'loss_consonant': 0.033882}\n",
      "   67 | 0.000093 | 151296/160635 | 0.0498 | 1.1775 |\n",
      "val: {'recall': 0.993354, 'recall_grapheme': 0.991008, 'recall_vowel': 0.995703, 'recall_consonant': 0.995698, 'acc_grapheme': 0.990325, 'acc_vowel': 0.99612, 'acc_consonant': 0.996518, 'loss_grapheme': 0.058381, 'loss_vowel': 0.046401, 'loss_consonant': 0.0299}\n",
      "   68 | 0.000098 | 144384/160635 | 1.4618 | 1.1904 |\n",
      "val: {'recall': 0.993273, 'recall_grapheme': 0.990549, 'recall_vowel': 0.995677, 'recall_consonant': 0.996319, 'acc_grapheme': 0.990126, 'acc_vowel': 0.99617, 'acc_consonant': 0.997189, 'loss_grapheme': 0.079717, 'loss_vowel': 0.051452, 'loss_consonant': 0.038678}\n",
      "   69 | 0.000100 | 137472/160635 | 3.8094 | 1.2388 |\n",
      "val: {'recall': 0.993831, 'recall_grapheme': 0.992159, 'recall_vowel': 0.996824, 'recall_consonant': 0.99418, 'acc_grapheme': 0.990548, 'acc_vowel': 0.996692, 'acc_consonant': 0.996617, 'loss_grapheme': 0.056822, 'loss_vowel': 0.038569, 'loss_consonant': 0.028232}\n",
      "   70 | 0.000098 | 130560/160635 | 0.0328 | 1.0802 |\n",
      "val: {'recall': 0.993522, 'recall_grapheme': 0.99116, 'recall_vowel': 0.996027, 'recall_consonant': 0.995743, 'acc_grapheme': 0.990872, 'acc_vowel': 0.99602, 'acc_consonant': 0.996767, 'loss_grapheme': 0.040226, 'loss_vowel': 0.024069, 'loss_consonant': 0.016999}\n",
      "   71 | 0.000093 | 123648/160635 | 1.7575 | 1.0899 |\n",
      "val: {'recall': 0.992884, 'recall_grapheme': 0.99118, 'recall_vowel': 0.995024, 'recall_consonant': 0.994153, 'acc_grapheme': 0.990698, 'acc_vowel': 0.995598, 'acc_consonant': 0.996568, 'loss_grapheme': 0.063813, 'loss_vowel': 0.048938, 'loss_consonant': 0.034035}\n",
      "   72 | 0.000086 | 116736/160635 | 0.0327 | 1.2741 |\n",
      "val: {'recall': 0.993278, 'recall_grapheme': 0.991262, 'recall_vowel': 0.995758, 'recall_consonant': 0.994832, 'acc_grapheme': 0.990374, 'acc_vowel': 0.996195, 'acc_consonant': 0.996717, 'loss_grapheme': 0.069276, 'loss_vowel': 0.049888, 'loss_consonant': 0.036623}\n",
      "   73 | 0.000075 | 109824/160635 | 0.0243 | 1.1296 |\n",
      "val: {'recall': 0.994927, 'recall_grapheme': 0.993045, 'recall_vowel': 0.996754, 'recall_consonant': 0.996865, 'acc_grapheme': 0.992737, 'acc_vowel': 0.997115, 'acc_consonant': 0.997861, 'loss_grapheme': 0.035589, 'loss_vowel': 0.023665, 'loss_consonant': 0.015453}\n",
      "   74 | 0.000063 | 102912/160635 | 1.9321 | 1.3510 |\n",
      "val: {'recall': 0.994176, 'recall_grapheme': 0.992454, 'recall_vowel': 0.996015, 'recall_consonant': 0.995782, 'acc_grapheme': 0.991593, 'acc_vowel': 0.996592, 'acc_consonant': 0.997413, 'loss_grapheme': 0.061175, 'loss_vowel': 0.050374, 'loss_consonant': 0.034132}\n",
      "   75 | 0.000051 | 096000/160635 | 0.0203 | 1.1863 |\n",
      "val: {'recall': 0.994736, 'recall_grapheme': 0.993156, 'recall_vowel': 0.996642, 'recall_consonant': 0.99599, 'acc_grapheme': 0.991543, 'acc_vowel': 0.996966, 'acc_consonant': 0.997364, 'loss_grapheme': 0.06668, 'loss_vowel': 0.059071, 'loss_consonant': 0.037586}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76 | 0.000038 | 089088/160635 | 0.8051 | 1.0865 |\n",
      "val: {'recall': 0.994123, 'recall_grapheme': 0.992238, 'recall_vowel': 0.995519, 'recall_consonant': 0.996495, 'acc_grapheme': 0.991419, 'acc_vowel': 0.996468, 'acc_consonant': 0.997289, 'loss_grapheme': 0.084627, 'loss_vowel': 0.076334, 'loss_consonant': 0.050077}\n",
      "   77 | 0.000026 | 082176/160635 | 1.9400 | 1.0239 |\n",
      "val: {'recall': 0.994848, 'recall_grapheme': 0.993567, 'recall_vowel': 0.996704, 'recall_consonant': 0.995556, 'acc_grapheme': 0.993135, 'acc_vowel': 0.997189, 'acc_consonant': 0.997438, 'loss_grapheme': 0.040753, 'loss_vowel': 0.029628, 'loss_consonant': 0.020642}\n",
      "   78 | 0.000015 | 075264/160635 | 0.0087 | 1.1218 |\n",
      "val: {'recall': 0.994816, 'recall_grapheme': 0.992987, 'recall_vowel': 0.996701, 'recall_consonant': 0.996589, 'acc_grapheme': 0.992812, 'acc_vowel': 0.997214, 'acc_consonant': 0.997513, 'loss_grapheme': 0.052885, 'loss_vowel': 0.043829, 'loss_consonant': 0.029879}\n",
      "   79 | 0.000008 | 068352/160635 | 0.0042 | 0.9088 |\n",
      "val: {'recall': 0.995225, 'recall_grapheme': 0.993811, 'recall_vowel': 0.996646, 'recall_consonant': 0.996631, 'acc_grapheme': 0.993434, 'acc_vowel': 0.997314, 'acc_consonant': 0.997662, 'loss_grapheme': 0.056859, 'loss_vowel': 0.047862, 'loss_consonant': 0.032312}\n",
      "   80 | 0.000003 | 061440/160635 | 0.0063 | 1.1063 |\n",
      "val: {'recall': 0.995512, 'recall_grapheme': 0.994108, 'recall_vowel': 0.997041, 'recall_consonant': 0.99679, 'acc_grapheme': 0.993633, 'acc_vowel': 0.997438, 'acc_consonant': 0.997861, 'loss_grapheme': 0.040401, 'loss_vowel': 0.031022, 'loss_consonant': 0.021436}\n",
      "   81 | 0.000001 | 054528/160635 | 2.3348 | 1.0749 |\n",
      "val: {'recall': 0.994545, 'recall_grapheme': 0.992726, 'recall_vowel': 0.996146, 'recall_consonant': 0.996581, 'acc_grapheme': 0.992265, 'acc_vowel': 0.99704, 'acc_consonant': 0.997687, 'loss_grapheme': 0.075849, 'loss_vowel': 0.074668, 'loss_consonant': 0.049308}\n",
      "   82 | 0.000003 | 047616/160635 | 0.0186 | 1.3135 |\n",
      "val: {'recall': 0.994594, 'recall_grapheme': 0.992649, 'recall_vowel': 0.996728, 'recall_consonant': 0.996349, 'acc_grapheme': 0.992414, 'acc_vowel': 0.996941, 'acc_consonant': 0.997339, 'loss_grapheme': 0.084685, 'loss_vowel': 0.076581, 'loss_consonant': 0.052465}\n",
      "   83 | 0.000008 | 040704/160635 | 2.0227 | 1.1588 |\n",
      "val: {'recall': 0.994482, 'recall_grapheme': 0.992448, 'recall_vowel': 0.99655, 'recall_consonant': 0.996482, 'acc_grapheme': 0.99229, 'acc_vowel': 0.99704, 'acc_consonant': 0.997637, 'loss_grapheme': 0.050101, 'loss_vowel': 0.043527, 'loss_consonant': 0.029127}\n",
      "   84 | 0.000015 | 033792/160635 | 1.6211 | 1.4997 |\n",
      "val: {'recall': 0.994638, 'recall_grapheme': 0.992639, 'recall_vowel': 0.996671, 'recall_consonant': 0.996603, 'acc_grapheme': 0.99229, 'acc_vowel': 0.99704, 'acc_consonant': 0.997513, 'loss_grapheme': 0.067572, 'loss_vowel': 0.060933, 'loss_consonant': 0.040419}\n",
      "   85 | 0.000026 | 026880/160635 | 1.6119 | 1.1883 |\n",
      "val: {'recall': 0.994868, 'recall_grapheme': 0.993136, 'recall_vowel': 0.996757, 'recall_consonant': 0.996446, 'acc_grapheme': 0.992687, 'acc_vowel': 0.997239, 'acc_consonant': 0.997438, 'loss_grapheme': 0.052657, 'loss_vowel': 0.041974, 'loss_consonant': 0.029964}\n",
      "   86 | 0.000038 | 019968/160635 | 0.0152 | 1.0858 |\n",
      "val: {'recall': 0.994847, 'recall_grapheme': 0.992657, 'recall_vowel': 0.996602, 'recall_consonant': 0.99747, 'acc_grapheme': 0.992613, 'acc_vowel': 0.997015, 'acc_consonant': 0.997712, 'loss_grapheme': 0.046256, 'loss_vowel': 0.036953, 'loss_consonant': 0.025917}\n",
      "   87 | 0.000051 | 013056/160635 | 1.8009 | 1.1018 |\n",
      "val: {'recall': 0.993843, 'recall_grapheme': 0.992072, 'recall_vowel': 0.995707, 'recall_consonant': 0.995521, 'acc_grapheme': 0.991867, 'acc_vowel': 0.996518, 'acc_consonant': 0.997339, 'loss_grapheme': 0.053019, 'loss_vowel': 0.038882, 'loss_consonant': 0.026792}\n",
      "   88 | 0.000063 | 006144/160635 | 1.2133 | 1.2267 |\n",
      "val: {'recall': 0.993831, 'recall_grapheme': 0.99174, 'recall_vowel': 0.995771, 'recall_consonant': 0.996074, 'acc_grapheme': 0.990847, 'acc_vowel': 0.996717, 'acc_consonant': 0.997438, 'loss_grapheme': 0.074259, 'loss_vowel': 0.062883, 'loss_consonant': 0.043485}\n",
      "   88 | 0.000075 | 159744/160635 | 3.1076 | 1.2822 |\n",
      "val: {'recall': 0.993343, 'recall_grapheme': 0.991341, 'recall_vowel': 0.995812, 'recall_consonant': 0.994876, 'acc_grapheme': 0.989976, 'acc_vowel': 0.996493, 'acc_consonant': 0.997388, 'loss_grapheme': 0.067648, 'loss_vowel': 0.054837, 'loss_consonant': 0.03641}\n",
      "   89 | 0.000086 | 152832/160635 | 1.1139 | 1.0940 |\n",
      "val: {'recall': 0.993441, 'recall_grapheme': 0.991825, 'recall_vowel': 0.995238, 'recall_consonant': 0.994877, 'acc_grapheme': 0.990922, 'acc_vowel': 0.996269, 'acc_consonant': 0.99714, 'loss_grapheme': 0.064271, 'loss_vowel': 0.046198, 'loss_consonant': 0.033703}\n",
      "   90 | 0.000093 | 145920/160635 | 1.5581 | 1.1784 |\n",
      "val: {'recall': 0.994002, 'recall_grapheme': 0.991771, 'recall_vowel': 0.99688, 'recall_consonant': 0.995584, 'acc_grapheme': 0.99117, 'acc_vowel': 0.996791, 'acc_consonant': 0.996816, 'loss_grapheme': 0.046142, 'loss_vowel': 0.027678, 'loss_consonant': 0.021006}\n",
      "   91 | 0.000098 | 139008/160635 | 0.0215 | 1.1712 |\n",
      "val: {'recall': 0.993266, 'recall_grapheme': 0.991194, 'recall_vowel': 0.99518, 'recall_consonant': 0.995498, 'acc_grapheme': 0.990474, 'acc_vowel': 0.99617, 'acc_consonant': 0.996468, 'loss_grapheme': 0.064016, 'loss_vowel': 0.044448, 'loss_consonant': 0.031065}\n",
      "   92 | 0.000100 | 132096/160635 | 1.7721 | 1.0942 |\n",
      "val: {'recall': 0.992193, 'recall_grapheme': 0.989238, 'recall_vowel': 0.995188, 'recall_consonant': 0.995109, 'acc_grapheme': 0.989081, 'acc_vowel': 0.996145, 'acc_consonant': 0.996518, 'loss_grapheme': 0.081454, 'loss_vowel': 0.061372, 'loss_consonant': 0.041541}\n",
      "   93 | 0.000098 | 125184/160635 | 2.7542 | 1.1878 |\n",
      "val: {'recall': 0.994206, 'recall_grapheme': 0.991908, 'recall_vowel': 0.996107, 'recall_consonant': 0.996903, 'acc_grapheme': 0.991643, 'acc_vowel': 0.996866, 'acc_consonant': 0.997836, 'loss_grapheme': 0.051875, 'loss_vowel': 0.034188, 'loss_consonant': 0.024972}\n",
      "   94 | 0.000093 | 118272/160635 | 0.0063 | 1.0676 |\n",
      "val: {'recall': 0.993959, 'recall_grapheme': 0.991854, 'recall_vowel': 0.995462, 'recall_consonant': 0.996664, 'acc_grapheme': 0.991319, 'acc_vowel': 0.996592, 'acc_consonant': 0.997364, 'loss_grapheme': 0.0831, 'loss_vowel': 0.070225, 'loss_consonant': 0.048819}\n",
      "   95 | 0.000086 | 111360/160635 | 0.0156 | 1.0947 |\n",
      "val: {'recall': 0.994365, 'recall_grapheme': 0.991873, 'recall_vowel': 0.996377, 'recall_consonant': 0.997336, 'acc_grapheme': 0.991543, 'acc_vowel': 0.99699, 'acc_consonant': 0.997314, 'loss_grapheme': 0.055729, 'loss_vowel': 0.04286, 'loss_consonant': 0.031211}\n",
      "   96 | 0.000075 | 104448/160635 | 2.1404 | 1.2414 |\n",
      "val: {'recall': 0.995142, 'recall_grapheme': 0.993272, 'recall_vowel': 0.997061, 'recall_consonant': 0.996964, 'acc_grapheme': 0.992389, 'acc_vowel': 0.996966, 'acc_consonant': 0.997761, 'loss_grapheme': 0.039619, 'loss_vowel': 0.026711, 'loss_consonant': 0.018018}\n",
      "   97 | 0.000063 | 097536/160635 | 1.5954 | 1.1935 |\n",
      "val: {'recall': 0.993847, 'recall_grapheme': 0.991671, 'recall_vowel': 0.995402, 'recall_consonant': 0.996644, 'acc_grapheme': 0.99127, 'acc_vowel': 0.996518, 'acc_consonant': 0.997015, 'loss_grapheme': 0.056169, 'loss_vowel': 0.041838, 'loss_consonant': 0.027396}\n",
      "   98 | 0.000051 | 090624/160635 | 0.0087 | 1.0925 |\n",
      "val: {'recall': 0.994817, 'recall_grapheme': 0.992966, 'recall_vowel': 0.996705, 'recall_consonant': 0.996629, 'acc_grapheme': 0.992513, 'acc_vowel': 0.997413, 'acc_consonant': 0.997786, 'loss_grapheme': 0.038922, 'loss_vowel': 0.026298, 'loss_consonant': 0.018954}\n",
      "   99 | 0.000038 | 083712/160635 | 2.5548 | 0.9808 |\n",
      "val: {'recall': 0.995216, 'recall_grapheme': 0.99325, 'recall_vowel': 0.996867, 'recall_consonant': 0.997496, 'acc_grapheme': 0.992538, 'acc_vowel': 0.997388, 'acc_consonant': 0.997786, 'loss_grapheme': 0.040752, 'loss_vowel': 0.027386, 'loss_consonant': 0.019231}\n",
      "  100 | 0.000026 | 076800/160635 | 3.4788 | 0.9861 |\n",
      "val: {'recall': 0.994089, 'recall_grapheme': 0.992252, 'recall_vowel': 0.996106, 'recall_consonant': 0.995747, 'acc_grapheme': 0.992115, 'acc_vowel': 0.997015, 'acc_consonant': 0.997662, 'loss_grapheme': 0.042762, 'loss_vowel': 0.03423, 'loss_consonant': 0.023373}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 | 0.000015 | 069888/160635 | 1.8625 | 1.1612 |\n",
      "val: {'recall': 0.994579, 'recall_grapheme': 0.992837, 'recall_vowel': 0.996571, 'recall_consonant': 0.996073, 'acc_grapheme': 0.99224, 'acc_vowel': 0.997214, 'acc_consonant': 0.997463, 'loss_grapheme': 0.06383, 'loss_vowel': 0.056826, 'loss_consonant': 0.038237}\n",
      "  102 | 0.000008 | 062976/160635 | 0.7255 | 1.2493 |\n",
      "val: {'recall': 0.994936, 'recall_grapheme': 0.993274, 'recall_vowel': 0.996968, 'recall_consonant': 0.996228, 'acc_grapheme': 0.992787, 'acc_vowel': 0.997488, 'acc_consonant': 0.997786, 'loss_grapheme': 0.04378, 'loss_vowel': 0.036432, 'loss_consonant': 0.024064}\n",
      "  103 | 0.000003 | 056064/160635 | 2.5527 | 1.1420 |\n",
      "val: {'recall': 0.994483, 'recall_grapheme': 0.992412, 'recall_vowel': 0.996446, 'recall_consonant': 0.996661, 'acc_grapheme': 0.991916, 'acc_vowel': 0.997289, 'acc_consonant': 0.997712, 'loss_grapheme': 0.056261, 'loss_vowel': 0.053454, 'loss_consonant': 0.035324}\n",
      "  104 | 0.000001 | 049152/160635 | 0.0052 | 1.0292 |\n",
      "val: {'recall': 0.995182, 'recall_grapheme': 0.993628, 'recall_vowel': 0.997094, 'recall_consonant': 0.99638, 'acc_grapheme': 0.993309, 'acc_vowel': 0.997687, 'acc_consonant': 0.99796, 'loss_grapheme': 0.040377, 'loss_vowel': 0.031525, 'loss_consonant': 0.021386}\n",
      "  105 | 0.000003 | 042240/160635 | 3.0925 | 1.3016 |\n",
      "val: {'recall': 0.994346, 'recall_grapheme': 0.992391, 'recall_vowel': 0.996309, 'recall_consonant': 0.996293, 'acc_grapheme': 0.991916, 'acc_vowel': 0.99714, 'acc_consonant': 0.997662, 'loss_grapheme': 0.099222, 'loss_vowel': 0.09677, 'loss_consonant': 0.061926}\n",
      "  106 | 0.000008 | 035328/160635 | 0.8079 | 1.0731 |\n",
      "val: {'recall': 0.994926, 'recall_grapheme': 0.992923, 'recall_vowel': 0.99705, 'recall_consonant': 0.996807, 'acc_grapheme': 0.992439, 'acc_vowel': 0.997538, 'acc_consonant': 0.997737, 'loss_grapheme': 0.066185, 'loss_vowel': 0.05842, 'loss_consonant': 0.037272}\n",
      "  107 | 0.000015 | 028416/160635 | 0.6606 | 1.1191 |\n",
      "val: {'recall': 0.99534, 'recall_grapheme': 0.993553, 'recall_vowel': 0.997304, 'recall_consonant': 0.996948, 'acc_grapheme': 0.993434, 'acc_vowel': 0.997637, 'acc_consonant': 0.997811, 'loss_grapheme': 0.04347, 'loss_vowel': 0.034463, 'loss_consonant': 0.023371}\n",
      "  108 | 0.000026 | 021504/160635 | 1.8790 | 1.0868 |\n",
      "val: {'recall': 0.995132, 'recall_grapheme': 0.993198, 'recall_vowel': 0.997165, 'recall_consonant': 0.996969, 'acc_grapheme': 0.992513, 'acc_vowel': 0.997513, 'acc_consonant': 0.997687, 'loss_grapheme': 0.054682, 'loss_vowel': 0.044806, 'loss_consonant': 0.030684}\n",
      "  109 | 0.000038 | 014592/160635 | 1.6466 | 1.2406 |\n",
      "val: {'recall': 0.993633, 'recall_grapheme': 0.990928, 'recall_vowel': 0.996074, 'recall_consonant': 0.996602, 'acc_grapheme': 0.990424, 'acc_vowel': 0.996692, 'acc_consonant': 0.997065, 'loss_grapheme': 0.07427, 'loss_vowel': 0.063317, 'loss_consonant': 0.040386}\n",
      "  110 | 0.000050 | 007680/160635 | 1.7004 | 1.4969 |\n",
      "val: {'recall': 0.993909, 'recall_grapheme': 0.991866, 'recall_vowel': 0.995636, 'recall_consonant': 0.996266, 'acc_grapheme': 0.991618, 'acc_vowel': 0.996592, 'acc_consonant': 0.997488, 'loss_grapheme': 0.084101, 'loss_vowel': 0.066802, 'loss_consonant': 0.045521}\n",
      "  111 | 0.000063 | 000768/160635 | 0.0109 | 0.0109 |\n",
      "val: {'recall': 0.994325, 'recall_grapheme': 0.992153, 'recall_vowel': 0.996219, 'recall_consonant': 0.996778, 'acc_grapheme': 0.992115, 'acc_vowel': 0.996791, 'acc_consonant': 0.997463, 'loss_grapheme': 0.067591, 'loss_vowel': 0.057164, 'loss_consonant': 0.038083}\n",
      "  111 | 0.000075 | 154368/160635 | 2.3392 | 1.3634 |\n",
      "val: {'recall': 0.99304, 'recall_grapheme': 0.990449, 'recall_vowel': 0.996688, 'recall_consonant': 0.994572, 'acc_grapheme': 0.990847, 'acc_vowel': 0.996916, 'acc_consonant': 0.997165, 'loss_grapheme': 0.049267, 'loss_vowel': 0.035415, 'loss_consonant': 0.023823}\n",
      "  112 | 0.000086 | 147456/160635 | 0.0247 | 1.1370 |\n",
      "val: {'recall': 0.994821, 'recall_grapheme': 0.992762, 'recall_vowel': 0.997284, 'recall_consonant': 0.996477, 'acc_grapheme': 0.992513, 'acc_vowel': 0.996966, 'acc_consonant': 0.997488, 'loss_grapheme': 0.034287, 'loss_vowel': 0.018747, 'loss_consonant': 0.014139}\n",
      "  113 | 0.000093 | 140544/160635 | 2.5351 | 1.1716 |\n",
      "val: {'recall': 0.994166, 'recall_grapheme': 0.991812, 'recall_vowel': 0.996372, 'recall_consonant': 0.996668, 'acc_grapheme': 0.990747, 'acc_vowel': 0.996568, 'acc_consonant': 0.996767, 'loss_grapheme': 0.084994, 'loss_vowel': 0.080098, 'loss_consonant': 0.057242}\n",
      "  114 | 0.000098 | 133632/160635 | 0.0104 | 1.0272 |\n",
      "val: {'recall': 0.994647, 'recall_grapheme': 0.99259, 'recall_vowel': 0.996427, 'recall_consonant': 0.99698, 'acc_grapheme': 0.991344, 'acc_vowel': 0.996543, 'acc_consonant': 0.997289, 'loss_grapheme': 0.043693, 'loss_vowel': 0.029575, 'loss_consonant': 0.01906}\n",
      "  115 | 0.000100 | 126720/160635 | 0.0215 | 1.2030 |\n",
      "val: {'recall': 0.993158, 'recall_grapheme': 0.990694, 'recall_vowel': 0.995835, 'recall_consonant': 0.995408, 'acc_grapheme': 0.990474, 'acc_vowel': 0.996393, 'acc_consonant': 0.997264, 'loss_grapheme': 0.060351, 'loss_vowel': 0.049057, 'loss_consonant': 0.032463}\n",
      "  116 | 0.000098 | 119808/160635 | 2.0496 | 1.0623 |\n",
      "val: {'recall': 0.995644, 'recall_grapheme': 0.993635, 'recall_vowel': 0.997188, 'recall_consonant': 0.998119, 'acc_grapheme': 0.99316, 'acc_vowel': 0.997214, 'acc_consonant': 0.998085, 'loss_grapheme': 0.044553, 'loss_vowel': 0.029013, 'loss_consonant': 0.021}\n",
      "** saved\n",
      "  117 | 0.000093 | 112896/160635 | 2.2657 | 1.0979 |\n",
      "val: {'recall': 0.992892, 'recall_grapheme': 0.990301, 'recall_vowel': 0.994925, 'recall_consonant': 0.996041, 'acc_grapheme': 0.988633, 'acc_vowel': 0.995622, 'acc_consonant': 0.996841, 'loss_grapheme': 0.122407, 'loss_vowel': 0.115744, 'loss_consonant': 0.070192}\n",
      "  118 | 0.000086 | 105984/160635 | 0.0451 | 1.2417 |\n",
      "val: {'recall': 0.993325, 'recall_grapheme': 0.991234, 'recall_vowel': 0.996329, 'recall_consonant': 0.994503, 'acc_grapheme': 0.9903, 'acc_vowel': 0.996617, 'acc_consonant': 0.99699, 'loss_grapheme': 0.091813, 'loss_vowel': 0.078911, 'loss_consonant': 0.05282}\n",
      "  119 | 0.000075 | 099072/160635 | 0.0221 | 1.0543 |\n",
      "val: {'recall': 0.995403, 'recall_grapheme': 0.993458, 'recall_vowel': 0.997819, 'recall_consonant': 0.99688, 'acc_grapheme': 0.993135, 'acc_vowel': 0.997637, 'acc_consonant': 0.997612, 'loss_grapheme': 0.031273, 'loss_vowel': 0.016252, 'loss_consonant': 0.01244}\n",
      "  120 | 0.000063 | 092160/160635 | 1.8639 | 1.2664 |\n",
      "val: {'recall': 0.993358, 'recall_grapheme': 0.990524, 'recall_vowel': 0.995957, 'recall_consonant': 0.996428, 'acc_grapheme': 0.990349, 'acc_vowel': 0.996145, 'acc_consonant': 0.997388, 'loss_grapheme': 0.071024, 'loss_vowel': 0.059745, 'loss_consonant': 0.036634}\n",
      "  121 | 0.000050 | 085248/160635 | 1.4206 | 1.0255 |\n",
      "val: {'recall': 0.99514, 'recall_grapheme': 0.993359, 'recall_vowel': 0.9969, 'recall_consonant': 0.996942, 'acc_grapheme': 0.992936, 'acc_vowel': 0.997314, 'acc_consonant': 0.997811, 'loss_grapheme': 0.041828, 'loss_vowel': 0.030615, 'loss_consonant': 0.020754}\n",
      "  122 | 0.000038 | 078336/160635 | 0.0114 | 1.1855 |\n",
      "val: {'recall': 0.995072, 'recall_grapheme': 0.993024, 'recall_vowel': 0.99695, 'recall_consonant': 0.997292, 'acc_grapheme': 0.992538, 'acc_vowel': 0.997264, 'acc_consonant': 0.99796, 'loss_grapheme': 0.039433, 'loss_vowel': 0.030535, 'loss_consonant': 0.020541}\n",
      "  123 | 0.000026 | 071424/160635 | 0.0086 | 1.1420 |\n",
      "val: {'recall': 0.995301, 'recall_grapheme': 0.993155, 'recall_vowel': 0.996868, 'recall_consonant': 0.998026, 'acc_grapheme': 0.99316, 'acc_vowel': 0.997289, 'acc_consonant': 0.998135, 'loss_grapheme': 0.039948, 'loss_vowel': 0.030393, 'loss_consonant': 0.020497}\n",
      "  124 | 0.000015 | 064512/160635 | 1.2242 | 1.0561 |\n",
      "val: {'recall': 0.996053, 'recall_grapheme': 0.994356, 'recall_vowel': 0.997474, 'recall_consonant': 0.998029, 'acc_grapheme': 0.993856, 'acc_vowel': 0.997687, 'acc_consonant': 0.998234, 'loss_grapheme': 0.035944, 'loss_vowel': 0.023426, 'loss_consonant': 0.015951}\n",
      "** saved\n",
      "  125 | 0.000008 | 057600/160635 | 0.7661 | 1.3124 |\n",
      "val: {'recall': 0.99499, 'recall_grapheme': 0.993069, 'recall_vowel': 0.996523, 'recall_consonant': 0.997301, 'acc_grapheme': 0.992613, 'acc_vowel': 0.99699, 'acc_consonant': 0.997911, 'loss_grapheme': 0.076472, 'loss_vowel': 0.06984, 'loss_consonant': 0.045276}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  126 | 0.000003 | 050688/160635 | 0.0189 | 0.8395 |\n",
      "val: {'recall': 0.996327, 'recall_grapheme': 0.994808, 'recall_vowel': 0.997596, 'recall_consonant': 0.998096, 'acc_grapheme': 0.994628, 'acc_vowel': 0.997886, 'acc_consonant': 0.998383, 'loss_grapheme': 0.025142, 'loss_vowel': 0.013603, 'loss_consonant': 0.009033}\n",
      "** saved\n",
      "  127 | 0.000001 | 043776/160635 | 2.9822 | 1.1725 |\n",
      "val: {'recall': 0.995387, 'recall_grapheme': 0.993219, 'recall_vowel': 0.996952, 'recall_consonant': 0.998159, 'acc_grapheme': 0.992886, 'acc_vowel': 0.997388, 'acc_consonant': 0.998135, 'loss_grapheme': 0.04732, 'loss_vowel': 0.039326, 'loss_consonant': 0.025731}\n",
      "  128 | 0.000003 | 036864/160635 | 0.0053 | 1.0314 |\n",
      "val: {'recall': 0.99531, 'recall_grapheme': 0.993278, 'recall_vowel': 0.996695, 'recall_consonant': 0.99799, 'acc_grapheme': 0.992961, 'acc_vowel': 0.997388, 'acc_consonant': 0.998159, 'loss_grapheme': 0.03769, 'loss_vowel': 0.02793, 'loss_consonant': 0.019143}\n",
      "  129 | 0.000008 | 029952/160635 | 0.0063 | 1.0562 |\n",
      "val: {'recall': 0.995952, 'recall_grapheme': 0.99427, 'recall_vowel': 0.997205, 'recall_consonant': 0.998061, 'acc_grapheme': 0.993832, 'acc_vowel': 0.997712, 'acc_consonant': 0.998284, 'loss_grapheme': 0.035991, 'loss_vowel': 0.025973, 'loss_consonant': 0.01707}\n",
      "  130 | 0.000015 | 023040/160635 | 2.6019 | 1.3385 |\n",
      "val: {'recall': 0.994079, 'recall_grapheme': 0.991369, 'recall_vowel': 0.996112, 'recall_consonant': 0.997465, 'acc_grapheme': 0.990747, 'acc_vowel': 0.996667, 'acc_consonant': 0.997538, 'loss_grapheme': 0.116546, 'loss_vowel': 0.120569, 'loss_consonant': 0.073891}\n",
      "  131 | 0.000026 | 016128/160635 | 2.8046 | 0.9948 |\n",
      "val: {'recall': 0.995475, 'recall_grapheme': 0.993634, 'recall_vowel': 0.997437, 'recall_consonant': 0.997196, 'acc_grapheme': 0.993235, 'acc_vowel': 0.997662, 'acc_consonant': 0.99801, 'loss_grapheme': 0.050466, 'loss_vowel': 0.041116, 'loss_consonant': 0.026825}\n",
      "  132 | 0.000038 | 009216/160635 | 0.6431 | 0.6501 |\n",
      "val: {'recall': 0.99561, 'recall_grapheme': 0.993547, 'recall_vowel': 0.997199, 'recall_consonant': 0.998148, 'acc_grapheme': 0.993409, 'acc_vowel': 0.997413, 'acc_consonant': 0.998159, 'loss_grapheme': 0.042865, 'loss_vowel': 0.030559, 'loss_consonant': 0.020516}\n",
      "  133 | 0.000050 | 002304/160635 | 1.5182 | 0.8086 |\n",
      "val: {'recall': 0.994358, 'recall_grapheme': 0.992392, 'recall_vowel': 0.996311, 'recall_consonant': 0.996336, 'acc_grapheme': 0.992215, 'acc_vowel': 0.996966, 'acc_consonant': 0.997637, 'loss_grapheme': 0.06547, 'loss_vowel': 0.052178, 'loss_consonant': 0.034374}\n",
      "  133 | 0.000063 | 155904/160635 | 0.0215 | 1.2059 |\n",
      "val: {'recall': 0.995018, 'recall_grapheme': 0.992866, 'recall_vowel': 0.996556, 'recall_consonant': 0.997784, 'acc_grapheme': 0.992488, 'acc_vowel': 0.99699, 'acc_consonant': 0.997886, 'loss_grapheme': 0.058338, 'loss_vowel': 0.04635, 'loss_consonant': 0.0286}\n",
      "  134 | 0.000075 | 148992/160635 | 1.3101 | 0.9358 |\n",
      "val: {'recall': 0.995042, 'recall_grapheme': 0.993436, 'recall_vowel': 0.997231, 'recall_consonant': 0.996066, 'acc_grapheme': 0.993135, 'acc_vowel': 0.997264, 'acc_consonant': 0.997786, 'loss_grapheme': 0.048341, 'loss_vowel': 0.037344, 'loss_consonant': 0.023658}\n",
      "  135 | 0.000086 | 142080/160635 | 0.3098 | 1.2139 |\n",
      "val: {'recall': 0.993508, 'recall_grapheme': 0.991712, 'recall_vowel': 0.996463, 'recall_consonant': 0.994143, 'acc_grapheme': 0.991071, 'acc_vowel': 0.996791, 'acc_consonant': 0.99699, 'loss_grapheme': 0.06028, 'loss_vowel': 0.049646, 'loss_consonant': 0.034867}\n",
      "  136 | 0.000093 | 135168/160635 | 3.0018 | 1.1712 |\n",
      "val: {'recall': 0.995205, 'recall_grapheme': 0.993191, 'recall_vowel': 0.996572, 'recall_consonant': 0.997867, 'acc_grapheme': 0.992339, 'acc_vowel': 0.996891, 'acc_consonant': 0.997562, 'loss_grapheme': 0.044448, 'loss_vowel': 0.032137, 'loss_consonant': 0.022512}\n",
      "  137 | 0.000098 | 128256/160635 | 1.4579 | 1.2376 |\n",
      "val: {'recall': 0.994211, 'recall_grapheme': 0.99205, 'recall_vowel': 0.996018, 'recall_consonant': 0.996727, 'acc_grapheme': 0.991046, 'acc_vowel': 0.996219, 'acc_consonant': 0.997314, 'loss_grapheme': 0.077739, 'loss_vowel': 0.055295, 'loss_consonant': 0.039365}\n",
      "  138 | 0.000100 | 121344/160635 | 1.2770 | 1.0402 |\n",
      "val: {'recall': 0.994387, 'recall_grapheme': 0.991876, 'recall_vowel': 0.996838, 'recall_consonant': 0.996956, 'acc_grapheme': 0.990648, 'acc_vowel': 0.996816, 'acc_consonant': 0.997214, 'loss_grapheme': 0.059631, 'loss_vowel': 0.037266, 'loss_consonant': 0.026562}\n",
      "  139 | 0.000098 | 114432/160635 | 3.5832 | 1.2067 |\n",
      "val: {'recall': 0.993803, 'recall_grapheme': 0.991396, 'recall_vowel': 0.995417, 'recall_consonant': 0.997004, 'acc_grapheme': 0.990598, 'acc_vowel': 0.996418, 'acc_consonant': 0.997264, 'loss_grapheme': 0.067696, 'loss_vowel': 0.05188, 'loss_consonant': 0.031442}\n",
      "  140 | 0.000093 | 107520/160635 | 0.0138 | 1.3478 |\n",
      "val: {'recall': 0.994247, 'recall_grapheme': 0.992115, 'recall_vowel': 0.995776, 'recall_consonant': 0.996983, 'acc_grapheme': 0.990772, 'acc_vowel': 0.996518, 'acc_consonant': 0.997165, 'loss_grapheme': 0.051661, 'loss_vowel': 0.03359, 'loss_consonant': 0.021978}\n",
      "  141 | 0.000086 | 100608/160635 | 1.3401 | 1.1878 |\n",
      "val: {'recall': 0.994606, 'recall_grapheme': 0.992675, 'recall_vowel': 0.996947, 'recall_consonant': 0.996127, 'acc_grapheme': 0.99229, 'acc_vowel': 0.997165, 'acc_consonant': 0.997364, 'loss_grapheme': 0.071334, 'loss_vowel': 0.053601, 'loss_consonant': 0.037372}\n",
      "  142 | 0.000075 | 093696/160635 | 1.1000 | 0.9768 |\n",
      "val: {'recall': 0.994344, 'recall_grapheme': 0.99248, 'recall_vowel': 0.996452, 'recall_consonant': 0.995965, 'acc_grapheme': 0.991593, 'acc_vowel': 0.996941, 'acc_consonant': 0.997339, 'loss_grapheme': 0.045728, 'loss_vowel': 0.026674, 'loss_consonant': 0.019162}\n",
      "  143 | 0.000063 | 086784/160635 | 2.5785 | 1.0748 |\n",
      "val: {'recall': 0.994889, 'recall_grapheme': 0.992678, 'recall_vowel': 0.996893, 'recall_consonant': 0.997306, 'acc_grapheme': 0.991717, 'acc_vowel': 0.996966, 'acc_consonant': 0.997438, 'loss_grapheme': 0.082959, 'loss_vowel': 0.074174, 'loss_consonant': 0.048501}\n",
      "  144 | 0.000050 | 079872/160635 | 1.1172 | 1.0656 |\n",
      "val: {'recall': 0.994823, 'recall_grapheme': 0.993338, 'recall_vowel': 0.997223, 'recall_consonant': 0.995393, 'acc_grapheme': 0.992886, 'acc_vowel': 0.997513, 'acc_consonant': 0.997761, 'loss_grapheme': 0.042642, 'loss_vowel': 0.029813, 'loss_consonant': 0.020454}\n",
      "  145 | 0.000038 | 072960/160635 | 0.0161 | 1.0254 |\n",
      "val: {'recall': 0.995315, 'recall_grapheme': 0.993331, 'recall_vowel': 0.99687, 'recall_consonant': 0.997726, 'acc_grapheme': 0.99326, 'acc_vowel': 0.997239, 'acc_consonant': 0.99806, 'loss_grapheme': 0.040466, 'loss_vowel': 0.030117, 'loss_consonant': 0.018936}\n",
      "  146 | 0.000026 | 066048/160635 | 0.0087 | 1.1036 |\n",
      "val: {'recall': 0.995378, 'recall_grapheme': 0.993547, 'recall_vowel': 0.997286, 'recall_consonant': 0.997131, 'acc_grapheme': 0.993359, 'acc_vowel': 0.997264, 'acc_consonant': 0.997911, 'loss_grapheme': 0.040453, 'loss_vowel': 0.031485, 'loss_consonant': 0.019768}\n",
      "  147 | 0.000015 | 059136/160635 | 0.0053 | 1.0463 |\n",
      "val: {'recall': 0.996125, 'recall_grapheme': 0.994597, 'recall_vowel': 0.998033, 'recall_consonant': 0.997273, 'acc_grapheme': 0.994304, 'acc_vowel': 0.997985, 'acc_consonant': 0.998085, 'loss_grapheme': 0.028388, 'loss_vowel': 0.017978, 'loss_consonant': 0.012105}\n",
      "  148 | 0.000008 | 052224/160635 | 0.0028 | 1.1327 |\n",
      "val: {'recall': 0.995882, 'recall_grapheme': 0.99404, 'recall_vowel': 0.997734, 'recall_consonant': 0.997715, 'acc_grapheme': 0.993682, 'acc_vowel': 0.997811, 'acc_consonant': 0.99801, 'loss_grapheme': 0.043381, 'loss_vowel': 0.034075, 'loss_consonant': 0.022202}\n",
      "  149 | 0.000003 | 045312/160635 | 0.0021 | 0.9377 |\n",
      "val: {'recall': 0.996389, 'recall_grapheme': 0.994968, 'recall_vowel': 0.997875, 'recall_consonant': 0.997746, 'acc_grapheme': 0.994727, 'acc_vowel': 0.99796, 'acc_consonant': 0.998159, 'loss_grapheme': 0.030016, 'loss_vowel': 0.01893, 'loss_consonant': 0.012683}\n",
      "** saved\n",
      "  150 | 0.000001 | 038400/160635 | 0.0040 | 1.1171 |\n",
      "val: {'recall': 0.995862, 'recall_grapheme': 0.994093, 'recall_vowel': 0.997487, 'recall_consonant': 0.997777, 'acc_grapheme': 0.993782, 'acc_vowel': 0.997761, 'acc_consonant': 0.998085, 'loss_grapheme': 0.046081, 'loss_vowel': 0.037936, 'loss_consonant': 0.024217}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  151 | 0.000003 | 031488/160635 | 0.0031 | 0.9315 |\n",
      "val: {'recall': 0.995941, 'recall_grapheme': 0.994214, 'recall_vowel': 0.997565, 'recall_consonant': 0.997771, 'acc_grapheme': 0.993981, 'acc_vowel': 0.997737, 'acc_consonant': 0.99806, 'loss_grapheme': 0.033601, 'loss_vowel': 0.023653, 'loss_consonant': 0.015669}\n",
      "  152 | 0.000008 | 024576/160635 | 1.6167 | 0.9418 |\n",
      "val: {'recall': 0.995369, 'recall_grapheme': 0.99337, 'recall_vowel': 0.997129, 'recall_consonant': 0.997607, 'acc_grapheme': 0.993061, 'acc_vowel': 0.997314, 'acc_consonant': 0.997836, 'loss_grapheme': 0.053603, 'loss_vowel': 0.047442, 'loss_consonant': 0.030336}\n",
      "  153 | 0.000015 | 017664/160635 | 1.9491 | 0.9719 |\n",
      "val: {'recall': 0.99535, 'recall_grapheme': 0.993089, 'recall_vowel': 0.997371, 'recall_consonant': 0.997852, 'acc_grapheme': 0.992886, 'acc_vowel': 0.997413, 'acc_consonant': 0.997911, 'loss_grapheme': 0.050413, 'loss_vowel': 0.043729, 'loss_consonant': 0.027799}\n",
      "  154 | 0.000026 | 010752/160635 | 0.5529 | 0.4030 |\n",
      "val: {'recall': 0.996505, 'recall_grapheme': 0.99507, 'recall_vowel': 0.998054, 'recall_consonant': 0.997826, 'acc_grapheme': 0.994603, 'acc_vowel': 0.998035, 'acc_consonant': 0.998433, 'loss_grapheme': 0.028234, 'loss_vowel': 0.015638, 'loss_consonant': 0.010985}\n",
      "** saved\n",
      "  155 | 0.000038 | 003840/160635 | 2.2029 | 1.4009 |\n",
      "val: {'recall': 0.99496, 'recall_grapheme': 0.993059, 'recall_vowel': 0.996577, 'recall_consonant': 0.997146, 'acc_grapheme': 0.992588, 'acc_vowel': 0.99709, 'acc_consonant': 0.997861, 'loss_grapheme': 0.069706, 'loss_vowel': 0.05745, 'loss_consonant': 0.036625}\n",
      "  155 | 0.000050 | 157440/160635 | 1.8055 | 1.2516 |\n",
      "val: {'recall': 0.992977, 'recall_grapheme': 0.989932, 'recall_vowel': 0.996735, 'recall_consonant': 0.995309, 'acc_grapheme': 0.989653, 'acc_vowel': 0.996543, 'acc_consonant': 0.996816, 'loss_grapheme': 0.068234, 'loss_vowel': 0.057003, 'loss_consonant': 0.037276}\n",
      "  156 | 0.000063 | 150528/160635 | 1.8193 | 1.0890 |\n",
      "val: {'recall': 0.994431, 'recall_grapheme': 0.992665, 'recall_vowel': 0.996197, 'recall_consonant': 0.996196, 'acc_grapheme': 0.992389, 'acc_vowel': 0.996916, 'acc_consonant': 0.997488, 'loss_grapheme': 0.066529, 'loss_vowel': 0.063939, 'loss_consonant': 0.04099}\n",
      "  157 | 0.000075 | 143616/160635 | 0.0311 | 1.2523 |\n",
      "val: {'recall': 0.994378, 'recall_grapheme': 0.992498, 'recall_vowel': 0.997282, 'recall_consonant': 0.995234, 'acc_grapheme': 0.992115, 'acc_vowel': 0.997189, 'acc_consonant': 0.99714, 'loss_grapheme': 0.068495, 'loss_vowel': 0.066067, 'loss_consonant': 0.045535}\n",
      "  158 | 0.000086 | 136704/160635 | 0.0120 | 1.1048 |\n",
      "val: {'recall': 0.99389, 'recall_grapheme': 0.991469, 'recall_vowel': 0.996486, 'recall_consonant': 0.996135, 'acc_grapheme': 0.990797, 'acc_vowel': 0.996493, 'acc_consonant': 0.99714, 'loss_grapheme': 0.082314, 'loss_vowel': 0.064971, 'loss_consonant': 0.041095}\n",
      "  159 | 0.000093 | 129792/160635 | 0.0204 | 1.1029 |\n",
      "val: {'recall': 0.995345, 'recall_grapheme': 0.993477, 'recall_vowel': 0.996931, 'recall_consonant': 0.997492, 'acc_grapheme': 0.992712, 'acc_vowel': 0.996966, 'acc_consonant': 0.997413, 'loss_grapheme': 0.043106, 'loss_vowel': 0.029712, 'loss_consonant': 0.018964}\n",
      "  160 | 0.000098 | 122880/160635 | 1.8014 | 1.2376 |\n",
      "val: {'recall': 0.993088, 'recall_grapheme': 0.990707, 'recall_vowel': 0.996197, 'recall_consonant': 0.994741, 'acc_grapheme': 0.991021, 'acc_vowel': 0.996717, 'acc_consonant': 0.997388, 'loss_grapheme': 0.074778, 'loss_vowel': 0.059927, 'loss_consonant': 0.039893}\n",
      "  161 | 0.000100 | 115968/160635 | 1.0772 | 1.1637 |\n",
      "val: {'recall': 0.993421, 'recall_grapheme': 0.992132, 'recall_vowel': 0.9966, 'recall_consonant': 0.99282, 'acc_grapheme': 0.990847, 'acc_vowel': 0.996841, 'acc_consonant': 0.99709, 'loss_grapheme': 0.095969, 'loss_vowel': 0.07395, 'loss_consonant': 0.047778}\n",
      "  162 | 0.000098 | 109056/160635 | 0.0232 | 1.1812 |\n",
      "val: {'recall': 0.993245, 'recall_grapheme': 0.990759, 'recall_vowel': 0.996156, 'recall_consonant': 0.995306, 'acc_grapheme': 0.990524, 'acc_vowel': 0.996493, 'acc_consonant': 0.996617, 'loss_grapheme': 0.064898, 'loss_vowel': 0.048451, 'loss_consonant': 0.033497}\n",
      "  163 | 0.000093 | 102144/160635 | 3.2524 | 1.1222 |\n",
      "val: {'recall': 0.994399, 'recall_grapheme': 0.992056, 'recall_vowel': 0.996953, 'recall_consonant': 0.996529, 'acc_grapheme': 0.99127, 'acc_vowel': 0.99709, 'acc_consonant': 0.997264, 'loss_grapheme': 0.084395, 'loss_vowel': 0.076881, 'loss_consonant': 0.048816}\n",
      "  164 | 0.000086 | 095232/160635 | 2.5441 | 1.1918 |\n",
      "val: {'recall': 0.995207, 'recall_grapheme': 0.993068, 'recall_vowel': 0.996982, 'recall_consonant': 0.997708, 'acc_grapheme': 0.992364, 'acc_vowel': 0.997289, 'acc_consonant': 0.997936, 'loss_grapheme': 0.083348, 'loss_vowel': 0.077349, 'loss_consonant': 0.049968}\n",
      "  165 | 0.000075 | 088320/160635 | 1.6410 | 1.0425 |\n",
      "val: {'recall': 0.995078, 'recall_grapheme': 0.993772, 'recall_vowel': 0.9969, 'recall_consonant': 0.995869, 'acc_grapheme': 0.993061, 'acc_vowel': 0.997388, 'acc_consonant': 0.997587, 'loss_grapheme': 0.03754, 'loss_vowel': 0.025665, 'loss_consonant': 0.017776}\n",
      "  166 | 0.000063 | 081408/160635 | 2.2121 | 1.1313 |\n",
      "val: {'recall': 0.995125, 'recall_grapheme': 0.993011, 'recall_vowel': 0.996861, 'recall_consonant': 0.997618, 'acc_grapheme': 0.992041, 'acc_vowel': 0.997065, 'acc_consonant': 0.997562, 'loss_grapheme': 0.064906, 'loss_vowel': 0.066992, 'loss_consonant': 0.041223}\n",
      "  167 | 0.000051 | 074496/160635 | 0.0101 | 1.3036 |\n",
      "val: {'recall': 0.995778, 'recall_grapheme': 0.994026, 'recall_vowel': 0.997404, 'recall_consonant': 0.997657, 'acc_grapheme': 0.993185, 'acc_vowel': 0.997339, 'acc_consonant': 0.998135, 'loss_grapheme': 0.049184, 'loss_vowel': 0.04129, 'loss_consonant': 0.024799}\n",
      "  168 | 0.000038 | 067584/160635 | 1.1647 | 1.1298 |\n",
      "val: {'recall': 0.99638, 'recall_grapheme': 0.994756, 'recall_vowel': 0.998077, 'recall_consonant': 0.99793, 'acc_grapheme': 0.994453, 'acc_vowel': 0.997662, 'acc_consonant': 0.998184, 'loss_grapheme': 0.034871, 'loss_vowel': 0.024507, 'loss_consonant': 0.016528}\n",
      "  169 | 0.000026 | 060672/160635 | 0.0078 | 0.9611 |\n",
      "val: {'recall': 0.996184, 'recall_grapheme': 0.99473, 'recall_vowel': 0.998012, 'recall_consonant': 0.997264, 'acc_grapheme': 0.994553, 'acc_vowel': 0.997786, 'acc_consonant': 0.998284, 'loss_grapheme': 0.026086, 'loss_vowel': 0.016725, 'loss_consonant': 0.012212}\n",
      "  170 | 0.000015 | 053760/160635 | 2.5467 | 1.1817 |\n",
      "val: {'recall': 0.995248, 'recall_grapheme': 0.993132, 'recall_vowel': 0.99711, 'recall_consonant': 0.997619, 'acc_grapheme': 0.992787, 'acc_vowel': 0.997289, 'acc_consonant': 0.997786, 'loss_grapheme': 0.06107, 'loss_vowel': 0.060514, 'loss_consonant': 0.039846}\n",
      "  171 | 0.000008 | 046848/160635 | 0.6059 | 1.1817 |\n",
      "val: {'recall': 0.995808, 'recall_grapheme': 0.994011, 'recall_vowel': 0.997528, 'recall_consonant': 0.997682, 'acc_grapheme': 0.993782, 'acc_vowel': 0.997488, 'acc_consonant': 0.998135, 'loss_grapheme': 0.055216, 'loss_vowel': 0.046161, 'loss_consonant': 0.029549}\n",
      "  172 | 0.000003 | 039936/160635 | 0.0147 | 0.8345 |\n",
      "val: {'recall': 0.996416, 'recall_grapheme': 0.994891, 'recall_vowel': 0.998113, 'recall_consonant': 0.99777, 'acc_grapheme': 0.994802, 'acc_vowel': 0.997861, 'acc_consonant': 0.998234, 'loss_grapheme': 0.027918, 'loss_vowel': 0.018329, 'loss_consonant': 0.012642}\n",
      "  173 | 0.000001 | 033024/160635 | 1.2806 | 0.9800 |\n",
      "val: {'recall': 0.99588, 'recall_grapheme': 0.993919, 'recall_vowel': 0.997849, 'recall_consonant': 0.997833, 'acc_grapheme': 0.993658, 'acc_vowel': 0.997587, 'acc_consonant': 0.99811, 'loss_grapheme': 0.047732, 'loss_vowel': 0.038357, 'loss_consonant': 0.025816}\n",
      "  174 | 0.000003 | 026112/160635 | 1.4998 | 1.1515 |\n",
      "val: {'recall': 0.995673, 'recall_grapheme': 0.993618, 'recall_vowel': 0.997698, 'recall_consonant': 0.997757, 'acc_grapheme': 0.993583, 'acc_vowel': 0.997513, 'acc_consonant': 0.998085, 'loss_grapheme': 0.052241, 'loss_vowel': 0.045607, 'loss_consonant': 0.030122}\n",
      "  175 | 0.000008 | 019200/160635 | 1.5549 | 1.0485 |\n",
      "val: {'recall': 0.9954, 'recall_grapheme': 0.993246, 'recall_vowel': 0.997468, 'recall_consonant': 0.997641, 'acc_grapheme': 0.99316, 'acc_vowel': 0.997538, 'acc_consonant': 0.998035, 'loss_grapheme': 0.058237, 'loss_vowel': 0.056041, 'loss_consonant': 0.036129}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  176 | 0.000015 | 012288/160635 | 0.0069 | 0.7804 |\n",
      "val: {'recall': 0.996229, 'recall_grapheme': 0.99442, 'recall_vowel': 0.998116, 'recall_consonant': 0.997961, 'acc_grapheme': 0.994429, 'acc_vowel': 0.997886, 'acc_consonant': 0.998334, 'loss_grapheme': 0.03338, 'loss_vowel': 0.023859, 'loss_consonant': 0.016146}\n",
      "  177 | 0.000026 | 005376/160635 | 1.6301 | 1.1908 |\n",
      "val: {'recall': 0.995366, 'recall_grapheme': 0.993325, 'recall_vowel': 0.997324, 'recall_consonant': 0.997491, 'acc_grapheme': 0.993558, 'acc_vowel': 0.997413, 'acc_consonant': 0.99796, 'loss_grapheme': 0.053936, 'loss_vowel': 0.046522, 'loss_consonant': 0.03066}\n",
      "  177 | 0.000038 | 158976/160635 | 1.5745 | 0.9867 |\n",
      "val: {'recall': 0.995656, 'recall_grapheme': 0.993776, 'recall_vowel': 0.997664, 'recall_consonant': 0.997408, 'acc_grapheme': 0.993583, 'acc_vowel': 0.997538, 'acc_consonant': 0.997985, 'loss_grapheme': 0.069683, 'loss_vowel': 0.055781, 'loss_consonant': 0.038163}\n",
      "  178 | 0.000050 | 152064/160635 | 0.0041 | 1.0478 |\n",
      "val: {'recall': 0.995438, 'recall_grapheme': 0.993454, 'recall_vowel': 0.997413, 'recall_consonant': 0.997432, 'acc_grapheme': 0.993085, 'acc_vowel': 0.997314, 'acc_consonant': 0.998085, 'loss_grapheme': 0.053447, 'loss_vowel': 0.044363, 'loss_consonant': 0.02934}\n",
      "  179 | 0.000063 | 145152/160635 | 2.6091 | 1.1124 |\n",
      "val: {'recall': 0.994717, 'recall_grapheme': 0.992765, 'recall_vowel': 0.996793, 'recall_consonant': 0.996547, 'acc_grapheme': 0.992563, 'acc_vowel': 0.997115, 'acc_consonant': 0.997339, 'loss_grapheme': 0.095689, 'loss_vowel': 0.082158, 'loss_consonant': 0.051655}\n",
      "  180 | 0.000075 | 138240/160635 | 1.6181 | 1.1496 |\n",
      "val: {'recall': 0.994212, 'recall_grapheme': 0.992438, 'recall_vowel': 0.996391, 'recall_consonant': 0.995579, 'acc_grapheme': 0.991767, 'acc_vowel': 0.996841, 'acc_consonant': 0.996941, 'loss_grapheme': 0.050636, 'loss_vowel': 0.043586, 'loss_consonant': 0.02813}\n",
      "  181 | 0.000086 | 131328/160635 | 0.0077 | 1.0226 |\n",
      "val: {'recall': 0.995478, 'recall_grapheme': 0.994093, 'recall_vowel': 0.996804, 'recall_consonant': 0.996921, 'acc_grapheme': 0.993533, 'acc_vowel': 0.997289, 'acc_consonant': 0.997463, 'loss_grapheme': 0.035828, 'loss_vowel': 0.021281, 'loss_consonant': 0.014934}\n",
      "  182 | 0.000093 | 124416/160635 | 3.1417 | 1.1043 |\n",
      "val: {'recall': 0.995356, 'recall_grapheme': 0.994824, 'recall_vowel': 0.99678, 'recall_consonant': 0.994998, 'acc_grapheme': 0.993235, 'acc_vowel': 0.997239, 'acc_consonant': 0.997562, 'loss_grapheme': 0.041237, 'loss_vowel': 0.029117, 'loss_consonant': 0.018572}\n",
      "  183 | 0.000098 | 117504/160635 | 1.8947 | 1.2065 |\n",
      "val: {'recall': 0.993923, 'recall_grapheme': 0.991833, 'recall_vowel': 0.995905, 'recall_consonant': 0.996119, 'acc_grapheme': 0.990847, 'acc_vowel': 0.996418, 'acc_consonant': 0.996816, 'loss_grapheme': 0.081759, 'loss_vowel': 0.073614, 'loss_consonant': 0.048768}\n",
      "  184 | 0.000100 | 110592/160635 | 1.5126 | 0.9621 |\n",
      "val: {'recall': 0.992783, 'recall_grapheme': 0.989771, 'recall_vowel': 0.995731, 'recall_consonant': 0.995857, 'acc_grapheme': 0.989852, 'acc_vowel': 0.995821, 'acc_consonant': 0.996742, 'loss_grapheme': 0.092067, 'loss_vowel': 0.0752, 'loss_consonant': 0.048991}\n",
      "  185 | 0.000098 | 103680/160635 | 1.9077 | 1.2890 |\n",
      "val: {'recall': 0.99405, 'recall_grapheme': 0.992289, 'recall_vowel': 0.995684, 'recall_consonant': 0.995939, 'acc_grapheme': 0.992414, 'acc_vowel': 0.996941, 'acc_consonant': 0.997413, 'loss_grapheme': 0.06785, 'loss_vowel': 0.060174, 'loss_consonant': 0.037337}\n",
      "  186 | 0.000093 | 096768/160635 | 0.9179 | 1.0416 |\n",
      "val: {'recall': 0.99428, 'recall_grapheme': 0.991464, 'recall_vowel': 0.996759, 'recall_consonant': 0.997434, 'acc_grapheme': 0.991071, 'acc_vowel': 0.996418, 'acc_consonant': 0.997264, 'loss_grapheme': 0.055941, 'loss_vowel': 0.036233, 'loss_consonant': 0.025595}\n",
      "  187 | 0.000086 | 089856/160635 | 3.2393 | 1.2214 |\n",
      "val: {'recall': 0.993923, 'recall_grapheme': 0.991406, 'recall_vowel': 0.996132, 'recall_consonant': 0.99675, 'acc_grapheme': 0.990772, 'acc_vowel': 0.996369, 'acc_consonant': 0.996916, 'loss_grapheme': 0.076558, 'loss_vowel': 0.079512, 'loss_consonant': 0.049007}\n",
      "  188 | 0.000075 | 082944/160635 | 2.0929 | 1.0633 |\n",
      "val: {'recall': 0.994831, 'recall_grapheme': 0.992956, 'recall_vowel': 0.996516, 'recall_consonant': 0.996897, 'acc_grapheme': 0.992538, 'acc_vowel': 0.996841, 'acc_consonant': 0.997488, 'loss_grapheme': 0.070951, 'loss_vowel': 0.059122, 'loss_consonant': 0.040654}\n",
      "  189 | 0.000063 | 076032/160635 | 1.6851 | 1.0130 |\n",
      "val: {'recall': 0.995474, 'recall_grapheme': 0.993629, 'recall_vowel': 0.997119, 'recall_consonant': 0.997521, 'acc_grapheme': 0.993608, 'acc_vowel': 0.997339, 'acc_consonant': 0.99806, 'loss_grapheme': 0.068813, 'loss_vowel': 0.053627, 'loss_consonant': 0.038012}\n",
      "  190 | 0.000051 | 069120/160635 | 0.0026 | 1.1776 |\n",
      "val: {'recall': 0.995872, 'recall_grapheme': 0.994854, 'recall_vowel': 0.997358, 'recall_consonant': 0.996424, 'acc_grapheme': 0.994105, 'acc_vowel': 0.997587, 'acc_consonant': 0.997786, 'loss_grapheme': 0.058978, 'loss_vowel': 0.044794, 'loss_consonant': 0.031142}\n",
      "  191 | 0.000038 | 062208/160635 | 2.1834 | 1.1527 |\n",
      "val: {'recall': 0.995491, 'recall_grapheme': 0.994087, 'recall_vowel': 0.997152, 'recall_consonant': 0.996641, 'acc_grapheme': 0.99321, 'acc_vowel': 0.997488, 'acc_consonant': 0.997936, 'loss_grapheme': 0.071562, 'loss_vowel': 0.060819, 'loss_consonant': 0.041421}\n",
      "  192 | 0.000026 | 055296/160635 | 0.3171 | 0.8710 |\n",
      "val: {'recall': 0.996473, 'recall_grapheme': 0.996005, 'recall_vowel': 0.998088, 'recall_consonant': 0.995793, 'acc_grapheme': 0.9952, 'acc_vowel': 0.998234, 'acc_consonant': 0.998284, 'loss_grapheme': 0.028164, 'loss_vowel': 0.01654, 'loss_consonant': 0.011663}\n",
      "  193 | 0.000015 | 048384/160635 | 0.0037 | 1.1732 |\n",
      "val: {'recall': 0.995693, 'recall_grapheme': 0.99464, 'recall_vowel': 0.997301, 'recall_consonant': 0.996191, 'acc_grapheme': 0.994105, 'acc_vowel': 0.997637, 'acc_consonant': 0.998234, 'loss_grapheme': 0.038543, 'loss_vowel': 0.029388, 'loss_consonant': 0.019667}\n",
      "  194 | 0.000008 | 041472/160635 | 1.3407 | 0.8973 |\n",
      "val: {'recall': 0.995684, 'recall_grapheme': 0.994544, 'recall_vowel': 0.997564, 'recall_consonant': 0.996086, 'acc_grapheme': 0.993782, 'acc_vowel': 0.997687, 'acc_consonant': 0.998135, 'loss_grapheme': 0.049986, 'loss_vowel': 0.042284, 'loss_consonant': 0.027608}\n",
      "  195 | 0.000003 | 034560/160635 | 0.0053 | 0.9267 |\n",
      "val: {'recall': 0.996307, 'recall_grapheme': 0.995572, 'recall_vowel': 0.997824, 'recall_consonant': 0.99626, 'acc_grapheme': 0.994926, 'acc_vowel': 0.99801, 'acc_consonant': 0.998433, 'loss_grapheme': 0.03212, 'loss_vowel': 0.022078, 'loss_consonant': 0.01521}\n",
      "  196 | 0.000001 | 027648/160635 | 2.2037 | 1.1612 |\n",
      "val: {'recall': 0.995459, 'recall_grapheme': 0.99397, 'recall_vowel': 0.997255, 'recall_consonant': 0.996643, 'acc_grapheme': 0.993459, 'acc_vowel': 0.997463, 'acc_consonant': 0.99801, 'loss_grapheme': 0.061437, 'loss_vowel': 0.054455, 'loss_consonant': 0.035025}\n",
      "  197 | 0.000003 | 020736/160635 | 2.2018 | 0.8795 |\n",
      "val: {'recall': 0.995134, 'recall_grapheme': 0.994078, 'recall_vowel': 0.996782, 'recall_consonant': 0.995598, 'acc_grapheme': 0.993707, 'acc_vowel': 0.997513, 'acc_consonant': 0.99806, 'loss_grapheme': 0.045156, 'loss_vowel': 0.036068, 'loss_consonant': 0.024622}\n",
      "  198 | 0.000008 | 013824/160635 | 2.9971 | 1.0307 |\n",
      "val: {'recall': 0.994871, 'recall_grapheme': 0.993612, 'recall_vowel': 0.99674, 'recall_consonant': 0.99552, 'acc_grapheme': 0.993459, 'acc_vowel': 0.997413, 'acc_consonant': 0.997861, 'loss_grapheme': 0.048102, 'loss_vowel': 0.0419, 'loss_consonant': 0.028209}\n",
      "  199 | 0.000015 | 006912/160635 | 2.2191 | 0.8236 |\n",
      "val: {'recall': 0.995477, 'recall_grapheme': 0.993961, 'recall_vowel': 0.997252, 'recall_consonant': 0.996733, 'acc_grapheme': 0.993658, 'acc_vowel': 0.997612, 'acc_consonant': 0.998159, 'loss_grapheme': 0.042261, 'loss_vowel': 0.031999, 'loss_consonant': 0.022395}\n",
      "  199 | 0.000026 | 160512/160635 | 0.0056 | 1.0402 |\n",
      "val: {'recall': 0.995873, 'recall_grapheme': 0.995059, 'recall_vowel': 0.997318, 'recall_consonant': 0.996055, 'acc_grapheme': 0.994404, 'acc_vowel': 0.997761, 'acc_consonant': 0.99801, 'loss_grapheme': 0.036889, 'loss_vowel': 0.025663, 'loss_consonant': 0.017793}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200 | 0.000038 | 153600/160635 | 0.0174 | 0.9570 |\n",
      "val: {'recall': 0.995923, 'recall_grapheme': 0.994982, 'recall_vowel': 0.997364, 'recall_consonant': 0.996363, 'acc_grapheme': 0.994553, 'acc_vowel': 0.99796, 'acc_consonant': 0.99811, 'loss_grapheme': 0.02816, 'loss_vowel': 0.016407, 'loss_consonant': 0.012094}\n",
      "  201 | 0.000051 | 146688/160635 | 2.0613 | 1.0812 |\n",
      "val: {'recall': 0.995229, 'recall_grapheme': 0.993138, 'recall_vowel': 0.996965, 'recall_consonant': 0.997673, 'acc_grapheme': 0.99316, 'acc_vowel': 0.997388, 'acc_consonant': 0.998234, 'loss_grapheme': 0.069777, 'loss_vowel': 0.052476, 'loss_consonant': 0.035723}\n",
      "  202 | 0.000063 | 139776/160635 | 0.0076 | 1.0752 |\n",
      "val: {'recall': 0.996016, 'recall_grapheme': 0.994547, 'recall_vowel': 0.997224, 'recall_consonant': 0.997744, 'acc_grapheme': 0.993881, 'acc_vowel': 0.997562, 'acc_consonant': 0.998184, 'loss_grapheme': 0.037891, 'loss_vowel': 0.026039, 'loss_consonant': 0.016262}\n",
      "  203 | 0.000075 | 132864/160635 | 0.5984 | 0.9684 |\n",
      "val: {'recall': 0.995251, 'recall_grapheme': 0.99321, 'recall_vowel': 0.997003, 'recall_consonant': 0.99758, 'acc_grapheme': 0.993036, 'acc_vowel': 0.996966, 'acc_consonant': 0.997438, 'loss_grapheme': 0.05578, 'loss_vowel': 0.045055, 'loss_consonant': 0.033849}\n",
      "  204 | 0.000086 | 125952/160635 | 1.3224 | 1.1015 |\n",
      "val: {'recall': 0.994826, 'recall_grapheme': 0.992897, 'recall_vowel': 0.997047, 'recall_consonant': 0.996463, 'acc_grapheme': 0.993284, 'acc_vowel': 0.997339, 'acc_consonant': 0.997985, 'loss_grapheme': 0.057277, 'loss_vowel': 0.041189, 'loss_consonant': 0.027042}\n",
      "  205 | 0.000093 | 119040/160635 | 0.6622 | 1.0503 |\n",
      "val: {'recall': 0.993924, 'recall_grapheme': 0.991876, 'recall_vowel': 0.995496, 'recall_consonant': 0.996447, 'acc_grapheme': 0.991469, 'acc_vowel': 0.996518, 'acc_consonant': 0.997364, 'loss_grapheme': 0.062434, 'loss_vowel': 0.049587, 'loss_consonant': 0.031681}\n",
      "  206 | 0.000098 | 112128/160635 | 0.0172 | 1.0316 |\n",
      "val: {'recall': 0.993231, 'recall_grapheme': 0.991638, 'recall_vowel': 0.996182, 'recall_consonant': 0.993466, 'acc_grapheme': 0.990897, 'acc_vowel': 0.996244, 'acc_consonant': 0.996767, 'loss_grapheme': 0.068877, 'loss_vowel': 0.064357, 'loss_consonant': 0.040904}\n",
      "  207 | 0.000100 | 105216/160635 | 1.1385 | 1.1234 |\n",
      "val: {'recall': 0.995055, 'recall_grapheme': 0.992736, 'recall_vowel': 0.996764, 'recall_consonant': 0.997985, 'acc_grapheme': 0.992016, 'acc_vowel': 0.996866, 'acc_consonant': 0.997587, 'loss_grapheme': 0.076405, 'loss_vowel': 0.065936, 'loss_consonant': 0.04469}\n",
      "  208 | 0.000098 | 098304/160635 | 2.6134 | 1.1147 |\n",
      "val: {'recall': 0.995591, 'recall_grapheme': 0.994001, 'recall_vowel': 0.997178, 'recall_consonant': 0.997185, 'acc_grapheme': 0.99321, 'acc_vowel': 0.997239, 'acc_consonant': 0.997438, 'loss_grapheme': 0.045617, 'loss_vowel': 0.035879, 'loss_consonant': 0.024073}\n",
      "  209 | 0.000093 | 091392/160635 | 0.4178 | 1.0487 |\n",
      "val: {'recall': 0.995432, 'recall_grapheme': 0.993877, 'recall_vowel': 0.997362, 'recall_consonant': 0.99661, 'acc_grapheme': 0.993309, 'acc_vowel': 0.997438, 'acc_consonant': 0.997562, 'loss_grapheme': 0.04818, 'loss_vowel': 0.03858, 'loss_consonant': 0.025876}\n",
      "  210 | 0.000086 | 005376/160635 | 0.0077 | 0.8052 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-0e72dd322b99>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m#loss = criterion(outputs, targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.991643, 'recall_grapheme': 0.987994, 'recall_vowel': 0.995136, 'recall_consonant': 0.995447, 'acc_grapheme': 0.987439, 'acc_vowel': 0.99515, 'acc_consonant': 0.996095, 'loss_grapheme': 0.16107, 'loss_vowel': 0.121419, 'loss_consonant': 0.08749}\n",
      "    0 | 0.000020 | 153600/160635 | 1.8225 | 1.0988 |\n",
      "val: {'recall': 0.991303, 'recall_grapheme': 0.987622, 'recall_vowel': 0.994785, 'recall_consonant': 0.99518, 'acc_grapheme': 0.986544, 'acc_vowel': 0.995274, 'acc_consonant': 0.996045, 'loss_grapheme': 0.095816, 'loss_vowel': 0.073148, 'loss_consonant': 0.051373}\n",
      "    1 | 0.000020 | 146688/160635 | 1.9591 | 1.3681 |\n",
      "val: {'recall': 0.99159, 'recall_grapheme': 0.988516, 'recall_vowel': 0.994824, 'recall_consonant': 0.994504, 'acc_grapheme': 0.98826, 'acc_vowel': 0.995473, 'acc_consonant': 0.996568, 'loss_grapheme': 0.128494, 'loss_vowel': 0.11986, 'loss_consonant': 0.076155}\n",
      "    2 | 0.000020 | 139776/160635 | 2.3023 | 1.1676 |\n",
      "val: {'recall': 0.99295, 'recall_grapheme': 0.990509, 'recall_vowel': 0.995751, 'recall_consonant': 0.995033, 'acc_grapheme': 0.989703, 'acc_vowel': 0.99607, 'acc_consonant': 0.996393, 'loss_grapheme': 0.087355, 'loss_vowel': 0.073775, 'loss_consonant': 0.049125}\n",
      "** saved\n",
      "    3 | 0.000020 | 132864/160635 | 2.0931 | 1.2325 |\n",
      "val: {'recall': 0.992355, 'recall_grapheme': 0.989453, 'recall_vowel': 0.995286, 'recall_consonant': 0.995227, 'acc_grapheme': 0.98923, 'acc_vowel': 0.995722, 'acc_consonant': 0.996518, 'loss_grapheme': 0.089982, 'loss_vowel': 0.077542, 'loss_consonant': 0.050968}\n",
      "    4 | 0.000020 | 125952/160635 | 2.4047 | 1.2302 |\n",
      "val: {'recall': 0.992319, 'recall_grapheme': 0.989113, 'recall_vowel': 0.995521, 'recall_consonant': 0.995529, 'acc_grapheme': 0.98933, 'acc_vowel': 0.995946, 'acc_consonant': 0.996518, 'loss_grapheme': 0.11866, 'loss_vowel': 0.089537, 'loss_consonant': 0.062369}\n",
      "    5 | 0.000020 | 119040/160635 | 3.1118 | 1.0801 |\n",
      "val: {'recall': 0.993326, 'recall_grapheme': 0.990795, 'recall_vowel': 0.996255, 'recall_consonant': 0.995459, 'acc_grapheme': 0.990026, 'acc_vowel': 0.996294, 'acc_consonant': 0.996592, 'loss_grapheme': 0.068497, 'loss_vowel': 0.056197, 'loss_consonant': 0.0395}\n",
      "** saved\n",
      "    6 | 0.000020 | 112128/160635 | 0.0678 | 1.2891 |\n",
      "val: {'recall': 0.992297, 'recall_grapheme': 0.989555, 'recall_vowel': 0.994874, 'recall_consonant': 0.995204, 'acc_grapheme': 0.98918, 'acc_vowel': 0.995523, 'acc_consonant': 0.996244, 'loss_grapheme': 0.091954, 'loss_vowel': 0.067951, 'loss_consonant': 0.052072}\n",
      "    7 | 0.000020 | 105216/160635 | 1.4064 | 1.1669 |\n",
      "val: {'recall': 0.99368, 'recall_grapheme': 0.991459, 'recall_vowel': 0.995971, 'recall_consonant': 0.99583, 'acc_grapheme': 0.990623, 'acc_vowel': 0.996219, 'acc_consonant': 0.99714, 'loss_grapheme': 0.064795, 'loss_vowel': 0.052646, 'loss_consonant': 0.037928}\n",
      "** saved\n",
      "    8 | 0.000020 | 098304/160635 | 1.6460 | 1.1214 |\n",
      "val: {'recall': 0.992808, 'recall_grapheme': 0.990066, 'recall_vowel': 0.995391, 'recall_consonant': 0.995709, 'acc_grapheme': 0.989404, 'acc_vowel': 0.995946, 'acc_consonant': 0.996667, 'loss_grapheme': 0.094917, 'loss_vowel': 0.083919, 'loss_consonant': 0.056649}\n",
      "    9 | 0.000020 | 091392/160635 | 2.6326 | 1.2333 |\n",
      "val: {'recall': 0.993083, 'recall_grapheme': 0.990759, 'recall_vowel': 0.995217, 'recall_consonant': 0.995598, 'acc_grapheme': 0.989902, 'acc_vowel': 0.995871, 'acc_consonant': 0.996742, 'loss_grapheme': 0.095943, 'loss_vowel': 0.087195, 'loss_consonant': 0.057651}\n",
      "   10 | 0.000020 | 084480/160635 | 2.9953 | 1.1938 |\n",
      "val: {'recall': 0.99283, 'recall_grapheme': 0.99022, 'recall_vowel': 0.995097, 'recall_consonant': 0.995783, 'acc_grapheme': 0.989554, 'acc_vowel': 0.995747, 'acc_consonant': 0.996816, 'loss_grapheme': 0.08662, 'loss_vowel': 0.078744, 'loss_consonant': 0.052065}\n",
      "   11 | 0.000020 | 077568/160635 | 1.2163 | 1.1468 |\n",
      "val: {'recall': 0.99256, 'recall_grapheme': 0.989931, 'recall_vowel': 0.994994, 'recall_consonant': 0.995384, 'acc_grapheme': 0.989827, 'acc_vowel': 0.995797, 'acc_consonant': 0.996966, 'loss_grapheme': 0.084206, 'loss_vowel': 0.071068, 'loss_consonant': 0.048746}\n",
      "   12 | 0.000020 | 070656/160635 | 0.0369 | 1.3201 |\n",
      "val: {'recall': 0.993422, 'recall_grapheme': 0.991309, 'recall_vowel': 0.996112, 'recall_consonant': 0.994957, 'acc_grapheme': 0.990797, 'acc_vowel': 0.996443, 'acc_consonant': 0.997314, 'loss_grapheme': 0.054328, 'loss_vowel': 0.041236, 'loss_consonant': 0.029245}\n",
      "   13 | 0.000020 | 063744/160635 | 3.2606 | 1.2475 |\n",
      "val: {'recall': 0.993152, 'recall_grapheme': 0.990645, 'recall_vowel': 0.995555, 'recall_consonant': 0.995761, 'acc_grapheme': 0.989777, 'acc_vowel': 0.996145, 'acc_consonant': 0.996767, 'loss_grapheme': 0.093406, 'loss_vowel': 0.079166, 'loss_consonant': 0.049743}\n",
      "   14 | 0.000010 | 056832/160635 | 0.2466 | 1.1780 |\n",
      "val: {'recall': 0.993219, 'recall_grapheme': 0.990644, 'recall_vowel': 0.995605, 'recall_consonant': 0.995985, 'acc_grapheme': 0.990051, 'acc_vowel': 0.995946, 'acc_consonant': 0.996841, 'loss_grapheme': 0.084163, 'loss_vowel': 0.062421, 'loss_consonant': 0.044362}\n",
      "   15 | 0.000010 | 049920/160635 | 2.3561 | 1.1020 |\n",
      "val: {'recall': 0.993457, 'recall_grapheme': 0.991136, 'recall_vowel': 0.995429, 'recall_consonant': 0.996128, 'acc_grapheme': 0.990349, 'acc_vowel': 0.996095, 'acc_consonant': 0.997388, 'loss_grapheme': 0.069804, 'loss_vowel': 0.059053, 'loss_consonant': 0.040546}\n",
      "   16 | 0.000010 | 043008/160635 | 1.4169 | 0.8462 |\n",
      "val: {'recall': 0.994437, 'recall_grapheme': 0.99255, 'recall_vowel': 0.996113, 'recall_consonant': 0.996534, 'acc_grapheme': 0.991643, 'acc_vowel': 0.996543, 'acc_consonant': 0.997463, 'loss_grapheme': 0.042325, 'loss_vowel': 0.026621, 'loss_consonant': 0.019315}\n",
      "** saved\n",
      "   17 | 0.000010 | 036096/160635 | 0.0276 | 0.9434 |\n",
      "val: {'recall': 0.99434, 'recall_grapheme': 0.992381, 'recall_vowel': 0.996009, 'recall_consonant': 0.996588, 'acc_grapheme': 0.991668, 'acc_vowel': 0.996518, 'acc_consonant': 0.997562, 'loss_grapheme': 0.038954, 'loss_vowel': 0.023121, 'loss_consonant': 0.01649}\n",
      "   18 | 0.000010 | 029184/160635 | 0.0187 | 1.0316 |\n",
      "val: {'recall': 0.993073, 'recall_grapheme': 0.990233, 'recall_vowel': 0.995512, 'recall_consonant': 0.996313, 'acc_grapheme': 0.990374, 'acc_vowel': 0.996145, 'acc_consonant': 0.996966, 'loss_grapheme': 0.068496, 'loss_vowel': 0.059224, 'loss_consonant': 0.039354}\n",
      "   19 | 0.000010 | 022272/160635 | 1.4970 | 1.2808 |\n",
      "val: {'recall': 0.992664, 'recall_grapheme': 0.989725, 'recall_vowel': 0.995405, 'recall_consonant': 0.9958, 'acc_grapheme': 0.98928, 'acc_vowel': 0.995821, 'acc_consonant': 0.996816, 'loss_grapheme': 0.078042, 'loss_vowel': 0.066842, 'loss_consonant': 0.045286}\n",
      "   20 | 0.000010 | 015360/160635 | 0.0474 | 0.6378 |\n",
      "val: {'recall': 0.993979, 'recall_grapheme': 0.991987, 'recall_vowel': 0.996227, 'recall_consonant': 0.995715, 'acc_grapheme': 0.991245, 'acc_vowel': 0.996592, 'acc_consonant': 0.997189, 'loss_grapheme': 0.044434, 'loss_vowel': 0.027733, 'loss_consonant': 0.018941}\n",
      "   21 | 0.000010 | 008448/160635 | 2.0127 | 1.0474 |\n",
      "val: {'recall': 0.99374, 'recall_grapheme': 0.991429, 'recall_vowel': 0.995948, 'recall_consonant': 0.996155, 'acc_grapheme': 0.990946, 'acc_vowel': 0.996369, 'acc_consonant': 0.99714, 'loss_grapheme': 0.072199, 'loss_vowel': 0.058497, 'loss_consonant': 0.040433}\n",
      "   22 | 0.000010 | 001536/160635 | 3.4090 | 1.7224 |\n",
      "val: {'recall': 0.992929, 'recall_grapheme': 0.990365, 'recall_vowel': 0.995429, 'recall_consonant': 0.995556, 'acc_grapheme': 0.989976, 'acc_vowel': 0.99602, 'acc_consonant': 0.996816, 'loss_grapheme': 0.0652, 'loss_vowel': 0.055802, 'loss_consonant': 0.037908}\n",
      "   22 | 0.000005 | 155136/160635 | 1.7512 | 1.1814 |\n",
      "val: {'recall': 0.992326, 'recall_grapheme': 0.989248, 'recall_vowel': 0.99503, 'recall_consonant': 0.995777, 'acc_grapheme': 0.988733, 'acc_vowel': 0.995772, 'acc_consonant': 0.996791, 'loss_grapheme': 0.111888, 'loss_vowel': 0.098338, 'loss_consonant': 0.063957}\n",
      "   22 | 0.000005 | 160512/160635 | 1.6967 | 1.1784 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-96cb3a1b9641>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mtrain_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.964754, 'recall_grapheme': 0.945865, 'recall_vowel': 0.981888, 'recall_consonant': 0.985398, 'acc_grapheme': 0.942221, 'acc_vowel': 0.979132, 'acc_consonant': 0.978784, 'loss_grapheme': 0.446205, 'loss_vowel': 0.209152, 'loss_consonant': 0.173068}\n",
      "    0 | 0.000050 | 153600/160635 | 2.0984 | 2.0929 |\n",
      "val: {'recall': 0.987377, 'recall_grapheme': 0.982044, 'recall_vowel': 0.993094, 'recall_consonant': 0.992325, 'acc_grapheme': 0.982763, 'acc_vowel': 0.993732, 'acc_consonant': 0.99423, 'loss_grapheme': 0.182521, 'loss_vowel': 0.127602, 'loss_consonant': 0.087338}\n",
      "** saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000049 | 146688/160635 | 1.1326 | 2.0749 |\n",
      "val: {'recall': 0.988424, 'recall_grapheme': 0.983784, 'recall_vowel': 0.993348, 'recall_consonant': 0.992778, 'acc_grapheme': 0.983808, 'acc_vowel': 0.993682, 'acc_consonant': 0.994478, 'loss_grapheme': 0.193488, 'loss_vowel': 0.145329, 'loss_consonant': 0.100129}\n",
      "** saved\n",
      "    2 | 0.000047 | 139776/160635 | 2.8045 | 2.0387 |\n",
      "val: {'recall': 0.989167, 'recall_grapheme': 0.984252, 'recall_vowel': 0.993671, 'recall_consonant': 0.994493, 'acc_grapheme': 0.984455, 'acc_vowel': 0.994031, 'acc_consonant': 0.994702, 'loss_grapheme': 0.209331, 'loss_vowel': 0.179077, 'loss_consonant': 0.107373}\n",
      "** saved\n",
      "    3 | 0.000043 | 132864/160635 | 1.2420 | 2.0176 |\n",
      "val: {'recall': 0.989761, 'recall_grapheme': 0.985813, 'recall_vowel': 0.993682, 'recall_consonant': 0.993737, 'acc_grapheme': 0.984082, 'acc_vowel': 0.993832, 'acc_consonant': 0.994777, 'loss_grapheme': 0.232536, 'loss_vowel': 0.20679, 'loss_consonant': 0.126389}\n",
      "** saved\n",
      "    4 | 0.000038 | 125952/160635 | 3.6457 | 2.0798 |\n",
      "val: {'recall': 0.990423, 'recall_grapheme': 0.986635, 'recall_vowel': 0.993884, 'recall_consonant': 0.99454, 'acc_grapheme': 0.985649, 'acc_vowel': 0.994578, 'acc_consonant': 0.995299, 'loss_grapheme': 0.200335, 'loss_vowel': 0.172443, 'loss_consonant': 0.108185}\n",
      "** saved\n",
      "    5 | 0.000032 | 119040/160635 | 2.9834 | 1.9523 |\n",
      "val: {'recall': 0.990594, 'recall_grapheme': 0.987053, 'recall_vowel': 0.99377, 'recall_consonant': 0.994501, 'acc_grapheme': 0.984952, 'acc_vowel': 0.99418, 'acc_consonant': 0.995025, 'loss_grapheme': 0.190408, 'loss_vowel': 0.16062, 'loss_consonant': 0.104577}\n",
      "** saved\n",
      "    6 | 0.000026 | 112128/160635 | 2.1653 | 1.8950 |\n",
      "val: {'recall': 0.990268, 'recall_grapheme': 0.986251, 'recall_vowel': 0.994192, 'recall_consonant': 0.99438, 'acc_grapheme': 0.985649, 'acc_vowel': 0.994578, 'acc_consonant': 0.994851, 'loss_grapheme': 0.202262, 'loss_vowel': 0.161758, 'loss_consonant': 0.114197}\n",
      "    7 | 0.000019 | 105216/160635 | 1.8484 | 1.9748 |\n",
      "val: {'recall': 0.990506, 'recall_grapheme': 0.986238, 'recall_vowel': 0.994262, 'recall_consonant': 0.995288, 'acc_grapheme': 0.985624, 'acc_vowel': 0.994802, 'acc_consonant': 0.995349, 'loss_grapheme': 0.220302, 'loss_vowel': 0.198603, 'loss_consonant': 0.122418}\n",
      "    8 | 0.000013 | 098304/160635 | 2.9047 | 2.0395 |\n",
      "val: {'recall': 0.991063, 'recall_grapheme': 0.987412, 'recall_vowel': 0.994528, 'recall_consonant': 0.994899, 'acc_grapheme': 0.986345, 'acc_vowel': 0.994951, 'acc_consonant': 0.995299, 'loss_grapheme': 0.184395, 'loss_vowel': 0.143986, 'loss_consonant': 0.098926}\n",
      "** saved\n",
      "    9 | 0.000008 | 091392/160635 | 2.2288 | 2.0114 |\n",
      "val: {'recall': 0.990775, 'recall_grapheme': 0.986849, 'recall_vowel': 0.994486, 'recall_consonant': 0.994916, 'acc_grapheme': 0.98627, 'acc_vowel': 0.994802, 'acc_consonant': 0.995374, 'loss_grapheme': 0.196372, 'loss_vowel': 0.174174, 'loss_consonant': 0.110719}\n",
      "   10 | 0.000004 | 084480/160635 | 1.9821 | 1.8541 |\n",
      "val: {'recall': 0.991007, 'recall_grapheme': 0.987191, 'recall_vowel': 0.994583, 'recall_consonant': 0.995063, 'acc_grapheme': 0.986619, 'acc_vowel': 0.994976, 'acc_consonant': 0.995772, 'loss_grapheme': 0.156313, 'loss_vowel': 0.110233, 'loss_consonant': 0.08047}\n",
      "   11 | 0.000002 | 077568/160635 | 2.8702 | 2.0045 |\n",
      "val: {'recall': 0.989724, 'recall_grapheme': 0.984943, 'recall_vowel': 0.993956, 'recall_consonant': 0.995056, 'acc_grapheme': 0.984778, 'acc_vowel': 0.994727, 'acc_consonant': 0.995224, 'loss_grapheme': 0.242686, 'loss_vowel': 0.22695, 'loss_consonant': 0.138442}\n",
      "   12 | 0.000001 | 070656/160635 | 1.7060 | 2.0232 |\n",
      "val: {'recall': 0.990641, 'recall_grapheme': 0.986554, 'recall_vowel': 0.994369, 'recall_consonant': 0.995088, 'acc_grapheme': 0.986022, 'acc_vowel': 0.994851, 'acc_consonant': 0.995423, 'loss_grapheme': 0.200908, 'loss_vowel': 0.172463, 'loss_consonant': 0.112499}\n",
      "   13 | 0.000002 | 063744/160635 | 2.3292 | 1.8592 |\n",
      "val: {'recall': 0.991169, 'recall_grapheme': 0.98735, 'recall_vowel': 0.994624, 'recall_consonant': 0.995353, 'acc_grapheme': 0.986693, 'acc_vowel': 0.995125, 'acc_consonant': 0.995871, 'loss_grapheme': 0.160375, 'loss_vowel': 0.133477, 'loss_consonant': 0.087583}\n",
      "** saved\n",
      "   14 | 0.000004 | 056832/160635 | 0.0612 | 1.9618 |\n",
      "val: {'recall': 0.990767, 'recall_grapheme': 0.986638, 'recall_vowel': 0.994407, 'recall_consonant': 0.995385, 'acc_grapheme': 0.986071, 'acc_vowel': 0.995001, 'acc_consonant': 0.995797, 'loss_grapheme': 0.192174, 'loss_vowel': 0.173963, 'loss_consonant': 0.109875}\n",
      "   15 | 0.000008 | 049920/160635 | 0.5936 | 1.9617 |\n",
      "val: {'recall': 0.990466, 'recall_grapheme': 0.985995, 'recall_vowel': 0.99471, 'recall_consonant': 0.995163, 'acc_grapheme': 0.985723, 'acc_vowel': 0.995001, 'acc_consonant': 0.995821, 'loss_grapheme': 0.175538, 'loss_vowel': 0.153657, 'loss_consonant': 0.0985}\n",
      "   16 | 0.000013 | 043008/160635 | 2.8178 | 1.7690 |\n",
      "val: {'recall': 0.991349, 'recall_grapheme': 0.987659, 'recall_vowel': 0.994758, 'recall_consonant': 0.995322, 'acc_grapheme': 0.986967, 'acc_vowel': 0.995025, 'acc_consonant': 0.995871, 'loss_grapheme': 0.155017, 'loss_vowel': 0.119997, 'loss_consonant': 0.085058}\n",
      "** saved\n",
      "   17 | 0.000019 | 036096/160635 | 2.8120 | 2.0654 |\n",
      "val: {'recall': 0.990905, 'recall_grapheme': 0.986919, 'recall_vowel': 0.994825, 'recall_consonant': 0.994958, 'acc_grapheme': 0.986221, 'acc_vowel': 0.994752, 'acc_consonant': 0.995598, 'loss_grapheme': 0.166187, 'loss_vowel': 0.14704, 'loss_consonant': 0.093487}\n",
      "   18 | 0.000025 | 029184/160635 | 1.4609 | 1.7457 |\n",
      "val: {'recall': 0.990732, 'recall_grapheme': 0.986494, 'recall_vowel': 0.995114, 'recall_consonant': 0.994827, 'acc_grapheme': 0.986196, 'acc_vowel': 0.994926, 'acc_consonant': 0.995772, 'loss_grapheme': 0.157143, 'loss_vowel': 0.119111, 'loss_consonant': 0.08303}\n",
      "   19 | 0.000032 | 022272/160635 | 1.2483 | 1.9413 |\n",
      "val: {'recall': 0.990553, 'recall_grapheme': 0.986956, 'recall_vowel': 0.993879, 'recall_consonant': 0.994419, 'acc_grapheme': 0.986569, 'acc_vowel': 0.994503, 'acc_consonant': 0.995573, 'loss_grapheme': 0.151666, 'loss_vowel': 0.12598, 'loss_consonant': 0.085901}\n",
      "   20 | 0.000038 | 015360/160635 | 2.6779 | 2.2857 |\n",
      "val: {'recall': 0.989704, 'recall_grapheme': 0.985493, 'recall_vowel': 0.993821, 'recall_consonant': 0.994009, 'acc_grapheme': 0.984281, 'acc_vowel': 0.994453, 'acc_consonant': 0.995075, 'loss_grapheme': 0.236249, 'loss_vowel': 0.222666, 'loss_consonant': 0.144347}\n",
      "   21 | 0.000043 | 008448/160635 | 1.5217 | 1.5536 |\n",
      "val: {'recall': 0.990666, 'recall_grapheme': 0.986686, 'recall_vowel': 0.994601, 'recall_consonant': 0.994691, 'acc_grapheme': 0.985997, 'acc_vowel': 0.994652, 'acc_consonant': 0.995399, 'loss_grapheme': 0.171085, 'loss_vowel': 0.124168, 'loss_consonant': 0.086401}\n",
      "   22 | 0.000047 | 001536/160635 | 3.2066 | 3.0567 |\n",
      "val: {'recall': 0.990492, 'recall_grapheme': 0.986487, 'recall_vowel': 0.994277, 'recall_consonant': 0.994719, 'acc_grapheme': 0.985052, 'acc_vowel': 0.994702, 'acc_consonant': 0.995249, 'loss_grapheme': 0.224446, 'loss_vowel': 0.191526, 'loss_consonant': 0.122576}\n",
      "   22 | 0.000049 | 155136/160635 | 1.8554 | 2.1544 |\n",
      "val: {'recall': 0.990302, 'recall_grapheme': 0.98672, 'recall_vowel': 0.994281, 'recall_consonant': 0.993485, 'acc_grapheme': 0.985599, 'acc_vowel': 0.994702, 'acc_consonant': 0.99515, 'loss_grapheme': 0.215892, 'loss_vowel': 0.189202, 'loss_consonant': 0.120572}\n",
      "   23 | 0.000050 | 148224/160635 | 2.0992 | 1.8776 |\n",
      "val: {'recall': 0.990689, 'recall_grapheme': 0.987201, 'recall_vowel': 0.99454, 'recall_consonant': 0.993816, 'acc_grapheme': 0.986171, 'acc_vowel': 0.99515, 'acc_consonant': 0.995548, 'loss_grapheme': 0.219697, 'loss_vowel': 0.197142, 'loss_consonant': 0.123991}\n",
      "   24 | 0.000049 | 141312/160635 | 2.5297 | 1.9480 |\n",
      "val: {'recall': 0.989953, 'recall_grapheme': 0.98582, 'recall_vowel': 0.994377, 'recall_consonant': 0.993797, 'acc_grapheme': 0.985549, 'acc_vowel': 0.994553, 'acc_consonant': 0.995274, 'loss_grapheme': 0.171374, 'loss_vowel': 0.139213, 'loss_consonant': 0.095552}\n",
      "   25 | 0.000047 | 134400/160635 | 1.8791 | 1.9123 |\n",
      "val: {'recall': 0.990614, 'recall_grapheme': 0.986846, 'recall_vowel': 0.994665, 'recall_consonant': 0.994102, 'acc_grapheme': 0.984977, 'acc_vowel': 0.994553, 'acc_consonant': 0.995274, 'loss_grapheme': 0.183184, 'loss_vowel': 0.162366, 'loss_consonant': 0.106821}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 0.000043 | 127488/160635 | 0.5985 | 1.9466 |\n",
      "val: {'recall': 0.989934, 'recall_grapheme': 0.985778, 'recall_vowel': 0.994147, 'recall_consonant': 0.994034, 'acc_grapheme': 0.986047, 'acc_vowel': 0.994727, 'acc_consonant': 0.995349, 'loss_grapheme': 0.162728, 'loss_vowel': 0.12239, 'loss_consonant': 0.085427}\n",
      "   27 | 0.000038 | 120576/160635 | 1.7230 | 2.0704 |\n",
      "val: {'recall': 0.990313, 'recall_grapheme': 0.986359, 'recall_vowel': 0.994044, 'recall_consonant': 0.994491, 'acc_grapheme': 0.985375, 'acc_vowel': 0.994926, 'acc_consonant': 0.995374, 'loss_grapheme': 0.184037, 'loss_vowel': 0.165725, 'loss_consonant': 0.102966}\n",
      "   28 | 0.000032 | 113664/160635 | 1.0739 | 1.8342 |\n",
      "val: {'recall': 0.991416, 'recall_grapheme': 0.987833, 'recall_vowel': 0.99478, 'recall_consonant': 0.99522, 'acc_grapheme': 0.986842, 'acc_vowel': 0.9952, 'acc_consonant': 0.995797, 'loss_grapheme': 0.157744, 'loss_vowel': 0.121454, 'loss_consonant': 0.083955}\n",
      "** saved\n",
      "   29 | 0.000026 | 106752/160635 | 3.0117 | 1.9348 |\n",
      "val: {'recall': 0.990286, 'recall_grapheme': 0.98601, 'recall_vowel': 0.993945, 'recall_consonant': 0.99518, 'acc_grapheme': 0.985126, 'acc_vowel': 0.994752, 'acc_consonant': 0.995672, 'loss_grapheme': 0.225487, 'loss_vowel': 0.212966, 'loss_consonant': 0.130689}\n",
      "   30 | 0.000019 | 099840/160635 | 2.4324 | 1.9374 |\n",
      "val: {'recall': 0.990143, 'recall_grapheme': 0.986943, 'recall_vowel': 0.994007, 'recall_consonant': 0.992678, 'acc_grapheme': 0.985947, 'acc_vowel': 0.995025, 'acc_consonant': 0.995423, 'loss_grapheme': 0.174678, 'loss_vowel': 0.172459, 'loss_consonant': 0.10968}\n",
      "   31 | 0.000013 | 092928/160635 | 2.5179 | 1.8186 |\n",
      "val: {'recall': 0.991063, 'recall_grapheme': 0.987596, 'recall_vowel': 0.994182, 'recall_consonant': 0.994877, 'acc_grapheme': 0.986221, 'acc_vowel': 0.995175, 'acc_consonant': 0.995498, 'loss_grapheme': 0.176106, 'loss_vowel': 0.163687, 'loss_consonant': 0.10646}\n",
      "   32 | 0.000008 | 086016/160635 | 1.2306 | 2.0087 |\n",
      "val: {'recall': 0.991392, 'recall_grapheme': 0.987663, 'recall_vowel': 0.994976, 'recall_consonant': 0.995266, 'acc_grapheme': 0.987216, 'acc_vowel': 0.994951, 'acc_consonant': 0.995996, 'loss_grapheme': 0.161904, 'loss_vowel': 0.131151, 'loss_consonant': 0.090145}\n",
      "   33 | 0.000004 | 079104/160635 | 1.2401 | 1.9647 |\n",
      "val: {'recall': 0.991069, 'recall_grapheme': 0.987226, 'recall_vowel': 0.994601, 'recall_consonant': 0.995224, 'acc_grapheme': 0.98627, 'acc_vowel': 0.994926, 'acc_consonant': 0.995722, 'loss_grapheme': 0.181661, 'loss_vowel': 0.164172, 'loss_consonant': 0.102739}\n",
      "   34 | 0.000002 | 072192/160635 | 2.5472 | 1.8938 |\n",
      "val: {'recall': 0.991405, 'recall_grapheme': 0.987973, 'recall_vowel': 0.994403, 'recall_consonant': 0.995272, 'acc_grapheme': 0.987141, 'acc_vowel': 0.995224, 'acc_consonant': 0.995871, 'loss_grapheme': 0.149899, 'loss_vowel': 0.131993, 'loss_consonant': 0.085222}\n",
      "   35 | 0.000001 | 065280/160635 | 1.8364 | 1.8619 |\n",
      "val: {'recall': 0.99144, 'recall_grapheme': 0.988265, 'recall_vowel': 0.994473, 'recall_consonant': 0.994757, 'acc_grapheme': 0.987265, 'acc_vowel': 0.99505, 'acc_consonant': 0.995946, 'loss_grapheme': 0.170764, 'loss_vowel': 0.152117, 'loss_consonant': 0.09882}\n",
      "** saved\n",
      "   36 | 0.000002 | 058368/160635 | 1.7221 | 1.8797 |\n",
      "val: {'recall': 0.990872, 'recall_grapheme': 0.986941, 'recall_vowel': 0.994508, 'recall_consonant': 0.995098, 'acc_grapheme': 0.986146, 'acc_vowel': 0.995175, 'acc_consonant': 0.995573, 'loss_grapheme': 0.198324, 'loss_vowel': 0.176894, 'loss_consonant': 0.115206}\n",
      "   37 | 0.000004 | 051456/160635 | 1.1304 | 1.9060 |\n",
      "val: {'recall': 0.991643, 'recall_grapheme': 0.987994, 'recall_vowel': 0.995136, 'recall_consonant': 0.995447, 'acc_grapheme': 0.987439, 'acc_vowel': 0.99515, 'acc_consonant': 0.996095, 'loss_grapheme': 0.16107, 'loss_vowel': 0.121419, 'loss_consonant': 0.08749}\n",
      "** saved\n",
      "   38 | 0.000008 | 044544/160635 | 0.4692 | 1.8482 |\n",
      "val: {'recall': 0.99158, 'recall_grapheme': 0.988258, 'recall_vowel': 0.994661, 'recall_consonant': 0.995142, 'acc_grapheme': 0.986768, 'acc_vowel': 0.9951, 'acc_consonant': 0.995821, 'loss_grapheme': 0.159497, 'loss_vowel': 0.142336, 'loss_consonant': 0.090999}\n",
      "   39 | 0.000013 | 037632/160635 | 1.7432 | 2.0209 |\n",
      "val: {'recall': 0.990899, 'recall_grapheme': 0.987077, 'recall_vowel': 0.994286, 'recall_consonant': 0.995153, 'acc_grapheme': 0.986544, 'acc_vowel': 0.994951, 'acc_consonant': 0.995946, 'loss_grapheme': 0.179162, 'loss_vowel': 0.160039, 'loss_consonant': 0.105944}\n",
      "   40 | 0.000019 | 030720/160635 | 1.8463 | 1.9510 |\n",
      "val: {'recall': 0.990469, 'recall_grapheme': 0.986337, 'recall_vowel': 0.994287, 'recall_consonant': 0.994913, 'acc_grapheme': 0.986519, 'acc_vowel': 0.994876, 'acc_consonant': 0.995548, 'loss_grapheme': 0.172916, 'loss_vowel': 0.124774, 'loss_consonant': 0.096873}\n",
      "   41 | 0.000025 | 023808/160635 | 2.2128 | 1.8930 |\n",
      "val: {'recall': 0.990238, 'recall_grapheme': 0.986142, 'recall_vowel': 0.993999, 'recall_consonant': 0.994669, 'acc_grapheme': 0.985599, 'acc_vowel': 0.994802, 'acc_consonant': 0.995473, 'loss_grapheme': 0.201585, 'loss_vowel': 0.18779, 'loss_consonant': 0.116186}\n",
      "   42 | 0.000032 | 016896/160635 | 1.8880 | 1.9265 |\n",
      "val: {'recall': 0.989376, 'recall_grapheme': 0.984782, 'recall_vowel': 0.99385, 'recall_consonant': 0.994091, 'acc_grapheme': 0.985947, 'acc_vowel': 0.994702, 'acc_consonant': 0.995598, 'loss_grapheme': 0.186808, 'loss_vowel': 0.147447, 'loss_consonant': 0.105695}\n",
      "   43 | 0.000038 | 009984/160635 | 2.4935 | 2.1532 |\n",
      "val: {'recall': 0.990472, 'recall_grapheme': 0.986784, 'recall_vowel': 0.993842, 'recall_consonant': 0.994477, 'acc_grapheme': 0.985823, 'acc_vowel': 0.994652, 'acc_consonant': 0.9952, 'loss_grapheme': 0.213388, 'loss_vowel': 0.197406, 'loss_consonant': 0.122146}\n",
      "   44 | 0.000043 | 003072/160635 | 3.2355 | 2.9731 |\n",
      "val: {'recall': 0.990282, 'recall_grapheme': 0.986014, 'recall_vowel': 0.99469, 'recall_consonant': 0.99441, 'acc_grapheme': 0.985723, 'acc_vowel': 0.994976, 'acc_consonant': 0.995224, 'loss_grapheme': 0.223039, 'loss_vowel': 0.193232, 'loss_consonant': 0.130942}\n",
      "   44 | 0.000047 | 156672/160635 | 2.4006 | 2.0095 |\n",
      "val: {'recall': 0.990948, 'recall_grapheme': 0.987093, 'recall_vowel': 0.99417, 'recall_consonant': 0.995436, 'acc_grapheme': 0.986295, 'acc_vowel': 0.994802, 'acc_consonant': 0.995399, 'loss_grapheme': 0.194765, 'loss_vowel': 0.177229, 'loss_consonant': 0.108301}\n",
      "   45 | 0.000049 | 149760/160635 | 1.8763 | 1.9096 |\n",
      "val: {'recall': 0.98793, 'recall_grapheme': 0.983671, 'recall_vowel': 0.992799, 'recall_consonant': 0.99158, 'acc_grapheme': 0.984355, 'acc_vowel': 0.993981, 'acc_consonant': 0.994429, 'loss_grapheme': 0.175348, 'loss_vowel': 0.099837, 'loss_consonant': 0.084707}\n",
      "   46 | 0.000050 | 142848/160635 | 1.2976 | 1.8494 |\n",
      "val: {'recall': 0.989464, 'recall_grapheme': 0.984493, 'recall_vowel': 0.994215, 'recall_consonant': 0.994655, 'acc_grapheme': 0.984629, 'acc_vowel': 0.994777, 'acc_consonant': 0.9952, 'loss_grapheme': 0.189093, 'loss_vowel': 0.160917, 'loss_consonant': 0.10089}\n",
      "   47 | 0.000049 | 135936/160635 | 1.4091 | 1.8197 |\n",
      "val: {'recall': 0.989473, 'recall_grapheme': 0.984647, 'recall_vowel': 0.993588, 'recall_consonant': 0.99501, 'acc_grapheme': 0.985201, 'acc_vowel': 0.994429, 'acc_consonant': 0.995573, 'loss_grapheme': 0.18145, 'loss_vowel': 0.128929, 'loss_consonant': 0.098226}\n",
      "   48 | 0.000047 | 129024/160635 | 2.1245 | 1.9737 |\n",
      "val: {'recall': 0.990621, 'recall_grapheme': 0.98702, 'recall_vowel': 0.994278, 'recall_consonant': 0.994167, 'acc_grapheme': 0.985897, 'acc_vowel': 0.994901, 'acc_consonant': 0.995448, 'loss_grapheme': 0.187264, 'loss_vowel': 0.149475, 'loss_consonant': 0.102552}\n",
      "   49 | 0.000043 | 122112/160635 | 2.6276 | 2.0124 |\n",
      "val: {'recall': 0.989676, 'recall_grapheme': 0.985465, 'recall_vowel': 0.993352, 'recall_consonant': 0.994425, 'acc_grapheme': 0.984927, 'acc_vowel': 0.994752, 'acc_consonant': 0.994827, 'loss_grapheme': 0.237684, 'loss_vowel': 0.220041, 'loss_consonant': 0.141644}\n",
      "   49 | 0.000038 | 145920/160635 | 2.4165 | 2.0246 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-1b14c80fc192>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mtrain_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;31m#do_mixup = False #(np.random.random() < 0.4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.997401, 'recall_grapheme': 0.996331, 'recall_vowel': 0.998438, 'recall_consonant': 0.998503, 'acc_grapheme': 0.995961, 'acc_vowel': 0.998479, 'acc_consonant': 0.998354, 'loss_grapheme': 0.019338, 'loss_vowel': 0.009742, 'loss_consonant': 0.007437}\n",
      "    0 | 0.000050 | 153600/160735 | 1.1514 | 1.0147 |\n",
      "val: {'recall': 0.99651, 'recall_grapheme': 0.994837, 'recall_vowel': 0.99797, 'recall_consonant': 0.998399, 'acc_grapheme': 0.994664, 'acc_vowel': 0.997905, 'acc_consonant': 0.997905, 'loss_grapheme': 0.033601, 'loss_vowel': 0.019487, 'loss_consonant': 0.013147}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000049 | 146688/160735 | 1.7823 | 1.1079 |\n",
      "val: {'recall': 0.99458, 'recall_grapheme': 0.992724, 'recall_vowel': 0.997169, 'recall_consonant': 0.995701, 'acc_grapheme': 0.99227, 'acc_vowel': 0.997507, 'acc_consonant': 0.997357, 'loss_grapheme': 0.05443, 'loss_vowel': 0.035074, 'loss_consonant': 0.024806}\n",
      "    2 | 0.000047 | 139776/160735 | 1.3825 | 0.9587 |\n",
      "val: {'recall': 0.996538, 'recall_grapheme': 0.995082, 'recall_vowel': 0.997917, 'recall_consonant': 0.998071, 'acc_grapheme': 0.995287, 'acc_vowel': 0.99803, 'acc_consonant': 0.998105, 'loss_grapheme': 0.026622, 'loss_vowel': 0.015517, 'loss_consonant': 0.010374}\n",
      "    3 | 0.000043 | 132864/160735 | 0.2587 | 0.9630 |\n",
      "val: {'recall': 0.993723, 'recall_grapheme': 0.991549, 'recall_vowel': 0.99695, 'recall_consonant': 0.994846, 'acc_grapheme': 0.991772, 'acc_vowel': 0.997133, 'acc_consonant': 0.997058, 'loss_grapheme': 0.044781, 'loss_vowel': 0.020896, 'loss_consonant': 0.016922}\n",
      "    4 | 0.000038 | 125952/160735 | 2.5432 | 1.1234 |\n",
      "val: {'recall': 0.99538, 'recall_grapheme': 0.99326, 'recall_vowel': 0.997472, 'recall_consonant': 0.997526, 'acc_grapheme': 0.992594, 'acc_vowel': 0.997806, 'acc_consonant': 0.997507, 'loss_grapheme': 0.044333, 'loss_vowel': 0.025633, 'loss_consonant': 0.020239}\n",
      "    5 | 0.000032 | 119040/160735 | 1.1159 | 1.0655 |\n",
      "val: {'recall': 0.996019, 'recall_grapheme': 0.994087, 'recall_vowel': 0.997696, 'recall_consonant': 0.998204, 'acc_grapheme': 0.993492, 'acc_vowel': 0.997731, 'acc_consonant': 0.997706, 'loss_grapheme': 0.032473, 'loss_vowel': 0.015456, 'loss_consonant': 0.012151}\n",
      "    6 | 0.000026 | 112128/160735 | 2.5789 | 0.9249 |\n",
      "val: {'recall': 0.996396, 'recall_grapheme': 0.994412, 'recall_vowel': 0.998192, 'recall_consonant': 0.998569, 'acc_grapheme': 0.994215, 'acc_vowel': 0.998055, 'acc_consonant': 0.99808, 'loss_grapheme': 0.037921, 'loss_vowel': 0.023979, 'loss_consonant': 0.017272}\n",
      "    7 | 0.000019 | 105216/160735 | 0.0035 | 0.9534 |\n",
      "val: {'recall': 0.996792, 'recall_grapheme': 0.995277, 'recall_vowel': 0.998079, 'recall_consonant': 0.998534, 'acc_grapheme': 0.994689, 'acc_vowel': 0.998155, 'acc_consonant': 0.998155, 'loss_grapheme': 0.025805, 'loss_vowel': 0.013773, 'loss_consonant': 0.009988}\n",
      "    8 | 0.000013 | 098304/160735 | 2.8361 | 1.1136 |\n",
      "val: {'recall': 0.99488, 'recall_grapheme': 0.992312, 'recall_vowel': 0.99735, 'recall_consonant': 0.997545, 'acc_grapheme': 0.991772, 'acc_vowel': 0.997507, 'acc_consonant': 0.997407, 'loss_grapheme': 0.057359, 'loss_vowel': 0.036543, 'loss_consonant': 0.02766}\n",
      "    9 | 0.000008 | 091392/160735 | 0.0185 | 1.0339 |\n",
      "val: {'recall': 0.9973, 'recall_grapheme': 0.995942, 'recall_vowel': 0.998435, 'recall_consonant': 0.998884, 'acc_grapheme': 0.995587, 'acc_vowel': 0.998404, 'acc_consonant': 0.998354, 'loss_grapheme': 0.023439, 'loss_vowel': 0.012709, 'loss_consonant': 0.009255}\n",
      "   10 | 0.000004 | 084480/160735 | 0.5566 | 0.9784 |\n",
      "val: {'recall': 0.996972, 'recall_grapheme': 0.995492, 'recall_vowel': 0.998214, 'recall_consonant': 0.99869, 'acc_grapheme': 0.994913, 'acc_vowel': 0.998205, 'acc_consonant': 0.99823, 'loss_grapheme': 0.024109, 'loss_vowel': 0.011027, 'loss_consonant': 0.00846}\n",
      "   11 | 0.000002 | 077568/160735 | 1.8015 | 1.0796 |\n",
      "val: {'recall': 0.995146, 'recall_grapheme': 0.992592, 'recall_vowel': 0.997367, 'recall_consonant': 0.998031, 'acc_grapheme': 0.992096, 'acc_vowel': 0.997581, 'acc_consonant': 0.997357, 'loss_grapheme': 0.042653, 'loss_vowel': 0.021956, 'loss_consonant': 0.017764}\n",
      "   12 | 0.000001 | 070656/160735 | 1.3234 | 1.1175 |\n",
      "val: {'recall': 0.995577, 'recall_grapheme': 0.993816, 'recall_vowel': 0.997739, 'recall_consonant': 0.996937, 'acc_grapheme': 0.993293, 'acc_vowel': 0.997706, 'acc_consonant': 0.997631, 'loss_grapheme': 0.034096, 'loss_vowel': 0.015168, 'loss_consonant': 0.012127}\n",
      "   13 | 0.000002 | 063744/160735 | 0.0014 | 0.9030 |\n",
      "val: {'recall': 0.996932, 'recall_grapheme': 0.995501, 'recall_vowel': 0.998044, 'recall_consonant': 0.998682, 'acc_grapheme': 0.995088, 'acc_vowel': 0.99818, 'acc_consonant': 0.998304, 'loss_grapheme': 0.022868, 'loss_vowel': 0.011626, 'loss_consonant': 0.008752}\n",
      "   14 | 0.000004 | 056832/160735 | 0.0016 | 1.1350 |\n",
      "val: {'recall': 0.995874, 'recall_grapheme': 0.993879, 'recall_vowel': 0.997571, 'recall_consonant': 0.998165, 'acc_grapheme': 0.993243, 'acc_vowel': 0.997756, 'acc_consonant': 0.997706, 'loss_grapheme': 0.03637, 'loss_vowel': 0.018545, 'loss_consonant': 0.014745}\n",
      "   15 | 0.000008 | 049920/160735 | 2.4699 | 0.8856 |\n",
      "val: {'recall': 0.995398, 'recall_grapheme': 0.993136, 'recall_vowel': 0.997216, 'recall_consonant': 0.998105, 'acc_grapheme': 0.99247, 'acc_vowel': 0.997556, 'acc_consonant': 0.997581, 'loss_grapheme': 0.037482, 'loss_vowel': 0.019573, 'loss_consonant': 0.015538}\n",
      "   16 | 0.000013 | 043008/160735 | 0.0021 | 1.1055 |\n",
      "val: {'recall': 0.996522, 'recall_grapheme': 0.995281, 'recall_vowel': 0.998011, 'recall_consonant': 0.997516, 'acc_grapheme': 0.994888, 'acc_vowel': 0.99823, 'acc_consonant': 0.998005, 'loss_grapheme': 0.028909, 'loss_vowel': 0.01606, 'loss_consonant': 0.012234}\n",
      "   17 | 0.000019 | 036096/160735 | 0.0029 | 0.9851 |\n",
      "val: {'recall': 0.996395, 'recall_grapheme': 0.994541, 'recall_vowel': 0.998004, 'recall_consonant': 0.998492, 'acc_grapheme': 0.994016, 'acc_vowel': 0.99813, 'acc_consonant': 0.998005, 'loss_grapheme': 0.029152, 'loss_vowel': 0.013014, 'loss_consonant': 0.010309}\n",
      "   18 | 0.000025 | 029184/160735 | 1.6661 | 0.9717 |\n",
      "val: {'recall': 0.996652, 'recall_grapheme': 0.994887, 'recall_vowel': 0.998282, 'recall_consonant': 0.99855, 'acc_grapheme': 0.99444, 'acc_vowel': 0.998429, 'acc_consonant': 0.99813, 'loss_grapheme': 0.029963, 'loss_vowel': 0.014678, 'loss_consonant': 0.011607}\n",
      "   19 | 0.000032 | 022272/160735 | 2.0672 | 1.2453 |\n",
      "val: {'recall': 0.995332, 'recall_grapheme': 0.993332, 'recall_vowel': 0.997505, 'recall_consonant': 0.997159, 'acc_grapheme': 0.992594, 'acc_vowel': 0.997556, 'acc_consonant': 0.997881, 'loss_grapheme': 0.043992, 'loss_vowel': 0.024203, 'loss_consonant': 0.01807}\n",
      "   20 | 0.000038 | 015360/160735 | 1.0206 | 0.6559 |\n",
      "val: {'recall': 0.996359, 'recall_grapheme': 0.994959, 'recall_vowel': 0.997771, 'recall_consonant': 0.997748, 'acc_grapheme': 0.99424, 'acc_vowel': 0.997831, 'acc_consonant': 0.997856, 'loss_grapheme': 0.027228, 'loss_vowel': 0.01198, 'loss_consonant': 0.008978}\n",
      "   21 | 0.000043 | 008448/160735 | 2.3098 | 1.3730 |\n",
      "val: {'recall': 0.995084, 'recall_grapheme': 0.992522, 'recall_vowel': 0.997108, 'recall_consonant': 0.998185, 'acc_grapheme': 0.991971, 'acc_vowel': 0.997457, 'acc_consonant': 0.997457, 'loss_grapheme': 0.036552, 'loss_vowel': 0.01526, 'loss_consonant': 0.01258}\n",
      "   22 | 0.000047 | 001536/160735 | 1.3932 | 1.3458 |\n",
      "val: {'recall': 0.996106, 'recall_grapheme': 0.994257, 'recall_vowel': 0.997741, 'recall_consonant': 0.998168, 'acc_grapheme': 0.993417, 'acc_vowel': 0.997856, 'acc_consonant': 0.997781, 'loss_grapheme': 0.036373, 'loss_vowel': 0.019158, 'loss_consonant': 0.014209}\n",
      "   22 | 0.000049 | 155136/160735 | 1.5757 | 0.9878 |\n",
      "val: {'recall': 0.995662, 'recall_grapheme': 0.993775, 'recall_vowel': 0.99791, 'recall_consonant': 0.99719, 'acc_grapheme': 0.993193, 'acc_vowel': 0.997731, 'acc_consonant': 0.997731, 'loss_grapheme': 0.032904, 'loss_vowel': 0.013551, 'loss_consonant': 0.010688}\n",
      "   23 | 0.000050 | 148224/160735 | 0.0102 | 0.9021 |\n",
      "val: {'recall': 0.996222, 'recall_grapheme': 0.994458, 'recall_vowel': 0.997732, 'recall_consonant': 0.99824, 'acc_grapheme': 0.994165, 'acc_vowel': 0.99798, 'acc_consonant': 0.997856, 'loss_grapheme': 0.032726, 'loss_vowel': 0.018083, 'loss_consonant': 0.013194}\n",
      "   24 | 0.000049 | 141312/160735 | 1.7406 | 1.0371 |\n",
      "val: {'recall': 0.995879, 'recall_grapheme': 0.993693, 'recall_vowel': 0.997792, 'recall_consonant': 0.998339, 'acc_grapheme': 0.992869, 'acc_vowel': 0.997856, 'acc_consonant': 0.997232, 'loss_grapheme': 0.035797, 'loss_vowel': 0.014981, 'loss_consonant': 0.014016}\n",
      "   25 | 0.000047 | 134400/160735 | 0.0081 | 0.9641 |\n",
      "val: {'recall': 0.996735, 'recall_grapheme': 0.995084, 'recall_vowel': 0.998209, 'recall_consonant': 0.99856, 'acc_grapheme': 0.994689, 'acc_vowel': 0.998255, 'acc_consonant': 0.998105, 'loss_grapheme': 0.036571, 'loss_vowel': 0.02453, 'loss_consonant': 0.017707}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 0.000043 | 127488/160735 | 0.0047 | 0.9961 |\n",
      "val: {'recall': 0.996007, 'recall_grapheme': 0.994401, 'recall_vowel': 0.997091, 'recall_consonant': 0.998135, 'acc_grapheme': 0.993941, 'acc_vowel': 0.997681, 'acc_consonant': 0.997881, 'loss_grapheme': 0.030932, 'loss_vowel': 0.016257, 'loss_consonant': 0.012754}\n",
      "   27 | 0.000038 | 120576/160735 | 2.9881 | 1.1158 |\n",
      "val: {'recall': 0.994956, 'recall_grapheme': 0.992688, 'recall_vowel': 0.997026, 'recall_consonant': 0.997421, 'acc_grapheme': 0.992046, 'acc_vowel': 0.997531, 'acc_consonant': 0.997507, 'loss_grapheme': 0.04463, 'loss_vowel': 0.02532, 'loss_consonant': 0.018043}\n",
      "   28 | 0.000032 | 113664/160735 | 1.9251 | 0.9913 |\n",
      "val: {'recall': 0.991583, 'recall_grapheme': 0.989058, 'recall_vowel': 0.996288, 'recall_consonant': 0.99193, 'acc_grapheme': 0.98843, 'acc_vowel': 0.996559, 'acc_consonant': 0.996035, 'loss_grapheme': 0.049937, 'loss_vowel': 0.01845, 'loss_consonant': 0.016871}\n",
      "   29 | 0.000026 | 106752/160735 | 0.0038 | 1.2365 |\n",
      "val: {'recall': 0.996073, 'recall_grapheme': 0.994595, 'recall_vowel': 0.997703, 'recall_consonant': 0.997399, 'acc_grapheme': 0.993991, 'acc_vowel': 0.99793, 'acc_consonant': 0.997955, 'loss_grapheme': 0.033835, 'loss_vowel': 0.019232, 'loss_consonant': 0.014322}\n",
      "   30 | 0.000019 | 099840/160735 | 0.0007 | 1.0111 |\n",
      "val: {'recall': 0.995716, 'recall_grapheme': 0.993589, 'recall_vowel': 0.997354, 'recall_consonant': 0.998333, 'acc_grapheme': 0.993342, 'acc_vowel': 0.997706, 'acc_consonant': 0.997706, 'loss_grapheme': 0.030459, 'loss_vowel': 0.013773, 'loss_consonant': 0.011095}\n",
      "   31 | 0.000013 | 092928/160735 | 0.0027 | 0.9680 |\n",
      "val: {'recall': 0.995521, 'recall_grapheme': 0.993295, 'recall_vowel': 0.997227, 'recall_consonant': 0.998267, 'acc_grapheme': 0.992794, 'acc_vowel': 0.997656, 'acc_consonant': 0.997656, 'loss_grapheme': 0.03571, 'loss_vowel': 0.0171, 'loss_consonant': 0.013683}\n",
      "   32 | 0.000008 | 086016/160735 | 1.3120 | 0.9159 |\n",
      "val: {'recall': 0.996666, 'recall_grapheme': 0.995015, 'recall_vowel': 0.997976, 'recall_consonant': 0.998659, 'acc_grapheme': 0.994091, 'acc_vowel': 0.99793, 'acc_consonant': 0.998205, 'loss_grapheme': 0.025789, 'loss_vowel': 0.010477, 'loss_consonant': 0.008175}\n",
      "   33 | 0.000004 | 079104/160735 | 0.0032 | 0.9568 |\n",
      "val: {'recall': 0.995031, 'recall_grapheme': 0.992482, 'recall_vowel': 0.996974, 'recall_consonant': 0.998186, 'acc_grapheme': 0.992171, 'acc_vowel': 0.997482, 'acc_consonant': 0.997407, 'loss_grapheme': 0.037634, 'loss_vowel': 0.017966, 'loss_consonant': 0.014746}\n",
      "   34 | 0.000002 | 072192/160735 | 0.0025 | 1.0051 |\n",
      "val: {'recall': 0.995361, 'recall_grapheme': 0.992971, 'recall_vowel': 0.997257, 'recall_consonant': 0.998244, 'acc_grapheme': 0.992719, 'acc_vowel': 0.997681, 'acc_consonant': 0.997656, 'loss_grapheme': 0.03504, 'loss_vowel': 0.017233, 'loss_consonant': 0.013143}\n",
      "   35 | 0.000001 | 065280/160735 | 0.0011 | 1.0066 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-96cb3a1b9641>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;31m#print('train:', train_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m#save_model(model, model_file+'_latest')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-0e344cb1f778>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.994807, 'recall_grapheme': 0.993211, 'recall_vowel': 0.997174, 'recall_consonant': 0.995633, 'acc_grapheme': 0.992968, 'acc_vowel': 0.997357, 'acc_consonant': 0.997033, 'loss_grapheme': 0.136084, 'loss_vowel': 0.089044, 'loss_consonant': 0.061338}\n",
      "    0 | 0.000100 | 153600/160735 | 0.0037 | 1.1513 |\n",
      "val: {'recall': 0.989714, 'recall_grapheme': 0.984654, 'recall_vowel': 0.994842, 'recall_consonant': 0.994707, 'acc_grapheme': 0.985538, 'acc_vowel': 0.995287, 'acc_consonant': 0.99424, 'loss_grapheme': 0.103949, 'loss_vowel': 0.063651, 'loss_consonant': 0.046677}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000098 | 146688/160735 | 1.0486 | 1.0954 |\n",
      "val: {'recall': 0.992231, 'recall_grapheme': 0.989128, 'recall_vowel': 0.995653, 'recall_consonant': 0.995015, 'acc_grapheme': 0.988854, 'acc_vowel': 0.99616, 'acc_consonant': 0.995537, 'loss_grapheme': 0.10485, 'loss_vowel': 0.072468, 'loss_consonant': 0.047801}\n",
      "    2 | 0.000093 | 139776/160735 | 1.8618 | 1.0786 |\n",
      "val: {'recall': 0.992574, 'recall_grapheme': 0.989244, 'recall_vowel': 0.995393, 'recall_consonant': 0.996413, 'acc_grapheme': 0.989602, 'acc_vowel': 0.99606, 'acc_consonant': 0.995886, 'loss_grapheme': 0.117554, 'loss_vowel': 0.077483, 'loss_consonant': 0.056601}\n",
      "    3 | 0.000086 | 132864/160735 | 1.5228 | 1.0907 |\n",
      "val: {'recall': 0.993971, 'recall_grapheme': 0.991248, 'recall_vowel': 0.996915, 'recall_consonant': 0.996473, 'acc_grapheme': 0.99045, 'acc_vowel': 0.997008, 'acc_consonant': 0.996584, 'loss_grapheme': 0.080691, 'loss_vowel': 0.054964, 'loss_consonant': 0.03495}\n",
      "    4 | 0.000075 | 125952/160735 | 0.0120 | 1.0546 |\n",
      "val: {'recall': 0.994052, 'recall_grapheme': 0.991836, 'recall_vowel': 0.995866, 'recall_consonant': 0.996668, 'acc_grapheme': 0.991048, 'acc_vowel': 0.996559, 'acc_consonant': 0.996384, 'loss_grapheme': 0.077188, 'loss_vowel': 0.057015, 'loss_consonant': 0.036131}\n",
      "    5 | 0.000063 | 119040/160735 | 0.0152 | 1.0722 |\n",
      "val: {'recall': 0.993917, 'recall_grapheme': 0.991149, 'recall_vowel': 0.99677, 'recall_consonant': 0.996602, 'acc_grapheme': 0.991398, 'acc_vowel': 0.997232, 'acc_consonant': 0.996684, 'loss_grapheme': 0.051953, 'loss_vowel': 0.0285, 'loss_consonant': 0.021605}\n",
      "    6 | 0.000051 | 112128/160735 | 2.2854 | 1.0423 |\n",
      "val: {'recall': 0.993625, 'recall_grapheme': 0.990769, 'recall_vowel': 0.996654, 'recall_consonant': 0.996307, 'acc_grapheme': 0.990101, 'acc_vowel': 0.997033, 'acc_consonant': 0.996783, 'loss_grapheme': 0.076819, 'loss_vowel': 0.058799, 'loss_consonant': 0.03788}\n",
      "    7 | 0.000038 | 105216/160735 | 2.0716 | 1.0782 |\n",
      "val: {'recall': 0.993245, 'recall_grapheme': 0.990386, 'recall_vowel': 0.995708, 'recall_consonant': 0.996499, 'acc_grapheme': 0.989727, 'acc_vowel': 0.996783, 'acc_consonant': 0.99616, 'loss_grapheme': 0.083216, 'loss_vowel': 0.065159, 'loss_consonant': 0.041191}\n",
      "    8 | 0.000026 | 098304/160735 | 2.3781 | 1.0269 |\n",
      "val: {'recall': 0.994032, 'recall_grapheme': 0.991273, 'recall_vowel': 0.996649, 'recall_consonant': 0.996932, 'acc_grapheme': 0.991248, 'acc_vowel': 0.997257, 'acc_consonant': 0.996783, 'loss_grapheme': 0.09937, 'loss_vowel': 0.073113, 'loss_consonant': 0.044911}\n",
      "    9 | 0.000015 | 091392/160735 | 2.2113 | 0.9876 |\n",
      "val: {'recall': 0.993716, 'recall_grapheme': 0.990596, 'recall_vowel': 0.996697, 'recall_consonant': 0.996975, 'acc_grapheme': 0.989926, 'acc_vowel': 0.997382, 'acc_consonant': 0.996559, 'loss_grapheme': 0.108188, 'loss_vowel': 0.082297, 'loss_consonant': 0.051967}\n",
      "   10 | 0.000008 | 084480/160735 | 1.9757 | 1.1030 |\n",
      "val: {'recall': 0.994492, 'recall_grapheme': 0.991983, 'recall_vowel': 0.996923, 'recall_consonant': 0.997079, 'acc_grapheme': 0.991522, 'acc_vowel': 0.997531, 'acc_consonant': 0.996783, 'loss_grapheme': 0.07975, 'loss_vowel': 0.063118, 'loss_consonant': 0.040505}\n",
      "   11 | 0.000003 | 077568/160735 | 2.7464 | 1.1546 |\n",
      "val: {'recall': 0.993916, 'recall_grapheme': 0.990996, 'recall_vowel': 0.996778, 'recall_consonant': 0.996891, 'acc_grapheme': 0.9903, 'acc_vowel': 0.997282, 'acc_consonant': 0.996584, 'loss_grapheme': 0.090654, 'loss_vowel': 0.071806, 'loss_consonant': 0.047088}\n",
      "   12 | 0.000001 | 070656/160735 | 0.0156 | 1.2683 |\n",
      "val: {'recall': 0.994237, 'recall_grapheme': 0.991562, 'recall_vowel': 0.996942, 'recall_consonant': 0.996881, 'acc_grapheme': 0.991747, 'acc_vowel': 0.997357, 'acc_consonant': 0.996734, 'loss_grapheme': 0.086761, 'loss_vowel': 0.069873, 'loss_consonant': 0.042757}\n",
      "   13 | 0.000003 | 063744/160735 | 2.0404 | 1.0652 |\n",
      "val: {'recall': 0.994753, 'recall_grapheme': 0.992144, 'recall_vowel': 0.997283, 'recall_consonant': 0.997441, 'acc_grapheme': 0.991772, 'acc_vowel': 0.997606, 'acc_consonant': 0.996933, 'loss_grapheme': 0.065674, 'loss_vowel': 0.047285, 'loss_consonant': 0.031846}\n",
      "   14 | 0.000008 | 056832/160735 | 0.0070 | 1.0874 |\n",
      "val: {'recall': 0.994471, 'recall_grapheme': 0.991912, 'recall_vowel': 0.996942, 'recall_consonant': 0.997119, 'acc_grapheme': 0.991472, 'acc_vowel': 0.997531, 'acc_consonant': 0.997083, 'loss_grapheme': 0.073287, 'loss_vowel': 0.055092, 'loss_consonant': 0.037209}\n",
      "   15 | 0.000015 | 049920/160735 | 0.8218 | 1.1787 |\n",
      "val: {'recall': 0.9945, 'recall_grapheme': 0.992016, 'recall_vowel': 0.996962, 'recall_consonant': 0.997006, 'acc_grapheme': 0.991921, 'acc_vowel': 0.997581, 'acc_consonant': 0.996958, 'loss_grapheme': 0.065, 'loss_vowel': 0.048012, 'loss_consonant': 0.032635}\n",
      "   16 | 0.000026 | 043008/160735 | 0.0085 | 1.0975 |\n",
      "val: {'recall': 0.994415, 'recall_grapheme': 0.991757, 'recall_vowel': 0.996786, 'recall_consonant': 0.99736, 'acc_grapheme': 0.991298, 'acc_vowel': 0.997382, 'acc_consonant': 0.996808, 'loss_grapheme': 0.093619, 'loss_vowel': 0.068998, 'loss_consonant': 0.047023}\n",
      "   17 | 0.000038 | 036096/160735 | 1.6247 | 1.0230 |\n",
      "val: {'recall': 0.994397, 'recall_grapheme': 0.99193, 'recall_vowel': 0.996907, 'recall_consonant': 0.996821, 'acc_grapheme': 0.991672, 'acc_vowel': 0.997357, 'acc_consonant': 0.996709, 'loss_grapheme': 0.076806, 'loss_vowel': 0.061161, 'loss_consonant': 0.039951}\n",
      "   18 | 0.000050 | 029184/160735 | 0.0461 | 0.8560 |\n",
      "val: {'recall': 0.994698, 'recall_grapheme': 0.992486, 'recall_vowel': 0.996809, 'recall_consonant': 0.997014, 'acc_grapheme': 0.99222, 'acc_vowel': 0.997332, 'acc_consonant': 0.997257, 'loss_grapheme': 0.052077, 'loss_vowel': 0.033389, 'loss_consonant': 0.023695}\n",
      "   19 | 0.000063 | 022272/160735 | 2.3509 | 1.0716 |\n",
      "val: {'recall': 0.993025, 'recall_grapheme': 0.989535, 'recall_vowel': 0.996445, 'recall_consonant': 0.996586, 'acc_grapheme': 0.989652, 'acc_vowel': 0.996958, 'acc_consonant': 0.996534, 'loss_grapheme': 0.076393, 'loss_vowel': 0.052507, 'loss_consonant': 0.036232}\n",
      "   20 | 0.000075 | 015360/160735 | 0.0234 | 0.9504 |\n",
      "val: {'recall': 0.994223, 'recall_grapheme': 0.991905, 'recall_vowel': 0.997274, 'recall_consonant': 0.995808, 'acc_grapheme': 0.991772, 'acc_vowel': 0.997232, 'acc_consonant': 0.996908, 'loss_grapheme': 0.045627, 'loss_vowel': 0.028278, 'loss_consonant': 0.020925}\n",
      "   21 | 0.000086 | 008448/160735 | 0.0133 | 1.0647 |\n",
      "val: {'recall': 0.994993, 'recall_grapheme': 0.992824, 'recall_vowel': 0.997431, 'recall_consonant': 0.996892, 'acc_grapheme': 0.992295, 'acc_vowel': 0.997282, 'acc_consonant': 0.996409, 'loss_grapheme': 0.050574, 'loss_vowel': 0.029809, 'loss_consonant': 0.023255}\n",
      "** saved\n",
      "   22 | 0.000093 | 001536/160735 | 0.0191 | 1.1889 |\n",
      "val: {'recall': 0.99406, 'recall_grapheme': 0.991197, 'recall_vowel': 0.997133, 'recall_consonant': 0.996711, 'acc_grapheme': 0.990749, 'acc_vowel': 0.997157, 'acc_consonant': 0.996384, 'loss_grapheme': 0.057186, 'loss_vowel': 0.033358, 'loss_consonant': 0.026183}\n",
      "   22 | 0.000098 | 155136/160735 | 2.3576 | 1.1280 |\n",
      "val: {'recall': 0.994078, 'recall_grapheme': 0.991763, 'recall_vowel': 0.99717, 'recall_consonant': 0.995617, 'acc_grapheme': 0.99055, 'acc_vowel': 0.997382, 'acc_consonant': 0.997058, 'loss_grapheme': 0.088167, 'loss_vowel': 0.057682, 'loss_consonant': 0.041471}\n",
      "   23 | 0.000100 | 148224/160735 | 1.9181 | 1.1385 |\n",
      "val: {'recall': 0.993811, 'recall_grapheme': 0.991701, 'recall_vowel': 0.996484, 'recall_consonant': 0.99536, 'acc_grapheme': 0.992295, 'acc_vowel': 0.997058, 'acc_consonant': 0.996759, 'loss_grapheme': 0.099963, 'loss_vowel': 0.056564, 'loss_consonant': 0.042223}\n",
      "   24 | 0.000098 | 141312/160735 | 0.0217 | 1.1476 |\n",
      "val: {'recall': 0.995142, 'recall_grapheme': 0.992904, 'recall_vowel': 0.996757, 'recall_consonant': 0.998002, 'acc_grapheme': 0.992744, 'acc_vowel': 0.997033, 'acc_consonant': 0.997033, 'loss_grapheme': 0.077127, 'loss_vowel': 0.053661, 'loss_consonant': 0.037508}\n",
      "** saved\n",
      "   25 | 0.000093 | 134400/160735 | 0.3087 | 1.2020 |\n",
      "val: {'recall': 0.995597, 'recall_grapheme': 0.993821, 'recall_vowel': 0.997269, 'recall_consonant': 0.997479, 'acc_grapheme': 0.993916, 'acc_vowel': 0.997581, 'acc_consonant': 0.997357, 'loss_grapheme': 0.047517, 'loss_vowel': 0.029916, 'loss_consonant': 0.02151}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   26 | 0.000086 | 127488/160735 | 3.4098 | 1.1860 |\n",
      "val: {'recall': 0.99461, 'recall_grapheme': 0.991818, 'recall_vowel': 0.997081, 'recall_consonant': 0.997721, 'acc_grapheme': 0.991672, 'acc_vowel': 0.996808, 'acc_consonant': 0.996783, 'loss_grapheme': 0.064706, 'loss_vowel': 0.048355, 'loss_consonant': 0.035835}\n",
      "   27 | 0.000075 | 120576/160735 | 0.0073 | 1.0463 |\n",
      "val: {'recall': 0.994773, 'recall_grapheme': 0.992577, 'recall_vowel': 0.997597, 'recall_consonant': 0.996342, 'acc_grapheme': 0.99257, 'acc_vowel': 0.997606, 'acc_consonant': 0.997182, 'loss_grapheme': 0.043618, 'loss_vowel': 0.028452, 'loss_consonant': 0.022686}\n",
      "   28 | 0.000063 | 113664/160735 | 2.6333 | 1.1025 |\n",
      "val: {'recall': 0.993794, 'recall_grapheme': 0.991102, 'recall_vowel': 0.996929, 'recall_consonant': 0.996045, 'acc_grapheme': 0.9905, 'acc_vowel': 0.997083, 'acc_consonant': 0.996584, 'loss_grapheme': 0.074834, 'loss_vowel': 0.060056, 'loss_consonant': 0.045007}\n",
      "   29 | 0.000051 | 106752/160735 | 0.5087 | 1.0954 |\n",
      "val: {'recall': 0.995195, 'recall_grapheme': 0.99276, 'recall_vowel': 0.997596, 'recall_consonant': 0.997665, 'acc_grapheme': 0.992395, 'acc_vowel': 0.997581, 'acc_consonant': 0.997232, 'loss_grapheme': 0.062327, 'loss_vowel': 0.04205, 'loss_consonant': 0.03064}\n",
      "   30 | 0.000038 | 099840/160735 | 2.0328 | 1.0104 |\n",
      "val: {'recall': 0.995821, 'recall_grapheme': 0.994205, 'recall_vowel': 0.997876, 'recall_consonant': 0.996995, 'acc_grapheme': 0.993966, 'acc_vowel': 0.998005, 'acc_consonant': 0.997781, 'loss_grapheme': 0.041193, 'loss_vowel': 0.025987, 'loss_consonant': 0.018972}\n",
      "** saved\n",
      "   31 | 0.000026 | 092928/160735 | 0.0170 | 1.0761 |\n",
      "val: {'recall': 0.996612, 'recall_grapheme': 0.994895, 'recall_vowel': 0.998754, 'recall_consonant': 0.997905, 'acc_grapheme': 0.994963, 'acc_vowel': 0.998529, 'acc_consonant': 0.998055, 'loss_grapheme': 0.026003, 'loss_vowel': 0.012947, 'loss_consonant': 0.010571}\n",
      "** saved\n",
      "   32 | 0.000015 | 086016/160735 | 1.6883 | 1.1161 |\n",
      "val: {'recall': 0.994903, 'recall_grapheme': 0.992377, 'recall_vowel': 0.99741, 'recall_consonant': 0.997446, 'acc_grapheme': 0.991348, 'acc_vowel': 0.997507, 'acc_consonant': 0.997207, 'loss_grapheme': 0.07537, 'loss_vowel': 0.065801, 'loss_consonant': 0.044293}\n",
      "   33 | 0.000008 | 079104/160735 | 2.1991 | 1.0758 |\n",
      "val: {'recall': 0.995617, 'recall_grapheme': 0.993343, 'recall_vowel': 0.997872, 'recall_consonant': 0.997908, 'acc_grapheme': 0.99247, 'acc_vowel': 0.997831, 'acc_consonant': 0.997556, 'loss_grapheme': 0.052315, 'loss_vowel': 0.038457, 'loss_consonant': 0.028935}\n",
      "   34 | 0.000003 | 072192/160735 | 0.0093 | 0.9037 |\n",
      "val: {'recall': 0.995217, 'recall_grapheme': 0.993284, 'recall_vowel': 0.997141, 'recall_consonant': 0.997158, 'acc_grapheme': 0.992495, 'acc_vowel': 0.997606, 'acc_consonant': 0.997307, 'loss_grapheme': 0.047881, 'loss_vowel': 0.033547, 'loss_consonant': 0.026808}\n",
      "   35 | 0.000001 | 065280/160735 | 0.0041 | 1.1809 |\n",
      "val: {'recall': 0.995942, 'recall_grapheme': 0.994073, 'recall_vowel': 0.99788, 'recall_consonant': 0.997743, 'acc_grapheme': 0.993642, 'acc_vowel': 0.997955, 'acc_consonant': 0.997905, 'loss_grapheme': 0.038763, 'loss_vowel': 0.025061, 'loss_consonant': 0.019254}\n",
      "   36 | 0.000003 | 058368/160735 | 0.0078 | 0.9750 |\n",
      "val: {'recall': 0.996404, 'recall_grapheme': 0.994663, 'recall_vowel': 0.998271, 'recall_consonant': 0.998017, 'acc_grapheme': 0.994066, 'acc_vowel': 0.998205, 'acc_consonant': 0.998055, 'loss_grapheme': 0.047788, 'loss_vowel': 0.032092, 'loss_consonant': 0.023555}\n",
      "   37 | 0.000008 | 051456/160735 | 2.1421 | 1.3406 |\n",
      "val: {'recall': 0.994734, 'recall_grapheme': 0.992151, 'recall_vowel': 0.997205, 'recall_consonant': 0.99743, 'acc_grapheme': 0.991273, 'acc_vowel': 0.997606, 'acc_consonant': 0.997008, 'loss_grapheme': 0.075693, 'loss_vowel': 0.065711, 'loss_consonant': 0.048397}\n",
      "   38 | 0.000015 | 044544/160735 | 1.9278 | 0.9059 |\n",
      "val: {'recall': 0.995867, 'recall_grapheme': 0.993687, 'recall_vowel': 0.99812, 'recall_consonant': 0.997974, 'acc_grapheme': 0.993417, 'acc_vowel': 0.998005, 'acc_consonant': 0.997881, 'loss_grapheme': 0.061357, 'loss_vowel': 0.046029, 'loss_consonant': 0.030495}\n",
      "   39 | 0.000026 | 037632/160735 | 1.4614 | 1.2423 |\n",
      "val: {'recall': 0.996372, 'recall_grapheme': 0.994679, 'recall_vowel': 0.99816, 'recall_consonant': 0.997969, 'acc_grapheme': 0.99414, 'acc_vowel': 0.998005, 'acc_consonant': 0.997781, 'loss_grapheme': 0.047774, 'loss_vowel': 0.03342, 'loss_consonant': 0.023535}\n",
      "   40 | 0.000038 | 030720/160735 | 1.1423 | 0.7841 |\n",
      "val: {'recall': 0.996462, 'recall_grapheme': 0.994953, 'recall_vowel': 0.997892, 'recall_consonant': 0.998049, 'acc_grapheme': 0.994415, 'acc_vowel': 0.99808, 'acc_consonant': 0.99793, 'loss_grapheme': 0.041564, 'loss_vowel': 0.028382, 'loss_consonant': 0.020233}\n",
      "   41 | 0.000050 | 023808/160735 | 1.7606 | 0.8483 |\n",
      "val: {'recall': 0.995954, 'recall_grapheme': 0.994177, 'recall_vowel': 0.997876, 'recall_consonant': 0.997585, 'acc_grapheme': 0.993542, 'acc_vowel': 0.997881, 'acc_consonant': 0.997182, 'loss_grapheme': 0.043834, 'loss_vowel': 0.027955, 'loss_consonant': 0.020844}\n",
      "   42 | 0.000063 | 016896/160735 | 0.5534 | 0.9143 |\n",
      "val: {'recall': 0.995296, 'recall_grapheme': 0.993109, 'recall_vowel': 0.99758, 'recall_consonant': 0.997387, 'acc_grapheme': 0.99237, 'acc_vowel': 0.997432, 'acc_consonant': 0.997232, 'loss_grapheme': 0.042223, 'loss_vowel': 0.026012, 'loss_consonant': 0.018688}\n",
      "   43 | 0.000075 | 009984/160735 | 1.2364 | 0.8435 |\n",
      "val: {'recall': 0.993738, 'recall_grapheme': 0.991113, 'recall_vowel': 0.996334, 'recall_consonant': 0.996394, 'acc_grapheme': 0.990176, 'acc_vowel': 0.996908, 'acc_consonant': 0.996783, 'loss_grapheme': 0.052083, 'loss_vowel': 0.028923, 'loss_consonant': 0.021436}\n",
      "   44 | 0.000086 | 003072/160735 | 0.0303 | 0.6454 |\n",
      "val: {'recall': 0.994121, 'recall_grapheme': 0.991655, 'recall_vowel': 0.996942, 'recall_consonant': 0.99623, 'acc_grapheme': 0.991373, 'acc_vowel': 0.997108, 'acc_consonant': 0.997058, 'loss_grapheme': 0.048602, 'loss_vowel': 0.029322, 'loss_consonant': 0.021591}\n",
      "   44 | 0.000093 | 156672/160735 | 1.6972 | 1.0765 |\n",
      "val: {'recall': 0.993788, 'recall_grapheme': 0.990881, 'recall_vowel': 0.996914, 'recall_consonant': 0.996478, 'acc_grapheme': 0.990525, 'acc_vowel': 0.996684, 'acc_consonant': 0.99636, 'loss_grapheme': 0.064186, 'loss_vowel': 0.042839, 'loss_consonant': 0.031995}\n",
      "   45 | 0.000098 | 149760/160735 | 0.0257 | 1.1625 |\n",
      "val: {'recall': 0.992126, 'recall_grapheme': 0.989487, 'recall_vowel': 0.996387, 'recall_consonant': 0.993144, 'acc_grapheme': 0.988755, 'acc_vowel': 0.996659, 'acc_consonant': 0.995537, 'loss_grapheme': 0.078864, 'loss_vowel': 0.062033, 'loss_consonant': 0.045275}\n",
      "   46 | 0.000100 | 142848/160735 | 2.0903 | 1.1427 |\n",
      "val: {'recall': 0.994176, 'recall_grapheme': 0.991463, 'recall_vowel': 0.997193, 'recall_consonant': 0.996586, 'acc_grapheme': 0.991373, 'acc_vowel': 0.997182, 'acc_consonant': 0.996684, 'loss_grapheme': 0.05758, 'loss_vowel': 0.036249, 'loss_consonant': 0.030916}\n",
      "   47 | 0.000098 | 135936/160735 | 1.8013 | 1.0701 |\n",
      "val: {'recall': 0.993896, 'recall_grapheme': 0.990858, 'recall_vowel': 0.996548, 'recall_consonant': 0.997321, 'acc_grapheme': 0.990799, 'acc_vowel': 0.996908, 'acc_consonant': 0.996684, 'loss_grapheme': 0.071742, 'loss_vowel': 0.049065, 'loss_consonant': 0.035804}\n",
      "   48 | 0.000093 | 129024/160735 | 0.0263 | 1.1137 |\n",
      "val: {'recall': 0.993978, 'recall_grapheme': 0.990733, 'recall_vowel': 0.997292, 'recall_consonant': 0.997153, 'acc_grapheme': 0.990375, 'acc_vowel': 0.997407, 'acc_consonant': 0.996384, 'loss_grapheme': 0.066303, 'loss_vowel': 0.046901, 'loss_consonant': 0.034851}\n",
      "   49 | 0.000086 | 122112/160735 | 0.6310 | 1.1509 |\n",
      "val: {'recall': 0.994584, 'recall_grapheme': 0.991813, 'recall_vowel': 0.997695, 'recall_consonant': 0.997016, 'acc_grapheme': 0.991497, 'acc_vowel': 0.997357, 'acc_consonant': 0.996908, 'loss_grapheme': 0.055637, 'loss_vowel': 0.03936, 'loss_consonant': 0.02658}\n",
      "   50 | 0.000075 | 115200/160735 | 0.0143 | 0.9259 |\n",
      "val: {'recall': 0.995487, 'recall_grapheme': 0.993198, 'recall_vowel': 0.997935, 'recall_consonant': 0.997617, 'acc_grapheme': 0.993542, 'acc_vowel': 0.99798, 'acc_consonant': 0.997581, 'loss_grapheme': 0.030772, 'loss_vowel': 0.014828, 'loss_consonant': 0.013056}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 0.000063 | 108288/160735 | 1.5406 | 0.9697 |\n",
      "val: {'recall': 0.993109, 'recall_grapheme': 0.990217, 'recall_vowel': 0.996522, 'recall_consonant': 0.995479, 'acc_grapheme': 0.988929, 'acc_vowel': 0.996833, 'acc_consonant': 0.995961, 'loss_grapheme': 0.056458, 'loss_vowel': 0.034883, 'loss_consonant': 0.031278}\n",
      "   52 | 0.000051 | 101376/160735 | 0.0033 | 1.1372 |\n",
      "val: {'recall': 0.995313, 'recall_grapheme': 0.99295, 'recall_vowel': 0.997803, 'recall_consonant': 0.997548, 'acc_grapheme': 0.992495, 'acc_vowel': 0.997756, 'acc_consonant': 0.997182, 'loss_grapheme': 0.040742, 'loss_vowel': 0.026209, 'loss_consonant': 0.020372}\n",
      "   53 | 0.000038 | 094464/160735 | 0.0121 | 0.8790 |\n",
      "val: {'recall': 0.996658, 'recall_grapheme': 0.994888, 'recall_vowel': 0.998465, 'recall_consonant': 0.998392, 'acc_grapheme': 0.994888, 'acc_vowel': 0.99828, 'acc_consonant': 0.99793, 'loss_grapheme': 0.031662, 'loss_vowel': 0.017433, 'loss_consonant': 0.013885}\n",
      "** saved\n",
      "   54 | 0.000026 | 087552/160735 | 0.0091 | 1.0379 |\n",
      "val: {'recall': 0.996077, 'recall_grapheme': 0.994378, 'recall_vowel': 0.997912, 'recall_consonant': 0.997638, 'acc_grapheme': 0.993866, 'acc_vowel': 0.998105, 'acc_consonant': 0.997507, 'loss_grapheme': 0.031219, 'loss_vowel': 0.016383, 'loss_consonant': 0.014176}\n",
      "   55 | 0.000015 | 080640/160735 | 1.6671 | 0.9057 |\n",
      "val: {'recall': 0.995969, 'recall_grapheme': 0.993921, 'recall_vowel': 0.998023, 'recall_consonant': 0.998012, 'acc_grapheme': 0.993243, 'acc_vowel': 0.99793, 'acc_consonant': 0.997432, 'loss_grapheme': 0.034537, 'loss_vowel': 0.019112, 'loss_consonant': 0.016538}\n",
      "   56 | 0.000008 | 073728/160735 | 0.0043 | 0.9288 |\n",
      "val: {'recall': 0.997022, 'recall_grapheme': 0.995669, 'recall_vowel': 0.998327, 'recall_consonant': 0.998422, 'acc_grapheme': 0.995063, 'acc_vowel': 0.998379, 'acc_consonant': 0.998005, 'loss_grapheme': 0.023797, 'loss_vowel': 0.011882, 'loss_consonant': 0.010033}\n",
      "** saved\n",
      "   57 | 0.000003 | 066816/160735 | 0.0206 | 0.9512 |\n",
      "val: {'recall': 0.996637, 'recall_grapheme': 0.994842, 'recall_vowel': 0.998371, 'recall_consonant': 0.998494, 'acc_grapheme': 0.994365, 'acc_vowel': 0.998354, 'acc_consonant': 0.99793, 'loss_grapheme': 0.029367, 'loss_vowel': 0.016864, 'loss_consonant': 0.012812}\n",
      "   58 | 0.000001 | 059904/160735 | 0.0043 | 0.8179 |\n",
      "val: {'recall': 0.996604, 'recall_grapheme': 0.994932, 'recall_vowel': 0.998224, 'recall_consonant': 0.998326, 'acc_grapheme': 0.99424, 'acc_vowel': 0.998155, 'acc_consonant': 0.997806, 'loss_grapheme': 0.029056, 'loss_vowel': 0.015884, 'loss_consonant': 0.013133}\n",
      "   59 | 0.000003 | 052992/160735 | 1.4697 | 1.1260 |\n",
      "val: {'recall': 0.996431, 'recall_grapheme': 0.994607, 'recall_vowel': 0.99823, 'recall_consonant': 0.998279, 'acc_grapheme': 0.993866, 'acc_vowel': 0.99808, 'acc_consonant': 0.997681, 'loss_grapheme': 0.034125, 'loss_vowel': 0.019635, 'loss_consonant': 0.016054}\n",
      "   60 | 0.000008 | 046080/160735 | 0.0037 | 1.2241 |\n",
      "val: {'recall': 0.995253, 'recall_grapheme': 0.993037, 'recall_vowel': 0.997514, 'recall_consonant': 0.997424, 'acc_grapheme': 0.992146, 'acc_vowel': 0.997731, 'acc_consonant': 0.997133, 'loss_grapheme': 0.046735, 'loss_vowel': 0.031448, 'loss_consonant': 0.025799}\n",
      "   61 | 0.000015 | 039168/160735 | 1.6221 | 1.0474 |\n",
      "val: {'recall': 0.995612, 'recall_grapheme': 0.993337, 'recall_vowel': 0.998155, 'recall_consonant': 0.997621, 'acc_grapheme': 0.993367, 'acc_vowel': 0.997955, 'acc_consonant': 0.997382, 'loss_grapheme': 0.038666, 'loss_vowel': 0.02437, 'loss_consonant': 0.018515}\n",
      "   62 | 0.000026 | 032256/160735 | 0.0047 | 0.9522 |\n",
      "val: {'recall': 0.995752, 'recall_grapheme': 0.993648, 'recall_vowel': 0.997721, 'recall_consonant': 0.997991, 'acc_grapheme': 0.992968, 'acc_vowel': 0.997706, 'acc_consonant': 0.997282, 'loss_grapheme': 0.042109, 'loss_vowel': 0.028132, 'loss_consonant': 0.020735}\n",
      "   63 | 0.000038 | 025344/160735 | 1.9562 | 1.0423 |\n",
      "val: {'recall': 0.995969, 'recall_grapheme': 0.99398, 'recall_vowel': 0.99796, 'recall_consonant': 0.997955, 'acc_grapheme': 0.993043, 'acc_vowel': 0.997856, 'acc_consonant': 0.997382, 'loss_grapheme': 0.048454, 'loss_vowel': 0.033906, 'loss_consonant': 0.024854}\n",
      "   64 | 0.000051 | 018432/160735 | 3.1631 | 1.0763 |\n",
      "val: {'recall': 0.995087, 'recall_grapheme': 0.992527, 'recall_vowel': 0.997567, 'recall_consonant': 0.997726, 'acc_grapheme': 0.992146, 'acc_vowel': 0.997507, 'acc_consonant': 0.997332, 'loss_grapheme': 0.041362, 'loss_vowel': 0.025011, 'loss_consonant': 0.01932}\n",
      "   65 | 0.000063 | 011520/160735 | 1.4897 | 1.1849 |\n",
      "val: {'recall': 0.994467, 'recall_grapheme': 0.992219, 'recall_vowel': 0.996849, 'recall_consonant': 0.996582, 'acc_grapheme': 0.991223, 'acc_vowel': 0.997083, 'acc_consonant': 0.996833, 'loss_grapheme': 0.06856, 'loss_vowel': 0.046946, 'loss_consonant': 0.035019}\n",
      "   66 | 0.000075 | 004608/160735 | 0.0197 | 0.6637 |\n",
      "val: {'recall': 0.994908, 'recall_grapheme': 0.992369, 'recall_vowel': 0.997038, 'recall_consonant': 0.997857, 'acc_grapheme': 0.991098, 'acc_vowel': 0.997207, 'acc_consonant': 0.997083, 'loss_grapheme': 0.046579, 'loss_vowel': 0.023857, 'loss_consonant': 0.020121}\n",
      "   66 | 0.000086 | 158208/160735 | 0.9085 | 1.0947 |\n",
      "val: {'recall': 0.995054, 'recall_grapheme': 0.992334, 'recall_vowel': 0.997576, 'recall_consonant': 0.997972, 'acc_grapheme': 0.992295, 'acc_vowel': 0.997531, 'acc_consonant': 0.997307, 'loss_grapheme': 0.06443, 'loss_vowel': 0.042692, 'loss_consonant': 0.028729}\n",
      "   67 | 0.000093 | 151296/160735 | 2.5476 | 1.1167 |\n",
      "val: {'recall': 0.992979, 'recall_grapheme': 0.989397, 'recall_vowel': 0.996091, 'recall_consonant': 0.99703, 'acc_grapheme': 0.988904, 'acc_vowel': 0.996709, 'acc_consonant': 0.995761, 'loss_grapheme': 0.04978, 'loss_vowel': 0.025005, 'loss_consonant': 0.024839}\n",
      "   68 | 0.000098 | 144384/160735 | 0.0113 | 1.0607 |\n",
      "val: {'recall': 0.995023, 'recall_grapheme': 0.993492, 'recall_vowel': 0.996951, 'recall_consonant': 0.996158, 'acc_grapheme': 0.99257, 'acc_vowel': 0.997157, 'acc_consonant': 0.997207, 'loss_grapheme': 0.052008, 'loss_vowel': 0.034678, 'loss_consonant': 0.026009}\n",
      "   69 | 0.000100 | 137472/160735 | 0.0106 | 0.9783 |\n",
      "val: {'recall': 0.995888, 'recall_grapheme': 0.993812, 'recall_vowel': 0.998121, 'recall_consonant': 0.997807, 'acc_grapheme': 0.993243, 'acc_vowel': 0.997756, 'acc_consonant': 0.997457, 'loss_grapheme': 0.034699, 'loss_vowel': 0.018914, 'loss_consonant': 0.015006}\n",
      "   70 | 0.000098 | 130560/160735 | 2.0871 | 1.1361 |\n",
      "val: {'recall': 0.99417, 'recall_grapheme': 0.991358, 'recall_vowel': 0.996992, 'recall_consonant': 0.996972, 'acc_grapheme': 0.990674, 'acc_vowel': 0.997207, 'acc_consonant': 0.996858, 'loss_grapheme': 0.064108, 'loss_vowel': 0.037454, 'loss_consonant': 0.026988}\n",
      "   71 | 0.000093 | 123648/160735 | 2.2628 | 1.0639 |\n",
      "val: {'recall': 0.995469, 'recall_grapheme': 0.993167, 'recall_vowel': 0.997358, 'recall_consonant': 0.998185, 'acc_grapheme': 0.992545, 'acc_vowel': 0.997407, 'acc_consonant': 0.997357, 'loss_grapheme': 0.041477, 'loss_vowel': 0.023549, 'loss_consonant': 0.020165}\n",
      "   72 | 0.000086 | 116736/160735 | 0.9330 | 1.1443 |\n",
      "val: {'recall': 0.993896, 'recall_grapheme': 0.991877, 'recall_vowel': 0.997149, 'recall_consonant': 0.994678, 'acc_grapheme': 0.991647, 'acc_vowel': 0.997207, 'acc_consonant': 0.996709, 'loss_grapheme': 0.057998, 'loss_vowel': 0.030069, 'loss_consonant': 0.026798}\n",
      "   73 | 0.000075 | 109824/160735 | 0.0051 | 1.0911 |\n",
      "val: {'recall': 0.994003, 'recall_grapheme': 0.991578, 'recall_vowel': 0.996342, 'recall_consonant': 0.996516, 'acc_grapheme': 0.9904, 'acc_vowel': 0.996833, 'acc_consonant': 0.996634, 'loss_grapheme': 0.054626, 'loss_vowel': 0.032511, 'loss_consonant': 0.028406}\n",
      "   74 | 0.000063 | 102912/160735 | 1.7120 | 0.9560 |\n",
      "val: {'recall': 0.995914, 'recall_grapheme': 0.993816, 'recall_vowel': 0.997895, 'recall_consonant': 0.998129, 'acc_grapheme': 0.993143, 'acc_vowel': 0.997681, 'acc_consonant': 0.997407, 'loss_grapheme': 0.036634, 'loss_vowel': 0.020285, 'loss_consonant': 0.014777}\n",
      "   75 | 0.000051 | 096000/160735 | 0.0142 | 0.9706 |\n",
      "val: {'recall': 0.996029, 'recall_grapheme': 0.994284, 'recall_vowel': 0.997975, 'recall_consonant': 0.997574, 'acc_grapheme': 0.993766, 'acc_vowel': 0.99813, 'acc_consonant': 0.997731, 'loss_grapheme': 0.040594, 'loss_vowel': 0.024532, 'loss_consonant': 0.019061}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76 | 0.000038 | 089088/160735 | 2.3035 | 1.0684 |\n",
      "val: {'recall': 0.995749, 'recall_grapheme': 0.993691, 'recall_vowel': 0.997361, 'recall_consonant': 0.998251, 'acc_grapheme': 0.993143, 'acc_vowel': 0.997656, 'acc_consonant': 0.997432, 'loss_grapheme': 0.037444, 'loss_vowel': 0.021558, 'loss_consonant': 0.019059}\n",
      "   77 | 0.000026 | 082176/160735 | 0.0068 | 1.0897 |\n",
      "val: {'recall': 0.995529, 'recall_grapheme': 0.993215, 'recall_vowel': 0.997974, 'recall_consonant': 0.99771, 'acc_grapheme': 0.993118, 'acc_vowel': 0.997856, 'acc_consonant': 0.997656, 'loss_grapheme': 0.035894, 'loss_vowel': 0.020457, 'loss_consonant': 0.016028}\n",
      "   78 | 0.000015 | 075264/160735 | 0.0054 | 0.8368 |\n",
      "val: {'recall': 0.996525, 'recall_grapheme': 0.994725, 'recall_vowel': 0.998073, 'recall_consonant': 0.998578, 'acc_grapheme': 0.99439, 'acc_vowel': 0.998055, 'acc_consonant': 0.998205, 'loss_grapheme': 0.027531, 'loss_vowel': 0.013278, 'loss_consonant': 0.010686}\n",
      "   79 | 0.000008 | 068352/160735 | 1.2188 | 1.0321 |\n",
      "val: {'recall': 0.995521, 'recall_grapheme': 0.993255, 'recall_vowel': 0.997653, 'recall_consonant': 0.997922, 'acc_grapheme': 0.993243, 'acc_vowel': 0.997706, 'acc_consonant': 0.997905, 'loss_grapheme': 0.033635, 'loss_vowel': 0.017583, 'loss_consonant': 0.014234}\n",
      "   80 | 0.000003 | 061440/160735 | 0.0051 | 0.8346 |\n",
      "val: {'recall': 0.996494, 'recall_grapheme': 0.994942, 'recall_vowel': 0.998142, 'recall_consonant': 0.997951, 'acc_grapheme': 0.994689, 'acc_vowel': 0.998105, 'acc_consonant': 0.998055, 'loss_grapheme': 0.028311, 'loss_vowel': 0.014685, 'loss_consonant': 0.011615}\n",
      "   81 | 0.000001 | 054528/160735 | 1.3874 | 0.9513 |\n",
      "val: {'recall': 0.997022, 'recall_grapheme': 0.995331, 'recall_vowel': 0.998593, 'recall_consonant': 0.998832, 'acc_grapheme': 0.995213, 'acc_vowel': 0.998404, 'acc_consonant': 0.998504, 'loss_grapheme': 0.028121, 'loss_vowel': 0.016307, 'loss_consonant': 0.012042}\n",
      "   82 | 0.000003 | 047616/160735 | 1.2336 | 1.0171 |\n",
      "val: {'recall': 0.996377, 'recall_grapheme': 0.994784, 'recall_vowel': 0.997912, 'recall_consonant': 0.998028, 'acc_grapheme': 0.99419, 'acc_vowel': 0.997905, 'acc_consonant': 0.998055, 'loss_grapheme': 0.02924, 'loss_vowel': 0.015921, 'loss_consonant': 0.012537}\n",
      "   83 | 0.000008 | 040704/160735 | 0.0055 | 1.1351 |\n",
      "val: {'recall': 0.995915, 'recall_grapheme': 0.994027, 'recall_vowel': 0.997807, 'recall_consonant': 0.997797, 'acc_grapheme': 0.993517, 'acc_vowel': 0.997881, 'acc_consonant': 0.997955, 'loss_grapheme': 0.034229, 'loss_vowel': 0.018507, 'loss_consonant': 0.014499}\n",
      "   84 | 0.000015 | 033792/160735 | 2.7628 | 1.0105 |\n",
      "val: {'recall': 0.996407, 'recall_grapheme': 0.994492, 'recall_vowel': 0.99808, 'recall_consonant': 0.998563, 'acc_grapheme': 0.993891, 'acc_vowel': 0.99813, 'acc_consonant': 0.998005, 'loss_grapheme': 0.031805, 'loss_vowel': 0.015578, 'loss_consonant': 0.012596}\n",
      "   85 | 0.000026 | 026880/160735 | 1.4626 | 1.0531 |\n",
      "val: {'recall': 0.99455, 'recall_grapheme': 0.99176, 'recall_vowel': 0.99727, 'recall_consonant': 0.99741, 'acc_grapheme': 0.991373, 'acc_vowel': 0.997357, 'acc_consonant': 0.997033, 'loss_grapheme': 0.042126, 'loss_vowel': 0.019934, 'loss_consonant': 0.017732}\n",
      "   86 | 0.000038 | 019968/160735 | 3.5361 | 0.8268 |\n",
      "val: {'recall': 0.99622, 'recall_grapheme': 0.994362, 'recall_vowel': 0.998231, 'recall_consonant': 0.997923, 'acc_grapheme': 0.994115, 'acc_vowel': 0.998005, 'acc_consonant': 0.997781, 'loss_grapheme': 0.032226, 'loss_vowel': 0.017469, 'loss_consonant': 0.014199}\n",
      "   87 | 0.000051 | 013056/160735 | 1.8142 | 0.7832 |\n",
      "val: {'recall': 0.995804, 'recall_grapheme': 0.994105, 'recall_vowel': 0.997542, 'recall_consonant': 0.997467, 'acc_grapheme': 0.993293, 'acc_vowel': 0.997681, 'acc_consonant': 0.997606, 'loss_grapheme': 0.033995, 'loss_vowel': 0.017269, 'loss_consonant': 0.013427}\n",
      "   88 | 0.000063 | 006144/160735 | 1.5323 | 1.3725 |\n",
      "val: {'recall': 0.995027, 'recall_grapheme': 0.992676, 'recall_vowel': 0.997343, 'recall_consonant': 0.997413, 'acc_grapheme': 0.99247, 'acc_vowel': 0.997407, 'acc_consonant': 0.997133, 'loss_grapheme': 0.042847, 'loss_vowel': 0.023656, 'loss_consonant': 0.018607}\n",
      "   88 | 0.000075 | 159744/160735 | 1.8491 | 0.9955 |\n",
      "val: {'recall': 0.996253, 'recall_grapheme': 0.99474, 'recall_vowel': 0.997966, 'recall_consonant': 0.997569, 'acc_grapheme': 0.994091, 'acc_vowel': 0.998055, 'acc_consonant': 0.997656, 'loss_grapheme': 0.036371, 'loss_vowel': 0.023334, 'loss_consonant': 0.017714}\n",
      "   89 | 0.000086 | 152832/160735 | 0.0060 | 1.1215 |\n",
      "val: {'recall': 0.996257, 'recall_grapheme': 0.994874, 'recall_vowel': 0.997612, 'recall_consonant': 0.997667, 'acc_grapheme': 0.994016, 'acc_vowel': 0.997731, 'acc_consonant': 0.997905, 'loss_grapheme': 0.030887, 'loss_vowel': 0.015396, 'loss_consonant': 0.012842}\n",
      "   90 | 0.000093 | 145920/160735 | 1.5644 | 1.0400 |\n",
      "val: {'recall': 0.995272, 'recall_grapheme': 0.993354, 'recall_vowel': 0.997078, 'recall_consonant': 0.997303, 'acc_grapheme': 0.993417, 'acc_vowel': 0.997407, 'acc_consonant': 0.997332, 'loss_grapheme': 0.039175, 'loss_vowel': 0.022909, 'loss_consonant': 0.017079}\n",
      "   91 | 0.000098 | 139008/160735 | 1.7689 | 0.9628 |\n",
      "val: {'recall': 0.99547, 'recall_grapheme': 0.993507, 'recall_vowel': 0.99775, 'recall_consonant': 0.997117, 'acc_grapheme': 0.992844, 'acc_vowel': 0.997781, 'acc_consonant': 0.997631, 'loss_grapheme': 0.051674, 'loss_vowel': 0.0281, 'loss_consonant': 0.021695}\n",
      "   92 | 0.000100 | 132096/160735 | 0.8002 | 1.1004 |\n",
      "val: {'recall': 0.995339, 'recall_grapheme': 0.993483, 'recall_vowel': 0.997528, 'recall_consonant': 0.996861, 'acc_grapheme': 0.992694, 'acc_vowel': 0.997357, 'acc_consonant': 0.997008, 'loss_grapheme': 0.037454, 'loss_vowel': 0.018116, 'loss_consonant': 0.015358}\n",
      "   93 | 0.000098 | 125184/160735 | 1.2267 | 1.2894 |\n",
      "val: {'recall': 0.993145, 'recall_grapheme': 0.990163, 'recall_vowel': 0.996259, 'recall_consonant': 0.995995, 'acc_grapheme': 0.989503, 'acc_vowel': 0.996459, 'acc_consonant': 0.99611, 'loss_grapheme': 0.05246, 'loss_vowel': 0.02771, 'loss_consonant': 0.026084}\n",
      "   94 | 0.000093 | 118272/160735 | 1.0793 | 1.2174 |\n",
      "val: {'recall': 0.992851, 'recall_grapheme': 0.990615, 'recall_vowel': 0.996435, 'recall_consonant': 0.993739, 'acc_grapheme': 0.99035, 'acc_vowel': 0.996709, 'acc_consonant': 0.996459, 'loss_grapheme': 0.048959, 'loss_vowel': 0.025541, 'loss_consonant': 0.02295}\n",
      "   95 | 0.000086 | 111360/160735 | 0.0084 | 0.9429 |\n",
      "val: {'recall': 0.994426, 'recall_grapheme': 0.991832, 'recall_vowel': 0.996876, 'recall_consonant': 0.997164, 'acc_grapheme': 0.991497, 'acc_vowel': 0.997058, 'acc_consonant': 0.996684, 'loss_grapheme': 0.040601, 'loss_vowel': 0.019772, 'loss_consonant': 0.019358}\n",
      "   96 | 0.000075 | 104448/160735 | 1.2575 | 1.0979 |\n",
      "val: {'recall': 0.99555, 'recall_grapheme': 0.993431, 'recall_vowel': 0.997141, 'recall_consonant': 0.998197, 'acc_grapheme': 0.993168, 'acc_vowel': 0.997457, 'acc_consonant': 0.997407, 'loss_grapheme': 0.041317, 'loss_vowel': 0.025577, 'loss_consonant': 0.019767}\n",
      "   97 | 0.000063 | 097536/160735 | 0.0272 | 0.9723 |\n",
      "val: {'recall': 0.995445, 'recall_grapheme': 0.993139, 'recall_vowel': 0.997231, 'recall_consonant': 0.998271, 'acc_grapheme': 0.992844, 'acc_vowel': 0.997507, 'acc_consonant': 0.997507, 'loss_grapheme': 0.039597, 'loss_vowel': 0.024102, 'loss_consonant': 0.018771}\n",
      "   98 | 0.000051 | 090624/160735 | 1.6776 | 1.1744 |\n",
      "val: {'recall': 0.995431, 'recall_grapheme': 0.994242, 'recall_vowel': 0.997102, 'recall_consonant': 0.996138, 'acc_grapheme': 0.993392, 'acc_vowel': 0.997731, 'acc_consonant': 0.997432, 'loss_grapheme': 0.033424, 'loss_vowel': 0.017304, 'loss_consonant': 0.014599}\n",
      "   99 | 0.000038 | 083712/160735 | 0.0114 | 0.8182 |\n",
      "val: {'recall': 0.995773, 'recall_grapheme': 0.994408, 'recall_vowel': 0.997519, 'recall_consonant': 0.996755, 'acc_grapheme': 0.993741, 'acc_vowel': 0.997831, 'acc_consonant': 0.997856, 'loss_grapheme': 0.031844, 'loss_vowel': 0.01735, 'loss_consonant': 0.013247}\n",
      "  100 | 0.000026 | 076800/160735 | 0.0104 | 1.0883 |\n",
      "val: {'recall': 0.995063, 'recall_grapheme': 0.993568, 'recall_vowel': 0.996805, 'recall_consonant': 0.996312, 'acc_grapheme': 0.992894, 'acc_vowel': 0.997531, 'acc_consonant': 0.997482, 'loss_grapheme': 0.044661, 'loss_vowel': 0.028091, 'loss_consonant': 0.021068}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 | 0.000015 | 069888/160735 | 1.6693 | 0.9381 |\n",
      "val: {'recall': 0.996133, 'recall_grapheme': 0.994301, 'recall_vowel': 0.997649, 'recall_consonant': 0.99828, 'acc_grapheme': 0.993667, 'acc_vowel': 0.997831, 'acc_consonant': 0.997955, 'loss_grapheme': 0.037403, 'loss_vowel': 0.02273, 'loss_consonant': 0.016761}\n",
      "  102 | 0.000008 | 062976/160735 | 0.0031 | 0.9741 |\n",
      "val: {'recall': 0.997018, 'recall_grapheme': 0.995462, 'recall_vowel': 0.998495, 'recall_consonant': 0.998655, 'acc_grapheme': 0.995088, 'acc_vowel': 0.998354, 'acc_consonant': 0.998404, 'loss_grapheme': 0.02418, 'loss_vowel': 0.011886, 'loss_consonant': 0.008562}\n",
      "  103 | 0.000003 | 056064/160735 | 1.6289 | 0.8747 |\n",
      "val: {'recall': 0.996627, 'recall_grapheme': 0.995, 'recall_vowel': 0.998122, 'recall_consonant': 0.998386, 'acc_grapheme': 0.99429, 'acc_vowel': 0.998055, 'acc_consonant': 0.99808, 'loss_grapheme': 0.031662, 'loss_vowel': 0.018117, 'loss_consonant': 0.013088}\n",
      "  104 | 0.000001 | 049152/160735 | 0.0041 | 0.9578 |\n",
      "val: {'recall': 0.996952, 'recall_grapheme': 0.995419, 'recall_vowel': 0.998189, 'recall_consonant': 0.998779, 'acc_grapheme': 0.995412, 'acc_vowel': 0.99823, 'acc_consonant': 0.998379, 'loss_grapheme': 0.02569, 'loss_vowel': 0.014419, 'loss_consonant': 0.010455}\n",
      "  105 | 0.000003 | 042240/160735 | 1.2150 | 1.1442 |\n",
      "val: {'recall': 0.994353, 'recall_grapheme': 0.991598, 'recall_vowel': 0.997055, 'recall_consonant': 0.997161, 'acc_grapheme': 0.991073, 'acc_vowel': 0.997282, 'acc_consonant': 0.997257, 'loss_grapheme': 0.04024, 'loss_vowel': 0.016769, 'loss_consonant': 0.015214}\n",
      "  106 | 0.000008 | 035328/160735 | 0.0044 | 1.0797 |\n",
      "val: {'recall': 0.996619, 'recall_grapheme': 0.995185, 'recall_vowel': 0.997651, 'recall_consonant': 0.998457, 'acc_grapheme': 0.99434, 'acc_vowel': 0.997955, 'acc_consonant': 0.99813, 'loss_grapheme': 0.028082, 'loss_vowel': 0.014592, 'loss_consonant': 0.010929}\n",
      "  107 | 0.000015 | 028416/160735 | 0.0093 | 1.0082 |\n",
      "val: {'recall': 0.996271, 'recall_grapheme': 0.994572, 'recall_vowel': 0.997701, 'recall_consonant': 0.998239, 'acc_grapheme': 0.993816, 'acc_vowel': 0.997955, 'acc_consonant': 0.997881, 'loss_grapheme': 0.033846, 'loss_vowel': 0.019077, 'loss_consonant': 0.014288}\n",
      "  108 | 0.000026 | 021504/160735 | 1.7826 | 1.1522 |\n",
      "val: {'recall': 0.995531, 'recall_grapheme': 0.993433, 'recall_vowel': 0.997461, 'recall_consonant': 0.997796, 'acc_grapheme': 0.992644, 'acc_vowel': 0.997756, 'acc_consonant': 0.997856, 'loss_grapheme': 0.040832, 'loss_vowel': 0.022632, 'loss_consonant': 0.017828}\n",
      "  109 | 0.000038 | 014592/160735 | 2.1660 | 0.9787 |\n",
      "val: {'recall': 0.99601, 'recall_grapheme': 0.994169, 'recall_vowel': 0.997848, 'recall_consonant': 0.997852, 'acc_grapheme': 0.993592, 'acc_vowel': 0.99793, 'acc_consonant': 0.997905, 'loss_grapheme': 0.039742, 'loss_vowel': 0.024191, 'loss_consonant': 0.016697}\n",
      "  110 | 0.000050 | 007680/160735 | 0.0063 | 0.9479 |\n",
      "val: {'recall': 0.995271, 'recall_grapheme': 0.993582, 'recall_vowel': 0.996654, 'recall_consonant': 0.997267, 'acc_grapheme': 0.99257, 'acc_vowel': 0.997133, 'acc_consonant': 0.997257, 'loss_grapheme': 0.038546, 'loss_vowel': 0.019889, 'loss_consonant': 0.016156}\n",
      "  111 | 0.000063 | 000768/160735 | 2.9451 | 2.9451 |\n",
      "val: {'recall': 0.995343, 'recall_grapheme': 0.994227, 'recall_vowel': 0.996866, 'recall_consonant': 0.996052, 'acc_grapheme': 0.993193, 'acc_vowel': 0.997432, 'acc_consonant': 0.997507, 'loss_grapheme': 0.034461, 'loss_vowel': 0.019401, 'loss_consonant': 0.015491}\n",
      "  111 | 0.000075 | 154368/160735 | 2.6960 | 1.0276 |\n",
      "val: {'recall': 0.994254, 'recall_grapheme': 0.992459, 'recall_vowel': 0.996691, 'recall_consonant': 0.995407, 'acc_grapheme': 0.991572, 'acc_vowel': 0.997133, 'acc_consonant': 0.997182, 'loss_grapheme': 0.047479, 'loss_vowel': 0.026197, 'loss_consonant': 0.022139}\n",
      "  112 | 0.000086 | 147456/160735 | 2.7103 | 1.0632 |\n",
      "val: {'recall': 0.994565, 'recall_grapheme': 0.99212, 'recall_vowel': 0.99704, 'recall_consonant': 0.996981, 'acc_grapheme': 0.991298, 'acc_vowel': 0.997033, 'acc_consonant': 0.997182, 'loss_grapheme': 0.044047, 'loss_vowel': 0.02106, 'loss_consonant': 0.016676}\n",
      "  113 | 0.000093 | 140544/160735 | 1.5952 | 0.9780 |\n",
      "val: {'recall': 0.993162, 'recall_grapheme': 0.990474, 'recall_vowel': 0.99696, 'recall_consonant': 0.994738, 'acc_grapheme': 0.990051, 'acc_vowel': 0.996883, 'acc_consonant': 0.99616, 'loss_grapheme': 0.04652, 'loss_vowel': 0.019628, 'loss_consonant': 0.021769}\n",
      "  114 | 0.000098 | 133632/160735 | 0.0064 | 1.1904 |\n",
      "val: {'recall': 0.996243, 'recall_grapheme': 0.994197, 'recall_vowel': 0.998453, 'recall_consonant': 0.998127, 'acc_grapheme': 0.993916, 'acc_vowel': 0.99808, 'acc_consonant': 0.997556, 'loss_grapheme': 0.04005, 'loss_vowel': 0.025726, 'loss_consonant': 0.018018}\n",
      "  115 | 0.000100 | 126720/160735 | 0.0350 | 0.9584 |\n",
      "val: {'recall': 0.995196, 'recall_grapheme': 0.992612, 'recall_vowel': 0.997622, 'recall_consonant': 0.997936, 'acc_grapheme': 0.992819, 'acc_vowel': 0.997631, 'acc_consonant': 0.997507, 'loss_grapheme': 0.046609, 'loss_vowel': 0.031094, 'loss_consonant': 0.022811}\n",
      "  116 | 0.000098 | 119808/160735 | 1.5358 | 0.9568 |\n",
      "val: {'recall': 0.995334, 'recall_grapheme': 0.993336, 'recall_vowel': 0.997438, 'recall_consonant': 0.997226, 'acc_grapheme': 0.992495, 'acc_vowel': 0.997407, 'acc_consonant': 0.997332, 'loss_grapheme': 0.036958, 'loss_vowel': 0.021188, 'loss_consonant': 0.01704}\n",
      "  117 | 0.000093 | 112896/160735 | 3.1163 | 1.1086 |\n",
      "val: {'recall': 0.994882, 'recall_grapheme': 0.992358, 'recall_vowel': 0.997206, 'recall_consonant': 0.997607, 'acc_grapheme': 0.992245, 'acc_vowel': 0.997282, 'acc_consonant': 0.996883, 'loss_grapheme': 0.04978, 'loss_vowel': 0.032626, 'loss_consonant': 0.027171}\n",
      "  118 | 0.000086 | 105984/160735 | 2.4781 | 1.0193 |\n",
      "val: {'recall': 0.993736, 'recall_grapheme': 0.990426, 'recall_vowel': 0.997085, 'recall_consonant': 0.997006, 'acc_grapheme': 0.9906, 'acc_vowel': 0.997058, 'acc_consonant': 0.996534, 'loss_grapheme': 0.055557, 'loss_vowel': 0.032842, 'loss_consonant': 0.026588}\n",
      "  119 | 0.000075 | 099072/160735 | 2.9077 | 0.9457 |\n",
      "val: {'recall': 0.995581, 'recall_grapheme': 0.993588, 'recall_vowel': 0.997514, 'recall_consonant': 0.997636, 'acc_grapheme': 0.992844, 'acc_vowel': 0.997581, 'acc_consonant': 0.997606, 'loss_grapheme': 0.047161, 'loss_vowel': 0.030763, 'loss_consonant': 0.020989}\n",
      "  120 | 0.000063 | 092160/160735 | 0.0024 | 0.8628 |\n",
      "val: {'recall': 0.994908, 'recall_grapheme': 0.992788, 'recall_vowel': 0.99715, 'recall_consonant': 0.996906, 'acc_grapheme': 0.99252, 'acc_vowel': 0.997482, 'acc_consonant': 0.997556, 'loss_grapheme': 0.032059, 'loss_vowel': 0.013641, 'loss_consonant': 0.011596}\n",
      "  121 | 0.000050 | 085248/160735 | 0.0029 | 1.0245 |\n",
      "val: {'recall': 0.99664, 'recall_grapheme': 0.994954, 'recall_vowel': 0.998358, 'recall_consonant': 0.998294, 'acc_grapheme': 0.994963, 'acc_vowel': 0.99823, 'acc_consonant': 0.997955, 'loss_grapheme': 0.02365, 'loss_vowel': 0.011954, 'loss_consonant': 0.009626}\n",
      "  122 | 0.000038 | 078336/160735 | 2.3447 | 0.9444 |\n",
      "val: {'recall': 0.99535, 'recall_grapheme': 0.992954, 'recall_vowel': 0.997914, 'recall_consonant': 0.997579, 'acc_grapheme': 0.992644, 'acc_vowel': 0.997781, 'acc_consonant': 0.997656, 'loss_grapheme': 0.039871, 'loss_vowel': 0.023592, 'loss_consonant': 0.017735}\n",
      "  123 | 0.000026 | 071424/160735 | 1.0606 | 0.9020 |\n",
      "val: {'recall': 0.997161, 'recall_grapheme': 0.995734, 'recall_vowel': 0.998445, 'recall_consonant': 0.99873, 'acc_grapheme': 0.995537, 'acc_vowel': 0.99818, 'acc_consonant': 0.998429, 'loss_grapheme': 0.024287, 'loss_vowel': 0.013856, 'loss_consonant': 0.009718}\n",
      "** saved\n",
      "  124 | 0.000015 | 064512/160735 | 0.0014 | 0.8802 |\n",
      "val: {'recall': 0.997401, 'recall_grapheme': 0.996331, 'recall_vowel': 0.998438, 'recall_consonant': 0.998503, 'acc_grapheme': 0.995961, 'acc_vowel': 0.998479, 'acc_consonant': 0.998354, 'loss_grapheme': 0.019338, 'loss_vowel': 0.009742, 'loss_consonant': 0.007437}\n",
      "** saved\n",
      "  125 | 0.000008 | 057600/160735 | 0.0148 | 1.1212 |\n",
      "val: {'recall': 0.996347, 'recall_grapheme': 0.994762, 'recall_vowel': 0.997914, 'recall_consonant': 0.997951, 'acc_grapheme': 0.994465, 'acc_vowel': 0.99803, 'acc_consonant': 0.998105, 'loss_grapheme': 0.027596, 'loss_vowel': 0.014951, 'loss_consonant': 0.011247}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  126 | 0.000003 | 050688/160735 | 2.1043 | 0.9254 |\n",
      "val: {'recall': 0.996198, 'recall_grapheme': 0.994444, 'recall_vowel': 0.998057, 'recall_consonant': 0.997847, 'acc_grapheme': 0.994315, 'acc_vowel': 0.997955, 'acc_consonant': 0.99808, 'loss_grapheme': 0.032837, 'loss_vowel': 0.021154, 'loss_consonant': 0.015282}\n",
      "  127 | 0.000001 | 043776/160735 | 0.0213 | 1.0302 |\n",
      "val: {'recall': 0.995947, 'recall_grapheme': 0.994032, 'recall_vowel': 0.997894, 'recall_consonant': 0.997829, 'acc_grapheme': 0.993567, 'acc_vowel': 0.997905, 'acc_consonant': 0.997905, 'loss_grapheme': 0.030067, 'loss_vowel': 0.014481, 'loss_consonant': 0.011062}\n",
      "  128 | 0.000003 | 036864/160735 | 0.4714 | 1.1853 |\n",
      "val: {'recall': 0.995707, 'recall_grapheme': 0.993753, 'recall_vowel': 0.99765, 'recall_consonant': 0.997672, 'acc_grapheme': 0.993118, 'acc_vowel': 0.997781, 'acc_consonant': 0.997581, 'loss_grapheme': 0.048194, 'loss_vowel': 0.033156, 'loss_consonant': 0.02459}\n",
      "  129 | 0.000008 | 029952/160735 | 1.4470 | 0.8383 |\n",
      "val: {'recall': 0.997184, 'recall_grapheme': 0.995764, 'recall_vowel': 0.998352, 'recall_consonant': 0.998855, 'acc_grapheme': 0.995836, 'acc_vowel': 0.99828, 'acc_consonant': 0.998529, 'loss_grapheme': 0.035367, 'loss_vowel': 0.024501, 'loss_consonant': 0.016408}\n",
      "  130 | 0.000015 | 023040/160735 | 0.0245 | 1.2537 |\n",
      "val: {'recall': 0.995618, 'recall_grapheme': 0.993523, 'recall_vowel': 0.997863, 'recall_consonant': 0.997563, 'acc_grapheme': 0.993118, 'acc_vowel': 0.99798, 'acc_consonant': 0.997681, 'loss_grapheme': 0.033359, 'loss_vowel': 0.016735, 'loss_consonant': 0.012869}\n",
      "  131 | 0.000026 | 016128/160735 | 1.9116 | 0.9763 |\n",
      "val: {'recall': 0.994658, 'recall_grapheme': 0.992013, 'recall_vowel': 0.997423, 'recall_consonant': 0.997183, 'acc_grapheme': 0.991971, 'acc_vowel': 0.997507, 'acc_consonant': 0.997133, 'loss_grapheme': 0.03749, 'loss_vowel': 0.018299, 'loss_consonant': 0.015456}\n",
      "  132 | 0.000038 | 009216/160735 | 0.0030 | 0.5317 |\n",
      "val: {'recall': 0.996634, 'recall_grapheme': 0.994998, 'recall_vowel': 0.997883, 'recall_consonant': 0.99866, 'acc_grapheme': 0.994564, 'acc_vowel': 0.99808, 'acc_consonant': 0.998205, 'loss_grapheme': 0.025619, 'loss_vowel': 0.012766, 'loss_consonant': 0.009489}\n",
      "  133 | 0.000050 | 002304/160735 | 2.1109 | 1.4389 |\n",
      "val: {'recall': 0.995611, 'recall_grapheme': 0.993283, 'recall_vowel': 0.997624, 'recall_consonant': 0.998253, 'acc_grapheme': 0.992644, 'acc_vowel': 0.997905, 'acc_consonant': 0.997407, 'loss_grapheme': 0.03972, 'loss_vowel': 0.021442, 'loss_consonant': 0.01745}\n",
      "  133 | 0.000063 | 155904/160735 | 1.2843 | 1.1024 |\n",
      "val: {'recall': 0.996676, 'recall_grapheme': 0.995002, 'recall_vowel': 0.997983, 'recall_consonant': 0.998716, 'acc_grapheme': 0.99434, 'acc_vowel': 0.997806, 'acc_consonant': 0.998155, 'loss_grapheme': 0.028685, 'loss_vowel': 0.014414, 'loss_consonant': 0.010187}\n",
      "  134 | 0.000075 | 148992/160735 | 0.8502 | 1.0072 |\n",
      "val: {'recall': 0.991749, 'recall_grapheme': 0.988869, 'recall_vowel': 0.996031, 'recall_consonant': 0.993225, 'acc_grapheme': 0.988705, 'acc_vowel': 0.996185, 'acc_consonant': 0.99631, 'loss_grapheme': 0.061532, 'loss_vowel': 0.027176, 'loss_consonant': 0.022094}\n",
      "  135 | 0.000086 | 142080/160735 | 0.0136 | 1.0126 |\n",
      "val: {'recall': 0.996565, 'recall_grapheme': 0.994546, 'recall_vowel': 0.998327, 'recall_consonant': 0.998842, 'acc_grapheme': 0.994689, 'acc_vowel': 0.99813, 'acc_consonant': 0.99828, 'loss_grapheme': 0.027536, 'loss_vowel': 0.015968, 'loss_consonant': 0.010641}\n",
      "  136 | 0.000093 | 135168/160735 | 0.0236 | 1.0845 |\n",
      "val: {'recall': 0.995783, 'recall_grapheme': 0.994243, 'recall_vowel': 0.997611, 'recall_consonant': 0.997036, 'acc_grapheme': 0.993567, 'acc_vowel': 0.997781, 'acc_consonant': 0.997606, 'loss_grapheme': 0.033939, 'loss_vowel': 0.017133, 'loss_consonant': 0.012931}\n",
      "  137 | 0.000098 | 128256/160735 | 0.0058 | 1.1391 |\n",
      "val: {'recall': 0.99523, 'recall_grapheme': 0.99358, 'recall_vowel': 0.997383, 'recall_consonant': 0.996377, 'acc_grapheme': 0.992944, 'acc_vowel': 0.997581, 'acc_consonant': 0.997207, 'loss_grapheme': 0.031251, 'loss_vowel': 0.014384, 'loss_consonant': 0.011074}\n",
      "  138 | 0.000100 | 121344/160735 | 0.0082 | 1.0037 |\n",
      "val: {'recall': 0.995331, 'recall_grapheme': 0.993406, 'recall_vowel': 0.997036, 'recall_consonant': 0.997477, 'acc_grapheme': 0.993018, 'acc_vowel': 0.997232, 'acc_consonant': 0.997232, 'loss_grapheme': 0.035526, 'loss_vowel': 0.01868, 'loss_consonant': 0.013677}\n",
      "  139 | 0.000098 | 114432/160735 | 0.0101 | 1.1017 |\n",
      "val: {'recall': 0.996631, 'recall_grapheme': 0.995827, 'recall_vowel': 0.99711, 'recall_consonant': 0.997757, 'acc_grapheme': 0.995013, 'acc_vowel': 0.997606, 'acc_consonant': 0.99793, 'loss_grapheme': 0.023462, 'loss_vowel': 0.013564, 'loss_consonant': 0.010071}\n",
      "  140 | 0.000093 | 107520/160735 | 0.0111 | 1.0439 |\n",
      "val: {'recall': 0.99577, 'recall_grapheme': 0.994108, 'recall_vowel': 0.997507, 'recall_consonant': 0.997359, 'acc_grapheme': 0.993567, 'acc_vowel': 0.997507, 'acc_consonant': 0.997507, 'loss_grapheme': 0.04486, 'loss_vowel': 0.028198, 'loss_consonant': 0.019546}\n",
      "  141 | 0.000086 | 100608/160735 | 0.0036 | 1.1183 |\n",
      "val: {'recall': 0.994895, 'recall_grapheme': 0.992405, 'recall_vowel': 0.997441, 'recall_consonant': 0.997327, 'acc_grapheme': 0.992495, 'acc_vowel': 0.997507, 'acc_consonant': 0.997332, 'loss_grapheme': 0.047013, 'loss_vowel': 0.025681, 'loss_consonant': 0.01975}\n",
      "  142 | 0.000075 | 093696/160735 | 1.6915 | 0.9914 |\n",
      "val: {'recall': 0.995392, 'recall_grapheme': 0.993254, 'recall_vowel': 0.997715, 'recall_consonant': 0.997345, 'acc_grapheme': 0.992744, 'acc_vowel': 0.997806, 'acc_consonant': 0.997033, 'loss_grapheme': 0.042221, 'loss_vowel': 0.024456, 'loss_consonant': 0.021081}\n",
      "  143 | 0.000063 | 086784/160735 | 1.6401 | 1.0673 |\n",
      "val: {'recall': 0.995698, 'recall_grapheme': 0.993278, 'recall_vowel': 0.997616, 'recall_consonant': 0.99862, 'acc_grapheme': 0.993442, 'acc_vowel': 0.997731, 'acc_consonant': 0.997706, 'loss_grapheme': 0.038034, 'loss_vowel': 0.022075, 'loss_consonant': 0.015194}\n",
      "  144 | 0.000050 | 079872/160735 | 0.0011 | 1.1453 |\n",
      "val: {'recall': 0.996225, 'recall_grapheme': 0.99455, 'recall_vowel': 0.997791, 'recall_consonant': 0.998009, 'acc_grapheme': 0.994564, 'acc_vowel': 0.99798, 'acc_consonant': 0.998105, 'loss_grapheme': 0.030262, 'loss_vowel': 0.018484, 'loss_consonant': 0.012829}\n",
      "  145 | 0.000038 | 072960/160735 | 0.0018 | 0.9893 |\n",
      "val: {'recall': 0.996092, 'recall_grapheme': 0.994191, 'recall_vowel': 0.997593, 'recall_consonant': 0.998395, 'acc_grapheme': 0.993791, 'acc_vowel': 0.997856, 'acc_consonant': 0.997831, 'loss_grapheme': 0.030728, 'loss_vowel': 0.015958, 'loss_consonant': 0.011781}\n",
      "  146 | 0.000026 | 066048/160735 | 0.4954 | 0.9667 |\n",
      "val: {'recall': 0.994922, 'recall_grapheme': 0.992576, 'recall_vowel': 0.996767, 'recall_consonant': 0.997768, 'acc_grapheme': 0.992694, 'acc_vowel': 0.997332, 'acc_consonant': 0.997332, 'loss_grapheme': 0.044278, 'loss_vowel': 0.028404, 'loss_consonant': 0.019002}\n",
      "  147 | 0.000015 | 059136/160735 | 1.0802 | 0.9199 |\n",
      "val: {'recall': 0.995997, 'recall_grapheme': 0.994216, 'recall_vowel': 0.997038, 'recall_consonant': 0.998519, 'acc_grapheme': 0.993866, 'acc_vowel': 0.997556, 'acc_consonant': 0.997955, 'loss_grapheme': 0.028609, 'loss_vowel': 0.014062, 'loss_consonant': 0.00981}\n",
      "  148 | 0.000008 | 052224/160735 | 1.2015 | 1.0411 |\n",
      "val: {'recall': 0.996437, 'recall_grapheme': 0.994685, 'recall_vowel': 0.997778, 'recall_consonant': 0.998602, 'acc_grapheme': 0.994489, 'acc_vowel': 0.99798, 'acc_consonant': 0.998055, 'loss_grapheme': 0.035343, 'loss_vowel': 0.022645, 'loss_consonant': 0.015492}\n",
      "  149 | 0.000003 | 045312/160735 | 0.0040 | 0.9464 |\n",
      "val: {'recall': 0.997065, 'recall_grapheme': 0.995639, 'recall_vowel': 0.998172, 'recall_consonant': 0.99881, 'acc_grapheme': 0.995362, 'acc_vowel': 0.99823, 'acc_consonant': 0.998379, 'loss_grapheme': 0.023773, 'loss_vowel': 0.013643, 'loss_consonant': 0.009674}\n",
      "  150 | 0.000001 | 038400/160735 | 1.2399 | 0.7146 |\n",
      "val: {'recall': 0.997291, 'recall_grapheme': 0.995956, 'recall_vowel': 0.998392, 'recall_consonant': 0.99886, 'acc_grapheme': 0.995861, 'acc_vowel': 0.998304, 'acc_consonant': 0.998479, 'loss_grapheme': 0.02365, 'loss_vowel': 0.014735, 'loss_consonant': 0.010152}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  151 | 0.000003 | 031488/160735 | 2.0051 | 1.0539 |\n",
      "val: {'recall': 0.99659, 'recall_grapheme': 0.99497, 'recall_vowel': 0.997655, 'recall_consonant': 0.998764, 'acc_grapheme': 0.994564, 'acc_vowel': 0.998055, 'acc_consonant': 0.998205, 'loss_grapheme': 0.029236, 'loss_vowel': 0.017448, 'loss_consonant': 0.011928}\n",
      "  152 | 0.000008 | 024576/160735 | 1.1848 | 0.8531 |\n",
      "val: {'recall': 0.997071, 'recall_grapheme': 0.995564, 'recall_vowel': 0.998247, 'recall_consonant': 0.99891, 'acc_grapheme': 0.995362, 'acc_vowel': 0.998329, 'acc_consonant': 0.998479, 'loss_grapheme': 0.023826, 'loss_vowel': 0.013686, 'loss_consonant': 0.009157}\n",
      "  153 | 0.000015 | 017664/160735 | 2.1579 | 0.9579 |\n",
      "val: {'recall': 0.996451, 'recall_grapheme': 0.994517, 'recall_vowel': 0.998093, 'recall_consonant': 0.998676, 'acc_grapheme': 0.994265, 'acc_vowel': 0.99813, 'acc_consonant': 0.99808, 'loss_grapheme': 0.037137, 'loss_vowel': 0.022186, 'loss_consonant': 0.015718}\n",
      "  154 | 0.000026 | 010752/160735 | 2.4124 | 1.1699 |\n",
      "val: {'recall': 0.995699, 'recall_grapheme': 0.993404, 'recall_vowel': 0.9976, 'recall_consonant': 0.99839, 'acc_grapheme': 0.993043, 'acc_vowel': 0.997656, 'acc_consonant': 0.997631, 'loss_grapheme': 0.048963, 'loss_vowel': 0.033972, 'loss_consonant': 0.024041}\n",
      "  155 | 0.000038 | 003840/160735 | 0.0089 | 0.0077 |\n",
      "val: {'recall': 0.996855, 'recall_grapheme': 0.995378, 'recall_vowel': 0.998144, 'recall_consonant': 0.998521, 'acc_grapheme': 0.995262, 'acc_vowel': 0.99818, 'acc_consonant': 0.998255, 'loss_grapheme': 0.021928, 'loss_vowel': 0.010125, 'loss_consonant': 0.007755}\n",
      "  155 | 0.000050 | 157440/160735 | 1.6851 | 1.0054 |\n",
      "val: {'recall': 0.996135, 'recall_grapheme': 0.994471, 'recall_vowel': 0.997831, 'recall_consonant': 0.997765, 'acc_grapheme': 0.994739, 'acc_vowel': 0.998055, 'acc_consonant': 0.99798, 'loss_grapheme': 0.043792, 'loss_vowel': 0.025783, 'loss_consonant': 0.01799}\n",
      "  156 | 0.000063 | 150528/160735 | 0.0098 | 0.9517 |\n",
      "val: {'recall': 0.99542, 'recall_grapheme': 0.993071, 'recall_vowel': 0.997169, 'recall_consonant': 0.998369, 'acc_grapheme': 0.993467, 'acc_vowel': 0.997706, 'acc_consonant': 0.997681, 'loss_grapheme': 0.034544, 'loss_vowel': 0.018773, 'loss_consonant': 0.013302}\n",
      "  157 | 0.000075 | 143616/160735 | 0.0041 | 0.9595 |\n",
      "val: {'recall': 0.995171, 'recall_grapheme': 0.992887, 'recall_vowel': 0.997154, 'recall_consonant': 0.997754, 'acc_grapheme': 0.992794, 'acc_vowel': 0.997507, 'acc_consonant': 0.997207, 'loss_grapheme': 0.036391, 'loss_vowel': 0.019899, 'loss_consonant': 0.016813}\n",
      "  158 | 0.000086 | 136704/160735 | 0.0049 | 1.0930 |\n",
      "val: {'recall': 0.994538, 'recall_grapheme': 0.991599, 'recall_vowel': 0.996743, 'recall_consonant': 0.998211, 'acc_grapheme': 0.992071, 'acc_vowel': 0.997257, 'acc_consonant': 0.997756, 'loss_grapheme': 0.041982, 'loss_vowel': 0.023749, 'loss_consonant': 0.017361}\n",
      "  159 | 0.000093 | 129792/160735 | 0.0059 | 1.1267 |\n",
      "val: {'recall': 0.993669, 'recall_grapheme': 0.990287, 'recall_vowel': 0.996392, 'recall_consonant': 0.997712, 'acc_grapheme': 0.990126, 'acc_vowel': 0.996808, 'acc_consonant': 0.996759, 'loss_grapheme': 0.045965, 'loss_vowel': 0.024302, 'loss_consonant': 0.019844}\n",
      "  160 | 0.000098 | 122880/160735 | 1.6992 | 1.0508 |\n",
      "val: {'recall': 0.995511, 'recall_grapheme': 0.993091, 'recall_vowel': 0.997514, 'recall_consonant': 0.998349, 'acc_grapheme': 0.993318, 'acc_vowel': 0.997531, 'acc_consonant': 0.997507, 'loss_grapheme': 0.033897, 'loss_vowel': 0.016389, 'loss_consonant': 0.013151}\n",
      "  161 | 0.000100 | 115968/160735 | 0.0102 | 0.9980 |\n",
      "val: {'recall': 0.996185, 'recall_grapheme': 0.99475, 'recall_vowel': 0.997681, 'recall_consonant': 0.997556, 'acc_grapheme': 0.994764, 'acc_vowel': 0.997831, 'acc_consonant': 0.998055, 'loss_grapheme': 0.02734, 'loss_vowel': 0.014063, 'loss_consonant': 0.01091}\n",
      "  162 | 0.000098 | 109056/160735 | 2.0594 | 0.9644 |\n",
      "val: {'recall': 0.995732, 'recall_grapheme': 0.993541, 'recall_vowel': 0.997507, 'recall_consonant': 0.998339, 'acc_grapheme': 0.993966, 'acc_vowel': 0.997656, 'acc_consonant': 0.997531, 'loss_grapheme': 0.046141, 'loss_vowel': 0.032944, 'loss_consonant': 0.020238}\n",
      "  163 | 0.000093 | 102144/160735 | 1.6276 | 1.2060 |\n",
      "val: {'recall': 0.995251, 'recall_grapheme': 0.993257, 'recall_vowel': 0.996818, 'recall_consonant': 0.997674, 'acc_grapheme': 0.993293, 'acc_vowel': 0.997108, 'acc_consonant': 0.997232, 'loss_grapheme': 0.037239, 'loss_vowel': 0.022712, 'loss_consonant': 0.017733}\n",
      "  164 | 0.000086 | 095232/160735 | 2.2689 | 1.1190 |\n",
      "val: {'recall': 0.995314, 'recall_grapheme': 0.993227, 'recall_vowel': 0.997283, 'recall_consonant': 0.99752, 'acc_grapheme': 0.99237, 'acc_vowel': 0.997382, 'acc_consonant': 0.997207, 'loss_grapheme': 0.055072, 'loss_vowel': 0.032207, 'loss_consonant': 0.024264}\n",
      "  165 | 0.000075 | 088320/160735 | 0.4218 | 1.0659 |\n",
      "val: {'recall': 0.995848, 'recall_grapheme': 0.993709, 'recall_vowel': 0.997674, 'recall_consonant': 0.998299, 'acc_grapheme': 0.993143, 'acc_vowel': 0.997856, 'acc_consonant': 0.997556, 'loss_grapheme': 0.038294, 'loss_vowel': 0.02036, 'loss_consonant': 0.015828}\n",
      "  166 | 0.000063 | 081408/160735 | 0.9043 | 1.0214 |\n",
      "val: {'recall': 0.995339, 'recall_grapheme': 0.992806, 'recall_vowel': 0.997541, 'recall_consonant': 0.998201, 'acc_grapheme': 0.992121, 'acc_vowel': 0.997681, 'acc_consonant': 0.997756, 'loss_grapheme': 0.032939, 'loss_vowel': 0.014156, 'loss_consonant': 0.011852}\n",
      "  167 | 0.000051 | 074496/160735 | 0.0021 | 1.1699 |\n",
      "val: {'recall': 0.994632, 'recall_grapheme': 0.991735, 'recall_vowel': 0.997099, 'recall_consonant': 0.99796, 'acc_grapheme': 0.991198, 'acc_vowel': 0.997232, 'acc_consonant': 0.997457, 'loss_grapheme': 0.039685, 'loss_vowel': 0.016694, 'loss_consonant': 0.012899}\n",
      "  168 | 0.000038 | 067584/160735 | 0.0036 | 1.1575 |\n",
      "val: {'recall': 0.996079, 'recall_grapheme': 0.994274, 'recall_vowel': 0.997723, 'recall_consonant': 0.998044, 'acc_grapheme': 0.993642, 'acc_vowel': 0.997881, 'acc_consonant': 0.997905, 'loss_grapheme': 0.033058, 'loss_vowel': 0.018078, 'loss_consonant': 0.013694}\n",
      "  169 | 0.000026 | 060672/160735 | 3.0686 | 1.0729 |\n",
      "val: {'recall': 0.995047, 'recall_grapheme': 0.993034, 'recall_vowel': 0.997384, 'recall_consonant': 0.996735, 'acc_grapheme': 0.993293, 'acc_vowel': 0.997756, 'acc_consonant': 0.997781, 'loss_grapheme': 0.045807, 'loss_vowel': 0.026281, 'loss_consonant': 0.018006}\n",
      "  170 | 0.000015 | 053760/160735 | 0.0057 | 0.9919 |\n",
      "val: {'recall': 0.996632, 'recall_grapheme': 0.995038, 'recall_vowel': 0.997785, 'recall_consonant': 0.998665, 'acc_grapheme': 0.994764, 'acc_vowel': 0.998105, 'acc_consonant': 0.99813, 'loss_grapheme': 0.036533, 'loss_vowel': 0.024516, 'loss_consonant': 0.01712}\n",
      "  171 | 0.000008 | 046848/160735 | 1.1507 | 0.9939 |\n",
      "val: {'recall': 0.995076, 'recall_grapheme': 0.993066, 'recall_vowel': 0.997165, 'recall_consonant': 0.997006, 'acc_grapheme': 0.992719, 'acc_vowel': 0.997606, 'acc_consonant': 0.997606, 'loss_grapheme': 0.032339, 'loss_vowel': 0.013926, 'loss_consonant': 0.011386}\n",
      "  172 | 0.000003 | 039936/160735 | 1.4938 | 1.1847 |\n",
      "val: {'recall': 0.996781, 'recall_grapheme': 0.99523, 'recall_vowel': 0.998025, 'recall_consonant': 0.99864, 'acc_grapheme': 0.994814, 'acc_vowel': 0.998105, 'acc_consonant': 0.998205, 'loss_grapheme': 0.03382, 'loss_vowel': 0.019634, 'loss_consonant': 0.014281}\n",
      "  173 | 0.000001 | 033024/160735 | 0.0011 | 0.8694 |\n",
      "val: {'recall': 0.995726, 'recall_grapheme': 0.994045, 'recall_vowel': 0.997484, 'recall_consonant': 0.997331, 'acc_grapheme': 0.993642, 'acc_vowel': 0.997806, 'acc_consonant': 0.99808, 'loss_grapheme': 0.029899, 'loss_vowel': 0.014443, 'loss_consonant': 0.010604}\n",
      "  174 | 0.000003 | 026112/160735 | 1.7400 | 1.2150 |\n",
      "val: {'recall': 0.995648, 'recall_grapheme': 0.993365, 'recall_vowel': 0.997629, 'recall_consonant': 0.998232, 'acc_grapheme': 0.993293, 'acc_vowel': 0.997881, 'acc_consonant': 0.997706, 'loss_grapheme': 0.040367, 'loss_vowel': 0.023768, 'loss_consonant': 0.017501}\n",
      "  175 | 0.000008 | 019200/160735 | 0.0342 | 0.8702 |\n",
      "val: {'recall': 0.996542, 'recall_grapheme': 0.994794, 'recall_vowel': 0.99801, 'recall_consonant': 0.998573, 'acc_grapheme': 0.994415, 'acc_vowel': 0.998105, 'acc_consonant': 0.99828, 'loss_grapheme': 0.025664, 'loss_vowel': 0.01175, 'loss_consonant': 0.009193}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  176 | 0.000015 | 012288/160735 | 2.4402 | 0.9590 |\n",
      "val: {'recall': 0.995664, 'recall_grapheme': 0.993392, 'recall_vowel': 0.997608, 'recall_consonant': 0.998265, 'acc_grapheme': 0.993218, 'acc_vowel': 0.997756, 'acc_consonant': 0.997731, 'loss_grapheme': 0.032383, 'loss_vowel': 0.015922, 'loss_consonant': 0.012419}\n",
      "  177 | 0.000026 | 005376/160735 | 1.4361 | 1.1820 |\n",
      "val: {'recall': 0.99608, 'recall_grapheme': 0.9943, 'recall_vowel': 0.997567, 'recall_consonant': 0.998153, 'acc_grapheme': 0.993916, 'acc_vowel': 0.997806, 'acc_consonant': 0.997856, 'loss_grapheme': 0.028746, 'loss_vowel': 0.01329, 'loss_consonant': 0.010584}\n",
      "  177 | 0.000038 | 158976/160735 | 0.0045 | 0.9369 |\n",
      "val: {'recall': 0.996069, 'recall_grapheme': 0.994068, 'recall_vowel': 0.997655, 'recall_consonant': 0.998485, 'acc_grapheme': 0.993667, 'acc_vowel': 0.997856, 'acc_consonant': 0.99793, 'loss_grapheme': 0.033645, 'loss_vowel': 0.018588, 'loss_consonant': 0.013091}\n",
      "  178 | 0.000050 | 152064/160735 | 0.0043 | 1.0196 |\n",
      "val: {'recall': 0.996664, 'recall_grapheme': 0.995164, 'recall_vowel': 0.998147, 'recall_consonant': 0.998179, 'acc_grapheme': 0.994514, 'acc_vowel': 0.99828, 'acc_consonant': 0.998354, 'loss_grapheme': 0.024323, 'loss_vowel': 0.010618, 'loss_consonant': 0.008316}\n",
      "  179 | 0.000063 | 145152/160735 | 0.0018 | 1.0600 |\n",
      "val: {'recall': 0.995562, 'recall_grapheme': 0.99372, 'recall_vowel': 0.997394, 'recall_consonant': 0.997416, 'acc_grapheme': 0.993318, 'acc_vowel': 0.997806, 'acc_consonant': 0.997631, 'loss_grapheme': 0.038067, 'loss_vowel': 0.02038, 'loss_consonant': 0.015242}\n",
      "  180 | 0.000075 | 138240/160735 | 3.3174 | 1.1025 |\n",
      "val: {'recall': 0.993761, 'recall_grapheme': 0.990906, 'recall_vowel': 0.997129, 'recall_consonant': 0.996103, 'acc_grapheme': 0.9906, 'acc_vowel': 0.997382, 'acc_consonant': 0.996908, 'loss_grapheme': 0.057533, 'loss_vowel': 0.034957, 'loss_consonant': 0.026955}\n",
      "  181 | 0.000086 | 131328/160735 | 0.0138 | 0.9377 |\n",
      "val: {'recall': 0.996121, 'recall_grapheme': 0.994027, 'recall_vowel': 0.997915, 'recall_consonant': 0.998515, 'acc_grapheme': 0.993692, 'acc_vowel': 0.997905, 'acc_consonant': 0.99813, 'loss_grapheme': 0.035705, 'loss_vowel': 0.019128, 'loss_consonant': 0.01412}\n",
      "  182 | 0.000093 | 124416/160735 | 0.3351 | 0.9134 |\n",
      "val: {'recall': 0.994187, 'recall_grapheme': 0.992146, 'recall_vowel': 0.995353, 'recall_consonant': 0.997102, 'acc_grapheme': 0.991622, 'acc_vowel': 0.996684, 'acc_consonant': 0.996709, 'loss_grapheme': 0.039402, 'loss_vowel': 0.020374, 'loss_consonant': 0.017391}\n",
      "  183 | 0.000098 | 117504/160735 | 0.0095 | 1.0369 |\n",
      "val: {'recall': 0.995164, 'recall_grapheme': 0.992852, 'recall_vowel': 0.99691, 'recall_consonant': 0.998043, 'acc_grapheme': 0.992096, 'acc_vowel': 0.997033, 'acc_consonant': 0.997083, 'loss_grapheme': 0.046046, 'loss_vowel': 0.026276, 'loss_consonant': 0.019266}\n",
      "  184 | 0.000100 | 110592/160735 | 1.5677 | 0.9722 |\n",
      "val: {'recall': 0.99621, 'recall_grapheme': 0.994413, 'recall_vowel': 0.997555, 'recall_consonant': 0.998459, 'acc_grapheme': 0.994091, 'acc_vowel': 0.997831, 'acc_consonant': 0.997706, 'loss_grapheme': 0.030072, 'loss_vowel': 0.014042, 'loss_consonant': 0.01132}\n",
      "  185 | 0.000098 | 103680/160735 | 3.4171 | 1.1373 |\n",
      "val: {'recall': 0.99422, 'recall_grapheme': 0.991752, 'recall_vowel': 0.997236, 'recall_consonant': 0.996138, 'acc_grapheme': 0.990774, 'acc_vowel': 0.997083, 'acc_consonant': 0.996434, 'loss_grapheme': 0.04812, 'loss_vowel': 0.025081, 'loss_consonant': 0.01999}\n",
      "  186 | 0.000093 | 096768/160735 | 1.2188 | 0.8193 |\n",
      "val: {'recall': 0.995742, 'recall_grapheme': 0.993511, 'recall_vowel': 0.997906, 'recall_consonant': 0.99804, 'acc_grapheme': 0.993442, 'acc_vowel': 0.997731, 'acc_consonant': 0.997507, 'loss_grapheme': 0.035405, 'loss_vowel': 0.018385, 'loss_consonant': 0.013465}\n",
      "  187 | 0.000086 | 089856/160735 | 0.0043 | 1.1346 |\n",
      "val: {'recall': 0.99475, 'recall_grapheme': 0.992611, 'recall_vowel': 0.996841, 'recall_consonant': 0.99694, 'acc_grapheme': 0.992096, 'acc_vowel': 0.997232, 'acc_consonant': 0.996958, 'loss_grapheme': 0.035282, 'loss_vowel': 0.015914, 'loss_consonant': 0.013094}\n",
      "  188 | 0.000075 | 082944/160735 | 1.9356 | 1.1199 |\n",
      "val: {'recall': 0.994922, 'recall_grapheme': 0.992539, 'recall_vowel': 0.997163, 'recall_consonant': 0.997446, 'acc_grapheme': 0.991896, 'acc_vowel': 0.997182, 'acc_consonant': 0.996958, 'loss_grapheme': 0.044561, 'loss_vowel': 0.026014, 'loss_consonant': 0.017272}\n",
      "  189 | 0.000063 | 076032/160735 | 1.0862 | 1.1370 |\n",
      "val: {'recall': 0.995216, 'recall_grapheme': 0.992789, 'recall_vowel': 0.997333, 'recall_consonant': 0.997954, 'acc_grapheme': 0.99227, 'acc_vowel': 0.997631, 'acc_consonant': 0.997482, 'loss_grapheme': 0.033463, 'loss_vowel': 0.013784, 'loss_consonant': 0.011178}\n",
      "  190 | 0.000051 | 069120/160735 | 0.0008 | 1.1398 |\n",
      "val: {'recall': 0.994738, 'recall_grapheme': 0.992326, 'recall_vowel': 0.996906, 'recall_consonant': 0.997395, 'acc_grapheme': 0.991472, 'acc_vowel': 0.997108, 'acc_consonant': 0.997033, 'loss_grapheme': 0.036293, 'loss_vowel': 0.014286, 'loss_consonant': 0.012364}\n",
      "  191 | 0.000038 | 062208/160735 | 0.0064 | 1.0836 |\n",
      "val: {'recall': 0.995962, 'recall_grapheme': 0.993961, 'recall_vowel': 0.997882, 'recall_consonant': 0.998042, 'acc_grapheme': 0.993193, 'acc_vowel': 0.997756, 'acc_consonant': 0.997631, 'loss_grapheme': 0.03149, 'loss_vowel': 0.016778, 'loss_consonant': 0.013723}\n",
      "  192 | 0.000026 | 055296/160735 | 0.0087 | 0.9724 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-96cb3a1b9641>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;31m#print('train:', train_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m#save_model(model, model_file+'_latest')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-0e344cb1f778>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.968796, 'recall_grapheme': 0.954354, 'recall_vowel': 0.981436, 'recall_consonant': 0.985042, 'acc_grapheme': 0.950954, 'acc_vowel': 0.981798, 'acc_consonant': 0.982496, 'loss_grapheme': 0.378759, 'loss_vowel': 0.200741, 'loss_consonant': 0.14877}\n",
      "    0 | 0.000100 | 153600/160735 | 2.7201 | 2.1176 |\n",
      "val: {'recall': 0.987331, 'recall_grapheme': 0.98181, 'recall_vowel': 0.994441, 'recall_consonant': 0.991263, 'acc_grapheme': 0.982521, 'acc_vowel': 0.994714, 'acc_consonant': 0.99424, 'loss_grapheme': 0.20238, 'loss_vowel': 0.171463, 'loss_consonant': 0.109966}\n",
      "** saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000098 | 146688/160735 | 1.9706 | 2.0632 |\n",
      "val: {'recall': 0.98721, 'recall_grapheme': 0.981044, 'recall_vowel': 0.993634, 'recall_consonant': 0.993119, 'acc_grapheme': 0.98297, 'acc_vowel': 0.994564, 'acc_consonant': 0.994789, 'loss_grapheme': 0.193056, 'loss_vowel': 0.165949, 'loss_consonant': 0.103149}\n",
      "    2 | 0.000093 | 139776/160735 | 1.5632 | 1.9585 |\n",
      "val: {'recall': 0.988972, 'recall_grapheme': 0.983604, 'recall_vowel': 0.993653, 'recall_consonant': 0.995028, 'acc_grapheme': 0.983992, 'acc_vowel': 0.994689, 'acc_consonant': 0.994639, 'loss_grapheme': 0.184705, 'loss_vowel': 0.15318, 'loss_consonant': 0.105877}\n",
      "** saved\n",
      "    3 | 0.000086 | 132864/160735 | 1.7528 | 2.1131 |\n",
      "val: {'recall': 0.989968, 'recall_grapheme': 0.985642, 'recall_vowel': 0.994857, 'recall_consonant': 0.993729, 'acc_grapheme': 0.98469, 'acc_vowel': 0.995437, 'acc_consonant': 0.995138, 'loss_grapheme': 0.207736, 'loss_vowel': 0.187592, 'loss_consonant': 0.11266}\n",
      "** saved\n",
      "    4 | 0.000075 | 125952/160735 | 1.5690 | 1.9051 |\n",
      "val: {'recall': 0.990287, 'recall_grapheme': 0.985763, 'recall_vowel': 0.994616, 'recall_consonant': 0.995007, 'acc_grapheme': 0.985613, 'acc_vowel': 0.995562, 'acc_consonant': 0.995462, 'loss_grapheme': 0.181378, 'loss_vowel': 0.160495, 'loss_consonant': 0.100009}\n",
      "** saved\n",
      "    5 | 0.000063 | 119040/160735 | 1.8334 | 1.9911 |\n",
      "val: {'recall': 0.990133, 'recall_grapheme': 0.985599, 'recall_vowel': 0.995602, 'recall_consonant': 0.99373, 'acc_grapheme': 0.986012, 'acc_vowel': 0.995986, 'acc_consonant': 0.995537, 'loss_grapheme': 0.166376, 'loss_vowel': 0.138689, 'loss_consonant': 0.086574}\n",
      "    6 | 0.000051 | 112128/160735 | 1.5363 | 1.9421 |\n",
      "val: {'recall': 0.990035, 'recall_grapheme': 0.986297, 'recall_vowel': 0.994267, 'recall_consonant': 0.993277, 'acc_grapheme': 0.986311, 'acc_vowel': 0.995636, 'acc_consonant': 0.995238, 'loss_grapheme': 0.145106, 'loss_vowel': 0.111144, 'loss_consonant': 0.077897}\n",
      "    7 | 0.000038 | 105216/160735 | 2.4644 | 1.9385 |\n",
      "val: {'recall': 0.990551, 'recall_grapheme': 0.985404, 'recall_vowel': 0.995076, 'recall_consonant': 0.996321, 'acc_grapheme': 0.985214, 'acc_vowel': 0.995612, 'acc_consonant': 0.995163, 'loss_grapheme': 0.212969, 'loss_vowel': 0.204959, 'loss_consonant': 0.123182}\n",
      "** saved\n",
      "    8 | 0.000026 | 098304/160735 | 2.5935 | 1.9456 |\n",
      "val: {'recall': 0.991441, 'recall_grapheme': 0.98712, 'recall_vowel': 0.995112, 'recall_consonant': 0.996412, 'acc_grapheme': 0.986959, 'acc_vowel': 0.995786, 'acc_consonant': 0.995562, 'loss_grapheme': 0.179965, 'loss_vowel': 0.16735, 'loss_consonant': 0.104465}\n",
      "** saved\n",
      "    9 | 0.000015 | 091392/160735 | 1.3296 | 1.9084 |\n",
      "val: {'recall': 0.991734, 'recall_grapheme': 0.987244, 'recall_vowel': 0.995766, 'recall_consonant': 0.99668, 'acc_grapheme': 0.987134, 'acc_vowel': 0.996135, 'acc_consonant': 0.995711, 'loss_grapheme': 0.169519, 'loss_vowel': 0.15343, 'loss_consonant': 0.097484}\n",
      "** saved\n",
      "   10 | 0.000008 | 084480/160735 | 1.4022 | 1.9163 |\n",
      "val: {'recall': 0.991499, 'recall_grapheme': 0.987133, 'recall_vowel': 0.99514, 'recall_consonant': 0.996589, 'acc_grapheme': 0.987533, 'acc_vowel': 0.995686, 'acc_consonant': 0.995636, 'loss_grapheme': 0.13179, 'loss_vowel': 0.087292, 'loss_consonant': 0.068336}\n",
      "   11 | 0.000003 | 077568/160735 | 3.0033 | 1.7967 |\n",
      "val: {'recall': 0.991709, 'recall_grapheme': 0.987508, 'recall_vowel': 0.995215, 'recall_consonant': 0.996606, 'acc_grapheme': 0.987533, 'acc_vowel': 0.995736, 'acc_consonant': 0.995612, 'loss_grapheme': 0.166281, 'loss_vowel': 0.140892, 'loss_consonant': 0.092602}\n",
      "   12 | 0.000001 | 070656/160735 | 0.8876 | 1.8258 |\n",
      "val: {'recall': 0.991361, 'recall_grapheme': 0.986783, 'recall_vowel': 0.995214, 'recall_consonant': 0.996665, 'acc_grapheme': 0.987034, 'acc_vowel': 0.995786, 'acc_consonant': 0.995861, 'loss_grapheme': 0.165974, 'loss_vowel': 0.139498, 'loss_consonant': 0.091072}\n",
      "   13 | 0.000003 | 063744/160735 | 1.1091 | 1.8960 |\n",
      "val: {'recall': 0.991477, 'recall_grapheme': 0.987007, 'recall_vowel': 0.995326, 'recall_consonant': 0.99657, 'acc_grapheme': 0.987308, 'acc_vowel': 0.995911, 'acc_consonant': 0.995612, 'loss_grapheme': 0.162519, 'loss_vowel': 0.146545, 'loss_consonant': 0.090947}\n",
      "   14 | 0.000008 | 056832/160735 | 3.1875 | 1.8456 |\n",
      "val: {'recall': 0.991678, 'recall_grapheme': 0.987274, 'recall_vowel': 0.995687, 'recall_consonant': 0.996479, 'acc_grapheme': 0.986859, 'acc_vowel': 0.99611, 'acc_consonant': 0.995686, 'loss_grapheme': 0.178977, 'loss_vowel': 0.163154, 'loss_consonant': 0.101506}\n",
      "   15 | 0.000015 | 049920/160735 | 2.2063 | 1.9190 |\n",
      "val: {'recall': 0.991707, 'recall_grapheme': 0.987399, 'recall_vowel': 0.99554, 'recall_consonant': 0.996487, 'acc_grapheme': 0.986984, 'acc_vowel': 0.995936, 'acc_consonant': 0.995686, 'loss_grapheme': 0.182326, 'loss_vowel': 0.162807, 'loss_consonant': 0.103767}\n",
      "   16 | 0.000026 | 043008/160735 | 1.8668 | 2.0000 |\n",
      "val: {'recall': 0.990305, 'recall_grapheme': 0.985843, 'recall_vowel': 0.994469, 'recall_consonant': 0.995065, 'acc_grapheme': 0.985563, 'acc_vowel': 0.995038, 'acc_consonant': 0.995088, 'loss_grapheme': 0.18777, 'loss_vowel': 0.170687, 'loss_consonant': 0.107578}\n",
      "   17 | 0.000038 | 036096/160735 | 2.3370 | 2.0084 |\n",
      "val: {'recall': 0.990352, 'recall_grapheme': 0.985249, 'recall_vowel': 0.994702, 'recall_consonant': 0.996208, 'acc_grapheme': 0.985563, 'acc_vowel': 0.995661, 'acc_consonant': 0.995213, 'loss_grapheme': 0.192563, 'loss_vowel': 0.163277, 'loss_consonant': 0.108277}\n",
      "   18 | 0.000050 | 029184/160735 | 3.7882 | 2.0209 |\n",
      "val: {'recall': 0.989889, 'recall_grapheme': 0.984669, 'recall_vowel': 0.994807, 'recall_consonant': 0.995413, 'acc_grapheme': 0.98464, 'acc_vowel': 0.995661, 'acc_consonant': 0.995312, 'loss_grapheme': 0.204139, 'loss_vowel': 0.188239, 'loss_consonant': 0.116583}\n",
      "   19 | 0.000063 | 022272/160735 | 3.0989 | 1.9353 |\n",
      "val: {'recall': 0.990122, 'recall_grapheme': 0.984663, 'recall_vowel': 0.994914, 'recall_consonant': 0.99625, 'acc_grapheme': 0.984042, 'acc_vowel': 0.995312, 'acc_consonant': 0.995387, 'loss_grapheme': 0.228385, 'loss_vowel': 0.204489, 'loss_consonant': 0.12821}\n",
      "   20 | 0.000075 | 015360/160735 | 1.3812 | 1.7326 |\n",
      "val: {'recall': 0.990443, 'recall_grapheme': 0.985838, 'recall_vowel': 0.995052, 'recall_consonant': 0.995046, 'acc_grapheme': 0.985962, 'acc_vowel': 0.995587, 'acc_consonant': 0.995636, 'loss_grapheme': 0.164637, 'loss_vowel': 0.119959, 'loss_consonant': 0.087095}\n",
      "   21 | 0.000086 | 008448/160735 | 2.1421 | 2.1415 |\n",
      "val: {'recall': 0.989218, 'recall_grapheme': 0.984551, 'recall_vowel': 0.995352, 'recall_consonant': 0.992417, 'acc_grapheme': 0.983967, 'acc_vowel': 0.995412, 'acc_consonant': 0.994639, 'loss_grapheme': 0.222395, 'loss_vowel': 0.210057, 'loss_consonant': 0.124773}\n",
      "   22 | 0.000093 | 001536/160735 | 2.3027 | 1.9659 |\n",
      "val: {'recall': 0.99039, 'recall_grapheme': 0.985835, 'recall_vowel': 0.994898, 'recall_consonant': 0.994992, 'acc_grapheme': 0.984989, 'acc_vowel': 0.995537, 'acc_consonant': 0.995262, 'loss_grapheme': 0.180731, 'loss_vowel': 0.148044, 'loss_consonant': 0.090351}\n",
      "   22 | 0.000098 | 155136/160735 | 3.3813 | 2.0456 |\n",
      "val: {'recall': 0.989434, 'recall_grapheme': 0.985597, 'recall_vowel': 0.993842, 'recall_consonant': 0.992701, 'acc_grapheme': 0.985388, 'acc_vowel': 0.995262, 'acc_consonant': 0.995362, 'loss_grapheme': 0.221609, 'loss_vowel': 0.189763, 'loss_consonant': 0.114932}\n",
      "   23 | 0.000100 | 148224/160735 | 2.2261 | 2.0311 |\n",
      "val: {'recall': 0.989119, 'recall_grapheme': 0.984076, 'recall_vowel': 0.994556, 'recall_consonant': 0.993769, 'acc_grapheme': 0.985189, 'acc_vowel': 0.995337, 'acc_consonant': 0.995188, 'loss_grapheme': 0.240987, 'loss_vowel': 0.188012, 'loss_consonant': 0.117537}\n",
      "   24 | 0.000098 | 141312/160735 | 2.3804 | 2.0768 |\n",
      "val: {'recall': 0.988772, 'recall_grapheme': 0.983166, 'recall_vowel': 0.994893, 'recall_consonant': 0.993864, 'acc_grapheme': 0.983618, 'acc_vowel': 0.995063, 'acc_consonant': 0.994888, 'loss_grapheme': 0.195533, 'loss_vowel': 0.167148, 'loss_consonant': 0.100263}\n",
      "   25 | 0.000093 | 134400/160735 | 1.8217 | 1.9206 |\n",
      "val: {'recall': 0.98925, 'recall_grapheme': 0.984659, 'recall_vowel': 0.9938, 'recall_consonant': 0.993885, 'acc_grapheme': 0.984541, 'acc_vowel': 0.995138, 'acc_consonant': 0.994514, 'loss_grapheme': 0.167812, 'loss_vowel': 0.099309, 'loss_consonant': 0.077924}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 0.000086 | 127488/160735 | 0.6730 | 1.8537 |\n",
      "val: {'recall': 0.986989, 'recall_grapheme': 0.980761, 'recall_vowel': 0.993584, 'recall_consonant': 0.992849, 'acc_grapheme': 0.983369, 'acc_vowel': 0.994714, 'acc_consonant': 0.994514, 'loss_grapheme': 0.165355, 'loss_vowel': 0.096894, 'loss_consonant': 0.069883}\n",
      "   27 | 0.000075 | 120576/160735 | 1.5488 | 1.8665 |\n",
      "val: {'recall': 0.989669, 'recall_grapheme': 0.985103, 'recall_vowel': 0.994121, 'recall_consonant': 0.994349, 'acc_grapheme': 0.984241, 'acc_vowel': 0.995437, 'acc_consonant': 0.994664, 'loss_grapheme': 0.199886, 'loss_vowel': 0.181033, 'loss_consonant': 0.106551}\n",
      "   28 | 0.000063 | 113664/160735 | 1.7374 | 1.8715 |\n",
      "val: {'recall': 0.991073, 'recall_grapheme': 0.986988, 'recall_vowel': 0.99497, 'recall_consonant': 0.995346, 'acc_grapheme': 0.987408, 'acc_vowel': 0.995562, 'acc_consonant': 0.995312, 'loss_grapheme': 0.119674, 'loss_vowel': 0.082174, 'loss_consonant': 0.058381}\n",
      "   29 | 0.000051 | 106752/160735 | 1.5602 | 1.9097 |\n",
      "val: {'recall': 0.991496, 'recall_grapheme': 0.987243, 'recall_vowel': 0.994659, 'recall_consonant': 0.996838, 'acc_grapheme': 0.986859, 'acc_vowel': 0.995587, 'acc_consonant': 0.995811, 'loss_grapheme': 0.171953, 'loss_vowel': 0.181384, 'loss_consonant': 0.107863}\n",
      "   30 | 0.000038 | 099840/160735 | 1.4834 | 1.8437 |\n",
      "val: {'recall': 0.992107, 'recall_grapheme': 0.988183, 'recall_vowel': 0.995509, 'recall_consonant': 0.996554, 'acc_grapheme': 0.988156, 'acc_vowel': 0.99626, 'acc_consonant': 0.995936, 'loss_grapheme': 0.157556, 'loss_vowel': 0.130161, 'loss_consonant': 0.079627}\n",
      "** saved\n",
      "   31 | 0.000026 | 092928/160735 | 1.7507 | 1.8854 |\n",
      "val: {'recall': 0.991859, 'recall_grapheme': 0.987408, 'recall_vowel': 0.995874, 'recall_consonant': 0.996745, 'acc_grapheme': 0.987982, 'acc_vowel': 0.996434, 'acc_consonant': 0.996185, 'loss_grapheme': 0.152768, 'loss_vowel': 0.131905, 'loss_consonant': 0.081757}\n",
      "   32 | 0.000015 | 086016/160735 | 3.9112 | 1.8788 |\n",
      "val: {'recall': 0.991457, 'recall_grapheme': 0.987252, 'recall_vowel': 0.995418, 'recall_consonant': 0.995906, 'acc_grapheme': 0.987657, 'acc_vowel': 0.996135, 'acc_consonant': 0.99616, 'loss_grapheme': 0.192357, 'loss_vowel': 0.168211, 'loss_consonant': 0.105698}\n",
      "   33 | 0.000008 | 079104/160735 | 1.8445 | 1.8180 |\n",
      "val: {'recall': 0.99195, 'recall_grapheme': 0.98792, 'recall_vowel': 0.996121, 'recall_consonant': 0.995838, 'acc_grapheme': 0.98853, 'acc_vowel': 0.996459, 'acc_consonant': 0.996135, 'loss_grapheme': 0.178283, 'loss_vowel': 0.149685, 'loss_consonant': 0.094951}\n",
      "   34 | 0.000003 | 072192/160735 | 1.1636 | 1.9638 |\n",
      "val: {'recall': 0.991762, 'recall_grapheme': 0.987699, 'recall_vowel': 0.995972, 'recall_consonant': 0.995679, 'acc_grapheme': 0.988356, 'acc_vowel': 0.996285, 'acc_consonant': 0.996035, 'loss_grapheme': 0.159187, 'loss_vowel': 0.135998, 'loss_consonant': 0.087844}\n",
      "   35 | 0.000001 | 065280/160735 | 1.4766 | 1.8466 |\n",
      "val: {'recall': 0.992293, 'recall_grapheme': 0.988761, 'recall_vowel': 0.995714, 'recall_consonant': 0.995936, 'acc_grapheme': 0.988705, 'acc_vowel': 0.996409, 'acc_consonant': 0.99611, 'loss_grapheme': 0.165501, 'loss_vowel': 0.158169, 'loss_consonant': 0.09679}\n",
      "** saved\n",
      "   36 | 0.000003 | 058368/160735 | 2.9711 | 2.0057 |\n",
      "val: {'recall': 0.991332, 'recall_grapheme': 0.986999, 'recall_vowel': 0.995578, 'recall_consonant': 0.995753, 'acc_grapheme': 0.98681, 'acc_vowel': 0.996085, 'acc_consonant': 0.996135, 'loss_grapheme': 0.199227, 'loss_vowel': 0.192009, 'loss_consonant': 0.116724}\n",
      "   37 | 0.000008 | 051456/160735 | 1.6276 | 1.8162 |\n",
      "val: {'recall': 0.991364, 'recall_grapheme': 0.988012, 'recall_vowel': 0.995566, 'recall_consonant': 0.993866, 'acc_grapheme': 0.989004, 'acc_vowel': 0.99601, 'acc_consonant': 0.99606, 'loss_grapheme': 0.135353, 'loss_vowel': 0.083454, 'loss_consonant': 0.066661}\n",
      "   38 | 0.000015 | 044544/160735 | 3.6550 | 1.8455 |\n",
      "val: {'recall': 0.991845, 'recall_grapheme': 0.988112, 'recall_vowel': 0.995409, 'recall_consonant': 0.99575, 'acc_grapheme': 0.98873, 'acc_vowel': 0.996135, 'acc_consonant': 0.99606, 'loss_grapheme': 0.174336, 'loss_vowel': 0.144189, 'loss_consonant': 0.093171}\n",
      "   39 | 0.000026 | 037632/160735 | 2.0499 | 1.9811 |\n",
      "val: {'recall': 0.991919, 'recall_grapheme': 0.987379, 'recall_vowel': 0.995908, 'recall_consonant': 0.997007, 'acc_grapheme': 0.987358, 'acc_vowel': 0.99631, 'acc_consonant': 0.99611, 'loss_grapheme': 0.214186, 'loss_vowel': 0.194677, 'loss_consonant': 0.121661}\n",
      "   40 | 0.000038 | 030720/160735 | 2.6050 | 1.7803 |\n",
      "val: {'recall': 0.992207, 'recall_grapheme': 0.98846, 'recall_vowel': 0.995713, 'recall_consonant': 0.996194, 'acc_grapheme': 0.987857, 'acc_vowel': 0.995836, 'acc_consonant': 0.995836, 'loss_grapheme': 0.161916, 'loss_vowel': 0.144222, 'loss_consonant': 0.087121}\n",
      "   41 | 0.000050 | 023808/160735 | 1.4072 | 1.8842 |\n",
      "val: {'recall': 0.989949, 'recall_grapheme': 0.985924, 'recall_vowel': 0.995153, 'recall_consonant': 0.992795, 'acc_grapheme': 0.986411, 'acc_vowel': 0.995786, 'acc_consonant': 0.995462, 'loss_grapheme': 0.196007, 'loss_vowel': 0.172345, 'loss_consonant': 0.108533}\n",
      "   42 | 0.000063 | 016896/160735 | 1.8510 | 2.1545 |\n",
      "val: {'recall': 0.990329, 'recall_grapheme': 0.984988, 'recall_vowel': 0.9949, 'recall_consonant': 0.996438, 'acc_grapheme': 0.985713, 'acc_vowel': 0.995612, 'acc_consonant': 0.995711, 'loss_grapheme': 0.198567, 'loss_vowel': 0.181592, 'loss_consonant': 0.113324}\n",
      "   43 | 0.000075 | 009984/160735 | 0.9532 | 1.7980 |\n",
      "val: {'recall': 0.991317, 'recall_grapheme': 0.986962, 'recall_vowel': 0.995525, 'recall_consonant': 0.995819, 'acc_grapheme': 0.987433, 'acc_vowel': 0.996135, 'acc_consonant': 0.995911, 'loss_grapheme': 0.157765, 'loss_vowel': 0.118792, 'loss_consonant': 0.080531}\n",
      "   44 | 0.000086 | 003072/160735 | 0.8936 | 1.7615 |\n",
      "val: {'recall': 0.989548, 'recall_grapheme': 0.985504, 'recall_vowel': 0.994444, 'recall_consonant': 0.992742, 'acc_grapheme': 0.985239, 'acc_vowel': 0.995287, 'acc_consonant': 0.995038, 'loss_grapheme': 0.205135, 'loss_vowel': 0.15303, 'loss_consonant': 0.093028}\n",
      "   44 | 0.000093 | 156672/160735 | 2.1341 | 1.9246 |\n",
      "val: {'recall': 0.990936, 'recall_grapheme': 0.986626, 'recall_vowel': 0.995628, 'recall_consonant': 0.994863, 'acc_grapheme': 0.986361, 'acc_vowel': 0.996035, 'acc_consonant': 0.995412, 'loss_grapheme': 0.221351, 'loss_vowel': 0.200434, 'loss_consonant': 0.120702}\n",
      "   45 | 0.000098 | 149760/160735 | 1.5953 | 1.8358 |\n",
      "val: {'recall': 0.989942, 'recall_grapheme': 0.986079, 'recall_vowel': 0.994909, 'recall_consonant': 0.9927, 'acc_grapheme': 0.986087, 'acc_vowel': 0.995811, 'acc_consonant': 0.995138, 'loss_grapheme': 0.182594, 'loss_vowel': 0.165489, 'loss_consonant': 0.100953}\n",
      "   46 | 0.000100 | 142848/160735 | 3.3020 | 1.9535 |\n",
      "val: {'recall': 0.98893, 'recall_grapheme': 0.983784, 'recall_vowel': 0.994134, 'recall_consonant': 0.99402, 'acc_grapheme': 0.983967, 'acc_vowel': 0.995038, 'acc_consonant': 0.994689, 'loss_grapheme': 0.227744, 'loss_vowel': 0.179821, 'loss_consonant': 0.113933}\n",
      "   47 | 0.000098 | 135936/160735 | 1.3981 | 1.9169 |\n",
      "val: {'recall': 0.990885, 'recall_grapheme': 0.986633, 'recall_vowel': 0.995836, 'recall_consonant': 0.994437, 'acc_grapheme': 0.98661, 'acc_vowel': 0.995587, 'acc_consonant': 0.995337, 'loss_grapheme': 0.17511, 'loss_vowel': 0.144481, 'loss_consonant': 0.091322}\n",
      "   48 | 0.000093 | 129024/160735 | 1.5278 | 1.9726 |\n",
      "val: {'recall': 0.990449, 'recall_grapheme': 0.986368, 'recall_vowel': 0.995597, 'recall_consonant': 0.993462, 'acc_grapheme': 0.986635, 'acc_vowel': 0.996035, 'acc_consonant': 0.995437, 'loss_grapheme': 0.188295, 'loss_vowel': 0.14144, 'loss_consonant': 0.090113}\n",
      "   49 | 0.000086 | 122112/160735 | 2.6124 | 1.9781 |\n",
      "val: {'recall': 0.99151, 'recall_grapheme': 0.987595, 'recall_vowel': 0.995587, 'recall_consonant': 0.995264, 'acc_grapheme': 0.986735, 'acc_vowel': 0.995786, 'acc_consonant': 0.995686, 'loss_grapheme': 0.202754, 'loss_vowel': 0.199263, 'loss_consonant': 0.103891}\n",
      "   50 | 0.000075 | 115200/160735 | 1.8216 | 1.9118 |\n",
      "val: {'recall': 0.991227, 'recall_grapheme': 0.988147, 'recall_vowel': 0.995202, 'recall_consonant': 0.993412, 'acc_grapheme': 0.988605, 'acc_vowel': 0.995986, 'acc_consonant': 0.995761, 'loss_grapheme': 0.171771, 'loss_vowel': 0.137983, 'loss_consonant': 0.093279}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 0.000063 | 108288/160735 | 0.8534 | 1.9240 |\n",
      "val: {'recall': 0.992213, 'recall_grapheme': 0.988386, 'recall_vowel': 0.996299, 'recall_consonant': 0.995783, 'acc_grapheme': 0.988131, 'acc_vowel': 0.995986, 'acc_consonant': 0.995886, 'loss_grapheme': 0.172872, 'loss_vowel': 0.14041, 'loss_consonant': 0.089729}\n",
      "   52 | 0.000051 | 101376/160735 | 1.8692 | 1.8458 |\n",
      "val: {'recall': 0.992772, 'recall_grapheme': 0.989642, 'recall_vowel': 0.996197, 'recall_consonant': 0.995609, 'acc_grapheme': 0.989453, 'acc_vowel': 0.996335, 'acc_consonant': 0.995886, 'loss_grapheme': 0.135381, 'loss_vowel': 0.090325, 'loss_consonant': 0.06973}\n",
      "** saved\n",
      "   53 | 0.000038 | 094464/160735 | 0.6151 | 1.8515 |\n",
      "val: {'recall': 0.992988, 'recall_grapheme': 0.989467, 'recall_vowel': 0.995835, 'recall_consonant': 0.997184, 'acc_grapheme': 0.988979, 'acc_vowel': 0.996509, 'acc_consonant': 0.99631, 'loss_grapheme': 0.170543, 'loss_vowel': 0.143205, 'loss_consonant': 0.086028}\n",
      "** saved\n",
      "   54 | 0.000026 | 087552/160735 | 1.6701 | 1.8294 |\n",
      "val: {'recall': 0.993216, 'recall_grapheme': 0.989801, 'recall_vowel': 0.996194, 'recall_consonant': 0.997066, 'acc_grapheme': 0.989303, 'acc_vowel': 0.996559, 'acc_consonant': 0.996335, 'loss_grapheme': 0.147518, 'loss_vowel': 0.120864, 'loss_consonant': 0.077687}\n",
      "** saved\n",
      "   55 | 0.000015 | 080640/160735 | 0.1314 | 1.7849 |\n",
      "val: {'recall': 0.992292, 'recall_grapheme': 0.988659, 'recall_vowel': 0.995996, 'recall_consonant': 0.995856, 'acc_grapheme': 0.988356, 'acc_vowel': 0.99626, 'acc_consonant': 0.99606, 'loss_grapheme': 0.188645, 'loss_vowel': 0.173052, 'loss_consonant': 0.104445}\n",
      "   56 | 0.000008 | 073728/160735 | 1.4584 | 1.6380 |\n",
      "val: {'recall': 0.993107, 'recall_grapheme': 0.98977, 'recall_vowel': 0.995891, 'recall_consonant': 0.996997, 'acc_grapheme': 0.989428, 'acc_vowel': 0.996484, 'acc_consonant': 0.99626, 'loss_grapheme': 0.161029, 'loss_vowel': 0.12244, 'loss_consonant': 0.084564}\n",
      "   57 | 0.000003 | 066816/160735 | 1.4261 | 1.8327 |\n",
      "val: {'recall': 0.99223, 'recall_grapheme': 0.988502, 'recall_vowel': 0.99605, 'recall_consonant': 0.995865, 'acc_grapheme': 0.987732, 'acc_vowel': 0.996335, 'acc_consonant': 0.995986, 'loss_grapheme': 0.203214, 'loss_vowel': 0.177957, 'loss_consonant': 0.108143}\n",
      "   58 | 0.000001 | 059904/160735 | 1.2640 | 1.9435 |\n",
      "val: {'recall': 0.992616, 'recall_grapheme': 0.989213, 'recall_vowel': 0.996164, 'recall_consonant': 0.995876, 'acc_grapheme': 0.988605, 'acc_vowel': 0.996534, 'acc_consonant': 0.996135, 'loss_grapheme': 0.187174, 'loss_vowel': 0.165912, 'loss_consonant': 0.099819}\n",
      "   59 | 0.000003 | 052992/160735 | 1.5280 | 1.7175 |\n",
      "val: {'recall': 0.993386, 'recall_grapheme': 0.990064, 'recall_vowel': 0.996365, 'recall_consonant': 0.997048, 'acc_grapheme': 0.989577, 'acc_vowel': 0.996783, 'acc_consonant': 0.996235, 'loss_grapheme': 0.156084, 'loss_vowel': 0.132882, 'loss_consonant': 0.081281}\n",
      "** saved\n",
      "   60 | 0.000008 | 046080/160735 | 1.6948 | 1.6586 |\n",
      "val: {'recall': 0.99297, 'recall_grapheme': 0.989878, 'recall_vowel': 0.996176, 'recall_consonant': 0.995947, 'acc_grapheme': 0.989303, 'acc_vowel': 0.996609, 'acc_consonant': 0.99611, 'loss_grapheme': 0.166557, 'loss_vowel': 0.146479, 'loss_consonant': 0.089275}\n",
      "   61 | 0.000015 | 039168/160735 | 1.6050 | 1.9275 |\n",
      "val: {'recall': 0.992557, 'recall_grapheme': 0.989149, 'recall_vowel': 0.996145, 'recall_consonant': 0.995787, 'acc_grapheme': 0.988256, 'acc_vowel': 0.996634, 'acc_consonant': 0.995986, 'loss_grapheme': 0.206832, 'loss_vowel': 0.193085, 'loss_consonant': 0.119956}\n",
      "   62 | 0.000026 | 032256/160735 | 1.3208 | 1.8922 |\n",
      "val: {'recall': 0.992665, 'recall_grapheme': 0.988849, 'recall_vowel': 0.995893, 'recall_consonant': 0.997068, 'acc_grapheme': 0.988779, 'acc_vowel': 0.996409, 'acc_consonant': 0.99601, 'loss_grapheme': 0.17766, 'loss_vowel': 0.155874, 'loss_consonant': 0.095932}\n",
      "   63 | 0.000038 | 025344/160735 | 1.7530 | 1.6964 |\n",
      "val: {'recall': 0.991343, 'recall_grapheme': 0.987555, 'recall_vowel': 0.995018, 'recall_consonant': 0.995246, 'acc_grapheme': 0.987657, 'acc_vowel': 0.995961, 'acc_consonant': 0.995686, 'loss_grapheme': 0.148497, 'loss_vowel': 0.087923, 'loss_consonant': 0.072887}\n",
      "   64 | 0.000051 | 018432/160735 | 1.8209 | 2.0543 |\n",
      "val: {'recall': 0.991365, 'recall_grapheme': 0.986694, 'recall_vowel': 0.995675, 'recall_consonant': 0.996397, 'acc_grapheme': 0.98656, 'acc_vowel': 0.995936, 'acc_consonant': 0.995786, 'loss_grapheme': 0.181364, 'loss_vowel': 0.151675, 'loss_consonant': 0.093539}\n",
      "   65 | 0.000063 | 011520/160735 | 1.6791 | 1.8193 |\n",
      "val: {'recall': 0.991927, 'recall_grapheme': 0.988382, 'recall_vowel': 0.995846, 'recall_consonant': 0.995099, 'acc_grapheme': 0.987533, 'acc_vowel': 0.996235, 'acc_consonant': 0.995512, 'loss_grapheme': 0.156653, 'loss_vowel': 0.132454, 'loss_consonant': 0.091501}\n",
      "   66 | 0.000075 | 004608/160735 | 0.6412 | 1.3438 |\n",
      "val: {'recall': 0.992754, 'recall_grapheme': 0.988887, 'recall_vowel': 0.99625, 'recall_consonant': 0.996994, 'acc_grapheme': 0.987982, 'acc_vowel': 0.996484, 'acc_consonant': 0.99616, 'loss_grapheme': 0.165009, 'loss_vowel': 0.132675, 'loss_consonant': 0.084226}\n",
      "   66 | 0.000086 | 158208/160735 | 2.2148 | 1.8431 |\n",
      "val: {'recall': 0.991566, 'recall_grapheme': 0.987696, 'recall_vowel': 0.996421, 'recall_consonant': 0.994453, 'acc_grapheme': 0.98671, 'acc_vowel': 0.996285, 'acc_consonant': 0.995636, 'loss_grapheme': 0.18254, 'loss_vowel': 0.156374, 'loss_consonant': 0.101236}\n",
      "   67 | 0.000093 | 151296/160735 | 3.8953 | 1.9722 |\n",
      "val: {'recall': 0.99089, 'recall_grapheme': 0.986131, 'recall_vowel': 0.996119, 'recall_consonant': 0.995179, 'acc_grapheme': 0.986111, 'acc_vowel': 0.995886, 'acc_consonant': 0.994115, 'loss_grapheme': 0.212863, 'loss_vowel': 0.200628, 'loss_consonant': 0.123493}\n",
      "   68 | 0.000098 | 144384/160735 | 0.2011 | 1.9740 |\n",
      "val: {'recall': 0.99203, 'recall_grapheme': 0.987769, 'recall_vowel': 0.9959, 'recall_consonant': 0.996685, 'acc_grapheme': 0.987757, 'acc_vowel': 0.99626, 'acc_consonant': 0.995562, 'loss_grapheme': 0.173471, 'loss_vowel': 0.138537, 'loss_consonant': 0.092692}\n",
      "   69 | 0.000100 | 137472/160735 | 3.1786 | 1.8187 |\n",
      "val: {'recall': 0.990379, 'recall_grapheme': 0.985849, 'recall_vowel': 0.99583, 'recall_consonant': 0.993989, 'acc_grapheme': 0.986111, 'acc_vowel': 0.995911, 'acc_consonant': 0.995213, 'loss_grapheme': 0.232199, 'loss_vowel': 0.200009, 'loss_consonant': 0.127818}\n",
      "   70 | 0.000098 | 130560/160735 | 1.2429 | 1.8594 |\n",
      "val: {'recall': 0.99241, 'recall_grapheme': 0.988393, 'recall_vowel': 0.996451, 'recall_consonant': 0.996405, 'acc_grapheme': 0.98848, 'acc_vowel': 0.996584, 'acc_consonant': 0.995936, 'loss_grapheme': 0.164711, 'loss_vowel': 0.135558, 'loss_consonant': 0.084546}\n",
      "   71 | 0.000093 | 123648/160735 | 3.0502 | 1.7979 |\n",
      "val: {'recall': 0.99092, 'recall_grapheme': 0.986334, 'recall_vowel': 0.995529, 'recall_consonant': 0.995483, 'acc_grapheme': 0.987034, 'acc_vowel': 0.995786, 'acc_consonant': 0.995038, 'loss_grapheme': 0.189306, 'loss_vowel': 0.160971, 'loss_consonant': 0.101306}\n",
      "   72 | 0.000086 | 116736/160735 | 1.2121 | 1.8412 |\n",
      "val: {'recall': 0.990819, 'recall_grapheme': 0.986369, 'recall_vowel': 0.995181, 'recall_consonant': 0.995355, 'acc_grapheme': 0.987333, 'acc_vowel': 0.995861, 'acc_consonant': 0.995262, 'loss_grapheme': 0.177696, 'loss_vowel': 0.151484, 'loss_consonant': 0.091947}\n",
      "   73 | 0.000075 | 109824/160735 | 3.1897 | 1.7792 |\n",
      "val: {'recall': 0.990836, 'recall_grapheme': 0.987799, 'recall_vowel': 0.994987, 'recall_consonant': 0.99276, 'acc_grapheme': 0.988281, 'acc_vowel': 0.99601, 'acc_consonant': 0.995661, 'loss_grapheme': 0.183025, 'loss_vowel': 0.146307, 'loss_consonant': 0.095422}\n",
      "   74 | 0.000063 | 102912/160735 | 2.5660 | 1.9119 |\n",
      "val: {'recall': 0.992444, 'recall_grapheme': 0.989047, 'recall_vowel': 0.995837, 'recall_consonant': 0.995846, 'acc_grapheme': 0.988705, 'acc_vowel': 0.996559, 'acc_consonant': 0.995761, 'loss_grapheme': 0.179173, 'loss_vowel': 0.163684, 'loss_consonant': 0.101423}\n",
      "   75 | 0.000051 | 096000/160735 | 1.5479 | 1.8057 |\n",
      "val: {'recall': 0.992354, 'recall_grapheme': 0.98868, 'recall_vowel': 0.996498, 'recall_consonant': 0.995556, 'acc_grapheme': 0.988031, 'acc_vowel': 0.996759, 'acc_consonant': 0.995612, 'loss_grapheme': 0.162501, 'loss_vowel': 0.14013, 'loss_consonant': 0.088039}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76 | 0.000038 | 089088/160735 | 1.7339 | 1.7588 |\n",
      "val: {'recall': 0.992533, 'recall_grapheme': 0.989128, 'recall_vowel': 0.995878, 'recall_consonant': 0.995998, 'acc_grapheme': 0.990101, 'acc_vowel': 0.996808, 'acc_consonant': 0.996609, 'loss_grapheme': 0.126719, 'loss_vowel': 0.091811, 'loss_consonant': 0.060809}\n",
      "   77 | 0.000026 | 082176/160735 | 2.1953 | 1.9615 |\n",
      "val: {'recall': 0.991878, 'recall_grapheme': 0.98777, 'recall_vowel': 0.99631, 'recall_consonant': 0.995664, 'acc_grapheme': 0.988006, 'acc_vowel': 0.996783, 'acc_consonant': 0.995736, 'loss_grapheme': 0.199839, 'loss_vowel': 0.195173, 'loss_consonant': 0.119304}\n",
      "   78 | 0.000015 | 075264/160735 | 1.9683 | 1.7289 |\n",
      "val: {'recall': 0.991602, 'recall_grapheme': 0.987989, 'recall_vowel': 0.995791, 'recall_consonant': 0.99464, 'acc_grapheme': 0.988331, 'acc_vowel': 0.996509, 'acc_consonant': 0.995961, 'loss_grapheme': 0.181821, 'loss_vowel': 0.16174, 'loss_consonant': 0.100145}\n",
      "   79 | 0.000008 | 068352/160735 | 1.5132 | 1.8153 |\n",
      "val: {'recall': 0.99277, 'recall_grapheme': 0.988925, 'recall_vowel': 0.99663, 'recall_consonant': 0.996599, 'acc_grapheme': 0.989129, 'acc_vowel': 0.996933, 'acc_consonant': 0.995961, 'loss_grapheme': 0.160093, 'loss_vowel': 0.146852, 'loss_consonant': 0.090879}\n",
      "   80 | 0.000003 | 061440/160735 | 1.5801 | 1.7238 |\n",
      "val: {'recall': 0.992096, 'recall_grapheme': 0.988441, 'recall_vowel': 0.996199, 'recall_consonant': 0.995303, 'acc_grapheme': 0.988181, 'acc_vowel': 0.996684, 'acc_consonant': 0.995612, 'loss_grapheme': 0.16402, 'loss_vowel': 0.157182, 'loss_consonant': 0.096889}\n",
      "   81 | 0.000001 | 054528/160735 | 2.7102 | 1.7802 |\n",
      "val: {'recall': 0.99332, 'recall_grapheme': 0.989947, 'recall_vowel': 0.996719, 'recall_consonant': 0.996667, 'acc_grapheme': 0.989926, 'acc_vowel': 0.997083, 'acc_consonant': 0.996384, 'loss_grapheme': 0.151294, 'loss_vowel': 0.132155, 'loss_consonant': 0.080938}\n",
      "   82 | 0.000003 | 047616/160735 | 1.7991 | 1.7593 |\n",
      "val: {'recall': 0.992802, 'recall_grapheme': 0.989014, 'recall_vowel': 0.996547, 'recall_consonant': 0.996632, 'acc_grapheme': 0.989353, 'acc_vowel': 0.996983, 'acc_consonant': 0.996384, 'loss_grapheme': 0.160317, 'loss_vowel': 0.136859, 'loss_consonant': 0.083781}\n",
      "   83 | 0.000008 | 040704/160735 | 0.1048 | 1.8766 |\n",
      "val: {'recall': 0.992804, 'recall_grapheme': 0.989761, 'recall_vowel': 0.99631, 'recall_consonant': 0.995386, 'acc_grapheme': 0.989203, 'acc_vowel': 0.996958, 'acc_consonant': 0.99606, 'loss_grapheme': 0.16114, 'loss_vowel': 0.146617, 'loss_consonant': 0.090107}\n",
      "   84 | 0.000015 | 033792/160735 | 2.5431 | 1.6399 |\n",
      "val: {'recall': 0.993722, 'recall_grapheme': 0.990424, 'recall_vowel': 0.996638, 'recall_consonant': 0.997404, 'acc_grapheme': 0.989951, 'acc_vowel': 0.997058, 'acc_consonant': 0.99626, 'loss_grapheme': 0.148842, 'loss_vowel': 0.129045, 'loss_consonant': 0.081981}\n",
      "** saved\n",
      "   85 | 0.000026 | 026880/160735 | 2.1998 | 1.7251 |\n",
      "val: {'recall': 0.992539, 'recall_grapheme': 0.989313, 'recall_vowel': 0.995836, 'recall_consonant': 0.995693, 'acc_grapheme': 0.988854, 'acc_vowel': 0.996808, 'acc_consonant': 0.996085, 'loss_grapheme': 0.163965, 'loss_vowel': 0.138421, 'loss_consonant': 0.088122}\n",
      "   86 | 0.000038 | 019968/160735 | 2.3829 | 1.7310 |\n",
      "val: {'recall': 0.992742, 'recall_grapheme': 0.989152, 'recall_vowel': 0.996411, 'recall_consonant': 0.996251, 'acc_grapheme': 0.989253, 'acc_vowel': 0.996858, 'acc_consonant': 0.996434, 'loss_grapheme': 0.170792, 'loss_vowel': 0.146587, 'loss_consonant': 0.089805}\n",
      "   87 | 0.000051 | 013056/160735 | 3.4271 | 1.6625 |\n",
      "val: {'recall': 0.992044, 'recall_grapheme': 0.988502, 'recall_vowel': 0.995827, 'recall_consonant': 0.995344, 'acc_grapheme': 0.98858, 'acc_vowel': 0.996684, 'acc_consonant': 0.996035, 'loss_grapheme': 0.163009, 'loss_vowel': 0.131473, 'loss_consonant': 0.083461}\n",
      "   88 | 0.000063 | 006144/160735 | 1.9276 | 1.2914 |\n",
      "val: {'recall': 0.99303, 'recall_grapheme': 0.98934, 'recall_vowel': 0.996003, 'recall_consonant': 0.997436, 'acc_grapheme': 0.989253, 'acc_vowel': 0.996684, 'acc_consonant': 0.996285, 'loss_grapheme': 0.184928, 'loss_vowel': 0.141483, 'loss_consonant': 0.084637}\n",
      "   88 | 0.000075 | 159744/160735 | 1.4486 | 1.7823 |\n",
      "val: {'recall': 0.99262, 'recall_grapheme': 0.988714, 'recall_vowel': 0.996001, 'recall_consonant': 0.99705, 'acc_grapheme': 0.988879, 'acc_vowel': 0.996484, 'acc_consonant': 0.995961, 'loss_grapheme': 0.167773, 'loss_vowel': 0.128246, 'loss_consonant': 0.077972}\n",
      "   89 | 0.000086 | 152832/160735 | 2.0558 | 1.8931 |\n",
      "val: {'recall': 0.991983, 'recall_grapheme': 0.988458, 'recall_vowel': 0.995799, 'recall_consonant': 0.995218, 'acc_grapheme': 0.988256, 'acc_vowel': 0.996434, 'acc_consonant': 0.995786, 'loss_grapheme': 0.165037, 'loss_vowel': 0.132189, 'loss_consonant': 0.084691}\n",
      "   90 | 0.000093 | 145920/160735 | 1.6676 | 1.8103 |\n",
      "val: {'recall': 0.992015, 'recall_grapheme': 0.988798, 'recall_vowel': 0.995227, 'recall_consonant': 0.995239, 'acc_grapheme': 0.988705, 'acc_vowel': 0.996185, 'acc_consonant': 0.995487, 'loss_grapheme': 0.192852, 'loss_vowel': 0.147865, 'loss_consonant': 0.089902}\n",
      "   91 | 0.000098 | 139008/160735 | 1.3244 | 1.7088 |\n",
      "val: {'recall': 0.992958, 'recall_grapheme': 0.989885, 'recall_vowel': 0.996814, 'recall_consonant': 0.995249, 'acc_grapheme': 0.989852, 'acc_vowel': 0.996709, 'acc_consonant': 0.996085, 'loss_grapheme': 0.184014, 'loss_vowel': 0.155133, 'loss_consonant': 0.091357}\n",
      "   92 | 0.000100 | 132096/160735 | 2.8505 | 1.9193 |\n",
      "val: {'recall': 0.991864, 'recall_grapheme': 0.988731, 'recall_vowel': 0.995673, 'recall_consonant': 0.994319, 'acc_grapheme': 0.986934, 'acc_vowel': 0.995861, 'acc_consonant': 0.994664, 'loss_grapheme': 0.175709, 'loss_vowel': 0.155121, 'loss_consonant': 0.095092}\n",
      "   93 | 0.000098 | 125184/160735 | 0.5159 | 1.8426 |\n",
      "val: {'recall': 0.99072, 'recall_grapheme': 0.98651, 'recall_vowel': 0.995553, 'recall_consonant': 0.994307, 'acc_grapheme': 0.987583, 'acc_vowel': 0.996335, 'acc_consonant': 0.995886, 'loss_grapheme': 0.191822, 'loss_vowel': 0.142595, 'loss_consonant': 0.089313}\n",
      "   94 | 0.000093 | 118272/160735 | 2.9272 | 1.8467 |\n",
      "val: {'recall': 0.991485, 'recall_grapheme': 0.986849, 'recall_vowel': 0.995825, 'recall_consonant': 0.996418, 'acc_grapheme': 0.987707, 'acc_vowel': 0.996459, 'acc_consonant': 0.995462, 'loss_grapheme': 0.18295, 'loss_vowel': 0.140749, 'loss_consonant': 0.085365}\n",
      "   95 | 0.000086 | 111360/160735 | 3.3159 | 1.8447 |\n",
      "val: {'recall': 0.990485, 'recall_grapheme': 0.986022, 'recall_vowel': 0.995282, 'recall_consonant': 0.994616, 'acc_grapheme': 0.986485, 'acc_vowel': 0.99626, 'acc_consonant': 0.994839, 'loss_grapheme': 0.232469, 'loss_vowel': 0.198522, 'loss_consonant': 0.124921}\n",
      "   96 | 0.000075 | 104448/160735 | 1.6802 | 1.8112 |\n",
      "val: {'recall': 0.991147, 'recall_grapheme': 0.986536, 'recall_vowel': 0.996009, 'recall_consonant': 0.995505, 'acc_grapheme': 0.987134, 'acc_vowel': 0.99636, 'acc_consonant': 0.995387, 'loss_grapheme': 0.191637, 'loss_vowel': 0.153551, 'loss_consonant': 0.096677}\n",
      "   97 | 0.000063 | 097536/160735 | 0.8740 | 1.8270 |\n",
      "val: {'recall': 0.992214, 'recall_grapheme': 0.988565, 'recall_vowel': 0.996258, 'recall_consonant': 0.99547, 'acc_grapheme': 0.987882, 'acc_vowel': 0.996659, 'acc_consonant': 0.995587, 'loss_grapheme': 0.195582, 'loss_vowel': 0.166549, 'loss_consonant': 0.104541}\n",
      "   98 | 0.000051 | 090624/160735 | 1.5244 | 1.8168 |\n",
      "val: {'recall': 0.992475, 'recall_grapheme': 0.988712, 'recall_vowel': 0.996309, 'recall_consonant': 0.996165, 'acc_grapheme': 0.988331, 'acc_vowel': 0.996933, 'acc_consonant': 0.995587, 'loss_grapheme': 0.185179, 'loss_vowel': 0.167469, 'loss_consonant': 0.104673}\n",
      "   99 | 0.000038 | 083712/160735 | 3.7267 | 1.8847 |\n",
      "val: {'recall': 0.991939, 'recall_grapheme': 0.988188, 'recall_vowel': 0.99637, 'recall_consonant': 0.99501, 'acc_grapheme': 0.988306, 'acc_vowel': 0.996684, 'acc_consonant': 0.995612, 'loss_grapheme': 0.171936, 'loss_vowel': 0.161762, 'loss_consonant': 0.098441}\n",
      "  100 | 0.000026 | 076800/160735 | 2.6003 | 1.8597 |\n",
      "val: {'recall': 0.994362, 'recall_grapheme': 0.991559, 'recall_vowel': 0.997235, 'recall_consonant': 0.997093, 'acc_grapheme': 0.991148, 'acc_vowel': 0.997382, 'acc_consonant': 0.996335, 'loss_grapheme': 0.147907, 'loss_vowel': 0.121651, 'loss_consonant': 0.076356}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "  101 | 0.000015 | 069888/160735 | 2.0242 | 1.6856 |\n",
      "val: {'recall': 0.992789, 'recall_grapheme': 0.990106, 'recall_vowel': 0.996376, 'recall_consonant': 0.994569, 'acc_grapheme': 0.990874, 'acc_vowel': 0.996883, 'acc_consonant': 0.996384, 'loss_grapheme': 0.167718, 'loss_vowel': 0.110026, 'loss_consonant': 0.082676}\n",
      "  102 | 0.000008 | 062976/160735 | 2.4685 | 1.7904 |\n",
      "val: {'recall': 0.993504, 'recall_grapheme': 0.990287, 'recall_vowel': 0.996599, 'recall_consonant': 0.996845, 'acc_grapheme': 0.989752, 'acc_vowel': 0.997083, 'acc_consonant': 0.996335, 'loss_grapheme': 0.170766, 'loss_vowel': 0.149114, 'loss_consonant': 0.089225}\n",
      "  103 | 0.000003 | 056064/160735 | 2.1733 | 1.8125 |\n",
      "val: {'recall': 0.993311, 'recall_grapheme': 0.989895, 'recall_vowel': 0.996625, 'recall_consonant': 0.996829, 'acc_grapheme': 0.989702, 'acc_vowel': 0.997083, 'acc_consonant': 0.996484, 'loss_grapheme': 0.186024, 'loss_vowel': 0.164717, 'loss_consonant': 0.096067}\n",
      "  104 | 0.000001 | 049152/160735 | 2.9037 | 1.8695 |\n",
      "val: {'recall': 0.993449, 'recall_grapheme': 0.990242, 'recall_vowel': 0.996609, 'recall_consonant': 0.996701, 'acc_grapheme': 0.990051, 'acc_vowel': 0.997207, 'acc_consonant': 0.99636, 'loss_grapheme': 0.176783, 'loss_vowel': 0.153486, 'loss_consonant': 0.091101}\n",
      "  105 | 0.000003 | 042240/160735 | 1.7296 | 1.7320 |\n",
      "val: {'recall': 0.993322, 'recall_grapheme': 0.990456, 'recall_vowel': 0.996642, 'recall_consonant': 0.995736, 'acc_grapheme': 0.991248, 'acc_vowel': 0.997058, 'acc_consonant': 0.996384, 'loss_grapheme': 0.182929, 'loss_vowel': 0.141906, 'loss_consonant': 0.093334}\n",
      "  106 | 0.000008 | 035328/160735 | 1.6789 | 1.6753 |\n",
      "val: {'recall': 0.992343, 'recall_grapheme': 0.988868, 'recall_vowel': 0.996281, 'recall_consonant': 0.995357, 'acc_grapheme': 0.988854, 'acc_vowel': 0.996908, 'acc_consonant': 0.996035, 'loss_grapheme': 0.155638, 'loss_vowel': 0.138117, 'loss_consonant': 0.08203}\n",
      "  107 | 0.000015 | 028416/160735 | 0.2545 | 1.5941 |\n",
      "val: {'recall': 0.994387, 'recall_grapheme': 0.991771, 'recall_vowel': 0.996982, 'recall_consonant': 0.997023, 'acc_grapheme': 0.991447, 'acc_vowel': 0.997182, 'acc_consonant': 0.996684, 'loss_grapheme': 0.140384, 'loss_vowel': 0.108135, 'loss_consonant': 0.067575}\n",
      "** saved\n",
      "  108 | 0.000026 | 021504/160735 | 0.8970 | 1.7452 |\n",
      "val: {'recall': 0.993915, 'recall_grapheme': 0.990784, 'recall_vowel': 0.997008, 'recall_consonant': 0.997084, 'acc_grapheme': 0.991198, 'acc_vowel': 0.997058, 'acc_consonant': 0.996509, 'loss_grapheme': 0.151263, 'loss_vowel': 0.111169, 'loss_consonant': 0.073643}\n",
      "  109 | 0.000038 | 014592/160735 | 2.8302 | 1.8135 |\n",
      "val: {'recall': 0.993079, 'recall_grapheme': 0.990209, 'recall_vowel': 0.996334, 'recall_consonant': 0.995562, 'acc_grapheme': 0.989079, 'acc_vowel': 0.996808, 'acc_consonant': 0.99611, 'loss_grapheme': 0.194737, 'loss_vowel': 0.18076, 'loss_consonant': 0.10805}\n",
      "  110 | 0.000050 | 007680/160735 | 1.3617 | 2.1554 |\n",
      "val: {'recall': 0.993269, 'recall_grapheme': 0.989954, 'recall_vowel': 0.996402, 'recall_consonant': 0.996765, 'acc_grapheme': 0.989777, 'acc_vowel': 0.996734, 'acc_consonant': 0.99606, 'loss_grapheme': 0.183534, 'loss_vowel': 0.161968, 'loss_consonant': 0.093491}\n",
      "  111 | 0.000063 | 000768/160735 | 2.2774 | 2.2774 |\n",
      "val: {'recall': 0.99123, 'recall_grapheme': 0.986407, 'recall_vowel': 0.995915, 'recall_consonant': 0.996192, 'acc_grapheme': 0.98666, 'acc_vowel': 0.99626, 'acc_consonant': 0.994664, 'loss_grapheme': 0.226685, 'loss_vowel': 0.203676, 'loss_consonant': 0.123143}\n",
      "  111 | 0.000075 | 154368/160735 | 1.6515 | 1.7669 |\n",
      "val: {'recall': 0.992675, 'recall_grapheme': 0.989396, 'recall_vowel': 0.996354, 'recall_consonant': 0.995553, 'acc_grapheme': 0.988979, 'acc_vowel': 0.996783, 'acc_consonant': 0.995661, 'loss_grapheme': 0.19267, 'loss_vowel': 0.156878, 'loss_consonant': 0.096831}\n",
      "  112 | 0.000086 | 147456/160735 | 0.9436 | 1.8539 |\n",
      "val: {'recall': 0.993279, 'recall_grapheme': 0.989411, 'recall_vowel': 0.996953, 'recall_consonant': 0.99734, 'acc_grapheme': 0.989727, 'acc_vowel': 0.996709, 'acc_consonant': 0.99626, 'loss_grapheme': 0.152003, 'loss_vowel': 0.117541, 'loss_consonant': 0.06598}\n",
      "  113 | 0.000093 | 140544/160735 | 2.4832 | 1.8383 |\n",
      "val: {'recall': 0.991956, 'recall_grapheme': 0.98887, 'recall_vowel': 0.996105, 'recall_consonant': 0.993978, 'acc_grapheme': 0.989029, 'acc_vowel': 0.996484, 'acc_consonant': 0.995786, 'loss_grapheme': 0.178239, 'loss_vowel': 0.136164, 'loss_consonant': 0.08326}\n",
      "  114 | 0.000098 | 133632/160735 | 0.7834 | 1.9052 |\n",
      "val: {'recall': 0.990971, 'recall_grapheme': 0.986633, 'recall_vowel': 0.994463, 'recall_consonant': 0.996154, 'acc_grapheme': 0.986485, 'acc_vowel': 0.995213, 'acc_consonant': 0.995437, 'loss_grapheme': 0.202726, 'loss_vowel': 0.161776, 'loss_consonant': 0.099235}\n",
      "  115 | 0.000100 | 126720/160735 | 1.6178 | 1.8961 |\n",
      "val: {'recall': 0.991816, 'recall_grapheme': 0.988538, 'recall_vowel': 0.994822, 'recall_consonant': 0.995367, 'acc_grapheme': 0.988306, 'acc_vowel': 0.99611, 'acc_consonant': 0.995811, 'loss_grapheme': 0.211018, 'loss_vowel': 0.183938, 'loss_consonant': 0.111572}\n",
      "  116 | 0.000098 | 119808/160735 | 1.9804 | 1.8111 |\n",
      "val: {'recall': 0.992544, 'recall_grapheme': 0.988807, 'recall_vowel': 0.995489, 'recall_consonant': 0.997072, 'acc_grapheme': 0.989153, 'acc_vowel': 0.996285, 'acc_consonant': 0.996035, 'loss_grapheme': 0.160909, 'loss_vowel': 0.131753, 'loss_consonant': 0.076818}\n",
      "  117 | 0.000093 | 112896/160735 | 1.7361 | 1.8008 |\n",
      "val: {'recall': 0.992515, 'recall_grapheme': 0.988808, 'recall_vowel': 0.995986, 'recall_consonant': 0.996455, 'acc_grapheme': 0.98868, 'acc_vowel': 0.996459, 'acc_consonant': 0.995986, 'loss_grapheme': 0.188041, 'loss_vowel': 0.135431, 'loss_consonant': 0.085048}\n",
      "  118 | 0.000086 | 105984/160735 | 1.7535 | 1.7321 |\n",
      "val: {'recall': 0.992929, 'recall_grapheme': 0.989548, 'recall_vowel': 0.996165, 'recall_consonant': 0.996456, 'acc_grapheme': 0.989503, 'acc_vowel': 0.996484, 'acc_consonant': 0.99621, 'loss_grapheme': 0.184718, 'loss_vowel': 0.161482, 'loss_consonant': 0.094786}\n",
      "  119 | 0.000075 | 099072/160735 | 1.2002 | 1.7787 |\n",
      "val: {'recall': 0.993986, 'recall_grapheme': 0.991892, 'recall_vowel': 0.996916, 'recall_consonant': 0.995243, 'acc_grapheme': 0.992046, 'acc_vowel': 0.997382, 'acc_consonant': 0.996659, 'loss_grapheme': 0.160851, 'loss_vowel': 0.113291, 'loss_consonant': 0.071656}\n",
      "  120 | 0.000063 | 092160/160735 | 0.2320 | 1.7116 |\n",
      "val: {'recall': 0.994002, 'recall_grapheme': 0.990904, 'recall_vowel': 0.996857, 'recall_consonant': 0.997342, 'acc_grapheme': 0.991373, 'acc_vowel': 0.997133, 'acc_consonant': 0.996734, 'loss_grapheme': 0.158557, 'loss_vowel': 0.130292, 'loss_consonant': 0.072536}\n",
      "  121 | 0.000050 | 085248/160735 | 0.1209 | 1.8020 |\n",
      "val: {'recall': 0.993766, 'recall_grapheme': 0.991018, 'recall_vowel': 0.996916, 'recall_consonant': 0.996113, 'acc_grapheme': 0.991722, 'acc_vowel': 0.997232, 'acc_consonant': 0.996908, 'loss_grapheme': 0.150915, 'loss_vowel': 0.117981, 'loss_consonant': 0.071003}\n",
      "  122 | 0.000038 | 078336/160735 | 2.3539 | 1.9221 |\n",
      "val: {'recall': 0.993031, 'recall_grapheme': 0.989525, 'recall_vowel': 0.996274, 'recall_consonant': 0.996801, 'acc_grapheme': 0.988954, 'acc_vowel': 0.996659, 'acc_consonant': 0.995886, 'loss_grapheme': 0.183064, 'loss_vowel': 0.183435, 'loss_consonant': 0.111117}\n",
      "  123 | 0.000026 | 071424/160735 | 2.8178 | 1.8354 |\n",
      "val: {'recall': 0.993159, 'recall_grapheme': 0.989703, 'recall_vowel': 0.99633, 'recall_consonant': 0.996901, 'acc_grapheme': 0.989378, 'acc_vowel': 0.996808, 'acc_consonant': 0.996484, 'loss_grapheme': 0.215014, 'loss_vowel': 0.196108, 'loss_consonant': 0.112822}\n",
      "  124 | 0.000015 | 064512/160735 | 1.1480 | 1.7642 |\n",
      "val: {'recall': 0.993231, 'recall_grapheme': 0.9897, 'recall_vowel': 0.996595, 'recall_consonant': 0.996929, 'acc_grapheme': 0.989802, 'acc_vowel': 0.996908, 'acc_consonant': 0.996285, 'loss_grapheme': 0.172213, 'loss_vowel': 0.144133, 'loss_consonant': 0.084591}\n",
      "  125 | 0.000008 | 057600/160735 | 0.7823 | 1.8755 |\n",
      "val: {'recall': 0.993037, 'recall_grapheme': 0.989253, 'recall_vowel': 0.996621, 'recall_consonant': 0.997019, 'acc_grapheme': 0.989552, 'acc_vowel': 0.996883, 'acc_consonant': 0.996185, 'loss_grapheme': 0.181961, 'loss_vowel': 0.156898, 'loss_consonant': 0.094562}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  126 | 0.000003 | 050688/160735 | 1.1572 | 1.8722 |\n",
      "val: {'recall': 0.994112, 'recall_grapheme': 0.991223, 'recall_vowel': 0.996817, 'recall_consonant': 0.997184, 'acc_grapheme': 0.991547, 'acc_vowel': 0.997157, 'acc_consonant': 0.996759, 'loss_grapheme': 0.179152, 'loss_vowel': 0.144877, 'loss_consonant': 0.087624}\n",
      "  127 | 0.000001 | 043776/160735 | 2.4575 | 1.7891 |\n",
      "val: {'recall': 0.993426, 'recall_grapheme': 0.989912, 'recall_vowel': 0.996859, 'recall_consonant': 0.997023, 'acc_grapheme': 0.990026, 'acc_vowel': 0.997033, 'acc_consonant': 0.99616, 'loss_grapheme': 0.176595, 'loss_vowel': 0.157275, 'loss_consonant': 0.090055}\n",
      "  128 | 0.000003 | 036864/160735 | 1.3953 | 1.7547 |\n",
      "val: {'recall': 0.993973, 'recall_grapheme': 0.990907, 'recall_vowel': 0.996913, 'recall_consonant': 0.997167, 'acc_grapheme': 0.990699, 'acc_vowel': 0.997157, 'acc_consonant': 0.996434, 'loss_grapheme': 0.160871, 'loss_vowel': 0.133616, 'loss_consonant': 0.079128}\n",
      "  129 | 0.000008 | 029952/160735 | 3.5278 | 1.7440 |\n",
      "val: {'recall': 0.992809, 'recall_grapheme': 0.988872, 'recall_vowel': 0.996697, 'recall_consonant': 0.996796, 'acc_grapheme': 0.989153, 'acc_vowel': 0.996958, 'acc_consonant': 0.99606, 'loss_grapheme': 0.184733, 'loss_vowel': 0.159368, 'loss_consonant': 0.092313}\n",
      "  130 | 0.000015 | 023040/160735 | 1.1796 | 1.6544 |\n",
      "val: {'recall': 0.993111, 'recall_grapheme': 0.989412, 'recall_vowel': 0.996685, 'recall_consonant': 0.996934, 'acc_grapheme': 0.989503, 'acc_vowel': 0.996933, 'acc_consonant': 0.99616, 'loss_grapheme': 0.178636, 'loss_vowel': 0.152703, 'loss_consonant': 0.090371}\n",
      "  131 | 0.000026 | 016128/160735 | 1.6352 | 1.7659 |\n",
      "val: {'recall': 0.993505, 'recall_grapheme': 0.990114, 'recall_vowel': 0.996804, 'recall_consonant': 0.996988, 'acc_grapheme': 0.989777, 'acc_vowel': 0.997182, 'acc_consonant': 0.996235, 'loss_grapheme': 0.184163, 'loss_vowel': 0.151846, 'loss_consonant': 0.089554}\n",
      "  132 | 0.000038 | 009216/160735 | 2.3504 | 1.8705 |\n",
      "val: {'recall': 0.993247, 'recall_grapheme': 0.989648, 'recall_vowel': 0.996698, 'recall_consonant': 0.996995, 'acc_grapheme': 0.989752, 'acc_vowel': 0.997033, 'acc_consonant': 0.99621, 'loss_grapheme': 0.191959, 'loss_vowel': 0.166312, 'loss_consonant': 0.094156}\n",
      "  133 | 0.000050 | 002304/160735 | 1.7134 | 1.9627 |\n",
      "val: {'recall': 0.99259, 'recall_grapheme': 0.988483, 'recall_vowel': 0.99659, 'recall_consonant': 0.996804, 'acc_grapheme': 0.989303, 'acc_vowel': 0.996783, 'acc_consonant': 0.99616, 'loss_grapheme': 0.183473, 'loss_vowel': 0.157049, 'loss_consonant': 0.094417}\n",
      "  133 | 0.000063 | 155904/160735 | 1.5720 | 1.7396 |\n",
      "val: {'recall': 0.993638, 'recall_grapheme': 0.990722, 'recall_vowel': 0.995932, 'recall_consonant': 0.997177, 'acc_grapheme': 0.990176, 'acc_vowel': 0.996509, 'acc_consonant': 0.996384, 'loss_grapheme': 0.173997, 'loss_vowel': 0.135079, 'loss_consonant': 0.08417}\n",
      "  134 | 0.000075 | 148992/160735 | 1.0352 | 1.7549 |\n",
      "val: {'recall': 0.993508, 'recall_grapheme': 0.990776, 'recall_vowel': 0.996288, 'recall_consonant': 0.996194, 'acc_grapheme': 0.990949, 'acc_vowel': 0.996783, 'acc_consonant': 0.996434, 'loss_grapheme': 0.203354, 'loss_vowel': 0.144957, 'loss_consonant': 0.083979}\n",
      "  135 | 0.000086 | 142080/160735 | 1.5740 | 1.7762 |\n",
      "val: {'recall': 0.99148, 'recall_grapheme': 0.988529, 'recall_vowel': 0.99617, 'recall_consonant': 0.992694, 'acc_grapheme': 0.989577, 'acc_vowel': 0.99616, 'acc_consonant': 0.995262, 'loss_grapheme': 0.146058, 'loss_vowel': 0.101748, 'loss_consonant': 0.070552}\n",
      "  136 | 0.000093 | 135168/160735 | 3.3682 | 1.7591 |\n",
      "val: {'recall': 0.992004, 'recall_grapheme': 0.988768, 'recall_vowel': 0.995433, 'recall_consonant': 0.995047, 'acc_grapheme': 0.987932, 'acc_vowel': 0.995736, 'acc_consonant': 0.995387, 'loss_grapheme': 0.166993, 'loss_vowel': 0.142086, 'loss_consonant': 0.088615}\n",
      "  137 | 0.000098 | 128256/160735 | 1.1292 | 1.7736 |\n",
      "val: {'recall': 0.992226, 'recall_grapheme': 0.988424, 'recall_vowel': 0.996123, 'recall_consonant': 0.995934, 'acc_grapheme': 0.988555, 'acc_vowel': 0.99626, 'acc_consonant': 0.995786, 'loss_grapheme': 0.160161, 'loss_vowel': 0.11927, 'loss_consonant': 0.070098}\n",
      "  138 | 0.000100 | 121344/160735 | 1.7374 | 1.8012 |\n",
      "val: {'recall': 0.992573, 'recall_grapheme': 0.988877, 'recall_vowel': 0.995823, 'recall_consonant': 0.996717, 'acc_grapheme': 0.988455, 'acc_vowel': 0.99636, 'acc_consonant': 0.995861, 'loss_grapheme': 0.186397, 'loss_vowel': 0.146521, 'loss_consonant': 0.088221}\n",
      "  139 | 0.000098 | 114432/160735 | 1.7567 | 1.7694 |\n",
      "val: {'recall': 0.992284, 'recall_grapheme': 0.988673, 'recall_vowel': 0.995534, 'recall_consonant': 0.996257, 'acc_grapheme': 0.988804, 'acc_vowel': 0.99626, 'acc_consonant': 0.995487, 'loss_grapheme': 0.160951, 'loss_vowel': 0.127383, 'loss_consonant': 0.072218}\n",
      "  140 | 0.000093 | 107520/160735 | 2.4616 | 1.6980 |\n",
      "val: {'recall': 0.992311, 'recall_grapheme': 0.98896, 'recall_vowel': 0.995879, 'recall_consonant': 0.995446, 'acc_grapheme': 0.98863, 'acc_vowel': 0.996409, 'acc_consonant': 0.99626, 'loss_grapheme': 0.18906, 'loss_vowel': 0.142767, 'loss_consonant': 0.087362}\n",
      "  141 | 0.000086 | 100608/160735 | 2.2495 | 1.7345 |\n",
      "val: {'recall': 0.992736, 'recall_grapheme': 0.989313, 'recall_vowel': 0.996127, 'recall_consonant': 0.99619, 'acc_grapheme': 0.989328, 'acc_vowel': 0.996459, 'acc_consonant': 0.996185, 'loss_grapheme': 0.175118, 'loss_vowel': 0.152594, 'loss_consonant': 0.095134}\n",
      "  142 | 0.000075 | 093696/160735 | 1.4618 | 1.7149 |\n",
      "val: {'recall': 0.99299, 'recall_grapheme': 0.9895, 'recall_vowel': 0.996087, 'recall_consonant': 0.996874, 'acc_grapheme': 0.98853, 'acc_vowel': 0.99636, 'acc_consonant': 0.99611, 'loss_grapheme': 0.187003, 'loss_vowel': 0.152735, 'loss_consonant': 0.09045}\n",
      "  143 | 0.000063 | 086784/160735 | 1.9354 | 1.7058 |\n",
      "val: {'recall': 0.994227, 'recall_grapheme': 0.991821, 'recall_vowel': 0.996948, 'recall_consonant': 0.996317, 'acc_grapheme': 0.990899, 'acc_vowel': 0.997033, 'acc_consonant': 0.996584, 'loss_grapheme': 0.157584, 'loss_vowel': 0.129446, 'loss_consonant': 0.077916}\n",
      "  144 | 0.000050 | 079872/160735 | 1.3532 | 1.5533 |\n",
      "val: {'recall': 0.993528, 'recall_grapheme': 0.991123, 'recall_vowel': 0.996473, 'recall_consonant': 0.995392, 'acc_grapheme': 0.990425, 'acc_vowel': 0.996883, 'acc_consonant': 0.99631, 'loss_grapheme': 0.140674, 'loss_vowel': 0.116679, 'loss_consonant': 0.06916}\n",
      "  145 | 0.000038 | 072960/160735 | 1.3036 | 1.8633 |\n",
      "val: {'recall': 0.993856, 'recall_grapheme': 0.991387, 'recall_vowel': 0.996709, 'recall_consonant': 0.995942, 'acc_grapheme': 0.990525, 'acc_vowel': 0.997182, 'acc_consonant': 0.996559, 'loss_grapheme': 0.176245, 'loss_vowel': 0.15197, 'loss_consonant': 0.089072}\n",
      "  146 | 0.000026 | 066048/160735 | 3.4247 | 1.7272 |\n",
      "val: {'recall': 0.99395, 'recall_grapheme': 0.992099, 'recall_vowel': 0.996426, 'recall_consonant': 0.995178, 'acc_grapheme': 0.991273, 'acc_vowel': 0.996908, 'acc_consonant': 0.996609, 'loss_grapheme': 0.19169, 'loss_vowel': 0.159767, 'loss_consonant': 0.09462}\n",
      "  147 | 0.000015 | 059136/160735 | 1.2888 | 1.8016 |\n",
      "val: {'recall': 0.993634, 'recall_grapheme': 0.991334, 'recall_vowel': 0.996666, 'recall_consonant': 0.995204, 'acc_grapheme': 0.9905, 'acc_vowel': 0.997133, 'acc_consonant': 0.996584, 'loss_grapheme': 0.162394, 'loss_vowel': 0.137838, 'loss_consonant': 0.083247}\n",
      "  148 | 0.000008 | 052224/160735 | 0.8543 | 1.5941 |\n",
      "val: {'recall': 0.993386, 'recall_grapheme': 0.990833, 'recall_vowel': 0.996749, 'recall_consonant': 0.995131, 'acc_grapheme': 0.990126, 'acc_vowel': 0.996983, 'acc_consonant': 0.996509, 'loss_grapheme': 0.160743, 'loss_vowel': 0.13829, 'loss_consonant': 0.085327}\n",
      "  149 | 0.000003 | 045312/160735 | 1.4444 | 1.7721 |\n",
      "val: {'recall': 0.994428, 'recall_grapheme': 0.992342, 'recall_vowel': 0.99699, 'recall_consonant': 0.996038, 'acc_grapheme': 0.991946, 'acc_vowel': 0.997282, 'acc_consonant': 0.997008, 'loss_grapheme': 0.16849, 'loss_vowel': 0.127564, 'loss_consonant': 0.078341}\n",
      "** saved\n",
      "  150 | 0.000001 | 038400/160735 | 1.4935 | 1.6651 |\n",
      "val: {'recall': 0.994483, 'recall_grapheme': 0.992541, 'recall_vowel': 0.996835, 'recall_consonant': 0.996014, 'acc_grapheme': 0.991996, 'acc_vowel': 0.997232, 'acc_consonant': 0.996883, 'loss_grapheme': 0.136893, 'loss_vowel': 0.107212, 'loss_consonant': 0.067079}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "  151 | 0.000003 | 031488/160735 | 1.4664 | 1.8525 |\n",
      "val: {'recall': 0.993524, 'recall_grapheme': 0.990969, 'recall_vowel': 0.996435, 'recall_consonant': 0.995726, 'acc_grapheme': 0.990051, 'acc_vowel': 0.996883, 'acc_consonant': 0.996434, 'loss_grapheme': 0.169892, 'loss_vowel': 0.152663, 'loss_consonant': 0.094209}\n",
      "  152 | 0.000008 | 024576/160735 | 0.8803 | 1.5736 |\n",
      "val: {'recall': 0.994322, 'recall_grapheme': 0.992729, 'recall_vowel': 0.996545, 'recall_consonant': 0.995284, 'acc_grapheme': 0.992669, 'acc_vowel': 0.996958, 'acc_consonant': 0.996933, 'loss_grapheme': 0.121052, 'loss_vowel': 0.078456, 'loss_consonant': 0.056436}\n",
      "  153 | 0.000015 | 017664/160735 | 1.7538 | 1.7494 |\n",
      "val: {'recall': 0.993763, 'recall_grapheme': 0.990911, 'recall_vowel': 0.996625, 'recall_consonant': 0.996606, 'acc_grapheme': 0.9903, 'acc_vowel': 0.997033, 'acc_consonant': 0.996833, 'loss_grapheme': 0.163015, 'loss_vowel': 0.146479, 'loss_consonant': 0.086465}\n",
      "  154 | 0.000026 | 010752/160735 | 2.2150 | 1.8680 |\n",
      "val: {'recall': 0.99358, 'recall_grapheme': 0.990772, 'recall_vowel': 0.996865, 'recall_consonant': 0.995911, 'acc_grapheme': 0.990674, 'acc_vowel': 0.997332, 'acc_consonant': 0.996534, 'loss_grapheme': 0.184979, 'loss_vowel': 0.15091, 'loss_consonant': 0.093295}\n",
      "  155 | 0.000038 | 003840/160735 | 0.9853 | 1.6816 |\n",
      "val: {'recall': 0.994286, 'recall_grapheme': 0.992377, 'recall_vowel': 0.997221, 'recall_consonant': 0.995168, 'acc_grapheme': 0.991921, 'acc_vowel': 0.997357, 'acc_consonant': 0.996634, 'loss_grapheme': 0.161255, 'loss_vowel': 0.123949, 'loss_consonant': 0.074585}\n",
      "  155 | 0.000050 | 157440/160735 | 0.6125 | 1.7131 |\n",
      "val: {'recall': 0.993385, 'recall_grapheme': 0.990775, 'recall_vowel': 0.996727, 'recall_consonant': 0.995265, 'acc_grapheme': 0.9903, 'acc_vowel': 0.997033, 'acc_consonant': 0.996609, 'loss_grapheme': 0.144592, 'loss_vowel': 0.108097, 'loss_consonant': 0.069742}\n",
      "  156 | 0.000063 | 150528/160735 | 2.2453 | 1.7740 |\n",
      "val: {'recall': 0.993908, 'recall_grapheme': 0.991176, 'recall_vowel': 0.99668, 'recall_consonant': 0.9966, 'acc_grapheme': 0.991622, 'acc_vowel': 0.997008, 'acc_consonant': 0.996684, 'loss_grapheme': 0.174866, 'loss_vowel': 0.105173, 'loss_consonant': 0.080119}\n",
      "  157 | 0.000075 | 143616/160735 | 1.4365 | 1.8551 |\n",
      "val: {'recall': 0.992453, 'recall_grapheme': 0.989888, 'recall_vowel': 0.99545, 'recall_consonant': 0.994586, 'acc_grapheme': 0.990051, 'acc_vowel': 0.996285, 'acc_consonant': 0.99611, 'loss_grapheme': 0.154856, 'loss_vowel': 0.092504, 'loss_consonant': 0.065159}\n",
      "  158 | 0.000086 | 136704/160735 | 1.6427 | 1.8049 |\n",
      "val: {'recall': 0.993928, 'recall_grapheme': 0.991034, 'recall_vowel': 0.996809, 'recall_consonant': 0.996837, 'acc_grapheme': 0.991148, 'acc_vowel': 0.997033, 'acc_consonant': 0.996459, 'loss_grapheme': 0.175693, 'loss_vowel': 0.131327, 'loss_consonant': 0.092799}\n",
      "  159 | 0.000093 | 129792/160735 | 2.8490 | 1.8042 |\n",
      "val: {'recall': 0.991847, 'recall_grapheme': 0.988159, 'recall_vowel': 0.995682, 'recall_consonant': 0.995387, 'acc_grapheme': 0.987558, 'acc_vowel': 0.995961, 'acc_consonant': 0.995238, 'loss_grapheme': 0.158809, 'loss_vowel': 0.133737, 'loss_consonant': 0.094528}\n",
      "  160 | 0.000098 | 122880/160735 | 2.6151 | 1.7759 |\n",
      "val: {'recall': 0.992105, 'recall_grapheme': 0.988264, 'recall_vowel': 0.996255, 'recall_consonant': 0.995638, 'acc_grapheme': 0.988605, 'acc_vowel': 0.996434, 'acc_consonant': 0.995587, 'loss_grapheme': 0.179754, 'loss_vowel': 0.161135, 'loss_consonant': 0.098094}\n",
      "  161 | 0.000100 | 115968/160735 | 0.4246 | 1.7769 |\n",
      "val: {'recall': 0.992531, 'recall_grapheme': 0.988994, 'recall_vowel': 0.996245, 'recall_consonant': 0.99589, 'acc_grapheme': 0.988031, 'acc_vowel': 0.996559, 'acc_consonant': 0.996035, 'loss_grapheme': 0.143933, 'loss_vowel': 0.104381, 'loss_consonant': 0.068032}\n",
      "  162 | 0.000098 | 109056/160735 | 1.8176 | 1.6258 |\n",
      "val: {'recall': 0.992855, 'recall_grapheme': 0.989669, 'recall_vowel': 0.996284, 'recall_consonant': 0.995799, 'acc_grapheme': 0.989926, 'acc_vowel': 0.996634, 'acc_consonant': 0.996409, 'loss_grapheme': 0.139895, 'loss_vowel': 0.098458, 'loss_consonant': 0.064882}\n",
      "  163 | 0.000093 | 102144/160735 | 1.0554 | 1.8997 |\n",
      "val: {'recall': 0.991788, 'recall_grapheme': 0.987895, 'recall_vowel': 0.99534, 'recall_consonant': 0.996019, 'acc_grapheme': 0.987558, 'acc_vowel': 0.996135, 'acc_consonant': 0.995636, 'loss_grapheme': 0.158169, 'loss_vowel': 0.116861, 'loss_consonant': 0.082125}\n",
      "  164 | 0.000086 | 095232/160735 | 0.2009 | 1.8620 |\n",
      "val: {'recall': 0.992658, 'recall_grapheme': 0.989131, 'recall_vowel': 0.99622, 'recall_consonant': 0.99615, 'acc_grapheme': 0.988555, 'acc_vowel': 0.996659, 'acc_consonant': 0.995761, 'loss_grapheme': 0.141421, 'loss_vowel': 0.108587, 'loss_consonant': 0.071817}\n",
      "  165 | 0.000075 | 088320/160735 | 0.8887 | 1.8213 |\n",
      "val: {'recall': 0.991259, 'recall_grapheme': 0.986915, 'recall_vowel': 0.995847, 'recall_consonant': 0.995359, 'acc_grapheme': 0.98681, 'acc_vowel': 0.996409, 'acc_consonant': 0.995786, 'loss_grapheme': 0.171785, 'loss_vowel': 0.131716, 'loss_consonant': 0.087645}\n",
      "  166 | 0.000063 | 081408/160735 | 1.5642 | 1.7124 |\n",
      "val: {'recall': 0.992586, 'recall_grapheme': 0.988711, 'recall_vowel': 0.996395, 'recall_consonant': 0.996526, 'acc_grapheme': 0.988655, 'acc_vowel': 0.996783, 'acc_consonant': 0.995811, 'loss_grapheme': 0.16272, 'loss_vowel': 0.124722, 'loss_consonant': 0.082093}\n",
      "  167 | 0.000051 | 074496/160735 | 1.3925 | 1.6470 |\n",
      "val: {'recall': 0.992366, 'recall_grapheme': 0.9885, 'recall_vowel': 0.995643, 'recall_consonant': 0.99682, 'acc_grapheme': 0.98868, 'acc_vowel': 0.996384, 'acc_consonant': 0.995986, 'loss_grapheme': 0.14702, 'loss_vowel': 0.11234, 'loss_consonant': 0.082444}\n",
      "  168 | 0.000038 | 067584/160735 | 2.8420 | 1.8644 |\n",
      "val: {'recall': 0.993797, 'recall_grapheme': 0.990963, 'recall_vowel': 0.996369, 'recall_consonant': 0.996896, 'acc_grapheme': 0.989677, 'acc_vowel': 0.997108, 'acc_consonant': 0.996634, 'loss_grapheme': 0.137351, 'loss_vowel': 0.101054, 'loss_consonant': 0.065724}\n",
      "  169 | 0.000026 | 060672/160735 | 1.7888 | 1.8259 |\n",
      "val: {'recall': 0.993195, 'recall_grapheme': 0.989736, 'recall_vowel': 0.99635, 'recall_consonant': 0.996956, 'acc_grapheme': 0.989054, 'acc_vowel': 0.996958, 'acc_consonant': 0.996285, 'loss_grapheme': 0.160568, 'loss_vowel': 0.131615, 'loss_consonant': 0.083775}\n",
      "  170 | 0.000015 | 053760/160735 | 1.7639 | 1.7900 |\n",
      "val: {'recall': 0.992288, 'recall_grapheme': 0.98836, 'recall_vowel': 0.995504, 'recall_consonant': 0.996927, 'acc_grapheme': 0.987907, 'acc_vowel': 0.996285, 'acc_consonant': 0.995836, 'loss_grapheme': 0.162217, 'loss_vowel': 0.147702, 'loss_consonant': 0.099016}\n",
      "  171 | 0.000008 | 046848/160735 | 1.7870 | 1.7133 |\n",
      "val: {'recall': 0.99324, 'recall_grapheme': 0.991616, 'recall_vowel': 0.9965, 'recall_consonant': 0.993229, 'acc_grapheme': 0.991323, 'acc_vowel': 0.997058, 'acc_consonant': 0.996559, 'loss_grapheme': 0.151114, 'loss_vowel': 0.104095, 'loss_consonant': 0.074288}\n",
      "  172 | 0.000003 | 039936/160735 | 0.8429 | 1.6750 |\n",
      "val: {'recall': 0.994259, 'recall_grapheme': 0.991655, 'recall_vowel': 0.996528, 'recall_consonant': 0.997199, 'acc_grapheme': 0.991098, 'acc_vowel': 0.997182, 'acc_consonant': 0.996808, 'loss_grapheme': 0.126679, 'loss_vowel': 0.09347, 'loss_consonant': 0.061873}\n",
      "  173 | 0.000001 | 033024/160735 | 2.9831 | 1.8225 |\n",
      "val: {'recall': 0.993005, 'recall_grapheme': 0.98965, 'recall_vowel': 0.99581, 'recall_consonant': 0.996908, 'acc_grapheme': 0.988829, 'acc_vowel': 0.996584, 'acc_consonant': 0.995786, 'loss_grapheme': 0.14951, 'loss_vowel': 0.137477, 'loss_consonant': 0.091231}\n",
      "  174 | 0.000003 | 026112/160735 | 0.1759 | 1.7744 |\n",
      "val: {'recall': 0.994642, 'recall_grapheme': 0.992139, 'recall_vowel': 0.996838, 'recall_consonant': 0.997451, 'acc_grapheme': 0.991921, 'acc_vowel': 0.997257, 'acc_consonant': 0.997033, 'loss_grapheme': 0.110731, 'loss_vowel': 0.079098, 'loss_consonant': 0.053144}\n",
      "** saved\n",
      "  175 | 0.000008 | 019200/160735 | 1.4347 | 1.5804 |\n",
      "val: {'recall': 0.994807, 'recall_grapheme': 0.993211, 'recall_vowel': 0.997174, 'recall_consonant': 0.995633, 'acc_grapheme': 0.992968, 'acc_vowel': 0.997357, 'acc_consonant': 0.997033, 'loss_grapheme': 0.136084, 'loss_vowel': 0.089044, 'loss_consonant': 0.061338}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "  176 | 0.000015 | 012288/160735 | 1.9095 | 1.9380 |\n",
      "val: {'recall': 0.992947, 'recall_grapheme': 0.989441, 'recall_vowel': 0.995992, 'recall_consonant': 0.996914, 'acc_grapheme': 0.988854, 'acc_vowel': 0.996634, 'acc_consonant': 0.99611, 'loss_grapheme': 0.148052, 'loss_vowel': 0.122292, 'loss_consonant': 0.080409}\n",
      "  177 | 0.000026 | 005376/160735 | 2.1672 | 1.8442 |\n",
      "val: {'recall': 0.993734, 'recall_grapheme': 0.990806, 'recall_vowel': 0.996438, 'recall_consonant': 0.996885, 'acc_grapheme': 0.990176, 'acc_vowel': 0.996908, 'acc_consonant': 0.996534, 'loss_grapheme': 0.152286, 'loss_vowel': 0.113841, 'loss_consonant': 0.07727}\n",
      "  177 | 0.000038 | 158976/160735 | 2.0699 | 1.8261 |\n",
      "val: {'recall': 0.992541, 'recall_grapheme': 0.988906, 'recall_vowel': 0.99569, 'recall_consonant': 0.99666, 'acc_grapheme': 0.988181, 'acc_vowel': 0.996459, 'acc_consonant': 0.995761, 'loss_grapheme': 0.155896, 'loss_vowel': 0.130231, 'loss_consonant': 0.088185}\n",
      "  178 | 0.000050 | 152064/160735 | 1.8241 | 1.7602 |\n",
      "val: {'recall': 0.993104, 'recall_grapheme': 0.989732, 'recall_vowel': 0.996073, 'recall_consonant': 0.996878, 'acc_grapheme': 0.989752, 'acc_vowel': 0.996759, 'acc_consonant': 0.99611, 'loss_grapheme': 0.136603, 'loss_vowel': 0.097625, 'loss_consonant': 0.076015}\n",
      "  179 | 0.000063 | 145152/160735 | 0.5248 | 1.7304 |\n",
      "val: {'recall': 0.994082, 'recall_grapheme': 0.991596, 'recall_vowel': 0.996606, 'recall_consonant': 0.996532, 'acc_grapheme': 0.990999, 'acc_vowel': 0.997257, 'acc_consonant': 0.996534, 'loss_grapheme': 0.12328, 'loss_vowel': 0.082339, 'loss_consonant': 0.055614}\n",
      "  180 | 0.000075 | 138240/160735 | 2.1825 | 1.7905 |\n",
      "val: {'recall': 0.993986, 'recall_grapheme': 0.991051, 'recall_vowel': 0.996448, 'recall_consonant': 0.997392, 'acc_grapheme': 0.989752, 'acc_vowel': 0.997058, 'acc_consonant': 0.995811, 'loss_grapheme': 0.110611, 'loss_vowel': 0.082405, 'loss_consonant': 0.06467}\n",
      "  181 | 0.000086 | 131328/160735 | 1.6215 | 1.7797 |\n",
      "val: {'recall': 0.992561, 'recall_grapheme': 0.988678, 'recall_vowel': 0.996129, 'recall_consonant': 0.99676, 'acc_grapheme': 0.98858, 'acc_vowel': 0.996684, 'acc_consonant': 0.995337, 'loss_grapheme': 0.154007, 'loss_vowel': 0.105428, 'loss_consonant': 0.07767}\n",
      "  182 | 0.000093 | 124416/160735 | 1.7263 | 1.8246 |\n",
      "val: {'recall': 0.99227, 'recall_grapheme': 0.988684, 'recall_vowel': 0.996243, 'recall_consonant': 0.995469, 'acc_grapheme': 0.988306, 'acc_vowel': 0.99626, 'acc_consonant': 0.995462, 'loss_grapheme': 0.147989, 'loss_vowel': 0.105462, 'loss_consonant': 0.082348}\n",
      "  183 | 0.000098 | 117504/160735 | 1.5637 | 1.6986 |\n",
      "val: {'recall': 0.991802, 'recall_grapheme': 0.988167, 'recall_vowel': 0.994866, 'recall_consonant': 0.996009, 'acc_grapheme': 0.988006, 'acc_vowel': 0.99616, 'acc_consonant': 0.995786, 'loss_grapheme': 0.154142, 'loss_vowel': 0.101592, 'loss_consonant': 0.071588}\n",
      "  184 | 0.000100 | 110592/160735 | 1.8276 | 1.7881 |\n",
      "val: {'recall': 0.991996, 'recall_grapheme': 0.98869, 'recall_vowel': 0.99601, 'recall_consonant': 0.994594, 'acc_grapheme': 0.989104, 'acc_vowel': 0.99636, 'acc_consonant': 0.995861, 'loss_grapheme': 0.1374, 'loss_vowel': 0.099939, 'loss_consonant': 0.064619}\n",
      "  185 | 0.000098 | 103680/160735 | 1.9172 | 1.7619 |\n",
      "val: {'recall': 0.99138, 'recall_grapheme': 0.987153, 'recall_vowel': 0.995636, 'recall_consonant': 0.995577, 'acc_grapheme': 0.98651, 'acc_vowel': 0.99626, 'acc_consonant': 0.995661, 'loss_grapheme': 0.149527, 'loss_vowel': 0.121522, 'loss_consonant': 0.088012}\n",
      "  186 | 0.000093 | 096768/160735 | 0.8058 | 1.7501 |\n",
      "val: {'recall': 0.992923, 'recall_grapheme': 0.989805, 'recall_vowel': 0.995342, 'recall_consonant': 0.99674, 'acc_grapheme': 0.989453, 'acc_vowel': 0.996534, 'acc_consonant': 0.995113, 'loss_grapheme': 0.124828, 'loss_vowel': 0.08483, 'loss_consonant': 0.069683}\n",
      "  187 | 0.000086 | 089856/160735 | 2.0190 | 1.6506 |\n",
      "val: {'recall': 0.992214, 'recall_grapheme': 0.988607, 'recall_vowel': 0.995656, 'recall_consonant': 0.995985, 'acc_grapheme': 0.988331, 'acc_vowel': 0.99636, 'acc_consonant': 0.995786, 'loss_grapheme': 0.12899, 'loss_vowel': 0.096362, 'loss_consonant': 0.069755}\n",
      "  188 | 0.000075 | 082944/160735 | 1.0526 | 1.7180 |\n",
      "val: {'recall': 0.99189, 'recall_grapheme': 0.98815, 'recall_vowel': 0.995345, 'recall_consonant': 0.995916, 'acc_grapheme': 0.98848, 'acc_vowel': 0.99606, 'acc_consonant': 0.995437, 'loss_grapheme': 0.105765, 'loss_vowel': 0.084971, 'loss_consonant': 0.068189}\n",
      "  189 | 0.000063 | 076032/160735 | 1.6209 | 1.8156 |\n",
      "val: {'recall': 0.993444, 'recall_grapheme': 0.990391, 'recall_vowel': 0.996192, 'recall_consonant': 0.996804, 'acc_grapheme': 0.990001, 'acc_vowel': 0.996808, 'acc_consonant': 0.996409, 'loss_grapheme': 0.121306, 'loss_vowel': 0.092667, 'loss_consonant': 0.061953}\n",
      "  190 | 0.000051 | 069120/160735 | 0.2409 | 1.7603 |\n",
      "val: {'recall': 0.9935, 'recall_grapheme': 0.990759, 'recall_vowel': 0.996042, 'recall_consonant': 0.996439, 'acc_grapheme': 0.990201, 'acc_vowel': 0.996509, 'acc_consonant': 0.99636, 'loss_grapheme': 0.101078, 'loss_vowel': 0.079846, 'loss_consonant': 0.060575}\n",
      "  191 | 0.000038 | 062208/160735 | 2.0919 | 1.6919 |\n",
      "val: {'recall': 0.993335, 'recall_grapheme': 0.989674, 'recall_vowel': 0.996578, 'recall_consonant': 0.997412, 'acc_grapheme': 0.989004, 'acc_vowel': 0.996734, 'acc_consonant': 0.996085, 'loss_grapheme': 0.108195, 'loss_vowel': 0.083682, 'loss_consonant': 0.062421}\n",
      "  192 | 0.000026 | 055296/160735 | 1.8211 | 1.7459 |\n",
      "val: {'recall': 0.992677, 'recall_grapheme': 0.989371, 'recall_vowel': 0.996432, 'recall_consonant': 0.995535, 'acc_grapheme': 0.988854, 'acc_vowel': 0.996808, 'acc_consonant': 0.996285, 'loss_grapheme': 0.145418, 'loss_vowel': 0.109174, 'loss_consonant': 0.075212}\n",
      "  193 | 0.000015 | 048384/160735 | 2.1673 | 1.7550 |\n",
      "val: {'recall': 0.992436, 'recall_grapheme': 0.988976, 'recall_vowel': 0.995946, 'recall_consonant': 0.995847, 'acc_grapheme': 0.988405, 'acc_vowel': 0.996534, 'acc_consonant': 0.99611, 'loss_grapheme': 0.106312, 'loss_vowel': 0.088883, 'loss_consonant': 0.06688}\n",
      "  194 | 0.000008 | 041472/160735 | 1.7726 | 1.6470 |\n",
      "val: {'recall': 0.992905, 'recall_grapheme': 0.989681, 'recall_vowel': 0.996219, 'recall_consonant': 0.996038, 'acc_grapheme': 0.989328, 'acc_vowel': 0.996858, 'acc_consonant': 0.996409, 'loss_grapheme': 0.092491, 'loss_vowel': 0.072207, 'loss_consonant': 0.056599}\n",
      "  195 | 0.000003 | 034560/160735 | 1.6801 | 1.6457 |\n",
      "val: {'recall': 0.993784, 'recall_grapheme': 0.990922, 'recall_vowel': 0.996571, 'recall_consonant': 0.996723, 'acc_grapheme': 0.9905, 'acc_vowel': 0.997182, 'acc_consonant': 0.996509, 'loss_grapheme': 0.101053, 'loss_vowel': 0.082552, 'loss_consonant': 0.060062}\n",
      "  196 | 0.000001 | 027648/160735 | 1.6872 | 1.6900 |\n",
      "val: {'recall': 0.992699, 'recall_grapheme': 0.989346, 'recall_vowel': 0.996139, 'recall_consonant': 0.995963, 'acc_grapheme': 0.989129, 'acc_vowel': 0.996883, 'acc_consonant': 0.996409, 'loss_grapheme': 0.112164, 'loss_vowel': 0.092129, 'loss_consonant': 0.067282}\n",
      "  197 | 0.000003 | 020736/160735 | 2.6307 | 1.8368 |\n",
      "val: {'recall': 0.992025, 'recall_grapheme': 0.988387, 'recall_vowel': 0.995678, 'recall_consonant': 0.995648, 'acc_grapheme': 0.987682, 'acc_vowel': 0.996335, 'acc_consonant': 0.995686, 'loss_grapheme': 0.085777, 'loss_vowel': 0.072444, 'loss_consonant': 0.062823}\n",
      "  198 | 0.000008 | 013824/160735 | 0.3023 | 1.6696 |\n",
      "val: {'recall': 0.994233, 'recall_grapheme': 0.991304, 'recall_vowel': 0.997111, 'recall_consonant': 0.997212, 'acc_grapheme': 0.990749, 'acc_vowel': 0.997407, 'acc_consonant': 0.996709, 'loss_grapheme': 0.096543, 'loss_vowel': 0.07234, 'loss_consonant': 0.052772}\n",
      "  199 | 0.000015 | 006912/160735 | 1.4098 | 1.7326 |\n",
      "val: {'recall': 0.994271, 'recall_grapheme': 0.991745, 'recall_vowel': 0.997043, 'recall_consonant': 0.996553, 'acc_grapheme': 0.991522, 'acc_vowel': 0.997357, 'acc_consonant': 0.996933, 'loss_grapheme': 0.115797, 'loss_vowel': 0.079063, 'loss_consonant': 0.058492}\n",
      "  199 | 0.000026 | 160512/160735 | 0.9890 | 1.6215 |\n",
      "val: {'recall': 0.993729, 'recall_grapheme': 0.990703, 'recall_vowel': 0.996771, 'recall_consonant': 0.99674, 'acc_grapheme': 0.989827, 'acc_vowel': 0.997282, 'acc_consonant': 0.996609, 'loss_grapheme': 0.115518, 'loss_vowel': 0.08338, 'loss_consonant': 0.060487}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200 | 0.000038 | 153600/160735 | 0.7268 | 1.6830 |\n",
      "val: {'recall': 0.993738, 'recall_grapheme': 0.991404, 'recall_vowel': 0.996603, 'recall_consonant': 0.995542, 'acc_grapheme': 0.991248, 'acc_vowel': 0.996983, 'acc_consonant': 0.996858, 'loss_grapheme': 0.096999, 'loss_vowel': 0.065398, 'loss_consonant': 0.048689}\n",
      "  201 | 0.000051 | 146688/160735 | 1.5096 | 1.7420 |\n",
      "val: {'recall': 0.992967, 'recall_grapheme': 0.989507, 'recall_vowel': 0.99619, 'recall_consonant': 0.996662, 'acc_grapheme': 0.988854, 'acc_vowel': 0.996709, 'acc_consonant': 0.995936, 'loss_grapheme': 0.095177, 'loss_vowel': 0.064534, 'loss_consonant': 0.051418}\n",
      "  202 | 0.000063 | 139776/160735 | 1.7080 | 1.7172 |\n",
      "val: {'recall': 0.992058, 'recall_grapheme': 0.98805, 'recall_vowel': 0.996103, 'recall_consonant': 0.996028, 'acc_grapheme': 0.987508, 'acc_vowel': 0.996409, 'acc_consonant': 0.995661, 'loss_grapheme': 0.097064, 'loss_vowel': 0.073032, 'loss_consonant': 0.060751}\n",
      "  203 | 0.000075 | 132864/160735 | 0.9834 | 1.7641 |\n",
      "val: {'recall': 0.993154, 'recall_grapheme': 0.990231, 'recall_vowel': 0.99614, 'recall_consonant': 0.996014, 'acc_grapheme': 0.989079, 'acc_vowel': 0.996734, 'acc_consonant': 0.996285, 'loss_grapheme': 0.108247, 'loss_vowel': 0.068074, 'loss_consonant': 0.048232}\n",
      "  204 | 0.000086 | 125952/160735 | 2.2241 | 1.7533 |\n",
      "val: {'recall': 0.99302, 'recall_grapheme': 0.990088, 'recall_vowel': 0.996417, 'recall_consonant': 0.995489, 'acc_grapheme': 0.989253, 'acc_vowel': 0.996559, 'acc_consonant': 0.995761, 'loss_grapheme': 0.097167, 'loss_vowel': 0.074937, 'loss_consonant': 0.059751}\n",
      "  205 | 0.000093 | 119040/160735 | 1.6791 | 1.7923 |\n",
      "val: {'recall': 0.992962, 'recall_grapheme': 0.990375, 'recall_vowel': 0.996417, 'recall_consonant': 0.99468, 'acc_grapheme': 0.990176, 'acc_vowel': 0.996734, 'acc_consonant': 0.996559, 'loss_grapheme': 0.122807, 'loss_vowel': 0.091386, 'loss_consonant': 0.065409}\n",
      "  206 | 0.000098 | 112128/160735 | 1.7476 | 1.7902 |\n",
      "val: {'recall': 0.993751, 'recall_grapheme': 0.99118, 'recall_vowel': 0.996044, 'recall_consonant': 0.996602, 'acc_grapheme': 0.989976, 'acc_vowel': 0.996634, 'acc_consonant': 0.99601, 'loss_grapheme': 0.117619, 'loss_vowel': 0.080508, 'loss_consonant': 0.058157}\n",
      "  207 | 0.000100 | 105216/160735 | 2.1794 | 1.7335 |\n",
      "val: {'recall': 0.992296, 'recall_grapheme': 0.988485, 'recall_vowel': 0.995257, 'recall_consonant': 0.996958, 'acc_grapheme': 0.987857, 'acc_vowel': 0.995861, 'acc_consonant': 0.995387, 'loss_grapheme': 0.08763, 'loss_vowel': 0.058951, 'loss_consonant': 0.055834}\n",
      "  208 | 0.000098 | 098304/160735 | 1.4501 | 1.7946 |\n",
      "val: {'recall': 0.991885, 'recall_grapheme': 0.988121, 'recall_vowel': 0.995079, 'recall_consonant': 0.996217, 'acc_grapheme': 0.987234, 'acc_vowel': 0.995612, 'acc_consonant': 0.995238, 'loss_grapheme': 0.06808, 'loss_vowel': 0.051248, 'loss_consonant': 0.049701}\n",
      "  209 | 0.000093 | 091392/160735 | 1.6198 | 1.8129 |\n",
      "val: {'recall': 0.991089, 'recall_grapheme': 0.987538, 'recall_vowel': 0.994862, 'recall_consonant': 0.994416, 'acc_grapheme': 0.986685, 'acc_vowel': 0.995437, 'acc_consonant': 0.995337, 'loss_grapheme': 0.099267, 'loss_vowel': 0.073392, 'loss_consonant': 0.059073}\n",
      "  210 | 0.000086 | 084480/160735 | 2.5349 | 1.7988 |\n",
      "val: {'recall': 0.989857, 'recall_grapheme': 0.984726, 'recall_vowel': 0.995199, 'recall_consonant': 0.994775, 'acc_grapheme': 0.985064, 'acc_vowel': 0.995861, 'acc_consonant': 0.995013, 'loss_grapheme': 0.085109, 'loss_vowel': 0.054577, 'loss_consonant': 0.052904}\n",
      "  211 | 0.000075 | 077568/160735 | 2.2901 | 1.6239 |\n",
      "val: {'recall': 0.992171, 'recall_grapheme': 0.988741, 'recall_vowel': 0.994807, 'recall_consonant': 0.996396, 'acc_grapheme': 0.988306, 'acc_vowel': 0.99601, 'acc_consonant': 0.995811, 'loss_grapheme': 0.07297, 'loss_vowel': 0.050526, 'loss_consonant': 0.046749}\n",
      "  212 | 0.000063 | 070656/160735 | 0.1089 | 1.7372 |\n",
      "val: {'recall': 0.992963, 'recall_grapheme': 0.989761, 'recall_vowel': 0.99621, 'recall_consonant': 0.996122, 'acc_grapheme': 0.989303, 'acc_vowel': 0.996659, 'acc_consonant': 0.995836, 'loss_grapheme': 0.079315, 'loss_vowel': 0.051597, 'loss_consonant': 0.041743}\n",
      "  213 | 0.000051 | 063744/160735 | 2.7253 | 1.6862 |\n",
      "val: {'recall': 0.992237, 'recall_grapheme': 0.988401, 'recall_vowel': 0.995669, 'recall_consonant': 0.996477, 'acc_grapheme': 0.988106, 'acc_vowel': 0.99616, 'acc_consonant': 0.995636, 'loss_grapheme': 0.067369, 'loss_vowel': 0.052729, 'loss_consonant': 0.048875}\n",
      "  214 | 0.000038 | 056832/160735 | 1.6276 | 1.6739 |\n",
      "val: {'recall': 0.991908, 'recall_grapheme': 0.988045, 'recall_vowel': 0.995417, 'recall_consonant': 0.996126, 'acc_grapheme': 0.98681, 'acc_vowel': 0.995936, 'acc_consonant': 0.995238, 'loss_grapheme': 0.058837, 'loss_vowel': 0.0319, 'loss_consonant': 0.038649}\n",
      "  215 | 0.000026 | 049920/160735 | 0.4821 | 1.6347 |\n",
      "val: {'recall': 0.99379, 'recall_grapheme': 0.991162, 'recall_vowel': 0.996259, 'recall_consonant': 0.996575, 'acc_grapheme': 0.989752, 'acc_vowel': 0.996559, 'acc_consonant': 0.996335, 'loss_grapheme': 0.06898, 'loss_vowel': 0.043231, 'loss_consonant': 0.038526}\n",
      "  216 | 0.000015 | 043008/160735 | 0.1600 | 1.6145 |\n",
      "val: {'recall': 0.994685, 'recall_grapheme': 0.992821, 'recall_vowel': 0.996659, 'recall_consonant': 0.99644, 'acc_grapheme': 0.99222, 'acc_vowel': 0.997232, 'acc_consonant': 0.996858, 'loss_grapheme': 0.101686, 'loss_vowel': 0.059457, 'loss_consonant': 0.044929}\n",
      "  217 | 0.000008 | 036096/160735 | 1.1994 | 1.6792 |\n",
      "val: {'recall': 0.99321, 'recall_grapheme': 0.99012, 'recall_vowel': 0.996251, 'recall_consonant': 0.996351, 'acc_grapheme': 0.989677, 'acc_vowel': 0.996759, 'acc_consonant': 0.99621, 'loss_grapheme': 0.070238, 'loss_vowel': 0.048816, 'loss_consonant': 0.042368}\n",
      "  218 | 0.000003 | 029184/160735 | 1.7271 | 1.6031 |\n",
      "val: {'recall': 0.994316, 'recall_grapheme': 0.991922, 'recall_vowel': 0.996963, 'recall_consonant': 0.996458, 'acc_grapheme': 0.991273, 'acc_vowel': 0.997307, 'acc_consonant': 0.996709, 'loss_grapheme': 0.077236, 'loss_vowel': 0.047047, 'loss_consonant': 0.039213}\n",
      "  219 | 0.000001 | 022272/160735 | 0.5786 | 1.8753 |\n",
      "val: {'recall': 0.992708, 'recall_grapheme': 0.98952, 'recall_vowel': 0.996434, 'recall_consonant': 0.995359, 'acc_grapheme': 0.988954, 'acc_vowel': 0.996808, 'acc_consonant': 0.99621, 'loss_grapheme': 0.102701, 'loss_vowel': 0.075976, 'loss_consonant': 0.059096}\n",
      "  220 | 0.000003 | 015360/160735 | 2.7798 | 1.9141 |\n",
      "val: {'recall': 0.992719, 'recall_grapheme': 0.989309, 'recall_vowel': 0.995929, 'recall_consonant': 0.99633, 'acc_grapheme': 0.98853, 'acc_vowel': 0.996459, 'acc_consonant': 0.995736, 'loss_grapheme': 0.070921, 'loss_vowel': 0.052415, 'loss_consonant': 0.050608}\n",
      "  221 | 0.000008 | 008448/160735 | 1.8675 | 1.4956 |\n",
      "val: {'recall': 0.994263, 'recall_grapheme': 0.991912, 'recall_vowel': 0.996785, 'recall_consonant': 0.996441, 'acc_grapheme': 0.990924, 'acc_vowel': 0.996958, 'acc_consonant': 0.996534, 'loss_grapheme': 0.066886, 'loss_vowel': 0.043874, 'loss_consonant': 0.037673}\n",
      "  222 | 0.000015 | 001536/160735 | 2.0327 | 2.0970 |\n",
      "val: {'recall': 0.991406, 'recall_grapheme': 0.987088, 'recall_vowel': 0.995424, 'recall_consonant': 0.996023, 'acc_grapheme': 0.98651, 'acc_vowel': 0.996085, 'acc_consonant': 0.995387, 'loss_grapheme': 0.066096, 'loss_vowel': 0.045129, 'loss_consonant': 0.048106}\n",
      "  222 | 0.000026 | 155136/160735 | 1.4123 | 1.7350 |\n",
      "val: {'recall': 0.994387, 'recall_grapheme': 0.991875, 'recall_vowel': 0.996922, 'recall_consonant': 0.996879, 'acc_grapheme': 0.991323, 'acc_vowel': 0.997232, 'acc_consonant': 0.996833, 'loss_grapheme': 0.089544, 'loss_vowel': 0.057879, 'loss_consonant': 0.048963}\n",
      "  223 | 0.000038 | 148224/160735 | 1.8747 | 1.6439 |\n",
      "val: {'recall': 0.99377, 'recall_grapheme': 0.991369, 'recall_vowel': 0.997038, 'recall_consonant': 0.995304, 'acc_grapheme': 0.990899, 'acc_vowel': 0.997282, 'acc_consonant': 0.996634, 'loss_grapheme': 0.093049, 'loss_vowel': 0.05226, 'loss_consonant': 0.043736}\n",
      "  224 | 0.000050 | 053760/160735 | 0.9746 | 1.7648 |"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
