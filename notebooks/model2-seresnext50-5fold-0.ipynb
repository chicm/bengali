{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengaliai-cv19.zip\t   test_image_data_3.parquet\r\n",
      "class_map.csv\t\t   train.csv\r\n",
      "sample_submission.csv\t   train_image_data_0.parquet\r\n",
      "test.csv\t\t   train_image_data_1.parquet\r\n",
      "test_image_data_0.parquet  train_image_data_2.parquet\r\n",
      "test_image_data_1.parquet  train_image_data_3.parquet\r\n",
      "test_image_data_2.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/chicm/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet_1(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3660004616960876"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                #img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                #loss = mixup_criterion(outputs, targets)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model2_se_resnext50_fold0.pth'\n",
    "args.predict = False\n",
    "args.optim = 'RAdam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 15\n",
    "args.factor = 0.6\n",
    "args.patience = 0\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160596, 5) (40244, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model2_se_resnext50_fold0.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model2_se_resnext50_fold0.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.98213, 'recall_grapheme': 0.9727, 'recall_vowel': 0.990763, 'recall_consonant': 0.992358, 'acc_grapheme': 0.974878, 'acc_vowel': 0.992322, 'acc_consonant': 0.991353, 'loss_grapheme': 0.09996, 'loss_vowel': 0.038796, 'loss_consonant': 0.036455}\n",
      "    1 | 0.000020 | 045056/160596 | 3.8520 | 1.5681 |\n",
      "val: {'recall': 0.981732, 'recall_grapheme': 0.972032, 'recall_vowel': 0.990823, 'recall_consonant': 0.992043, 'acc_grapheme': 0.974158, 'acc_vowel': 0.992297, 'acc_consonant': 0.991055, 'loss_grapheme': 0.11556, 'loss_vowel': 0.055904, 'loss_consonant': 0.048619}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000020 | 090112/160596 | 0.0116 | 1.5583 |\n",
      "val: {'recall': 0.981472, 'recall_grapheme': 0.971554, 'recall_vowel': 0.990365, 'recall_consonant': 0.992418, 'acc_grapheme': 0.973189, 'acc_vowel': 0.992098, 'acc_consonant': 0.990806, 'loss_grapheme': 0.162569, 'loss_vowel': 0.099336, 'loss_consonant': 0.078764}\n",
      "    3 | 0.000019 | 135168/160596 | 0.0104 | 1.5188 |\n",
      "val: {'recall': 0.981652, 'recall_grapheme': 0.971992, 'recall_vowel': 0.99017, 'recall_consonant': 0.992454, 'acc_grapheme': 0.973213, 'acc_vowel': 0.991949, 'acc_consonant': 0.99098, 'loss_grapheme': 0.143441, 'loss_vowel': 0.083762, 'loss_consonant': 0.066712}\n",
      "    5 | 0.000018 | 020480/160596 | 4.5529 | 2.2100 |\n",
      "val: {'recall': 0.981492, 'recall_grapheme': 0.971757, 'recall_vowel': 0.990222, 'recall_consonant': 0.992231, 'acc_grapheme': 0.973189, 'acc_vowel': 0.991924, 'acc_consonant': 0.990707, 'loss_grapheme': 0.189168, 'loss_vowel': 0.121868, 'loss_consonant': 0.094003}\n",
      "    6 | 0.000017 | 065536/160596 | 0.0105 | 1.1125 |\n",
      "val: {'recall': 0.982497, 'recall_grapheme': 0.9735, 'recall_vowel': 0.991, 'recall_consonant': 0.991989, 'acc_grapheme': 0.974655, 'acc_vowel': 0.992446, 'acc_consonant': 0.991452, 'loss_grapheme': 0.104576, 'loss_vowel': 0.044134, 'loss_consonant': 0.039814}\n",
      "** saved\n",
      "    7 | 0.000015 | 110592/160596 | 2.9744 | 1.5110 |\n",
      "val: {'recall': 0.982247, 'recall_grapheme': 0.97307, 'recall_vowel': 0.990566, 'recall_consonant': 0.992282, 'acc_grapheme': 0.974481, 'acc_vowel': 0.992247, 'acc_consonant': 0.99098, 'loss_grapheme': 0.10904, 'loss_vowel': 0.048158, 'loss_consonant': 0.043987}\n",
      "    8 | 0.000013 | 155648/160596 | 0.0184 | 1.3154 |\n",
      "val: {'recall': 0.982314, 'recall_grapheme': 0.973, 'recall_vowel': 0.990988, 'recall_consonant': 0.992268, 'acc_grapheme': 0.974779, 'acc_vowel': 0.992496, 'acc_consonant': 0.991328, 'loss_grapheme': 0.100714, 'loss_vowel': 0.039446, 'loss_consonant': 0.03669}\n",
      "   10 | 0.000011 | 040960/160596 | 3.8494 | 1.9974 |\n",
      "val: {'recall': 0.98143, 'recall_grapheme': 0.971571, 'recall_vowel': 0.990218, 'recall_consonant': 0.992361, 'acc_grapheme': 0.973462, 'acc_vowel': 0.992073, 'acc_consonant': 0.99103, 'loss_grapheme': 0.167065, 'loss_vowel': 0.103308, 'loss_consonant': 0.081289}\n",
      "   11 | 0.000010 | 086016/160596 | 3.6987 | 2.0165 |\n",
      "val: {'recall': 0.981289, 'recall_grapheme': 0.971347, 'recall_vowel': 0.98998, 'recall_consonant': 0.992482, 'acc_grapheme': 0.973015, 'acc_vowel': 0.991924, 'acc_consonant': 0.990632, 'loss_grapheme': 0.240525, 'loss_vowel': 0.158293, 'loss_consonant': 0.115659}\n",
      "   12 | 0.000008 | 131072/160596 | 0.0143 | 1.5469 |\n",
      "val: {'recall': 0.982443, 'recall_grapheme': 0.973271, 'recall_vowel': 0.99092, 'recall_consonant': 0.992313, 'acc_grapheme': 0.974928, 'acc_vowel': 0.992521, 'acc_consonant': 0.991552, 'loss_grapheme': 0.101109, 'loss_vowel': 0.040296, 'loss_consonant': 0.037676}\n",
      "   14 | 0.000006 | 016384/160596 | 4.5168 | 1.4749 |\n",
      "val: {'recall': 0.982229, 'recall_grapheme': 0.972862, 'recall_vowel': 0.990833, 'recall_consonant': 0.99236, 'acc_grapheme': 0.974605, 'acc_vowel': 0.992421, 'acc_consonant': 0.991303, 'loss_grapheme': 0.11385, 'loss_vowel': 0.054189, 'loss_consonant': 0.047317}\n",
      "   15 | 0.000004 | 061440/160596 | 4.8777 | 1.6079 |\n",
      "val: {'recall': 0.981566, 'recall_grapheme': 0.971721, 'recall_vowel': 0.990486, 'recall_consonant': 0.992333, 'acc_grapheme': 0.97381, 'acc_vowel': 0.992198, 'acc_consonant': 0.990905, 'loss_grapheme': 0.144724, 'loss_vowel': 0.085879, 'loss_consonant': 0.068546}\n",
      "   16 | 0.000003 | 106496/160596 | 4.5494 | 1.6012 |\n",
      "val: {'recall': 0.981768, 'recall_grapheme': 0.972275, 'recall_vowel': 0.99038, 'recall_consonant': 0.992141, 'acc_grapheme': 0.974108, 'acc_vowel': 0.992098, 'acc_consonant': 0.990707, 'loss_grapheme': 0.131097, 'loss_vowel': 0.070508, 'loss_consonant': 0.059155}\n",
      "   17 | 0.000002 | 151552/160596 | 3.5401 | 1.6293 |\n",
      "val: {'recall': 0.982194, 'recall_grapheme': 0.972896, 'recall_vowel': 0.990769, 'recall_consonant': 0.992216, 'acc_grapheme': 0.974655, 'acc_vowel': 0.992421, 'acc_consonant': 0.991079, 'loss_grapheme': 0.110793, 'loss_vowel': 0.05241, 'loss_consonant': 0.045721}\n",
      "   19 | 0.000001 | 036864/160596 | 0.0101 | 0.9338 |\n",
      "val: {'recall': 0.982386, 'recall_grapheme': 0.973033, 'recall_vowel': 0.991084, 'recall_consonant': 0.992396, 'acc_grapheme': 0.974953, 'acc_vowel': 0.99257, 'acc_consonant': 0.991452, 'loss_grapheme': 0.10052, 'loss_vowel': 0.040079, 'loss_consonant': 0.037233}\n",
      "   20 | 0.000001 | 081920/160596 | 4.8101 | 1.7302 |\n",
      "val: {'recall': 0.982468, 'recall_grapheme': 0.973368, 'recall_vowel': 0.990795, 'recall_consonant': 0.992341, 'acc_grapheme': 0.974878, 'acc_vowel': 0.992545, 'acc_consonant': 0.991378, 'loss_grapheme': 0.104323, 'loss_vowel': 0.044423, 'loss_consonant': 0.040673}\n",
      "   21 | 0.000001 | 126976/160596 | 0.0150 | 1.4888 |\n",
      "val: {'recall': 0.982606, 'recall_grapheme': 0.973554, 'recall_vowel': 0.990993, 'recall_consonant': 0.992323, 'acc_grapheme': 0.974953, 'acc_vowel': 0.99257, 'acc_consonant': 0.991278, 'loss_grapheme': 0.102555, 'loss_vowel': 0.041891, 'loss_consonant': 0.038961}\n",
      "** saved\n",
      "   23 | 0.000002 | 012288/160596 | 4.3248 | 1.8470 |\n",
      "val: {'recall': 0.981899, 'recall_grapheme': 0.972345, 'recall_vowel': 0.990611, 'recall_consonant': 0.992296, 'acc_grapheme': 0.974158, 'acc_vowel': 0.992272, 'acc_consonant': 0.99098, 'loss_grapheme': 0.121852, 'loss_vowel': 0.064531, 'loss_consonant': 0.054556}\n",
      "   24 | 0.000003 | 057344/160596 | 4.6653 | 1.5164 |\n",
      "val: {'recall': 0.982037, 'recall_grapheme': 0.972522, 'recall_vowel': 0.990976, 'recall_consonant': 0.992129, 'acc_grapheme': 0.974481, 'acc_vowel': 0.992247, 'acc_consonant': 0.991079, 'loss_grapheme': 0.113889, 'loss_vowel': 0.055985, 'loss_consonant': 0.048984}\n",
      "   25 | 0.000004 | 102400/160596 | 4.3648 | 1.4486 |\n",
      "val: {'recall': 0.981961, 'recall_grapheme': 0.972471, 'recall_vowel': 0.990647, 'recall_consonant': 0.992257, 'acc_grapheme': 0.974332, 'acc_vowel': 0.992123, 'acc_consonant': 0.99103, 'loss_grapheme': 0.119902, 'loss_vowel': 0.061123, 'loss_consonant': 0.052517}\n",
      "   26 | 0.000006 | 147456/160596 | 3.1853 | 1.8400 |\n",
      "val: {'recall': 0.981729, 'recall_grapheme': 0.971968, 'recall_vowel': 0.99052, 'recall_consonant': 0.992461, 'acc_grapheme': 0.973661, 'acc_vowel': 0.992073, 'acc_consonant': 0.990707, 'loss_grapheme': 0.157787, 'loss_vowel': 0.097834, 'loss_consonant': 0.077812}\n",
      "   28 | 0.000008 | 032768/160596 | 3.5711 | 1.7009 |\n",
      "val: {'recall': 0.981813, 'recall_grapheme': 0.972187, 'recall_vowel': 0.990756, 'recall_consonant': 0.992124, 'acc_grapheme': 0.973512, 'acc_vowel': 0.992247, 'acc_consonant': 0.990781, 'loss_grapheme': 0.137232, 'loss_vowel': 0.079468, 'loss_consonant': 0.065111}\n",
      "   29 | 0.000010 | 077824/160596 | 0.0164 | 1.8666 |\n",
      "val: {'recall': 0.981989, 'recall_grapheme': 0.97255, 'recall_vowel': 0.990552, 'recall_consonant': 0.992303, 'acc_grapheme': 0.974158, 'acc_vowel': 0.992421, 'acc_consonant': 0.990856, 'loss_grapheme': 0.118084, 'loss_vowel': 0.058219, 'loss_consonant': 0.051335}\n",
      "   30 | 0.000011 | 122880/160596 | 0.0138 | 1.7096 |\n",
      "val: {'recall': 0.982635, 'recall_grapheme': 0.973881, 'recall_vowel': 0.990374, 'recall_consonant': 0.992405, 'acc_grapheme': 0.975102, 'acc_vowel': 0.992272, 'acc_consonant': 0.991402, 'loss_grapheme': 0.104126, 'loss_vowel': 0.042943, 'loss_consonant': 0.039694}\n",
      "** saved\n",
      "   32 | 0.000013 | 008192/160596 | 3.8615 | 2.2712 |\n",
      "val: {'recall': 0.98188, 'recall_grapheme': 0.972308, 'recall_vowel': 0.990584, 'recall_consonant': 0.992321, 'acc_grapheme': 0.973362, 'acc_vowel': 0.992198, 'acc_consonant': 0.990781, 'loss_grapheme': 0.163033, 'loss_vowel': 0.10251, 'loss_consonant': 0.080783}\n",
      "   33 | 0.000015 | 053248/160596 | 2.0785 | 2.0554 |\n",
      "val: {'recall': 0.982188, 'recall_grapheme': 0.972842, 'recall_vowel': 0.990894, 'recall_consonant': 0.992173, 'acc_grapheme': 0.974207, 'acc_vowel': 0.992173, 'acc_consonant': 0.990856, 'loss_grapheme': 0.118345, 'loss_vowel': 0.059365, 'loss_consonant': 0.052122}\n",
      "   34 | 0.000017 | 098304/160596 | 0.0099 | 1.5785 |\n",
      "val: {'recall': 0.982615, 'recall_grapheme': 0.97361, 'recall_vowel': 0.990938, 'recall_consonant': 0.992303, 'acc_grapheme': 0.974655, 'acc_vowel': 0.992396, 'acc_consonant': 0.991204, 'loss_grapheme': 0.115781, 'loss_vowel': 0.057191, 'loss_consonant': 0.048844}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000018 | 143360/160596 | 4.1131 | 1.8110 |\n",
      "val: {'recall': 0.98208, 'recall_grapheme': 0.972535, 'recall_vowel': 0.990844, 'recall_consonant': 0.992404, 'acc_grapheme': 0.973835, 'acc_vowel': 0.992446, 'acc_consonant': 0.991378, 'loss_grapheme': 0.148978, 'loss_vowel': 0.084875, 'loss_consonant': 0.068412}\n",
      "   37 | 0.000019 | 028672/160596 | 2.6233 | 1.5760 |\n",
      "val: {'recall': 0.98188, 'recall_grapheme': 0.97207, 'recall_vowel': 0.991346, 'recall_consonant': 0.992034, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992446, 'acc_consonant': 0.991378, 'loss_grapheme': 0.112496, 'loss_vowel': 0.053568, 'loss_consonant': 0.045383}\n",
      "   38 | 0.000020 | 073728/160596 | 0.0235 | 1.6251 |\n",
      "val: {'recall': 0.982452, 'recall_grapheme': 0.973136, 'recall_vowel': 0.991149, 'recall_consonant': 0.992388, 'acc_grapheme': 0.975301, 'acc_vowel': 0.992918, 'acc_consonant': 0.991676, 'loss_grapheme': 0.099788, 'loss_vowel': 0.037113, 'loss_consonant': 0.035303}\n",
      "   39 | 0.000020 | 118784/160596 | 3.3927 | 1.4419 |\n",
      "val: {'recall': 0.981985, 'recall_grapheme': 0.972822, 'recall_vowel': 0.990245, 'recall_consonant': 0.992052, 'acc_grapheme': 0.974431, 'acc_vowel': 0.992049, 'acc_consonant': 0.991402, 'loss_grapheme': 0.127196, 'loss_vowel': 0.069041, 'loss_consonant': 0.056816}\n",
      "   41 | 0.000020 | 004096/160596 | 0.0097 | 0.7146 |\n",
      "val: {'recall': 0.982228, 'recall_grapheme': 0.972764, 'recall_vowel': 0.991071, 'recall_consonant': 0.992311, 'acc_grapheme': 0.974655, 'acc_vowel': 0.992521, 'acc_consonant': 0.991477, 'loss_grapheme': 0.105471, 'loss_vowel': 0.044592, 'loss_consonant': 0.040095}\n",
      "   42 | 0.000019 | 049152/160596 | 4.4147 | 1.6085 |\n",
      "val: {'recall': 0.981576, 'recall_grapheme': 0.971964, 'recall_vowel': 0.990023, 'recall_consonant': 0.992351, 'acc_grapheme': 0.974133, 'acc_vowel': 0.992347, 'acc_consonant': 0.991229, 'loss_grapheme': 0.114725, 'loss_vowel': 0.057081, 'loss_consonant': 0.049554}\n",
      "   43 | 0.000018 | 094208/160596 | 0.0080 | 1.6048 |\n",
      "val: {'recall': 0.982416, 'recall_grapheme': 0.973597, 'recall_vowel': 0.990336, 'recall_consonant': 0.992134, 'acc_grapheme': 0.974605, 'acc_vowel': 0.992247, 'acc_consonant': 0.990707, 'loss_grapheme': 0.126341, 'loss_vowel': 0.069695, 'loss_consonant': 0.057816}\n",
      "   44 | 0.000017 | 139264/160596 | 2.6641 | 1.5388 |\n",
      "val: {'recall': 0.982682, 'recall_grapheme': 0.973982, 'recall_vowel': 0.990755, 'recall_consonant': 0.992009, 'acc_grapheme': 0.975425, 'acc_vowel': 0.992496, 'acc_consonant': 0.991527, 'loss_grapheme': 0.099008, 'loss_vowel': 0.038631, 'loss_consonant': 0.035626}\n",
      "** saved\n",
      "   46 | 0.000015 | 024576/160596 | 3.8836 | 2.0529 |\n",
      "val: {'recall': 0.982612, 'recall_grapheme': 0.973464, 'recall_vowel': 0.991361, 'recall_consonant': 0.99216, 'acc_grapheme': 0.974679, 'acc_vowel': 0.992471, 'acc_consonant': 0.991527, 'loss_grapheme': 0.123277, 'loss_vowel': 0.067771, 'loss_consonant': 0.055824}\n",
      "   47 | 0.000013 | 069632/160596 | 0.0128 | 1.6723 |\n",
      "val: {'recall': 0.98241, 'recall_grapheme': 0.973175, 'recall_vowel': 0.991014, 'recall_consonant': 0.992278, 'acc_grapheme': 0.974207, 'acc_vowel': 0.992496, 'acc_consonant': 0.991005, 'loss_grapheme': 0.1416, 'loss_vowel': 0.083857, 'loss_consonant': 0.065187}\n",
      "   48 | 0.000011 | 114688/160596 | 0.0112 | 1.4007 |\n",
      "val: {'recall': 0.983189, 'recall_grapheme': 0.974478, 'recall_vowel': 0.991336, 'recall_consonant': 0.992467, 'acc_grapheme': 0.97535, 'acc_vowel': 0.992869, 'acc_consonant': 0.99185, 'loss_grapheme': 0.09936, 'loss_vowel': 0.037894, 'loss_consonant': 0.035422}\n",
      "** saved\n",
      "   49 | 0.000010 | 159744/160596 | 0.0129 | 1.5949 |\n",
      "val: {'recall': 0.982857, 'recall_grapheme': 0.974087, 'recall_vowel': 0.990782, 'recall_consonant': 0.992473, 'acc_grapheme': 0.974779, 'acc_vowel': 0.99257, 'acc_consonant': 0.991427, 'loss_grapheme': 0.102713, 'loss_vowel': 0.042692, 'loss_consonant': 0.039061}\n",
      "   51 | 0.000008 | 045056/160596 | 1.5444 | 1.3703 |\n",
      "val: {'recall': 0.982541, 'recall_grapheme': 0.973315, 'recall_vowel': 0.99104, 'recall_consonant': 0.992493, 'acc_grapheme': 0.973984, 'acc_vowel': 0.992545, 'acc_consonant': 0.991179, 'loss_grapheme': 0.142015, 'loss_vowel': 0.084628, 'loss_consonant': 0.067351}\n",
      "   52 | 0.000006 | 090112/160596 | 2.8067 | 1.5088 |\n",
      "val: {'recall': 0.982874, 'recall_grapheme': 0.973945, 'recall_vowel': 0.991165, 'recall_consonant': 0.992443, 'acc_grapheme': 0.974853, 'acc_vowel': 0.99262, 'acc_consonant': 0.991278, 'loss_grapheme': 0.111398, 'loss_vowel': 0.052457, 'loss_consonant': 0.045422}\n",
      "   53 | 0.000004 | 135168/160596 | 3.6135 | 1.5382 |\n",
      "val: {'recall': 0.982271, 'recall_grapheme': 0.973002, 'recall_vowel': 0.99066, 'recall_consonant': 0.992418, 'acc_grapheme': 0.974033, 'acc_vowel': 0.992396, 'acc_consonant': 0.991502, 'loss_grapheme': 0.126165, 'loss_vowel': 0.068909, 'loss_consonant': 0.05695}\n",
      "   55 | 0.000003 | 020480/160596 | 4.5942 | 1.4737 |\n",
      "val: {'recall': 0.982674, 'recall_grapheme': 0.973335, 'recall_vowel': 0.991585, 'recall_consonant': 0.992444, 'acc_grapheme': 0.974356, 'acc_vowel': 0.992695, 'acc_consonant': 0.991725, 'loss_grapheme': 0.108726, 'loss_vowel': 0.050603, 'loss_consonant': 0.044062}\n",
      "   56 | 0.000002 | 065536/160596 | 3.0637 | 1.5709 |\n",
      "val: {'recall': 0.9825, 'recall_grapheme': 0.973376, 'recall_vowel': 0.990758, 'recall_consonant': 0.992491, 'acc_grapheme': 0.973934, 'acc_vowel': 0.99257, 'acc_consonant': 0.991527, 'loss_grapheme': 0.116702, 'loss_vowel': 0.059005, 'loss_consonant': 0.049216}\n",
      "   57 | 0.000001 | 110592/160596 | 3.4966 | 1.5199 |\n",
      "val: {'recall': 0.982604, 'recall_grapheme': 0.973495, 'recall_vowel': 0.990865, 'recall_consonant': 0.992561, 'acc_grapheme': 0.974033, 'acc_vowel': 0.99257, 'acc_consonant': 0.991452, 'loss_grapheme': 0.116508, 'loss_vowel': 0.059493, 'loss_consonant': 0.050876}\n",
      "   58 | 0.000001 | 155648/160596 | 0.0081 | 1.6633 |\n",
      "val: {'recall': 0.982778, 'recall_grapheme': 0.973733, 'recall_vowel': 0.991263, 'recall_consonant': 0.992382, 'acc_grapheme': 0.974754, 'acc_vowel': 0.99262, 'acc_consonant': 0.991353, 'loss_grapheme': 0.102298, 'loss_vowel': 0.042307, 'loss_consonant': 0.038334}\n",
      "   60 | 0.000001 | 040960/160596 | 0.0067 | 1.9098 |\n",
      "val: {'recall': 0.982572, 'recall_grapheme': 0.973549, 'recall_vowel': 0.990705, 'recall_consonant': 0.992486, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992496, 'acc_consonant': 0.991402, 'loss_grapheme': 0.137663, 'loss_vowel': 0.080596, 'loss_consonant': 0.063589}\n",
      "   61 | 0.000002 | 086016/160596 | 4.8331 | 1.5536 |\n",
      "val: {'recall': 0.982706, 'recall_grapheme': 0.97366, 'recall_vowel': 0.99108, 'recall_consonant': 0.992426, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992719, 'acc_consonant': 0.991427, 'loss_grapheme': 0.118643, 'loss_vowel': 0.061704, 'loss_consonant': 0.05132}\n",
      "   62 | 0.000003 | 131072/160596 | 0.0123 | 1.8512 |\n",
      "val: {'recall': 0.982513, 'recall_grapheme': 0.973433, 'recall_vowel': 0.990791, 'recall_consonant': 0.992393, 'acc_grapheme': 0.974108, 'acc_vowel': 0.992645, 'acc_consonant': 0.991527, 'loss_grapheme': 0.110685, 'loss_vowel': 0.052445, 'loss_consonant': 0.044889}\n",
      "   64 | 0.000004 | 016384/160596 | 0.2904 | 1.9172 |\n",
      "val: {'recall': 0.982254, 'recall_grapheme': 0.972883, 'recall_vowel': 0.990787, 'recall_consonant': 0.992462, 'acc_grapheme': 0.974356, 'acc_vowel': 0.992496, 'acc_consonant': 0.991576, 'loss_grapheme': 0.131188, 'loss_vowel': 0.071375, 'loss_consonant': 0.059209}\n",
      "   65 | 0.000006 | 061440/160596 | 0.0237 | 1.3049 |\n",
      "val: {'recall': 0.982997, 'recall_grapheme': 0.97399, 'recall_vowel': 0.991605, 'recall_consonant': 0.992402, 'acc_grapheme': 0.974853, 'acc_vowel': 0.992794, 'acc_consonant': 0.991899, 'loss_grapheme': 0.099705, 'loss_vowel': 0.036398, 'loss_consonant': 0.033489}\n",
      "   66 | 0.000008 | 106496/160596 | 0.0100 | 1.5836 |\n",
      "val: {'recall': 0.982771, 'recall_grapheme': 0.973713, 'recall_vowel': 0.991307, 'recall_consonant': 0.992351, 'acc_grapheme': 0.974804, 'acc_vowel': 0.99262, 'acc_consonant': 0.991626, 'loss_grapheme': 0.105263, 'loss_vowel': 0.044922, 'loss_consonant': 0.040285}\n",
      "   67 | 0.000010 | 151552/160596 | 0.0048 | 1.4615 |\n",
      "val: {'recall': 0.982855, 'recall_grapheme': 0.973587, 'recall_vowel': 0.99169, 'recall_consonant': 0.992556, 'acc_grapheme': 0.974431, 'acc_vowel': 0.99257, 'acc_consonant': 0.991626, 'loss_grapheme': 0.109787, 'loss_vowel': 0.049697, 'loss_consonant': 0.04343}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 | 0.000011 | 036864/160596 | 0.0086 | 1.2077 |\n",
      "val: {'recall': 0.982932, 'recall_grapheme': 0.974048, 'recall_vowel': 0.991445, 'recall_consonant': 0.992186, 'acc_grapheme': 0.974953, 'acc_vowel': 0.992819, 'acc_consonant': 0.991775, 'loss_grapheme': 0.10231, 'loss_vowel': 0.041024, 'loss_consonant': 0.036967}\n",
      "   70 | 0.000013 | 081920/160596 | 2.6843 | 1.6888 |\n",
      "val: {'recall': 0.982407, 'recall_grapheme': 0.973087, 'recall_vowel': 0.991271, 'recall_consonant': 0.992184, 'acc_grapheme': 0.974282, 'acc_vowel': 0.992645, 'acc_consonant': 0.991179, 'loss_grapheme': 0.109814, 'loss_vowel': 0.050335, 'loss_consonant': 0.044278}\n",
      "   71 | 0.000015 | 126976/160596 | 3.5531 | 1.5794 |\n",
      "val: {'recall': 0.982127, 'recall_grapheme': 0.97243, 'recall_vowel': 0.991226, 'recall_consonant': 0.992423, 'acc_grapheme': 0.974406, 'acc_vowel': 0.992719, 'acc_consonant': 0.991651, 'loss_grapheme': 0.123261, 'loss_vowel': 0.064229, 'loss_consonant': 0.052798}\n",
      "   73 | 0.000017 | 012288/160596 | 0.0079 | 2.0086 |\n",
      "val: {'recall': 0.982629, 'recall_grapheme': 0.973616, 'recall_vowel': 0.991312, 'recall_consonant': 0.991974, 'acc_grapheme': 0.974605, 'acc_vowel': 0.992719, 'acc_consonant': 0.991129, 'loss_grapheme': 0.126977, 'loss_vowel': 0.069534, 'loss_consonant': 0.055411}\n",
      "   74 | 0.000018 | 057344/160596 | 4.4651 | 1.5996 |\n",
      "val: {'recall': 0.982504, 'recall_grapheme': 0.973239, 'recall_vowel': 0.99093, 'recall_consonant': 0.992609, 'acc_grapheme': 0.97458, 'acc_vowel': 0.992446, 'acc_consonant': 0.991477, 'loss_grapheme': 0.127148, 'loss_vowel': 0.069648, 'loss_consonant': 0.057535}\n",
      "   75 | 0.000019 | 102400/160596 | 1.2787 | 1.8393 |\n",
      "val: {'recall': 0.982801, 'recall_grapheme': 0.973557, 'recall_vowel': 0.991404, 'recall_consonant': 0.992688, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992695, 'acc_consonant': 0.991253, 'loss_grapheme': 0.159782, 'loss_vowel': 0.098112, 'loss_consonant': 0.075498}\n",
      "   76 | 0.000020 | 147456/160596 | 0.0129 | 1.4836 |\n",
      "val: {'recall': 0.982582, 'recall_grapheme': 0.97357, 'recall_vowel': 0.99031, 'recall_consonant': 0.992877, 'acc_grapheme': 0.974679, 'acc_vowel': 0.992595, 'acc_consonant': 0.991899, 'loss_grapheme': 0.104334, 'loss_vowel': 0.043313, 'loss_consonant': 0.038692}\n",
      "   78 | 0.000020 | 032768/160596 | 3.1198 | 1.2494 |\n",
      "val: {'recall': 0.983067, 'recall_grapheme': 0.974508, 'recall_vowel': 0.991292, 'recall_consonant': 0.991961, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992595, 'acc_consonant': 0.991477, 'loss_grapheme': 0.109156, 'loss_vowel': 0.048807, 'loss_consonant': 0.043063}\n",
      "   79 | 0.000020 | 077824/160596 | 0.0060 | 1.6076 |\n",
      "val: {'recall': 0.982341, 'recall_grapheme': 0.972466, 'recall_vowel': 0.991795, 'recall_consonant': 0.992638, 'acc_grapheme': 0.974158, 'acc_vowel': 0.992769, 'acc_consonant': 0.991676, 'loss_grapheme': 0.111903, 'loss_vowel': 0.053133, 'loss_consonant': 0.046384}\n",
      "   80 | 0.000019 | 122880/160596 | 1.7305 | 1.5088 |\n",
      "val: {'recall': 0.982972, 'recall_grapheme': 0.973815, 'recall_vowel': 0.991675, 'recall_consonant': 0.992585, 'acc_grapheme': 0.975152, 'acc_vowel': 0.992993, 'acc_consonant': 0.991899, 'loss_grapheme': 0.101311, 'loss_vowel': 0.039581, 'loss_consonant': 0.03584}\n",
      "   82 | 0.000018 | 008192/160596 | 2.7199 | 2.4190 |\n",
      "val: {'recall': 0.982392, 'recall_grapheme': 0.973555, 'recall_vowel': 0.990847, 'recall_consonant': 0.991611, 'acc_grapheme': 0.974605, 'acc_vowel': 0.992595, 'acc_consonant': 0.99185, 'loss_grapheme': 0.120886, 'loss_vowel': 0.063012, 'loss_consonant': 0.052209}\n",
      "   83 | 0.000017 | 053248/160596 | 4.0796 | 1.6572 |\n",
      "val: {'recall': 0.983289, 'recall_grapheme': 0.974353, 'recall_vowel': 0.991644, 'recall_consonant': 0.992805, 'acc_grapheme': 0.975201, 'acc_vowel': 0.992893, 'acc_consonant': 0.992049, 'loss_grapheme': 0.10221, 'loss_vowel': 0.039092, 'loss_consonant': 0.03639}\n",
      "** saved\n",
      "   84 | 0.000015 | 098304/160596 | 0.0048 | 1.4731 |\n",
      "val: {'recall': 0.982866, 'recall_grapheme': 0.973703, 'recall_vowel': 0.99157, 'recall_consonant': 0.992491, 'acc_grapheme': 0.974729, 'acc_vowel': 0.992695, 'acc_consonant': 0.991775, 'loss_grapheme': 0.106298, 'loss_vowel': 0.044609, 'loss_consonant': 0.039716}\n",
      "   85 | 0.000013 | 143360/160596 | 2.6268 | 1.4141 |\n",
      "val: {'recall': 0.982516, 'recall_grapheme': 0.973127, 'recall_vowel': 0.991447, 'recall_consonant': 0.992366, 'acc_grapheme': 0.974381, 'acc_vowel': 0.992769, 'acc_consonant': 0.991303, 'loss_grapheme': 0.126527, 'loss_vowel': 0.067354, 'loss_consonant': 0.054829}\n",
      "   87 | 0.000011 | 028672/160596 | 1.2625 | 1.3512 |\n",
      "val: {'recall': 0.983017, 'recall_grapheme': 0.973999, 'recall_vowel': 0.991399, 'recall_consonant': 0.992672, 'acc_grapheme': 0.975077, 'acc_vowel': 0.992869, 'acc_consonant': 0.991651, 'loss_grapheme': 0.10708, 'loss_vowel': 0.047077, 'loss_consonant': 0.04187}\n",
      "   88 | 0.000010 | 073728/160596 | 0.0085 | 1.2862 |\n",
      "val: {'recall': 0.982992, 'recall_grapheme': 0.974218, 'recall_vowel': 0.991581, 'recall_consonant': 0.99195, 'acc_grapheme': 0.975002, 'acc_vowel': 0.992844, 'acc_consonant': 0.992024, 'loss_grapheme': 0.101658, 'loss_vowel': 0.040083, 'loss_consonant': 0.036219}\n",
      "   89 | 0.000008 | 118784/160596 | 1.0025 | 1.6510 |\n",
      "val: {'recall': 0.982802, 'recall_grapheme': 0.973631, 'recall_vowel': 0.991418, 'recall_consonant': 0.992529, 'acc_grapheme': 0.974704, 'acc_vowel': 0.992794, 'acc_consonant': 0.991576, 'loss_grapheme': 0.12575, 'loss_vowel': 0.066934, 'loss_consonant': 0.054485}\n",
      "   91 | 0.000006 | 004096/160596 | 1.3428 | 1.3138 |\n",
      "val: {'recall': 0.983383, 'recall_grapheme': 0.974804, 'recall_vowel': 0.99162, 'recall_consonant': 0.992305, 'acc_grapheme': 0.975624, 'acc_vowel': 0.992943, 'acc_consonant': 0.992073, 'loss_grapheme': 0.098993, 'loss_vowel': 0.03642, 'loss_consonant': 0.033757}\n",
      "** saved\n",
      "   92 | 0.000004 | 049152/160596 | 3.6617 | 1.7872 |\n",
      "val: {'recall': 0.982988, 'recall_grapheme': 0.973745, 'recall_vowel': 0.991746, 'recall_consonant': 0.992716, 'acc_grapheme': 0.974655, 'acc_vowel': 0.992794, 'acc_consonant': 0.991601, 'loss_grapheme': 0.113695, 'loss_vowel': 0.057465, 'loss_consonant': 0.048711}\n",
      "   93 | 0.000003 | 094208/160596 | 4.2252 | 1.7842 |\n",
      "val: {'recall': 0.982794, 'recall_grapheme': 0.973115, 'recall_vowel': 0.991969, 'recall_consonant': 0.992976, 'acc_grapheme': 0.974555, 'acc_vowel': 0.992918, 'acc_consonant': 0.991651, 'loss_grapheme': 0.117551, 'loss_vowel': 0.059758, 'loss_consonant': 0.051133}\n",
      "   94 | 0.000002 | 139264/160596 | 2.9289 | 1.4996 |\n",
      "val: {'recall': 0.983061, 'recall_grapheme': 0.973807, 'recall_vowel': 0.9918, 'recall_consonant': 0.992829, 'acc_grapheme': 0.974779, 'acc_vowel': 0.992794, 'acc_consonant': 0.992049, 'loss_grapheme': 0.111355, 'loss_vowel': 0.052456, 'loss_consonant': 0.045004}\n",
      "   96 | 0.000001 | 024576/160596 | 0.0057 | 1.3800 |\n",
      "val: {'recall': 0.983174, 'recall_grapheme': 0.974427, 'recall_vowel': 0.991551, 'recall_consonant': 0.992291, 'acc_grapheme': 0.975326, 'acc_vowel': 0.992893, 'acc_consonant': 0.991999, 'loss_grapheme': 0.100873, 'loss_vowel': 0.039731, 'loss_consonant': 0.035568}\n",
      "   97 | 0.000001 | 069632/160596 | 2.1655 | 1.6397 |\n",
      "val: {'recall': 0.982716, 'recall_grapheme': 0.973151, 'recall_vowel': 0.99181, 'recall_consonant': 0.99275, 'acc_grapheme': 0.974406, 'acc_vowel': 0.992893, 'acc_consonant': 0.991477, 'loss_grapheme': 0.133313, 'loss_vowel': 0.077147, 'loss_consonant': 0.061016}\n",
      "   98 | 0.000001 | 114688/160596 | 0.0077 | 1.6200 |\n",
      "val: {'recall': 0.983277, 'recall_grapheme': 0.974433, 'recall_vowel': 0.991654, 'recall_consonant': 0.992588, 'acc_grapheme': 0.975176, 'acc_vowel': 0.992918, 'acc_consonant': 0.991949, 'loss_grapheme': 0.100709, 'loss_vowel': 0.038708, 'loss_consonant': 0.035292}\n",
      "   99 | 0.000002 | 159744/160596 | 4.3203 | 1.5473 |\n",
      "val: {'recall': 0.982798, 'recall_grapheme': 0.973619, 'recall_vowel': 0.991279, 'recall_consonant': 0.992676, 'acc_grapheme': 0.974853, 'acc_vowel': 0.992695, 'acc_consonant': 0.991899, 'loss_grapheme': 0.103792, 'loss_vowel': 0.043166, 'loss_consonant': 0.038354}\n",
      "  101 | 0.000003 | 045056/160596 | 0.0050 | 1.7496 |\n",
      "val: {'recall': 0.983033, 'recall_grapheme': 0.973762, 'recall_vowel': 0.991924, 'recall_consonant': 0.992683, 'acc_grapheme': 0.974953, 'acc_vowel': 0.992968, 'acc_consonant': 0.9918, 'loss_grapheme': 0.107176, 'loss_vowel': 0.047796, 'loss_consonant': 0.042066}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 | 0.000004 | 090112/160596 | 0.0035 | 2.1664 |\n",
      "val: {'recall': 0.982769, 'recall_grapheme': 0.973493, 'recall_vowel': 0.991624, 'recall_consonant': 0.992466, 'acc_grapheme': 0.974506, 'acc_vowel': 0.992794, 'acc_consonant': 0.991651, 'loss_grapheme': 0.121342, 'loss_vowel': 0.065156, 'loss_consonant': 0.054019}\n",
      "  103 | 0.000006 | 135168/160596 | 1.1722 | 1.5963 |\n",
      "val: {'recall': 0.982968, 'recall_grapheme': 0.973931, 'recall_vowel': 0.991478, 'recall_consonant': 0.99253, 'acc_grapheme': 0.974829, 'acc_vowel': 0.992744, 'acc_consonant': 0.991502, 'loss_grapheme': 0.141735, 'loss_vowel': 0.082014, 'loss_consonant': 0.064545}\n",
      "  105 | 0.000008 | 020480/160596 | 0.0108 | 0.5951 |\n",
      "val: {'recall': 0.983576, 'recall_grapheme': 0.975054, 'recall_vowel': 0.991996, 'recall_consonant': 0.992201, 'acc_grapheme': 0.975822, 'acc_vowel': 0.993067, 'acc_consonant': 0.992347, 'loss_grapheme': 0.099012, 'loss_vowel': 0.035992, 'loss_consonant': 0.033031}\n",
      "** saved\n",
      "  106 | 0.000010 | 065536/160596 | 0.0060 | 1.5092 |\n",
      "val: {'recall': 0.983091, 'recall_grapheme': 0.973838, 'recall_vowel': 0.991904, 'recall_consonant': 0.992784, 'acc_grapheme': 0.974804, 'acc_vowel': 0.993018, 'acc_consonant': 0.991601, 'loss_grapheme': 0.107208, 'loss_vowel': 0.046003, 'loss_consonant': 0.041576}\n",
      "  107 | 0.000011 | 110592/160596 | 0.0041 | 1.6065 |\n",
      "val: {'recall': 0.983217, 'recall_grapheme': 0.974285, 'recall_vowel': 0.991833, 'recall_consonant': 0.992464, 'acc_grapheme': 0.974754, 'acc_vowel': 0.992918, 'acc_consonant': 0.991576, 'loss_grapheme': 0.124448, 'loss_vowel': 0.067716, 'loss_consonant': 0.054758}\n",
      "  108 | 0.000013 | 155648/160596 | 0.7003 | 1.5796 |\n",
      "val: {'recall': 0.982548, 'recall_grapheme': 0.973005, 'recall_vowel': 0.991483, 'recall_consonant': 0.992699, 'acc_grapheme': 0.974009, 'acc_vowel': 0.992893, 'acc_consonant': 0.991502, 'loss_grapheme': 0.12992, 'loss_vowel': 0.073702, 'loss_consonant': 0.059505}\n",
      "  110 | 0.000015 | 040960/160596 | 0.8007 | 1.1732 |\n",
      "val: {'recall': 0.982826, 'recall_grapheme': 0.973707, 'recall_vowel': 0.991174, 'recall_consonant': 0.992717, 'acc_grapheme': 0.974754, 'acc_vowel': 0.99267, 'acc_consonant': 0.991452, 'loss_grapheme': 0.11551, 'loss_vowel': 0.056388, 'loss_consonant': 0.04744}\n",
      "  111 | 0.000017 | 086016/160596 | 0.0111 | 1.4604 |\n",
      "val: {'recall': 0.983371, 'recall_grapheme': 0.974296, 'recall_vowel': 0.991973, 'recall_consonant': 0.99292, 'acc_grapheme': 0.975375, 'acc_vowel': 0.992968, 'acc_consonant': 0.991949, 'loss_grapheme': 0.108192, 'loss_vowel': 0.050597, 'loss_consonant': 0.042524}\n",
      "  112 | 0.000018 | 131072/160596 | 0.0086 | 1.7208 |\n",
      "val: {'recall': 0.982953, 'recall_grapheme': 0.973773, 'recall_vowel': 0.991647, 'recall_consonant': 0.992618, 'acc_grapheme': 0.975027, 'acc_vowel': 0.992819, 'acc_consonant': 0.992049, 'loss_grapheme': 0.102587, 'loss_vowel': 0.04099, 'loss_consonant': 0.037092}\n",
      "  114 | 0.000019 | 016384/160596 | 3.7212 | 1.5917 |\n",
      "val: {'recall': 0.982547, 'recall_grapheme': 0.973231, 'recall_vowel': 0.991013, 'recall_consonant': 0.992711, 'acc_grapheme': 0.974928, 'acc_vowel': 0.992819, 'acc_consonant': 0.991402, 'loss_grapheme': 0.114557, 'loss_vowel': 0.056452, 'loss_consonant': 0.048672}\n",
      "  115 | 0.000020 | 061440/160596 | 0.0080 | 1.3143 |\n",
      "val: {'recall': 0.983591, 'recall_grapheme': 0.974838, 'recall_vowel': 0.992174, 'recall_consonant': 0.992515, 'acc_grapheme': 0.975649, 'acc_vowel': 0.993117, 'acc_consonant': 0.992148, 'loss_grapheme': 0.100854, 'loss_vowel': 0.037487, 'loss_consonant': 0.034735}\n",
      "** saved\n",
      "  116 | 0.000020 | 106496/160596 | 3.3133 | 1.7242 |\n",
      "val: {'recall': 0.983374, 'recall_grapheme': 0.974477, 'recall_vowel': 0.992001, 'recall_consonant': 0.992541, 'acc_grapheme': 0.97545, 'acc_vowel': 0.992993, 'acc_consonant': 0.992148, 'loss_grapheme': 0.107513, 'loss_vowel': 0.046899, 'loss_consonant': 0.041722}\n",
      "  117 | 0.000020 | 151552/160596 | 3.2888 | 1.4519 |\n",
      "val: {'recall': 0.982369, 'recall_grapheme': 0.972786, 'recall_vowel': 0.991434, 'recall_consonant': 0.99247, 'acc_grapheme': 0.974506, 'acc_vowel': 0.992869, 'acc_consonant': 0.991576, 'loss_grapheme': 0.127318, 'loss_vowel': 0.070017, 'loss_consonant': 0.056705}\n",
      "  119 | 0.000019 | 036864/160596 | 0.1937 | 1.7427 |\n",
      "val: {'recall': 0.982887, 'recall_grapheme': 0.973657, 'recall_vowel': 0.991663, 'recall_consonant': 0.992569, 'acc_grapheme': 0.975152, 'acc_vowel': 0.992819, 'acc_consonant': 0.99185, 'loss_grapheme': 0.109734, 'loss_vowel': 0.04997, 'loss_consonant': 0.043467}\n",
      "  120 | 0.000018 | 081920/160596 | 3.6464 | 1.5741 |\n",
      "val: {'recall': 0.982353, 'recall_grapheme': 0.972747, 'recall_vowel': 0.991206, 'recall_consonant': 0.992713, 'acc_grapheme': 0.97463, 'acc_vowel': 0.992744, 'acc_consonant': 0.991725, 'loss_grapheme': 0.108833, 'loss_vowel': 0.049546, 'loss_consonant': 0.042938}\n",
      "  121 | 0.000017 | 126976/160596 | 0.0075 | 1.3376 |\n",
      "val: {'recall': 0.983092, 'recall_grapheme': 0.973813, 'recall_vowel': 0.992276, 'recall_consonant': 0.992466, 'acc_grapheme': 0.975201, 'acc_vowel': 0.993092, 'acc_consonant': 0.991974, 'loss_grapheme': 0.114216, 'loss_vowel': 0.056765, 'loss_consonant': 0.047531}\n",
      "  123 | 0.000015 | 012288/160596 | 0.0049 | 1.7475 |\n",
      "val: {'recall': 0.982768, 'recall_grapheme': 0.973528, 'recall_vowel': 0.991468, 'recall_consonant': 0.992549, 'acc_grapheme': 0.975201, 'acc_vowel': 0.992918, 'acc_consonant': 0.99175, 'loss_grapheme': 0.10833, 'loss_vowel': 0.048479, 'loss_consonant': 0.042011}\n",
      "  124 | 0.000013 | 057344/160596 | 0.0027 | 1.0686 |\n",
      "val: {'recall': 0.983477, 'recall_grapheme': 0.974821, 'recall_vowel': 0.991675, 'recall_consonant': 0.992592, 'acc_grapheme': 0.975524, 'acc_vowel': 0.992968, 'acc_consonant': 0.992073, 'loss_grapheme': 0.100628, 'loss_vowel': 0.035682, 'loss_consonant': 0.033245}\n",
      "  125 | 0.000011 | 102400/160596 | 0.0045 | 1.6184 |\n",
      "val: {'recall': 0.983352, 'recall_grapheme': 0.974534, 'recall_vowel': 0.991937, 'recall_consonant': 0.992402, 'acc_grapheme': 0.97535, 'acc_vowel': 0.992968, 'acc_consonant': 0.992173, 'loss_grapheme': 0.10098, 'loss_vowel': 0.037267, 'loss_consonant': 0.033909}\n",
      "  126 | 0.000010 | 147456/160596 | 2.5226 | 1.3662 |\n",
      "val: {'recall': 0.983005, 'recall_grapheme': 0.973791, 'recall_vowel': 0.99189, 'recall_consonant': 0.992549, 'acc_grapheme': 0.974928, 'acc_vowel': 0.992993, 'acc_consonant': 0.99185, 'loss_grapheme': 0.132082, 'loss_vowel': 0.076227, 'loss_consonant': 0.05947}\n",
      "  128 | 0.000008 | 032768/160596 | 3.0853 | 1.6733 |\n",
      "val: {'recall': 0.983177, 'recall_grapheme': 0.97424, 'recall_vowel': 0.991495, 'recall_consonant': 0.992735, 'acc_grapheme': 0.975251, 'acc_vowel': 0.992918, 'acc_consonant': 0.991899, 'loss_grapheme': 0.111017, 'loss_vowel': 0.052696, 'loss_consonant': 0.044563}\n",
      "  129 | 0.000006 | 077824/160596 | 2.0313 | 1.4919 |\n",
      "val: {'recall': 0.983507, 'recall_grapheme': 0.974781, 'recall_vowel': 0.991728, 'recall_consonant': 0.99274, 'acc_grapheme': 0.975524, 'acc_vowel': 0.993042, 'acc_consonant': 0.992297, 'loss_grapheme': 0.101719, 'loss_vowel': 0.039538, 'loss_consonant': 0.035595}\n",
      "  130 | 0.000004 | 122880/160596 | 0.0039 | 1.7443 |\n",
      "val: {'recall': 0.983073, 'recall_grapheme': 0.974045, 'recall_vowel': 0.991549, 'recall_consonant': 0.992653, 'acc_grapheme': 0.975052, 'acc_vowel': 0.992869, 'acc_consonant': 0.992024, 'loss_grapheme': 0.119909, 'loss_vowel': 0.06287, 'loss_consonant': 0.05128}\n",
      "  132 | 0.000003 | 008192/160596 | 0.0048 | 1.1347 |\n",
      "val: {'recall': 0.983689, 'recall_grapheme': 0.974919, 'recall_vowel': 0.992245, 'recall_consonant': 0.992672, 'acc_grapheme': 0.975748, 'acc_vowel': 0.993117, 'acc_consonant': 0.992322, 'loss_grapheme': 0.100519, 'loss_vowel': 0.03905, 'loss_consonant': 0.035132}\n",
      "** saved\n",
      "  133 | 0.000002 | 053248/160596 | 2.9364 | 1.7754 |\n",
      "val: {'recall': 0.98312, 'recall_grapheme': 0.974248, 'recall_vowel': 0.991481, 'recall_consonant': 0.992505, 'acc_grapheme': 0.975176, 'acc_vowel': 0.992695, 'acc_consonant': 0.991576, 'loss_grapheme': 0.167422, 'loss_vowel': 0.103531, 'loss_consonant': 0.077511}\n",
      "  134 | 0.000001 | 098304/160596 | 0.1759 | 1.7960 |\n",
      "val: {'recall': 0.9834, 'recall_grapheme': 0.974532, 'recall_vowel': 0.991754, 'recall_consonant': 0.992783, 'acc_grapheme': 0.975773, 'acc_vowel': 0.992943, 'acc_consonant': 0.992073, 'loss_grapheme': 0.102376, 'loss_vowel': 0.041685, 'loss_consonant': 0.037641}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  135 | 0.000001 | 143360/160596 | 0.0073 | 1.7023 |\n",
      "val: {'recall': 0.983305, 'recall_grapheme': 0.974293, 'recall_vowel': 0.991832, 'recall_consonant': 0.992802, 'acc_grapheme': 0.975127, 'acc_vowel': 0.993018, 'acc_consonant': 0.992123, 'loss_grapheme': 0.117981, 'loss_vowel': 0.062206, 'loss_consonant': 0.05135}\n",
      "  137 | 0.000001 | 028672/160596 | 0.0050 | 1.5210 |\n",
      "val: {'recall': 0.982955, 'recall_grapheme': 0.973855, 'recall_vowel': 0.991566, 'recall_consonant': 0.992542, 'acc_grapheme': 0.975077, 'acc_vowel': 0.992918, 'acc_consonant': 0.991899, 'loss_grapheme': 0.110823, 'loss_vowel': 0.053087, 'loss_consonant': 0.045367}\n",
      "  138 | 0.000002 | 073728/160596 | 0.0030 | 1.5821 |\n",
      "val: {'recall': 0.983479, 'recall_grapheme': 0.974661, 'recall_vowel': 0.991806, 'recall_consonant': 0.992789, 'acc_grapheme': 0.975847, 'acc_vowel': 0.992893, 'acc_consonant': 0.992496, 'loss_grapheme': 0.09992, 'loss_vowel': 0.034296, 'loss_consonant': 0.032096}\n",
      "  139 | 0.000003 | 118784/160596 | 4.8307 | 1.4891 |\n",
      "val: {'recall': 0.983341, 'recall_grapheme': 0.974504, 'recall_vowel': 0.99158, 'recall_consonant': 0.992776, 'acc_grapheme': 0.975425, 'acc_vowel': 0.992968, 'acc_consonant': 0.992198, 'loss_grapheme': 0.100435, 'loss_vowel': 0.038006, 'loss_consonant': 0.034819}\n",
      "  141 | 0.000004 | 004096/160596 | 1.3133 | 0.3335 |\n",
      "val: {'recall': 0.983388, 'recall_grapheme': 0.974405, 'recall_vowel': 0.991726, 'recall_consonant': 0.993015, 'acc_grapheme': 0.975425, 'acc_vowel': 0.992893, 'acc_consonant': 0.992347, 'loss_grapheme': 0.100327, 'loss_vowel': 0.037383, 'loss_consonant': 0.034207}\n",
      "  142 | 0.000006 | 049152/160596 | 0.0036 | 1.9521 |\n",
      "val: {'recall': 0.98338, 'recall_grapheme': 0.974524, 'recall_vowel': 0.991577, 'recall_consonant': 0.992895, 'acc_grapheme': 0.975673, 'acc_vowel': 0.993067, 'acc_consonant': 0.991999, 'loss_grapheme': 0.112903, 'loss_vowel': 0.0542, 'loss_consonant': 0.046338}\n",
      "  143 | 0.000008 | 094208/160596 | 0.0076 | 1.7009 |\n",
      "val: {'recall': 0.983286, 'recall_grapheme': 0.974413, 'recall_vowel': 0.991668, 'recall_consonant': 0.992651, 'acc_grapheme': 0.97535, 'acc_vowel': 0.992943, 'acc_consonant': 0.992198, 'loss_grapheme': 0.100254, 'loss_vowel': 0.037156, 'loss_consonant': 0.034164}\n",
      "  144 | 0.000010 | 139264/160596 | 0.0074 | 1.1566 |\n",
      "val: {'recall': 0.983394, 'recall_grapheme': 0.974421, 'recall_vowel': 0.992071, 'recall_consonant': 0.992661, 'acc_grapheme': 0.975301, 'acc_vowel': 0.993018, 'acc_consonant': 0.991875, 'loss_grapheme': 0.113746, 'loss_vowel': 0.056318, 'loss_consonant': 0.047804}\n",
      "  146 | 0.000011 | 024576/160596 | 2.2168 | 1.7903 |\n",
      "val: {'recall': 0.983046, 'recall_grapheme': 0.973753, 'recall_vowel': 0.991972, 'recall_consonant': 0.992709, 'acc_grapheme': 0.974754, 'acc_vowel': 0.992943, 'acc_consonant': 0.991949, 'loss_grapheme': 0.131319, 'loss_vowel': 0.074544, 'loss_consonant': 0.0603}\n",
      "  147 | 0.000013 | 069632/160596 | 4.4046 | 1.0619 |\n",
      "val: {'recall': 0.983514, 'recall_grapheme': 0.974652, 'recall_vowel': 0.992021, 'recall_consonant': 0.992733, 'acc_grapheme': 0.9754, 'acc_vowel': 0.993067, 'acc_consonant': 0.992247, 'loss_grapheme': 0.102805, 'loss_vowel': 0.034442, 'loss_consonant': 0.032674}\n",
      "  148 | 0.000015 | 114688/160596 | 4.3464 | 1.8211 |\n",
      "val: {'recall': 0.983105, 'recall_grapheme': 0.974079, 'recall_vowel': 0.991822, 'recall_consonant': 0.992438, 'acc_grapheme': 0.974953, 'acc_vowel': 0.992595, 'acc_consonant': 0.991427, 'loss_grapheme': 0.139182, 'loss_vowel': 0.083785, 'loss_consonant': 0.066971}\n",
      "  149 | 0.000017 | 159744/160596 | 0.0027 | 1.2397 |\n",
      "val: {'recall': 0.983439, 'recall_grapheme': 0.974416, 'recall_vowel': 0.992119, 'recall_consonant': 0.992804, 'acc_grapheme': 0.9754, 'acc_vowel': 0.992968, 'acc_consonant': 0.992049, 'loss_grapheme': 0.099588, 'loss_vowel': 0.035564, 'loss_consonant': 0.033471}\n",
      "  151 | 0.000018 | 045056/160596 | 3.2155 | 1.5828 |\n",
      "val: {'recall': 0.983182, 'recall_grapheme': 0.973951, 'recall_vowel': 0.99227, 'recall_consonant': 0.992557, 'acc_grapheme': 0.975301, 'acc_vowel': 0.992968, 'acc_consonant': 0.99185, 'loss_grapheme': 0.110812, 'loss_vowel': 0.051515, 'loss_consonant': 0.044385}\n",
      "  152 | 0.000019 | 090112/160596 | 0.0051 | 1.3258 |\n",
      "val: {'recall': 0.98323, 'recall_grapheme': 0.974063, 'recall_vowel': 0.991884, 'recall_consonant': 0.99291, 'acc_grapheme': 0.975624, 'acc_vowel': 0.992844, 'acc_consonant': 0.992073, 'loss_grapheme': 0.10111, 'loss_vowel': 0.04002, 'loss_consonant': 0.036009}\n",
      "  153 | 0.000020 | 135168/160596 | 1.0139 | 1.5682 |\n",
      "val: {'recall': 0.982747, 'recall_grapheme': 0.973588, 'recall_vowel': 0.991345, 'recall_consonant': 0.992467, 'acc_grapheme': 0.975226, 'acc_vowel': 0.992968, 'acc_consonant': 0.991974, 'loss_grapheme': 0.104075, 'loss_vowel': 0.044353, 'loss_consonant': 0.039624}\n",
      "  155 | 0.000020 | 020480/160596 | 2.9066 | 1.9771 |\n",
      "val: {'recall': 0.983272, 'recall_grapheme': 0.974732, 'recall_vowel': 0.991053, 'recall_consonant': 0.992571, 'acc_grapheme': 0.975897, 'acc_vowel': 0.992719, 'acc_consonant': 0.991775, 'loss_grapheme': 0.12592, 'loss_vowel': 0.070839, 'loss_consonant': 0.057324}\n",
      "  156 | 0.000020 | 065536/160596 | 0.6341 | 1.3848 |\n",
      "val: {'recall': 0.983135, 'recall_grapheme': 0.97435, 'recall_vowel': 0.991908, 'recall_consonant': 0.991931, 'acc_grapheme': 0.975947, 'acc_vowel': 0.992819, 'acc_consonant': 0.992222, 'loss_grapheme': 0.100592, 'loss_vowel': 0.038607, 'loss_consonant': 0.035005}\n",
      "  157 | 0.000019 | 110592/160596 | 0.0086 | 1.5051 |\n",
      "val: {'recall': 0.983159, 'recall_grapheme': 0.97429, 'recall_vowel': 0.99136, 'recall_consonant': 0.992696, 'acc_grapheme': 0.975822, 'acc_vowel': 0.992769, 'acc_consonant': 0.991999, 'loss_grapheme': 0.113837, 'loss_vowel': 0.057315, 'loss_consonant': 0.047021}\n",
      "  158 | 0.000018 | 155648/160596 | 0.0036 | 1.4706 |\n",
      "val: {'recall': 0.983075, 'recall_grapheme': 0.973809, 'recall_vowel': 0.992003, 'recall_consonant': 0.992681, 'acc_grapheme': 0.975698, 'acc_vowel': 0.992819, 'acc_consonant': 0.992073, 'loss_grapheme': 0.106843, 'loss_vowel': 0.04794, 'loss_consonant': 0.042063}\n",
      "  160 | 0.000017 | 040960/160596 | 2.2879 | 1.1732 |\n",
      "val: {'recall': 0.98282, 'recall_grapheme': 0.973337, 'recall_vowel': 0.991555, 'recall_consonant': 0.993049, 'acc_grapheme': 0.975723, 'acc_vowel': 0.992719, 'acc_consonant': 0.992198, 'loss_grapheme': 0.111407, 'loss_vowel': 0.053759, 'loss_consonant': 0.045194}\n",
      "  161 | 0.000015 | 086016/160596 | 3.0601 | 1.4115 |\n",
      "val: {'recall': 0.983449, 'recall_grapheme': 0.974553, 'recall_vowel': 0.991911, 'recall_consonant': 0.992779, 'acc_grapheme': 0.975897, 'acc_vowel': 0.993092, 'acc_consonant': 0.991999, 'loss_grapheme': 0.106598, 'loss_vowel': 0.046501, 'loss_consonant': 0.040619}\n",
      "  162 | 0.000013 | 131072/160596 | 0.0045 | 1.1900 |\n",
      "val: {'recall': 0.983459, 'recall_grapheme': 0.974451, 'recall_vowel': 0.992018, 'recall_consonant': 0.992914, 'acc_grapheme': 0.976096, 'acc_vowel': 0.993067, 'acc_consonant': 0.992247, 'loss_grapheme': 0.100386, 'loss_vowel': 0.039238, 'loss_consonant': 0.035862}\n",
      "  164 | 0.000011 | 016384/160596 | 0.0061 | 1.2363 |\n",
      "val: {'recall': 0.983745, 'recall_grapheme': 0.974981, 'recall_vowel': 0.992261, 'recall_consonant': 0.992757, 'acc_grapheme': 0.976046, 'acc_vowel': 0.993167, 'acc_consonant': 0.992297, 'loss_grapheme': 0.103041, 'loss_vowel': 0.042857, 'loss_consonant': 0.038426}\n",
      "** saved\n",
      "  165 | 0.000010 | 061440/160596 | 0.0034 | 1.8495 |\n",
      "val: {'recall': 0.983669, 'recall_grapheme': 0.9748, 'recall_vowel': 0.992091, 'recall_consonant': 0.992986, 'acc_grapheme': 0.976096, 'acc_vowel': 0.993018, 'acc_consonant': 0.992421, 'loss_grapheme': 0.099934, 'loss_vowel': 0.038737, 'loss_consonant': 0.035355}\n",
      "  166 | 0.000008 | 106496/160596 | 2.3447 | 1.5952 |\n",
      "val: {'recall': 0.98369, 'recall_grapheme': 0.974889, 'recall_vowel': 0.991823, 'recall_consonant': 0.993158, 'acc_grapheme': 0.975947, 'acc_vowel': 0.993042, 'acc_consonant': 0.992347, 'loss_grapheme': 0.102992, 'loss_vowel': 0.043974, 'loss_consonant': 0.039216}\n",
      "  167 | 0.000006 | 151552/160596 | 3.3839 | 1.3837 |\n",
      "val: {'recall': 0.982514, 'recall_grapheme': 0.972957, 'recall_vowel': 0.99158, 'recall_consonant': 0.992561, 'acc_grapheme': 0.97535, 'acc_vowel': 0.992744, 'acc_consonant': 0.991999, 'loss_grapheme': 0.11455, 'loss_vowel': 0.05833, 'loss_consonant': 0.049338}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  169 | 0.000004 | 036864/160596 | 0.0049 | 1.6461 |\n",
      "val: {'recall': 0.983587, 'recall_grapheme': 0.974959, 'recall_vowel': 0.991551, 'recall_consonant': 0.99288, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992943, 'acc_consonant': 0.992297, 'loss_grapheme': 0.106689, 'loss_vowel': 0.048555, 'loss_consonant': 0.042065}\n",
      "  170 | 0.000003 | 081920/160596 | 3.4770 | 1.1386 |\n",
      "val: {'recall': 0.983269, 'recall_grapheme': 0.974252, 'recall_vowel': 0.991643, 'recall_consonant': 0.992929, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992943, 'acc_consonant': 0.992198, 'loss_grapheme': 0.100378, 'loss_vowel': 0.03884, 'loss_consonant': 0.035963}\n",
      "  171 | 0.000002 | 126976/160596 | 0.0022 | 1.4488 |\n",
      "val: {'recall': 0.983334, 'recall_grapheme': 0.974387, 'recall_vowel': 0.991797, 'recall_consonant': 0.992764, 'acc_grapheme': 0.975872, 'acc_vowel': 0.992918, 'acc_consonant': 0.992272, 'loss_grapheme': 0.103192, 'loss_vowel': 0.044723, 'loss_consonant': 0.039454}\n",
      "  173 | 0.000001 | 012288/160596 | 4.3750 | 1.6492 |\n",
      "val: {'recall': 0.983094, 'recall_grapheme': 0.973977, 'recall_vowel': 0.991705, 'recall_consonant': 0.992718, 'acc_grapheme': 0.975723, 'acc_vowel': 0.992943, 'acc_consonant': 0.992098, 'loss_grapheme': 0.110841, 'loss_vowel': 0.055002, 'loss_consonant': 0.046564}\n",
      "  173 | 0.000001 | 080896/160596 | 3.4076 | 1.5711 |"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
