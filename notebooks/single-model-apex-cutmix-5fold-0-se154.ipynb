{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install opencv-python\\n!pip install fastparquet\\n!pip install pyarrow\\n!pip install snappy\\n!conda install python-snappy -y\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install opencv-python\n",
    "!pip install fastparquet\n",
    "!pip install pyarrow\n",
    "!pip install snappy\n",
    "!conda install python-snappy -y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengaliai-cv19.zip\t   test_image_data_3.parquet\r\n",
      "class_map.csv\t\t   train.csv\r\n",
      "sample_submission.csv\t   train_image_data_0.parquet\r\n",
      "test.csv\t\t   train_image_data_1.parquet\r\n",
      "test_image_data_0.parquet  train_image_data_2.parquet\r\n",
      "test_image_data_1.parquet  train_image_data_3.parquet\r\n",
      "test_image_data_2.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       test_image_data_3.parquet.zip\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     4      8     12 ... 200813 200835 200837]\n"
     ]
    }
   ],
   "source": [
    "ifold = 1\n",
    "kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "    if i == ifold:\n",
    "        print(val_idx)\n",
    "        val_sub = train_df.iloc[val_idx]\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40205, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200840, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.image_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72     5736\n",
       "64     5596\n",
       "13     5420\n",
       "107    5321\n",
       "23     5149\n",
       "       ... \n",
       "130     144\n",
       "158     143\n",
       "102     141\n",
       "33      136\n",
       "73      130\n",
       "Name: grapheme_root, Length: 168, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.grapheme_root.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>32322</th>\n",
       "      <th>32323</th>\n",
       "      <th>32324</th>\n",
       "      <th>32325</th>\n",
       "      <th>32326</th>\n",
       "      <th>32327</th>\n",
       "      <th>32328</th>\n",
       "      <th>32329</th>\n",
       "      <th>32330</th>\n",
       "      <th>32331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>251</td>\n",
       "      <td>244</td>\n",
       "      <td>238</td>\n",
       "      <td>245</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>248</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id    0    1    2    3    4    5    6    7    8  ...  32322  32323  \\\n",
       "0  Train_0  254  253  252  253  251  252  253  251  251  ...    253    253   \n",
       "1  Train_1  251  244  238  245  248  246  246  247  251  ...    255    255   \n",
       "2  Train_2  251  250  249  250  249  245  247  252  252  ...    254    253   \n",
       "3  Train_3  247  247  249  253  253  252  251  251  250  ...    254    254   \n",
       "4  Train_4  249  248  246  246  248  244  242  242  229  ...    255    255   \n",
       "\n",
       "   32324  32325  32326  32327  32328  32329  32330  32331  \n",
       "0    253    253    253    253    253    253    253    251  \n",
       "1    255    255    255    255    255    255    255    254  \n",
       "2    252    252    253    253    253    253    251    249  \n",
       "3    254    254    254    253    253    252    251    252  \n",
       "4    255    255    255    255    255    255    255    255  \n",
       "\n",
       "[5 rows x 32333 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50210, 32333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32322</th>\n",
       "      <th>32323</th>\n",
       "      <th>32324</th>\n",
       "      <th>32325</th>\n",
       "      <th>32326</th>\n",
       "      <th>32327</th>\n",
       "      <th>32328</th>\n",
       "      <th>32329</th>\n",
       "      <th>32330</th>\n",
       "      <th>32331</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Train_0</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_1</td>\n",
       "      <td>251</td>\n",
       "      <td>244</td>\n",
       "      <td>238</td>\n",
       "      <td>245</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_2</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>249</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_3</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train_4</td>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>248</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>229</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9  ...  32322  32323  \\\n",
       "image_id                                                    ...                 \n",
       "Train_0   254  253  252  253  251  252  253  251  251  253  ...    253    253   \n",
       "Train_1   251  244  238  245  248  246  246  247  251  252  ...    255    255   \n",
       "Train_2   251  250  249  250  249  245  247  252  252  252  ...    254    253   \n",
       "Train_3   247  247  249  253  253  252  251  251  250  250  ...    254    254   \n",
       "Train_4   249  248  246  246  248  244  242  242  229  225  ...    255    255   \n",
       "\n",
       "          32324  32325  32326  32327  32328  32329  32330  32331  \n",
       "image_id                                                          \n",
       "Train_0     253    253    253    253    253    253    253    251  \n",
       "Train_1     255    255    255    255    255    255    255    254  \n",
       "Train_2     252    252    253    253    253    253    251    249  \n",
       "Train_3     254    254    254    253    253    252    251    252  \n",
       "Train_4     255    255    255    255    255    255    255    255  \n",
       "\n",
       "[5 rows x 32332 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Train_0', 'Train_1', 'Train_2', 'Train_3', 'Train_4', 'Train_5',\n",
       "       'Train_6', 'Train_7', 'Train_8', 'Train_9',\n",
       "       ...\n",
       "       'Train_50200', 'Train_50201', 'Train_50202', 'Train_50203',\n",
       "       'Train_50204', 'Train_50205', 'Train_50206', 'Train_50207',\n",
       "       'Train_50208', 'Train_50209'],\n",
       "      dtype='object', name='image_id', length=50210)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb36d4a4f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = 255 - df.iloc[10, 1:].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img2 = cv2.resize(img, (256, 128))\n",
    "#plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = get_train_augs(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-32ad6cb7aa56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=augs(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor img, y in train_loader:\\n    print(img.size(), y.size())\\n    print(y)\\n    #print(img)\\n    #plt.imshow(img.squeeze()[0].numpy())\\n    break\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for img, y in train_loader:\n",
    "    print(img.size(), y.size())\n",
    "    print(y)\n",
    "    #print(img)\n",
    "    #plt.imshow(img.squeeze()[0].numpy())\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048, 5, 8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.backbone = pretrainedmodels.__dict__[backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nargs = Namespace()\\nargs.backbone = 'se_resnext50_32x4d'\\nargs.ckp_name = 'best_model.pth'\\nargs.predict = False\\n\\nbnet = create_model(args)[0].cuda()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "\n",
    "bnet = create_model(args)[0].cuda()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 137, 236])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 186])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum().item()\n",
    "        res.append(correct_k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(batch_size=32, val_batch_size=128, dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(180756, 5) (20084, 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/best_model.pth, exist: False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7773158355823127"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand(1)\n",
    "            if args.beta > 0 and r < args.cutmix_prob:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'senet154'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 256\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160596, 5) (40244, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/senet154/best_model.pth, exist: True\n",
      "loading ./models/senet154/best_model.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.948801, 'recall_grapheme': 0.924691, 'recall_vowel': 0.975039, 'recall_consonant': 0.970783, 'acc_grapheme': 0.924535, 'acc_vowel': 0.981389, 'acc_consonant': 0.974108, 'loss_grapheme': 0.314899, 'loss_vowel': 0.119143, 'loss_consonant': 0.112746}\n",
      "    0 | 0.000020 | 051200/160596 | 5.7880 | 2.2411 |\n",
      "val: {'recall': 0.962973, 'recall_grapheme': 0.943947, 'recall_vowel': 0.981796, 'recall_consonant': 0.9822, 'acc_grapheme': 0.94352, 'acc_vowel': 0.984867, 'acc_consonant': 0.983327, 'loss_grapheme': 0.299794, 'loss_vowel': 0.135286, 'loss_consonant': 0.112861}\n",
      "** saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.000020 | 102400/160596 | 2.7638 | 2.3215 |\n",
      "val: {'recall': 0.963744, 'recall_grapheme': 0.94497, 'recall_vowel': 0.982378, 'recall_consonant': 0.982659, 'acc_grapheme': 0.94593, 'acc_vowel': 0.985116, 'acc_consonant': 0.98114, 'loss_grapheme': 0.35942, 'loss_vowel': 0.198909, 'loss_consonant': 0.159413}\n",
      "** saved\n",
      "    0 | 0.000019 | 153600/160596 | 0.2106 | 2.1888 |\n",
      "val: {'recall': 0.966388, 'recall_grapheme': 0.949662, 'recall_vowel': 0.98376, 'recall_consonant': 0.982466, 'acc_grapheme': 0.949433, 'acc_vowel': 0.987054, 'acc_consonant': 0.984644, 'loss_grapheme': 0.19351, 'loss_vowel': 0.06497, 'loss_consonant': 0.064292}\n",
      "** saved\n",
      "    1 | 0.000017 | 044288/160596 | 0.1534 | 2.0030 |\n",
      "val: {'recall': 0.96593, 'recall_grapheme': 0.948157, 'recall_vowel': 0.985449, 'recall_consonant': 0.981958, 'acc_grapheme': 0.949235, 'acc_vowel': 0.987153, 'acc_consonant': 0.985389, 'loss_grapheme': 0.200116, 'loss_vowel': 0.083015, 'loss_consonant': 0.073146}\n",
      "    1 | 0.000015 | 095488/160596 | 4.8267 | 2.1991 |\n",
      "val: {'recall': 0.966198, 'recall_grapheme': 0.948759, 'recall_vowel': 0.984549, 'recall_consonant': 0.982724, 'acc_grapheme': 0.951049, 'acc_vowel': 0.987576, 'acc_consonant': 0.986433, 'loss_grapheme': 0.201331, 'loss_vowel': 0.081437, 'loss_consonant': 0.072403}\n",
      "    1 | 0.000013 | 146688/160596 | 0.2098 | 2.2192 |\n",
      "val: {'recall': 0.965922, 'recall_grapheme': 0.948095, 'recall_vowel': 0.98418, 'recall_consonant': 0.983319, 'acc_grapheme': 0.951073, 'acc_vowel': 0.987278, 'acc_consonant': 0.985141, 'loss_grapheme': 0.246302, 'loss_vowel': 0.123964, 'loss_consonant': 0.104794}\n",
      "    2 | 0.000011 | 037376/160596 | 0.1764 | 2.0182 |\n",
      "val: {'recall': 0.968861, 'recall_grapheme': 0.951502, 'recall_vowel': 0.986414, 'recall_consonant': 0.986027, 'acc_grapheme': 0.951869, 'acc_vowel': 0.987874, 'acc_consonant': 0.986309, 'loss_grapheme': 0.233853, 'loss_vowel': 0.124597, 'loss_consonant': 0.092813}\n",
      "** saved\n",
      "    2 | 0.000008 | 088576/160596 | 0.1577 | 1.8432 |\n",
      "val: {'recall': 0.968335, 'recall_grapheme': 0.951463, 'recall_vowel': 0.985405, 'recall_consonant': 0.98501, 'acc_grapheme': 0.953856, 'acc_vowel': 0.987799, 'acc_consonant': 0.98693, 'loss_grapheme': 0.174524, 'loss_vowel': 0.061184, 'loss_consonant': 0.058118}\n",
      "    2 | 0.000006 | 139776/160596 | 4.8958 | 1.9619 |\n",
      "val: {'recall': 0.969777, 'recall_grapheme': 0.952888, 'recall_vowel': 0.985169, 'recall_consonant': 0.988164, 'acc_grapheme': 0.953981, 'acc_vowel': 0.988098, 'acc_consonant': 0.986184, 'loss_grapheme': 0.235897, 'loss_vowel': 0.120648, 'loss_consonant': 0.099673}\n",
      "** saved\n",
      "    3 | 0.000004 | 030464/160596 | 4.8960 | 1.7262 |\n",
      "val: {'recall': 0.970334, 'recall_grapheme': 0.953395, 'recall_vowel': 0.986358, 'recall_consonant': 0.988187, 'acc_grapheme': 0.9549, 'acc_vowel': 0.988793, 'acc_consonant': 0.987004, 'loss_grapheme': 0.188363, 'loss_vowel': 0.081725, 'loss_consonant': 0.0735}\n",
      "** saved\n",
      "    3 | 0.000002 | 081664/160596 | 1.7218 | 1.8505 |\n",
      "val: {'recall': 0.970422, 'recall_grapheme': 0.954192, 'recall_vowel': 0.986132, 'recall_consonant': 0.987175, 'acc_grapheme': 0.954776, 'acc_vowel': 0.988247, 'acc_consonant': 0.986632, 'loss_grapheme': 0.240163, 'loss_vowel': 0.136648, 'loss_consonant': 0.1083}\n",
      "** saved\n",
      "    3 | 0.000001 | 132864/160596 | 4.1799 | 1.9904 |\n",
      "val: {'recall': 0.969938, 'recall_grapheme': 0.953412, 'recall_vowel': 0.985628, 'recall_consonant': 0.987299, 'acc_grapheme': 0.954577, 'acc_vowel': 0.988346, 'acc_consonant': 0.986781, 'loss_grapheme': 0.211644, 'loss_vowel': 0.095417, 'loss_consonant': 0.082252}\n",
      "    4 | 0.000001 | 023552/160596 | 0.1885 | 2.4178 |\n",
      "val: {'recall': 0.96955, 'recall_grapheme': 0.952872, 'recall_vowel': 0.985428, 'recall_consonant': 0.98703, 'acc_grapheme': 0.954204, 'acc_vowel': 0.988023, 'acc_consonant': 0.986507, 'loss_grapheme': 0.266241, 'loss_vowel': 0.150166, 'loss_consonant': 0.114552}\n",
      "    4 | 0.000001 | 074752/160596 | 0.1970 | 2.0854 |\n",
      "val: {'recall': 0.970379, 'recall_grapheme': 0.954394, 'recall_vowel': 0.986127, 'recall_consonant': 0.986602, 'acc_grapheme': 0.95577, 'acc_vowel': 0.988967, 'acc_consonant': 0.986855, 'loss_grapheme': 0.168828, 'loss_vowel': 0.062888, 'loss_consonant': 0.059243}\n",
      "    4 | 0.000002 | 125952/160596 | 5.5360 | 2.0188 |\n",
      "val: {'recall': 0.969974, 'recall_grapheme': 0.953226, 'recall_vowel': 0.985609, 'recall_consonant': 0.987836, 'acc_grapheme': 0.9549, 'acc_vowel': 0.987998, 'acc_consonant': 0.986085, 'loss_grapheme': 0.261897, 'loss_vowel': 0.15687, 'loss_consonant': 0.116705}\n",
      "    5 | 0.000004 | 016640/160596 | 4.4214 | 2.1928 |\n",
      "val: {'recall': 0.970265, 'recall_grapheme': 0.954361, 'recall_vowel': 0.985075, 'recall_consonant': 0.987261, 'acc_grapheme': 0.955447, 'acc_vowel': 0.988247, 'acc_consonant': 0.987129, 'loss_grapheme': 0.196263, 'loss_vowel': 0.088205, 'loss_consonant': 0.077515}\n",
      "    5 | 0.000006 | 067840/160596 | 5.0807 | 2.0846 |\n",
      "val: {'recall': 0.969453, 'recall_grapheme': 0.953149, 'recall_vowel': 0.985857, 'recall_consonant': 0.985657, 'acc_grapheme': 0.955521, 'acc_vowel': 0.988744, 'acc_consonant': 0.986805, 'loss_grapheme': 0.20327, 'loss_vowel': 0.09566, 'loss_consonant': 0.082235}\n",
      "    5 | 0.000008 | 119040/160596 | 0.1562 | 2.1222 |\n",
      "val: {'recall': 0.969943, 'recall_grapheme': 0.952896, 'recall_vowel': 0.986468, 'recall_consonant': 0.987511, 'acc_grapheme': 0.955422, 'acc_vowel': 0.988744, 'acc_consonant': 0.986557, 'loss_grapheme': 0.181612, 'loss_vowel': 0.077238, 'loss_consonant': 0.070626}\n",
      "    6 | 0.000010 | 009728/160596 | 0.3113 | 2.0186 |\n",
      "val: {'recall': 0.969113, 'recall_grapheme': 0.951506, 'recall_vowel': 0.986777, 'recall_consonant': 0.986664, 'acc_grapheme': 0.955099, 'acc_vowel': 0.988744, 'acc_consonant': 0.986507, 'loss_grapheme': 0.19452, 'loss_vowel': 0.085617, 'loss_consonant': 0.076344}\n",
      "    6 | 0.000013 | 060928/160596 | 0.1436 | 2.2592 |\n",
      "val: {'recall': 0.968388, 'recall_grapheme': 0.953219, 'recall_vowel': 0.984854, 'recall_consonant': 0.982259, 'acc_grapheme': 0.954552, 'acc_vowel': 0.988023, 'acc_consonant': 0.987327, 'loss_grapheme': 0.19074, 'loss_vowel': 0.084523, 'loss_consonant': 0.073453}\n",
      "    6 | 0.000015 | 112128/160596 | 4.7551 | 2.1902 |\n",
      "val: {'recall': 0.969613, 'recall_grapheme': 0.953385, 'recall_vowel': 0.986482, 'recall_consonant': 0.985199, 'acc_grapheme': 0.955869, 'acc_vowel': 0.987849, 'acc_consonant': 0.987129, 'loss_grapheme': 0.184618, 'loss_vowel': 0.079139, 'loss_consonant': 0.071977}\n",
      "    7 | 0.000017 | 002816/160596 | 0.1479 | 1.2338 |\n",
      "val: {'recall': 0.969429, 'recall_grapheme': 0.952487, 'recall_vowel': 0.985394, 'recall_consonant': 0.98735, 'acc_grapheme': 0.955173, 'acc_vowel': 0.988843, 'acc_consonant': 0.987402, 'loss_grapheme': 0.172267, 'loss_vowel': 0.063479, 'loss_consonant': 0.061454}\n",
      "    7 | 0.000019 | 054016/160596 | 0.1087 | 1.8405 |\n",
      "val: {'recall': 0.968983, 'recall_grapheme': 0.951927, 'recall_vowel': 0.986368, 'recall_consonant': 0.985708, 'acc_grapheme': 0.954527, 'acc_vowel': 0.988818, 'acc_consonant': 0.987129, 'loss_grapheme': 0.182565, 'loss_vowel': 0.076348, 'loss_consonant': 0.064704}\n",
      "    7 | 0.000020 | 105216/160596 | 5.0019 | 2.0113 |\n",
      "val: {'recall': 0.968067, 'recall_grapheme': 0.952924, 'recall_vowel': 0.982945, 'recall_consonant': 0.983478, 'acc_grapheme': 0.954055, 'acc_vowel': 0.987675, 'acc_consonant': 0.986756, 'loss_grapheme': 0.224311, 'loss_vowel': 0.115593, 'loss_consonant': 0.089148}\n",
      "    7 | 0.000020 | 156416/160596 | 0.1152 | 2.0064 |\n",
      "val: {'recall': 0.968006, 'recall_grapheme': 0.951341, 'recall_vowel': 0.986605, 'recall_consonant': 0.982736, 'acc_grapheme': 0.955099, 'acc_vowel': 0.988769, 'acc_consonant': 0.987079, 'loss_grapheme': 0.178344, 'loss_vowel': 0.069343, 'loss_consonant': 0.06392}\n",
      "    8 | 0.000020 | 047104/160596 | 3.6020 | 1.8523 |\n",
      "val: {'recall': 0.969774, 'recall_grapheme': 0.953366, 'recall_vowel': 0.985011, 'recall_consonant': 0.987353, 'acc_grapheme': 0.956764, 'acc_vowel': 0.988247, 'acc_consonant': 0.987104, 'loss_grapheme': 0.220123, 'loss_vowel': 0.108464, 'loss_consonant': 0.080504}\n",
      "    8 | 0.000019 | 098304/160596 | 0.1405 | 1.8774 |\n",
      "val: {'recall': 0.968992, 'recall_grapheme': 0.952493, 'recall_vowel': 0.985768, 'recall_consonant': 0.985216, 'acc_grapheme': 0.956391, 'acc_vowel': 0.988694, 'acc_consonant': 0.987004, 'loss_grapheme': 0.186951, 'loss_vowel': 0.09128, 'loss_consonant': 0.078302}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 | 0.000017 | 149504/160596 | 5.0557 | 1.9309 |\n",
      "val: {'recall': 0.969815, 'recall_grapheme': 0.951966, 'recall_vowel': 0.98662, 'recall_consonant': 0.98871, 'acc_grapheme': 0.957758, 'acc_vowel': 0.989067, 'acc_consonant': 0.987377, 'loss_grapheme': 0.183392, 'loss_vowel': 0.081903, 'loss_consonant': 0.069431}\n",
      "    9 | 0.000015 | 040192/160596 | 0.1353 | 1.8449 |\n",
      "val: {'recall': 0.969378, 'recall_grapheme': 0.952156, 'recall_vowel': 0.986825, 'recall_consonant': 0.986378, 'acc_grapheme': 0.955993, 'acc_vowel': 0.988893, 'acc_consonant': 0.9877, 'loss_grapheme': 0.191096, 'loss_vowel': 0.098603, 'loss_consonant': 0.076308}\n",
      "    9 | 0.000013 | 091392/160596 | 0.0988 | 1.9897 |\n",
      "val: {'recall': 0.97073, 'recall_grapheme': 0.955714, 'recall_vowel': 0.986749, 'recall_consonant': 0.984745, 'acc_grapheme': 0.958578, 'acc_vowel': 0.98939, 'acc_consonant': 0.987725, 'loss_grapheme': 0.171256, 'loss_vowel': 0.070452, 'loss_consonant': 0.061318}\n",
      "** saved\n",
      "    9 | 0.000011 | 142592/160596 | 5.2956 | 1.9498 |\n",
      "val: {'recall': 0.9722, 'recall_grapheme': 0.957194, 'recall_vowel': 0.986203, 'recall_consonant': 0.988209, 'acc_grapheme': 0.959273, 'acc_vowel': 0.989116, 'acc_consonant': 0.988619, 'loss_grapheme': 0.16324, 'loss_vowel': 0.066038, 'loss_consonant': 0.057436}\n",
      "** saved\n",
      "   10 | 0.000008 | 033280/160596 | 0.1943 | 1.9020 |\n",
      "val: {'recall': 0.971998, 'recall_grapheme': 0.957103, 'recall_vowel': 0.987235, 'recall_consonant': 0.98655, 'acc_grapheme': 0.959895, 'acc_vowel': 0.989688, 'acc_consonant': 0.988197, 'loss_grapheme': 0.164756, 'loss_vowel': 0.065919, 'loss_consonant': 0.061535}\n",
      "   10 | 0.000006 | 084480/160596 | 4.6855 | 1.9226 |\n",
      "val: {'recall': 0.971946, 'recall_grapheme': 0.956911, 'recall_vowel': 0.986294, 'recall_consonant': 0.987667, 'acc_grapheme': 0.960093, 'acc_vowel': 0.989439, 'acc_consonant': 0.98852, 'loss_grapheme': 0.179655, 'loss_vowel': 0.090137, 'loss_consonant': 0.074449}\n",
      "   10 | 0.000004 | 135680/160596 | 2.5952 | 1.9638 |\n",
      "val: {'recall': 0.972454, 'recall_grapheme': 0.957554, 'recall_vowel': 0.987411, 'recall_consonant': 0.987298, 'acc_grapheme': 0.960416, 'acc_vowel': 0.989713, 'acc_consonant': 0.98847, 'loss_grapheme': 0.184312, 'loss_vowel': 0.097742, 'loss_consonant': 0.074347}\n",
      "** saved\n",
      "   11 | 0.000002 | 026368/160596 | 1.4136 | 1.6975 |\n",
      "val: {'recall': 0.971959, 'recall_grapheme': 0.955943, 'recall_vowel': 0.98708, 'recall_consonant': 0.98887, 'acc_grapheme': 0.960118, 'acc_vowel': 0.989265, 'acc_consonant': 0.988272, 'loss_grapheme': 0.211424, 'loss_vowel': 0.123733, 'loss_consonant': 0.093634}\n",
      "   11 | 0.000001 | 077568/160596 | 0.1408 | 2.1024 |\n",
      "val: {'recall': 0.972117, 'recall_grapheme': 0.956477, 'recall_vowel': 0.986905, 'recall_consonant': 0.988609, 'acc_grapheme': 0.960739, 'acc_vowel': 0.989713, 'acc_consonant': 0.987998, 'loss_grapheme': 0.195, 'loss_vowel': 0.100368, 'loss_consonant': 0.082166}\n",
      "   11 | 0.000001 | 128768/160596 | 3.6453 | 2.0135 |\n",
      "val: {'recall': 0.972048, 'recall_grapheme': 0.957319, 'recall_vowel': 0.98663, 'recall_consonant': 0.986925, 'acc_grapheme': 0.961087, 'acc_vowel': 0.989589, 'acc_consonant': 0.988619, 'loss_grapheme': 0.183373, 'loss_vowel': 0.093593, 'loss_consonant': 0.075961}\n",
      "   12 | 0.000001 | 019456/160596 | 0.1394 | 1.5776 |\n",
      "val: {'recall': 0.972745, 'recall_grapheme': 0.957149, 'recall_vowel': 0.987887, 'recall_consonant': 0.988793, 'acc_grapheme': 0.961038, 'acc_vowel': 0.989887, 'acc_consonant': 0.98857, 'loss_grapheme': 0.164337, 'loss_vowel': 0.069496, 'loss_consonant': 0.061679}\n",
      "** saved\n",
      "   12 | 0.000002 | 070656/160596 | 0.6061 | 1.8331 |\n",
      "val: {'recall': 0.971976, 'recall_grapheme': 0.955893, 'recall_vowel': 0.987158, 'recall_consonant': 0.988962, 'acc_grapheme': 0.960789, 'acc_vowel': 0.989986, 'acc_consonant': 0.988421, 'loss_grapheme': 0.18321, 'loss_vowel': 0.094179, 'loss_consonant': 0.076669}\n",
      "   12 | 0.000004 | 121856/160596 | 4.6741 | 1.7916 |\n",
      "val: {'recall': 0.971878, 'recall_grapheme': 0.956435, 'recall_vowel': 0.986987, 'recall_consonant': 0.987653, 'acc_grapheme': 0.961087, 'acc_vowel': 0.989539, 'acc_consonant': 0.988098, 'loss_grapheme': 0.170434, 'loss_vowel': 0.079486, 'loss_consonant': 0.067145}\n",
      "   13 | 0.000006 | 012544/160596 | 5.7430 | 2.3708 |\n",
      "val: {'recall': 0.972149, 'recall_grapheme': 0.956878, 'recall_vowel': 0.987527, 'recall_consonant': 0.987313, 'acc_grapheme': 0.96064, 'acc_vowel': 0.989564, 'acc_consonant': 0.988222, 'loss_grapheme': 0.201437, 'loss_vowel': 0.110337, 'loss_consonant': 0.0858}\n",
      "   13 | 0.000008 | 063744/160596 | 1.2180 | 2.1830 |\n",
      "val: {'recall': 0.972157, 'recall_grapheme': 0.957398, 'recall_vowel': 0.985884, 'recall_consonant': 0.987949, 'acc_grapheme': 0.960093, 'acc_vowel': 0.989439, 'acc_consonant': 0.988247, 'loss_grapheme': 0.178011, 'loss_vowel': 0.086053, 'loss_consonant': 0.069734}\n",
      "   13 | 0.000010 | 114944/160596 | 3.6197 | 2.0206 |\n",
      "val: {'recall': 0.97235, 'recall_grapheme': 0.957043, 'recall_vowel': 0.987435, 'recall_consonant': 0.987879, 'acc_grapheme': 0.959919, 'acc_vowel': 0.989365, 'acc_consonant': 0.987452, 'loss_grapheme': 0.212145, 'loss_vowel': 0.124355, 'loss_consonant': 0.096665}\n",
      "   14 | 0.000013 | 005632/160596 | 0.0875 | 1.8543 |\n",
      "val: {'recall': 0.971342, 'recall_grapheme': 0.956527, 'recall_vowel': 0.987076, 'recall_consonant': 0.985239, 'acc_grapheme': 0.959099, 'acc_vowel': 0.989464, 'acc_consonant': 0.988098, 'loss_grapheme': 0.174192, 'loss_vowel': 0.074005, 'loss_consonant': 0.062781}\n",
      "   14 | 0.000015 | 056832/160596 | 4.0727 | 1.9895 |\n",
      "val: {'recall': 0.968974, 'recall_grapheme': 0.953193, 'recall_vowel': 0.985802, 'recall_consonant': 0.983709, 'acc_grapheme': 0.957932, 'acc_vowel': 0.98857, 'acc_consonant': 0.988147, 'loss_grapheme': 0.229733, 'loss_vowel': 0.118744, 'loss_consonant': 0.091156}\n",
      "   14 | 0.000017 | 108032/160596 | 5.0637 | 1.9758 |\n",
      "val: {'recall': 0.969901, 'recall_grapheme': 0.95342, 'recall_vowel': 0.986746, 'recall_consonant': 0.986018, 'acc_grapheme': 0.958081, 'acc_vowel': 0.989166, 'acc_consonant': 0.987501, 'loss_grapheme': 0.190261, 'loss_vowel': 0.093113, 'loss_consonant': 0.079574}\n",
      "   14 | 0.000019 | 159232/160596 | 0.0717 | 1.8969 |\n",
      "val: {'recall': 0.970143, 'recall_grapheme': 0.952952, 'recall_vowel': 0.986927, 'recall_consonant': 0.987742, 'acc_grapheme': 0.959323, 'acc_vowel': 0.989688, 'acc_consonant': 0.987501, 'loss_grapheme': 0.160151, 'loss_vowel': 0.0633, 'loss_consonant': 0.059407}\n",
      "   15 | 0.000020 | 049920/160596 | 5.1967 | 1.8127 |\n",
      "val: {'recall': 0.970974, 'recall_grapheme': 0.954422, 'recall_vowel': 0.986439, 'recall_consonant': 0.988613, 'acc_grapheme': 0.958901, 'acc_vowel': 0.988918, 'acc_consonant': 0.987476, 'loss_grapheme': 0.194501, 'loss_vowel': 0.097722, 'loss_consonant': 0.076718}\n",
      "   15 | 0.000020 | 101120/160596 | 1.5282 | 1.7957 |\n",
      "val: {'recall': 0.971108, 'recall_grapheme': 0.954263, 'recall_vowel': 0.986138, 'recall_consonant': 0.989768, 'acc_grapheme': 0.957733, 'acc_vowel': 0.989688, 'acc_consonant': 0.987526, 'loss_grapheme': 0.188774, 'loss_vowel': 0.088, 'loss_consonant': 0.082926}\n",
      "   15 | 0.000020 | 152320/160596 | 5.1373 | 1.7485 |\n",
      "val: {'recall': 0.97032, 'recall_grapheme': 0.954784, 'recall_vowel': 0.985256, 'recall_consonant': 0.986458, 'acc_grapheme': 0.95895, 'acc_vowel': 0.988396, 'acc_consonant': 0.987899, 'loss_grapheme': 0.179155, 'loss_vowel': 0.080764, 'loss_consonant': 0.068051}\n",
      "   16 | 0.000019 | 043008/160596 | 0.0992 | 1.7133 |\n",
      "val: {'recall': 0.970175, 'recall_grapheme': 0.953067, 'recall_vowel': 0.986716, 'recall_consonant': 0.98785, 'acc_grapheme': 0.958752, 'acc_vowel': 0.989539, 'acc_consonant': 0.988421, 'loss_grapheme': 0.1887, 'loss_vowel': 0.09981, 'loss_consonant': 0.079529}\n",
      "   16 | 0.000017 | 094208/160596 | 5.1343 | 1.8238 |\n",
      "val: {'recall': 0.969535, 'recall_grapheme': 0.952699, 'recall_vowel': 0.98597, 'recall_consonant': 0.986773, 'acc_grapheme': 0.959298, 'acc_vowel': 0.989539, 'acc_consonant': 0.987949, 'loss_grapheme': 0.236182, 'loss_vowel': 0.142807, 'loss_consonant': 0.100961}\n",
      "   16 | 0.000015 | 145408/160596 | 1.3434 | 1.8138 |\n",
      "val: {'recall': 0.972253, 'recall_grapheme': 0.957253, 'recall_vowel': 0.987064, 'recall_consonant': 0.987443, 'acc_grapheme': 0.959994, 'acc_vowel': 0.989489, 'acc_consonant': 0.988048, 'loss_grapheme': 0.225716, 'loss_vowel': 0.110102, 'loss_consonant': 0.089461}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 0.000013 | 036096/160596 | 0.1266 | 1.6545 |\n",
      "val: {'recall': 0.972134, 'recall_grapheme': 0.956388, 'recall_vowel': 0.98695, 'recall_consonant': 0.988811, 'acc_grapheme': 0.961311, 'acc_vowel': 0.989986, 'acc_consonant': 0.988371, 'loss_grapheme': 0.16089, 'loss_vowel': 0.070179, 'loss_consonant': 0.062238}\n",
      "   17 | 0.000011 | 087296/160596 | 0.1002 | 1.7665 |\n",
      "val: {'recall': 0.973475, 'recall_grapheme': 0.959405, 'recall_vowel': 0.986484, 'recall_consonant': 0.988608, 'acc_grapheme': 0.96228, 'acc_vowel': 0.989713, 'acc_consonant': 0.988595, 'loss_grapheme': 0.149904, 'loss_vowel': 0.054957, 'loss_consonant': 0.051192}\n",
      "** saved\n",
      "   17 | 0.000008 | 138496/160596 | 3.0106 | 1.8719 |\n",
      "val: {'recall': 0.972185, 'recall_grapheme': 0.956005, 'recall_vowel': 0.987779, 'recall_consonant': 0.988951, 'acc_grapheme': 0.960889, 'acc_vowel': 0.989812, 'acc_consonant': 0.98857, 'loss_grapheme': 0.208941, 'loss_vowel': 0.131117, 'loss_consonant': 0.091479}\n",
      "   18 | 0.000006 | 029184/160596 | 0.0749 | 1.6858 |\n",
      "val: {'recall': 0.973373, 'recall_grapheme': 0.958302, 'recall_vowel': 0.986618, 'recall_consonant': 0.990269, 'acc_grapheme': 0.96146, 'acc_vowel': 0.989837, 'acc_consonant': 0.989067, 'loss_grapheme': 0.175248, 'loss_vowel': 0.088431, 'loss_consonant': 0.068824}\n",
      "   18 | 0.000004 | 080384/160596 | 0.1150 | 1.6816 |\n",
      "val: {'recall': 0.973381, 'recall_grapheme': 0.958054, 'recall_vowel': 0.987285, 'recall_consonant': 0.990132, 'acc_grapheme': 0.962578, 'acc_vowel': 0.990185, 'acc_consonant': 0.989067, 'loss_grapheme': 0.146914, 'loss_vowel': 0.055292, 'loss_consonant': 0.051078}\n",
      "   18 | 0.000002 | 131584/160596 | 0.0799 | 1.6925 |\n",
      "val: {'recall': 0.973452, 'recall_grapheme': 0.95821, 'recall_vowel': 0.987362, 'recall_consonant': 0.990025, 'acc_grapheme': 0.962578, 'acc_vowel': 0.99016, 'acc_consonant': 0.988992, 'loss_grapheme': 0.148841, 'loss_vowel': 0.06049, 'loss_consonant': 0.052825}\n",
      "   19 | 0.000001 | 022272/160596 | 0.0543 | 1.7203 |\n",
      "val: {'recall': 0.973323, 'recall_grapheme': 0.957667, 'recall_vowel': 0.987648, 'recall_consonant': 0.99031, 'acc_grapheme': 0.962206, 'acc_vowel': 0.990284, 'acc_consonant': 0.988967, 'loss_grapheme': 0.179705, 'loss_vowel': 0.097595, 'loss_consonant': 0.076531}\n",
      "   19 | 0.000001 | 073472/160596 | 3.6343 | 1.9264 |\n",
      "val: {'recall': 0.973382, 'recall_grapheme': 0.958479, 'recall_vowel': 0.986829, 'recall_consonant': 0.989739, 'acc_grapheme': 0.962479, 'acc_vowel': 0.989837, 'acc_consonant': 0.989116, 'loss_grapheme': 0.162044, 'loss_vowel': 0.076853, 'loss_consonant': 0.063616}\n",
      "   19 | 0.000001 | 124672/160596 | 0.0464 | 1.9011 |\n",
      "val: {'recall': 0.972805, 'recall_grapheme': 0.957539, 'recall_vowel': 0.987103, 'recall_consonant': 0.989037, 'acc_grapheme': 0.962181, 'acc_vowel': 0.989986, 'acc_consonant': 0.989042, 'loss_grapheme': 0.180816, 'loss_vowel': 0.103695, 'loss_consonant': 0.07988}\n",
      "   20 | 0.000002 | 015360/160596 | 0.0706 | 1.7100 |\n",
      "val: {'recall': 0.973281, 'recall_grapheme': 0.958195, 'recall_vowel': 0.987497, 'recall_consonant': 0.98924, 'acc_grapheme': 0.962727, 'acc_vowel': 0.990309, 'acc_consonant': 0.988992, 'loss_grapheme': 0.147979, 'loss_vowel': 0.05765, 'loss_consonant': 0.052926}\n",
      "   20 | 0.000004 | 066560/160596 | 4.2491 | 1.8166 |\n",
      "val: {'recall': 0.973396, 'recall_grapheme': 0.958044, 'recall_vowel': 0.98709, 'recall_consonant': 0.990406, 'acc_grapheme': 0.962504, 'acc_vowel': 0.990284, 'acc_consonant': 0.989241, 'loss_grapheme': 0.162001, 'loss_vowel': 0.072264, 'loss_consonant': 0.062057}\n",
      "   20 | 0.000006 | 117760/160596 | 0.0370 | 1.7780 |\n",
      "val: {'recall': 0.972464, 'recall_grapheme': 0.958899, 'recall_vowel': 0.986975, 'recall_consonant': 0.985082, 'acc_grapheme': 0.962255, 'acc_vowel': 0.989812, 'acc_consonant': 0.988719, 'loss_grapheme': 0.157574, 'loss_vowel': 0.071578, 'loss_consonant': 0.058228}\n",
      "   21 | 0.000008 | 008448/160596 | 4.5001 | 2.0133 |\n",
      "val: {'recall': 0.972518, 'recall_grapheme': 0.956781, 'recall_vowel': 0.988074, 'recall_consonant': 0.988438, 'acc_grapheme': 0.961386, 'acc_vowel': 0.990185, 'acc_consonant': 0.988843, 'loss_grapheme': 0.184284, 'loss_vowel': 0.093909, 'loss_consonant': 0.076633}\n",
      "   21 | 0.000011 | 059648/160596 | 4.4699 | 1.6788 |\n",
      "val: {'recall': 0.971713, 'recall_grapheme': 0.956685, 'recall_vowel': 0.98687, 'recall_consonant': 0.986612, 'acc_grapheme': 0.961659, 'acc_vowel': 0.990235, 'acc_consonant': 0.988644, 'loss_grapheme': 0.160282, 'loss_vowel': 0.063574, 'loss_consonant': 0.057593}\n",
      "   21 | 0.000013 | 110848/160596 | 2.4010 | 1.6332 |\n",
      "val: {'recall': 0.972347, 'recall_grapheme': 0.957621, 'recall_vowel': 0.986331, 'recall_consonant': 0.987814, 'acc_grapheme': 0.961733, 'acc_vowel': 0.990085, 'acc_consonant': 0.988868, 'loss_grapheme': 0.153625, 'loss_vowel': 0.055446, 'loss_consonant': 0.052575}\n",
      "   22 | 0.000015 | 001536/160596 | 2.0915 | 3.6130 |\n",
      "val: {'recall': 0.971449, 'recall_grapheme': 0.954216, 'recall_vowel': 0.987027, 'recall_consonant': 0.990336, 'acc_grapheme': 0.960392, 'acc_vowel': 0.989613, 'acc_consonant': 0.98857, 'loss_grapheme': 0.233311, 'loss_vowel': 0.133108, 'loss_consonant': 0.099612}\n",
      "   22 | 0.000017 | 052736/160596 | 0.0719 | 1.7249 |\n",
      "val: {'recall': 0.972858, 'recall_grapheme': 0.95873, 'recall_vowel': 0.986122, 'recall_consonant': 0.987849, 'acc_grapheme': 0.962131, 'acc_vowel': 0.99016, 'acc_consonant': 0.988719, 'loss_grapheme': 0.155876, 'loss_vowel': 0.062537, 'loss_consonant': 0.057747}\n",
      "   22 | 0.000019 | 103936/160596 | 2.9264 | 1.7637 |\n",
      "val: {'recall': 0.971733, 'recall_grapheme': 0.955339, 'recall_vowel': 0.988198, 'recall_consonant': 0.988055, 'acc_grapheme': 0.960441, 'acc_vowel': 0.989762, 'acc_consonant': 0.988346, 'loss_grapheme': 0.195128, 'loss_vowel': 0.104583, 'loss_consonant': 0.080872}\n",
      "   22 | 0.000020 | 155136/160596 | 4.7329 | 1.8586 |\n",
      "val: {'recall': 0.971561, 'recall_grapheme': 0.957016, 'recall_vowel': 0.987377, 'recall_consonant': 0.984834, 'acc_grapheme': 0.960889, 'acc_vowel': 0.989663, 'acc_consonant': 0.988197, 'loss_grapheme': 0.193649, 'loss_vowel': 0.101315, 'loss_consonant': 0.07796}\n",
      "   23 | 0.000020 | 045824/160596 | 2.0772 | 1.7835 |\n",
      "val: {'recall': 0.971308, 'recall_grapheme': 0.954846, 'recall_vowel': 0.987169, 'recall_consonant': 0.988374, 'acc_grapheme': 0.960466, 'acc_vowel': 0.989961, 'acc_consonant': 0.987849, 'loss_grapheme': 0.191219, 'loss_vowel': 0.107801, 'loss_consonant': 0.084171}\n",
      "   23 | 0.000020 | 097024/160596 | 4.0233 | 1.7837 |\n",
      "val: {'recall': 0.970113, 'recall_grapheme': 0.951983, 'recall_vowel': 0.986777, 'recall_consonant': 0.989707, 'acc_grapheme': 0.957907, 'acc_vowel': 0.98929, 'acc_consonant': 0.988172, 'loss_grapheme': 0.197993, 'loss_vowel': 0.118172, 'loss_consonant': 0.09123}\n",
      "   23 | 0.000019 | 148224/160596 | 0.0764 | 1.8308 |\n",
      "val: {'recall': 0.972608, 'recall_grapheme': 0.957348, 'recall_vowel': 0.987293, 'recall_consonant': 0.988443, 'acc_grapheme': 0.96069, 'acc_vowel': 0.989762, 'acc_consonant': 0.988247, 'loss_grapheme': 0.166058, 'loss_vowel': 0.073335, 'loss_consonant': 0.062947}\n",
      "   24 | 0.000017 | 038912/160596 | 3.0178 | 1.7393 |\n",
      "val: {'recall': 0.97122, 'recall_grapheme': 0.954131, 'recall_vowel': 0.986736, 'recall_consonant': 0.989883, 'acc_grapheme': 0.96064, 'acc_vowel': 0.989514, 'acc_consonant': 0.987998, 'loss_grapheme': 0.183518, 'loss_vowel': 0.09938, 'loss_consonant': 0.075531}\n",
      "   24 | 0.000015 | 090112/160596 | 0.1068 | 1.7592 |\n",
      "val: {'recall': 0.972237, 'recall_grapheme': 0.958298, 'recall_vowel': 0.986952, 'recall_consonant': 0.985399, 'acc_grapheme': 0.96151, 'acc_vowel': 0.989315, 'acc_consonant': 0.988669, 'loss_grapheme': 0.157633, 'loss_vowel': 0.064475, 'loss_consonant': 0.054717}\n",
      "   24 | 0.000013 | 141312/160596 | 0.0996 | 1.7571 |\n",
      "val: {'recall': 0.972013, 'recall_grapheme': 0.956058, 'recall_vowel': 0.987372, 'recall_consonant': 0.988562, 'acc_grapheme': 0.961212, 'acc_vowel': 0.989887, 'acc_consonant': 0.988495, 'loss_grapheme': 0.15081, 'loss_vowel': 0.049169, 'loss_consonant': 0.048276}\n",
      "   25 | 0.000011 | 032000/160596 | 0.0702 | 1.8394 |\n",
      "val: {'recall': 0.972445, 'recall_grapheme': 0.95662, 'recall_vowel': 0.986918, 'recall_consonant': 0.989622, 'acc_grapheme': 0.962056, 'acc_vowel': 0.989688, 'acc_consonant': 0.98857, 'loss_grapheme': 0.154459, 'loss_vowel': 0.063547, 'loss_consonant': 0.056664}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 0.000008 | 083200/160596 | 0.1357 | 1.7955 |\n",
      "val: {'recall': 0.972648, 'recall_grapheme': 0.957216, 'recall_vowel': 0.986032, 'recall_consonant': 0.990129, 'acc_grapheme': 0.961957, 'acc_vowel': 0.989489, 'acc_consonant': 0.988967, 'loss_grapheme': 0.203036, 'loss_vowel': 0.122925, 'loss_consonant': 0.092664}\n",
      "   25 | 0.000006 | 134400/160596 | 2.8360 | 1.7047 |\n",
      "val: {'recall': 0.974044, 'recall_grapheme': 0.959666, 'recall_vowel': 0.986834, 'recall_consonant': 0.99001, 'acc_grapheme': 0.963597, 'acc_vowel': 0.989713, 'acc_consonant': 0.989166, 'loss_grapheme': 0.18841, 'loss_vowel': 0.107752, 'loss_consonant': 0.081721}\n",
      "** saved\n",
      "   26 | 0.000004 | 025088/160596 | 0.0267 | 1.5122 |\n",
      "val: {'recall': 0.973218, 'recall_grapheme': 0.958349, 'recall_vowel': 0.986484, 'recall_consonant': 0.989693, 'acc_grapheme': 0.963373, 'acc_vowel': 0.990061, 'acc_consonant': 0.989315, 'loss_grapheme': 0.155314, 'loss_vowel': 0.068729, 'loss_consonant': 0.057606}\n",
      "   26 | 0.000002 | 076288/160596 | 0.0306 | 1.6058 |\n",
      "val: {'recall': 0.973171, 'recall_grapheme': 0.958003, 'recall_vowel': 0.986998, 'recall_consonant': 0.989678, 'acc_grapheme': 0.963523, 'acc_vowel': 0.990259, 'acc_consonant': 0.989042, 'loss_grapheme': 0.150415, 'loss_vowel': 0.059057, 'loss_consonant': 0.051815}\n",
      "   26 | 0.000001 | 127488/160596 | 2.9063 | 1.6989 |\n",
      "val: {'recall': 0.973955, 'recall_grapheme': 0.959509, 'recall_vowel': 0.986861, 'recall_consonant': 0.989942, 'acc_grapheme': 0.963895, 'acc_vowel': 0.990135, 'acc_consonant': 0.989265, 'loss_grapheme': 0.1785, 'loss_vowel': 0.099597, 'loss_consonant': 0.073702}\n",
      "   27 | 0.000001 | 018176/160596 | 0.0280 | 1.6369 |\n",
      "val: {'recall': 0.973913, 'recall_grapheme': 0.959061, 'recall_vowel': 0.987253, 'recall_consonant': 0.990279, 'acc_grapheme': 0.963895, 'acc_vowel': 0.990359, 'acc_consonant': 0.98929, 'loss_grapheme': 0.168502, 'loss_vowel': 0.086925, 'loss_consonant': 0.067949}\n",
      "   27 | 0.000001 | 069376/160596 | 0.0461 | 1.7299 |\n",
      "val: {'recall': 0.973684, 'recall_grapheme': 0.958834, 'recall_vowel': 0.986968, 'recall_consonant': 0.990102, 'acc_grapheme': 0.963846, 'acc_vowel': 0.990185, 'acc_consonant': 0.989116, 'loss_grapheme': 0.149857, 'loss_vowel': 0.064609, 'loss_consonant': 0.055041}\n",
      "   27 | 0.000002 | 120576/160596 | 0.0129 | 1.7967 |\n",
      "val: {'recall': 0.973645, 'recall_grapheme': 0.959118, 'recall_vowel': 0.986619, 'recall_consonant': 0.989725, 'acc_grapheme': 0.964069, 'acc_vowel': 0.989986, 'acc_consonant': 0.989489, 'loss_grapheme': 0.154157, 'loss_vowel': 0.068211, 'loss_consonant': 0.056808}\n",
      "   28 | 0.000004 | 011264/160596 | 0.0150 | 1.4447 |\n",
      "val: {'recall': 0.973977, 'recall_grapheme': 0.959585, 'recall_vowel': 0.987021, 'recall_consonant': 0.989715, 'acc_grapheme': 0.963647, 'acc_vowel': 0.99016, 'acc_consonant': 0.989166, 'loss_grapheme': 0.158667, 'loss_vowel': 0.072128, 'loss_consonant': 0.05924}\n",
      "   28 | 0.000006 | 062464/160596 | 0.0286 | 1.7570 |\n",
      "val: {'recall': 0.973266, 'recall_grapheme': 0.957701, 'recall_vowel': 0.987421, 'recall_consonant': 0.990239, 'acc_grapheme': 0.962901, 'acc_vowel': 0.990036, 'acc_consonant': 0.989315, 'loss_grapheme': 0.175362, 'loss_vowel': 0.101512, 'loss_consonant': 0.079217}\n",
      "   28 | 0.000008 | 113664/160596 | 0.0341 | 1.7332 |\n",
      "val: {'recall': 0.97327, 'recall_grapheme': 0.957911, 'recall_vowel': 0.987594, 'recall_consonant': 0.989666, 'acc_grapheme': 0.962479, 'acc_vowel': 0.989812, 'acc_consonant': 0.989265, 'loss_grapheme': 0.169204, 'loss_vowel': 0.089836, 'loss_consonant': 0.067996}\n",
      "   29 | 0.000011 | 004352/160596 | 0.0465 | 1.0957 |\n",
      "val: {'recall': 0.972006, 'recall_grapheme': 0.955927, 'recall_vowel': 0.986513, 'recall_consonant': 0.989657, 'acc_grapheme': 0.961733, 'acc_vowel': 0.990185, 'acc_consonant': 0.988893, 'loss_grapheme': 0.153571, 'loss_vowel': 0.057107, 'loss_consonant': 0.052122}\n",
      "   29 | 0.000013 | 055552/160596 | 3.8148 | 1.4850 |\n",
      "val: {'recall': 0.972084, 'recall_grapheme': 0.955427, 'recall_vowel': 0.986595, 'recall_consonant': 0.990885, 'acc_grapheme': 0.961783, 'acc_vowel': 0.990011, 'acc_consonant': 0.989241, 'loss_grapheme': 0.164929, 'loss_vowel': 0.068496, 'loss_consonant': 0.06081}\n",
      "   29 | 0.000015 | 106752/160596 | 4.7000 | 1.6067 |\n",
      "val: {'recall': 0.972004, 'recall_grapheme': 0.95554, 'recall_vowel': 0.987218, 'recall_consonant': 0.989716, 'acc_grapheme': 0.961659, 'acc_vowel': 0.989738, 'acc_consonant': 0.988272, 'loss_grapheme': 0.197267, 'loss_vowel': 0.104747, 'loss_consonant': 0.084917}\n",
      "   29 | 0.000017 | 157952/160596 | 4.9059 | 1.5777 |\n",
      "val: {'recall': 0.972476, 'recall_grapheme': 0.956488, 'recall_vowel': 0.987243, 'recall_consonant': 0.989686, 'acc_grapheme': 0.961212, 'acc_vowel': 0.989812, 'acc_consonant': 0.988694, 'loss_grapheme': 0.18265, 'loss_vowel': 0.092028, 'loss_consonant': 0.071687}\n",
      "   30 | 0.000019 | 048640/160596 | 0.0695 | 1.6544 |\n",
      "val: {'recall': 0.972075, 'recall_grapheme': 0.955158, 'recall_vowel': 0.987113, 'recall_consonant': 0.990871, 'acc_grapheme': 0.960441, 'acc_vowel': 0.989887, 'acc_consonant': 0.988669, 'loss_grapheme': 0.174571, 'loss_vowel': 0.091866, 'loss_consonant': 0.074398}\n",
      "   30 | 0.000020 | 099840/160596 | 1.7660 | 1.7206 |\n",
      "val: {'recall': 0.97198, 'recall_grapheme': 0.956618, 'recall_vowel': 0.987286, 'recall_consonant': 0.987396, 'acc_grapheme': 0.960218, 'acc_vowel': 0.989887, 'acc_consonant': 0.988421, 'loss_grapheme': 0.161977, 'loss_vowel': 0.054899, 'loss_consonant': 0.051765}\n",
      "   30 | 0.000020 | 151040/160596 | 0.0385 | 1.7694 |\n",
      "val: {'recall': 0.970013, 'recall_grapheme': 0.955588, 'recall_vowel': 0.986598, 'recall_consonant': 0.98228, 'acc_grapheme': 0.961709, 'acc_vowel': 0.989713, 'acc_consonant': 0.987377, 'loss_grapheme': 0.164991, 'loss_vowel': 0.072258, 'loss_consonant': 0.06387}\n",
      "   31 | 0.000020 | 041728/160596 | 0.0610 | 2.0288 |\n",
      "val: {'recall': 0.973171, 'recall_grapheme': 0.957808, 'recall_vowel': 0.988257, 'recall_consonant': 0.988811, 'acc_grapheme': 0.961609, 'acc_vowel': 0.989936, 'acc_consonant': 0.98857, 'loss_grapheme': 0.182229, 'loss_vowel': 0.08757, 'loss_consonant': 0.074081}\n",
      "   31 | 0.000019 | 092928/160596 | 0.0494 | 1.8903 |\n",
      "val: {'recall': 0.971715, 'recall_grapheme': 0.955619, 'recall_vowel': 0.986446, 'recall_consonant': 0.989177, 'acc_grapheme': 0.96069, 'acc_vowel': 0.990011, 'acc_consonant': 0.987899, 'loss_grapheme': 0.176533, 'loss_vowel': 0.0858, 'loss_consonant': 0.074645}\n",
      "   31 | 0.000017 | 144128/160596 | 0.0514 | 1.8520 |\n",
      "val: {'recall': 0.972423, 'recall_grapheme': 0.957458, 'recall_vowel': 0.986858, 'recall_consonant': 0.987919, 'acc_grapheme': 0.962156, 'acc_vowel': 0.989912, 'acc_consonant': 0.988222, 'loss_grapheme': 0.170893, 'loss_vowel': 0.083395, 'loss_consonant': 0.069173}\n",
      "   32 | 0.000015 | 034816/160596 | 0.0363 | 1.6959 |\n",
      "val: {'recall': 0.97295, 'recall_grapheme': 0.959075, 'recall_vowel': 0.986121, 'recall_consonant': 0.98753, 'acc_grapheme': 0.962255, 'acc_vowel': 0.989738, 'acc_consonant': 0.988818, 'loss_grapheme': 0.16362, 'loss_vowel': 0.075682, 'loss_consonant': 0.06502}\n",
      "   32 | 0.000013 | 086016/160596 | 0.0372 | 1.7781 |\n",
      "val: {'recall': 0.972, 'recall_grapheme': 0.957074, 'recall_vowel': 0.986107, 'recall_consonant': 0.987743, 'acc_grapheme': 0.962305, 'acc_vowel': 0.99011, 'acc_consonant': 0.988719, 'loss_grapheme': 0.172517, 'loss_vowel': 0.094879, 'loss_consonant': 0.074466}\n",
      "   32 | 0.000011 | 137216/160596 | 2.5781 | 1.8113 |\n",
      "val: {'recall': 0.972669, 'recall_grapheme': 0.958703, 'recall_vowel': 0.987303, 'recall_consonant': 0.985966, 'acc_grapheme': 0.962827, 'acc_vowel': 0.989762, 'acc_consonant': 0.989017, 'loss_grapheme': 0.218059, 'loss_vowel': 0.13459, 'loss_consonant': 0.09928}\n",
      "   33 | 0.000008 | 027904/160596 | 4.5060 | 2.1785 |\n",
      "val: {'recall': 0.973349, 'recall_grapheme': 0.9584, 'recall_vowel': 0.987919, 'recall_consonant': 0.988677, 'acc_grapheme': 0.962056, 'acc_vowel': 0.990359, 'acc_consonant': 0.989116, 'loss_grapheme': 0.197875, 'loss_vowel': 0.127265, 'loss_consonant': 0.089441}\n",
      "   33 | 0.000006 | 079104/160596 | 0.0476 | 1.7820 |\n",
      "val: {'recall': 0.973836, 'recall_grapheme': 0.958949, 'recall_vowel': 0.987321, 'recall_consonant': 0.990127, 'acc_grapheme': 0.963224, 'acc_vowel': 0.990259, 'acc_consonant': 0.989092, 'loss_grapheme': 0.18164, 'loss_vowel': 0.094962, 'loss_consonant': 0.07747}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 0.000004 | 130304/160596 | 0.0219 | 1.7403 |\n",
      "val: {'recall': 0.973862, 'recall_grapheme': 0.958766, 'recall_vowel': 0.987794, 'recall_consonant': 0.990119, 'acc_grapheme': 0.963175, 'acc_vowel': 0.990533, 'acc_consonant': 0.988942, 'loss_grapheme': 0.169849, 'loss_vowel': 0.088869, 'loss_consonant': 0.070356}\n",
      "   34 | 0.000002 | 020992/160596 | 4.1628 | 1.1759 |\n",
      "val: {'recall': 0.973459, 'recall_grapheme': 0.958008, 'recall_vowel': 0.987899, 'recall_consonant': 0.989922, 'acc_grapheme': 0.96315, 'acc_vowel': 0.990483, 'acc_consonant': 0.989216, 'loss_grapheme': 0.146142, 'loss_vowel': 0.050469, 'loss_consonant': 0.048092}\n",
      "   34 | 0.000001 | 072192/160596 | 3.9224 | 1.4745 |\n",
      "val: {'recall': 0.974373, 'recall_grapheme': 0.959983, 'recall_vowel': 0.987248, 'recall_consonant': 0.990277, 'acc_grapheme': 0.963796, 'acc_vowel': 0.990508, 'acc_consonant': 0.989315, 'loss_grapheme': 0.1519, 'loss_vowel': 0.064594, 'loss_consonant': 0.056173}\n",
      "** saved\n",
      "   34 | 0.000001 | 123392/160596 | 1.9063 | 1.6106 |\n",
      "val: {'recall': 0.974115, 'recall_grapheme': 0.959207, 'recall_vowel': 0.987815, 'recall_consonant': 0.990232, 'acc_grapheme': 0.963796, 'acc_vowel': 0.990533, 'acc_consonant': 0.989265, 'loss_grapheme': 0.170205, 'loss_vowel': 0.086837, 'loss_consonant': 0.069771}\n",
      "   35 | 0.000001 | 014080/160596 | 4.1601 | 1.3201 |\n",
      "val: {'recall': 0.974051, 'recall_grapheme': 0.959267, 'recall_vowel': 0.987171, 'recall_consonant': 0.9905, 'acc_grapheme': 0.963523, 'acc_vowel': 0.990657, 'acc_consonant': 0.989265, 'loss_grapheme': 0.175557, 'loss_vowel': 0.10256, 'loss_consonant': 0.075592}\n",
      "   35 | 0.000002 | 065280/160596 | 0.0141 | 1.6905 |\n",
      "val: {'recall': 0.974226, 'recall_grapheme': 0.95973, 'recall_vowel': 0.987303, 'recall_consonant': 0.99014, 'acc_grapheme': 0.963473, 'acc_vowel': 0.990533, 'acc_consonant': 0.98939, 'loss_grapheme': 0.152072, 'loss_vowel': 0.063877, 'loss_consonant': 0.054939}\n",
      "   35 | 0.000004 | 116480/160596 | 0.7262 | 1.6893 |\n",
      "val: {'recall': 0.974183, 'recall_grapheme': 0.95914, 'recall_vowel': 0.988252, 'recall_consonant': 0.9902, 'acc_grapheme': 0.963696, 'acc_vowel': 0.990682, 'acc_consonant': 0.989489, 'loss_grapheme': 0.150787, 'loss_vowel': 0.060064, 'loss_consonant': 0.051798}\n",
      "   36 | 0.000006 | 007168/160596 | 3.6803 | 1.2751 |\n",
      "val: {'recall': 0.973992, 'recall_grapheme': 0.959634, 'recall_vowel': 0.987705, 'recall_consonant': 0.988996, 'acc_grapheme': 0.963423, 'acc_vowel': 0.990433, 'acc_consonant': 0.98929, 'loss_grapheme': 0.159358, 'loss_vowel': 0.072392, 'loss_consonant': 0.05958}\n",
      "   36 | 0.000008 | 058368/160596 | 4.8396 | 1.7558 |\n",
      "val: {'recall': 0.97374, 'recall_grapheme': 0.958306, 'recall_vowel': 0.988156, 'recall_consonant': 0.990193, 'acc_grapheme': 0.962653, 'acc_vowel': 0.990657, 'acc_consonant': 0.989241, 'loss_grapheme': 0.164549, 'loss_vowel': 0.08725, 'loss_consonant': 0.067237}\n",
      "   36 | 0.000010 | 109568/160596 | 0.0390 | 1.8051 |\n",
      "val: {'recall': 0.972531, 'recall_grapheme': 0.956473, 'recall_vowel': 0.987827, 'recall_consonant': 0.989351, 'acc_grapheme': 0.962628, 'acc_vowel': 0.990607, 'acc_consonant': 0.989017, 'loss_grapheme': 0.149909, 'loss_vowel': 0.053165, 'loss_consonant': 0.050025}\n",
      "   37 | 0.000013 | 000256/160596 | 3.7730 | 3.7730 |\n",
      "val: {'recall': 0.97268, 'recall_grapheme': 0.958645, 'recall_vowel': 0.988383, 'recall_consonant': 0.985047, 'acc_grapheme': 0.961609, 'acc_vowel': 0.990558, 'acc_consonant': 0.988793, 'loss_grapheme': 0.186666, 'loss_vowel': 0.103603, 'loss_consonant': 0.075307}\n",
      "   37 | 0.000015 | 051456/160596 | 0.0580 | 1.9787 |\n",
      "val: {'recall': 0.973326, 'recall_grapheme': 0.957995, 'recall_vowel': 0.987091, 'recall_consonant': 0.990224, 'acc_grapheme': 0.961758, 'acc_vowel': 0.990334, 'acc_consonant': 0.98929, 'loss_grapheme': 0.17435, 'loss_vowel': 0.085907, 'loss_consonant': 0.068589}\n",
      "   37 | 0.000017 | 102656/160596 | 4.4080 | 1.7834 |\n",
      "val: {'recall': 0.973036, 'recall_grapheme': 0.957952, 'recall_vowel': 0.987655, 'recall_consonant': 0.988584, 'acc_grapheme': 0.960913, 'acc_vowel': 0.990508, 'acc_consonant': 0.989141, 'loss_grapheme': 0.201152, 'loss_vowel': 0.119591, 'loss_consonant': 0.092802}\n",
      "   37 | 0.000019 | 153856/160596 | 0.0438 | 1.7097 |\n",
      "val: {'recall': 0.972223, 'recall_grapheme': 0.958519, 'recall_vowel': 0.986935, 'recall_consonant': 0.984918, 'acc_grapheme': 0.962081, 'acc_vowel': 0.989514, 'acc_consonant': 0.988445, 'loss_grapheme': 0.159258, 'loss_vowel': 0.063858, 'loss_consonant': 0.057202}\n",
      "   38 | 0.000020 | 044544/160596 | 0.0430 | 1.6635 |\n",
      "val: {'recall': 0.9725, 'recall_grapheme': 0.956397, 'recall_vowel': 0.988404, 'recall_consonant': 0.988804, 'acc_grapheme': 0.962255, 'acc_vowel': 0.990384, 'acc_consonant': 0.988744, 'loss_grapheme': 0.162455, 'loss_vowel': 0.059763, 'loss_consonant': 0.054349}\n",
      "   38 | 0.000020 | 095744/160596 | 3.5345 | 1.7561 |\n",
      "val: {'recall': 0.972506, 'recall_grapheme': 0.955907, 'recall_vowel': 0.98749, 'recall_consonant': 0.990721, 'acc_grapheme': 0.96151, 'acc_vowel': 0.990235, 'acc_consonant': 0.989067, 'loss_grapheme': 0.197238, 'loss_vowel': 0.103709, 'loss_consonant': 0.085168}\n",
      "   38 | 0.000020 | 146944/160596 | 0.0393 | 1.7864 |\n",
      "val: {'recall': 0.973046, 'recall_grapheme': 0.957718, 'recall_vowel': 0.986393, 'recall_consonant': 0.990354, 'acc_grapheme': 0.961783, 'acc_vowel': 0.989787, 'acc_consonant': 0.989812, 'loss_grapheme': 0.185397, 'loss_vowel': 0.107313, 'loss_consonant': 0.074646}\n",
      "   39 | 0.000019 | 037632/160596 | 5.0795 | 1.9233 |\n",
      "val: {'recall': 0.973908, 'recall_grapheme': 0.958633, 'recall_vowel': 0.987994, 'recall_consonant': 0.990374, 'acc_grapheme': 0.961883, 'acc_vowel': 0.990135, 'acc_consonant': 0.989191, 'loss_grapheme': 0.24922, 'loss_vowel': 0.154289, 'loss_consonant': 0.114447}\n",
      "   39 | 0.000017 | 088832/160596 | 2.9945 | 1.8540 |\n",
      "val: {'recall': 0.973056, 'recall_grapheme': 0.958037, 'recall_vowel': 0.988886, 'recall_consonant': 0.987265, 'acc_grapheme': 0.962504, 'acc_vowel': 0.990458, 'acc_consonant': 0.989017, 'loss_grapheme': 0.166659, 'loss_vowel': 0.07744, 'loss_consonant': 0.060273}\n",
      "   39 | 0.000015 | 140032/160596 | 0.0425 | 1.7472 |\n",
      "val: {'recall': 0.972198, 'recall_grapheme': 0.956787, 'recall_vowel': 0.98852, 'recall_consonant': 0.9867, 'acc_grapheme': 0.964417, 'acc_vowel': 0.990831, 'acc_consonant': 0.989514, 'loss_grapheme': 0.145002, 'loss_vowel': 0.044741, 'loss_consonant': 0.044507}\n",
      "   40 | 0.000013 | 030720/160596 | 2.2441 | 1.5659 |\n",
      "val: {'recall': 0.972435, 'recall_grapheme': 0.955779, 'recall_vowel': 0.987874, 'recall_consonant': 0.990307, 'acc_grapheme': 0.962653, 'acc_vowel': 0.990781, 'acc_consonant': 0.988918, 'loss_grapheme': 0.166854, 'loss_vowel': 0.083729, 'loss_consonant': 0.070023}\n",
      "   40 | 0.000010 | 081920/160596 | 4.8771 | 1.6195 |\n",
      "val: {'recall': 0.973483, 'recall_grapheme': 0.958154, 'recall_vowel': 0.988168, 'recall_consonant': 0.989456, 'acc_grapheme': 0.964666, 'acc_vowel': 0.990582, 'acc_consonant': 0.98934, 'loss_grapheme': 0.147883, 'loss_vowel': 0.059332, 'loss_consonant': 0.052435}\n",
      "   40 | 0.000008 | 133120/160596 | 0.0084 | 1.6143 |\n",
      "val: {'recall': 0.974751, 'recall_grapheme': 0.961246, 'recall_vowel': 0.987543, 'recall_consonant': 0.988969, 'acc_grapheme': 0.965287, 'acc_vowel': 0.990682, 'acc_consonant': 0.989439, 'loss_grapheme': 0.147049, 'loss_vowel': 0.053823, 'loss_consonant': 0.049046}\n",
      "** saved\n",
      "   41 | 0.000006 | 023808/160596 | 0.0100 | 2.0247 |\n",
      "val: {'recall': 0.974981, 'recall_grapheme': 0.961375, 'recall_vowel': 0.987465, 'recall_consonant': 0.989709, 'acc_grapheme': 0.964864, 'acc_vowel': 0.990756, 'acc_consonant': 0.98934, 'loss_grapheme': 0.153572, 'loss_vowel': 0.071663, 'loss_consonant': 0.058065}\n",
      "** saved\n",
      "   41 | 0.000004 | 075008/160596 | 3.6866 | 1.8618 |\n",
      "val: {'recall': 0.974809, 'recall_grapheme': 0.960927, 'recall_vowel': 0.987666, 'recall_consonant': 0.989714, 'acc_grapheme': 0.965063, 'acc_vowel': 0.990756, 'acc_consonant': 0.989589, 'loss_grapheme': 0.183945, 'loss_vowel': 0.110262, 'loss_consonant': 0.081941}\n",
      "   41 | 0.000002 | 126208/160596 | 0.0220 | 1.8229 |\n",
      "val: {'recall': 0.974892, 'recall_grapheme': 0.961237, 'recall_vowel': 0.988422, 'recall_consonant': 0.988674, 'acc_grapheme': 0.965486, 'acc_vowel': 0.990955, 'acc_consonant': 0.989365, 'loss_grapheme': 0.143822, 'loss_vowel': 0.050625, 'loss_consonant': 0.047338}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 0.000001 | 016896/160596 | 0.0312 | 1.9648 |\n",
      "val: {'recall': 0.974447, 'recall_grapheme': 0.95981, 'recall_vowel': 0.988466, 'recall_consonant': 0.989701, 'acc_grapheme': 0.965237, 'acc_vowel': 0.990806, 'acc_consonant': 0.989489, 'loss_grapheme': 0.178157, 'loss_vowel': 0.104925, 'loss_consonant': 0.080156}\n",
      "   42 | 0.000001 | 068096/160596 | 0.0257 | 1.5935 |\n",
      "val: {'recall': 0.974857, 'recall_grapheme': 0.960532, 'recall_vowel': 0.988404, 'recall_consonant': 0.98996, 'acc_grapheme': 0.965535, 'acc_vowel': 0.991104, 'acc_consonant': 0.989514, 'loss_grapheme': 0.144943, 'loss_vowel': 0.042161, 'loss_consonant': 0.043545}\n",
      "   42 | 0.000001 | 119296/160596 | 4.3262 | 1.7643 |\n",
      "val: {'recall': 0.974714, 'recall_grapheme': 0.960483, 'recall_vowel': 0.988131, 'recall_consonant': 0.98976, 'acc_grapheme': 0.965784, 'acc_vowel': 0.99093, 'acc_consonant': 0.989638, 'loss_grapheme': 0.16014, 'loss_vowel': 0.079177, 'loss_consonant': 0.064631}\n",
      "   43 | 0.000002 | 009984/160596 | 0.0117 | 2.0320 |\n",
      "val: {'recall': 0.97458, 'recall_grapheme': 0.960229, 'recall_vowel': 0.987968, 'recall_consonant': 0.989896, 'acc_grapheme': 0.96551, 'acc_vowel': 0.990806, 'acc_consonant': 0.989589, 'loss_grapheme': 0.171896, 'loss_vowel': 0.099861, 'loss_consonant': 0.075473}\n",
      "   43 | 0.000004 | 061184/160596 | 4.4035 | 1.6592 |\n",
      "val: {'recall': 0.974583, 'recall_grapheme': 0.960382, 'recall_vowel': 0.987674, 'recall_consonant': 0.989892, 'acc_grapheme': 0.965212, 'acc_vowel': 0.990732, 'acc_consonant': 0.989415, 'loss_grapheme': 0.172109, 'loss_vowel': 0.102492, 'loss_consonant': 0.075004}\n",
      "   43 | 0.000006 | 112384/160596 | 0.0125 | 1.6035 |\n",
      "val: {'recall': 0.974934, 'recall_grapheme': 0.96058, 'recall_vowel': 0.988537, 'recall_consonant': 0.990039, 'acc_grapheme': 0.965312, 'acc_vowel': 0.991402, 'acc_consonant': 0.98939, 'loss_grapheme': 0.166575, 'loss_vowel': 0.087026, 'loss_consonant': 0.067418}\n",
      "   44 | 0.000008 | 003072/160596 | 3.2705 | 1.1861 |\n",
      "val: {'recall': 0.974267, 'recall_grapheme': 0.960581, 'recall_vowel': 0.988486, 'recall_consonant': 0.987421, 'acc_grapheme': 0.96474, 'acc_vowel': 0.99103, 'acc_consonant': 0.988942, 'loss_grapheme': 0.15308, 'loss_vowel': 0.068189, 'loss_consonant': 0.058021}\n",
      "   44 | 0.000010 | 054272/160596 | 0.0146 | 1.7088 |\n",
      "val: {'recall': 0.974004, 'recall_grapheme': 0.95828, 'recall_vowel': 0.989032, 'recall_consonant': 0.990426, 'acc_grapheme': 0.964119, 'acc_vowel': 0.991104, 'acc_consonant': 0.988918, 'loss_grapheme': 0.150519, 'loss_vowel': 0.060314, 'loss_consonant': 0.055736}\n",
      "   44 | 0.000013 | 105472/160596 | 3.5741 | 1.6411 |\n",
      "val: {'recall': 0.974281, 'recall_grapheme': 0.95938, 'recall_vowel': 0.989335, 'recall_consonant': 0.989029, 'acc_grapheme': 0.965187, 'acc_vowel': 0.99093, 'acc_consonant': 0.989216, 'loss_grapheme': 0.150583, 'loss_vowel': 0.059022, 'loss_consonant': 0.053217}\n",
      "   44 | 0.000015 | 156672/160596 | 4.7172 | 1.6025 |\n",
      "val: {'recall': 0.973785, 'recall_grapheme': 0.95828, 'recall_vowel': 0.989028, 'recall_consonant': 0.989552, 'acc_grapheme': 0.963771, 'acc_vowel': 0.99098, 'acc_consonant': 0.989191, 'loss_grapheme': 0.16134, 'loss_vowel': 0.069997, 'loss_consonant': 0.060398}\n",
      "   45 | 0.000017 | 047360/160596 | 0.0310 | 1.7720 |\n",
      "val: {'recall': 0.972266, 'recall_grapheme': 0.957118, 'recall_vowel': 0.987944, 'recall_consonant': 0.986885, 'acc_grapheme': 0.962876, 'acc_vowel': 0.990831, 'acc_consonant': 0.989365, 'loss_grapheme': 0.15798, 'loss_vowel': 0.058052, 'loss_consonant': 0.053674}\n",
      "   45 | 0.000019 | 098560/160596 | 4.8162 | 1.7655 |\n",
      "val: {'recall': 0.974041, 'recall_grapheme': 0.958903, 'recall_vowel': 0.989369, 'recall_consonant': 0.988987, 'acc_grapheme': 0.962876, 'acc_vowel': 0.990781, 'acc_consonant': 0.989042, 'loss_grapheme': 0.188716, 'loss_vowel': 0.113143, 'loss_consonant': 0.084239}\n",
      "   45 | 0.000020 | 149760/160596 | 2.0133 | 1.7692 |\n",
      "val: {'recall': 0.973601, 'recall_grapheme': 0.957853, 'recall_vowel': 0.98949, 'recall_consonant': 0.989207, 'acc_grapheme': 0.962653, 'acc_vowel': 0.991079, 'acc_consonant': 0.98939, 'loss_grapheme': 0.160454, 'loss_vowel': 0.062826, 'loss_consonant': 0.059507}\n",
      "   46 | 0.000020 | 040448/160596 | 0.0531 | 1.7243 |\n",
      "val: {'recall': 0.971251, 'recall_grapheme': 0.957479, 'recall_vowel': 0.988178, 'recall_consonant': 0.98187, 'acc_grapheme': 0.962156, 'acc_vowel': 0.990433, 'acc_consonant': 0.988942, 'loss_grapheme': 0.167572, 'loss_vowel': 0.069152, 'loss_consonant': 0.061417}\n",
      "   46 | 0.000020 | 091648/160596 | 0.0182 | 1.7434 |\n",
      "val: {'recall': 0.97263, 'recall_grapheme': 0.958627, 'recall_vowel': 0.988223, 'recall_consonant': 0.985044, 'acc_grapheme': 0.963026, 'acc_vowel': 0.990384, 'acc_consonant': 0.989017, 'loss_grapheme': 0.174062, 'loss_vowel': 0.078232, 'loss_consonant': 0.069266}\n",
      "   46 | 0.000019 | 142848/160596 | 0.0161 | 1.7245 |\n",
      "val: {'recall': 0.974152, 'recall_grapheme': 0.960095, 'recall_vowel': 0.988689, 'recall_consonant': 0.987727, 'acc_grapheme': 0.963324, 'acc_vowel': 0.990508, 'acc_consonant': 0.989166, 'loss_grapheme': 0.15963, 'loss_vowel': 0.061623, 'loss_consonant': 0.057862}\n",
      "   47 | 0.000017 | 033536/160596 | 3.0360 | 1.7107 |\n",
      "val: {'recall': 0.973465, 'recall_grapheme': 0.958367, 'recall_vowel': 0.987658, 'recall_consonant': 0.989466, 'acc_grapheme': 0.963249, 'acc_vowel': 0.990632, 'acc_consonant': 0.987998, 'loss_grapheme': 0.183622, 'loss_vowel': 0.1082, 'loss_consonant': 0.085647}\n",
      "   47 | 0.000015 | 084736/160596 | 0.0082 | 1.6975 |\n",
      "val: {'recall': 0.973759, 'recall_grapheme': 0.958, 'recall_vowel': 0.98982, 'recall_consonant': 0.989215, 'acc_grapheme': 0.963821, 'acc_vowel': 0.990682, 'acc_consonant': 0.98934, 'loss_grapheme': 0.156865, 'loss_vowel': 0.071553, 'loss_consonant': 0.058033}\n",
      "   47 | 0.000013 | 135936/160596 | 3.0829 | 1.6586 |\n",
      "val: {'recall': 0.974986, 'recall_grapheme': 0.96088, 'recall_vowel': 0.989314, 'recall_consonant': 0.988871, 'acc_grapheme': 0.964492, 'acc_vowel': 0.99098, 'acc_consonant': 0.98934, 'loss_grapheme': 0.154776, 'loss_vowel': 0.058336, 'loss_consonant': 0.053103}\n",
      "** saved\n",
      "   48 | 0.000010 | 026624/160596 | 4.3978 | 1.6898 |\n",
      "val: {'recall': 0.973847, 'recall_grapheme': 0.960068, 'recall_vowel': 0.988729, 'recall_consonant': 0.986525, 'acc_grapheme': 0.965138, 'acc_vowel': 0.991055, 'acc_consonant': 0.989415, 'loss_grapheme': 0.160174, 'loss_vowel': 0.069696, 'loss_consonant': 0.05855}\n",
      "   48 | 0.000008 | 077824/160596 | 0.0367 | 1.6914 |\n",
      "val: {'recall': 0.973952, 'recall_grapheme': 0.959737, 'recall_vowel': 0.989772, 'recall_consonant': 0.98656, 'acc_grapheme': 0.965461, 'acc_vowel': 0.991402, 'acc_consonant': 0.989613, 'loss_grapheme': 0.146786, 'loss_vowel': 0.052966, 'loss_consonant': 0.049229}\n",
      "   48 | 0.000006 | 129024/160596 | 0.0143 | 1.6797 |\n",
      "val: {'recall': 0.974381, 'recall_grapheme': 0.960564, 'recall_vowel': 0.989019, 'recall_consonant': 0.987377, 'acc_grapheme': 0.965038, 'acc_vowel': 0.991179, 'acc_consonant': 0.989439, 'loss_grapheme': 0.147124, 'loss_vowel': 0.054323, 'loss_consonant': 0.04962}\n",
      "   49 | 0.000004 | 019712/160596 | 0.0272 | 1.7591 |\n",
      "val: {'recall': 0.974416, 'recall_grapheme': 0.960775, 'recall_vowel': 0.989475, 'recall_consonant': 0.986638, 'acc_grapheme': 0.965659, 'acc_vowel': 0.991204, 'acc_consonant': 0.989589, 'loss_grapheme': 0.145622, 'loss_vowel': 0.05768, 'loss_consonant': 0.051464}\n",
      "   49 | 0.000002 | 070912/160596 | 0.0260 | 1.7086 |\n",
      "val: {'recall': 0.975052, 'recall_grapheme': 0.962024, 'recall_vowel': 0.989487, 'recall_consonant': 0.986672, 'acc_grapheme': 0.965983, 'acc_vowel': 0.991378, 'acc_consonant': 0.989415, 'loss_grapheme': 0.144042, 'loss_vowel': 0.045147, 'loss_consonant': 0.045271}\n",
      "** saved\n",
      "   49 | 0.000001 | 122112/160596 | 0.0096 | 1.6689 |\n",
      "val: {'recall': 0.97441, 'recall_grapheme': 0.960945, 'recall_vowel': 0.989586, 'recall_consonant': 0.986164, 'acc_grapheme': 0.965709, 'acc_vowel': 0.991427, 'acc_consonant': 0.989464, 'loss_grapheme': 0.168906, 'loss_vowel': 0.091161, 'loss_consonant': 0.070726}\n",
      "   50 | 0.000001 | 012800/160596 | 0.0126 | 1.7608 |\n",
      "val: {'recall': 0.974065, 'recall_grapheme': 0.96051, 'recall_vowel': 0.989361, 'recall_consonant': 0.985881, 'acc_grapheme': 0.965709, 'acc_vowel': 0.991378, 'acc_consonant': 0.989539, 'loss_grapheme': 0.149107, 'loss_vowel': 0.063112, 'loss_consonant': 0.05464}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 | 0.000001 | 064000/160596 | 4.2212 | 1.5631 |\n",
      "val: {'recall': 0.974694, 'recall_grapheme': 0.961171, 'recall_vowel': 0.989679, 'recall_consonant': 0.986754, 'acc_grapheme': 0.965958, 'acc_vowel': 0.991502, 'acc_consonant': 0.989564, 'loss_grapheme': 0.143505, 'loss_vowel': 0.046794, 'loss_consonant': 0.046424}\n",
      "   50 | 0.000002 | 115200/160596 | 0.0125 | 1.6555 |\n",
      "val: {'recall': 0.973897, 'recall_grapheme': 0.95993, 'recall_vowel': 0.989492, 'recall_consonant': 0.986236, 'acc_grapheme': 0.965585, 'acc_vowel': 0.991477, 'acc_consonant': 0.989514, 'loss_grapheme': 0.16886, 'loss_vowel': 0.095591, 'loss_consonant': 0.073448}\n",
      "   51 | 0.000004 | 005888/160596 | 2.7642 | 1.8369 |\n",
      "val: {'recall': 0.973848, 'recall_grapheme': 0.959828, 'recall_vowel': 0.989423, 'recall_consonant': 0.986311, 'acc_grapheme': 0.965759, 'acc_vowel': 0.991527, 'acc_consonant': 0.989663, 'loss_grapheme': 0.160352, 'loss_vowel': 0.078989, 'loss_consonant': 0.064717}\n",
      "   51 | 0.000006 | 057088/160596 | 4.0984 | 1.6316 |\n",
      "val: {'recall': 0.974488, 'recall_grapheme': 0.96127, 'recall_vowel': 0.988438, 'recall_consonant': 0.986973, 'acc_grapheme': 0.96551, 'acc_vowel': 0.991179, 'acc_consonant': 0.989489, 'loss_grapheme': 0.154663, 'loss_vowel': 0.076004, 'loss_consonant': 0.061045}\n",
      "   51 | 0.000008 | 108288/160596 | 2.9155 | 1.6844 |\n",
      "val: {'recall': 0.973608, 'recall_grapheme': 0.959356, 'recall_vowel': 0.988866, 'recall_consonant': 0.986856, 'acc_grapheme': 0.964566, 'acc_vowel': 0.991229, 'acc_consonant': 0.989315, 'loss_grapheme': 0.16681, 'loss_vowel': 0.081332, 'loss_consonant': 0.064997}\n",
      "   51 | 0.000010 | 159488/160596 | 4.6325 | 1.6887 |\n",
      "val: {'recall': 0.9737, 'recall_grapheme': 0.959436, 'recall_vowel': 0.988706, 'recall_consonant': 0.987222, 'acc_grapheme': 0.964591, 'acc_vowel': 0.991229, 'acc_consonant': 0.989713, 'loss_grapheme': 0.157273, 'loss_vowel': 0.065669, 'loss_consonant': 0.058395}\n",
      "   52 | 0.000013 | 050176/160596 | 0.0122 | 1.6619 |\n",
      "val: {'recall': 0.973812, 'recall_grapheme': 0.958421, 'recall_vowel': 0.988973, 'recall_consonant': 0.989435, 'acc_grapheme': 0.964044, 'acc_vowel': 0.990856, 'acc_consonant': 0.989613, 'loss_grapheme': 0.156295, 'loss_vowel': 0.062834, 'loss_consonant': 0.054136}\n",
      "   52 | 0.000015 | 101376/160596 | 3.3333 | 1.6165 |\n",
      "val: {'recall': 0.972432, 'recall_grapheme': 0.957037, 'recall_vowel': 0.988593, 'recall_consonant': 0.98706, 'acc_grapheme': 0.963721, 'acc_vowel': 0.991154, 'acc_consonant': 0.989017, 'loss_grapheme': 0.161897, 'loss_vowel': 0.070985, 'loss_consonant': 0.063166}\n",
      "   52 | 0.000017 | 152576/160596 | 4.3551 | 1.6410 |\n",
      "val: {'recall': 0.972771, 'recall_grapheme': 0.957926, 'recall_vowel': 0.988419, 'recall_consonant': 0.986814, 'acc_grapheme': 0.963199, 'acc_vowel': 0.990881, 'acc_consonant': 0.989265, 'loss_grapheme': 0.160553, 'loss_vowel': 0.066756, 'loss_consonant': 0.058854}\n",
      "   53 | 0.000019 | 043264/160596 | 0.0240 | 1.7115 |\n",
      "val: {'recall': 0.973491, 'recall_grapheme': 0.95975, 'recall_vowel': 0.987926, 'recall_consonant': 0.986536, 'acc_grapheme': 0.963696, 'acc_vowel': 0.990632, 'acc_consonant': 0.98934, 'loss_grapheme': 0.161207, 'loss_vowel': 0.072696, 'loss_consonant': 0.060365}\n",
      "   53 | 0.000020 | 094464/160596 | 4.0603 | 1.7073 |\n",
      "val: {'recall': 0.9749, 'recall_grapheme': 0.960431, 'recall_vowel': 0.988023, 'recall_consonant': 0.990714, 'acc_grapheme': 0.963945, 'acc_vowel': 0.989986, 'acc_consonant': 0.989241, 'loss_grapheme': 0.176534, 'loss_vowel': 0.093412, 'loss_consonant': 0.07763}\n",
      "   53 | 0.000020 | 145664/160596 | 0.0408 | 1.7455 |\n",
      "val: {'recall': 0.973012, 'recall_grapheme': 0.956081, 'recall_vowel': 0.988921, 'recall_consonant': 0.990967, 'acc_grapheme': 0.963125, 'acc_vowel': 0.990955, 'acc_consonant': 0.988868, 'loss_grapheme': 0.161988, 'loss_vowel': 0.073211, 'loss_consonant': 0.061917}\n",
      "   54 | 0.000020 | 036352/160596 | 3.9699 | 1.6778 |\n",
      "val: {'recall': 0.974157, 'recall_grapheme': 0.960642, 'recall_vowel': 0.988995, 'recall_consonant': 0.986348, 'acc_grapheme': 0.964442, 'acc_vowel': 0.991005, 'acc_consonant': 0.989191, 'loss_grapheme': 0.160131, 'loss_vowel': 0.06862, 'loss_consonant': 0.060149}\n",
      "   54 | 0.000019 | 087552/160596 | 0.0263 | 1.7691 |\n",
      "val: {'recall': 0.972944, 'recall_grapheme': 0.958909, 'recall_vowel': 0.987374, 'recall_consonant': 0.986584, 'acc_grapheme': 0.963771, 'acc_vowel': 0.99093, 'acc_consonant': 0.988967, 'loss_grapheme': 0.151555, 'loss_vowel': 0.050537, 'loss_consonant': 0.048655}\n",
      "   54 | 0.000017 | 138752/160596 | 0.0390 | 1.6996 |\n",
      "val: {'recall': 0.974122, 'recall_grapheme': 0.959366, 'recall_vowel': 0.987715, 'recall_consonant': 0.990039, 'acc_grapheme': 0.962876, 'acc_vowel': 0.990309, 'acc_consonant': 0.988769, 'loss_grapheme': 0.155264, 'loss_vowel': 0.04916, 'loss_consonant': 0.049264}\n",
      "   55 | 0.000015 | 029440/160596 | 0.0127 | 1.8301 |\n",
      "val: {'recall': 0.974007, 'recall_grapheme': 0.960066, 'recall_vowel': 0.98899, 'recall_consonant': 0.986907, 'acc_grapheme': 0.964765, 'acc_vowel': 0.991055, 'acc_consonant': 0.989613, 'loss_grapheme': 0.159261, 'loss_vowel': 0.075568, 'loss_consonant': 0.061456}\n",
      "   55 | 0.000013 | 080640/160596 | 4.0169 | 1.7217 |\n",
      "val: {'recall': 0.976063, 'recall_grapheme': 0.962056, 'recall_vowel': 0.989464, 'recall_consonant': 0.990675, 'acc_grapheme': 0.965262, 'acc_vowel': 0.99098, 'acc_consonant': 0.989762, 'loss_grapheme': 0.183669, 'loss_vowel': 0.110787, 'loss_consonant': 0.077836}\n",
      "** saved\n",
      "   55 | 0.000011 | 131840/160596 | 0.0109 | 1.7014 |\n",
      "val: {'recall': 0.976377, 'recall_grapheme': 0.963393, 'recall_vowel': 0.989067, 'recall_consonant': 0.989657, 'acc_grapheme': 0.966231, 'acc_vowel': 0.991378, 'acc_consonant': 0.990036, 'loss_grapheme': 0.161512, 'loss_vowel': 0.078129, 'loss_consonant': 0.065165}\n",
      "** saved\n",
      "   56 | 0.000008 | 022528/160596 | 0.0288 | 1.6585 |\n",
      "val: {'recall': 0.975479, 'recall_grapheme': 0.961485, 'recall_vowel': 0.988802, 'recall_consonant': 0.990142, 'acc_grapheme': 0.966107, 'acc_vowel': 0.991353, 'acc_consonant': 0.989489, 'loss_grapheme': 0.150043, 'loss_vowel': 0.055319, 'loss_consonant': 0.052615}\n",
      "   56 | 0.000006 | 073728/160596 | 0.0101 | 1.5376 |\n",
      "val: {'recall': 0.975463, 'recall_grapheme': 0.96187, 'recall_vowel': 0.989626, 'recall_consonant': 0.988485, 'acc_grapheme': 0.966156, 'acc_vowel': 0.991576, 'acc_consonant': 0.989663, 'loss_grapheme': 0.147008, 'loss_vowel': 0.049529, 'loss_consonant': 0.047493}\n",
      "   56 | 0.000004 | 124928/160596 | 0.0120 | 1.5029 |\n",
      "val: {'recall': 0.975869, 'recall_grapheme': 0.961751, 'recall_vowel': 0.989698, 'recall_consonant': 0.990276, 'acc_grapheme': 0.96643, 'acc_vowel': 0.991701, 'acc_consonant': 0.989837, 'loss_grapheme': 0.14671, 'loss_vowel': 0.057583, 'loss_consonant': 0.052203}\n",
      "   57 | 0.000002 | 015616/160596 | 0.0037 | 1.2414 |\n",
      "val: {'recall': 0.976046, 'recall_grapheme': 0.962392, 'recall_vowel': 0.989328, 'recall_consonant': 0.990071, 'acc_grapheme': 0.966653, 'acc_vowel': 0.99185, 'acc_consonant': 0.989663, 'loss_grapheme': 0.144706, 'loss_vowel': 0.05075, 'loss_consonant': 0.048165}\n",
      "   57 | 0.000001 | 066816/160596 | 0.0198 | 1.5666 |\n",
      "val: {'recall': 0.975996, 'recall_grapheme': 0.962478, 'recall_vowel': 0.989129, 'recall_consonant': 0.989899, 'acc_grapheme': 0.966678, 'acc_vowel': 0.991775, 'acc_consonant': 0.989613, 'loss_grapheme': 0.143981, 'loss_vowel': 0.041003, 'loss_consonant': 0.043267}\n",
      "   57 | 0.000001 | 118016/160596 | 0.0043 | 1.5877 |\n",
      "val: {'recall': 0.976076, 'recall_grapheme': 0.962777, 'recall_vowel': 0.989301, 'recall_consonant': 0.989448, 'acc_grapheme': 0.967026, 'acc_vowel': 0.991725, 'acc_consonant': 0.989688, 'loss_grapheme': 0.141925, 'loss_vowel': 0.043088, 'loss_consonant': 0.043795}\n",
      "   58 | 0.000001 | 008704/160596 | 4.2583 | 1.9530 |\n",
      "val: {'recall': 0.97618, 'recall_grapheme': 0.962064, 'recall_vowel': 0.9902, 'recall_consonant': 0.990393, 'acc_grapheme': 0.966554, 'acc_vowel': 0.991949, 'acc_consonant': 0.989688, 'loss_grapheme': 0.162128, 'loss_vowel': 0.081898, 'loss_consonant': 0.06759}\n",
      "   58 | 0.000002 | 059904/160596 | 4.4489 | 1.7168 |\n",
      "val: {'recall': 0.975738, 'recall_grapheme': 0.962537, 'recall_vowel': 0.988975, 'recall_consonant': 0.988902, 'acc_grapheme': 0.966455, 'acc_vowel': 0.99175, 'acc_consonant': 0.989663, 'loss_grapheme': 0.165407, 'loss_vowel': 0.089685, 'loss_consonant': 0.071525}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58 | 0.000004 | 111104/160596 | 0.4774 | 1.6451 |\n",
      "val: {'recall': 0.975296, 'recall_grapheme': 0.961756, 'recall_vowel': 0.989341, 'recall_consonant': 0.98833, 'acc_grapheme': 0.966728, 'acc_vowel': 0.991626, 'acc_consonant': 0.989514, 'loss_grapheme': 0.143374, 'loss_vowel': 0.045783, 'loss_consonant': 0.044901}\n",
      "   59 | 0.000006 | 001792/160596 | 0.0050 | 2.9121 |\n",
      "val: {'recall': 0.974918, 'recall_grapheme': 0.960419, 'recall_vowel': 0.988291, 'recall_consonant': 0.990544, 'acc_grapheme': 0.965411, 'acc_vowel': 0.991452, 'acc_consonant': 0.989464, 'loss_grapheme': 0.16973, 'loss_vowel': 0.09056, 'loss_consonant': 0.073629}\n",
      "   59 | 0.000008 | 052992/160596 | 0.0170 | 1.4022 |\n",
      "val: {'recall': 0.976109, 'recall_grapheme': 0.96255, 'recall_vowel': 0.98917, 'recall_consonant': 0.990164, 'acc_grapheme': 0.966355, 'acc_vowel': 0.991477, 'acc_consonant': 0.989762, 'loss_grapheme': 0.148525, 'loss_vowel': 0.04409, 'loss_consonant': 0.044791}\n",
      "   59 | 0.000010 | 104192/160596 | 3.8658 | 1.4838 |\n",
      "val: {'recall': 0.975366, 'recall_grapheme': 0.960816, 'recall_vowel': 0.989109, 'recall_consonant': 0.990721, 'acc_grapheme': 0.966082, 'acc_vowel': 0.991651, 'acc_consonant': 0.989365, 'loss_grapheme': 0.151953, 'loss_vowel': 0.063647, 'loss_consonant': 0.05661}\n",
      "   59 | 0.000013 | 155392/160596 | 0.0074 | 1.5323 |\n",
      "val: {'recall': 0.974879, 'recall_grapheme': 0.960799, 'recall_vowel': 0.988585, 'recall_consonant': 0.989331, 'acc_grapheme': 0.96551, 'acc_vowel': 0.991452, 'acc_consonant': 0.989415, 'loss_grapheme': 0.147237, 'loss_vowel': 0.048446, 'loss_consonant': 0.046838}\n",
      "   60 | 0.000015 | 046080/160596 | 3.4553 | 1.6880 |\n",
      "val: {'recall': 0.97244, 'recall_grapheme': 0.956232, 'recall_vowel': 0.988376, 'recall_consonant': 0.988921, 'acc_grapheme': 0.963448, 'acc_vowel': 0.991229, 'acc_consonant': 0.989315, 'loss_grapheme': 0.1566, 'loss_vowel': 0.050001, 'loss_consonant': 0.049544}\n",
      "   60 | 0.000017 | 097280/160596 | 0.0096 | 1.5575 |\n",
      "val: {'recall': 0.974813, 'recall_grapheme': 0.96129, 'recall_vowel': 0.987416, 'recall_consonant': 0.989256, 'acc_grapheme': 0.964591, 'acc_vowel': 0.990707, 'acc_consonant': 0.989141, 'loss_grapheme': 0.153781, 'loss_vowel': 0.055309, 'loss_consonant': 0.05221}\n",
      "   60 | 0.000019 | 148480/160596 | 0.0442 | 1.6015 |\n",
      "val: {'recall': 0.974139, 'recall_grapheme': 0.960117, 'recall_vowel': 0.988381, 'recall_consonant': 0.987939, 'acc_grapheme': 0.963895, 'acc_vowel': 0.991079, 'acc_consonant': 0.989315, 'loss_grapheme': 0.161564, 'loss_vowel': 0.062951, 'loss_consonant': 0.057137}\n",
      "   61 | 0.000020 | 039168/160596 | 3.7858 | 1.3883 |\n",
      "val: {'recall': 0.974437, 'recall_grapheme': 0.958994, 'recall_vowel': 0.989679, 'recall_consonant': 0.990079, 'acc_grapheme': 0.962653, 'acc_vowel': 0.991104, 'acc_consonant': 0.989613, 'loss_grapheme': 0.161662, 'loss_vowel': 0.063006, 'loss_consonant': 0.054144}\n",
      "   61 | 0.000020 | 090368/160596 | 0.8051 | 1.5669 |\n",
      "val: {'recall': 0.974141, 'recall_grapheme': 0.958152, 'recall_vowel': 0.989646, 'recall_consonant': 0.990616, 'acc_grapheme': 0.963498, 'acc_vowel': 0.99093, 'acc_consonant': 0.989141, 'loss_grapheme': 0.160024, 'loss_vowel': 0.068949, 'loss_consonant': 0.060467}\n",
      "   61 | 0.000020 | 141568/160596 | 0.0274 | 1.6143 |\n",
      "val: {'recall': 0.975602, 'recall_grapheme': 0.962058, 'recall_vowel': 0.988964, 'recall_consonant': 0.989327, 'acc_grapheme': 0.964516, 'acc_vowel': 0.990657, 'acc_consonant': 0.98934, 'loss_grapheme': 0.160495, 'loss_vowel': 0.06557, 'loss_consonant': 0.056841}\n",
      "   62 | 0.000019 | 032256/160596 | 0.0071 | 1.5247 |\n",
      "val: {'recall': 0.974732, 'recall_grapheme': 0.960879, 'recall_vowel': 0.987899, 'recall_consonant': 0.989271, 'acc_grapheme': 0.964069, 'acc_vowel': 0.990806, 'acc_consonant': 0.989265, 'loss_grapheme': 0.166674, 'loss_vowel': 0.078336, 'loss_consonant': 0.065514}\n",
      "   62 | 0.000017 | 083456/160596 | 0.0406 | 1.6351 |\n",
      "val: {'recall': 0.97439, 'recall_grapheme': 0.960115, 'recall_vowel': 0.989204, 'recall_consonant': 0.988127, 'acc_grapheme': 0.964218, 'acc_vowel': 0.990955, 'acc_consonant': 0.989564, 'loss_grapheme': 0.161937, 'loss_vowel': 0.066348, 'loss_consonant': 0.059687}\n",
      "   62 | 0.000015 | 134656/160596 | 0.0229 | 1.6428 |\n",
      "val: {'recall': 0.97429, 'recall_grapheme': 0.960608, 'recall_vowel': 0.987703, 'recall_consonant': 0.98824, 'acc_grapheme': 0.964989, 'acc_vowel': 0.991204, 'acc_consonant': 0.989539, 'loss_grapheme': 0.152641, 'loss_vowel': 0.056802, 'loss_consonant': 0.052367}\n",
      "   63 | 0.000013 | 025344/160596 | 0.0203 | 1.7087 |\n",
      "val: {'recall': 0.975578, 'recall_grapheme': 0.961304, 'recall_vowel': 0.98909, 'recall_consonant': 0.990616, 'acc_grapheme': 0.965386, 'acc_vowel': 0.991229, 'acc_consonant': 0.989787, 'loss_grapheme': 0.149063, 'loss_vowel': 0.050966, 'loss_consonant': 0.049788}\n",
      "   63 | 0.000011 | 076544/160596 | 0.0072 | 1.6607 |\n",
      "val: {'recall': 0.974934, 'recall_grapheme': 0.960879, 'recall_vowel': 0.988872, 'recall_consonant': 0.989105, 'acc_grapheme': 0.965933, 'acc_vowel': 0.991427, 'acc_consonant': 0.989738, 'loss_grapheme': 0.1498, 'loss_vowel': 0.055148, 'loss_consonant': 0.052382}\n",
      "   63 | 0.000008 | 127744/160596 | 0.0073 | 1.6774 |\n",
      "val: {'recall': 0.975049, 'recall_grapheme': 0.961695, 'recall_vowel': 0.988161, 'recall_consonant': 0.988645, 'acc_grapheme': 0.967026, 'acc_vowel': 0.991378, 'acc_consonant': 0.989936, 'loss_grapheme': 0.152944, 'loss_vowel': 0.065666, 'loss_consonant': 0.057911}\n",
      "   64 | 0.000006 | 018432/160596 | 1.0155 | 1.8918 |\n",
      "val: {'recall': 0.975818, 'recall_grapheme': 0.962032, 'recall_vowel': 0.988895, 'recall_consonant': 0.990313, 'acc_grapheme': 0.967076, 'acc_vowel': 0.991725, 'acc_consonant': 0.989986, 'loss_grapheme': 0.156695, 'loss_vowel': 0.069008, 'loss_consonant': 0.060066}\n",
      "   64 | 0.000004 | 069632/160596 | 3.0793 | 1.7632 |\n",
      "val: {'recall': 0.9767, 'recall_grapheme': 0.96321, 'recall_vowel': 0.98959, 'recall_consonant': 0.990789, 'acc_grapheme': 0.967598, 'acc_vowel': 0.99185, 'acc_consonant': 0.989887, 'loss_grapheme': 0.166559, 'loss_vowel': 0.087938, 'loss_consonant': 0.069579}\n",
      "** saved\n",
      "   64 | 0.000002 | 120832/160596 | 2.7900 | 1.6896 |\n",
      "val: {'recall': 0.976185, 'recall_grapheme': 0.9623, 'recall_vowel': 0.989675, 'recall_consonant': 0.990466, 'acc_grapheme': 0.967523, 'acc_vowel': 0.991775, 'acc_consonant': 0.989762, 'loss_grapheme': 0.150737, 'loss_vowel': 0.062901, 'loss_consonant': 0.055758}\n",
      "   65 | 0.000001 | 011520/160596 | 0.0048 | 1.5391 |\n",
      "val: {'recall': 0.976131, 'recall_grapheme': 0.962104, 'recall_vowel': 0.989901, 'recall_consonant': 0.990417, 'acc_grapheme': 0.967548, 'acc_vowel': 0.991924, 'acc_consonant': 0.989762, 'loss_grapheme': 0.145722, 'loss_vowel': 0.05438, 'loss_consonant': 0.049529}\n",
      "   65 | 0.000001 | 062720/160596 | 3.4832 | 1.4412 |\n",
      "val: {'recall': 0.976658, 'recall_grapheme': 0.963215, 'recall_vowel': 0.989734, 'recall_consonant': 0.990468, 'acc_grapheme': 0.967374, 'acc_vowel': 0.9918, 'acc_consonant': 0.990085, 'loss_grapheme': 0.142863, 'loss_vowel': 0.047839, 'loss_consonant': 0.046089}\n",
      "   65 | 0.000001 | 113920/160596 | 0.0160 | 1.4605 |\n",
      "val: {'recall': 0.976872, 'recall_grapheme': 0.963419, 'recall_vowel': 0.990364, 'recall_consonant': 0.990286, 'acc_grapheme': 0.967896, 'acc_vowel': 0.991999, 'acc_consonant': 0.990011, 'loss_grapheme': 0.14306, 'loss_vowel': 0.04337, 'loss_consonant': 0.043577}\n",
      "** saved\n",
      "   66 | 0.000002 | 004608/160596 | 0.0051 | 1.5290 |\n",
      "val: {'recall': 0.976413, 'recall_grapheme': 0.963431, 'recall_vowel': 0.988663, 'recall_consonant': 0.990129, 'acc_grapheme': 0.967796, 'acc_vowel': 0.991651, 'acc_consonant': 0.989862, 'loss_grapheme': 0.145297, 'loss_vowel': 0.05083, 'loss_consonant': 0.048097}\n",
      "   66 | 0.000004 | 055808/160596 | 3.0516 | 1.6620 |\n",
      "val: {'recall': 0.976176, 'recall_grapheme': 0.962447, 'recall_vowel': 0.989563, 'recall_consonant': 0.990246, 'acc_grapheme': 0.966952, 'acc_vowel': 0.991999, 'acc_consonant': 0.989738, 'loss_grapheme': 0.162495, 'loss_vowel': 0.076795, 'loss_consonant': 0.063146}\n",
      "   66 | 0.000006 | 107008/160596 | 4.7852 | 1.6749 |\n",
      "val: {'recall': 0.976312, 'recall_grapheme': 0.962769, 'recall_vowel': 0.989466, 'recall_consonant': 0.990246, 'acc_grapheme': 0.966952, 'acc_vowel': 0.991676, 'acc_consonant': 0.989812, 'loss_grapheme': 0.180419, 'loss_vowel': 0.095618, 'loss_consonant': 0.074434}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   66 | 0.000008 | 158208/160596 | 0.5671 | 1.6283 |\n",
      "val: {'recall': 0.975643, 'recall_grapheme': 0.962965, 'recall_vowel': 0.989067, 'recall_consonant': 0.987574, 'acc_grapheme': 0.966132, 'acc_vowel': 0.991427, 'acc_consonant': 0.989688, 'loss_grapheme': 0.151541, 'loss_vowel': 0.062035, 'loss_consonant': 0.055042}\n",
      "   67 | 0.000011 | 048896/160596 | 1.3668 | 1.5910 |\n",
      "val: {'recall': 0.975496, 'recall_grapheme': 0.961085, 'recall_vowel': 0.989272, 'recall_consonant': 0.990542, 'acc_grapheme': 0.966728, 'acc_vowel': 0.991527, 'acc_consonant': 0.990259, 'loss_grapheme': 0.178617, 'loss_vowel': 0.091258, 'loss_consonant': 0.073821}\n",
      "   67 | 0.000013 | 100096/160596 | 0.0080 | 1.6480 |\n",
      "val: {'recall': 0.975715, 'recall_grapheme': 0.961871, 'recall_vowel': 0.989324, 'recall_consonant': 0.989795, 'acc_grapheme': 0.966132, 'acc_vowel': 0.991477, 'acc_consonant': 0.989514, 'loss_grapheme': 0.166749, 'loss_vowel': 0.079406, 'loss_consonant': 0.06064}\n",
      "   67 | 0.000015 | 151296/160596 | 0.0317 | 1.5372 |\n",
      "val: {'recall': 0.973125, 'recall_grapheme': 0.957881, 'recall_vowel': 0.987885, 'recall_consonant': 0.988855, 'acc_grapheme': 0.963547, 'acc_vowel': 0.990607, 'acc_consonant': 0.98934, 'loss_grapheme': 0.159046, 'loss_vowel': 0.060071, 'loss_consonant': 0.052776}\n",
      "   68 | 0.000017 | 041984/160596 | 0.0396 | 1.5437 |\n",
      "val: {'recall': 0.974588, 'recall_grapheme': 0.960915, 'recall_vowel': 0.989028, 'recall_consonant': 0.987493, 'acc_grapheme': 0.965436, 'acc_vowel': 0.991253, 'acc_consonant': 0.989365, 'loss_grapheme': 0.150476, 'loss_vowel': 0.052695, 'loss_consonant': 0.048227}\n",
      "   68 | 0.000019 | 093184/160596 | 0.0341 | 1.6050 |\n",
      "val: {'recall': 0.973371, 'recall_grapheme': 0.957982, 'recall_vowel': 0.986772, 'recall_consonant': 0.990745, 'acc_grapheme': 0.964343, 'acc_vowel': 0.990881, 'acc_consonant': 0.988719, 'loss_grapheme': 0.152515, 'loss_vowel': 0.058482, 'loss_consonant': 0.057743}\n",
      "   68 | 0.000020 | 144384/160596 | 4.3374 | 1.5950 |\n",
      "val: {'recall': 0.974021, 'recall_grapheme': 0.960488, 'recall_vowel': 0.988221, 'recall_consonant': 0.986885, 'acc_grapheme': 0.964989, 'acc_vowel': 0.991079, 'acc_consonant': 0.989141, 'loss_grapheme': 0.17919, 'loss_vowel': 0.089141, 'loss_consonant': 0.07335}\n",
      "   69 | 0.000020 | 035072/160596 | 4.1703 | 1.6807 |\n",
      "val: {'recall': 0.97405, 'recall_grapheme': 0.959468, 'recall_vowel': 0.989147, 'recall_consonant': 0.988116, 'acc_grapheme': 0.964218, 'acc_vowel': 0.99103, 'acc_consonant': 0.989092, 'loss_grapheme': 0.166885, 'loss_vowel': 0.081221, 'loss_consonant': 0.063376}\n",
      "   69 | 0.000020 | 086272/160596 | 0.0366 | 1.7353 |\n",
      "val: {'recall': 0.973469, 'recall_grapheme': 0.9596, 'recall_vowel': 0.986857, 'recall_consonant': 0.987818, 'acc_grapheme': 0.964765, 'acc_vowel': 0.990707, 'acc_consonant': 0.990036, 'loss_grapheme': 0.151965, 'loss_vowel': 0.059942, 'loss_consonant': 0.051562}\n",
      "   69 | 0.000019 | 137472/160596 | 2.8695 | 1.6758 |\n",
      "val: {'recall': 0.974309, 'recall_grapheme': 0.960274, 'recall_vowel': 0.988339, 'recall_consonant': 0.988351, 'acc_grapheme': 0.964864, 'acc_vowel': 0.99103, 'acc_consonant': 0.989141, 'loss_grapheme': 0.157233, 'loss_vowel': 0.06553, 'loss_consonant': 0.057808}\n",
      "   70 | 0.000017 | 028160/160596 | 2.9425 | 1.5529 |\n",
      "val: {'recall': 0.975099, 'recall_grapheme': 0.960743, 'recall_vowel': 0.989186, 'recall_consonant': 0.989725, 'acc_grapheme': 0.964914, 'acc_vowel': 0.991427, 'acc_consonant': 0.989713, 'loss_grapheme': 0.164559, 'loss_vowel': 0.074015, 'loss_consonant': 0.064075}\n",
      "   70 | 0.000015 | 079360/160596 | 4.6531 | 1.6611 |\n",
      "val: {'recall': 0.973552, 'recall_grapheme': 0.959309, 'recall_vowel': 0.987772, 'recall_consonant': 0.987816, 'acc_grapheme': 0.965759, 'acc_vowel': 0.991179, 'acc_consonant': 0.989589, 'loss_grapheme': 0.15419, 'loss_vowel': 0.063791, 'loss_consonant': 0.057286}\n",
      "   70 | 0.000013 | 130560/160596 | 2.9259 | 1.7035 |\n",
      "val: {'recall': 0.975546, 'recall_grapheme': 0.961633, 'recall_vowel': 0.989634, 'recall_consonant': 0.989283, 'acc_grapheme': 0.96561, 'acc_vowel': 0.991204, 'acc_consonant': 0.989787, 'loss_grapheme': 0.155077, 'loss_vowel': 0.063507, 'loss_consonant': 0.055497}\n",
      "   71 | 0.000011 | 021248/160596 | 0.0049 | 1.8769 |\n",
      "val: {'recall': 0.975814, 'recall_grapheme': 0.962734, 'recall_vowel': 0.988938, 'recall_consonant': 0.98885, 'acc_grapheme': 0.967001, 'acc_vowel': 0.991601, 'acc_consonant': 0.989439, 'loss_grapheme': 0.149915, 'loss_vowel': 0.059964, 'loss_consonant': 0.053163}\n",
      "   71 | 0.000008 | 072448/160596 | 2.9549 | 1.8159 |\n",
      "val: {'recall': 0.975574, 'recall_grapheme': 0.961472, 'recall_vowel': 0.989333, 'recall_consonant': 0.990022, 'acc_grapheme': 0.966206, 'acc_vowel': 0.991502, 'acc_consonant': 0.989439, 'loss_grapheme': 0.164317, 'loss_vowel': 0.079153, 'loss_consonant': 0.066664}\n",
      "   71 | 0.000006 | 123648/160596 | 2.8452 | 1.7563 |\n",
      "val: {'recall': 0.976426, 'recall_grapheme': 0.963862, 'recall_vowel': 0.989042, 'recall_consonant': 0.988938, 'acc_grapheme': 0.967796, 'acc_vowel': 0.991651, 'acc_consonant': 0.989489, 'loss_grapheme': 0.157813, 'loss_vowel': 0.070135, 'loss_consonant': 0.060614}\n",
      "   72 | 0.000004 | 014336/160596 | 2.0009 | 1.5390 |\n",
      "val: {'recall': 0.976024, 'recall_grapheme': 0.963764, 'recall_vowel': 0.988957, 'recall_consonant': 0.987609, 'acc_grapheme': 0.967349, 'acc_vowel': 0.991651, 'acc_consonant': 0.990036, 'loss_grapheme': 0.152323, 'loss_vowel': 0.070909, 'loss_consonant': 0.057963}\n",
      "   72 | 0.000002 | 065536/160596 | 0.0032 | 1.5071 |\n",
      "val: {'recall': 0.975511, 'recall_grapheme': 0.962273, 'recall_vowel': 0.988909, 'recall_consonant': 0.988589, 'acc_grapheme': 0.967647, 'acc_vowel': 0.991601, 'acc_consonant': 0.990036, 'loss_grapheme': 0.141986, 'loss_vowel': 0.046629, 'loss_consonant': 0.045607}\n",
      "   72 | 0.000001 | 116736/160596 | 0.0040 | 1.5298 |\n",
      "val: {'recall': 0.975984, 'recall_grapheme': 0.962598, 'recall_vowel': 0.989044, 'recall_consonant': 0.989695, 'acc_grapheme': 0.967573, 'acc_vowel': 0.991651, 'acc_consonant': 0.989961, 'loss_grapheme': 0.150369, 'loss_vowel': 0.069982, 'loss_consonant': 0.058696}\n",
      "   73 | 0.000001 | 007424/160596 | 4.5568 | 1.9188 |\n",
      "val: {'recall': 0.976045, 'recall_grapheme': 0.963043, 'recall_vowel': 0.988931, 'recall_consonant': 0.989164, 'acc_grapheme': 0.967473, 'acc_vowel': 0.991576, 'acc_consonant': 0.989961, 'loss_grapheme': 0.152538, 'loss_vowel': 0.071696, 'loss_consonant': 0.059986}\n",
      "   73 | 0.000001 | 058624/160596 | 2.9224 | 1.5715 |\n",
      "val: {'recall': 0.976225, 'recall_grapheme': 0.963498, 'recall_vowel': 0.989181, 'recall_consonant': 0.988721, 'acc_grapheme': 0.968119, 'acc_vowel': 0.991725, 'acc_consonant': 0.989812, 'loss_grapheme': 0.14415, 'loss_vowel': 0.05433, 'loss_consonant': 0.050151}\n",
      "   73 | 0.000002 | 109824/160596 | 0.0028 | 1.4966 |\n",
      "val: {'recall': 0.976008, 'recall_grapheme': 0.963025, 'recall_vowel': 0.988989, 'recall_consonant': 0.988993, 'acc_grapheme': 0.968095, 'acc_vowel': 0.99175, 'acc_consonant': 0.989936, 'loss_grapheme': 0.143319, 'loss_vowel': 0.052221, 'loss_consonant': 0.04892}\n",
      "   74 | 0.000004 | 000512/160596 | 0.0028 | 1.3967 |\n",
      "val: {'recall': 0.976461, 'recall_grapheme': 0.963643, 'recall_vowel': 0.988642, 'recall_consonant': 0.989916, 'acc_grapheme': 0.968269, 'acc_vowel': 0.991452, 'acc_consonant': 0.990185, 'loss_grapheme': 0.145301, 'loss_vowel': 0.057369, 'loss_consonant': 0.051825}\n",
      "   74 | 0.000006 | 051712/160596 | 0.0108 | 1.5495 |\n",
      "val: {'recall': 0.976042, 'recall_grapheme': 0.962509, 'recall_vowel': 0.989475, 'recall_consonant': 0.989677, 'acc_grapheme': 0.967374, 'acc_vowel': 0.991651, 'acc_consonant': 0.989738, 'loss_grapheme': 0.16645, 'loss_vowel': 0.080996, 'loss_consonant': 0.06639}\n",
      "   74 | 0.000008 | 102912/160596 | 0.0257 | 1.5537 |\n",
      "val: {'recall': 0.975918, 'recall_grapheme': 0.963267, 'recall_vowel': 0.988085, 'recall_consonant': 0.989055, 'acc_grapheme': 0.967349, 'acc_vowel': 0.991229, 'acc_consonant': 0.989837, 'loss_grapheme': 0.145534, 'loss_vowel': 0.044324, 'loss_consonant': 0.044191}\n",
      "   74 | 0.000010 | 154112/160596 | 4.3402 | 1.5633 |\n",
      "val: {'recall': 0.975217, 'recall_grapheme': 0.96132, 'recall_vowel': 0.989154, 'recall_consonant': 0.989075, 'acc_grapheme': 0.96725, 'acc_vowel': 0.991402, 'acc_consonant': 0.99016, 'loss_grapheme': 0.147958, 'loss_vowel': 0.053488, 'loss_consonant': 0.049464}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   75 | 0.000013 | 044800/160596 | 3.0360 | 1.6371 |\n",
      "val: {'recall': 0.975421, 'recall_grapheme': 0.962109, 'recall_vowel': 0.987159, 'recall_consonant': 0.990308, 'acc_grapheme': 0.966902, 'acc_vowel': 0.991303, 'acc_consonant': 0.989762, 'loss_grapheme': 0.155436, 'loss_vowel': 0.064313, 'loss_consonant': 0.057717}\n",
      "   75 | 0.000015 | 096000/160596 | 0.0048 | 1.6102 |\n",
      "val: {'recall': 0.975294, 'recall_grapheme': 0.960483, 'recall_vowel': 0.989598, 'recall_consonant': 0.990612, 'acc_grapheme': 0.96561, 'acc_vowel': 0.99175, 'acc_consonant': 0.989738, 'loss_grapheme': 0.158936, 'loss_vowel': 0.061328, 'loss_consonant': 0.056324}\n",
      "   75 | 0.000017 | 147200/160596 | 0.0098 | 1.5834 |\n",
      "val: {'recall': 0.974764, 'recall_grapheme': 0.960743, 'recall_vowel': 0.988543, 'recall_consonant': 0.989026, 'acc_grapheme': 0.965237, 'acc_vowel': 0.991204, 'acc_consonant': 0.989738, 'loss_grapheme': 0.163765, 'loss_vowel': 0.071929, 'loss_consonant': 0.061818}\n",
      "   76 | 0.000019 | 037888/160596 | 4.8343 | 1.8405 |\n",
      "val: {'recall': 0.974081, 'recall_grapheme': 0.959334, 'recall_vowel': 0.988625, 'recall_consonant': 0.989033, 'acc_grapheme': 0.966082, 'acc_vowel': 0.991427, 'acc_consonant': 0.989837, 'loss_grapheme': 0.15839, 'loss_vowel': 0.066109, 'loss_consonant': 0.058422}\n",
      "   76 | 0.000020 | 089088/160596 | 0.0172 | 1.6356 |\n",
      "val: {'recall': 0.97483, 'recall_grapheme': 0.960555, 'recall_vowel': 0.988063, 'recall_consonant': 0.99015, 'acc_grapheme': 0.964541, 'acc_vowel': 0.990085, 'acc_consonant': 0.989912, 'loss_grapheme': 0.158909, 'loss_vowel': 0.06605, 'loss_consonant': 0.056948}\n",
      "   76 | 0.000020 | 140288/160596 | 0.0111 | 1.6042 |\n",
      "val: {'recall': 0.975311, 'recall_grapheme': 0.962839, 'recall_vowel': 0.98801, 'recall_consonant': 0.987554, 'acc_grapheme': 0.964591, 'acc_vowel': 0.991055, 'acc_consonant': 0.988942, 'loss_grapheme': 0.165709, 'loss_vowel': 0.070982, 'loss_consonant': 0.060119}\n",
      "   77 | 0.000020 | 030976/160596 | 0.0275 | 1.6968 |\n",
      "val: {'recall': 0.972746, 'recall_grapheme': 0.957739, 'recall_vowel': 0.988583, 'recall_consonant': 0.986921, 'acc_grapheme': 0.964566, 'acc_vowel': 0.991005, 'acc_consonant': 0.98929, 'loss_grapheme': 0.157038, 'loss_vowel': 0.056693, 'loss_consonant': 0.053997}\n",
      "   77 | 0.000019 | 082176/160596 | 3.4515 | 1.6716 |\n",
      "val: {'recall': 0.974881, 'recall_grapheme': 0.960633, 'recall_vowel': 0.990078, 'recall_consonant': 0.98818, 'acc_grapheme': 0.965535, 'acc_vowel': 0.991452, 'acc_consonant': 0.989315, 'loss_grapheme': 0.166756, 'loss_vowel': 0.079437, 'loss_consonant': 0.06331}\n",
      "   77 | 0.000017 | 133376/160596 | 0.0143 | 1.6714 |\n",
      "val: {'recall': 0.974295, 'recall_grapheme': 0.960713, 'recall_vowel': 0.987608, 'recall_consonant': 0.988147, 'acc_grapheme': 0.965659, 'acc_vowel': 0.990856, 'acc_consonant': 0.989539, 'loss_grapheme': 0.155364, 'loss_vowel': 0.063872, 'loss_consonant': 0.056693}\n",
      "   78 | 0.000015 | 024064/160596 | 4.1567 | 1.6706 |\n",
      "val: {'recall': 0.975008, 'recall_grapheme': 0.960758, 'recall_vowel': 0.988687, 'recall_consonant': 0.989826, 'acc_grapheme': 0.965983, 'acc_vowel': 0.991402, 'acc_consonant': 0.98929, 'loss_grapheme': 0.159752, 'loss_vowel': 0.071247, 'loss_consonant': 0.061963}\n",
      "   78 | 0.000013 | 075264/160596 | 2.2079 | 1.6886 |\n",
      "val: {'recall': 0.975586, 'recall_grapheme': 0.962395, 'recall_vowel': 0.989464, 'recall_consonant': 0.988091, 'acc_grapheme': 0.966803, 'acc_vowel': 0.991626, 'acc_consonant': 0.989862, 'loss_grapheme': 0.171026, 'loss_vowel': 0.087483, 'loss_consonant': 0.070387}\n",
      "   78 | 0.000011 | 126464/160596 | 4.0410 | 1.6633 |\n",
      "val: {'recall': 0.975622, 'recall_grapheme': 0.962839, 'recall_vowel': 0.988161, 'recall_consonant': 0.988647, 'acc_grapheme': 0.967424, 'acc_vowel': 0.991427, 'acc_consonant': 0.989762, 'loss_grapheme': 0.154545, 'loss_vowel': 0.068986, 'loss_consonant': 0.060217}\n",
      "   79 | 0.000008 | 017152/160596 | 0.0052 | 1.6194 |\n",
      "val: {'recall': 0.976162, 'recall_grapheme': 0.962835, 'recall_vowel': 0.988989, 'recall_consonant': 0.989988, 'acc_grapheme': 0.967324, 'acc_vowel': 0.991725, 'acc_consonant': 0.990061, 'loss_grapheme': 0.145857, 'loss_vowel': 0.047207, 'loss_consonant': 0.047777}\n",
      "   79 | 0.000006 | 068352/160596 | 0.0055 | 1.5064 |\n",
      "val: {'recall': 0.976755, 'recall_grapheme': 0.964446, 'recall_vowel': 0.989405, 'recall_consonant': 0.988721, 'acc_grapheme': 0.967821, 'acc_vowel': 0.991949, 'acc_consonant': 0.989887, 'loss_grapheme': 0.147989, 'loss_vowel': 0.054817, 'loss_consonant': 0.051377}\n",
      "   79 | 0.000004 | 119552/160596 | 0.0093 | 1.5542 |\n",
      "val: {'recall': 0.975732, 'recall_grapheme': 0.962004, 'recall_vowel': 0.989903, 'recall_consonant': 0.989016, 'acc_grapheme': 0.967126, 'acc_vowel': 0.992098, 'acc_consonant': 0.990235, 'loss_grapheme': 0.144571, 'loss_vowel': 0.045314, 'loss_consonant': 0.046204}\n",
      "   80 | 0.000002 | 010240/160596 | 2.9673 | 1.3029 |\n",
      "val: {'recall': 0.976319, 'recall_grapheme': 0.963528, 'recall_vowel': 0.989183, 'recall_consonant': 0.989037, 'acc_grapheme': 0.967921, 'acc_vowel': 0.991924, 'acc_consonant': 0.990259, 'loss_grapheme': 0.147728, 'loss_vowel': 0.058057, 'loss_consonant': 0.053293}\n",
      "   80 | 0.000001 | 061440/160596 | 1.8185 | 1.4345 |\n",
      "val: {'recall': 0.975728, 'recall_grapheme': 0.962225, 'recall_vowel': 0.9894, 'recall_consonant': 0.989061, 'acc_grapheme': 0.967747, 'acc_vowel': 0.992024, 'acc_consonant': 0.990384, 'loss_grapheme': 0.146262, 'loss_vowel': 0.055955, 'loss_consonant': 0.051151}\n",
      "   80 | 0.000001 | 112640/160596 | 0.0047 | 1.4332 |\n",
      "val: {'recall': 0.976511, 'recall_grapheme': 0.963496, 'recall_vowel': 0.989859, 'recall_consonant': 0.989193, 'acc_grapheme': 0.968318, 'acc_vowel': 0.992024, 'acc_consonant': 0.99021, 'loss_grapheme': 0.143819, 'loss_vowel': 0.048968, 'loss_consonant': 0.047853}\n",
      "   81 | 0.000001 | 003328/160596 | 3.0183 | 1.0699 |\n",
      "val: {'recall': 0.976309, 'recall_grapheme': 0.963187, 'recall_vowel': 0.989622, 'recall_consonant': 0.989238, 'acc_grapheme': 0.967921, 'acc_vowel': 0.992049, 'acc_consonant': 0.990433, 'loss_grapheme': 0.148554, 'loss_vowel': 0.058576, 'loss_consonant': 0.052797}\n",
      "   81 | 0.000002 | 054528/160596 | 2.9480 | 1.5803 |\n",
      "val: {'recall': 0.976688, 'recall_grapheme': 0.964104, 'recall_vowel': 0.989837, 'recall_consonant': 0.988708, 'acc_grapheme': 0.96879, 'acc_vowel': 0.992123, 'acc_consonant': 0.99016, 'loss_grapheme': 0.145328, 'loss_vowel': 0.055368, 'loss_consonant': 0.05123}\n",
      "   81 | 0.000004 | 105728/160596 | 1.9598 | 1.7174 |\n",
      "val: {'recall': 0.976817, 'recall_grapheme': 0.963317, 'recall_vowel': 0.989994, 'recall_consonant': 0.990638, 'acc_grapheme': 0.967697, 'acc_vowel': 0.992098, 'acc_consonant': 0.990384, 'loss_grapheme': 0.171774, 'loss_vowel': 0.085722, 'loss_consonant': 0.069633}\n",
      "   81 | 0.000006 | 156928/160596 | 4.0454 | 1.6269 |\n",
      "val: {'recall': 0.975817, 'recall_grapheme': 0.962693, 'recall_vowel': 0.989235, 'recall_consonant': 0.988648, 'acc_grapheme': 0.967324, 'acc_vowel': 0.991775, 'acc_consonant': 0.989812, 'loss_grapheme': 0.14738, 'loss_vowel': 0.052306, 'loss_consonant': 0.051555}\n",
      "   82 | 0.000008 | 047616/160596 | 0.0035 | 1.4531 |\n",
      "val: {'recall': 0.976745, 'recall_grapheme': 0.964062, 'recall_vowel': 0.989482, 'recall_consonant': 0.989372, 'acc_grapheme': 0.967647, 'acc_vowel': 0.992073, 'acc_consonant': 0.990433, 'loss_grapheme': 0.149751, 'loss_vowel': 0.06329, 'loss_consonant': 0.055063}\n",
      "   82 | 0.000010 | 098816/160596 | 2.7097 | 1.6418 |\n",
      "val: {'recall': 0.975907, 'recall_grapheme': 0.963066, 'recall_vowel': 0.989861, 'recall_consonant': 0.987634, 'acc_grapheme': 0.967796, 'acc_vowel': 0.99185, 'acc_consonant': 0.990185, 'loss_grapheme': 0.155418, 'loss_vowel': 0.062718, 'loss_consonant': 0.058442}\n",
      "   82 | 0.000013 | 150016/160596 | 3.4555 | 1.6747 |\n",
      "val: {'recall': 0.97598, 'recall_grapheme': 0.962414, 'recall_vowel': 0.989184, 'recall_consonant': 0.989907, 'acc_grapheme': 0.967225, 'acc_vowel': 0.992073, 'acc_consonant': 0.990384, 'loss_grapheme': 0.153548, 'loss_vowel': 0.069114, 'loss_consonant': 0.056873}\n",
      "   83 | 0.000015 | 040704/160596 | 0.0256 | 1.5377 |\n",
      "val: {'recall': 0.975236, 'recall_grapheme': 0.960874, 'recall_vowel': 0.989573, 'recall_consonant': 0.989625, 'acc_grapheme': 0.966877, 'acc_vowel': 0.991552, 'acc_consonant': 0.990259, 'loss_grapheme': 0.165059, 'loss_vowel': 0.075422, 'loss_consonant': 0.061368}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 | 0.000017 | 091904/160596 | 0.0048 | 1.5017 |\n",
      "val: {'recall': 0.975384, 'recall_grapheme': 0.961853, 'recall_vowel': 0.989048, 'recall_consonant': 0.988781, 'acc_grapheme': 0.965983, 'acc_vowel': 0.991527, 'acc_consonant': 0.989589, 'loss_grapheme': 0.153, 'loss_vowel': 0.049288, 'loss_consonant': 0.050446}\n",
      "   83 | 0.000019 | 143104/160596 | 0.0098 | 1.5397 |\n",
      "val: {'recall': 0.976094, 'recall_grapheme': 0.962027, 'recall_vowel': 0.989173, 'recall_consonant': 0.991149, 'acc_grapheme': 0.966504, 'acc_vowel': 0.991452, 'acc_consonant': 0.990036, 'loss_grapheme': 0.156366, 'loss_vowel': 0.064007, 'loss_consonant': 0.057641}\n",
      "   84 | 0.000020 | 033792/160596 | 0.0065 | 1.8177 |\n",
      "val: {'recall': 0.974757, 'recall_grapheme': 0.962804, 'recall_vowel': 0.986392, 'recall_consonant': 0.987028, 'acc_grapheme': 0.966927, 'acc_vowel': 0.991179, 'acc_consonant': 0.989738, 'loss_grapheme': 0.148996, 'loss_vowel': 0.050577, 'loss_consonant': 0.050779}\n",
      "   84 | 0.000020 | 084992/160596 | 0.0070 | 1.7405 |\n",
      "val: {'recall': 0.974018, 'recall_grapheme': 0.961301, 'recall_vowel': 0.986645, 'recall_consonant': 0.986826, 'acc_grapheme': 0.966952, 'acc_vowel': 0.99093, 'acc_consonant': 0.989589, 'loss_grapheme': 0.14978, 'loss_vowel': 0.057221, 'loss_consonant': 0.052293}\n",
      "   84 | 0.000020 | 136192/160596 | 3.5899 | 1.6805 |\n",
      "val: {'recall': 0.972462, 'recall_grapheme': 0.958324, 'recall_vowel': 0.987352, 'recall_consonant': 0.985848, 'acc_grapheme': 0.965486, 'acc_vowel': 0.99103, 'acc_consonant': 0.988793, 'loss_grapheme': 0.174545, 'loss_vowel': 0.089439, 'loss_consonant': 0.07313}\n",
      "   85 | 0.000019 | 026880/160596 | 1.3603 | 1.4502 |\n",
      "val: {'recall': 0.974634, 'recall_grapheme': 0.959622, 'recall_vowel': 0.989382, 'recall_consonant': 0.989908, 'acc_grapheme': 0.965361, 'acc_vowel': 0.991527, 'acc_consonant': 0.989166, 'loss_grapheme': 0.156764, 'loss_vowel': 0.061623, 'loss_consonant': 0.056204}\n",
      "   85 | 0.000017 | 078080/160596 | 0.0110 | 1.5425 |\n",
      "val: {'recall': 0.975115, 'recall_grapheme': 0.963215, 'recall_vowel': 0.988022, 'recall_consonant': 0.986009, 'acc_grapheme': 0.966653, 'acc_vowel': 0.991378, 'acc_consonant': 0.988942, 'loss_grapheme': 0.154642, 'loss_vowel': 0.059944, 'loss_consonant': 0.056595}\n",
      "   85 | 0.000015 | 129280/160596 | 1.9157 | 1.5816 |\n",
      "val: {'recall': 0.974524, 'recall_grapheme': 0.961795, 'recall_vowel': 0.986797, 'recall_consonant': 0.987709, 'acc_grapheme': 0.966156, 'acc_vowel': 0.991129, 'acc_consonant': 0.989539, 'loss_grapheme': 0.157965, 'loss_vowel': 0.069382, 'loss_consonant': 0.061923}\n",
      "   86 | 0.000013 | 019968/160596 | 0.0114 | 1.6442 |\n",
      "val: {'recall': 0.975831, 'recall_grapheme': 0.962927, 'recall_vowel': 0.988556, 'recall_consonant': 0.988913, 'acc_grapheme': 0.967324, 'acc_vowel': 0.991576, 'acc_consonant': 0.990011, 'loss_grapheme': 0.153165, 'loss_vowel': 0.063062, 'loss_consonant': 0.056319}\n",
      "   86 | 0.000011 | 071168/160596 | 1.9950 | 1.5900 |\n",
      "val: {'recall': 0.976737, 'recall_grapheme': 0.964137, 'recall_vowel': 0.989047, 'recall_consonant': 0.989628, 'acc_grapheme': 0.968219, 'acc_vowel': 0.991875, 'acc_consonant': 0.99016, 'loss_grapheme': 0.167862, 'loss_vowel': 0.086439, 'loss_consonant': 0.071686}\n",
      "   86 | 0.000008 | 122368/160596 | 3.4011 | 1.4617 |\n",
      "val: {'recall': 0.976888, 'recall_grapheme': 0.964572, 'recall_vowel': 0.989368, 'recall_consonant': 0.989039, 'acc_grapheme': 0.968741, 'acc_vowel': 0.992173, 'acc_consonant': 0.990259, 'loss_grapheme': 0.145199, 'loss_vowel': 0.059786, 'loss_consonant': 0.054934}\n",
      "** saved\n",
      "   87 | 0.000006 | 013056/160596 | 0.0076 | 1.7136 |\n",
      "val: {'recall': 0.97687, 'recall_grapheme': 0.964544, 'recall_vowel': 0.989535, 'recall_consonant': 0.988858, 'acc_grapheme': 0.968666, 'acc_vowel': 0.992347, 'acc_consonant': 0.990309, 'loss_grapheme': 0.144968, 'loss_vowel': 0.056335, 'loss_consonant': 0.051844}\n",
      "   87 | 0.000004 | 064256/160596 | 4.5983 | 1.5980 |\n",
      "val: {'recall': 0.97672, 'recall_grapheme': 0.964419, 'recall_vowel': 0.989505, 'recall_consonant': 0.988539, 'acc_grapheme': 0.96884, 'acc_vowel': 0.992173, 'acc_consonant': 0.989936, 'loss_grapheme': 0.146726, 'loss_vowel': 0.060848, 'loss_consonant': 0.055442}\n",
      "   87 | 0.000002 | 115456/160596 | 1.4407 | 1.5754 |\n",
      "val: {'recall': 0.976824, 'recall_grapheme': 0.964649, 'recall_vowel': 0.989306, 'recall_consonant': 0.98869, 'acc_grapheme': 0.969213, 'acc_vowel': 0.992222, 'acc_consonant': 0.990135, 'loss_grapheme': 0.140584, 'loss_vowel': 0.050194, 'loss_consonant': 0.048411}\n",
      "   88 | 0.000001 | 006144/160596 | 0.0037 | 1.0426 |\n",
      "val: {'recall': 0.977313, 'recall_grapheme': 0.965303, 'recall_vowel': 0.989865, 'recall_consonant': 0.988781, 'acc_grapheme': 0.969287, 'acc_vowel': 0.992396, 'acc_consonant': 0.990309, 'loss_grapheme': 0.138421, 'loss_vowel': 0.042304, 'loss_consonant': 0.043957}\n",
      "** saved\n",
      "   88 | 0.000001 | 057344/160596 | 0.0020 | 1.4036 |\n",
      "val: {'recall': 0.97726, 'recall_grapheme': 0.965694, 'recall_vowel': 0.989081, 'recall_consonant': 0.988569, 'acc_grapheme': 0.96961, 'acc_vowel': 0.992173, 'acc_consonant': 0.990235, 'loss_grapheme': 0.138779, 'loss_vowel': 0.04703, 'loss_consonant': 0.046782}\n",
      "   88 | 0.000001 | 108544/160596 | 3.6513 | 1.4717 |\n",
      "val: {'recall': 0.976851, 'recall_grapheme': 0.964496, 'recall_vowel': 0.989474, 'recall_consonant': 0.98894, 'acc_grapheme': 0.969436, 'acc_vowel': 0.992297, 'acc_consonant': 0.990384, 'loss_grapheme': 0.153295, 'loss_vowel': 0.07353, 'loss_consonant': 0.062156}\n",
      "   88 | 0.000002 | 159744/160596 | 0.0024 | 1.5352 |\n",
      "val: {'recall': 0.977209, 'recall_grapheme': 0.965034, 'recall_vowel': 0.990024, 'recall_consonant': 0.988744, 'acc_grapheme': 0.969759, 'acc_vowel': 0.992446, 'acc_consonant': 0.99011, 'loss_grapheme': 0.141007, 'loss_vowel': 0.052004, 'loss_consonant': 0.049578}\n",
      "   89 | 0.000004 | 050432/160596 | 0.0026 | 1.6733 |\n",
      "val: {'recall': 0.977192, 'recall_grapheme': 0.964609, 'recall_vowel': 0.989563, 'recall_consonant': 0.989986, 'acc_grapheme': 0.968964, 'acc_vowel': 0.991949, 'acc_consonant': 0.99021, 'loss_grapheme': 0.152313, 'loss_vowel': 0.064422, 'loss_consonant': 0.058401}\n",
      "   89 | 0.000006 | 101632/160596 | 4.2428 | 1.5500 |\n",
      "val: {'recall': 0.976905, 'recall_grapheme': 0.963877, 'recall_vowel': 0.989722, 'recall_consonant': 0.990143, 'acc_grapheme': 0.968766, 'acc_vowel': 0.992073, 'acc_consonant': 0.990135, 'loss_grapheme': 0.158321, 'loss_vowel': 0.074968, 'loss_consonant': 0.065159}\n",
      "   89 | 0.000008 | 152832/160596 | 1.7986 | 1.5624 |\n",
      "val: {'recall': 0.976638, 'recall_grapheme': 0.963715, 'recall_vowel': 0.988655, 'recall_consonant': 0.990467, 'acc_grapheme': 0.968616, 'acc_vowel': 0.991949, 'acc_consonant': 0.989936, 'loss_grapheme': 0.148952, 'loss_vowel': 0.060778, 'loss_consonant': 0.056313}\n",
      "   90 | 0.000010 | 043520/160596 | 1.1252 | 1.6611 |\n",
      "val: {'recall': 0.976816, 'recall_grapheme': 0.964438, 'recall_vowel': 0.98882, 'recall_consonant': 0.989566, 'acc_grapheme': 0.968269, 'acc_vowel': 0.991552, 'acc_consonant': 0.990085, 'loss_grapheme': 0.155431, 'loss_vowel': 0.068957, 'loss_consonant': 0.060329}\n",
      "   90 | 0.000013 | 094720/160596 | 0.0028 | 1.5945 |\n",
      "val: {'recall': 0.976572, 'recall_grapheme': 0.963687, 'recall_vowel': 0.989528, 'recall_consonant': 0.989387, 'acc_grapheme': 0.967573, 'acc_vowel': 0.991949, 'acc_consonant': 0.990135, 'loss_grapheme': 0.165774, 'loss_vowel': 0.081383, 'loss_consonant': 0.065873}\n",
      "   90 | 0.000015 | 145920/160596 | 3.9357 | 1.5777 |\n",
      "val: {'recall': 0.975897, 'recall_grapheme': 0.96283, 'recall_vowel': 0.989472, 'recall_consonant': 0.988457, 'acc_grapheme': 0.96638, 'acc_vowel': 0.991875, 'acc_consonant': 0.989837, 'loss_grapheme': 0.150684, 'loss_vowel': 0.051671, 'loss_consonant': 0.051423}\n",
      "   91 | 0.000017 | 036608/160596 | 0.0039 | 1.6288 |\n",
      "val: {'recall': 0.975991, 'recall_grapheme': 0.963333, 'recall_vowel': 0.989351, 'recall_consonant': 0.987946, 'acc_grapheme': 0.966703, 'acc_vowel': 0.9918, 'acc_consonant': 0.989439, 'loss_grapheme': 0.151042, 'loss_vowel': 0.052987, 'loss_consonant': 0.050768}\n",
      "   91 | 0.000019 | 087808/160596 | 4.3614 | 1.6275 |\n",
      "val: {'recall': 0.975693, 'recall_grapheme': 0.963316, 'recall_vowel': 0.987091, 'recall_consonant': 0.989049, 'acc_grapheme': 0.967399, 'acc_vowel': 0.990756, 'acc_consonant': 0.989912, 'loss_grapheme': 0.162127, 'loss_vowel': 0.0737, 'loss_consonant': 0.062644}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   91 | 0.000020 | 139008/160596 | 3.6806 | 1.6164 |\n",
      "val: {'recall': 0.973863, 'recall_grapheme': 0.959784, 'recall_vowel': 0.989199, 'recall_consonant': 0.986687, 'acc_grapheme': 0.966107, 'acc_vowel': 0.991651, 'acc_consonant': 0.989638, 'loss_grapheme': 0.158803, 'loss_vowel': 0.064957, 'loss_consonant': 0.058167}\n",
      "   92 | 0.000020 | 029696/160596 | 0.0053 | 1.8408 |\n",
      "val: {'recall': 0.97509, 'recall_grapheme': 0.961984, 'recall_vowel': 0.98662, 'recall_consonant': 0.989773, 'acc_grapheme': 0.965809, 'acc_vowel': 0.990558, 'acc_consonant': 0.989415, 'loss_grapheme': 0.172446, 'loss_vowel': 0.086603, 'loss_consonant': 0.070253}\n",
      "   92 | 0.000020 | 080896/160596 | 3.6599 | 1.7100 |\n",
      "val: {'recall': 0.975586, 'recall_grapheme': 0.961846, 'recall_vowel': 0.988929, 'recall_consonant': 0.989722, 'acc_grapheme': 0.964715, 'acc_vowel': 0.991129, 'acc_consonant': 0.99016, 'loss_grapheme': 0.167259, 'loss_vowel': 0.070987, 'loss_consonant': 0.061611}\n",
      "   92 | 0.000019 | 132096/160596 | 3.5471 | 1.6565 |\n",
      "val: {'recall': 0.975621, 'recall_grapheme': 0.961742, 'recall_vowel': 0.989481, 'recall_consonant': 0.989519, 'acc_grapheme': 0.966653, 'acc_vowel': 0.991427, 'acc_consonant': 0.990384, 'loss_grapheme': 0.159099, 'loss_vowel': 0.068641, 'loss_consonant': 0.060763}\n",
      "   93 | 0.000017 | 022784/160596 | 3.9418 | 1.4938 |\n",
      "val: {'recall': 0.97627, 'recall_grapheme': 0.963169, 'recall_vowel': 0.990254, 'recall_consonant': 0.98849, 'acc_grapheme': 0.968119, 'acc_vowel': 0.991949, 'acc_consonant': 0.990359, 'loss_grapheme': 0.147974, 'loss_vowel': 0.060495, 'loss_consonant': 0.055478}\n",
      "   93 | 0.000015 | 073984/160596 | 0.0070 | 1.4441 |\n",
      "val: {'recall': 0.975892, 'recall_grapheme': 0.963363, 'recall_vowel': 0.988326, 'recall_consonant': 0.988516, 'acc_grapheme': 0.968293, 'acc_vowel': 0.991477, 'acc_consonant': 0.990259, 'loss_grapheme': 0.14361, 'loss_vowel': 0.048619, 'loss_consonant': 0.04617}\n",
      "   93 | 0.000013 | 125184/160596 | 0.0172 | 1.4624 |\n",
      "val: {'recall': 0.976147, 'recall_grapheme': 0.962997, 'recall_vowel': 0.98988, 'recall_consonant': 0.988716, 'acc_grapheme': 0.967796, 'acc_vowel': 0.991204, 'acc_consonant': 0.990135, 'loss_grapheme': 0.144726, 'loss_vowel': 0.048062, 'loss_consonant': 0.045358}\n",
      "   94 | 0.000010 | 015872/160596 | 3.7938 | 1.5213 |\n",
      "val: {'recall': 0.976432, 'recall_grapheme': 0.963793, 'recall_vowel': 0.989581, 'recall_consonant': 0.98856, 'acc_grapheme': 0.968592, 'acc_vowel': 0.991701, 'acc_consonant': 0.990036, 'loss_grapheme': 0.155786, 'loss_vowel': 0.066798, 'loss_consonant': 0.060069}\n",
      "   94 | 0.000008 | 067072/160596 | 0.0142 | 1.6121 |\n",
      "val: {'recall': 0.977181, 'recall_grapheme': 0.964924, 'recall_vowel': 0.98913, 'recall_consonant': 0.989743, 'acc_grapheme': 0.968865, 'acc_vowel': 0.991899, 'acc_consonant': 0.990582, 'loss_grapheme': 0.150517, 'loss_vowel': 0.063196, 'loss_consonant': 0.056582}\n",
      "   94 | 0.000006 | 118272/160596 | 4.4914 | 1.5640 |\n",
      "val: {'recall': 0.977709, 'recall_grapheme': 0.965358, 'recall_vowel': 0.989546, 'recall_consonant': 0.990572, 'acc_grapheme': 0.968716, 'acc_vowel': 0.992222, 'acc_consonant': 0.990508, 'loss_grapheme': 0.151173, 'loss_vowel': 0.069274, 'loss_consonant': 0.059334}\n",
      "** saved\n",
      "   95 | 0.000004 | 008960/160596 | 1.1109 | 1.8844 |\n",
      "val: {'recall': 0.977891, 'recall_grapheme': 0.96546, 'recall_vowel': 0.990421, 'recall_consonant': 0.990225, 'acc_grapheme': 0.969337, 'acc_vowel': 0.992421, 'acc_consonant': 0.990607, 'loss_grapheme': 0.147733, 'loss_vowel': 0.060391, 'loss_consonant': 0.053668}\n",
      "** saved\n",
      "   95 | 0.000002 | 060160/160596 | 4.1500 | 1.5275 |\n",
      "val: {'recall': 0.977803, 'recall_grapheme': 0.96555, 'recall_vowel': 0.989858, 'recall_consonant': 0.990256, 'acc_grapheme': 0.969461, 'acc_vowel': 0.992421, 'acc_consonant': 0.990558, 'loss_grapheme': 0.143578, 'loss_vowel': 0.056005, 'loss_consonant': 0.052331}\n",
      "   95 | 0.000001 | 111360/160596 | 0.0025 | 1.5808 |\n",
      "val: {'recall': 0.978009, 'recall_grapheme': 0.96588, 'recall_vowel': 0.990321, 'recall_consonant': 0.989955, 'acc_grapheme': 0.969536, 'acc_vowel': 0.99267, 'acc_consonant': 0.990533, 'loss_grapheme': 0.145873, 'loss_vowel': 0.060435, 'loss_consonant': 0.055208}\n",
      "** saved\n",
      "   96 | 0.000001 | 002048/160596 | 2.5616 | 0.9881 |\n",
      "val: {'recall': 0.977881, 'recall_grapheme': 0.966534, 'recall_vowel': 0.989815, 'recall_consonant': 0.988641, 'acc_grapheme': 0.969759, 'acc_vowel': 0.992471, 'acc_consonant': 0.990632, 'loss_grapheme': 0.138504, 'loss_vowel': 0.045688, 'loss_consonant': 0.044875}\n",
      "   96 | 0.000001 | 053248/160596 | 2.5149 | 1.4794 |\n",
      "val: {'recall': 0.977065, 'recall_grapheme': 0.965035, 'recall_vowel': 0.989406, 'recall_consonant': 0.988784, 'acc_grapheme': 0.969536, 'acc_vowel': 0.992347, 'acc_consonant': 0.990632, 'loss_grapheme': 0.144549, 'loss_vowel': 0.056464, 'loss_consonant': 0.051392}\n",
      "   96 | 0.000002 | 104448/160596 | 0.0018 | 1.5378 |\n",
      "val: {'recall': 0.977179, 'recall_grapheme': 0.965023, 'recall_vowel': 0.989783, 'recall_consonant': 0.988886, 'acc_grapheme': 0.96966, 'acc_vowel': 0.992198, 'acc_consonant': 0.990632, 'loss_grapheme': 0.152531, 'loss_vowel': 0.068069, 'loss_consonant': 0.058219}\n",
      "   96 | 0.000004 | 155648/160596 | 0.0030 | 1.5282 |\n",
      "val: {'recall': 0.976627, 'recall_grapheme': 0.964037, 'recall_vowel': 0.989689, 'recall_consonant': 0.988745, 'acc_grapheme': 0.969238, 'acc_vowel': 0.992098, 'acc_consonant': 0.990235, 'loss_grapheme': 0.148828, 'loss_vowel': 0.061623, 'loss_consonant': 0.054223}\n",
      "   97 | 0.000006 | 046336/160596 | 3.1650 | 1.4906 |\n",
      "val: {'recall': 0.977426, 'recall_grapheme': 0.96504, 'recall_vowel': 0.989808, 'recall_consonant': 0.989817, 'acc_grapheme': 0.969337, 'acc_vowel': 0.991999, 'acc_consonant': 0.990533, 'loss_grapheme': 0.147217, 'loss_vowel': 0.058357, 'loss_consonant': 0.053285}\n",
      "   97 | 0.000008 | 097536/160596 | 2.9594 | 1.6316 |\n",
      "val: {'recall': 0.977067, 'recall_grapheme': 0.963797, 'recall_vowel': 0.98974, 'recall_consonant': 0.990934, 'acc_grapheme': 0.968666, 'acc_vowel': 0.992222, 'acc_consonant': 0.990632, 'loss_grapheme': 0.157222, 'loss_vowel': 0.069653, 'loss_consonant': 0.060565}\n",
      "   97 | 0.000010 | 148736/160596 | 0.0084 | 1.6145 |\n",
      "val: {'recall': 0.976801, 'recall_grapheme': 0.963829, 'recall_vowel': 0.989621, 'recall_consonant': 0.989924, 'acc_grapheme': 0.96797, 'acc_vowel': 0.992347, 'acc_consonant': 0.990409, 'loss_grapheme': 0.151859, 'loss_vowel': 0.062794, 'loss_consonant': 0.055176}\n",
      "   98 | 0.000013 | 039424/160596 | 0.0231 | 1.9708 |\n",
      "val: {'recall': 0.976369, 'recall_grapheme': 0.962775, 'recall_vowel': 0.989219, 'recall_consonant': 0.990704, 'acc_grapheme': 0.96643, 'acc_vowel': 0.991676, 'acc_consonant': 0.990259, 'loss_grapheme': 0.169032, 'loss_vowel': 0.074249, 'loss_consonant': 0.06473}\n",
      "   98 | 0.000015 | 090624/160596 | 4.1046 | 1.8529 |\n",
      "val: {'recall': 0.976027, 'recall_grapheme': 0.962824, 'recall_vowel': 0.989413, 'recall_consonant': 0.989048, 'acc_grapheme': 0.967647, 'acc_vowel': 0.991775, 'acc_consonant': 0.989688, 'loss_grapheme': 0.149413, 'loss_vowel': 0.060128, 'loss_consonant': 0.055428}\n",
      "   98 | 0.000017 | 141824/160596 | 0.0216 | 1.7749 |\n",
      "val: {'recall': 0.977056, 'recall_grapheme': 0.964637, 'recall_vowel': 0.989821, 'recall_consonant': 0.989129, 'acc_grapheme': 0.967126, 'acc_vowel': 0.992073, 'acc_consonant': 0.990284, 'loss_grapheme': 0.15266, 'loss_vowel': 0.061029, 'loss_consonant': 0.054836}\n",
      "   99 | 0.000019 | 032512/160596 | 0.0073 | 1.4290 |\n",
      "val: {'recall': 0.975892, 'recall_grapheme': 0.962292, 'recall_vowel': 0.989611, 'recall_consonant': 0.989371, 'acc_grapheme': 0.966107, 'acc_vowel': 0.992123, 'acc_consonant': 0.989912, 'loss_grapheme': 0.151817, 'loss_vowel': 0.050722, 'loss_consonant': 0.049277}\n",
      "   99 | 0.000020 | 083712/160596 | 2.0861 | 1.4987 |\n",
      "val: {'recall': 0.975666, 'recall_grapheme': 0.963536, 'recall_vowel': 0.989164, 'recall_consonant': 0.986429, 'acc_grapheme': 0.967896, 'acc_vowel': 0.991527, 'acc_consonant': 0.989042, 'loss_grapheme': 0.150964, 'loss_vowel': 0.066136, 'loss_consonant': 0.057637}\n",
      "   99 | 0.000020 | 134912/160596 | 0.0042 | 1.4896 |\n",
      "val: {'recall': 0.975386, 'recall_grapheme': 0.962658, 'recall_vowel': 0.988593, 'recall_consonant': 0.987635, 'acc_grapheme': 0.967026, 'acc_vowel': 0.991825, 'acc_consonant': 0.990036, 'loss_grapheme': 0.146783, 'loss_vowel': 0.048304, 'loss_consonant': 0.048387}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 | 0.000020 | 025600/160596 | 0.0066 | 1.6555 |\n",
      "val: {'recall': 0.975743, 'recall_grapheme': 0.963929, 'recall_vowel': 0.985528, 'recall_consonant': 0.989585, 'acc_grapheme': 0.966455, 'acc_vowel': 0.99093, 'acc_consonant': 0.989564, 'loss_grapheme': 0.153643, 'loss_vowel': 0.052493, 'loss_consonant': 0.050877}\n",
      "  100 | 0.000019 | 076800/160596 | 1.8782 | 1.4573 |\n",
      "val: {'recall': 0.97513, 'recall_grapheme': 0.962492, 'recall_vowel': 0.989288, 'recall_consonant': 0.986248, 'acc_grapheme': 0.96638, 'acc_vowel': 0.991552, 'acc_consonant': 0.98929, 'loss_grapheme': 0.153631, 'loss_vowel': 0.043317, 'loss_consonant': 0.048311}\n",
      "  100 | 0.000017 | 128000/160596 | 0.8016 | 1.5072 |\n",
      "val: {'recall': 0.974849, 'recall_grapheme': 0.96161, 'recall_vowel': 0.989406, 'recall_consonant': 0.986769, 'acc_grapheme': 0.967051, 'acc_vowel': 0.991552, 'acc_consonant': 0.989936, 'loss_grapheme': 0.153711, 'loss_vowel': 0.06401, 'loss_consonant': 0.056446}\n",
      "  101 | 0.000015 | 018688/160596 | 0.0108 | 1.1752 |\n",
      "val: {'recall': 0.975084, 'recall_grapheme': 0.9621, 'recall_vowel': 0.987968, 'recall_consonant': 0.988169, 'acc_grapheme': 0.967449, 'acc_vowel': 0.991229, 'acc_consonant': 0.989812, 'loss_grapheme': 0.147401, 'loss_vowel': 0.054827, 'loss_consonant': 0.051288}\n",
      "  101 | 0.000013 | 069888/160596 | 0.0166 | 1.4627 |\n",
      "val: {'recall': 0.976302, 'recall_grapheme': 0.964796, 'recall_vowel': 0.98824, 'recall_consonant': 0.987375, 'acc_grapheme': 0.968045, 'acc_vowel': 0.991676, 'acc_consonant': 0.989738, 'loss_grapheme': 0.151377, 'loss_vowel': 0.058962, 'loss_consonant': 0.0556}\n",
      "  101 | 0.000011 | 121088/160596 | 2.1769 | 1.5541 |\n",
      "val: {'recall': 0.975669, 'recall_grapheme': 0.962875, 'recall_vowel': 0.988747, 'recall_consonant': 0.988179, 'acc_grapheme': 0.967946, 'acc_vowel': 0.991999, 'acc_consonant': 0.990085, 'loss_grapheme': 0.144264, 'loss_vowel': 0.046717, 'loss_consonant': 0.04737}\n",
      "  101 | 0.000008 | 141568/160596 | 1.1577 | 1.5451 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-54080d9d42c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-28f20a7d4cf4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbbx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbby2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbby1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
