{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class PlainRAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "        super(PlainRAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PlainRAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                beta2_t = beta2 ** state['step']\n",
    "                N_sma_max = 2 / (1 - beta2) - 1\n",
    "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:                    \n",
    "                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, warmup = warmup)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AdamW, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                \n",
    "                if group['warmup'] > state['step']:\n",
    "                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n",
    "                else:\n",
    "                    scheduled_lr = group['lr']\n",
    "\n",
    "                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n",
    "                \n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n",
    "\n",
    "                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install opencv-python\\n!pip install fastparquet\\n!pip install pyarrow\\n!pip install snappy\\n!conda install python-snappy -y\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install opencv-python\n",
    "!pip install fastparquet\n",
    "!pip install pyarrow\n",
    "!pip install snappy\n",
    "!conda install python-snappy -y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/mnt/chicm/data/bengali': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/chicm/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor img, y in train_loader:\\n    print(img.size(), y.size())\\n    print(y)\\n    #print(img)\\n    #plt.imshow(img.squeeze()[0].numpy())\\n    break\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for img, y in train_loader:\n",
    "    print(img.size(), y.size())\n",
    "    print(y)\n",
    "    #print(img)\n",
    "    #plt.imshow(img.squeeze()[0].numpy())\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet_1(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch.utils import get_same_padding_conv2d, round_filters\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "        \n",
    "        self.fix_input_layer()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        elif self.backbone_name.startswith('efficientnet'):\n",
    "            w = self.backbone._conv_stem.weight.data\n",
    "            #print('fixing...', w.size())\n",
    "            Conv2d = get_same_padding_conv2d(image_size = self.backbone._global_params.image_size)\n",
    "            out_channels = round_filters(32, self.backbone._global_params)\n",
    "            #print('out:', out_channels)\n",
    "            self.backbone._conv_stem = Conv2d(1, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "            self.backbone._conv_stem.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.size())\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nm = BengaliNet('efficientnet-b5')\\nprint(m.backbone._conv_stem)\\nm(torch.randn(2,1,224,224)).size()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "m = BengaliNet('efficientnet-b5')\n",
    "print(m.backbone._conv_stem)\n",
    "m(torch.randn(2,1,224,224)).size()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nargs = Namespace()\\nargs.backbone = 'se_resnext50_32x4d'\\nargs.ckp_name = 'best_model.pth'\\nargs.predict = False\\n\\nbnet = create_model(args)[0].cuda()\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'best_model.pth'\n",
    "args.predict = False\n",
    "\n",
    "bnet = create_model(args)[0].cuda()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum().item()\n",
    "        res.append(correct_k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025174487323645023"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                #img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                #loss = mixup_criterion(outputs, targets)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'efficientnet-b5'\n",
    "args.ckp_name = 'model2_best_model_fold1.pth'\n",
    "args.predict = False\n",
    "args.optim = 'RAdam'\n",
    "args.lr = 2e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.6\n",
    "args.patience = 3\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 512\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160635, 5) (40205, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "model file: ./models/efficientnet-b5/model2_best_model_fold1.pth, exist: True\n",
      "loading ./models/efficientnet-b5/model2_best_model_fold1.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.97883, 'recall_grapheme': 0.967717, 'recall_vowel': 0.989912, 'recall_consonant': 0.989973, 'acc_grapheme': 0.966397, 'acc_vowel': 0.990548, 'acc_consonant': 0.9902, 'loss_grapheme': 0.144399, 'loss_vowel': 0.068905, 'loss_consonant': 0.05851}\n",
      "    0 | 0.000020 | 102400/160635 | 4.2188 | 1.8981 |\n",
      "val: {'recall': 0.979289, 'recall_grapheme': 0.968518, 'recall_vowel': 0.989948, 'recall_consonant': 0.990175, 'acc_grapheme': 0.967317, 'acc_vowel': 0.990598, 'acc_consonant': 0.990349, 'loss_grapheme': 0.146752, 'loss_vowel': 0.07137, 'loss_consonant': 0.06097}\n",
      "** saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000020 | 044544/160635 | 1.6816 | 1.8062 |\n",
      "val: {'recall': 0.978874, 'recall_grapheme': 0.967681, 'recall_vowel': 0.989938, 'recall_consonant': 0.990197, 'acc_grapheme': 0.967566, 'acc_vowel': 0.990623, 'acc_consonant': 0.990548, 'loss_grapheme': 0.138688, 'loss_vowel': 0.063209, 'loss_consonant': 0.054866}\n",
      "    1 | 0.000019 | 146944/160635 | 0.0716 | 1.7022 |\n",
      "val: {'recall': 0.979022, 'recall_grapheme': 0.968485, 'recall_vowel': 0.989825, 'recall_consonant': 0.98929, 'acc_grapheme': 0.968188, 'acc_vowel': 0.990648, 'acc_consonant': 0.990449, 'loss_grapheme': 0.133711, 'loss_vowel': 0.059674, 'loss_consonant': 0.051799}\n",
      "    2 | 0.000017 | 089088/160635 | 2.9948 | 2.0134 |\n",
      "val: {'recall': 0.979205, 'recall_grapheme': 0.968322, 'recall_vowel': 0.989708, 'recall_consonant': 0.990467, 'acc_grapheme': 0.968138, 'acc_vowel': 0.990474, 'acc_consonant': 0.990349, 'loss_grapheme': 0.143055, 'loss_vowel': 0.067097, 'loss_consonant': 0.058574}\n",
      "    3 | 0.000015 | 031232/160635 | 0.1102 | 1.8668 |\n",
      "val: {'recall': 0.979431, 'recall_grapheme': 0.968601, 'recall_vowel': 0.990174, 'recall_consonant': 0.990346, 'acc_grapheme': 0.968312, 'acc_vowel': 0.990723, 'acc_consonant': 0.990424, 'loss_grapheme': 0.135784, 'loss_vowel': 0.062407, 'loss_consonant': 0.054368}\n",
      "** saved\n",
      "    3 | 0.000013 | 133632/160635 | 3.7101 | 1.9133 |\n",
      "val: {'recall': 0.978982, 'recall_grapheme': 0.96777, 'recall_vowel': 0.98986, 'recall_consonant': 0.990527, 'acc_grapheme': 0.967865, 'acc_vowel': 0.990648, 'acc_consonant': 0.990598, 'loss_grapheme': 0.138022, 'loss_vowel': 0.062884, 'loss_consonant': 0.054187}\n",
      "    4 | 0.000011 | 075776/160635 | 0.1214 | 1.7851 |\n",
      "val: {'recall': 0.979308, 'recall_grapheme': 0.96848, 'recall_vowel': 0.989948, 'recall_consonant': 0.990324, 'acc_grapheme': 0.968387, 'acc_vowel': 0.990673, 'acc_consonant': 0.990698, 'loss_grapheme': 0.132349, 'loss_vowel': 0.058896, 'loss_consonant': 0.050387}\n",
      "    5 | 0.000008 | 017920/160635 | 4.8766 | 1.7972 |\n",
      "val: {'recall': 0.979196, 'recall_grapheme': 0.968225, 'recall_vowel': 0.99008, 'recall_consonant': 0.990255, 'acc_grapheme': 0.96784, 'acc_vowel': 0.990648, 'acc_consonant': 0.990573, 'loss_grapheme': 0.136563, 'loss_vowel': 0.062853, 'loss_consonant': 0.053569}\n",
      "    5 | 0.000006 | 120320/160635 | 0.4333 | 1.9324 |\n",
      "val: {'recall': 0.97909, 'recall_grapheme': 0.968039, 'recall_vowel': 0.990008, 'recall_consonant': 0.990272, 'acc_grapheme': 0.967541, 'acc_vowel': 0.990499, 'acc_consonant': 0.990499, 'loss_grapheme': 0.147112, 'loss_vowel': 0.070597, 'loss_consonant': 0.059832}\n",
      "    6 | 0.000004 | 062464/160635 | 0.0731 | 1.8952 |\n",
      "val: {'recall': 0.979435, 'recall_grapheme': 0.968697, 'recall_vowel': 0.990031, 'recall_consonant': 0.990316, 'acc_grapheme': 0.968312, 'acc_vowel': 0.990673, 'acc_consonant': 0.990648, 'loss_grapheme': 0.139702, 'loss_vowel': 0.064824, 'loss_consonant': 0.055812}\n",
      "** saved\n",
      "    7 | 0.000002 | 004608/160635 | 4.6324 | 2.8545 |\n",
      "val: {'recall': 0.97945, 'recall_grapheme': 0.968645, 'recall_vowel': 0.99017, 'recall_consonant': 0.990338, 'acc_grapheme': 0.968337, 'acc_vowel': 0.990598, 'acc_consonant': 0.990573, 'loss_grapheme': 0.142675, 'loss_vowel': 0.067198, 'loss_consonant': 0.05778}\n",
      "** saved\n",
      "    7 | 0.000001 | 107008/160635 | 4.4135 | 1.7609 |\n",
      "val: {'recall': 0.979485, 'recall_grapheme': 0.968729, 'recall_vowel': 0.990152, 'recall_consonant': 0.990328, 'acc_grapheme': 0.968412, 'acc_vowel': 0.990698, 'acc_consonant': 0.990623, 'loss_grapheme': 0.135513, 'loss_vowel': 0.061808, 'loss_consonant': 0.053842}\n",
      "** saved\n",
      "    8 | 0.000001 | 049152/160635 | 3.4311 | 1.7725 |\n",
      "val: {'recall': 0.979492, 'recall_grapheme': 0.968682, 'recall_vowel': 0.990112, 'recall_consonant': 0.990494, 'acc_grapheme': 0.968138, 'acc_vowel': 0.990623, 'acc_consonant': 0.990723, 'loss_grapheme': 0.138445, 'loss_vowel': 0.064215, 'loss_consonant': 0.055943}\n",
      "** saved\n",
      "    8 | 0.000001 | 151552/160635 | 2.8081 | 1.8202 |\n",
      "val: {'recall': 0.979502, 'recall_grapheme': 0.968828, 'recall_vowel': 0.990149, 'recall_consonant': 0.990201, 'acc_grapheme': 0.968362, 'acc_vowel': 0.990673, 'acc_consonant': 0.990598, 'loss_grapheme': 0.136757, 'loss_vowel': 0.062492, 'loss_consonant': 0.054196}\n",
      "** saved\n",
      "    9 | 0.000002 | 093696/160635 | 4.9390 | 1.9280 |\n",
      "val: {'recall': 0.979482, 'recall_grapheme': 0.968847, 'recall_vowel': 0.990003, 'recall_consonant': 0.99023, 'acc_grapheme': 0.968462, 'acc_vowel': 0.990623, 'acc_consonant': 0.990573, 'loss_grapheme': 0.138976, 'loss_vowel': 0.063923, 'loss_consonant': 0.05499}\n",
      "   10 | 0.000004 | 035840/160635 | 0.0893 | 2.4846 |\n",
      "val: {'recall': 0.979405, 'recall_grapheme': 0.968495, 'recall_vowel': 0.990076, 'recall_consonant': 0.990553, 'acc_grapheme': 0.96784, 'acc_vowel': 0.990548, 'acc_consonant': 0.990548, 'loss_grapheme': 0.15158, 'loss_vowel': 0.075219, 'loss_consonant': 0.064208}\n",
      "   10 | 0.000006 | 138240/160635 | 5.1093 | 2.0810 |\n",
      "val: {'recall': 0.979486, 'recall_grapheme': 0.968689, 'recall_vowel': 0.990177, 'recall_consonant': 0.990389, 'acc_grapheme': 0.968163, 'acc_vowel': 0.990648, 'acc_consonant': 0.990623, 'loss_grapheme': 0.144082, 'loss_vowel': 0.069036, 'loss_consonant': 0.058981}\n",
      "   11 | 0.000008 | 080384/160635 | 0.0583 | 1.7332 |\n",
      "val: {'recall': 0.979646, 'recall_grapheme': 0.96905, 'recall_vowel': 0.989998, 'recall_consonant': 0.990484, 'acc_grapheme': 0.968586, 'acc_vowel': 0.990822, 'acc_consonant': 0.990772, 'loss_grapheme': 0.129494, 'loss_vowel': 0.056355, 'loss_consonant': 0.04888}\n",
      "** saved\n",
      "   12 | 0.000010 | 022528/160635 | 4.2840 | 2.0395 |\n",
      "val: {'recall': 0.97948, 'recall_grapheme': 0.968882, 'recall_vowel': 0.989712, 'recall_consonant': 0.990445, 'acc_grapheme': 0.968462, 'acc_vowel': 0.990623, 'acc_consonant': 0.990623, 'loss_grapheme': 0.144953, 'loss_vowel': 0.069569, 'loss_consonant': 0.0588}\n",
      "   12 | 0.000013 | 124928/160635 | 4.8821 | 1.6936 |\n",
      "val: {'recall': 0.97972, 'recall_grapheme': 0.96914, 'recall_vowel': 0.990176, 'recall_consonant': 0.990425, 'acc_grapheme': 0.968561, 'acc_vowel': 0.990822, 'acc_consonant': 0.990623, 'loss_grapheme': 0.134233, 'loss_vowel': 0.060236, 'loss_consonant': 0.052277}\n",
      "** saved\n",
      "   13 | 0.000015 | 067072/160635 | 0.0546 | 1.9117 |\n",
      "val: {'recall': 0.979515, 'recall_grapheme': 0.969028, 'recall_vowel': 0.990026, 'recall_consonant': 0.989979, 'acc_grapheme': 0.968685, 'acc_vowel': 0.990797, 'acc_consonant': 0.990573, 'loss_grapheme': 0.136192, 'loss_vowel': 0.061839, 'loss_consonant': 0.052396}\n",
      "   14 | 0.000017 | 009216/160635 | 1.2172 | 1.8534 |\n",
      "val: {'recall': 0.979348, 'recall_grapheme': 0.968819, 'recall_vowel': 0.9901, 'recall_consonant': 0.989655, 'acc_grapheme': 0.96886, 'acc_vowel': 0.990872, 'acc_consonant': 0.990797, 'loss_grapheme': 0.130625, 'loss_vowel': 0.057697, 'loss_consonant': 0.048496}\n",
      "   14 | 0.000019 | 111616/160635 | 0.1054 | 1.5275 |\n",
      "val: {'recall': 0.978942, 'recall_grapheme': 0.968889, 'recall_vowel': 0.989847, 'recall_consonant': 0.988143, 'acc_grapheme': 0.968984, 'acc_vowel': 0.990772, 'acc_consonant': 0.990822, 'loss_grapheme': 0.122795, 'loss_vowel': 0.051332, 'loss_consonant': 0.044353}\n",
      "   15 | 0.000020 | 053760/160635 | 0.0853 | 2.0604 |\n",
      "val: {'recall': 0.979739, 'recall_grapheme': 0.969143, 'recall_vowel': 0.990313, 'recall_consonant': 0.990356, 'acc_grapheme': 0.968312, 'acc_vowel': 0.990623, 'acc_consonant': 0.990623, 'loss_grapheme': 0.139465, 'loss_vowel': 0.065959, 'loss_consonant': 0.056887}\n",
      "** saved\n",
      "   15 | 0.000020 | 156160/160635 | 3.2167 | 1.8748 |\n",
      "val: {'recall': 0.979406, 'recall_grapheme': 0.968805, 'recall_vowel': 0.990158, 'recall_consonant': 0.989856, 'acc_grapheme': 0.968263, 'acc_vowel': 0.990747, 'acc_consonant': 0.990573, 'loss_grapheme': 0.136724, 'loss_vowel': 0.063093, 'loss_consonant': 0.053075}\n",
      "   16 | 0.000020 | 098304/160635 | 4.4484 | 1.7955 |\n",
      "val: {'recall': 0.979421, 'recall_grapheme': 0.96869, 'recall_vowel': 0.98972, 'recall_consonant': 0.990585, 'acc_grapheme': 0.968785, 'acc_vowel': 0.990747, 'acc_consonant': 0.990772, 'loss_grapheme': 0.131224, 'loss_vowel': 0.05916, 'loss_consonant': 0.051426}\n",
      "   17 | 0.000019 | 040448/160635 | 0.5035 | 1.9176 |\n",
      "val: {'recall': 0.97917, 'recall_grapheme': 0.968302, 'recall_vowel': 0.989988, 'recall_consonant': 0.990086, 'acc_grapheme': 0.967964, 'acc_vowel': 0.990623, 'acc_consonant': 0.990474, 'loss_grapheme': 0.138774, 'loss_vowel': 0.066707, 'loss_consonant': 0.054243}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 0.000017 | 142848/160635 | 0.0490 | 2.0338 |\n",
      "val: {'recall': 0.979489, 'recall_grapheme': 0.968817, 'recall_vowel': 0.989896, 'recall_consonant': 0.990425, 'acc_grapheme': 0.968437, 'acc_vowel': 0.990573, 'acc_consonant': 0.990797, 'loss_grapheme': 0.135704, 'loss_vowel': 0.06378, 'loss_consonant': 0.053391}\n",
      "   18 | 0.000015 | 084992/160635 | 0.0460 | 1.9036 |\n",
      "val: {'recall': 0.979563, 'recall_grapheme': 0.968969, 'recall_vowel': 0.98994, 'recall_consonant': 0.990377, 'acc_grapheme': 0.968511, 'acc_vowel': 0.990648, 'acc_consonant': 0.990573, 'loss_grapheme': 0.13837, 'loss_vowel': 0.064393, 'loss_consonant': 0.055772}\n",
      "   19 | 0.000013 | 027136/160635 | 4.2418 | 1.6728 |\n",
      "val: {'recall': 0.979668, 'recall_grapheme': 0.969379, 'recall_vowel': 0.989902, 'recall_consonant': 0.990013, 'acc_grapheme': 0.969108, 'acc_vowel': 0.990822, 'acc_consonant': 0.990598, 'loss_grapheme': 0.127754, 'loss_vowel': 0.056528, 'loss_consonant': 0.048657}\n",
      "   19 | 0.000011 | 129536/160635 | 0.7974 | 1.8354 |\n",
      "val: {'recall': 0.97972, 'recall_grapheme': 0.969432, 'recall_vowel': 0.989833, 'recall_consonant': 0.990185, 'acc_grapheme': 0.968785, 'acc_vowel': 0.990772, 'acc_consonant': 0.990723, 'loss_grapheme': 0.136218, 'loss_vowel': 0.062931, 'loss_consonant': 0.053905}\n",
      "   20 | 0.000008 | 071680/160635 | 0.0670 | 1.8701 |\n",
      "val: {'recall': 0.979698, 'recall_grapheme': 0.969314, 'recall_vowel': 0.989989, 'recall_consonant': 0.990174, 'acc_grapheme': 0.96871, 'acc_vowel': 0.990747, 'acc_consonant': 0.990698, 'loss_grapheme': 0.140521, 'loss_vowel': 0.06643, 'loss_consonant': 0.05607}\n",
      "   21 | 0.000006 | 013824/160635 | 0.0758 | 1.9171 |\n",
      "val: {'recall': 0.979664, 'recall_grapheme': 0.969725, 'recall_vowel': 0.99006, 'recall_consonant': 0.989145, 'acc_grapheme': 0.969531, 'acc_vowel': 0.990747, 'acc_consonant': 0.990772, 'loss_grapheme': 0.12896, 'loss_vowel': 0.057229, 'loss_consonant': 0.049152}\n",
      "   21 | 0.000004 | 116224/160635 | 0.0637 | 1.8732 |\n",
      "val: {'recall': 0.979771, 'recall_grapheme': 0.96935, 'recall_vowel': 0.990111, 'recall_consonant': 0.990276, 'acc_grapheme': 0.969233, 'acc_vowel': 0.990872, 'acc_consonant': 0.990723, 'loss_grapheme': 0.128522, 'loss_vowel': 0.057035, 'loss_consonant': 0.049069}\n",
      "** saved\n",
      "   22 | 0.000002 | 058368/160635 | 4.6672 | 2.0119 |\n",
      "val: {'recall': 0.97961, 'recall_grapheme': 0.969035, 'recall_vowel': 0.990054, 'recall_consonant': 0.990314, 'acc_grapheme': 0.969133, 'acc_vowel': 0.990797, 'acc_consonant': 0.990648, 'loss_grapheme': 0.135519, 'loss_vowel': 0.062688, 'loss_consonant': 0.053483}\n",
      "   23 | 0.000001 | 000512/160635 | 0.0468 | 0.0468 |\n",
      "val: {'recall': 0.980096, 'recall_grapheme': 0.97011, 'recall_vowel': 0.989991, 'recall_consonant': 0.990173, 'acc_grapheme': 0.969805, 'acc_vowel': 0.990897, 'acc_consonant': 0.990797, 'loss_grapheme': 0.124408, 'loss_vowel': 0.053327, 'loss_consonant': 0.046034}\n",
      "** saved\n",
      "   23 | 0.000001 | 102912/160635 | 0.0592 | 1.5365 |\n",
      "val: {'recall': 0.979554, 'recall_grapheme': 0.96967, 'recall_vowel': 0.989932, 'recall_consonant': 0.988943, 'acc_grapheme': 0.969656, 'acc_vowel': 0.990922, 'acc_consonant': 0.990747, 'loss_grapheme': 0.120705, 'loss_vowel': 0.050041, 'loss_consonant': 0.043285}\n",
      "   24 | 0.000001 | 045056/160635 | 2.2004 | 2.0765 |\n",
      "val: {'recall': 0.979691, 'recall_grapheme': 0.969221, 'recall_vowel': 0.989939, 'recall_consonant': 0.990382, 'acc_grapheme': 0.969208, 'acc_vowel': 0.990698, 'acc_consonant': 0.990747, 'loss_grapheme': 0.137035, 'loss_vowel': 0.064205, 'loss_consonant': 0.054664}\n",
      "   24 | 0.000002 | 147456/160635 | 0.0618 | 1.8138 |\n",
      "val: {'recall': 0.979767, 'recall_grapheme': 0.969307, 'recall_vowel': 0.990141, 'recall_consonant': 0.990315, 'acc_grapheme': 0.969233, 'acc_vowel': 0.990797, 'acc_consonant': 0.990797, 'loss_grapheme': 0.13479, 'loss_vowel': 0.062216, 'loss_consonant': 0.053177}\n",
      "   25 | 0.000004 | 089600/160635 | 0.5868 | 1.8107 |\n",
      "val: {'recall': 0.979412, 'recall_grapheme': 0.96928, 'recall_vowel': 0.989799, 'recall_consonant': 0.98929, 'acc_grapheme': 0.969133, 'acc_vowel': 0.990648, 'acc_consonant': 0.990747, 'loss_grapheme': 0.13374, 'loss_vowel': 0.061848, 'loss_consonant': 0.052336}\n",
      "   26 | 0.000006 | 031744/160635 | 3.7324 | 1.3659 |\n",
      "val: {'recall': 0.97973, 'recall_grapheme': 0.969286, 'recall_vowel': 0.990146, 'recall_consonant': 0.990203, 'acc_grapheme': 0.969457, 'acc_vowel': 0.990946, 'acc_consonant': 0.990772, 'loss_grapheme': 0.12647, 'loss_vowel': 0.055657, 'loss_consonant': 0.047774}\n",
      "   26 | 0.000008 | 134144/160635 | 0.4590 | 1.8070 |\n",
      "val: {'recall': 0.979614, 'recall_grapheme': 0.969037, 'recall_vowel': 0.990166, 'recall_consonant': 0.990218, 'acc_grapheme': 0.96871, 'acc_vowel': 0.990723, 'acc_consonant': 0.990673, 'loss_grapheme': 0.139861, 'loss_vowel': 0.066696, 'loss_consonant': 0.055793}\n",
      "   27 | 0.000010 | 076288/160635 | 4.9161 | 2.4458 |\n",
      "val: {'recall': 0.979466, 'recall_grapheme': 0.968816, 'recall_vowel': 0.989655, 'recall_consonant': 0.990579, 'acc_grapheme': 0.968785, 'acc_vowel': 0.990623, 'acc_consonant': 0.990648, 'loss_grapheme': 0.16063, 'loss_vowel': 0.084541, 'loss_consonant': 0.069167}\n",
      "   28 | 0.000013 | 018432/160635 | 2.4120 | 1.4739 |\n",
      "val: {'recall': 0.979653, 'recall_grapheme': 0.969065, 'recall_vowel': 0.990128, 'recall_consonant': 0.990352, 'acc_grapheme': 0.969208, 'acc_vowel': 0.990797, 'acc_consonant': 0.990847, 'loss_grapheme': 0.133879, 'loss_vowel': 0.062109, 'loss_consonant': 0.051835}\n",
      "   28 | 0.000015 | 120832/160635 | 3.7575 | 1.8852 |\n",
      "val: {'recall': 0.979081, 'recall_grapheme': 0.968565, 'recall_vowel': 0.989803, 'recall_consonant': 0.989391, 'acc_grapheme': 0.968909, 'acc_vowel': 0.990797, 'acc_consonant': 0.990598, 'loss_grapheme': 0.141029, 'loss_vowel': 0.068249, 'loss_consonant': 0.058188}\n",
      "   29 | 0.000017 | 062976/160635 | 0.9955 | 1.5947 |\n",
      "val: {'recall': 0.979764, 'recall_grapheme': 0.969424, 'recall_vowel': 0.989856, 'recall_consonant': 0.990351, 'acc_grapheme': 0.969233, 'acc_vowel': 0.990772, 'acc_consonant': 0.990648, 'loss_grapheme': 0.128146, 'loss_vowel': 0.05831, 'loss_consonant': 0.049251}\n",
      "   30 | 0.000019 | 005120/160635 | 0.0473 | 1.6090 |\n",
      "val: {'recall': 0.979959, 'recall_grapheme': 0.969757, 'recall_vowel': 0.990012, 'recall_consonant': 0.990311, 'acc_grapheme': 0.969506, 'acc_vowel': 0.990971, 'acc_consonant': 0.990648, 'loss_grapheme': 0.131785, 'loss_vowel': 0.061066, 'loss_consonant': 0.051991}\n",
      "   30 | 0.000020 | 107520/160635 | 0.0452 | 1.7068 |\n",
      "val: {'recall': 0.979299, 'recall_grapheme': 0.968779, 'recall_vowel': 0.990265, 'recall_consonant': 0.989373, 'acc_grapheme': 0.969457, 'acc_vowel': 0.991071, 'acc_consonant': 0.990772, 'loss_grapheme': 0.126181, 'loss_vowel': 0.055957, 'loss_consonant': 0.047092}\n",
      "   31 | 0.000020 | 049664/160635 | 0.0427 | 1.7217 |\n",
      "val: {'recall': 0.979313, 'recall_grapheme': 0.968432, 'recall_vowel': 0.989957, 'recall_consonant': 0.990429, 'acc_grapheme': 0.969133, 'acc_vowel': 0.990822, 'acc_consonant': 0.990872, 'loss_grapheme': 0.131787, 'loss_vowel': 0.061628, 'loss_consonant': 0.051964}\n",
      "   31 | 0.000020 | 152064/160635 | 3.7582 | 1.8422 |\n",
      "val: {'recall': 0.979575, 'recall_grapheme': 0.969088, 'recall_vowel': 0.989934, 'recall_consonant': 0.990191, 'acc_grapheme': 0.969183, 'acc_vowel': 0.990648, 'acc_consonant': 0.990822, 'loss_grapheme': 0.136791, 'loss_vowel': 0.065641, 'loss_consonant': 0.055911}\n",
      "   32 | 0.000019 | 094208/160635 | 0.7070 | 1.7742 |\n",
      "val: {'recall': 0.979773, 'recall_grapheme': 0.969861, 'recall_vowel': 0.990449, 'recall_consonant': 0.988922, 'acc_grapheme': 0.969755, 'acc_vowel': 0.990996, 'acc_consonant': 0.990872, 'loss_grapheme': 0.132535, 'loss_vowel': 0.061168, 'loss_consonant': 0.052055}\n",
      "   33 | 0.000017 | 036352/160635 | 2.6345 | 1.7285 |\n",
      "val: {'recall': 0.979752, 'recall_grapheme': 0.969443, 'recall_vowel': 0.99014, 'recall_consonant': 0.989984, 'acc_grapheme': 0.969581, 'acc_vowel': 0.990872, 'acc_consonant': 0.991021, 'loss_grapheme': 0.128904, 'loss_vowel': 0.058182, 'loss_consonant': 0.049038}\n",
      "   33 | 0.000015 | 138752/160635 | 0.0841 | 1.7037 |\n",
      "val: {'recall': 0.979945, 'recall_grapheme': 0.969756, 'recall_vowel': 0.990358, 'recall_consonant': 0.989909, 'acc_grapheme': 0.96968, 'acc_vowel': 0.990971, 'acc_consonant': 0.990946, 'loss_grapheme': 0.127359, 'loss_vowel': 0.057341, 'loss_consonant': 0.04749}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 0.000013 | 080896/160635 | 0.0407 | 1.7787 |\n",
      "val: {'recall': 0.980157, 'recall_grapheme': 0.970245, 'recall_vowel': 0.989876, 'recall_consonant': 0.990264, 'acc_grapheme': 0.969954, 'acc_vowel': 0.990847, 'acc_consonant': 0.991071, 'loss_grapheme': 0.125148, 'loss_vowel': 0.055707, 'loss_consonant': 0.046645}\n",
      "** saved\n",
      "   35 | 0.000011 | 023040/160635 | 2.0665 | 1.8259 |\n",
      "val: {'recall': 0.9799, 'recall_grapheme': 0.970212, 'recall_vowel': 0.989807, 'recall_consonant': 0.989371, 'acc_grapheme': 0.970128, 'acc_vowel': 0.990847, 'acc_consonant': 0.990872, 'loss_grapheme': 0.127251, 'loss_vowel': 0.058642, 'loss_consonant': 0.048538}\n",
      "   35 | 0.000008 | 125440/160635 | 4.7399 | 1.9289 |\n",
      "val: {'recall': 0.979536, 'recall_grapheme': 0.969747, 'recall_vowel': 0.989829, 'recall_consonant': 0.98882, 'acc_grapheme': 0.970078, 'acc_vowel': 0.990872, 'acc_consonant': 0.990872, 'loss_grapheme': 0.129282, 'loss_vowel': 0.059558, 'loss_consonant': 0.049141}\n",
      "   36 | 0.000006 | 067584/160635 | 0.0591 | 1.6160 |\n",
      "val: {'recall': 0.980141, 'recall_grapheme': 0.970185, 'recall_vowel': 0.989747, 'recall_consonant': 0.990447, 'acc_grapheme': 0.970402, 'acc_vowel': 0.991021, 'acc_consonant': 0.990996, 'loss_grapheme': 0.123315, 'loss_vowel': 0.05416, 'loss_consonant': 0.04553}\n",
      "   37 | 0.000004 | 009728/160635 | 3.9586 | 1.5181 |\n",
      "val: {'recall': 0.979856, 'recall_grapheme': 0.97011, 'recall_vowel': 0.990054, 'recall_consonant': 0.989152, 'acc_grapheme': 0.970476, 'acc_vowel': 0.991145, 'acc_consonant': 0.990946, 'loss_grapheme': 0.122508, 'loss_vowel': 0.054208, 'loss_consonant': 0.045202}\n",
      "   37 | 0.000002 | 112128/160635 | 4.2680 | 1.6829 |\n",
      "val: {'recall': 0.979882, 'recall_grapheme': 0.970072, 'recall_vowel': 0.989936, 'recall_consonant': 0.989449, 'acc_grapheme': 0.970327, 'acc_vowel': 0.990996, 'acc_consonant': 0.991046, 'loss_grapheme': 0.126202, 'loss_vowel': 0.057526, 'loss_consonant': 0.047794}\n",
      "   38 | 0.000001 | 054272/160635 | 0.0438 | 1.8540 |\n",
      "val: {'recall': 0.980057, 'recall_grapheme': 0.970474, 'recall_vowel': 0.989956, 'recall_consonant': 0.989325, 'acc_grapheme': 0.970252, 'acc_vowel': 0.991071, 'acc_consonant': 0.990897, 'loss_grapheme': 0.128835, 'loss_vowel': 0.059771, 'loss_consonant': 0.04918}\n",
      "   38 | 0.000001 | 156672/160635 | 1.0167 | 1.8992 |\n",
      "val: {'recall': 0.980014, 'recall_grapheme': 0.970349, 'recall_vowel': 0.989973, 'recall_consonant': 0.989385, 'acc_grapheme': 0.969979, 'acc_vowel': 0.990847, 'acc_consonant': 0.990797, 'loss_grapheme': 0.141628, 'loss_vowel': 0.070499, 'loss_consonant': 0.057201}\n",
      "   39 | 0.000001 | 098816/160635 | 0.8953 | 1.5195 |\n",
      "val: {'recall': 0.979784, 'recall_grapheme': 0.969978, 'recall_vowel': 0.989986, 'recall_consonant': 0.989194, 'acc_grapheme': 0.970277, 'acc_vowel': 0.990996, 'acc_consonant': 0.991021, 'loss_grapheme': 0.120168, 'loss_vowel': 0.052029, 'loss_consonant': 0.043613}\n",
      "   40 | 0.000002 | 040960/160635 | 0.0484 | 2.1517 |\n",
      "val: {'recall': 0.980095, 'recall_grapheme': 0.970239, 'recall_vowel': 0.989947, 'recall_consonant': 0.989954, 'acc_grapheme': 0.970402, 'acc_vowel': 0.990822, 'acc_consonant': 0.990797, 'loss_grapheme': 0.131722, 'loss_vowel': 0.061731, 'loss_consonant': 0.051254}\n",
      "   40 | 0.000004 | 143360/160635 | 0.0356 | 1.9273 |\n",
      "val: {'recall': 0.979834, 'recall_grapheme': 0.970146, 'recall_vowel': 0.989863, 'recall_consonant': 0.989179, 'acc_grapheme': 0.970053, 'acc_vowel': 0.990872, 'acc_consonant': 0.990946, 'loss_grapheme': 0.127542, 'loss_vowel': 0.058721, 'loss_consonant': 0.048533}\n",
      "   41 | 0.000006 | 085504/160635 | 0.0554 | 2.0914 |\n",
      "val: {'recall': 0.979779, 'recall_grapheme': 0.970048, 'recall_vowel': 0.989787, 'recall_consonant': 0.989233, 'acc_grapheme': 0.969805, 'acc_vowel': 0.990772, 'acc_consonant': 0.990673, 'loss_grapheme': 0.138792, 'loss_vowel': 0.068118, 'loss_consonant': 0.055945}\n",
      "   42 | 0.000008 | 027648/160635 | 0.0690 | 1.8879 |\n",
      "val: {'recall': 0.980444, 'recall_grapheme': 0.97035, 'recall_vowel': 0.989952, 'recall_consonant': 0.991125, 'acc_grapheme': 0.970302, 'acc_vowel': 0.990897, 'acc_consonant': 0.990922, 'loss_grapheme': 0.130276, 'loss_vowel': 0.061638, 'loss_consonant': 0.051613}\n",
      "** saved\n",
      "   42 | 0.000011 | 130048/160635 | 2.9852 | 1.8028 |\n",
      "val: {'recall': 0.980137, 'recall_grapheme': 0.970607, 'recall_vowel': 0.990007, 'recall_consonant': 0.989327, 'acc_grapheme': 0.970377, 'acc_vowel': 0.990996, 'acc_consonant': 0.990996, 'loss_grapheme': 0.12747, 'loss_vowel': 0.059688, 'loss_consonant': 0.049167}\n",
      "   43 | 0.000013 | 072192/160635 | 0.0452 | 1.7111 |\n",
      "val: {'recall': 0.980034, 'recall_grapheme': 0.969898, 'recall_vowel': 0.989912, 'recall_consonant': 0.990427, 'acc_grapheme': 0.970327, 'acc_vowel': 0.991021, 'acc_consonant': 0.990996, 'loss_grapheme': 0.126723, 'loss_vowel': 0.058088, 'loss_consonant': 0.048428}\n",
      "   44 | 0.000015 | 014336/160635 | 4.7416 | 1.8187 |\n",
      "val: {'recall': 0.979947, 'recall_grapheme': 0.969766, 'recall_vowel': 0.990107, 'recall_consonant': 0.990148, 'acc_grapheme': 0.970327, 'acc_vowel': 0.991021, 'acc_consonant': 0.991096, 'loss_grapheme': 0.124623, 'loss_vowel': 0.056618, 'loss_consonant': 0.047092}\n",
      "   44 | 0.000017 | 116736/160635 | 3.4770 | 1.7364 |\n",
      "val: {'recall': 0.980111, 'recall_grapheme': 0.970825, 'recall_vowel': 0.990088, 'recall_consonant': 0.988706, 'acc_grapheme': 0.970501, 'acc_vowel': 0.991021, 'acc_consonant': 0.990971, 'loss_grapheme': 0.126679, 'loss_vowel': 0.057349, 'loss_consonant': 0.047341}\n",
      "   45 | 0.000019 | 058880/160635 | 3.1718 | 1.7963 |\n",
      "val: {'recall': 0.980039, 'recall_grapheme': 0.970307, 'recall_vowel': 0.989653, 'recall_consonant': 0.989887, 'acc_grapheme': 0.970427, 'acc_vowel': 0.990847, 'acc_consonant': 0.990971, 'loss_grapheme': 0.126363, 'loss_vowel': 0.057587, 'loss_consonant': 0.048112}\n",
      "   46 | 0.000020 | 001024/160635 | 0.0712 | 1.6626 |\n",
      "val: {'recall': 0.980403, 'recall_grapheme': 0.970875, 'recall_vowel': 0.98997, 'recall_consonant': 0.989892, 'acc_grapheme': 0.970377, 'acc_vowel': 0.990971, 'acc_consonant': 0.991071, 'loss_grapheme': 0.131329, 'loss_vowel': 0.063365, 'loss_consonant': 0.050791}\n",
      "   46 | 0.000020 | 103424/160635 | 3.6352 | 1.5277 |\n",
      "val: {'recall': 0.979895, 'recall_grapheme': 0.970634, 'recall_vowel': 0.990232, 'recall_consonant': 0.988079, 'acc_grapheme': 0.970228, 'acc_vowel': 0.991195, 'acc_consonant': 0.991071, 'loss_grapheme': 0.122569, 'loss_vowel': 0.054524, 'loss_consonant': 0.045518}\n",
      "   47 | 0.000020 | 045568/160635 | 4.7309 | 1.7974 |\n",
      "val: {'recall': 0.980025, 'recall_grapheme': 0.970345, 'recall_vowel': 0.990122, 'recall_consonant': 0.989287, 'acc_grapheme': 0.970128, 'acc_vowel': 0.991046, 'acc_consonant': 0.990996, 'loss_grapheme': 0.126188, 'loss_vowel': 0.056567, 'loss_consonant': 0.047941}\n",
      "   47 | 0.000019 | 147968/160635 | 3.8082 | 1.8162 |\n",
      "val: {'recall': 0.980352, 'recall_grapheme': 0.97074, 'recall_vowel': 0.98993, 'recall_consonant': 0.989999, 'acc_grapheme': 0.970725, 'acc_vowel': 0.991121, 'acc_consonant': 0.991195, 'loss_grapheme': 0.125953, 'loss_vowel': 0.058073, 'loss_consonant': 0.048434}\n",
      "   48 | 0.000017 | 090112/160635 | 4.4202 | 1.6670 |\n",
      "val: {'recall': 0.980522, 'recall_grapheme': 0.971113, 'recall_vowel': 0.989944, 'recall_consonant': 0.989917, 'acc_grapheme': 0.97075, 'acc_vowel': 0.991195, 'acc_consonant': 0.991195, 'loss_grapheme': 0.121527, 'loss_vowel': 0.054813, 'loss_consonant': 0.045598}\n",
      "** saved\n",
      "   49 | 0.000015 | 032256/160635 | 4.7270 | 2.2625 |\n",
      "val: {'recall': 0.980054, 'recall_grapheme': 0.970414, 'recall_vowel': 0.98995, 'recall_consonant': 0.989437, 'acc_grapheme': 0.970601, 'acc_vowel': 0.990971, 'acc_consonant': 0.990996, 'loss_grapheme': 0.139383, 'loss_vowel': 0.069262, 'loss_consonant': 0.055438}\n",
      "   49 | 0.000013 | 134656/160635 | 0.0715 | 1.8720 |\n",
      "val: {'recall': 0.980143, 'recall_grapheme': 0.970313, 'recall_vowel': 0.990051, 'recall_consonant': 0.989896, 'acc_grapheme': 0.970601, 'acc_vowel': 0.991071, 'acc_consonant': 0.991344, 'loss_grapheme': 0.125125, 'loss_vowel': 0.057218, 'loss_consonant': 0.047226}\n",
      "   50 | 0.000011 | 076800/160635 | 2.1134 | 1.6496 |\n",
      "val: {'recall': 0.980039, 'recall_grapheme': 0.970467, 'recall_vowel': 0.989873, 'recall_consonant': 0.989348, 'acc_grapheme': 0.97065, 'acc_vowel': 0.991071, 'acc_consonant': 0.99127, 'loss_grapheme': 0.124678, 'loss_vowel': 0.05727, 'loss_consonant': 0.047018}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 | 0.000008 | 018944/160635 | 1.7934 | 2.0777 |\n",
      "val: {'recall': 0.980174, 'recall_grapheme': 0.970374, 'recall_vowel': 0.990034, 'recall_consonant': 0.989913, 'acc_grapheme': 0.9707, 'acc_vowel': 0.991195, 'acc_consonant': 0.991319, 'loss_grapheme': 0.125993, 'loss_vowel': 0.058161, 'loss_consonant': 0.04817}\n",
      "   51 | 0.000006 | 121344/160635 | 1.5485 | 1.7957 |\n",
      "val: {'recall': 0.980236, 'recall_grapheme': 0.970331, 'recall_vowel': 0.990109, 'recall_consonant': 0.99017, 'acc_grapheme': 0.9707, 'acc_vowel': 0.99117, 'acc_consonant': 0.991444, 'loss_grapheme': 0.126141, 'loss_vowel': 0.058823, 'loss_consonant': 0.048424}\n",
      "   52 | 0.000004 | 063488/160635 | 3.3391 | 1.9434 |\n",
      "val: {'recall': 0.980179, 'recall_grapheme': 0.970413, 'recall_vowel': 0.989864, 'recall_consonant': 0.990024, 'acc_grapheme': 0.970551, 'acc_vowel': 0.990847, 'acc_consonant': 0.991121, 'loss_grapheme': 0.136572, 'loss_vowel': 0.067385, 'loss_consonant': 0.055233}\n",
      "   53 | 0.000002 | 005632/160635 | 3.7805 | 1.2905 |\n",
      "val: {'recall': 0.979997, 'recall_grapheme': 0.970355, 'recall_vowel': 0.989863, 'recall_consonant': 0.989416, 'acc_grapheme': 0.970501, 'acc_vowel': 0.990922, 'acc_consonant': 0.991245, 'loss_grapheme': 0.130577, 'loss_vowel': 0.062338, 'loss_consonant': 0.050885}\n",
      "   53 | 0.000001 | 108032/160635 | 0.0736 | 1.5775 |\n",
      "val: {'recall': 0.980173, 'recall_grapheme': 0.970981, 'recall_vowel': 0.989911, 'recall_consonant': 0.988818, 'acc_grapheme': 0.970999, 'acc_vowel': 0.99117, 'acc_consonant': 0.991245, 'loss_grapheme': 0.119876, 'loss_vowel': 0.052932, 'loss_consonant': 0.043937}\n",
      "   54 | 0.000001 | 050176/160635 | 1.5120 | 1.4993 |\n",
      "val: {'recall': 0.980339, 'recall_grapheme': 0.97103, 'recall_vowel': 0.989891, 'recall_consonant': 0.989404, 'acc_grapheme': 0.971098, 'acc_vowel': 0.991145, 'acc_consonant': 0.99127, 'loss_grapheme': 0.120985, 'loss_vowel': 0.053742, 'loss_consonant': 0.044729}\n",
      "   54 | 0.000001 | 152576/160635 | 0.0442 | 1.7352 |\n",
      "val: {'recall': 0.980089, 'recall_grapheme': 0.970534, 'recall_vowel': 0.989918, 'recall_consonant': 0.98937, 'acc_grapheme': 0.970725, 'acc_vowel': 0.991021, 'acc_consonant': 0.99122, 'loss_grapheme': 0.12905, 'loss_vowel': 0.060971, 'loss_consonant': 0.049797}\n",
      "   55 | 0.000002 | 094720/160635 | 0.0573 | 2.1314 |\n",
      "val: {'recall': 0.980194, 'recall_grapheme': 0.970443, 'recall_vowel': 0.989849, 'recall_consonant': 0.990042, 'acc_grapheme': 0.970501, 'acc_vowel': 0.990872, 'acc_consonant': 0.991195, 'loss_grapheme': 0.139816, 'loss_vowel': 0.070042, 'loss_consonant': 0.05672}\n",
      "   56 | 0.000004 | 036864/160635 | 5.1718 | 1.4650 |\n",
      "val: {'recall': 0.980351, 'recall_grapheme': 0.971095, 'recall_vowel': 0.990009, 'recall_consonant': 0.989207, 'acc_grapheme': 0.971024, 'acc_vowel': 0.99122, 'acc_consonant': 0.99122, 'loss_grapheme': 0.119944, 'loss_vowel': 0.052237, 'loss_consonant': 0.043689}\n",
      "   56 | 0.000006 | 139264/160635 | 0.0375 | 1.7008 |\n",
      "val: {'recall': 0.980311, 'recall_grapheme': 0.970926, 'recall_vowel': 0.990022, 'recall_consonant': 0.989369, 'acc_grapheme': 0.970849, 'acc_vowel': 0.99117, 'acc_consonant': 0.99127, 'loss_grapheme': 0.12412, 'loss_vowel': 0.056645, 'loss_consonant': 0.047166}\n",
      "   57 | 0.000008 | 081408/160635 | 0.0426 | 1.7997 |\n",
      "val: {'recall': 0.980407, 'recall_grapheme': 0.97087, 'recall_vowel': 0.990074, 'recall_consonant': 0.989814, 'acc_grapheme': 0.970551, 'acc_vowel': 0.991071, 'acc_consonant': 0.991121, 'loss_grapheme': 0.13021, 'loss_vowel': 0.061802, 'loss_consonant': 0.050872}\n",
      "   58 | 0.000011 | 023552/160635 | 0.0418 | 2.3439 |\n",
      "val: {'recall': 0.980313, 'recall_grapheme': 0.970833, 'recall_vowel': 0.989616, 'recall_consonant': 0.989968, 'acc_grapheme': 0.970675, 'acc_vowel': 0.990922, 'acc_consonant': 0.99122, 'loss_grapheme': 0.130091, 'loss_vowel': 0.062077, 'loss_consonant': 0.051447}\n",
      "   58 | 0.000013 | 125952/160635 | 4.4785 | 1.8856 |\n",
      "val: {'recall': 0.980231, 'recall_grapheme': 0.970807, 'recall_vowel': 0.989917, 'recall_consonant': 0.989394, 'acc_grapheme': 0.970825, 'acc_vowel': 0.99127, 'acc_consonant': 0.99127, 'loss_grapheme': 0.120155, 'loss_vowel': 0.052854, 'loss_consonant': 0.044062}\n",
      "   59 | 0.000015 | 068096/160635 | 0.0556 | 1.7645 |\n",
      "val: {'recall': 0.980066, 'recall_grapheme': 0.970573, 'recall_vowel': 0.989987, 'recall_consonant': 0.989133, 'acc_grapheme': 0.970501, 'acc_vowel': 0.991195, 'acc_consonant': 0.99122, 'loss_grapheme': 0.120894, 'loss_vowel': 0.053891, 'loss_consonant': 0.044492}\n",
      "   60 | 0.000017 | 010240/160635 | 0.0523 | 1.3431 |\n",
      "val: {'recall': 0.980562, 'recall_grapheme': 0.97134, 'recall_vowel': 0.990241, 'recall_consonant': 0.989329, 'acc_grapheme': 0.971098, 'acc_vowel': 0.99127, 'acc_consonant': 0.991245, 'loss_grapheme': 0.12091, 'loss_vowel': 0.053991, 'loss_consonant': 0.044364}\n",
      "** saved\n",
      "   60 | 0.000019 | 112640/160635 | 4.9462 | 1.7080 |\n",
      "val: {'recall': 0.980186, 'recall_grapheme': 0.970769, 'recall_vowel': 0.98957, 'recall_consonant': 0.989636, 'acc_grapheme': 0.971222, 'acc_vowel': 0.991121, 'acc_consonant': 0.990922, 'loss_grapheme': 0.123626, 'loss_vowel': 0.056968, 'loss_consonant': 0.047192}\n",
      "   61 | 0.000020 | 054784/160635 | 0.0296 | 1.6530 |\n",
      "val: {'recall': 0.980193, 'recall_grapheme': 0.970735, 'recall_vowel': 0.989781, 'recall_consonant': 0.989522, 'acc_grapheme': 0.970451, 'acc_vowel': 0.991245, 'acc_consonant': 0.991295, 'loss_grapheme': 0.124118, 'loss_vowel': 0.056732, 'loss_consonant': 0.047072}\n",
      "   61 | 0.000020 | 157184/160635 | 0.0627 | 1.7366 |\n",
      "val: {'recall': 0.980278, 'recall_grapheme': 0.970697, 'recall_vowel': 0.989958, 'recall_consonant': 0.98976, 'acc_grapheme': 0.970924, 'acc_vowel': 0.991369, 'acc_consonant': 0.991494, 'loss_grapheme': 0.122895, 'loss_vowel': 0.055928, 'loss_consonant': 0.047023}\n",
      "   62 | 0.000020 | 099328/160635 | 0.0624 | 1.9704 |\n",
      "val: {'recall': 0.980594, 'recall_grapheme': 0.970451, 'recall_vowel': 0.990253, 'recall_consonant': 0.991221, 'acc_grapheme': 0.970825, 'acc_vowel': 0.991245, 'acc_consonant': 0.991145, 'loss_grapheme': 0.134478, 'loss_vowel': 0.066979, 'loss_consonant': 0.055148}\n",
      "** saved\n",
      "   63 | 0.000019 | 041472/160635 | 0.0673 | 2.0528 |\n",
      "val: {'recall': 0.980343, 'recall_grapheme': 0.971176, 'recall_vowel': 0.989797, 'recall_consonant': 0.989223, 'acc_grapheme': 0.971347, 'acc_vowel': 0.991295, 'acc_consonant': 0.991096, 'loss_grapheme': 0.130401, 'loss_vowel': 0.063107, 'loss_consonant': 0.051908}\n",
      "   63 | 0.000017 | 143872/160635 | 0.0552 | 1.8852 |\n",
      "val: {'recall': 0.980221, 'recall_grapheme': 0.97065, 'recall_vowel': 0.990448, 'recall_consonant': 0.989137, 'acc_grapheme': 0.971048, 'acc_vowel': 0.991494, 'acc_consonant': 0.991096, 'loss_grapheme': 0.123672, 'loss_vowel': 0.056263, 'loss_consonant': 0.047643}\n",
      "   64 | 0.000015 | 086016/160635 | 0.0250 | 1.8119 |\n",
      "val: {'recall': 0.980466, 'recall_grapheme': 0.971383, 'recall_vowel': 0.989708, 'recall_consonant': 0.989392, 'acc_grapheme': 0.971222, 'acc_vowel': 0.991319, 'acc_consonant': 0.991245, 'loss_grapheme': 0.123887, 'loss_vowel': 0.056655, 'loss_consonant': 0.047555}\n",
      "   65 | 0.000013 | 028160/160635 | 4.4357 | 1.8841 |\n",
      "val: {'recall': 0.980414, 'recall_grapheme': 0.970971, 'recall_vowel': 0.990364, 'recall_consonant': 0.989348, 'acc_grapheme': 0.971173, 'acc_vowel': 0.991344, 'acc_consonant': 0.991096, 'loss_grapheme': 0.130839, 'loss_vowel': 0.063629, 'loss_consonant': 0.052339}\n",
      "   65 | 0.000011 | 130560/160635 | 2.7477 | 1.8891 |\n",
      "val: {'recall': 0.980585, 'recall_grapheme': 0.971564, 'recall_vowel': 0.989782, 'recall_consonant': 0.989428, 'acc_grapheme': 0.971247, 'acc_vowel': 0.99122, 'acc_consonant': 0.99117, 'loss_grapheme': 0.132968, 'loss_vowel': 0.064753, 'loss_consonant': 0.053199}\n",
      "   66 | 0.000008 | 072704/160635 | 2.8757 | 1.7507 |\n",
      "val: {'recall': 0.980513, 'recall_grapheme': 0.971419, 'recall_vowel': 0.989782, 'recall_consonant': 0.989433, 'acc_grapheme': 0.971446, 'acc_vowel': 0.99122, 'acc_consonant': 0.991145, 'loss_grapheme': 0.127604, 'loss_vowel': 0.06007, 'loss_consonant': 0.049181}\n",
      "   67 | 0.000006 | 014848/160635 | 4.0879 | 1.5352 |\n",
      "val: {'recall': 0.980359, 'recall_grapheme': 0.971285, 'recall_vowel': 0.990022, 'recall_consonant': 0.988845, 'acc_grapheme': 0.971471, 'acc_vowel': 0.991568, 'acc_consonant': 0.991295, 'loss_grapheme': 0.117565, 'loss_vowel': 0.051409, 'loss_consonant': 0.042959}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 | 0.000004 | 117248/160635 | 2.4431 | 1.8696 |\n",
      "val: {'recall': 0.980525, 'recall_grapheme': 0.97151, 'recall_vowel': 0.990187, 'recall_consonant': 0.988894, 'acc_grapheme': 0.971471, 'acc_vowel': 0.991245, 'acc_consonant': 0.99117, 'loss_grapheme': 0.124817, 'loss_vowel': 0.058292, 'loss_consonant': 0.047772}\n",
      "   68 | 0.000002 | 059392/160635 | 0.0302 | 1.7790 |\n",
      "val: {'recall': 0.980411, 'recall_grapheme': 0.9714, 'recall_vowel': 0.99004, 'recall_consonant': 0.988805, 'acc_grapheme': 0.971645, 'acc_vowel': 0.991344, 'acc_consonant': 0.991245, 'loss_grapheme': 0.120157, 'loss_vowel': 0.054312, 'loss_consonant': 0.044744}\n",
      "   69 | 0.000001 | 001536/160635 | 4.9364 | 3.1027 |\n",
      "val: {'recall': 0.980694, 'recall_grapheme': 0.971609, 'recall_vowel': 0.990114, 'recall_consonant': 0.989443, 'acc_grapheme': 0.971496, 'acc_vowel': 0.99122, 'acc_consonant': 0.991046, 'loss_grapheme': 0.130403, 'loss_vowel': 0.06365, 'loss_consonant': 0.052036}\n",
      "** saved\n",
      "   69 | 0.000001 | 103936/160635 | 0.0535 | 1.5138 |\n",
      "val: {'recall': 0.980617, 'recall_grapheme': 0.971731, 'recall_vowel': 0.990241, 'recall_consonant': 0.988763, 'acc_grapheme': 0.972043, 'acc_vowel': 0.991643, 'acc_consonant': 0.991369, 'loss_grapheme': 0.112926, 'loss_vowel': 0.047121, 'loss_consonant': 0.039552}\n",
      "   70 | 0.000001 | 046080/160635 | 3.6329 | 1.6656 |\n",
      "val: {'recall': 0.980512, 'recall_grapheme': 0.971536, 'recall_vowel': 0.990131, 'recall_consonant': 0.988845, 'acc_grapheme': 0.971645, 'acc_vowel': 0.991369, 'acc_consonant': 0.991295, 'loss_grapheme': 0.121686, 'loss_vowel': 0.05551, 'loss_consonant': 0.045694}\n",
      "   70 | 0.000002 | 148480/160635 | 3.9104 | 1.8359 |\n",
      "val: {'recall': 0.980647, 'recall_grapheme': 0.971816, 'recall_vowel': 0.990144, 'recall_consonant': 0.988812, 'acc_grapheme': 0.971496, 'acc_vowel': 0.99117, 'acc_consonant': 0.991071, 'loss_grapheme': 0.127335, 'loss_vowel': 0.060609, 'loss_consonant': 0.050131}\n",
      "   71 | 0.000004 | 090624/160635 | 3.2836 | 1.6604 |\n",
      "val: {'recall': 0.980524, 'recall_grapheme': 0.971487, 'recall_vowel': 0.990335, 'recall_consonant': 0.988787, 'acc_grapheme': 0.97172, 'acc_vowel': 0.991469, 'acc_consonant': 0.99127, 'loss_grapheme': 0.121258, 'loss_vowel': 0.05484, 'loss_consonant': 0.045469}\n",
      "   72 | 0.000006 | 032768/160635 | 0.0427 | 1.7644 |\n",
      "val: {'recall': 0.980703, 'recall_grapheme': 0.971675, 'recall_vowel': 0.990235, 'recall_consonant': 0.98923, 'acc_grapheme': 0.97167, 'acc_vowel': 0.991543, 'acc_consonant': 0.991245, 'loss_grapheme': 0.121655, 'loss_vowel': 0.054843, 'loss_consonant': 0.045305}\n",
      "** saved\n",
      "   72 | 0.000008 | 135168/160635 | 0.0550 | 1.6201 |\n",
      "val: {'recall': 0.980528, 'recall_grapheme': 0.971234, 'recall_vowel': 0.99029, 'recall_consonant': 0.989354, 'acc_grapheme': 0.971571, 'acc_vowel': 0.991419, 'acc_consonant': 0.991145, 'loss_grapheme': 0.120106, 'loss_vowel': 0.05329, 'loss_consonant': 0.044513}\n",
      "   73 | 0.000010 | 077312/160635 | 0.0468 | 2.0044 |\n",
      "val: {'recall': 0.98064, 'recall_grapheme': 0.971289, 'recall_vowel': 0.990457, 'recall_consonant': 0.989524, 'acc_grapheme': 0.971571, 'acc_vowel': 0.991568, 'acc_consonant': 0.991295, 'loss_grapheme': 0.126667, 'loss_vowel': 0.060746, 'loss_consonant': 0.049533}\n",
      "   74 | 0.000013 | 019456/160635 | 4.0303 | 2.1267 |\n",
      "val: {'recall': 0.980803, 'recall_grapheme': 0.971932, 'recall_vowel': 0.990351, 'recall_consonant': 0.988999, 'acc_grapheme': 0.971272, 'acc_vowel': 0.991295, 'acc_consonant': 0.991195, 'loss_grapheme': 0.13261, 'loss_vowel': 0.063823, 'loss_consonant': 0.052148}\n",
      "** saved\n",
      "   74 | 0.000015 | 121856/160635 | 0.0519 | 1.8453 |\n",
      "val: {'recall': 0.98067, 'recall_grapheme': 0.971615, 'recall_vowel': 0.990192, 'recall_consonant': 0.989257, 'acc_grapheme': 0.971645, 'acc_vowel': 0.991319, 'acc_consonant': 0.991071, 'loss_grapheme': 0.124041, 'loss_vowel': 0.057229, 'loss_consonant': 0.047437}\n",
      "   75 | 0.000017 | 064000/160635 | 4.1933 | 1.5528 |\n",
      "val: {'recall': 0.980431, 'recall_grapheme': 0.971113, 'recall_vowel': 0.990288, 'recall_consonant': 0.98921, 'acc_grapheme': 0.971571, 'acc_vowel': 0.991344, 'acc_consonant': 0.991444, 'loss_grapheme': 0.117657, 'loss_vowel': 0.052217, 'loss_consonant': 0.043234}\n",
      "   76 | 0.000019 | 006144/160635 | 2.0977 | 1.4733 |\n",
      "val: {'recall': 0.980545, 'recall_grapheme': 0.971528, 'recall_vowel': 0.990123, 'recall_consonant': 0.989001, 'acc_grapheme': 0.971496, 'acc_vowel': 0.991295, 'acc_consonant': 0.99127, 'loss_grapheme': 0.123809, 'loss_vowel': 0.057852, 'loss_consonant': 0.048139}\n",
      "   76 | 0.000020 | 108544/160635 | 0.0362 | 1.8022 |\n",
      "val: {'recall': 0.980544, 'recall_grapheme': 0.971245, 'recall_vowel': 0.990108, 'recall_consonant': 0.989579, 'acc_grapheme': 0.971471, 'acc_vowel': 0.991494, 'acc_consonant': 0.991145, 'loss_grapheme': 0.121907, 'loss_vowel': 0.055343, 'loss_consonant': 0.046825}\n",
      "   77 | 0.000020 | 050688/160635 | 0.2985 | 1.7813 |\n",
      "val: {'recall': 0.980513, 'recall_grapheme': 0.971397, 'recall_vowel': 0.98999, 'recall_consonant': 0.989267, 'acc_grapheme': 0.971596, 'acc_vowel': 0.991543, 'acc_consonant': 0.991145, 'loss_grapheme': 0.122801, 'loss_vowel': 0.056775, 'loss_consonant': 0.046503}\n",
      "   77 | 0.000020 | 153088/160635 | 2.1539 | 1.6841 |\n",
      "val: {'recall': 0.980892, 'recall_grapheme': 0.971741, 'recall_vowel': 0.990532, 'recall_consonant': 0.989551, 'acc_grapheme': 0.971645, 'acc_vowel': 0.991593, 'acc_consonant': 0.991145, 'loss_grapheme': 0.120329, 'loss_vowel': 0.054342, 'loss_consonant': 0.046211}\n",
      "** saved\n",
      "   78 | 0.000019 | 095232/160635 | 0.0396 | 1.4510 |\n",
      "val: {'recall': 0.980831, 'recall_grapheme': 0.972178, 'recall_vowel': 0.990661, 'recall_consonant': 0.988306, 'acc_grapheme': 0.971819, 'acc_vowel': 0.991792, 'acc_consonant': 0.991121, 'loss_grapheme': 0.114035, 'loss_vowel': 0.047657, 'loss_consonant': 0.039951}\n",
      "   79 | 0.000017 | 037376/160635 | 2.8230 | 1.6653 |\n",
      "val: {'recall': 0.980754, 'recall_grapheme': 0.971861, 'recall_vowel': 0.990273, 'recall_consonant': 0.989019, 'acc_grapheme': 0.971869, 'acc_vowel': 0.991518, 'acc_consonant': 0.991295, 'loss_grapheme': 0.12177, 'loss_vowel': 0.055048, 'loss_consonant': 0.044621}\n",
      "   79 | 0.000015 | 139776/160635 | 4.0750 | 1.7492 |\n",
      "val: {'recall': 0.980697, 'recall_grapheme': 0.971282, 'recall_vowel': 0.99079, 'recall_consonant': 0.989435, 'acc_grapheme': 0.97162, 'acc_vowel': 0.991643, 'acc_consonant': 0.991344, 'loss_grapheme': 0.121933, 'loss_vowel': 0.056507, 'loss_consonant': 0.046791}\n",
      "   80 | 0.000013 | 081920/160635 | 3.1950 | 1.8807 |\n",
      "val: {'recall': 0.980619, 'recall_grapheme': 0.971363, 'recall_vowel': 0.990407, 'recall_consonant': 0.989341, 'acc_grapheme': 0.971819, 'acc_vowel': 0.991543, 'acc_consonant': 0.99117, 'loss_grapheme': 0.122844, 'loss_vowel': 0.056999, 'loss_consonant': 0.047205}\n",
      "   81 | 0.000010 | 024064/160635 | 3.7241 | 1.6339 |\n",
      "val: {'recall': 0.980608, 'recall_grapheme': 0.971679, 'recall_vowel': 0.990254, 'recall_consonant': 0.988818, 'acc_grapheme': 0.971969, 'acc_vowel': 0.991543, 'acc_consonant': 0.99117, 'loss_grapheme': 0.122265, 'loss_vowel': 0.05665, 'loss_consonant': 0.046857}\n",
      "   81 | 0.000008 | 126464/160635 | 3.1163 | 1.7937 |\n",
      "val: {'recall': 0.980597, 'recall_grapheme': 0.971322, 'recall_vowel': 0.99036, 'recall_consonant': 0.989383, 'acc_grapheme': 0.971819, 'acc_vowel': 0.991518, 'acc_consonant': 0.991245, 'loss_grapheme': 0.125884, 'loss_vowel': 0.059934, 'loss_consonant': 0.049408}\n",
      "   82 | 0.000006 | 068608/160635 | 0.0588 | 1.6703 |\n",
      "val: {'recall': 0.981137, 'recall_grapheme': 0.972431, 'recall_vowel': 0.990449, 'recall_consonant': 0.989236, 'acc_grapheme': 0.972118, 'acc_vowel': 0.991643, 'acc_consonant': 0.991046, 'loss_grapheme': 0.118402, 'loss_vowel': 0.052463, 'loss_consonant': 0.043662}\n",
      "** saved\n",
      "   83 | 0.000004 | 010752/160635 | 3.6981 | 1.6637 |\n",
      "val: {'recall': 0.980897, 'recall_grapheme': 0.972137, 'recall_vowel': 0.990508, 'recall_consonant': 0.988805, 'acc_grapheme': 0.972118, 'acc_vowel': 0.991593, 'acc_consonant': 0.99117, 'loss_grapheme': 0.119429, 'loss_vowel': 0.05401, 'loss_consonant': 0.044283}\n",
      "   83 | 0.000002 | 113152/160635 | 4.9005 | 1.8099 |\n",
      "val: {'recall': 0.98112, 'recall_grapheme': 0.972274, 'recall_vowel': 0.990634, 'recall_consonant': 0.989298, 'acc_grapheme': 0.972043, 'acc_vowel': 0.991618, 'acc_consonant': 0.991121, 'loss_grapheme': 0.121689, 'loss_vowel': 0.055963, 'loss_consonant': 0.045866}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84 | 0.000001 | 055296/160635 | 3.3735 | 1.8579 |\n",
      "val: {'recall': 0.980927, 'recall_grapheme': 0.972212, 'recall_vowel': 0.990275, 'recall_consonant': 0.989008, 'acc_grapheme': 0.972068, 'acc_vowel': 0.991568, 'acc_consonant': 0.99127, 'loss_grapheme': 0.121251, 'loss_vowel': 0.055526, 'loss_consonant': 0.04602}\n",
      "   84 | 0.000001 | 157696/160635 | 0.0284 | 1.8262 |\n",
      "val: {'recall': 0.980976, 'recall_grapheme': 0.972299, 'recall_vowel': 0.99043, 'recall_consonant': 0.988877, 'acc_grapheme': 0.971944, 'acc_vowel': 0.991593, 'acc_consonant': 0.991295, 'loss_grapheme': 0.119184, 'loss_vowel': 0.053978, 'loss_consonant': 0.044814}\n",
      "   85 | 0.000001 | 099840/160635 | 2.1357 | 1.8194 |\n",
      "val: {'recall': 0.981011, 'recall_grapheme': 0.972328, 'recall_vowel': 0.990478, 'recall_consonant': 0.988911, 'acc_grapheme': 0.971944, 'acc_vowel': 0.991469, 'acc_consonant': 0.99122, 'loss_grapheme': 0.123304, 'loss_vowel': 0.057872, 'loss_consonant': 0.047619}\n",
      "   86 | 0.000002 | 041984/160635 | 0.0554 | 1.6653 |\n",
      "val: {'recall': 0.980843, 'recall_grapheme': 0.972042, 'recall_vowel': 0.990426, 'recall_consonant': 0.988862, 'acc_grapheme': 0.97177, 'acc_vowel': 0.991618, 'acc_consonant': 0.99122, 'loss_grapheme': 0.118239, 'loss_vowel': 0.053407, 'loss_consonant': 0.044352}\n",
      "   86 | 0.000004 | 144384/160635 | 0.0314 | 1.6368 |\n",
      "val: {'recall': 0.98073, 'recall_grapheme': 0.971689, 'recall_vowel': 0.990669, 'recall_consonant': 0.988873, 'acc_grapheme': 0.972018, 'acc_vowel': 0.991767, 'acc_consonant': 0.991319, 'loss_grapheme': 0.112953, 'loss_vowel': 0.048514, 'loss_consonant': 0.040613}\n",
      "   87 | 0.000006 | 086528/160635 | 0.0211 | 1.6351 |\n",
      "val: {'recall': 0.980625, 'recall_grapheme': 0.971781, 'recall_vowel': 0.99017, 'recall_consonant': 0.98877, 'acc_grapheme': 0.972093, 'acc_vowel': 0.991618, 'acc_consonant': 0.991245, 'loss_grapheme': 0.114075, 'loss_vowel': 0.049192, 'loss_consonant': 0.041231}\n",
      "   88 | 0.000008 | 028672/160635 | 4.2315 | 1.2728 |\n",
      "val: {'recall': 0.980552, 'recall_grapheme': 0.971274, 'recall_vowel': 0.99036, 'recall_consonant': 0.9893, 'acc_grapheme': 0.971944, 'acc_vowel': 0.991568, 'acc_consonant': 0.991245, 'loss_grapheme': 0.11546, 'loss_vowel': 0.050555, 'loss_consonant': 0.041869}\n",
      "   88 | 0.000010 | 131072/160635 | 0.0522 | 1.6692 |\n",
      "val: {'recall': 0.980521, 'recall_grapheme': 0.971374, 'recall_vowel': 0.989997, 'recall_consonant': 0.989341, 'acc_grapheme': 0.971944, 'acc_vowel': 0.991494, 'acc_consonant': 0.991319, 'loss_grapheme': 0.12052, 'loss_vowel': 0.056027, 'loss_consonant': 0.045996}\n",
      "   89 | 0.000013 | 073216/160635 | 0.0237 | 1.8249 |\n",
      "val: {'recall': 0.980841, 'recall_grapheme': 0.971704, 'recall_vowel': 0.990816, 'recall_consonant': 0.989142, 'acc_grapheme': 0.972143, 'acc_vowel': 0.991792, 'acc_consonant': 0.991394, 'loss_grapheme': 0.12011, 'loss_vowel': 0.054405, 'loss_consonant': 0.04531}\n",
      "   90 | 0.000015 | 015360/160635 | 4.6802 | 1.8337 |\n",
      "val: {'recall': 0.980746, 'recall_grapheme': 0.971575, 'recall_vowel': 0.990877, 'recall_consonant': 0.988958, 'acc_grapheme': 0.971695, 'acc_vowel': 0.991767, 'acc_consonant': 0.991319, 'loss_grapheme': 0.122737, 'loss_vowel': 0.057518, 'loss_consonant': 0.046968}\n",
      "   90 | 0.000017 | 117760/160635 | 4.0257 | 1.9983 |\n",
      "val: {'recall': 0.981107, 'recall_grapheme': 0.972294, 'recall_vowel': 0.990446, 'recall_consonant': 0.989392, 'acc_grapheme': 0.971994, 'acc_vowel': 0.991518, 'acc_consonant': 0.991145, 'loss_grapheme': 0.128538, 'loss_vowel': 0.062659, 'loss_consonant': 0.050952}\n",
      "   91 | 0.000019 | 059904/160635 | 2.7605 | 1.3852 |\n",
      "val: {'recall': 0.981092, 'recall_grapheme': 0.972394, 'recall_vowel': 0.990509, 'recall_consonant': 0.98907, 'acc_grapheme': 0.97259, 'acc_vowel': 0.991817, 'acc_consonant': 0.991319, 'loss_grapheme': 0.114218, 'loss_vowel': 0.048981, 'loss_consonant': 0.040739}\n",
      "   92 | 0.000020 | 002048/160635 | 0.0444 | 0.0436 |\n",
      "val: {'recall': 0.980493, 'recall_grapheme': 0.971831, 'recall_vowel': 0.990404, 'recall_consonant': 0.987904, 'acc_grapheme': 0.972466, 'acc_vowel': 0.991742, 'acc_consonant': 0.991295, 'loss_grapheme': 0.114969, 'loss_vowel': 0.049722, 'loss_consonant': 0.041939}\n",
      "   92 | 0.000020 | 104448/160635 | 0.0454 | 1.6323 |\n",
      "val: {'recall': 0.980779, 'recall_grapheme': 0.971913, 'recall_vowel': 0.990265, 'recall_consonant': 0.989025, 'acc_grapheme': 0.972541, 'acc_vowel': 0.991892, 'acc_consonant': 0.991295, 'loss_grapheme': 0.114832, 'loss_vowel': 0.048702, 'loss_consonant': 0.04187}\n",
      "   93 | 0.000020 | 046592/160635 | 0.0339 | 1.2594 |\n",
      "val: {'recall': 0.98034, 'recall_grapheme': 0.971242, 'recall_vowel': 0.990451, 'recall_consonant': 0.988424, 'acc_grapheme': 0.972118, 'acc_vowel': 0.991892, 'acc_consonant': 0.991444, 'loss_grapheme': 0.112164, 'loss_vowel': 0.046085, 'loss_consonant': 0.038907}\n",
      "   93 | 0.000019 | 148992/160635 | 0.0217 | 1.4754 |\n",
      "val: {'recall': 0.98039, 'recall_grapheme': 0.970735, 'recall_vowel': 0.990485, 'recall_consonant': 0.989605, 'acc_grapheme': 0.971944, 'acc_vowel': 0.991543, 'acc_consonant': 0.991419, 'loss_grapheme': 0.115271, 'loss_vowel': 0.050258, 'loss_consonant': 0.042212}\n",
      "   94 | 0.000017 | 091136/160635 | 3.4321 | 1.6101 |\n",
      "val: {'recall': 0.980915, 'recall_grapheme': 0.9719, 'recall_vowel': 0.99031, 'recall_consonant': 0.98955, 'acc_grapheme': 0.972068, 'acc_vowel': 0.991668, 'acc_consonant': 0.991369, 'loss_grapheme': 0.118163, 'loss_vowel': 0.052609, 'loss_consonant': 0.043699}\n",
      "   95 | 0.000015 | 033280/160635 | 4.3441 | 1.7125 |\n",
      "val: {'recall': 0.980338, 'recall_grapheme': 0.971916, 'recall_vowel': 0.989714, 'recall_consonant': 0.987805, 'acc_grapheme': 0.972317, 'acc_vowel': 0.991717, 'acc_consonant': 0.991394, 'loss_grapheme': 0.118897, 'loss_vowel': 0.053344, 'loss_consonant': 0.044729}\n",
      "   95 | 0.000013 | 135680/160635 | 2.4833 | 1.8423 |\n",
      "val: {'recall': 0.981104, 'recall_grapheme': 0.972485, 'recall_vowel': 0.990014, 'recall_consonant': 0.989431, 'acc_grapheme': 0.972391, 'acc_vowel': 0.991518, 'acc_consonant': 0.991145, 'loss_grapheme': 0.126236, 'loss_vowel': 0.061341, 'loss_consonant': 0.049088}\n",
      "   96 | 0.000010 | 077824/160635 | 0.0250 | 1.8630 |\n",
      "val: {'recall': 0.980775, 'recall_grapheme': 0.971604, 'recall_vowel': 0.990322, 'recall_consonant': 0.989571, 'acc_grapheme': 0.972342, 'acc_vowel': 0.991568, 'acc_consonant': 0.991344, 'loss_grapheme': 0.128734, 'loss_vowel': 0.062359, 'loss_consonant': 0.049914}\n",
      "   97 | 0.000008 | 019968/160635 | 3.3596 | 1.8016 |\n",
      "val: {'recall': 0.980638, 'recall_grapheme': 0.971501, 'recall_vowel': 0.99019, 'recall_consonant': 0.989359, 'acc_grapheme': 0.97274, 'acc_vowel': 0.991792, 'acc_consonant': 0.991394, 'loss_grapheme': 0.116187, 'loss_vowel': 0.052087, 'loss_consonant': 0.042729}\n",
      "   97 | 0.000006 | 122368/160635 | 4.7768 | 1.6753 |\n",
      "val: {'recall': 0.980847, 'recall_grapheme': 0.971775, 'recall_vowel': 0.990212, 'recall_consonant': 0.989625, 'acc_grapheme': 0.972317, 'acc_vowel': 0.991618, 'acc_consonant': 0.991469, 'loss_grapheme': 0.118686, 'loss_vowel': 0.0544, 'loss_consonant': 0.044672}\n",
      "   98 | 0.000004 | 064512/160635 | 0.1218 | 1.7051 |\n",
      "val: {'recall': 0.980803, 'recall_grapheme': 0.971769, 'recall_vowel': 0.990139, 'recall_consonant': 0.989536, 'acc_grapheme': 0.972317, 'acc_vowel': 0.991494, 'acc_consonant': 0.991444, 'loss_grapheme': 0.119639, 'loss_vowel': 0.054895, 'loss_consonant': 0.045201}\n",
      "   99 | 0.000002 | 006656/160635 | 2.8004 | 1.6493 |\n",
      "val: {'recall': 0.980882, 'recall_grapheme': 0.971804, 'recall_vowel': 0.990349, 'recall_consonant': 0.989574, 'acc_grapheme': 0.972441, 'acc_vowel': 0.991643, 'acc_consonant': 0.991568, 'loss_grapheme': 0.114159, 'loss_vowel': 0.049887, 'loss_consonant': 0.041214}\n",
      "   99 | 0.000001 | 109056/160635 | 3.6531 | 1.8703 |\n",
      "val: {'recall': 0.980899, 'recall_grapheme': 0.971979, 'recall_vowel': 0.990067, 'recall_consonant': 0.989571, 'acc_grapheme': 0.972441, 'acc_vowel': 0.991568, 'acc_consonant': 0.991444, 'loss_grapheme': 0.124774, 'loss_vowel': 0.060219, 'loss_consonant': 0.04903}\n",
      "  100 | 0.000001 | 051200/160635 | 3.7903 | 1.7342 |\n",
      "val: {'recall': 0.980688, 'recall_grapheme': 0.971446, 'recall_vowel': 0.990199, 'recall_consonant': 0.989661, 'acc_grapheme': 0.972118, 'acc_vowel': 0.991494, 'acc_consonant': 0.991618, 'loss_grapheme': 0.118648, 'loss_vowel': 0.054456, 'loss_consonant': 0.044737}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 | 0.000001 | 153600/160635 | 4.2793 | 1.6943 |\n",
      "val: {'recall': 0.98063, 'recall_grapheme': 0.971378, 'recall_vowel': 0.990157, 'recall_consonant': 0.989606, 'acc_grapheme': 0.972118, 'acc_vowel': 0.991593, 'acc_consonant': 0.991518, 'loss_grapheme': 0.117469, 'loss_vowel': 0.05318, 'loss_consonant': 0.043807}\n",
      "  101 | 0.000002 | 095744/160635 | 4.3528 | 1.8391 |\n",
      "val: {'recall': 0.980709, 'recall_grapheme': 0.971758, 'recall_vowel': 0.989803, 'recall_consonant': 0.989518, 'acc_grapheme': 0.972168, 'acc_vowel': 0.991494, 'acc_consonant': 0.991469, 'loss_grapheme': 0.121643, 'loss_vowel': 0.056857, 'loss_consonant': 0.046549}\n",
      "  102 | 0.000004 | 037888/160635 | 0.0346 | 1.4538 |\n",
      "val: {'recall': 0.980803, 'recall_grapheme': 0.971873, 'recall_vowel': 0.990011, 'recall_consonant': 0.989454, 'acc_grapheme': 0.972566, 'acc_vowel': 0.991842, 'acc_consonant': 0.991618, 'loss_grapheme': 0.110199, 'loss_vowel': 0.045388, 'loss_consonant': 0.038108}\n",
      "  102 | 0.000006 | 140288/160635 | 0.0717 | 1.5517 |\n",
      "val: {'recall': 0.980606, 'recall_grapheme': 0.971867, 'recall_vowel': 0.990113, 'recall_consonant': 0.988575, 'acc_grapheme': 0.972217, 'acc_vowel': 0.991742, 'acc_consonant': 0.991593, 'loss_grapheme': 0.112821, 'loss_vowel': 0.048306, 'loss_consonant': 0.04026}\n",
      "  103 | 0.000008 | 082432/160635 | 3.9537 | 1.8432 |\n",
      "val: {'recall': 0.980677, 'recall_grapheme': 0.971473, 'recall_vowel': 0.990107, 'recall_consonant': 0.989653, 'acc_grapheme': 0.972242, 'acc_vowel': 0.991717, 'acc_consonant': 0.991469, 'loss_grapheme': 0.122832, 'loss_vowel': 0.058098, 'loss_consonant': 0.047686}\n",
      "  104 | 0.000010 | 024576/160635 | 3.6719 | 1.3758 |\n",
      "val: {'recall': 0.980722, 'recall_grapheme': 0.971826, 'recall_vowel': 0.990109, 'recall_consonant': 0.989129, 'acc_grapheme': 0.972466, 'acc_vowel': 0.991792, 'acc_consonant': 0.991469, 'loss_grapheme': 0.114856, 'loss_vowel': 0.050077, 'loss_consonant': 0.041577}\n",
      "  104 | 0.000013 | 126976/160635 | 4.7217 | 1.6919 |\n",
      "val: {'recall': 0.98092, 'recall_grapheme': 0.972071, 'recall_vowel': 0.989967, 'recall_consonant': 0.989573, 'acc_grapheme': 0.972466, 'acc_vowel': 0.991668, 'acc_consonant': 0.991593, 'loss_grapheme': 0.120056, 'loss_vowel': 0.056121, 'loss_consonant': 0.045717}\n",
      "  105 | 0.000015 | 069120/160635 | 3.1408 | 1.8876 |\n",
      "val: {'recall': 0.980922, 'recall_grapheme': 0.972324, 'recall_vowel': 0.990096, 'recall_consonant': 0.988945, 'acc_grapheme': 0.972441, 'acc_vowel': 0.991568, 'acc_consonant': 0.991344, 'loss_grapheme': 0.124933, 'loss_vowel': 0.060454, 'loss_consonant': 0.048696}\n",
      "  106 | 0.000017 | 011264/160635 | 0.0464 | 2.6320 |\n",
      "val: {'recall': 0.980789, 'recall_grapheme': 0.971827, 'recall_vowel': 0.989945, 'recall_consonant': 0.989557, 'acc_grapheme': 0.972292, 'acc_vowel': 0.991543, 'acc_consonant': 0.991344, 'loss_grapheme': 0.128845, 'loss_vowel': 0.06378, 'loss_consonant': 0.05214}\n",
      "  106 | 0.000019 | 113664/160635 | 3.3311 | 1.7254 |\n",
      "val: {'recall': 0.980742, 'recall_grapheme': 0.971682, 'recall_vowel': 0.990054, 'recall_consonant': 0.98955, 'acc_grapheme': 0.972441, 'acc_vowel': 0.991593, 'acc_consonant': 0.991618, 'loss_grapheme': 0.11624, 'loss_vowel': 0.052135, 'loss_consonant': 0.04349}\n",
      "  107 | 0.000020 | 055808/160635 | 4.4742 | 1.9127 |\n",
      "val: {'recall': 0.981059, 'recall_grapheme': 0.972147, 'recall_vowel': 0.990444, 'recall_consonant': 0.989496, 'acc_grapheme': 0.972391, 'acc_vowel': 0.991717, 'acc_consonant': 0.991543, 'loss_grapheme': 0.11982, 'loss_vowel': 0.055672, 'loss_consonant': 0.045951}\n",
      "  107 | 0.000020 | 148480/160635 | 5.1382 | 1.7460 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-54080d9d42c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-2329e2f97030>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbbx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbby2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbby1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
