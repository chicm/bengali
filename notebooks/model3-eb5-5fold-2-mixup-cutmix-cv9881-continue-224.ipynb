{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        #if self.train_mode:\n",
    "        #    augs = get_train_augs()\n",
    "        #    img = augs(image=img)['image']\n",
    "        \n",
    "        #img = cv2.resize(img, (224, 224))\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "        x = torch.cat([x,x,x], 1)\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966877996778257"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'efficientnet-b5'\n",
    "args.ckp_name = 'model3_efficientnet-b5_fold2_mixup_cutmix_224.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 3e-4\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.5\n",
    "args.patience = 5\n",
    "args.min_lr = 2e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 320\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160678, 5) (40162, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n",
      "model file: ./models/efficientnet-b5/model3_efficientnet-b5_fold2_mixup_cutmix_224.pth, exist: True\n",
      "loading ./models/efficientnet-b5/model3_efficientnet-b5_fold2_mixup_cutmix_224.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.989304, 'recall_grapheme': 0.985111, 'recall_vowel': 0.994026, 'recall_consonant': 0.992967, 'acc_grapheme': 0.984289, 'acc_vowel': 0.994771, 'acc_consonant': 0.994622, 'loss_grapheme': 0.064851, 'loss_vowel': 0.028989, 'loss_consonant': 0.024527}\n",
      "    0 | 0.000300 | 064000/160678 | 4.0913 | 2.1350 |\n",
      "val: {'recall': 0.985135, 'recall_grapheme': 0.97954, 'recall_vowel': 0.991045, 'recall_consonant': 0.990413, 'acc_grapheme': 0.979608, 'acc_vowel': 0.993526, 'acc_consonant': 0.993302, 'loss_grapheme': 0.086374, 'loss_vowel': 0.039131, 'loss_consonant': 0.031923}\n",
      "    0 | 0.000295 | 128000/160678 | 3.6988 | 2.1949 |\n",
      "val: {'recall': 0.984218, 'recall_grapheme': 0.979975, 'recall_vowel': 0.99184, 'recall_consonant': 0.985082, 'acc_grapheme': 0.979159, 'acc_vowel': 0.992854, 'acc_consonant': 0.991136, 'loss_grapheme': 0.087321, 'loss_vowel': 0.038468, 'loss_consonant': 0.038352}\n",
      "    1 | 0.000280 | 031360/160678 | 2.1844 | 2.1429 |\n",
      "val: {'recall': 0.984711, 'recall_grapheme': 0.978226, 'recall_vowel': 0.992054, 'recall_consonant': 0.990335, 'acc_grapheme': 0.978562, 'acc_vowel': 0.992754, 'acc_consonant': 0.992431, 'loss_grapheme': 0.089598, 'loss_vowel': 0.04277, 'loss_consonant': 0.05149}\n",
      "    1 | 0.000256 | 072640/160678 | 1.5274 | 2.1512 |"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.987769, 'recall_grapheme': 0.982918, 'recall_vowel': 0.993188, 'recall_consonant': 0.992052, 'acc_grapheme': 0.982035, 'acc_vowel': 0.994335, 'acc_consonant': 0.993689, 'loss_grapheme': 0.230987, 'loss_vowel': 0.15323, 'loss_consonant': 0.099472}\n",
      "    0 | 0.000100 | 144000/160596 | 1.8490 | 1.9192 |\n",
      "val: {'recall': 0.988941, 'recall_grapheme': 0.985034, 'recall_vowel': 0.994307, 'recall_consonant': 0.991388, 'acc_grapheme': 0.98442, 'acc_vowel': 0.994658, 'acc_consonant': 0.993738, 'loss_grapheme': 0.183109, 'loss_vowel': 0.106912, 'loss_consonant': 0.085281}\n",
      "** saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/chicm/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:113: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 | 0.000098 | 127440/160596 | 1.7123 | 1.9082 |\n",
      "val: {'recall': 0.990256, 'recall_grapheme': 0.985826, 'recall_vowel': 0.994998, 'recall_consonant': 0.994374, 'acc_grapheme': 0.986955, 'acc_vowel': 0.995403, 'acc_consonant': 0.994707, 'loss_grapheme': 0.214729, 'loss_vowel': 0.156357, 'loss_consonant': 0.098806}\n",
      "** saved\n",
      "    2 | 0.000093 | 110880/160596 | 3.3321 | 1.9592 |\n",
      "val: {'recall': 0.989953, 'recall_grapheme': 0.986059, 'recall_vowel': 0.995261, 'recall_consonant': 0.992434, 'acc_grapheme': 0.986756, 'acc_vowel': 0.995875, 'acc_consonant': 0.994732, 'loss_grapheme': 0.249035, 'loss_vowel': 0.19251, 'loss_consonant': 0.124437}\n",
      "    3 | 0.000086 | 094320/160596 | 1.0515 | 2.0535 |\n",
      "val: {'recall': 0.990025, 'recall_grapheme': 0.985642, 'recall_vowel': 0.99463, 'recall_consonant': 0.994187, 'acc_grapheme': 0.98683, 'acc_vowel': 0.995552, 'acc_consonant': 0.99513, 'loss_grapheme': 0.215131, 'loss_vowel': 0.165944, 'loss_consonant': 0.096077}\n",
      "    4 | 0.000075 | 077760/160596 | 2.6915 | 1.9435 |\n",
      "val: {'recall': 0.990156, 'recall_grapheme': 0.986037, 'recall_vowel': 0.994844, 'recall_consonant': 0.993704, 'acc_grapheme': 0.986507, 'acc_vowel': 0.995925, 'acc_consonant': 0.995204, 'loss_grapheme': 0.213024, 'loss_vowel': 0.162799, 'loss_consonant': 0.101532}\n",
      "    5 | 0.000063 | 061200/160596 | 3.2401 | 2.0502 |\n",
      "val: {'recall': 0.990486, 'recall_grapheme': 0.986122, 'recall_vowel': 0.995783, 'recall_consonant': 0.993915, 'acc_grapheme': 0.987675, 'acc_vowel': 0.996322, 'acc_consonant': 0.995627, 'loss_grapheme': 0.20003, 'loss_vowel': 0.157917, 'loss_consonant': 0.098778}\n",
      "** saved\n",
      "    6 | 0.000050 | 044640/160596 | 1.5048 | 1.8283 |\n",
      "val: {'recall': 0.991648, 'recall_grapheme': 0.988116, 'recall_vowel': 0.995661, 'recall_consonant': 0.9947, 'acc_grapheme': 0.988371, 'acc_vowel': 0.996148, 'acc_consonant': 0.995999, 'loss_grapheme': 0.168092, 'loss_vowel': 0.137076, 'loss_consonant': 0.082084}\n",
      "** saved\n",
      "    7 | 0.000038 | 028080/160596 | 2.8543 | 1.7631 |\n",
      "val: {'recall': 0.991853, 'recall_grapheme': 0.988544, 'recall_vowel': 0.995711, 'recall_consonant': 0.994613, 'acc_grapheme': 0.988197, 'acc_vowel': 0.996496, 'acc_consonant': 0.99595, 'loss_grapheme': 0.202822, 'loss_vowel': 0.149125, 'loss_consonant': 0.0915}\n",
      "** saved\n",
      "    8 | 0.000026 | 011520/160596 | 2.6193 | 2.1193 |\n",
      "val: {'recall': 0.991718, 'recall_grapheme': 0.988223, 'recall_vowel': 0.996189, 'recall_consonant': 0.994238, 'acc_grapheme': 0.988023, 'acc_vowel': 0.996596, 'acc_consonant': 0.995999, 'loss_grapheme': 0.203742, 'loss_vowel': 0.166928, 'loss_consonant': 0.100866}\n",
      "    8 | 0.000015 | 155520/160596 | 1.1745 | 1.8130 |\n",
      "val: {'recall': 0.992382, 'recall_grapheme': 0.989474, 'recall_vowel': 0.99557, 'recall_consonant': 0.995012, 'acc_grapheme': 0.990011, 'acc_vowel': 0.996472, 'acc_consonant': 0.996198, 'loss_grapheme': 0.126876, 'loss_vowel': 0.084153, 'loss_consonant': 0.060557}\n",
      "** saved\n",
      "    9 | 0.000008 | 138960/160596 | 3.1656 | 1.7021 |\n",
      "val: {'recall': 0.992502, 'recall_grapheme': 0.989924, 'recall_vowel': 0.995954, 'recall_consonant': 0.994207, 'acc_grapheme': 0.989738, 'acc_vowel': 0.99667, 'acc_consonant': 0.996124, 'loss_grapheme': 0.181781, 'loss_vowel': 0.14013, 'loss_consonant': 0.08768}\n",
      "** saved\n",
      "   10 | 0.000003 | 122400/160596 | 3.2873 | 1.8715 |\n",
      "val: {'recall': 0.991838, 'recall_grapheme': 0.988731, 'recall_vowel': 0.995456, 'recall_consonant': 0.994437, 'acc_grapheme': 0.988321, 'acc_vowel': 0.996596, 'acc_consonant': 0.995975, 'loss_grapheme': 0.232727, 'loss_vowel': 0.198539, 'loss_consonant': 0.121793}\n",
      "   11 | 0.000001 | 105840/160596 | 2.9375 | 1.7804 |\n",
      "val: {'recall': 0.991742, 'recall_grapheme': 0.98877, 'recall_vowel': 0.995237, 'recall_consonant': 0.99419, 'acc_grapheme': 0.988445, 'acc_vowel': 0.996347, 'acc_consonant': 0.995925, 'loss_grapheme': 0.193749, 'loss_vowel': 0.163773, 'loss_consonant': 0.098761}\n",
      "   12 | 0.000003 | 089280/160596 | 0.9590 | 1.8314 |\n",
      "val: {'recall': 0.992051, 'recall_grapheme': 0.989007, 'recall_vowel': 0.995879, 'recall_consonant': 0.994312, 'acc_grapheme': 0.989688, 'acc_vowel': 0.996596, 'acc_consonant': 0.996099, 'loss_grapheme': 0.196551, 'loss_vowel': 0.147794, 'loss_consonant': 0.097406}\n",
      "   13 | 0.000008 | 072720/160596 | 1.2141 | 1.8671 |\n",
      "val: {'recall': 0.992603, 'recall_grapheme': 0.990125, 'recall_vowel': 0.995799, 'recall_consonant': 0.994363, 'acc_grapheme': 0.990085, 'acc_vowel': 0.996695, 'acc_consonant': 0.996099, 'loss_grapheme': 0.183796, 'loss_vowel': 0.139618, 'loss_consonant': 0.091061}\n",
      "** saved\n",
      "   14 | 0.000015 | 056160/160596 | 1.4881 | 1.8731 |\n",
      "val: {'recall': 0.991851, 'recall_grapheme': 0.988637, 'recall_vowel': 0.996091, 'recall_consonant': 0.99404, 'acc_grapheme': 0.988967, 'acc_vowel': 0.996596, 'acc_consonant': 0.995726, 'loss_grapheme': 0.209392, 'loss_vowel': 0.173587, 'loss_consonant': 0.105527}\n",
      "   15 | 0.000026 | 039600/160596 | 2.4953 | 1.8422 |\n",
      "val: {'recall': 0.990927, 'recall_grapheme': 0.987219, 'recall_vowel': 0.995088, 'recall_consonant': 0.994182, 'acc_grapheme': 0.987576, 'acc_vowel': 0.996099, 'acc_consonant': 0.995602, 'loss_grapheme': 0.231552, 'loss_vowel': 0.191293, 'loss_consonant': 0.117404}\n",
      "   16 | 0.000038 | 023040/160596 | 2.4345 | 1.6767 |\n",
      "val: {'recall': 0.991781, 'recall_grapheme': 0.988057, 'recall_vowel': 0.99597, 'recall_consonant': 0.995041, 'acc_grapheme': 0.988346, 'acc_vowel': 0.996422, 'acc_consonant': 0.996074, 'loss_grapheme': 0.178447, 'loss_vowel': 0.136419, 'loss_consonant': 0.088172}\n",
      "   17 | 0.000050 | 006480/160596 | 3.6147 | 1.7332 |\n",
      "val: {'recall': 0.991681, 'recall_grapheme': 0.987755, 'recall_vowel': 0.995969, 'recall_consonant': 0.995243, 'acc_grapheme': 0.987576, 'acc_vowel': 0.996273, 'acc_consonant': 0.995726, 'loss_grapheme': 0.182653, 'loss_vowel': 0.132629, 'loss_consonant': 0.08541}\n",
      "   17 | 0.000063 | 150480/160596 | 1.0070 | 1.8164 |\n",
      "val: {'recall': 0.991805, 'recall_grapheme': 0.988822, 'recall_vowel': 0.996124, 'recall_consonant': 0.993452, 'acc_grapheme': 0.989439, 'acc_vowel': 0.99672, 'acc_consonant': 0.995825, 'loss_grapheme': 0.20962, 'loss_vowel': 0.159448, 'loss_consonant': 0.099568}\n",
      "   18 | 0.000075 | 133920/160596 | 3.3211 | 1.8766 |\n",
      "val: {'recall': 0.990161, 'recall_grapheme': 0.986675, 'recall_vowel': 0.995278, 'recall_consonant': 0.992016, 'acc_grapheme': 0.987104, 'acc_vowel': 0.995975, 'acc_consonant': 0.995229, 'loss_grapheme': 0.227424, 'loss_vowel': 0.16922, 'loss_consonant': 0.107725}\n",
      "   19 | 0.000086 | 117360/160596 | 0.1443 | 1.9183 |\n",
      "val: {'recall': 0.991167, 'recall_grapheme': 0.986791, 'recall_vowel': 0.995502, 'recall_consonant': 0.995585, 'acc_grapheme': 0.987427, 'acc_vowel': 0.996198, 'acc_consonant': 0.995229, 'loss_grapheme': 0.16633, 'loss_vowel': 0.130587, 'loss_consonant': 0.081883}\n",
      "   20 | 0.000093 | 100800/160596 | 0.6233 | 1.9703 |\n",
      "val: {'recall': 0.991272, 'recall_grapheme': 0.987176, 'recall_vowel': 0.994878, 'recall_consonant': 0.995857, 'acc_grapheme': 0.987725, 'acc_vowel': 0.996223, 'acc_consonant': 0.99585, 'loss_grapheme': 0.194573, 'loss_vowel': 0.144955, 'loss_consonant': 0.090852}\n",
      "   21 | 0.000098 | 084240/160596 | 3.7009 | 2.0259 |\n",
      "val: {'recall': 0.99049, 'recall_grapheme': 0.986386, 'recall_vowel': 0.995135, 'recall_consonant': 0.994055, 'acc_grapheme': 0.985961, 'acc_vowel': 0.995676, 'acc_consonant': 0.995179, 'loss_grapheme': 0.2343, 'loss_vowel': 0.21492, 'loss_consonant': 0.136033}\n",
      "   22 | 0.000100 | 067680/160596 | 0.9240 | 1.7507 |\n",
      "val: {'recall': 0.991563, 'recall_grapheme': 0.987673, 'recall_vowel': 0.995811, 'recall_consonant': 0.995097, 'acc_grapheme': 0.98852, 'acc_vowel': 0.996173, 'acc_consonant': 0.995602, 'loss_grapheme': 0.194442, 'loss_vowel': 0.127462, 'loss_consonant': 0.091038}\n",
      "   23 | 0.000098 | 051120/160596 | 2.3082 | 1.9884 |\n",
      "val: {'recall': 0.992562, 'recall_grapheme': 0.989507, 'recall_vowel': 0.996414, 'recall_consonant': 0.99482, 'acc_grapheme': 0.988321, 'acc_vowel': 0.996397, 'acc_consonant': 0.995527, 'loss_grapheme': 0.212426, 'loss_vowel': 0.159506, 'loss_consonant': 0.091539}\n",
      "   24 | 0.000093 | 034560/160596 | 0.9263 | 2.0098 |\n",
      "val: {'recall': 0.991173, 'recall_grapheme': 0.987316, 'recall_vowel': 0.995011, 'recall_consonant': 0.995047, 'acc_grapheme': 0.987278, 'acc_vowel': 0.995577, 'acc_consonant': 0.995627, 'loss_grapheme': 0.200663, 'loss_vowel': 0.160446, 'loss_consonant': 0.099695}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 0.000086 | 018000/160596 | 1.8911 | 2.0103 |\n",
      "val: {'recall': 0.991798, 'recall_grapheme': 0.988771, 'recall_vowel': 0.995519, 'recall_consonant': 0.994133, 'acc_grapheme': 0.989042, 'acc_vowel': 0.996372, 'acc_consonant': 0.995428, 'loss_grapheme': 0.216286, 'loss_vowel': 0.129529, 'loss_consonant': 0.09244}\n",
      "   26 | 0.000075 | 001440/160596 | 2.9533 | 2.9026 |\n",
      "val: {'recall': 0.992637, 'recall_grapheme': 0.988959, 'recall_vowel': 0.996413, 'recall_consonant': 0.99622, 'acc_grapheme': 0.989216, 'acc_vowel': 0.996571, 'acc_consonant': 0.995701, 'loss_grapheme': 0.212417, 'loss_vowel': 0.163295, 'loss_consonant': 0.097383}\n",
      "** saved\n",
      "   26 | 0.000063 | 145440/160596 | 2.6632 | 1.9373 |\n",
      "val: {'recall': 0.992202, 'recall_grapheme': 0.988811, 'recall_vowel': 0.996096, 'recall_consonant': 0.995089, 'acc_grapheme': 0.988048, 'acc_vowel': 0.996546, 'acc_consonant': 0.995776, 'loss_grapheme': 0.218281, 'loss_vowel': 0.173208, 'loss_consonant': 0.099098}\n",
      "   27 | 0.000051 | 128880/160596 | 2.7856 | 1.8610 |\n",
      "val: {'recall': 0.992948, 'recall_grapheme': 0.990133, 'recall_vowel': 0.996128, 'recall_consonant': 0.9954, 'acc_grapheme': 0.989141, 'acc_vowel': 0.996621, 'acc_consonant': 0.996099, 'loss_grapheme': 0.200634, 'loss_vowel': 0.16135, 'loss_consonant': 0.097392}\n",
      "** saved\n",
      "   28 | 0.000038 | 112320/160596 | 2.0074 | 1.8026 |\n",
      "val: {'recall': 0.991272, 'recall_grapheme': 0.988112, 'recall_vowel': 0.995729, 'recall_consonant': 0.993132, 'acc_grapheme': 0.989116, 'acc_vowel': 0.996322, 'acc_consonant': 0.995726, 'loss_grapheme': 0.168015, 'loss_vowel': 0.098442, 'loss_consonant': 0.077352}\n",
      "   29 | 0.000026 | 095760/160596 | 1.1689 | 1.7759 |\n",
      "val: {'recall': 0.9934, 'recall_grapheme': 0.990581, 'recall_vowel': 0.995965, 'recall_consonant': 0.996472, 'acc_grapheme': 0.990483, 'acc_vowel': 0.996844, 'acc_consonant': 0.996745, 'loss_grapheme': 0.172902, 'loss_vowel': 0.133042, 'loss_consonant': 0.0816}\n",
      "** saved\n",
      "   30 | 0.000015 | 079200/160596 | 2.3356 | 1.8251 |\n",
      "val: {'recall': 0.99297, 'recall_grapheme': 0.990288, 'recall_vowel': 0.996036, 'recall_consonant': 0.995269, 'acc_grapheme': 0.989241, 'acc_vowel': 0.996621, 'acc_consonant': 0.996173, 'loss_grapheme': 0.179572, 'loss_vowel': 0.149878, 'loss_consonant': 0.090135}\n",
      "   31 | 0.000008 | 062640/160596 | 0.3249 | 1.6791 |\n",
      "val: {'recall': 0.993215, 'recall_grapheme': 0.99052, 'recall_vowel': 0.996146, 'recall_consonant': 0.995677, 'acc_grapheme': 0.990259, 'acc_vowel': 0.996795, 'acc_consonant': 0.996273, 'loss_grapheme': 0.18356, 'loss_vowel': 0.135989, 'loss_consonant': 0.085401}\n",
      "   32 | 0.000003 | 046080/160596 | 1.9216 | 1.9074 |\n",
      "val: {'recall': 0.993509, 'recall_grapheme': 0.990969, 'recall_vowel': 0.996191, 'recall_consonant': 0.995907, 'acc_grapheme': 0.99021, 'acc_vowel': 0.99677, 'acc_consonant': 0.996322, 'loss_grapheme': 0.204285, 'loss_vowel': 0.172423, 'loss_consonant': 0.104952}\n",
      "** saved\n",
      "   33 | 0.000001 | 029520/160596 | 1.5198 | 1.7336 |\n",
      "val: {'recall': 0.993461, 'recall_grapheme': 0.990853, 'recall_vowel': 0.996432, 'recall_consonant': 0.995705, 'acc_grapheme': 0.990806, 'acc_vowel': 0.996944, 'acc_consonant': 0.996496, 'loss_grapheme': 0.185316, 'loss_vowel': 0.139272, 'loss_consonant': 0.084998}\n",
      "   34 | 0.000003 | 012960/160596 | 1.4199 | 1.9625 |\n",
      "val: {'recall': 0.993249, 'recall_grapheme': 0.990488, 'recall_vowel': 0.996223, 'recall_consonant': 0.995798, 'acc_grapheme': 0.989738, 'acc_vowel': 0.996596, 'acc_consonant': 0.996248, 'loss_grapheme': 0.201512, 'loss_vowel': 0.168599, 'loss_consonant': 0.102101}\n",
      "   34 | 0.000008 | 156960/160596 | 1.7230 | 1.7525 |\n",
      "val: {'recall': 0.993544, 'recall_grapheme': 0.990988, 'recall_vowel': 0.996105, 'recall_consonant': 0.996096, 'acc_grapheme': 0.990582, 'acc_vowel': 0.99672, 'acc_consonant': 0.996521, 'loss_grapheme': 0.195788, 'loss_vowel': 0.151001, 'loss_consonant': 0.092023}\n",
      "** saved\n",
      "   35 | 0.000015 | 140400/160596 | 1.2870 | 1.7891 |\n",
      "val: {'recall': 0.993383, 'recall_grapheme': 0.990706, 'recall_vowel': 0.996303, 'recall_consonant': 0.995815, 'acc_grapheme': 0.990856, 'acc_vowel': 0.996894, 'acc_consonant': 0.996621, 'loss_grapheme': 0.18267, 'loss_vowel': 0.138368, 'loss_consonant': 0.084224}\n",
      "   36 | 0.000026 | 123840/160596 | 2.8104 | 1.7334 |\n",
      "val: {'recall': 0.993515, 'recall_grapheme': 0.991396, 'recall_vowel': 0.996319, 'recall_consonant': 0.99495, 'acc_grapheme': 0.990607, 'acc_vowel': 0.997018, 'acc_consonant': 0.996372, 'loss_grapheme': 0.153088, 'loss_vowel': 0.118384, 'loss_consonant': 0.075569}\n",
      "   37 | 0.000038 | 107280/160596 | 1.1902 | 1.8421 |\n",
      "val: {'recall': 0.992891, 'recall_grapheme': 0.990125, 'recall_vowel': 0.996082, 'recall_consonant': 0.995234, 'acc_grapheme': 0.990036, 'acc_vowel': 0.996819, 'acc_consonant': 0.996322, 'loss_grapheme': 0.170341, 'loss_vowel': 0.126165, 'loss_consonant': 0.076453}\n",
      "   38 | 0.000051 | 090720/160596 | 1.7826 | 1.9736 |\n",
      "val: {'recall': 0.992093, 'recall_grapheme': 0.989292, 'recall_vowel': 0.995169, 'recall_consonant': 0.99462, 'acc_grapheme': 0.988222, 'acc_vowel': 0.996074, 'acc_consonant': 0.995726, 'loss_grapheme': 0.227871, 'loss_vowel': 0.16359, 'loss_consonant': 0.104991}\n",
      "   39 | 0.000063 | 074160/160596 | 2.3488 | 1.9267 |\n",
      "val: {'recall': 0.991776, 'recall_grapheme': 0.987909, 'recall_vowel': 0.995393, 'recall_consonant': 0.995895, 'acc_grapheme': 0.987725, 'acc_vowel': 0.996248, 'acc_consonant': 0.995975, 'loss_grapheme': 0.230666, 'loss_vowel': 0.178743, 'loss_consonant': 0.113319}\n",
      "   40 | 0.000075 | 057600/160596 | 1.5467 | 1.8025 |\n",
      "val: {'recall': 0.991622, 'recall_grapheme': 0.988397, 'recall_vowel': 0.994931, 'recall_consonant': 0.994762, 'acc_grapheme': 0.988048, 'acc_vowel': 0.996074, 'acc_consonant': 0.995627, 'loss_grapheme': 0.218939, 'loss_vowel': 0.150724, 'loss_consonant': 0.093748}\n",
      "   41 | 0.000086 | 041040/160596 | 1.8629 | 1.7267 |\n",
      "val: {'recall': 0.991842, 'recall_grapheme': 0.988635, 'recall_vowel': 0.995915, 'recall_consonant': 0.994184, 'acc_grapheme': 0.98847, 'acc_vowel': 0.996347, 'acc_consonant': 0.995502, 'loss_grapheme': 0.169032, 'loss_vowel': 0.126287, 'loss_consonant': 0.077187}\n",
      "   42 | 0.000093 | 024480/160596 | 2.7149 | 1.8970 |\n",
      "val: {'recall': 0.992795, 'recall_grapheme': 0.990172, 'recall_vowel': 0.995925, 'recall_consonant': 0.994912, 'acc_grapheme': 0.987849, 'acc_vowel': 0.996447, 'acc_consonant': 0.995751, 'loss_grapheme': 0.155666, 'loss_vowel': 0.11793, 'loss_consonant': 0.071071}\n",
      "   43 | 0.000098 | 007920/160596 | 1.8144 | 2.0737 |\n",
      "val: {'recall': 0.991893, 'recall_grapheme': 0.988116, 'recall_vowel': 0.995697, 'recall_consonant': 0.995642, 'acc_grapheme': 0.988098, 'acc_vowel': 0.995801, 'acc_consonant': 0.995304, 'loss_grapheme': 0.299334, 'loss_vowel': 0.187073, 'loss_consonant': 0.119441}\n",
      "   43 | 0.000100 | 151920/160596 | 3.2523 | 2.0128 |\n",
      "val: {'recall': 0.98976, 'recall_grapheme': 0.985503, 'recall_vowel': 0.993878, 'recall_consonant': 0.994156, 'acc_grapheme': 0.985638, 'acc_vowel': 0.995229, 'acc_consonant': 0.994359, 'loss_grapheme': 0.214088, 'loss_vowel': 0.154906, 'loss_consonant': 0.096522}\n",
      "   44 | 0.000098 | 135360/160596 | 0.7381 | 1.7866 |\n",
      "val: {'recall': 0.991937, 'recall_grapheme': 0.988, 'recall_vowel': 0.996102, 'recall_consonant': 0.995646, 'acc_grapheme': 0.989191, 'acc_vowel': 0.99672, 'acc_consonant': 0.996074, 'loss_grapheme': 0.209113, 'loss_vowel': 0.140703, 'loss_consonant': 0.091954}\n",
      "   45 | 0.000093 | 118800/160596 | 2.8528 | 1.8353 |\n",
      "val: {'recall': 0.992521, 'recall_grapheme': 0.988997, 'recall_vowel': 0.996385, 'recall_consonant': 0.995704, 'acc_grapheme': 0.989042, 'acc_vowel': 0.996645, 'acc_consonant': 0.995801, 'loss_grapheme': 0.208974, 'loss_vowel': 0.157786, 'loss_consonant': 0.095034}\n",
      "   46 | 0.000086 | 102240/160596 | 2.8276 | 1.9184 |\n",
      "val: {'recall': 0.990827, 'recall_grapheme': 0.987055, 'recall_vowel': 0.99393, 'recall_consonant': 0.995265, 'acc_grapheme': 0.986656, 'acc_vowel': 0.995105, 'acc_consonant': 0.994856, 'loss_grapheme': 0.213236, 'loss_vowel': 0.169906, 'loss_consonant': 0.106443}\n",
      "   47 | 0.000075 | 085680/160596 | 1.7151 | 1.8070 |\n",
      "val: {'recall': 0.991824, 'recall_grapheme': 0.989432, 'recall_vowel': 0.996594, 'recall_consonant': 0.991837, 'acc_grapheme': 0.989539, 'acc_vowel': 0.996819, 'acc_consonant': 0.99595, 'loss_grapheme': 0.178099, 'loss_vowel': 0.131068, 'loss_consonant': 0.081631}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 | 0.000063 | 069120/160596 | 2.7455 | 1.7793 |\n",
      "val: {'recall': 0.993727, 'recall_grapheme': 0.991098, 'recall_vowel': 0.99662, 'recall_consonant': 0.996093, 'acc_grapheme': 0.990582, 'acc_vowel': 0.996621, 'acc_consonant': 0.996173, 'loss_grapheme': 0.172522, 'loss_vowel': 0.114462, 'loss_consonant': 0.078324}\n",
      "** saved\n",
      "   49 | 0.000051 | 052560/160596 | 2.0017 | 1.8439 |\n",
      "val: {'recall': 0.993, 'recall_grapheme': 0.989735, 'recall_vowel': 0.996357, 'recall_consonant': 0.996175, 'acc_grapheme': 0.989464, 'acc_vowel': 0.996795, 'acc_consonant': 0.99585, 'loss_grapheme': 0.216581, 'loss_vowel': 0.155391, 'loss_consonant': 0.094304}\n",
      "   50 | 0.000038 | 036000/160596 | 2.8190 | 1.7392 |\n",
      "val: {'recall': 0.993665, 'recall_grapheme': 0.990976, 'recall_vowel': 0.99635, 'recall_consonant': 0.996357, 'acc_grapheme': 0.990707, 'acc_vowel': 0.996894, 'acc_consonant': 0.996447, 'loss_grapheme': 0.202577, 'loss_vowel': 0.141524, 'loss_consonant': 0.08619}\n",
      "   51 | 0.000026 | 019440/160596 | 0.7174 | 1.8760 |\n",
      "val: {'recall': 0.993225, 'recall_grapheme': 0.990431, 'recall_vowel': 0.996261, 'recall_consonant': 0.995779, 'acc_grapheme': 0.989762, 'acc_vowel': 0.996745, 'acc_consonant': 0.996173, 'loss_grapheme': 0.208335, 'loss_vowel': 0.152944, 'loss_consonant': 0.09551}\n",
      "   52 | 0.000015 | 002880/160596 | 2.3356 | 1.7881 |\n",
      "val: {'recall': 0.993118, 'recall_grapheme': 0.990169, 'recall_vowel': 0.996212, 'recall_consonant': 0.995921, 'acc_grapheme': 0.989713, 'acc_vowel': 0.996819, 'acc_consonant': 0.996049, 'loss_grapheme': 0.220448, 'loss_vowel': 0.167035, 'loss_consonant': 0.10112}\n",
      "   52 | 0.000008 | 146880/160596 | 1.9035 | 1.7679 |\n",
      "val: {'recall': 0.993873, 'recall_grapheme': 0.991268, 'recall_vowel': 0.996713, 'recall_consonant': 0.996243, 'acc_grapheme': 0.991502, 'acc_vowel': 0.997118, 'acc_consonant': 0.996745, 'loss_grapheme': 0.158311, 'loss_vowel': 0.099244, 'loss_consonant': 0.066546}\n",
      "** saved\n",
      "   53 | 0.000003 | 130320/160596 | 2.1118 | 1.8452 |\n",
      "val: {'recall': 0.993874, 'recall_grapheme': 0.991746, 'recall_vowel': 0.99656, 'recall_consonant': 0.995444, 'acc_grapheme': 0.991402, 'acc_vowel': 0.997068, 'acc_consonant': 0.996844, 'loss_grapheme': 0.153738, 'loss_vowel': 0.101945, 'loss_consonant': 0.065352}\n",
      "** saved\n",
      "   54 | 0.000001 | 113760/160596 | 3.3902 | 1.8014 |\n",
      "val: {'recall': 0.992925, 'recall_grapheme': 0.989741, 'recall_vowel': 0.995943, 'recall_consonant': 0.996274, 'acc_grapheme': 0.989092, 'acc_vowel': 0.99667, 'acc_consonant': 0.996024, 'loss_grapheme': 0.204428, 'loss_vowel': 0.167147, 'loss_consonant': 0.101666}\n",
      "   55 | 0.000003 | 097200/160596 | 1.2326 | 1.8913 |\n",
      "val: {'recall': 0.993061, 'recall_grapheme': 0.990005, 'recall_vowel': 0.995969, 'recall_consonant': 0.996265, 'acc_grapheme': 0.989564, 'acc_vowel': 0.996795, 'acc_consonant': 0.996347, 'loss_grapheme': 0.207713, 'loss_vowel': 0.165271, 'loss_consonant': 0.100598}\n",
      "   56 | 0.000008 | 080640/160596 | 2.0293 | 1.8116 |\n",
      "val: {'recall': 0.993635, 'recall_grapheme': 0.99095, 'recall_vowel': 0.996271, 'recall_consonant': 0.996371, 'acc_grapheme': 0.990384, 'acc_vowel': 0.996919, 'acc_consonant': 0.996298, 'loss_grapheme': 0.188076, 'loss_vowel': 0.146174, 'loss_consonant': 0.089054}\n",
      "   57 | 0.000015 | 064080/160596 | 1.6781 | 1.6918 |\n",
      "val: {'recall': 0.99375, 'recall_grapheme': 0.99112, 'recall_vowel': 0.996364, 'recall_consonant': 0.996397, 'acc_grapheme': 0.991477, 'acc_vowel': 0.997043, 'acc_consonant': 0.996496, 'loss_grapheme': 0.168759, 'loss_vowel': 0.11188, 'loss_consonant': 0.07356}\n",
      "   58 | 0.000026 | 047520/160596 | 2.5816 | 1.6894 |\n",
      "val: {'recall': 0.994103, 'recall_grapheme': 0.991549, 'recall_vowel': 0.996872, 'recall_consonant': 0.996445, 'acc_grapheme': 0.990831, 'acc_vowel': 0.997118, 'acc_consonant': 0.996645, 'loss_grapheme': 0.171154, 'loss_vowel': 0.117546, 'loss_consonant': 0.072389}\n",
      "** saved\n",
      "   59 | 0.000038 | 030960/160596 | 0.7333 | 1.8274 |\n",
      "val: {'recall': 0.992992, 'recall_grapheme': 0.990519, 'recall_vowel': 0.995579, 'recall_consonant': 0.995351, 'acc_grapheme': 0.989564, 'acc_vowel': 0.99667, 'acc_consonant': 0.995999, 'loss_grapheme': 0.17582, 'loss_vowel': 0.129511, 'loss_consonant': 0.083459}\n",
      "   60 | 0.000051 | 014400/160596 | 1.7905 | 1.9430 |\n",
      "val: {'recall': 0.992566, 'recall_grapheme': 0.989653, 'recall_vowel': 0.995988, 'recall_consonant': 0.99497, 'acc_grapheme': 0.98929, 'acc_vowel': 0.996496, 'acc_consonant': 0.996124, 'loss_grapheme': 0.224457, 'loss_vowel': 0.14647, 'loss_consonant': 0.098947}\n",
      "   60 | 0.000063 | 158400/160596 | 0.2953 | 1.8458 |\n",
      "val: {'recall': 0.992516, 'recall_grapheme': 0.989041, 'recall_vowel': 0.996587, 'recall_consonant': 0.995394, 'acc_grapheme': 0.98939, 'acc_vowel': 0.99667, 'acc_consonant': 0.996074, 'loss_grapheme': 0.163869, 'loss_vowel': 0.107374, 'loss_consonant': 0.067342}\n",
      "   61 | 0.000075 | 141840/160596 | 1.5670 | 1.8155 |\n",
      "val: {'recall': 0.991375, 'recall_grapheme': 0.98778, 'recall_vowel': 0.995275, 'recall_consonant': 0.994665, 'acc_grapheme': 0.987327, 'acc_vowel': 0.995925, 'acc_consonant': 0.995403, 'loss_grapheme': 0.253676, 'loss_vowel': 0.187507, 'loss_consonant': 0.115447}\n",
      "   62 | 0.000086 | 125280/160596 | 2.1966 | 1.8068 |\n",
      "val: {'recall': 0.992862, 'recall_grapheme': 0.990065, 'recall_vowel': 0.995439, 'recall_consonant': 0.995879, 'acc_grapheme': 0.989837, 'acc_vowel': 0.996447, 'acc_consonant': 0.995751, 'loss_grapheme': 0.211508, 'loss_vowel': 0.136315, 'loss_consonant': 0.085435}\n",
      "   63 | 0.000093 | 108720/160596 | 1.5563 | 1.8846 |\n",
      "val: {'recall': 0.991692, 'recall_grapheme': 0.989023, 'recall_vowel': 0.995397, 'recall_consonant': 0.993326, 'acc_grapheme': 0.988694, 'acc_vowel': 0.996273, 'acc_consonant': 0.995428, 'loss_grapheme': 0.168921, 'loss_vowel': 0.100053, 'loss_consonant': 0.072199}\n",
      "   64 | 0.000098 | 092160/160596 | 0.3278 | 1.7195 |\n",
      "val: {'recall': 0.990291, 'recall_grapheme': 0.987433, 'recall_vowel': 0.994849, 'recall_consonant': 0.99145, 'acc_grapheme': 0.987824, 'acc_vowel': 0.995975, 'acc_consonant': 0.994981, 'loss_grapheme': 0.156986, 'loss_vowel': 0.083422, 'loss_consonant': 0.06035}\n",
      "   65 | 0.000100 | 075600/160596 | 2.4211 | 1.7830 |\n",
      "val: {'recall': 0.992158, 'recall_grapheme': 0.989247, 'recall_vowel': 0.995413, 'recall_consonant': 0.994726, 'acc_grapheme': 0.989141, 'acc_vowel': 0.996298, 'acc_consonant': 0.995825, 'loss_grapheme': 0.216205, 'loss_vowel': 0.141225, 'loss_consonant': 0.088293}\n",
      "   66 | 0.000098 | 059040/160596 | 2.2771 | 1.9041 |\n",
      "val: {'recall': 0.992895, 'recall_grapheme': 0.989981, 'recall_vowel': 0.996178, 'recall_consonant': 0.995441, 'acc_grapheme': 0.989887, 'acc_vowel': 0.996695, 'acc_consonant': 0.996223, 'loss_grapheme': 0.137491, 'loss_vowel': 0.095289, 'loss_consonant': 0.062432}\n",
      "   67 | 0.000093 | 042480/160596 | 3.6916 | 1.8415 |\n",
      "val: {'recall': 0.991993, 'recall_grapheme': 0.989354, 'recall_vowel': 0.995486, 'recall_consonant': 0.993778, 'acc_grapheme': 0.988321, 'acc_vowel': 0.996372, 'acc_consonant': 0.995701, 'loss_grapheme': 0.236774, 'loss_vowel': 0.173406, 'loss_consonant': 0.105809}\n",
      "   68 | 0.000086 | 025920/160596 | 2.2489 | 1.7839 |\n",
      "val: {'recall': 0.993692, 'recall_grapheme': 0.991157, 'recall_vowel': 0.996474, 'recall_consonant': 0.995981, 'acc_grapheme': 0.990011, 'acc_vowel': 0.996745, 'acc_consonant': 0.995825, 'loss_grapheme': 0.231668, 'loss_vowel': 0.159773, 'loss_consonant': 0.096132}\n",
      "   69 | 0.000075 | 009360/160596 | 0.9974 | 1.7894 |\n",
      "val: {'recall': 0.992253, 'recall_grapheme': 0.988294, 'recall_vowel': 0.99656, 'recall_consonant': 0.995863, 'acc_grapheme': 0.989564, 'acc_vowel': 0.996621, 'acc_consonant': 0.996173, 'loss_grapheme': 0.203442, 'loss_vowel': 0.123123, 'loss_consonant': 0.089939}\n",
      "   69 | 0.000063 | 153360/160596 | 1.2438 | 1.8163 |\n",
      "val: {'recall': 0.993343, 'recall_grapheme': 0.990431, 'recall_vowel': 0.996424, 'recall_consonant': 0.996086, 'acc_grapheme': 0.990533, 'acc_vowel': 0.996521, 'acc_consonant': 0.996248, 'loss_grapheme': 0.19873, 'loss_vowel': 0.127151, 'loss_consonant': 0.083991}\n",
      "   70 | 0.000051 | 136800/160596 | 2.3253 | 1.6855 |\n",
      "val: {'recall': 0.99343, 'recall_grapheme': 0.990758, 'recall_vowel': 0.996863, 'recall_consonant': 0.995342, 'acc_grapheme': 0.990259, 'acc_vowel': 0.997093, 'acc_consonant': 0.996173, 'loss_grapheme': 0.199292, 'loss_vowel': 0.156153, 'loss_consonant': 0.09382}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   71 | 0.000038 | 120240/160596 | 2.0812 | 1.7359 |\n",
      "val: {'recall': 0.993435, 'recall_grapheme': 0.990611, 'recall_vowel': 0.996562, 'recall_consonant': 0.995957, 'acc_grapheme': 0.990235, 'acc_vowel': 0.996869, 'acc_consonant': 0.996496, 'loss_grapheme': 0.204306, 'loss_vowel': 0.137563, 'loss_consonant': 0.082771}\n",
      "   72 | 0.000026 | 103680/160596 | 2.0809 | 1.7606 |\n",
      "val: {'recall': 0.993803, 'recall_grapheme': 0.991227, 'recall_vowel': 0.996602, 'recall_consonant': 0.996154, 'acc_grapheme': 0.991402, 'acc_vowel': 0.996968, 'acc_consonant': 0.99677, 'loss_grapheme': 0.205298, 'loss_vowel': 0.141558, 'loss_consonant': 0.09173}\n",
      "   73 | 0.000015 | 087120/160596 | 1.3628 | 1.7295 |\n",
      "val: {'recall': 0.994402, 'recall_grapheme': 0.991982, 'recall_vowel': 0.996818, 'recall_consonant': 0.996826, 'acc_grapheme': 0.991775, 'acc_vowel': 0.997018, 'acc_consonant': 0.996869, 'loss_grapheme': 0.165361, 'loss_vowel': 0.109888, 'loss_consonant': 0.068455}\n",
      "** saved\n",
      "   74 | 0.000008 | 070560/160596 | 0.8637 | 1.7668 |\n",
      "val: {'recall': 0.994236, 'recall_grapheme': 0.991843, 'recall_vowel': 0.996972, 'recall_consonant': 0.996285, 'acc_grapheme': 0.991899, 'acc_vowel': 0.997267, 'acc_consonant': 0.996869, 'loss_grapheme': 0.175528, 'loss_vowel': 0.114044, 'loss_consonant': 0.072608}\n",
      "   75 | 0.000003 | 054000/160596 | 2.1121 | 1.6908 |\n",
      "val: {'recall': 0.994295, 'recall_grapheme': 0.991974, 'recall_vowel': 0.996961, 'recall_consonant': 0.996269, 'acc_grapheme': 0.991601, 'acc_vowel': 0.997142, 'acc_consonant': 0.99672, 'loss_grapheme': 0.149689, 'loss_vowel': 0.107451, 'loss_consonant': 0.066083}\n",
      "   76 | 0.000001 | 037440/160596 | 1.3868 | 1.6031 |\n",
      "val: {'recall': 0.994143, 'recall_grapheme': 0.991757, 'recall_vowel': 0.99658, 'recall_consonant': 0.996477, 'acc_grapheme': 0.991055, 'acc_vowel': 0.996869, 'acc_consonant': 0.996447, 'loss_grapheme': 0.169782, 'loss_vowel': 0.121777, 'loss_consonant': 0.07377}\n",
      "   77 | 0.000003 | 020880/160596 | 2.5605 | 1.6241 |\n",
      "val: {'recall': 0.993135, 'recall_grapheme': 0.99049, 'recall_vowel': 0.996324, 'recall_consonant': 0.995236, 'acc_grapheme': 0.991303, 'acc_vowel': 0.996894, 'acc_consonant': 0.996521, 'loss_grapheme': 0.162069, 'loss_vowel': 0.09453, 'loss_consonant': 0.071698}\n",
      "   78 | 0.000008 | 004320/160596 | 1.9508 | 2.0498 |\n",
      "val: {'recall': 0.992816, 'recall_grapheme': 0.989977, 'recall_vowel': 0.996367, 'recall_consonant': 0.994942, 'acc_grapheme': 0.990806, 'acc_vowel': 0.996968, 'acc_consonant': 0.99667, 'loss_grapheme': 0.149584, 'loss_vowel': 0.088023, 'loss_consonant': 0.066545}\n",
      "   78 | 0.000015 | 148320/160596 | 0.5353 | 1.8025 |\n",
      "val: {'recall': 0.994322, 'recall_grapheme': 0.992085, 'recall_vowel': 0.996824, 'recall_consonant': 0.996293, 'acc_grapheme': 0.991899, 'acc_vowel': 0.997217, 'acc_consonant': 0.996795, 'loss_grapheme': 0.156925, 'loss_vowel': 0.10003, 'loss_consonant': 0.065835}\n",
      "   79 | 0.000026 | 131760/160596 | 1.4607 | 1.7216 |\n",
      "val: {'recall': 0.994071, 'recall_grapheme': 0.991869, 'recall_vowel': 0.996666, 'recall_consonant': 0.995879, 'acc_grapheme': 0.991651, 'acc_vowel': 0.997142, 'acc_consonant': 0.996745, 'loss_grapheme': 0.197087, 'loss_vowel': 0.130801, 'loss_consonant': 0.080081}\n",
      "   80 | 0.000038 | 115200/160596 | 1.5044 | 1.7249 |\n",
      "val: {'recall': 0.993364, 'recall_grapheme': 0.991144, 'recall_vowel': 0.996146, 'recall_consonant': 0.995023, 'acc_grapheme': 0.990384, 'acc_vowel': 0.996695, 'acc_consonant': 0.996148, 'loss_grapheme': 0.233, 'loss_vowel': 0.169739, 'loss_consonant': 0.105475}\n",
      "   81 | 0.000050 | 098640/160596 | 1.5113 | 1.8450 |\n",
      "val: {'recall': 0.992955, 'recall_grapheme': 0.99, 'recall_vowel': 0.996216, 'recall_consonant': 0.995604, 'acc_grapheme': 0.989738, 'acc_vowel': 0.996645, 'acc_consonant': 0.995825, 'loss_grapheme': 0.253062, 'loss_vowel': 0.162405, 'loss_consonant': 0.102239}\n",
      "   82 | 0.000063 | 082080/160596 | 0.7367 | 1.8045 |\n",
      "val: {'recall': 0.992335, 'recall_grapheme': 0.98979, 'recall_vowel': 0.996259, 'recall_consonant': 0.9935, 'acc_grapheme': 0.989762, 'acc_vowel': 0.996571, 'acc_consonant': 0.995726, 'loss_grapheme': 0.184601, 'loss_vowel': 0.135723, 'loss_consonant': 0.080602}\n",
      "   83 | 0.000075 | 065520/160596 | 1.1021 | 1.9376 |\n",
      "val: {'recall': 0.992178, 'recall_grapheme': 0.989117, 'recall_vowel': 0.995294, 'recall_consonant': 0.995186, 'acc_grapheme': 0.989092, 'acc_vowel': 0.996148, 'acc_consonant': 0.995602, 'loss_grapheme': 0.193732, 'loss_vowel': 0.120894, 'loss_consonant': 0.083675}\n",
      "   84 | 0.000086 | 048960/160596 | 2.7309 | 1.7770 |\n",
      "val: {'recall': 0.991048, 'recall_grapheme': 0.987792, 'recall_vowel': 0.995466, 'recall_consonant': 0.99314, 'acc_grapheme': 0.98775, 'acc_vowel': 0.996074, 'acc_consonant': 0.995453, 'loss_grapheme': 0.232796, 'loss_vowel': 0.158559, 'loss_consonant': 0.098507}\n",
      "   85 | 0.000093 | 032400/160596 | 2.0286 | 1.9585 |\n",
      "val: {'recall': 0.992058, 'recall_grapheme': 0.988464, 'recall_vowel': 0.995032, 'recall_consonant': 0.99627, 'acc_grapheme': 0.98847, 'acc_vowel': 0.996024, 'acc_consonant': 0.995751, 'loss_grapheme': 0.218747, 'loss_vowel': 0.159627, 'loss_consonant': 0.103723}\n",
      "   86 | 0.000098 | 015840/160596 | 1.9426 | 1.7595 |\n",
      "val: {'recall': 0.992075, 'recall_grapheme': 0.988781, 'recall_vowel': 0.995438, 'recall_consonant': 0.995302, 'acc_grapheme': 0.989688, 'acc_vowel': 0.995975, 'acc_consonant': 0.995527, 'loss_grapheme': 0.232796, 'loss_vowel': 0.149562, 'loss_consonant': 0.095356}\n",
      "   86 | 0.000100 | 159840/160596 | 1.8947 | 1.8784 |\n",
      "val: {'recall': 0.993261, 'recall_grapheme': 0.99062, 'recall_vowel': 0.996065, 'recall_consonant': 0.995738, 'acc_grapheme': 0.99016, 'acc_vowel': 0.996745, 'acc_consonant': 0.996322, 'loss_grapheme': 0.248978, 'loss_vowel': 0.160723, 'loss_consonant': 0.096616}\n",
      "   87 | 0.000098 | 143280/160596 | 1.7420 | 1.7115 |\n",
      "val: {'recall': 0.992709, 'recall_grapheme': 0.989724, 'recall_vowel': 0.99619, 'recall_consonant': 0.995197, 'acc_grapheme': 0.989787, 'acc_vowel': 0.996447, 'acc_consonant': 0.995999, 'loss_grapheme': 0.256981, 'loss_vowel': 0.157118, 'loss_consonant': 0.091554}\n",
      "   88 | 0.000093 | 126720/160596 | 2.0763 | 1.7800 |\n",
      "val: {'recall': 0.993266, 'recall_grapheme': 0.990527, 'recall_vowel': 0.995712, 'recall_consonant': 0.996298, 'acc_grapheme': 0.990483, 'acc_vowel': 0.996148, 'acc_consonant': 0.996298, 'loss_grapheme': 0.229118, 'loss_vowel': 0.143223, 'loss_consonant': 0.093454}\n",
      "   89 | 0.000086 | 110160/160596 | 1.4416 | 1.7878 |\n",
      "val: {'recall': 0.993055, 'recall_grapheme': 0.990266, 'recall_vowel': 0.995738, 'recall_consonant': 0.995952, 'acc_grapheme': 0.990682, 'acc_vowel': 0.99667, 'acc_consonant': 0.996472, 'loss_grapheme': 0.189673, 'loss_vowel': 0.117455, 'loss_consonant': 0.077091}\n",
      "   90 | 0.000075 | 093600/160596 | 1.9472 | 1.7564 |\n",
      "val: {'recall': 0.993221, 'recall_grapheme': 0.991016, 'recall_vowel': 0.995998, 'recall_consonant': 0.994853, 'acc_grapheme': 0.990558, 'acc_vowel': 0.99677, 'acc_consonant': 0.996198, 'loss_grapheme': 0.210202, 'loss_vowel': 0.129836, 'loss_consonant': 0.087647}\n",
      "   91 | 0.000063 | 077040/160596 | 1.9699 | 1.7708 |\n",
      "val: {'recall': 0.993813, 'recall_grapheme': 0.991586, 'recall_vowel': 0.996134, 'recall_consonant': 0.995947, 'acc_grapheme': 0.990781, 'acc_vowel': 0.996819, 'acc_consonant': 0.996472, 'loss_grapheme': 0.206605, 'loss_vowel': 0.135543, 'loss_consonant': 0.084316}\n",
      "   92 | 0.000050 | 060480/160596 | 2.1953 | 1.7158 |\n",
      "val: {'recall': 0.993673, 'recall_grapheme': 0.991374, 'recall_vowel': 0.996278, 'recall_consonant': 0.995665, 'acc_grapheme': 0.990756, 'acc_vowel': 0.99667, 'acc_consonant': 0.996298, 'loss_grapheme': 0.244955, 'loss_vowel': 0.149261, 'loss_consonant': 0.101186}\n",
      "   93 | 0.000038 | 043920/160596 | 2.1642 | 1.7903 |\n",
      "val: {'recall': 0.99447, 'recall_grapheme': 0.992541, 'recall_vowel': 0.996436, 'recall_consonant': 0.996364, 'acc_grapheme': 0.992098, 'acc_vowel': 0.997142, 'acc_consonant': 0.997118, 'loss_grapheme': 0.207724, 'loss_vowel': 0.135848, 'loss_consonant': 0.088524}\n",
      "** saved\n",
      "   94 | 0.000026 | 027360/160596 | 1.3982 | 1.7639 |\n",
      "val: {'recall': 0.99402, 'recall_grapheme': 0.991988, 'recall_vowel': 0.996347, 'recall_consonant': 0.995758, 'acc_grapheme': 0.991477, 'acc_vowel': 0.997142, 'acc_consonant': 0.996745, 'loss_grapheme': 0.166334, 'loss_vowel': 0.104144, 'loss_consonant': 0.065071}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 | 0.000015 | 010800/160596 | 2.1405 | 1.9080 |\n",
      "val: {'recall': 0.993904, 'recall_grapheme': 0.991782, 'recall_vowel': 0.99668, 'recall_consonant': 0.995372, 'acc_grapheme': 0.991353, 'acc_vowel': 0.997142, 'acc_consonant': 0.996621, 'loss_grapheme': 0.206664, 'loss_vowel': 0.144018, 'loss_consonant': 0.088599}\n",
      "   95 | 0.000008 | 154800/160596 | 0.9187 | 1.7715 |\n",
      "val: {'recall': 0.993714, 'recall_grapheme': 0.991554, 'recall_vowel': 0.996222, 'recall_consonant': 0.995527, 'acc_grapheme': 0.990657, 'acc_vowel': 0.996869, 'acc_consonant': 0.996596, 'loss_grapheme': 0.212181, 'loss_vowel': 0.137703, 'loss_consonant': 0.088472}\n",
      "   96 | 0.000003 | 138240/160596 | 1.7743 | 1.7494 |\n",
      "val: {'recall': 0.994067, 'recall_grapheme': 0.99199, 'recall_vowel': 0.99618, 'recall_consonant': 0.996107, 'acc_grapheme': 0.991079, 'acc_vowel': 0.99677, 'acc_consonant': 0.996621, 'loss_grapheme': 0.208468, 'loss_vowel': 0.14876, 'loss_consonant': 0.094962}\n",
      "   97 | 0.000001 | 121680/160596 | 2.2002 | 1.7543 |\n",
      "val: {'recall': 0.994239, 'recall_grapheme': 0.99215, 'recall_vowel': 0.996894, 'recall_consonant': 0.995761, 'acc_grapheme': 0.991725, 'acc_vowel': 0.997267, 'acc_consonant': 0.996645, 'loss_grapheme': 0.191153, 'loss_vowel': 0.136912, 'loss_consonant': 0.086135}\n",
      "   98 | 0.000003 | 105120/160596 | 1.4751 | 1.7573 |\n",
      "val: {'recall': 0.994289, 'recall_grapheme': 0.992205, 'recall_vowel': 0.996611, 'recall_consonant': 0.996134, 'acc_grapheme': 0.991775, 'acc_vowel': 0.997093, 'acc_consonant': 0.996819, 'loss_grapheme': 0.210386, 'loss_vowel': 0.134846, 'loss_consonant': 0.087349}\n",
      "   99 | 0.000008 | 088560/160596 | 0.9531 | 1.7871 |\n",
      "val: {'recall': 0.994423, 'recall_grapheme': 0.992516, 'recall_vowel': 0.996587, 'recall_consonant': 0.996072, 'acc_grapheme': 0.991899, 'acc_vowel': 0.997142, 'acc_consonant': 0.996795, 'loss_grapheme': 0.192333, 'loss_vowel': 0.12625, 'loss_consonant': 0.080366}\n",
      "  100 | 0.000015 | 072000/160596 | 1.5810 | 1.7340 |\n",
      "val: {'recall': 0.994356, 'recall_grapheme': 0.992412, 'recall_vowel': 0.996541, 'recall_consonant': 0.996059, 'acc_grapheme': 0.991601, 'acc_vowel': 0.997118, 'acc_consonant': 0.99677, 'loss_grapheme': 0.207177, 'loss_vowel': 0.133306, 'loss_consonant': 0.085714}\n",
      "  101 | 0.000026 | 055440/160596 | 0.8543 | 1.6236 |\n",
      "val: {'recall': 0.994178, 'recall_grapheme': 0.992179, 'recall_vowel': 0.996353, 'recall_consonant': 0.996, 'acc_grapheme': 0.991552, 'acc_vowel': 0.996993, 'acc_consonant': 0.996596, 'loss_grapheme': 0.195981, 'loss_vowel': 0.132486, 'loss_consonant': 0.081941}\n",
      "  102 | 0.000038 | 038880/160596 | 1.9068 | 1.7956 |\n",
      "val: {'recall': 0.993715, 'recall_grapheme': 0.991776, 'recall_vowel': 0.995648, 'recall_consonant': 0.995659, 'acc_grapheme': 0.991552, 'acc_vowel': 0.996795, 'acc_consonant': 0.996422, 'loss_grapheme': 0.225451, 'loss_vowel': 0.14288, 'loss_consonant': 0.092876}\n",
      "  103 | 0.000051 | 022320/160596 | 1.1546 | 1.7252 |\n",
      "val: {'recall': 0.991688, 'recall_grapheme': 0.990179, 'recall_vowel': 0.994516, 'recall_consonant': 0.991879, 'acc_grapheme': 0.989837, 'acc_vowel': 0.995925, 'acc_consonant': 0.99585, 'loss_grapheme': 0.143651, 'loss_vowel': 0.076571, 'loss_consonant': 0.058491}\n",
      "  104 | 0.000063 | 005760/160596 | 1.6393 | 1.7155 |\n",
      "val: {'recall': 0.994243, 'recall_grapheme': 0.992421, 'recall_vowel': 0.996006, 'recall_consonant': 0.996126, 'acc_grapheme': 0.991204, 'acc_vowel': 0.996894, 'acc_consonant': 0.996472, 'loss_grapheme': 0.256945, 'loss_vowel': 0.161759, 'loss_consonant': 0.100599}\n",
      "  104 | 0.000075 | 149760/160596 | 3.0023 | 1.8221 |\n",
      "val: {'recall': 0.992638, 'recall_grapheme': 0.989186, 'recall_vowel': 0.995721, 'recall_consonant': 0.996458, 'acc_grapheme': 0.989912, 'acc_vowel': 0.99667, 'acc_consonant': 0.996472, 'loss_grapheme': 0.245499, 'loss_vowel': 0.159055, 'loss_consonant': 0.097752}\n",
      "  105 | 0.000086 | 133200/160596 | 2.7803 | 1.8120 |\n",
      "val: {'recall': 0.993048, 'recall_grapheme': 0.990937, 'recall_vowel': 0.996267, 'recall_consonant': 0.994051, 'acc_grapheme': 0.990607, 'acc_vowel': 0.996745, 'acc_consonant': 0.995975, 'loss_grapheme': 0.204826, 'loss_vowel': 0.131211, 'loss_consonant': 0.081897}\n",
      "  106 | 0.000093 | 116640/160596 | 1.7151 | 1.8064 |\n",
      "val: {'recall': 0.993149, 'recall_grapheme': 0.991366, 'recall_vowel': 0.995558, 'recall_consonant': 0.994307, 'acc_grapheme': 0.990955, 'acc_vowel': 0.996645, 'acc_consonant': 0.996099, 'loss_grapheme': 0.18544, 'loss_vowel': 0.103706, 'loss_consonant': 0.077428}\n",
      "  107 | 0.000098 | 100080/160596 | 0.7873 | 1.7613 |\n",
      "val: {'recall': 0.98995, 'recall_grapheme': 0.987467, 'recall_vowel': 0.995262, 'recall_consonant': 0.989604, 'acc_grapheme': 0.986855, 'acc_vowel': 0.995502, 'acc_consonant': 0.995155, 'loss_grapheme': 0.229943, 'loss_vowel': 0.154391, 'loss_consonant': 0.097987}\n",
      "  108 | 0.000100 | 083520/160596 | 1.4743 | 1.8635 |\n",
      "val: {'recall': 0.992506, 'recall_grapheme': 0.989498, 'recall_vowel': 0.995185, 'recall_consonant': 0.995843, 'acc_grapheme': 0.989067, 'acc_vowel': 0.996173, 'acc_consonant': 0.996198, 'loss_grapheme': 0.252334, 'loss_vowel': 0.146797, 'loss_consonant': 0.09488}\n",
      "  109 | 0.000098 | 066960/160596 | 1.3056 | 1.7361 |\n",
      "val: {'recall': 0.992952, 'recall_grapheme': 0.990196, 'recall_vowel': 0.996304, 'recall_consonant': 0.995111, 'acc_grapheme': 0.990011, 'acc_vowel': 0.996745, 'acc_consonant': 0.995776, 'loss_grapheme': 0.235891, 'loss_vowel': 0.145717, 'loss_consonant': 0.089928}\n",
      "  110 | 0.000093 | 050400/160596 | 1.8159 | 1.7205 |\n",
      "val: {'recall': 0.991907, 'recall_grapheme': 0.988425, 'recall_vowel': 0.995655, 'recall_consonant': 0.995122, 'acc_grapheme': 0.989166, 'acc_vowel': 0.996496, 'acc_consonant': 0.996074, 'loss_grapheme': 0.243735, 'loss_vowel': 0.138974, 'loss_consonant': 0.097055}\n",
      "  111 | 0.000086 | 033840/160596 | 2.2967 | 1.6139 |\n",
      "val: {'recall': 0.993409, 'recall_grapheme': 0.991099, 'recall_vowel': 0.995997, 'recall_consonant': 0.995443, 'acc_grapheme': 0.990607, 'acc_vowel': 0.996596, 'acc_consonant': 0.996273, 'loss_grapheme': 0.234499, 'loss_vowel': 0.13534, 'loss_consonant': 0.090728}\n",
      "  112 | 0.000075 | 017280/160596 | 2.3602 | 1.9814 |\n",
      "val: {'recall': 0.994402, 'recall_grapheme': 0.992171, 'recall_vowel': 0.99683, 'recall_consonant': 0.996435, 'acc_grapheme': 0.991427, 'acc_vowel': 0.997192, 'acc_consonant': 0.996571, 'loss_grapheme': 0.247624, 'loss_vowel': 0.161501, 'loss_consonant': 0.102648}\n",
      "  113 | 0.000063 | 000720/160596 | 2.6126 | 2.6126 |\n",
      "val: {'recall': 0.992222, 'recall_grapheme': 0.989714, 'recall_vowel': 0.99562, 'recall_consonant': 0.993838, 'acc_grapheme': 0.989489, 'acc_vowel': 0.996397, 'acc_consonant': 0.996074, 'loss_grapheme': 0.246947, 'loss_vowel': 0.156976, 'loss_consonant': 0.09928}\n",
      "  113 | 0.000051 | 144720/160596 | 2.7335 | 1.7482 |\n",
      "val: {'recall': 0.993573, 'recall_grapheme': 0.991085, 'recall_vowel': 0.996511, 'recall_consonant': 0.99561, 'acc_grapheme': 0.990334, 'acc_vowel': 0.997093, 'acc_consonant': 0.996447, 'loss_grapheme': 0.236889, 'loss_vowel': 0.154137, 'loss_consonant': 0.099962}\n",
      "  114 | 0.000038 | 128160/160596 | 1.5353 | 1.7366 |\n",
      "val: {'recall': 0.994194, 'recall_grapheme': 0.9923, 'recall_vowel': 0.995983, 'recall_consonant': 0.996195, 'acc_grapheme': 0.991725, 'acc_vowel': 0.997118, 'acc_consonant': 0.996621, 'loss_grapheme': 0.198118, 'loss_vowel': 0.115073, 'loss_consonant': 0.078773}\n",
      "  115 | 0.000026 | 111600/160596 | 0.2348 | 1.7263 |\n",
      "val: {'recall': 0.993012, 'recall_grapheme': 0.990164, 'recall_vowel': 0.9958, 'recall_consonant': 0.995919, 'acc_grapheme': 0.989564, 'acc_vowel': 0.996596, 'acc_consonant': 0.996472, 'loss_grapheme': 0.222357, 'loss_vowel': 0.15473, 'loss_consonant': 0.099056}\n",
      "  116 | 0.000015 | 095040/160596 | 2.5753 | 1.8392 |\n",
      "val: {'recall': 0.993552, 'recall_grapheme': 0.990879, 'recall_vowel': 0.99641, 'recall_consonant': 0.99604, 'acc_grapheme': 0.990756, 'acc_vowel': 0.99677, 'acc_consonant': 0.996571, 'loss_grapheme': 0.220451, 'loss_vowel': 0.141484, 'loss_consonant': 0.091104}\n",
      "  117 | 0.000008 | 078480/160596 | 1.7087 | 1.6850 |\n",
      "val: {'recall': 0.994405, 'recall_grapheme': 0.992378, 'recall_vowel': 0.996512, 'recall_consonant': 0.996354, 'acc_grapheme': 0.992049, 'acc_vowel': 0.997118, 'acc_consonant': 0.996621, 'loss_grapheme': 0.2175, 'loss_vowel': 0.129949, 'loss_consonant': 0.083461}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  118 | 0.000003 | 061920/160596 | 0.7009 | 1.6500 |\n",
      "val: {'recall': 0.993566, 'recall_grapheme': 0.990998, 'recall_vowel': 0.996285, 'recall_consonant': 0.995983, 'acc_grapheme': 0.990582, 'acc_vowel': 0.996819, 'acc_consonant': 0.996521, 'loss_grapheme': 0.202901, 'loss_vowel': 0.13552, 'loss_consonant': 0.086717}\n",
      "  119 | 0.000001 | 045360/160596 | 2.3225 | 1.7665 |\n",
      "val: {'recall': 0.993179, 'recall_grapheme': 0.990529, 'recall_vowel': 0.995723, 'recall_consonant': 0.995937, 'acc_grapheme': 0.990135, 'acc_vowel': 0.99667, 'acc_consonant': 0.996472, 'loss_grapheme': 0.172909, 'loss_vowel': 0.128672, 'loss_consonant': 0.083592}\n",
      "  120 | 0.000003 | 028800/160596 | 0.0587 | 1.7202 |\n",
      "val: {'recall': 0.993157, 'recall_grapheme': 0.990587, 'recall_vowel': 0.995636, 'recall_consonant': 0.995818, 'acc_grapheme': 0.990409, 'acc_vowel': 0.996645, 'acc_consonant': 0.996223, 'loss_grapheme': 0.158516, 'loss_vowel': 0.125297, 'loss_consonant': 0.082739}\n",
      "  121 | 0.000008 | 012240/160596 | 1.7968 | 1.5521 |\n",
      "val: {'recall': 0.994203, 'recall_grapheme': 0.991917, 'recall_vowel': 0.996326, 'recall_consonant': 0.996652, 'acc_grapheme': 0.991229, 'acc_vowel': 0.997018, 'acc_consonant': 0.996869, 'loss_grapheme': 0.172948, 'loss_vowel': 0.109259, 'loss_consonant': 0.069688}\n",
      "  121 | 0.000015 | 156240/160596 | 0.7359 | 1.6571 |\n",
      "val: {'recall': 0.994138, 'recall_grapheme': 0.991918, 'recall_vowel': 0.996254, 'recall_consonant': 0.99646, 'acc_grapheme': 0.991402, 'acc_vowel': 0.996894, 'acc_consonant': 0.99672, 'loss_grapheme': 0.1568, 'loss_vowel': 0.103769, 'loss_consonant': 0.064609}\n",
      "  122 | 0.000026 | 139680/160596 | 2.0400 | 1.7623 |\n",
      "val: {'recall': 0.994208, 'recall_grapheme': 0.992488, 'recall_vowel': 0.995789, 'recall_consonant': 0.996067, 'acc_grapheme': 0.991129, 'acc_vowel': 0.99672, 'acc_consonant': 0.996447, 'loss_grapheme': 0.153807, 'loss_vowel': 0.102672, 'loss_consonant': 0.066442}\n",
      "  123 | 0.000038 | 123120/160596 | 1.6283 | 1.7957 |\n",
      "val: {'recall': 0.993222, 'recall_grapheme': 0.990489, 'recall_vowel': 0.995945, 'recall_consonant': 0.995968, 'acc_grapheme': 0.989688, 'acc_vowel': 0.99677, 'acc_consonant': 0.996148, 'loss_grapheme': 0.221594, 'loss_vowel': 0.151798, 'loss_consonant': 0.10091}\n",
      "  124 | 0.000051 | 106560/160596 | 1.7037 | 1.7684 |\n",
      "val: {'recall': 0.993436, 'recall_grapheme': 0.990996, 'recall_vowel': 0.996865, 'recall_consonant': 0.994885, 'acc_grapheme': 0.991229, 'acc_vowel': 0.996944, 'acc_consonant': 0.996819, 'loss_grapheme': 0.199655, 'loss_vowel': 0.113534, 'loss_consonant': 0.075237}\n",
      "  125 | 0.000063 | 090000/160596 | 2.1903 | 1.7960 |\n",
      "val: {'recall': 0.993687, 'recall_grapheme': 0.99158, 'recall_vowel': 0.995381, 'recall_consonant': 0.996209, 'acc_grapheme': 0.990657, 'acc_vowel': 0.996645, 'acc_consonant': 0.996198, 'loss_grapheme': 0.188435, 'loss_vowel': 0.12648, 'loss_consonant': 0.080699}\n",
      "  126 | 0.000075 | 073440/160596 | 1.3440 | 1.7932 |\n",
      "val: {'recall': 0.993863, 'recall_grapheme': 0.991385, 'recall_vowel': 0.995914, 'recall_consonant': 0.996766, 'acc_grapheme': 0.990334, 'acc_vowel': 0.996919, 'acc_consonant': 0.996521, 'loss_grapheme': 0.193268, 'loss_vowel': 0.121403, 'loss_consonant': 0.075364}\n",
      "  127 | 0.000086 | 056880/160596 | 1.9840 | 1.6645 |\n",
      "val: {'recall': 0.994178, 'recall_grapheme': 0.991915, 'recall_vowel': 0.996776, 'recall_consonant': 0.996107, 'acc_grapheme': 0.991278, 'acc_vowel': 0.99667, 'acc_consonant': 0.996422, 'loss_grapheme': 0.242571, 'loss_vowel': 0.139012, 'loss_consonant': 0.091865}\n",
      "  128 | 0.000093 | 040320/160596 | 1.7241 | 1.7908 |\n",
      "val: {'recall': 0.993586, 'recall_grapheme': 0.991828, 'recall_vowel': 0.995421, 'recall_consonant': 0.995268, 'acc_grapheme': 0.991055, 'acc_vowel': 0.996596, 'acc_consonant': 0.996273, 'loss_grapheme': 0.212189, 'loss_vowel': 0.122797, 'loss_consonant': 0.08416}\n",
      "  129 | 0.000098 | 023760/160596 | 1.5272 | 1.8931 |\n",
      "val: {'recall': 0.992394, 'recall_grapheme': 0.98927, 'recall_vowel': 0.995186, 'recall_consonant': 0.995852, 'acc_grapheme': 0.989663, 'acc_vowel': 0.996198, 'acc_consonant': 0.996273, 'loss_grapheme': 0.277717, 'loss_vowel': 0.153316, 'loss_consonant': 0.100962}\n",
      "  130 | 0.000100 | 007200/160596 | 1.8531 | 2.1114 |\n",
      "val: {'recall': 0.99007, 'recall_grapheme': 0.986456, 'recall_vowel': 0.994122, 'recall_consonant': 0.993245, 'acc_grapheme': 0.98519, 'acc_vowel': 0.99513, 'acc_consonant': 0.994558, 'loss_grapheme': 0.266135, 'loss_vowel': 0.163143, 'loss_consonant': 0.103547}\n",
      "  130 | 0.000098 | 151200/160596 | 1.7430 | 1.7902 |\n",
      "val: {'recall': 0.992552, 'recall_grapheme': 0.989251, 'recall_vowel': 0.995739, 'recall_consonant': 0.995966, 'acc_grapheme': 0.989663, 'acc_vowel': 0.996298, 'acc_consonant': 0.995999, 'loss_grapheme': 0.17283, 'loss_vowel': 0.091833, 'loss_consonant': 0.070877}\n",
      "  131 | 0.000093 | 134640/160596 | 1.1941 | 1.8645 |\n",
      "val: {'recall': 0.993949, 'recall_grapheme': 0.991689, 'recall_vowel': 0.996224, 'recall_consonant': 0.996194, 'acc_grapheme': 0.990955, 'acc_vowel': 0.996944, 'acc_consonant': 0.996496, 'loss_grapheme': 0.211658, 'loss_vowel': 0.115747, 'loss_consonant': 0.069685}\n",
      "  132 | 0.000086 | 118080/160596 | 0.5495 | 1.7020 |\n",
      "val: {'recall': 0.992528, 'recall_grapheme': 0.989136, 'recall_vowel': 0.995809, 'recall_consonant': 0.996031, 'acc_grapheme': 0.989812, 'acc_vowel': 0.996372, 'acc_consonant': 0.996099, 'loss_grapheme': 0.205842, 'loss_vowel': 0.124324, 'loss_consonant': 0.080847}\n",
      "  133 | 0.000075 | 101520/160596 | 2.0419 | 1.8411 |\n",
      "val: {'recall': 0.992142, 'recall_grapheme': 0.989366, 'recall_vowel': 0.994266, 'recall_consonant': 0.995573, 'acc_grapheme': 0.988868, 'acc_vowel': 0.995378, 'acc_consonant': 0.995676, 'loss_grapheme': 0.194677, 'loss_vowel': 0.15013, 'loss_consonant': 0.094086}\n",
      "  134 | 0.000063 | 084960/160596 | 2.1819 | 1.7500 |\n",
      "val: {'recall': 0.99327, 'recall_grapheme': 0.990286, 'recall_vowel': 0.996146, 'recall_consonant': 0.996364, 'acc_grapheme': 0.989762, 'acc_vowel': 0.99667, 'acc_consonant': 0.996223, 'loss_grapheme': 0.251624, 'loss_vowel': 0.159449, 'loss_consonant': 0.096483}\n",
      "  135 | 0.000051 | 068400/160596 | 0.1812 | 1.7811 |\n",
      "val: {'recall': 0.993131, 'recall_grapheme': 0.990389, 'recall_vowel': 0.99543, 'recall_consonant': 0.996317, 'acc_grapheme': 0.989912, 'acc_vowel': 0.996571, 'acc_consonant': 0.996546, 'loss_grapheme': 0.186797, 'loss_vowel': 0.120097, 'loss_consonant': 0.075068}\n",
      "  136 | 0.000038 | 051840/160596 | 1.0469 | 1.7468 |\n",
      "val: {'recall': 0.993878, 'recall_grapheme': 0.991203, 'recall_vowel': 0.996587, 'recall_consonant': 0.996517, 'acc_grapheme': 0.991651, 'acc_vowel': 0.997167, 'acc_consonant': 0.996869, 'loss_grapheme': 0.184651, 'loss_vowel': 0.105913, 'loss_consonant': 0.069275}\n",
      "  137 | 0.000026 | 035280/160596 | 2.6433 | 1.6348 |\n",
      "val: {'recall': 0.994168, 'recall_grapheme': 0.99175, 'recall_vowel': 0.996589, 'recall_consonant': 0.996583, 'acc_grapheme': 0.991701, 'acc_vowel': 0.997167, 'acc_consonant': 0.996944, 'loss_grapheme': 0.190567, 'loss_vowel': 0.114073, 'loss_consonant': 0.071038}\n",
      "  138 | 0.000015 | 018720/160596 | 0.5718 | 1.4705 |\n",
      "val: {'recall': 0.994689, 'recall_grapheme': 0.992502, 'recall_vowel': 0.9969, 'recall_consonant': 0.996851, 'acc_grapheme': 0.992719, 'acc_vowel': 0.997242, 'acc_consonant': 0.997068, 'loss_grapheme': 0.150021, 'loss_vowel': 0.086543, 'loss_consonant': 0.057975}\n",
      "** saved\n",
      "  139 | 0.000008 | 002160/160596 | 2.0571 | 1.8171 |\n",
      "val: {'recall': 0.993958, 'recall_grapheme': 0.992013, 'recall_vowel': 0.996502, 'recall_consonant': 0.995306, 'acc_grapheme': 0.991427, 'acc_vowel': 0.997142, 'acc_consonant': 0.996795, 'loss_grapheme': 0.204557, 'loss_vowel': 0.124862, 'loss_consonant': 0.08014}\n",
      "  139 | 0.000003 | 146160/160596 | 1.6781 | 1.6123 |\n",
      "val: {'recall': 0.994276, 'recall_grapheme': 0.992476, 'recall_vowel': 0.996829, 'recall_consonant': 0.995322, 'acc_grapheme': 0.992173, 'acc_vowel': 0.997341, 'acc_consonant': 0.996894, 'loss_grapheme': 0.208869, 'loss_vowel': 0.123359, 'loss_consonant': 0.076494}\n",
      "  140 | 0.000001 | 129600/160596 | 1.5466 | 1.6811 |\n",
      "val: {'recall': 0.994516, 'recall_grapheme': 0.992415, 'recall_vowel': 0.996606, 'recall_consonant': 0.996626, 'acc_grapheme': 0.992173, 'acc_vowel': 0.997316, 'acc_consonant': 0.997018, 'loss_grapheme': 0.182598, 'loss_vowel': 0.110004, 'loss_consonant': 0.071926}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  141 | 0.000003 | 113040/160596 | 2.4189 | 1.7417 |\n",
      "val: {'recall': 0.994323, 'recall_grapheme': 0.992132, 'recall_vowel': 0.996274, 'recall_consonant': 0.996753, 'acc_grapheme': 0.991303, 'acc_vowel': 0.996993, 'acc_consonant': 0.996993, 'loss_grapheme': 0.181507, 'loss_vowel': 0.114626, 'loss_consonant': 0.069149}\n",
      "  142 | 0.000008 | 096480/160596 | 2.3521 | 1.5960 |\n",
      "val: {'recall': 0.99453, 'recall_grapheme': 0.992765, 'recall_vowel': 0.997065, 'recall_consonant': 0.995524, 'acc_grapheme': 0.992595, 'acc_vowel': 0.997465, 'acc_consonant': 0.997118, 'loss_grapheme': 0.162754, 'loss_vowel': 0.098538, 'loss_consonant': 0.059229}\n",
      "  143 | 0.000015 | 079920/160596 | 3.0535 | 1.7548 |\n",
      "val: {'recall': 0.993858, 'recall_grapheme': 0.991664, 'recall_vowel': 0.996038, 'recall_consonant': 0.996064, 'acc_grapheme': 0.990682, 'acc_vowel': 0.996844, 'acc_consonant': 0.996347, 'loss_grapheme': 0.223647, 'loss_vowel': 0.148062, 'loss_consonant': 0.098788}\n",
      "  144 | 0.000026 | 063360/160596 | 1.4107 | 1.5486 |\n",
      "val: {'recall': 0.994304, 'recall_grapheme': 0.99212, 'recall_vowel': 0.99662, 'recall_consonant': 0.996357, 'acc_grapheme': 0.992024, 'acc_vowel': 0.997316, 'acc_consonant': 0.99667, 'loss_grapheme': 0.185897, 'loss_vowel': 0.109736, 'loss_consonant': 0.074011}\n",
      "  145 | 0.000038 | 046800/160596 | 1.6145 | 1.5811 |\n",
      "val: {'recall': 0.993462, 'recall_grapheme': 0.990994, 'recall_vowel': 0.996183, 'recall_consonant': 0.995676, 'acc_grapheme': 0.990756, 'acc_vowel': 0.997018, 'acc_consonant': 0.996372, 'loss_grapheme': 0.198098, 'loss_vowel': 0.112601, 'loss_consonant': 0.075731}\n",
      "  146 | 0.000051 | 030240/160596 | 2.6869 | 1.6355 |\n",
      "val: {'recall': 0.993868, 'recall_grapheme': 0.991358, 'recall_vowel': 0.996357, 'recall_consonant': 0.996402, 'acc_grapheme': 0.991477, 'acc_vowel': 0.997068, 'acc_consonant': 0.99667, 'loss_grapheme': 0.236094, 'loss_vowel': 0.131667, 'loss_consonant': 0.093039}\n",
      "  147 | 0.000063 | 013680/160596 | 0.8959 | 1.5916 |\n",
      "val: {'recall': 0.994142, 'recall_grapheme': 0.992135, 'recall_vowel': 0.996546, 'recall_consonant': 0.995755, 'acc_grapheme': 0.992024, 'acc_vowel': 0.997068, 'acc_consonant': 0.996322, 'loss_grapheme': 0.187552, 'loss_vowel': 0.101225, 'loss_consonant': 0.066299}\n",
      "  147 | 0.000075 | 157680/160596 | 1.9428 | 1.8187 |\n",
      "val: {'recall': 0.993374, 'recall_grapheme': 0.990792, 'recall_vowel': 0.996689, 'recall_consonant': 0.995222, 'acc_grapheme': 0.991378, 'acc_vowel': 0.996993, 'acc_consonant': 0.996248, 'loss_grapheme': 0.2048, 'loss_vowel': 0.141388, 'loss_consonant': 0.089305}\n",
      "  148 | 0.000086 | 141120/160596 | 2.7289 | 1.8082 |\n",
      "val: {'recall': 0.991751, 'recall_grapheme': 0.988223, 'recall_vowel': 0.994901, 'recall_consonant': 0.995659, 'acc_grapheme': 0.988222, 'acc_vowel': 0.995527, 'acc_consonant': 0.995204, 'loss_grapheme': 0.249326, 'loss_vowel': 0.208825, 'loss_consonant': 0.121982}\n",
      "  149 | 0.000093 | 124560/160596 | 2.2731 | 1.8477 |\n",
      "val: {'recall': 0.992888, 'recall_grapheme': 0.990156, 'recall_vowel': 0.995347, 'recall_consonant': 0.995892, 'acc_grapheme': 0.990309, 'acc_vowel': 0.996695, 'acc_consonant': 0.996248, 'loss_grapheme': 0.242836, 'loss_vowel': 0.145046, 'loss_consonant': 0.09698}\n",
      "  150 | 0.000098 | 108000/160596 | 1.9948 | 1.7652 |\n",
      "val: {'recall': 0.99262, 'recall_grapheme': 0.989666, 'recall_vowel': 0.995612, 'recall_consonant': 0.995535, 'acc_grapheme': 0.989961, 'acc_vowel': 0.996322, 'acc_consonant': 0.996372, 'loss_grapheme': 0.187734, 'loss_vowel': 0.103032, 'loss_consonant': 0.065927}\n",
      "  151 | 0.000100 | 091440/160596 | 1.4620 | 1.8088 |\n",
      "val: {'recall': 0.993273, 'recall_grapheme': 0.991002, 'recall_vowel': 0.995842, 'recall_consonant': 0.995246, 'acc_grapheme': 0.990732, 'acc_vowel': 0.996819, 'acc_consonant': 0.996397, 'loss_grapheme': 0.222569, 'loss_vowel': 0.136208, 'loss_consonant': 0.087452}\n",
      "  152 | 0.000098 | 074880/160596 | 0.3535 | 1.7239 |\n",
      "val: {'recall': 0.993672, 'recall_grapheme': 0.990884, 'recall_vowel': 0.996415, 'recall_consonant': 0.996506, 'acc_grapheme': 0.991527, 'acc_vowel': 0.997043, 'acc_consonant': 0.996869, 'loss_grapheme': 0.168786, 'loss_vowel': 0.09617, 'loss_consonant': 0.059598}\n",
      "  153 | 0.000093 | 058320/160596 | 2.2466 | 1.7579 |\n",
      "val: {'recall': 0.99293, 'recall_grapheme': 0.989578, 'recall_vowel': 0.996373, 'recall_consonant': 0.99619, 'acc_grapheme': 0.989762, 'acc_vowel': 0.996695, 'acc_consonant': 0.996322, 'loss_grapheme': 0.261416, 'loss_vowel': 0.152696, 'loss_consonant': 0.091472}\n",
      "  154 | 0.000086 | 041760/160596 | 0.1293 | 1.7678 |\n",
      "val: {'recall': 0.993419, 'recall_grapheme': 0.990783, 'recall_vowel': 0.996604, 'recall_consonant': 0.995508, 'acc_grapheme': 0.991278, 'acc_vowel': 0.996819, 'acc_consonant': 0.99667, 'loss_grapheme': 0.188612, 'loss_vowel': 0.11725, 'loss_consonant': 0.077349}\n",
      "  155 | 0.000075 | 025200/160596 | 1.8840 | 1.7613 |\n",
      "val: {'recall': 0.993255, 'recall_grapheme': 0.990155, 'recall_vowel': 0.996539, 'recall_consonant': 0.996171, 'acc_grapheme': 0.99098, 'acc_vowel': 0.996596, 'acc_consonant': 0.996546, 'loss_grapheme': 0.229621, 'loss_vowel': 0.145258, 'loss_consonant': 0.086783}\n",
      "  156 | 0.000063 | 008640/160596 | 2.7019 | 1.5479 |\n",
      "val: {'recall': 0.993966, 'recall_grapheme': 0.991623, 'recall_vowel': 0.996326, 'recall_consonant': 0.996293, 'acc_grapheme': 0.990707, 'acc_vowel': 0.996919, 'acc_consonant': 0.996521, 'loss_grapheme': 0.210471, 'loss_vowel': 0.127052, 'loss_consonant': 0.074311}\n",
      "  156 | 0.000051 | 152640/160596 | 1.8417 | 1.6805 |\n",
      "val: {'recall': 0.993042, 'recall_grapheme': 0.989808, 'recall_vowel': 0.995728, 'recall_consonant': 0.996822, 'acc_grapheme': 0.99021, 'acc_vowel': 0.996372, 'acc_consonant': 0.996521, 'loss_grapheme': 0.22155, 'loss_vowel': 0.16307, 'loss_consonant': 0.10609}\n",
      "  157 | 0.000038 | 136080/160596 | 0.6998 | 1.5651 |\n",
      "val: {'recall': 0.994487, 'recall_grapheme': 0.992322, 'recall_vowel': 0.99653, 'recall_consonant': 0.996773, 'acc_grapheme': 0.991626, 'acc_vowel': 0.997118, 'acc_consonant': 0.996919, 'loss_grapheme': 0.192282, 'loss_vowel': 0.114013, 'loss_consonant': 0.070282}\n",
      "  158 | 0.000026 | 119520/160596 | 2.4106 | 1.6226 |\n",
      "val: {'recall': 0.9941, 'recall_grapheme': 0.99133, 'recall_vowel': 0.996805, 'recall_consonant': 0.996936, 'acc_grapheme': 0.991452, 'acc_vowel': 0.997391, 'acc_consonant': 0.997142, 'loss_grapheme': 0.215958, 'loss_vowel': 0.136636, 'loss_consonant': 0.086443}\n",
      "  159 | 0.000015 | 102960/160596 | 1.6816 | 1.7691 |\n",
      "val: {'recall': 0.99415, 'recall_grapheme': 0.991791, 'recall_vowel': 0.996299, 'recall_consonant': 0.996718, 'acc_grapheme': 0.991253, 'acc_vowel': 0.997068, 'acc_consonant': 0.996795, 'loss_grapheme': 0.18529, 'loss_vowel': 0.1245, 'loss_consonant': 0.076347}\n",
      "  160 | 0.000008 | 086400/160596 | 1.7580 | 1.6589 |\n",
      "val: {'recall': 0.994439, 'recall_grapheme': 0.992035, 'recall_vowel': 0.996758, 'recall_consonant': 0.996928, 'acc_grapheme': 0.991924, 'acc_vowel': 0.99749, 'acc_consonant': 0.997118, 'loss_grapheme': 0.200581, 'loss_vowel': 0.122508, 'loss_consonant': 0.074914}\n",
      "  161 | 0.000003 | 069840/160596 | 1.8133 | 1.5766 |\n",
      "val: {'recall': 0.994637, 'recall_grapheme': 0.992453, 'recall_vowel': 0.996589, 'recall_consonant': 0.997053, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997341, 'acc_consonant': 0.997391, 'loss_grapheme': 0.216855, 'loss_vowel': 0.121415, 'loss_consonant': 0.077457}\n",
      "  162 | 0.000001 | 053280/160596 | 2.9547 | 1.6996 |\n",
      "val: {'recall': 0.994524, 'recall_grapheme': 0.992089, 'recall_vowel': 0.996921, 'recall_consonant': 0.996998, 'acc_grapheme': 0.991999, 'acc_vowel': 0.99749, 'acc_consonant': 0.997292, 'loss_grapheme': 0.233198, 'loss_vowel': 0.133968, 'loss_consonant': 0.084773}\n",
      "  163 | 0.000003 | 036720/160596 | 2.4347 | 1.7239 |\n",
      "val: {'recall': 0.994359, 'recall_grapheme': 0.99201, 'recall_vowel': 0.996626, 'recall_consonant': 0.996791, 'acc_grapheme': 0.991527, 'acc_vowel': 0.997391, 'acc_consonant': 0.996869, 'loss_grapheme': 0.173268, 'loss_vowel': 0.112436, 'loss_consonant': 0.070036}\n",
      "  164 | 0.000008 | 020160/160596 | 0.4001 | 1.8058 |\n",
      "val: {'recall': 0.994084, 'recall_grapheme': 0.991438, 'recall_vowel': 0.996525, 'recall_consonant': 0.996934, 'acc_grapheme': 0.991576, 'acc_vowel': 0.997192, 'acc_consonant': 0.997142, 'loss_grapheme': 0.200274, 'loss_vowel': 0.129709, 'loss_consonant': 0.079782}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  165 | 0.000015 | 003600/160596 | 1.8934 | 1.4177 |\n",
      "val: {'recall': 0.993967, 'recall_grapheme': 0.991481, 'recall_vowel': 0.996307, 'recall_consonant': 0.996599, 'acc_grapheme': 0.991204, 'acc_vowel': 0.996944, 'acc_consonant': 0.996621, 'loss_grapheme': 0.173667, 'loss_vowel': 0.120629, 'loss_consonant': 0.080063}\n",
      "  165 | 0.000026 | 147600/160596 | 1.2000 | 1.6009 |\n",
      "val: {'recall': 0.994838, 'recall_grapheme': 0.992766, 'recall_vowel': 0.99686, 'recall_consonant': 0.996962, 'acc_grapheme': 0.99257, 'acc_vowel': 0.997316, 'acc_consonant': 0.997366, 'loss_grapheme': 0.175724, 'loss_vowel': 0.098428, 'loss_consonant': 0.059425}\n",
      "** saved\n",
      "  166 | 0.000038 | 131040/160596 | 2.7452 | 1.6085 |\n",
      "val: {'recall': 0.993659, 'recall_grapheme': 0.990944, 'recall_vowel': 0.996153, 'recall_consonant': 0.996595, 'acc_grapheme': 0.990582, 'acc_vowel': 0.996621, 'acc_consonant': 0.996347, 'loss_grapheme': 0.164472, 'loss_vowel': 0.11985, 'loss_consonant': 0.080672}\n",
      "  167 | 0.000051 | 114480/160596 | 1.9057 | 1.6659 |\n",
      "val: {'recall': 0.993179, 'recall_grapheme': 0.990199, 'recall_vowel': 0.996015, 'recall_consonant': 0.996304, 'acc_grapheme': 0.99011, 'acc_vowel': 0.996571, 'acc_consonant': 0.996496, 'loss_grapheme': 0.168678, 'loss_vowel': 0.123425, 'loss_consonant': 0.080697}\n",
      "  168 | 0.000063 | 097920/160596 | 2.8539 | 1.6418 |\n",
      "val: {'recall': 0.99302, 'recall_grapheme': 0.989973, 'recall_vowel': 0.996173, 'recall_consonant': 0.99596, 'acc_grapheme': 0.989539, 'acc_vowel': 0.996347, 'acc_consonant': 0.996248, 'loss_grapheme': 0.20609, 'loss_vowel': 0.135205, 'loss_consonant': 0.080904}\n",
      "  169 | 0.000075 | 081360/160596 | 0.7554 | 1.8035 |\n",
      "val: {'recall': 0.993477, 'recall_grapheme': 0.990362, 'recall_vowel': 0.9965, 'recall_consonant': 0.996682, 'acc_grapheme': 0.99093, 'acc_vowel': 0.996993, 'acc_consonant': 0.996745, 'loss_grapheme': 0.182613, 'loss_vowel': 0.107778, 'loss_consonant': 0.064995}\n",
      "  170 | 0.000086 | 064800/160596 | 2.8045 | 1.7979 |\n",
      "val: {'recall': 0.993613, 'recall_grapheme': 0.991565, 'recall_vowel': 0.99623, 'recall_consonant': 0.995093, 'acc_grapheme': 0.990682, 'acc_vowel': 0.996869, 'acc_consonant': 0.996422, 'loss_grapheme': 0.253462, 'loss_vowel': 0.157292, 'loss_consonant': 0.097126}\n",
      "  171 | 0.000093 | 048240/160596 | 3.2462 | 1.9122 |\n",
      "val: {'recall': 0.992588, 'recall_grapheme': 0.989658, 'recall_vowel': 0.995904, 'recall_consonant': 0.995131, 'acc_grapheme': 0.989986, 'acc_vowel': 0.996645, 'acc_consonant': 0.996447, 'loss_grapheme': 0.227703, 'loss_vowel': 0.152222, 'loss_consonant': 0.089217}\n",
      "  172 | 0.000098 | 031680/160596 | 1.3309 | 1.7071 |\n",
      "val: {'recall': 0.993469, 'recall_grapheme': 0.990775, 'recall_vowel': 0.995774, 'recall_consonant': 0.996552, 'acc_grapheme': 0.991055, 'acc_vowel': 0.996645, 'acc_consonant': 0.996521, 'loss_grapheme': 0.233699, 'loss_vowel': 0.139889, 'loss_consonant': 0.084195}\n",
      "  173 | 0.000100 | 015120/160596 | 3.1677 | 1.9590 |\n",
      "val: {'recall': 0.992844, 'recall_grapheme': 0.989562, 'recall_vowel': 0.99569, 'recall_consonant': 0.996562, 'acc_grapheme': 0.989787, 'acc_vowel': 0.996521, 'acc_consonant': 0.996447, 'loss_grapheme': 0.281064, 'loss_vowel': 0.161459, 'loss_consonant': 0.098677}\n",
      "  173 | 0.000098 | 159120/160596 | 2.0231 | 1.7635 |\n",
      "val: {'recall': 0.990836, 'recall_grapheme': 0.986919, 'recall_vowel': 0.995588, 'recall_consonant': 0.993917, 'acc_grapheme': 0.987228, 'acc_vowel': 0.996074, 'acc_consonant': 0.995179, 'loss_grapheme': 0.238775, 'loss_vowel': 0.152881, 'loss_consonant': 0.099391}\n",
      "  174 | 0.000093 | 142560/160596 | 2.8403 | 1.7516 |\n",
      "val: {'recall': 0.992878, 'recall_grapheme': 0.9907, 'recall_vowel': 0.9955, 'recall_consonant': 0.994612, 'acc_grapheme': 0.989912, 'acc_vowel': 0.995999, 'acc_consonant': 0.996322, 'loss_grapheme': 0.229997, 'loss_vowel': 0.14904, 'loss_consonant': 0.091187}\n",
      "  175 | 0.000086 | 126000/160596 | 2.6761 | 1.7869 |\n",
      "val: {'recall': 0.992658, 'recall_grapheme': 0.989872, 'recall_vowel': 0.99572, 'recall_consonant': 0.995166, 'acc_grapheme': 0.988619, 'acc_vowel': 0.996173, 'acc_consonant': 0.995652, 'loss_grapheme': 0.165291, 'loss_vowel': 0.111544, 'loss_consonant': 0.072714}\n",
      "  176 | 0.000075 | 109440/160596 | 2.6824 | 1.7398 |\n",
      "val: {'recall': 0.993086, 'recall_grapheme': 0.990452, 'recall_vowel': 0.99605, 'recall_consonant': 0.995389, 'acc_grapheme': 0.989762, 'acc_vowel': 0.996596, 'acc_consonant': 0.995925, 'loss_grapheme': 0.256679, 'loss_vowel': 0.163887, 'loss_consonant': 0.100933}\n",
      "  177 | 0.000063 | 092880/160596 | 1.2147 | 1.6934 |\n",
      "val: {'recall': 0.995033, 'recall_grapheme': 0.993214, 'recall_vowel': 0.996669, 'recall_consonant': 0.997035, 'acc_grapheme': 0.992918, 'acc_vowel': 0.997341, 'acc_consonant': 0.997217, 'loss_grapheme': 0.215446, 'loss_vowel': 0.117826, 'loss_consonant': 0.07367}\n",
      "** saved\n",
      "  178 | 0.000051 | 076320/160596 | 2.0154 | 1.7067 |\n",
      "val: {'recall': 0.993727, 'recall_grapheme': 0.991333, 'recall_vowel': 0.996085, 'recall_consonant': 0.996158, 'acc_grapheme': 0.991328, 'acc_vowel': 0.99677, 'acc_consonant': 0.996571, 'loss_grapheme': 0.168892, 'loss_vowel': 0.107698, 'loss_consonant': 0.068285}\n",
      "  179 | 0.000038 | 059760/160596 | 1.8577 | 1.5870 |\n",
      "val: {'recall': 0.994175, 'recall_grapheme': 0.991634, 'recall_vowel': 0.996442, 'recall_consonant': 0.996989, 'acc_grapheme': 0.991725, 'acc_vowel': 0.997267, 'acc_consonant': 0.996944, 'loss_grapheme': 0.16074, 'loss_vowel': 0.103091, 'loss_consonant': 0.061689}\n",
      "  180 | 0.000026 | 043200/160596 | 1.6269 | 1.7052 |\n",
      "val: {'recall': 0.994571, 'recall_grapheme': 0.992501, 'recall_vowel': 0.996543, 'recall_consonant': 0.996737, 'acc_grapheme': 0.992049, 'acc_vowel': 0.997316, 'acc_consonant': 0.996944, 'loss_grapheme': 0.244922, 'loss_vowel': 0.147014, 'loss_consonant': 0.089976}\n",
      "  181 | 0.000015 | 026640/160596 | 0.4252 | 1.8900 |\n",
      "val: {'recall': 0.994429, 'recall_grapheme': 0.992601, 'recall_vowel': 0.996344, 'recall_consonant': 0.996171, 'acc_grapheme': 0.992098, 'acc_vowel': 0.997366, 'acc_consonant': 0.996745, 'loss_grapheme': 0.197939, 'loss_vowel': 0.127425, 'loss_consonant': 0.077483}\n",
      "  182 | 0.000008 | 010080/160596 | 1.8803 | 1.7838 |\n",
      "val: {'recall': 0.993786, 'recall_grapheme': 0.991433, 'recall_vowel': 0.996113, 'recall_consonant': 0.996165, 'acc_grapheme': 0.990831, 'acc_vowel': 0.997068, 'acc_consonant': 0.996496, 'loss_grapheme': 0.194081, 'loss_vowel': 0.125663, 'loss_consonant': 0.078338}\n",
      "  182 | 0.000003 | 154080/160596 | 1.9982 | 1.7323 |\n",
      "val: {'recall': 0.994136, 'recall_grapheme': 0.992131, 'recall_vowel': 0.996078, 'recall_consonant': 0.996205, 'acc_grapheme': 0.991452, 'acc_vowel': 0.997142, 'acc_consonant': 0.99667, 'loss_grapheme': 0.181763, 'loss_vowel': 0.11799, 'loss_consonant': 0.075341}\n",
      "  183 | 0.000001 | 137520/160596 | 1.5194 | 1.7655 |\n",
      "val: {'recall': 0.994714, 'recall_grapheme': 0.992863, 'recall_vowel': 0.996459, 'recall_consonant': 0.996672, 'acc_grapheme': 0.992993, 'acc_vowel': 0.997292, 'acc_consonant': 0.997217, 'loss_grapheme': 0.155741, 'loss_vowel': 0.086975, 'loss_consonant': 0.058298}\n",
      "  184 | 0.000003 | 120960/160596 | 0.7741 | 1.5807 |\n",
      "val: {'recall': 0.994915, 'recall_grapheme': 0.992933, 'recall_vowel': 0.996823, 'recall_consonant': 0.996972, 'acc_grapheme': 0.992322, 'acc_vowel': 0.99754, 'acc_consonant': 0.997292, 'loss_grapheme': 0.149509, 'loss_vowel': 0.086437, 'loss_consonant': 0.050984}\n",
      "  185 | 0.000008 | 104400/160596 | 2.0699 | 1.6052 |\n",
      "val: {'recall': 0.994737, 'recall_grapheme': 0.99272, 'recall_vowel': 0.996537, 'recall_consonant': 0.99697, 'acc_grapheme': 0.992645, 'acc_vowel': 0.997292, 'acc_consonant': 0.997217, 'loss_grapheme': 0.212552, 'loss_vowel': 0.118938, 'loss_consonant': 0.079606}\n",
      "  186 | 0.000015 | 087840/160596 | 1.8882 | 1.5469 |\n",
      "val: {'recall': 0.994807, 'recall_grapheme': 0.992801, 'recall_vowel': 0.996694, 'recall_consonant': 0.996934, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997515, 'acc_consonant': 0.997267, 'loss_grapheme': 0.210377, 'loss_vowel': 0.117636, 'loss_consonant': 0.071272}\n",
      "  187 | 0.000026 | 071280/160596 | 1.8481 | 1.7709 |\n",
      "val: {'recall': 0.993863, 'recall_grapheme': 0.991354, 'recall_vowel': 0.996123, 'recall_consonant': 0.996621, 'acc_grapheme': 0.991527, 'acc_vowel': 0.997167, 'acc_consonant': 0.996844, 'loss_grapheme': 0.263268, 'loss_vowel': 0.150148, 'loss_consonant': 0.095038}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  188 | 0.000038 | 054720/160596 | 2.4831 | 1.8379 |\n",
      "val: {'recall': 0.99382, 'recall_grapheme': 0.991322, 'recall_vowel': 0.995696, 'recall_consonant': 0.996938, 'acc_grapheme': 0.991229, 'acc_vowel': 0.996422, 'acc_consonant': 0.996571, 'loss_grapheme': 0.185547, 'loss_vowel': 0.134004, 'loss_consonant': 0.088937}\n",
      "  189 | 0.000051 | 038160/160596 | 1.6782 | 1.6708 |\n",
      "val: {'recall': 0.994778, 'recall_grapheme': 0.993, 'recall_vowel': 0.996225, 'recall_consonant': 0.996887, 'acc_grapheme': 0.992322, 'acc_vowel': 0.997267, 'acc_consonant': 0.997043, 'loss_grapheme': 0.196368, 'loss_vowel': 0.10847, 'loss_consonant': 0.071526}\n",
      "  190 | 0.000063 | 021600/160596 | 2.3653 | 1.6604 |\n",
      "val: {'recall': 0.992898, 'recall_grapheme': 0.990522, 'recall_vowel': 0.99579, 'recall_consonant': 0.99476, 'acc_grapheme': 0.989688, 'acc_vowel': 0.996944, 'acc_consonant': 0.996099, 'loss_grapheme': 0.243178, 'loss_vowel': 0.129244, 'loss_consonant': 0.087587}\n",
      "  191 | 0.000075 | 005040/160596 | 0.5627 | 1.7813 |\n",
      "val: {'recall': 0.993679, 'recall_grapheme': 0.990971, 'recall_vowel': 0.996432, 'recall_consonant': 0.996341, 'acc_grapheme': 0.991005, 'acc_vowel': 0.997093, 'acc_consonant': 0.996397, 'loss_grapheme': 0.26042, 'loss_vowel': 0.130823, 'loss_consonant': 0.088484}\n",
      "  191 | 0.000086 | 149040/160596 | 1.7002 | 1.7090 |\n",
      "val: {'recall': 0.993352, 'recall_grapheme': 0.99032, 'recall_vowel': 0.996015, 'recall_consonant': 0.996753, 'acc_grapheme': 0.991179, 'acc_vowel': 0.996645, 'acc_consonant': 0.996521, 'loss_grapheme': 0.154121, 'loss_vowel': 0.073619, 'loss_consonant': 0.061356}\n",
      "  192 | 0.000093 | 132480/160596 | 1.7593 | 1.7950 |\n",
      "val: {'recall': 0.993403, 'recall_grapheme': 0.990823, 'recall_vowel': 0.996168, 'recall_consonant': 0.995798, 'acc_grapheme': 0.991154, 'acc_vowel': 0.99672, 'acc_consonant': 0.996546, 'loss_grapheme': 0.242512, 'loss_vowel': 0.108423, 'loss_consonant': 0.080411}\n",
      "  193 | 0.000098 | 115920/160596 | 1.7852 | 1.7357 |\n",
      "val: {'recall': 0.992198, 'recall_grapheme': 0.988493, 'recall_vowel': 0.995944, 'recall_consonant': 0.995863, 'acc_grapheme': 0.989986, 'acc_vowel': 0.996496, 'acc_consonant': 0.995925, 'loss_grapheme': 0.235263, 'loss_vowel': 0.131022, 'loss_consonant': 0.093431}\n",
      "  194 | 0.000100 | 099360/160596 | 1.4628 | 1.8181 |\n",
      "val: {'recall': 0.99434, 'recall_grapheme': 0.99243, 'recall_vowel': 0.996268, 'recall_consonant': 0.996233, 'acc_grapheme': 0.99185, 'acc_vowel': 0.996819, 'acc_consonant': 0.997068, 'loss_grapheme': 0.220417, 'loss_vowel': 0.140849, 'loss_consonant': 0.088903}\n",
      "  195 | 0.000098 | 082800/160596 | 1.8291 | 1.6771 |\n",
      "val: {'recall': 0.992616, 'recall_grapheme': 0.989559, 'recall_vowel': 0.995987, 'recall_consonant': 0.995358, 'acc_grapheme': 0.989936, 'acc_vowel': 0.99677, 'acc_consonant': 0.996198, 'loss_grapheme': 0.244855, 'loss_vowel': 0.12437, 'loss_consonant': 0.085339}\n",
      "  196 | 0.000093 | 066240/160596 | 1.9948 | 1.7083 |\n",
      "val: {'recall': 0.992814, 'recall_grapheme': 0.990582, 'recall_vowel': 0.995839, 'recall_consonant': 0.994252, 'acc_grapheme': 0.991328, 'acc_vowel': 0.996869, 'acc_consonant': 0.996496, 'loss_grapheme': 0.203605, 'loss_vowel': 0.10243, 'loss_consonant': 0.068655}\n",
      "  197 | 0.000086 | 049680/160596 | 2.2643 | 1.7039 |\n",
      "val: {'recall': 0.992801, 'recall_grapheme': 0.989273, 'recall_vowel': 0.99671, 'recall_consonant': 0.995947, 'acc_grapheme': 0.990259, 'acc_vowel': 0.997043, 'acc_consonant': 0.996472, 'loss_grapheme': 0.193338, 'loss_vowel': 0.113995, 'loss_consonant': 0.072584}\n",
      "  198 | 0.000075 | 033120/160596 | 2.4240 | 1.6222 |\n",
      "val: {'recall': 0.994283, 'recall_grapheme': 0.991796, 'recall_vowel': 0.996549, 'recall_consonant': 0.99699, 'acc_grapheme': 0.991402, 'acc_vowel': 0.997043, 'acc_consonant': 0.996993, 'loss_grapheme': 0.217067, 'loss_vowel': 0.13192, 'loss_consonant': 0.0822}\n",
      "  199 | 0.000063 | 016560/160596 | 1.5568 | 1.7900 |\n",
      "val: {'recall': 0.993595, 'recall_grapheme': 0.990731, 'recall_vowel': 0.996521, 'recall_consonant': 0.996396, 'acc_grapheme': 0.990657, 'acc_vowel': 0.996894, 'acc_consonant': 0.996869, 'loss_grapheme': 0.220792, 'loss_vowel': 0.119296, 'loss_consonant': 0.079046}\n",
      "  199 | 0.000051 | 160560/160596 | 0.2784 | 1.7290 |\n",
      "val: {'recall': 0.994151, 'recall_grapheme': 0.991683, 'recall_vowel': 0.996299, 'recall_consonant': 0.996938, 'acc_grapheme': 0.991229, 'acc_vowel': 0.996993, 'acc_consonant': 0.996919, 'loss_grapheme': 0.208631, 'loss_vowel': 0.113305, 'loss_consonant': 0.065942}\n",
      "  200 | 0.000038 | 144000/160596 | 1.6640 | 1.8016 |\n",
      "val: {'recall': 0.994236, 'recall_grapheme': 0.991929, 'recall_vowel': 0.996663, 'recall_consonant': 0.996424, 'acc_grapheme': 0.991676, 'acc_vowel': 0.997192, 'acc_consonant': 0.996993, 'loss_grapheme': 0.242386, 'loss_vowel': 0.13431, 'loss_consonant': 0.089192}\n",
      "  201 | 0.000026 | 127440/160596 | 1.4664 | 1.6185 |\n",
      "val: {'recall': 0.994314, 'recall_grapheme': 0.992043, 'recall_vowel': 0.996708, 'recall_consonant': 0.996463, 'acc_grapheme': 0.992396, 'acc_vowel': 0.997242, 'acc_consonant': 0.997118, 'loss_grapheme': 0.196795, 'loss_vowel': 0.10343, 'loss_consonant': 0.071585}\n",
      "  202 | 0.000015 | 110880/160596 | 0.3697 | 1.6429 |\n",
      "val: {'recall': 0.994103, 'recall_grapheme': 0.991593, 'recall_vowel': 0.996667, 'recall_consonant': 0.996561, 'acc_grapheme': 0.991005, 'acc_vowel': 0.997118, 'acc_consonant': 0.997018, 'loss_grapheme': 0.184657, 'loss_vowel': 0.117946, 'loss_consonant': 0.073549}\n",
      "  203 | 0.000008 | 094320/160596 | 2.4535 | 1.6875 |\n",
      "val: {'recall': 0.993611, 'recall_grapheme': 0.991069, 'recall_vowel': 0.996269, 'recall_consonant': 0.996037, 'acc_grapheme': 0.990707, 'acc_vowel': 0.996894, 'acc_consonant': 0.996546, 'loss_grapheme': 0.149341, 'loss_vowel': 0.100678, 'loss_consonant': 0.067867}\n",
      "  204 | 0.000003 | 077760/160596 | 0.9227 | 1.6980 |\n",
      "val: {'recall': 0.993941, 'recall_grapheme': 0.99148, 'recall_vowel': 0.996475, 'recall_consonant': 0.996328, 'acc_grapheme': 0.991104, 'acc_vowel': 0.997068, 'acc_consonant': 0.996844, 'loss_grapheme': 0.169062, 'loss_vowel': 0.103249, 'loss_consonant': 0.071408}\n",
      "  205 | 0.000001 | 061200/160596 | 1.7634 | 1.6994 |\n",
      "val: {'recall': 0.994947, 'recall_grapheme': 0.992815, 'recall_vowel': 0.996985, 'recall_consonant': 0.997172, 'acc_grapheme': 0.992695, 'acc_vowel': 0.997515, 'acc_consonant': 0.997267, 'loss_grapheme': 0.194854, 'loss_vowel': 0.106975, 'loss_consonant': 0.065943}\n",
      "  206 | 0.000003 | 044640/160596 | 1.4662 | 1.7179 |\n",
      "val: {'recall': 0.994473, 'recall_grapheme': 0.99227, 'recall_vowel': 0.99657, 'recall_consonant': 0.996782, 'acc_grapheme': 0.992396, 'acc_vowel': 0.997192, 'acc_consonant': 0.996968, 'loss_grapheme': 0.210709, 'loss_vowel': 0.115252, 'loss_consonant': 0.075087}\n",
      "  207 | 0.000008 | 028080/160596 | 1.6354 | 1.6454 |\n",
      "val: {'recall': 0.994252, 'recall_grapheme': 0.992265, 'recall_vowel': 0.996371, 'recall_consonant': 0.996108, 'acc_grapheme': 0.991452, 'acc_vowel': 0.997068, 'acc_consonant': 0.996645, 'loss_grapheme': 0.205502, 'loss_vowel': 0.117488, 'loss_consonant': 0.076356}\n",
      "  208 | 0.000015 | 011520/160596 | 0.7608 | 1.6480 |\n",
      "val: {'recall': 0.995076, 'recall_grapheme': 0.99314, 'recall_vowel': 0.99686, 'recall_consonant': 0.997166, 'acc_grapheme': 0.99267, 'acc_vowel': 0.997391, 'acc_consonant': 0.997341, 'loss_grapheme': 0.182113, 'loss_vowel': 0.097773, 'loss_consonant': 0.059578}\n",
      "** saved\n",
      "  208 | 0.000026 | 155520/160596 | 1.9475 | 1.6637 |\n",
      "val: {'recall': 0.994651, 'recall_grapheme': 0.992851, 'recall_vowel': 0.996797, 'recall_consonant': 0.996106, 'acc_grapheme': 0.992222, 'acc_vowel': 0.997043, 'acc_consonant': 0.99677, 'loss_grapheme': 0.225541, 'loss_vowel': 0.120002, 'loss_consonant': 0.080232}\n",
      "  209 | 0.000038 | 138960/160596 | 1.6226 | 1.7168 |\n",
      "val: {'recall': 0.994937, 'recall_grapheme': 0.993023, 'recall_vowel': 0.996843, 'recall_consonant': 0.996858, 'acc_grapheme': 0.992918, 'acc_vowel': 0.997465, 'acc_consonant': 0.997018, 'loss_grapheme': 0.20933, 'loss_vowel': 0.109813, 'loss_consonant': 0.070805}\n",
      "  210 | 0.000051 | 122400/160596 | 3.1586 | 1.7215 |\n",
      "val: {'recall': 0.994302, 'recall_grapheme': 0.991758, 'recall_vowel': 0.996629, 'recall_consonant': 0.99706, 'acc_grapheme': 0.991601, 'acc_vowel': 0.997217, 'acc_consonant': 0.997217, 'loss_grapheme': 0.184725, 'loss_vowel': 0.094294, 'loss_consonant': 0.067528}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  211 | 0.000063 | 105840/160596 | 3.5722 | 1.6140 |\n",
      "val: {'recall': 0.994234, 'recall_grapheme': 0.991927, 'recall_vowel': 0.996679, 'recall_consonant': 0.996401, 'acc_grapheme': 0.991055, 'acc_vowel': 0.997192, 'acc_consonant': 0.996795, 'loss_grapheme': 0.229229, 'loss_vowel': 0.119446, 'loss_consonant': 0.076131}\n",
      "  212 | 0.000075 | 089280/160596 | 2.5102 | 1.6650 |\n",
      "val: {'recall': 0.994533, 'recall_grapheme': 0.99203, 'recall_vowel': 0.996714, 'recall_consonant': 0.997355, 'acc_grapheme': 0.991899, 'acc_vowel': 0.997515, 'acc_consonant': 0.997391, 'loss_grapheme': 0.254168, 'loss_vowel': 0.130995, 'loss_consonant': 0.084437}\n",
      "  213 | 0.000086 | 072720/160596 | 1.6722 | 1.7846 |\n",
      "val: {'recall': 0.992733, 'recall_grapheme': 0.989459, 'recall_vowel': 0.995626, 'recall_consonant': 0.996387, 'acc_grapheme': 0.989116, 'acc_vowel': 0.996148, 'acc_consonant': 0.99595, 'loss_grapheme': 0.168562, 'loss_vowel': 0.100059, 'loss_consonant': 0.07559}\n",
      "  214 | 0.000093 | 056160/160596 | 1.7666 | 1.7132 |\n",
      "val: {'recall': 0.993215, 'recall_grapheme': 0.990293, 'recall_vowel': 0.995565, 'recall_consonant': 0.99671, 'acc_grapheme': 0.990359, 'acc_vowel': 0.996347, 'acc_consonant': 0.99677, 'loss_grapheme': 0.206527, 'loss_vowel': 0.109613, 'loss_consonant': 0.068534}\n",
      "  215 | 0.000098 | 039600/160596 | 0.7677 | 1.6526 |\n",
      "val: {'recall': 0.992868, 'recall_grapheme': 0.989936, 'recall_vowel': 0.995416, 'recall_consonant': 0.996181, 'acc_grapheme': 0.991079, 'acc_vowel': 0.996322, 'acc_consonant': 0.996745, 'loss_grapheme': 0.195519, 'loss_vowel': 0.094762, 'loss_consonant': 0.067922}\n",
      "  216 | 0.000100 | 023040/160596 | 1.7848 | 1.7157 |\n",
      "val: {'recall': 0.994011, 'recall_grapheme': 0.991698, 'recall_vowel': 0.995805, 'recall_consonant': 0.996843, 'acc_grapheme': 0.991079, 'acc_vowel': 0.996596, 'acc_consonant': 0.996571, 'loss_grapheme': 0.271968, 'loss_vowel': 0.117884, 'loss_consonant': 0.090879}\n",
      "  217 | 0.000098 | 006480/160596 | 0.8091 | 1.8550 |\n",
      "val: {'recall': 0.994096, 'recall_grapheme': 0.991976, 'recall_vowel': 0.995995, 'recall_consonant': 0.996438, 'acc_grapheme': 0.991402, 'acc_vowel': 0.996819, 'acc_consonant': 0.996919, 'loss_grapheme': 0.231683, 'loss_vowel': 0.123252, 'loss_consonant': 0.075941}\n",
      "  217 | 0.000093 | 150480/160596 | 2.1789 | 1.6788 |\n",
      "val: {'recall': 0.993711, 'recall_grapheme': 0.990856, 'recall_vowel': 0.996625, 'recall_consonant': 0.996505, 'acc_grapheme': 0.991278, 'acc_vowel': 0.997341, 'acc_consonant': 0.996546, 'loss_grapheme': 0.175552, 'loss_vowel': 0.09774, 'loss_consonant': 0.059961}\n",
      "  218 | 0.000086 | 133920/160596 | 1.6372 | 1.7289 |\n",
      "val: {'recall': 0.992977, 'recall_grapheme': 0.990029, 'recall_vowel': 0.996056, 'recall_consonant': 0.995794, 'acc_grapheme': 0.99021, 'acc_vowel': 0.996571, 'acc_consonant': 0.996173, 'loss_grapheme': 0.217929, 'loss_vowel': 0.135578, 'loss_consonant': 0.081555}\n",
      "  219 | 0.000075 | 117360/160596 | 1.0105 | 1.7797 |\n",
      "val: {'recall': 0.992716, 'recall_grapheme': 0.989801, 'recall_vowel': 0.995296, 'recall_consonant': 0.995965, 'acc_grapheme': 0.990036, 'acc_vowel': 0.996273, 'acc_consonant': 0.9959, 'loss_grapheme': 0.179202, 'loss_vowel': 0.126233, 'loss_consonant': 0.084259}\n",
      "  220 | 0.000063 | 100800/160596 | 1.4158 | 1.7252 |\n",
      "val: {'recall': 0.99353, 'recall_grapheme': 0.990669, 'recall_vowel': 0.996622, 'recall_consonant': 0.996158, 'acc_grapheme': 0.991974, 'acc_vowel': 0.996919, 'acc_consonant': 0.997068, 'loss_grapheme': 0.161177, 'loss_vowel': 0.083439, 'loss_consonant': 0.058311}\n",
      "  221 | 0.000051 | 084240/160596 | 1.5500 | 1.6785 |\n",
      "val: {'recall': 0.994786, 'recall_grapheme': 0.992832, 'recall_vowel': 0.996925, 'recall_consonant': 0.996555, 'acc_grapheme': 0.992471, 'acc_vowel': 0.997242, 'acc_consonant': 0.996819, 'loss_grapheme': 0.172197, 'loss_vowel': 0.087076, 'loss_consonant': 0.055265}\n",
      "  222 | 0.000038 | 067680/160596 | 1.2442 | 1.4981 |\n",
      "val: {'recall': 0.995039, 'recall_grapheme': 0.993149, 'recall_vowel': 0.99677, 'recall_consonant': 0.99709, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997292, 'acc_consonant': 0.997391, 'loss_grapheme': 0.163878, 'loss_vowel': 0.086671, 'loss_consonant': 0.058145}\n",
      "  223 | 0.000026 | 051120/160596 | 1.6935 | 1.5438 |\n",
      "val: {'recall': 0.99467, 'recall_grapheme': 0.992518, 'recall_vowel': 0.996717, 'recall_consonant': 0.996926, 'acc_grapheme': 0.992049, 'acc_vowel': 0.997118, 'acc_consonant': 0.997167, 'loss_grapheme': 0.187881, 'loss_vowel': 0.100063, 'loss_consonant': 0.064927}\n",
      "  224 | 0.000015 | 034560/160596 | 1.6270 | 1.5734 |\n",
      "val: {'recall': 0.994859, 'recall_grapheme': 0.992825, 'recall_vowel': 0.996691, 'recall_consonant': 0.997093, 'acc_grapheme': 0.993117, 'acc_vowel': 0.997316, 'acc_consonant': 0.99759, 'loss_grapheme': 0.160094, 'loss_vowel': 0.090257, 'loss_consonant': 0.059001}\n",
      "  225 | 0.000008 | 018000/160596 | 2.4532 | 1.4168 |\n",
      "val: {'recall': 0.995219, 'recall_grapheme': 0.993332, 'recall_vowel': 0.997166, 'recall_consonant': 0.997046, 'acc_grapheme': 0.993664, 'acc_vowel': 0.99754, 'acc_consonant': 0.997441, 'loss_grapheme': 0.156942, 'loss_vowel': 0.080665, 'loss_consonant': 0.049176}\n",
      "** saved\n",
      "  226 | 0.000003 | 001440/160596 | 1.9797 | 2.1300 |\n",
      "val: {'recall': 0.994874, 'recall_grapheme': 0.993063, 'recall_vowel': 0.997031, 'recall_consonant': 0.996336, 'acc_grapheme': 0.992819, 'acc_vowel': 0.997267, 'acc_consonant': 0.997093, 'loss_grapheme': 0.218376, 'loss_vowel': 0.114193, 'loss_consonant': 0.075296}\n",
      "  226 | 0.000001 | 145440/160596 | 1.9581 | 1.6889 |\n",
      "val: {'recall': 0.994717, 'recall_grapheme': 0.99285, 'recall_vowel': 0.996778, 'recall_consonant': 0.996393, 'acc_grapheme': 0.992521, 'acc_vowel': 0.997242, 'acc_consonant': 0.997142, 'loss_grapheme': 0.179499, 'loss_vowel': 0.096159, 'loss_consonant': 0.062717}\n",
      "  227 | 0.000003 | 128880/160596 | 1.4488 | 1.6845 |\n",
      "val: {'recall': 0.994638, 'recall_grapheme': 0.992499, 'recall_vowel': 0.996594, 'recall_consonant': 0.996961, 'acc_grapheme': 0.992993, 'acc_vowel': 0.997341, 'acc_consonant': 0.997441, 'loss_grapheme': 0.200752, 'loss_vowel': 0.100915, 'loss_consonant': 0.06522}\n",
      "  228 | 0.000008 | 112320/160596 | 2.1992 | 1.6474 |\n",
      "val: {'recall': 0.993602, 'recall_grapheme': 0.990923, 'recall_vowel': 0.996053, 'recall_consonant': 0.996509, 'acc_grapheme': 0.990707, 'acc_vowel': 0.996819, 'acc_consonant': 0.997043, 'loss_grapheme': 0.193876, 'loss_vowel': 0.125352, 'loss_consonant': 0.084191}\n",
      "  229 | 0.000015 | 095760/160596 | 2.2957 | 1.5863 |\n",
      "val: {'recall': 0.994267, 'recall_grapheme': 0.991999, 'recall_vowel': 0.996312, 'recall_consonant': 0.996757, 'acc_grapheme': 0.992148, 'acc_vowel': 0.997118, 'acc_consonant': 0.997391, 'loss_grapheme': 0.18473, 'loss_vowel': 0.102024, 'loss_consonant': 0.068763}\n",
      "  230 | 0.000026 | 079200/160596 | 0.7498 | 1.6938 |\n",
      "val: {'recall': 0.994288, 'recall_grapheme': 0.991992, 'recall_vowel': 0.996399, 'recall_consonant': 0.996771, 'acc_grapheme': 0.992446, 'acc_vowel': 0.997142, 'acc_consonant': 0.997142, 'loss_grapheme': 0.175789, 'loss_vowel': 0.098054, 'loss_consonant': 0.068757}\n",
      "  231 | 0.000038 | 062640/160596 | 1.9418 | 1.7681 |\n",
      "val: {'recall': 0.993857, 'recall_grapheme': 0.991476, 'recall_vowel': 0.996158, 'recall_consonant': 0.996317, 'acc_grapheme': 0.991179, 'acc_vowel': 0.996944, 'acc_consonant': 0.996968, 'loss_grapheme': 0.204215, 'loss_vowel': 0.109028, 'loss_consonant': 0.071198}\n",
      "  232 | 0.000051 | 046080/160596 | 2.8253 | 1.7100 |\n",
      "val: {'recall': 0.993799, 'recall_grapheme': 0.991295, 'recall_vowel': 0.996636, 'recall_consonant': 0.995969, 'acc_grapheme': 0.991402, 'acc_vowel': 0.997043, 'acc_consonant': 0.996596, 'loss_grapheme': 0.198623, 'loss_vowel': 0.105999, 'loss_consonant': 0.063657}\n",
      "  233 | 0.000063 | 029520/160596 | 1.0240 | 1.7524 |\n",
      "val: {'recall': 0.993482, 'recall_grapheme': 0.991472, 'recall_vowel': 0.996087, 'recall_consonant': 0.994898, 'acc_grapheme': 0.991378, 'acc_vowel': 0.996645, 'acc_consonant': 0.996322, 'loss_grapheme': 0.150747, 'loss_vowel': 0.092732, 'loss_consonant': 0.064559}\n",
      "  234 | 0.000075 | 012960/160596 | 2.1479 | 1.5591 |\n",
      "val: {'recall': 0.993635, 'recall_grapheme': 0.990924, 'recall_vowel': 0.996219, 'recall_consonant': 0.996471, 'acc_grapheme': 0.990632, 'acc_vowel': 0.99667, 'acc_consonant': 0.996621, 'loss_grapheme': 0.208659, 'loss_vowel': 0.110139, 'loss_consonant': 0.070215}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  234 | 0.000086 | 156960/160596 | 2.3966 | 1.6234 |\n",
      "val: {'recall': 0.992841, 'recall_grapheme': 0.990413, 'recall_vowel': 0.995874, 'recall_consonant': 0.994664, 'acc_grapheme': 0.990458, 'acc_vowel': 0.996397, 'acc_consonant': 0.996347, 'loss_grapheme': 0.20179, 'loss_vowel': 0.104209, 'loss_consonant': 0.06583}\n",
      "  235 | 0.000093 | 140400/160596 | 1.1907 | 1.7767 |\n",
      "val: {'recall': 0.993624, 'recall_grapheme': 0.991629, 'recall_vowel': 0.996067, 'recall_consonant': 0.995173, 'acc_grapheme': 0.991353, 'acc_vowel': 0.996844, 'acc_consonant': 0.996944, 'loss_grapheme': 0.230878, 'loss_vowel': 0.122597, 'loss_consonant': 0.082995}\n",
      "  236 | 0.000098 | 123840/160596 | 1.5327 | 1.7184 |\n",
      "val: {'recall': 0.992581, 'recall_grapheme': 0.990146, 'recall_vowel': 0.995158, 'recall_consonant': 0.994876, 'acc_grapheme': 0.990508, 'acc_vowel': 0.996248, 'acc_consonant': 0.9959, 'loss_grapheme': 0.198729, 'loss_vowel': 0.106843, 'loss_consonant': 0.072458}\n",
      "  237 | 0.000100 | 107280/160596 | 1.0317 | 1.8040 |\n",
      "val: {'recall': 0.992721, 'recall_grapheme': 0.98954, 'recall_vowel': 0.995339, 'recall_consonant': 0.996466, 'acc_grapheme': 0.990756, 'acc_vowel': 0.996372, 'acc_consonant': 0.996099, 'loss_grapheme': 0.175116, 'loss_vowel': 0.107543, 'loss_consonant': 0.077183}\n",
      "  238 | 0.000098 | 090720/160596 | 2.1689 | 1.7476 |\n",
      "val: {'recall': 0.994416, 'recall_grapheme': 0.992604, 'recall_vowel': 0.996349, 'recall_consonant': 0.996107, 'acc_grapheme': 0.991502, 'acc_vowel': 0.996869, 'acc_consonant': 0.996819, 'loss_grapheme': 0.273127, 'loss_vowel': 0.133235, 'loss_consonant': 0.085059}\n",
      "  239 | 0.000093 | 074160/160596 | 1.6169 | 1.6516 |\n",
      "val: {'recall': 0.993695, 'recall_grapheme': 0.992573, 'recall_vowel': 0.995878, 'recall_consonant': 0.993757, 'acc_grapheme': 0.992049, 'acc_vowel': 0.996571, 'acc_consonant': 0.996571, 'loss_grapheme': 0.266127, 'loss_vowel': 0.120096, 'loss_consonant': 0.07783}\n",
      "  240 | 0.000086 | 057600/160596 | 1.7454 | 1.7871 |\n",
      "val: {'recall': 0.992916, 'recall_grapheme': 0.99036, 'recall_vowel': 0.995345, 'recall_consonant': 0.995597, 'acc_grapheme': 0.989663, 'acc_vowel': 0.996546, 'acc_consonant': 0.996049, 'loss_grapheme': 0.193528, 'loss_vowel': 0.115159, 'loss_consonant': 0.080275}\n",
      "  241 | 0.000075 | 041040/160596 | 0.9598 | 1.6275 |\n",
      "val: {'recall': 0.993825, 'recall_grapheme': 0.992177, 'recall_vowel': 0.997112, 'recall_consonant': 0.993834, 'acc_grapheme': 0.992098, 'acc_vowel': 0.997416, 'acc_consonant': 0.996919, 'loss_grapheme': 0.213736, 'loss_vowel': 0.106328, 'loss_consonant': 0.063983}\n",
      "  242 | 0.000063 | 024480/160596 | 0.9332 | 1.6336 |\n",
      "val: {'recall': 0.994059, 'recall_grapheme': 0.992315, 'recall_vowel': 0.996682, 'recall_consonant': 0.994924, 'acc_grapheme': 0.992943, 'acc_vowel': 0.997217, 'acc_consonant': 0.997366, 'loss_grapheme': 0.174944, 'loss_vowel': 0.075923, 'loss_consonant': 0.059706}\n",
      "  243 | 0.000051 | 007920/160596 | 0.9036 | 1.8423 |\n",
      "val: {'recall': 0.993629, 'recall_grapheme': 0.991884, 'recall_vowel': 0.996005, 'recall_consonant': 0.994745, 'acc_grapheme': 0.992446, 'acc_vowel': 0.996844, 'acc_consonant': 0.996944, 'loss_grapheme': 0.222615, 'loss_vowel': 0.100892, 'loss_consonant': 0.072185}\n",
      "  243 | 0.000038 | 151920/160596 | 2.2510 | 1.5574 |\n",
      "val: {'recall': 0.994051, 'recall_grapheme': 0.992199, 'recall_vowel': 0.996801, 'recall_consonant': 0.995004, 'acc_grapheme': 0.99257, 'acc_vowel': 0.997366, 'acc_consonant': 0.997192, 'loss_grapheme': 0.264113, 'loss_vowel': 0.128626, 'loss_consonant': 0.082105}\n",
      "  244 | 0.000026 | 135360/160596 | 1.6670 | 1.6474 |\n",
      "val: {'recall': 0.99392, 'recall_grapheme': 0.992236, 'recall_vowel': 0.996381, 'recall_consonant': 0.994828, 'acc_grapheme': 0.992123, 'acc_vowel': 0.997118, 'acc_consonant': 0.996993, 'loss_grapheme': 0.242748, 'loss_vowel': 0.124943, 'loss_consonant': 0.075891}\n",
      "  245 | 0.000015 | 118800/160596 | 2.0020 | 1.6379 |\n",
      "val: {'recall': 0.994284, 'recall_grapheme': 0.99289, 'recall_vowel': 0.996667, 'recall_consonant': 0.994688, 'acc_grapheme': 0.992247, 'acc_vowel': 0.997192, 'acc_consonant': 0.996968, 'loss_grapheme': 0.191609, 'loss_vowel': 0.101134, 'loss_consonant': 0.063655}\n",
      "  246 | 0.000008 | 102240/160596 | 1.6132 | 1.5877 |\n",
      "val: {'recall': 0.994336, 'recall_grapheme': 0.992902, 'recall_vowel': 0.996712, 'recall_consonant': 0.994828, 'acc_grapheme': 0.992421, 'acc_vowel': 0.997316, 'acc_consonant': 0.996968, 'loss_grapheme': 0.200514, 'loss_vowel': 0.108848, 'loss_consonant': 0.069157}\n",
      "  247 | 0.000003 | 085680/160596 | 2.1418 | 1.5418 |\n",
      "val: {'recall': 0.993955, 'recall_grapheme': 0.992094, 'recall_vowel': 0.996742, 'recall_consonant': 0.994891, 'acc_grapheme': 0.992073, 'acc_vowel': 0.997341, 'acc_consonant': 0.996919, 'loss_grapheme': 0.166775, 'loss_vowel': 0.093432, 'loss_consonant': 0.061777}\n",
      "  248 | 0.000001 | 069120/160596 | 1.6875 | 1.6824 |\n",
      "val: {'recall': 0.993006, 'recall_grapheme': 0.990932, 'recall_vowel': 0.995983, 'recall_consonant': 0.994176, 'acc_grapheme': 0.992272, 'acc_vowel': 0.997018, 'acc_consonant': 0.997167, 'loss_grapheme': 0.126462, 'loss_vowel': 0.065517, 'loss_consonant': 0.048194}\n",
      "  249 | 0.000003 | 052560/160596 | 2.3923 | 1.7334 |\n",
      "val: {'recall': 0.993123, 'recall_grapheme': 0.991031, 'recall_vowel': 0.995869, 'recall_consonant': 0.994561, 'acc_grapheme': 0.990632, 'acc_vowel': 0.99672, 'acc_consonant': 0.996372, 'loss_grapheme': 0.170439, 'loss_vowel': 0.115263, 'loss_consonant': 0.077201}\n",
      "  250 | 0.000008 | 036000/160596 | 1.6820 | 1.6301 |\n",
      "val: {'recall': 0.993507, 'recall_grapheme': 0.991141, 'recall_vowel': 0.996118, 'recall_consonant': 0.995629, 'acc_grapheme': 0.992297, 'acc_vowel': 0.996993, 'acc_consonant': 0.997142, 'loss_grapheme': 0.144653, 'loss_vowel': 0.076694, 'loss_consonant': 0.052171}\n",
      "  251 | 0.000015 | 019440/160596 | 1.4845 | 1.3304 |\n",
      "val: {'recall': 0.994326, 'recall_grapheme': 0.992711, 'recall_vowel': 0.99642, 'recall_consonant': 0.995462, 'acc_grapheme': 0.993341, 'acc_vowel': 0.997292, 'acc_consonant': 0.997416, 'loss_grapheme': 0.169645, 'loss_vowel': 0.079304, 'loss_consonant': 0.052625}\n",
      "  252 | 0.000026 | 002880/160596 | 1.7186 | 1.5198 |\n",
      "val: {'recall': 0.994494, 'recall_grapheme': 0.992973, 'recall_vowel': 0.99679, 'recall_consonant': 0.995242, 'acc_grapheme': 0.992993, 'acc_vowel': 0.997341, 'acc_consonant': 0.997341, 'loss_grapheme': 0.250385, 'loss_vowel': 0.121891, 'loss_consonant': 0.07657}\n",
      "  252 | 0.000038 | 146880/160596 | 1.2727 | 1.7281 |\n",
      "val: {'recall': 0.993632, 'recall_grapheme': 0.991555, 'recall_vowel': 0.996485, 'recall_consonant': 0.994935, 'acc_grapheme': 0.991402, 'acc_vowel': 0.997118, 'acc_consonant': 0.996944, 'loss_grapheme': 0.220093, 'loss_vowel': 0.111401, 'loss_consonant': 0.073985}\n",
      "  253 | 0.000050 | 130320/160596 | 2.0630 | 1.6230 |\n",
      "val: {'recall': 0.992595, 'recall_grapheme': 0.989272, 'recall_vowel': 0.995894, 'recall_consonant': 0.995943, 'acc_grapheme': 0.989837, 'acc_vowel': 0.996819, 'acc_consonant': 0.996248, 'loss_grapheme': 0.189389, 'loss_vowel': 0.113205, 'loss_consonant': 0.074159}\n",
      "  254 | 0.000063 | 113760/160596 | 0.9069 | 1.7001 |\n",
      "val: {'recall': 0.992562, 'recall_grapheme': 0.989397, 'recall_vowel': 0.995719, 'recall_consonant': 0.995735, 'acc_grapheme': 0.989067, 'acc_vowel': 0.996546, 'acc_consonant': 0.996074, 'loss_grapheme': 0.157104, 'loss_vowel': 0.09546, 'loss_consonant': 0.067075}\n",
      "  255 | 0.000075 | 097200/160596 | 1.9775 | 1.6400 |\n",
      "val: {'recall': 0.993796, 'recall_grapheme': 0.992624, 'recall_vowel': 0.99597, 'recall_consonant': 0.993964, 'acc_grapheme': 0.991875, 'acc_vowel': 0.996944, 'acc_consonant': 0.996546, 'loss_grapheme': 0.260978, 'loss_vowel': 0.125582, 'loss_consonant': 0.072296}\n",
      "  256 | 0.000086 | 080640/160596 | 2.2863 | 1.6885 |\n",
      "val: {'recall': 0.993917, 'recall_grapheme': 0.991642, 'recall_vowel': 0.996271, 'recall_consonant': 0.996113, 'acc_grapheme': 0.991005, 'acc_vowel': 0.996944, 'acc_consonant': 0.996546, 'loss_grapheme': 0.243745, 'loss_vowel': 0.128722, 'loss_consonant': 0.08256}\n",
      "  257 | 0.000093 | 064080/160596 | 2.2235 | 1.6873 |\n",
      "val: {'recall': 0.99195, 'recall_grapheme': 0.989217, 'recall_vowel': 0.994551, 'recall_consonant': 0.994816, 'acc_grapheme': 0.988222, 'acc_vowel': 0.995925, 'acc_consonant': 0.995527, 'loss_grapheme': 0.169852, 'loss_vowel': 0.102591, 'loss_consonant': 0.069708}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  258 | 0.000098 | 047520/160596 | 0.9052 | 1.7931 |\n",
      "val: {'recall': 0.994441, 'recall_grapheme': 0.992623, 'recall_vowel': 0.996707, 'recall_consonant': 0.995808, 'acc_grapheme': 0.9918, 'acc_vowel': 0.997242, 'acc_consonant': 0.996596, 'loss_grapheme': 0.195736, 'loss_vowel': 0.104524, 'loss_consonant': 0.070656}\n",
      "  259 | 0.000100 | 030960/160596 | 2.3566 | 1.6954 |\n",
      "val: {'recall': 0.992888, 'recall_grapheme': 0.989383, 'recall_vowel': 0.996531, 'recall_consonant': 0.996253, 'acc_grapheme': 0.990235, 'acc_vowel': 0.996819, 'acc_consonant': 0.996198, 'loss_grapheme': 0.223854, 'loss_vowel': 0.133408, 'loss_consonant': 0.082446}\n",
      "  260 | 0.000098 | 014400/160596 | 2.7934 | 1.6074 |\n",
      "val: {'recall': 0.994105, 'recall_grapheme': 0.992519, 'recall_vowel': 0.995995, 'recall_consonant': 0.995389, 'acc_grapheme': 0.991601, 'acc_vowel': 0.99672, 'acc_consonant': 0.997018, 'loss_grapheme': 0.272782, 'loss_vowel': 0.120502, 'loss_consonant': 0.082534}\n",
      "  260 | 0.000093 | 158400/160596 | 0.5477 | 1.5751 |\n",
      "val: {'recall': 0.993608, 'recall_grapheme': 0.992149, 'recall_vowel': 0.996202, 'recall_consonant': 0.993931, 'acc_grapheme': 0.991999, 'acc_vowel': 0.996919, 'acc_consonant': 0.996645, 'loss_grapheme': 0.147173, 'loss_vowel': 0.06894, 'loss_consonant': 0.051177}\n",
      "  261 | 0.000086 | 141840/160596 | 1.5464 | 1.7598 |\n",
      "val: {'recall': 0.99328, 'recall_grapheme': 0.991003, 'recall_vowel': 0.995766, 'recall_consonant': 0.995347, 'acc_grapheme': 0.99098, 'acc_vowel': 0.996372, 'acc_consonant': 0.996472, 'loss_grapheme': 0.210648, 'loss_vowel': 0.116365, 'loss_consonant': 0.075396}\n",
      "  262 | 0.000075 | 125280/160596 | 1.3204 | 1.7262 |\n",
      "val: {'recall': 0.99464, 'recall_grapheme': 0.993058, 'recall_vowel': 0.996794, 'recall_consonant': 0.995651, 'acc_grapheme': 0.992446, 'acc_vowel': 0.997167, 'acc_consonant': 0.997142, 'loss_grapheme': 0.206357, 'loss_vowel': 0.097197, 'loss_consonant': 0.066387}\n",
      "  263 | 0.000063 | 108720/160596 | 3.4685 | 1.6299 |\n",
      "val: {'recall': 0.9937, 'recall_grapheme': 0.991928, 'recall_vowel': 0.995589, 'recall_consonant': 0.995353, 'acc_grapheme': 0.991253, 'acc_vowel': 0.996844, 'acc_consonant': 0.996869, 'loss_grapheme': 0.200668, 'loss_vowel': 0.113977, 'loss_consonant': 0.06963}\n",
      "  263 | 0.000050 | 119520/160596 | 0.2985 | 1.6227 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-813ae6dcb078>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_no_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpost_backward_models_are_masters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_models_are_masters\u001b[0;34m(scaler, params, stashed_grads, scale_override)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mstashed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mgrads_needing_unscale_with_stash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Clear the stash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[1;32m    182\u001b[0m                                              \u001b[0mmaster_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                              \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                                              out_scale/stashed_have_scale)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Defer to update_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed_python\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, a, b)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                                                  \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                                                                  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                                                                  self.dynamic)\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/chicm/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36maxpby_check_overflow_python\u001b[0;34m(model_grad, stashed_grad, master_grad, a, b, check_overflow)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Exception handling for 18.04 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcpu_sum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
