{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cvcore.data.auto_augment import RandAugment\n",
    "from PIL import Image\n",
    "from utils import bn_update, moving_average, copy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations as albu\n",
    "def get_train_augs():\n",
    "    return RandAugment(n=2, m=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        orig_img = img.copy()\n",
    "        #print(img.shape)\n",
    "        if self.train_mode:\n",
    "            augs = get_train_augs()\n",
    "            #img = augs(image=img)['image']\n",
    "            img = np.asarray(augs(Image.fromarray(img)))\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        orig_img = np.expand_dims(orig_img, axis=-1)\n",
    "        \n",
    "        #print('###', img.shape)\n",
    "        #img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        #MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        #STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        orig_img = transforms.functional.to_tensor(orig_img)\n",
    "        \n",
    "        #img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        elif self.train_mode:\n",
    "            return img, orig_img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic, row.word_label])\n",
    "                    \n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "\n",
    "    grapheme_words = np.unique(train_df.grapheme.values)\n",
    "    grapheme_words_dict = {grapheme: i for i, grapheme in enumerate(grapheme_words)}\n",
    "    train_df['word_label'] = train_df['grapheme'].map(lambda x: grapheme_words_dict[x])\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in train_loader:\n",
    "#    print(x)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import timm\n",
    "from timm.models.activations import Swish, Mish\n",
    "from timm.models.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "\n",
    "MEAN = [ 0.06922848809290576 ]\n",
    "STD = [ 0.20515700083327537 ]\n",
    "\n",
    "class BengaliNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNet B0-B8.\n",
    "    Args:\n",
    "        cfg (CfgNode): configs\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        model_name = cfg.MODEL_NAME\n",
    "        pretrained = cfg.PRETRAINED\n",
    "        input_channels = cfg.IN_CHANNELS\n",
    "        pool_type = cfg.POOL_TYPE\n",
    "        drop_connect_rate = cfg.DROP_CONNECT\n",
    "        self.drop_rate = cfg.DROPOUT\n",
    "        cls_head = cfg.CLS_HEAD\n",
    "        num_total_classes = cfg.NUM_GRAPHEME_CLASSES + cfg.NUM_VOWEL_CLASSES + cfg.NUM_CONSONANT_CLASSES \\\n",
    "            + cfg.NUM_WORD_CLASSES\n",
    "\n",
    "        backbone = timm.create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=input_channels,\n",
    "            drop_connect_rate=drop_connect_rate,\n",
    "        )\n",
    "        self.conv_stem = backbone.conv_stem\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.act1 = backbone.act1\n",
    "        ### Original blocks ###\n",
    "        for i in range(len((backbone.blocks))):\n",
    "            setattr(self, \"block{}\".format(str(i)), backbone.blocks[i])\n",
    "        self.conv_head = backbone.conv_head\n",
    "        self.bn2 = backbone.bn2\n",
    "        self.act2 = backbone.act2\n",
    "        self.aux_block5 = backbone.blocks[5]\n",
    "        self.aux_num_features = self.block5[-1].bn3.num_features\n",
    "        self.aux_head4 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act4 = Swish()\n",
    "        self.aux_head5 = nn.Conv2d(self.aux_num_features, self.aux_num_features * 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(self.aux_num_features * 4)\n",
    "        self.act5 = Swish()\n",
    "        self.global_pool = SelectAdaptivePool2d(pool_type=pool_type)\n",
    "        self.num_features = backbone.num_features * self.global_pool.feat_mult()\n",
    "        assert cls_head == 'linear'\n",
    "        if cls_head == \"linear\":\n",
    "            ### Baseline head ###\n",
    "            self.fc = nn.Linear(self.num_features, num_total_classes)            \n",
    "            self.aux_fc1 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            self.aux_fc2 = nn.Linear(self.aux_num_features*4, num_total_classes)\n",
    "            \n",
    "            for fc in [self.fc, self.aux_fc1, self.aux_fc2]:\n",
    "                nn.init.zeros_(fc.bias.data)\n",
    "        elif cls_head == \"norm_softmax\":\n",
    "            ### NormSoftmax ###\n",
    "            self.grapheme_fc = NormSoftmax(self.num_features, num_grapheme_classes)\n",
    "            self.consonant_fc = NormSoftmax(self.num_features, num_consonant_classes)\n",
    "            self.vowel_fc = NormSoftmax(self.num_features, num_vowel_classes)\n",
    "        # Replace with Mish activation\n",
    "        if cfg.MODEL_ACTIVATION == \"mish\":\n",
    "            convert_swish_to_mish(self)\n",
    "        del backbone\n",
    "\n",
    "    def _features(self, x):\n",
    "        x = self.conv_stem(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x); b4 = x\n",
    "        x = self.block5(x); b4 = self.aux_block5(b4); b5 = x\n",
    "        x = self.block6(x)\n",
    "        x = self.conv_head(x); b4 = self.aux_head4(b4); b5 = self.aux_head5(b5)\n",
    "        x = self.bn2(x); b4 = self.bn4(b4); b5 = self.bn5(b5)\n",
    "        x = self.act2(x); b4 = self.act4(b4); b5 = self.act5(b5)\n",
    "        return b4, b5, x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(380, 380), mode='bilinear', align_corners=False)\n",
    "        for i in range(len(x)):\n",
    "            transforms.functional.normalize(x[i], mean=MEAN, std=STD, inplace=True)\n",
    "\n",
    "        # _, _, x = self._features(x)\n",
    "        b4, b5, x = self._features(x)\n",
    "        x = self.global_pool(x); b4 = self.global_pool(b4); b5 = self.global_pool(b5)\n",
    "        x = torch.flatten(x, 1); b4 = torch.flatten(b4, 1); b5 = torch.flatten(b5, 1)\n",
    "        if self.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.drop_rate, training=self.training)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        aux_logits1 = self.aux_fc1(b4)\n",
    "        aux_logits2 = self.aux_fc2(b5)\n",
    "        \n",
    "        return logits, aux_logits1, aux_logits2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model4-ckps'\n",
    "def create_model(cfg):\n",
    "    model = BengaliNet(cfg)\n",
    "    model_file = os.path.join(MODEL_DIR, cfg.MODEL_NAME, cfg.CKP_NAME)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, preds3, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2) == len(preds3)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    recall_word = sklearn.metrics.recall_score(preds3, y[:, 3], average='macro')\n",
    "    \n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    metrics['recall_word'] = round(recall_word, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    metrics['acc_word'] = round((preds3 == y[:, 3]).sum() / len(y), 6)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    loss3 = F.cross_entropy(outputs[3], y_true[:, 3], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 + loss3 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2, loss3 = 0., 0., 0., 0.\n",
    "    preds0, preds1, preds2, preds3 = [], [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs, _, _ = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7, 1295], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            preds3.append(torch.max(outputs[3], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            loss3 += F.cross_entropy(outputs[3], y[:, 3], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    preds3 = torch.cat(preds3, 0).cpu().numpy()\n",
    "    \n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, preds3, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    metrics['loss_word'] = round(loss3 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox_new(size, lam):\n",
    "    H = size[2]\n",
    "    W = size[3]\n",
    "\n",
    "    x_margin_rate = 0.2\n",
    "\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * (1-x_margin_rate*2) * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "    \n",
    "    min_x_center = np.int(W * x_margin_rate + cut_w / 2)\n",
    "    max_x_center = np.int(W * (1-x_margin_rate) - cut_w / 2)\n",
    "    #print(min_x_center, max_x_center, lam, cut_w)\n",
    "    min_y_center = cut_h // 2\n",
    "    max_y_center = H - cut_h // 2\n",
    "    if max_y_center == min_y_center:\n",
    "        max_y_center += 1\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(min_x_center, max_x_center)\n",
    "    cy = np.random.randint(min_y_center, max_y_center)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    \n",
    "    #print(bbx1, bbx2, bby1, bby2)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13892441877098294"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam\n",
    "from gridmask import GridMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvcore.solver import WarmupCyclicalLR\n",
    "def make_optimizer(model, base_lr=4e-4, weight_decay=0., weight_decay_bias=0., epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Create optimizer with per-layer learning rate and weight decay.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr\n",
    "        params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay_bias if 'bias' in key else weight_decay}]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(params, lr, eps=epsilon)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid):\n",
    "    train_loss = 0\n",
    "    bg = time.time()\n",
    "\n",
    "    for batch_idx, (img, orig_img, targets) in enumerate(train_loader):\n",
    "        img, orig_img, targets  = img.cuda(), orig_img.cuda(), targets.cuda()\n",
    "        batch_size = img.size(0)\n",
    "        r = np.random.rand()\n",
    "\n",
    "        if r < 0.3:\n",
    "            # generate mixed sample\n",
    "            lam = np.random.beta(args.beta, args.beta)\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = targets\n",
    "            target_b = targets[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            #img[:, :, bby1:bby2, bbx1:bbx2] = img[rand_index, :, bby1:bby2, bbx1:bbx2] #for new cutmix\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            \n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "            # compute output\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            loss_aux1 = criterion(outputs_aux1, target_a) * lam + criterion(outputs_aux1, target_b) * (1. - lam)\n",
    "            loss_aux2 = criterion(outputs_aux2, target_a) * lam + criterion(outputs_aux2, target_b) * (1. - lam)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        elif r > 0.7:\n",
    "            img = grid(img)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(img)\n",
    "            loss_primary = criterion(outputs, targets)\n",
    "            loss_aux1 = criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "        else:\n",
    "            orig_img, targets = mixup(orig_img, targets)\n",
    "            outputs, outputs_aux1, outputs_aux2 = model(orig_img)\n",
    "            loss_primary = mixup_criterion(outputs, targets)\n",
    "            loss_aux1 = mixup_criterion(outputs_aux1, targets)\n",
    "            loss_aux2 = mixup_criterion(outputs_aux2, targets)\n",
    "            loss = loss_primary + (loss_aux1 + loss_aux2)*0.8\n",
    "            #loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        lr_scheduler(optimizer, batch_idx, epoch)\n",
    "        optimizer.step()            \n",
    "        \n",
    "        current_lr = get_lrs(optimizer)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} | {:.2f} |'.format(\n",
    "            epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "            loss.item(), train_loss/(batch_idx+1), (time.time() - bg) / 60), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "best_metrics = 0.\n",
    "best_metrics_swa = 0.\n",
    "\n",
    "\n",
    "def validate_and_save(model, model_file, val_loader, save=False):\n",
    "    global best_metrics\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics:\n",
    "        best_metrics = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "\n",
    "def validate_and_save_swa(model, model_file, val_loader, save=False):\n",
    "    global best_metrics_swa\n",
    "    best_key = 'recall'\n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print('\\nval:', val_metrics)\n",
    "    \n",
    "    if val_metrics[best_key] > best_metrics_swa:\n",
    "        best_metrics_swa = val_metrics[best_key]\n",
    "        if save:\n",
    "            save_model(model, model_file)\n",
    "            print('###>>>>> saved', model_file)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    model, model_file = create_model(cfg)\n",
    "    model = model.cuda()\n",
    "\n",
    "    swa_cfg = copy.deepcopy(cfg)\n",
    "    swa_cfg.CKP_NAME = cfg.CKP_NAME + '_swa'\n",
    "    swa_model, swa_model_file = create_model(swa_cfg)\n",
    "    swa_model = swa_model.cuda()\n",
    "\n",
    "    optimizer = make_optimizer(model)\n",
    "    lr_scheduler = WarmupCyclicalLR(\n",
    "        \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)\n",
    "    \n",
    "    [model, swa_model], optimizer = amp.initialize([model, swa_model], optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        swa_model = nn.DataParallel(swa_model)\n",
    "    \n",
    "    validate_and_save(model, model_file, val_loader, save=False)\n",
    "\n",
    "    swa_model_loaded = False\n",
    "    if os.path.exists(swa_model_file):\n",
    "        swa_model_loaded = True\n",
    "        validate_and_save_swa(swa_model, swa_model_file, val_loader, save=False)\n",
    "    \n",
    "    for cycle in range(1, args.num_cycles+1):\n",
    "        print('CYCLE:', cycle)\n",
    "        grid = GridMask(64, 128, rotate=15, ratio=0.6, mode=1, prob=1.)\n",
    "\n",
    "        for epoch in range(args.num_epochs):\n",
    "            grid.set_prob(epoch, args.st_epochs)\n",
    "            train_epoch(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\n",
    "            validate_and_save(model, model_file, val_loader, save=True)\n",
    "            \n",
    "            if (epoch+1) == args.swa_start and cycle == 1:\n",
    "                if not swa_model_loaded:\n",
    "                    copy_model(swa_model, model)\n",
    "                swa_n = 0\n",
    "            if (epoch+1) >= args.swa_start and (epoch+1) % args.swa_freq == 0:\n",
    "                print('SWA>>>:')\n",
    "                moving_average(swa_model, model, 1.0 / (swa_n + 1))\n",
    "                swa_n += 1\n",
    "                bn_update(train_loader, swa_model)\n",
    "                validate_and_save_swa(swa_model, swa_model_file, val_loader, save=True)\n",
    "\n",
    "        args.base_lr = 2e-4\n",
    "        args.num_epochs = 40\n",
    "        args.warmup_epochs = 1\n",
    "\n",
    "        # reset scheduler at each cycle\n",
    "        lr_scheduler = WarmupCyclicalLR(\n",
    "            \"cos\", args.base_lr, args.num_epochs, iters_per_epoch=len(train_loader), warmup_epochs=args.warmup_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Namespace()\n",
    "cfg.MODEL_NAME = 'tf_efficientnet_b4'\n",
    "cfg.PRETRAINED = True\n",
    "cfg.IN_CHANNELS = 1\n",
    "cfg.POOL_TYPE = 'avg'\n",
    "cfg.CLS_HEAD = 'linear'\n",
    "cfg.MODEL_ACTIVATION = 'swish'\n",
    "cfg.DROP_CONNECT = 0.2\n",
    "cfg.DROPOUT= 0.\n",
    "cfg.NUM_WORD_CLASSES = 1295\n",
    "cfg.NUM_GRAPHEME_CLASSES = 168\n",
    "cfg.NUM_VOWEL_CLASSES = 11\n",
    "cfg.NUM_CONSONANT_CLASSES = 7\n",
    "cfg.CKP_NAME = 'model4_eb4_fold2_380.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, model_file = create_model(cfg)\n",
    "#model(torch.randn(2,1,137,236))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "\n",
    "args.base_lr = 4e-4\n",
    "args.num_epochs = 40\n",
    "args.warmup_epochs = 1\n",
    "args.num_cycles = 100\n",
    "args.batch_size = 128\n",
    "args.val_batch_size = 512\n",
    "args.st_epochs = 5\n",
    "\n",
    "args.swa_start = 1000\n",
    "args.swa_freq = 2\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 6)\n",
      "(200840, 32332)\n",
      "(160678, 6) (40162, 6)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth, exist: True\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth...\n",
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.996864, 'recall_grapheme': 0.995341, 'recall_vowel': 0.998716, 'recall_consonant': 0.998059, 'recall_word': 0.995527, 'acc_grapheme': 0.995643, 'acc_vowel': 0.998456, 'acc_consonant': 0.998531, 'acc_word': 0.995543, 'loss_grapheme': 0.021051, 'loss_vowel': 0.009045, 'loss_consonant': 0.00687, 'loss_word': 0.019851}\n",
      "CYCLE: 1\n",
      "    0 | 0.000399 | 160640/160678 | 0.5148 | 5.8375 | 13.83 ||\n",
      "val: {'recall': 0.994827, 'recall_grapheme': 0.993436, 'recall_vowel': 0.997847, 'recall_consonant': 0.994591, 'recall_word': 0.99367, 'acc_grapheme': 0.993501, 'acc_vowel': 0.997834, 'acc_consonant': 0.997784, 'acc_word': 0.993576, 'loss_grapheme': 0.027582, 'loss_vowel': 0.012216, 'loss_consonant': 0.01028, 'loss_word': 0.026025}\n",
      "    1 | 0.000398 | 160640/160678 | 9.8195 | 6.5763 | 13.90 ||\n",
      "val: {'recall': 0.994648, 'recall_grapheme': 0.993459, 'recall_vowel': 0.997064, 'recall_consonant': 0.994611, 'recall_word': 0.993391, 'acc_grapheme': 0.993327, 'acc_vowel': 0.997311, 'acc_consonant': 0.997884, 'acc_word': 0.993476, 'loss_grapheme': 0.028689, 'loss_vowel': 0.012892, 'loss_consonant': 0.009593, 'loss_word': 0.027664}\n",
      "    2 | 0.000394 | 160640/160678 | 5.8221 | 6.4261 | 14.04 ||\n",
      "val: {'recall': 0.992946, 'recall_grapheme': 0.990502, 'recall_vowel': 0.99651, 'recall_consonant': 0.99427, 'recall_word': 0.992616, 'acc_grapheme': 0.991982, 'acc_vowel': 0.997361, 'acc_consonant': 0.99741, 'acc_word': 0.992456, 'loss_grapheme': 0.033417, 'loss_vowel': 0.013914, 'loss_consonant': 0.011905, 'loss_word': 0.031714}\n",
      "    3 | 0.000390 | 160640/160678 | 15.9063 | 6.4960 | 14.12 |\n",
      "val: {'recall': 0.994341, 'recall_grapheme': 0.99307, 'recall_vowel': 0.997371, 'recall_consonant': 0.993853, 'recall_word': 0.993823, 'acc_grapheme': 0.993651, 'acc_vowel': 0.99761, 'acc_consonant': 0.997485, 'acc_word': 0.993725, 'loss_grapheme': 0.025991, 'loss_vowel': 0.01203, 'loss_consonant': 0.009593, 'loss_word': 0.02456}\n",
      "    5 | 0.000378 | 160640/160678 | 14.5043 | 6.4603 | 14.39 |\n",
      "val: {'recall': 0.995245, 'recall_grapheme': 0.993289, 'recall_vowel': 0.997599, 'recall_consonant': 0.996804, 'recall_word': 0.993677, 'acc_grapheme': 0.9938, 'acc_vowel': 0.997759, 'acc_consonant': 0.998182, 'acc_word': 0.993601, 'loss_grapheme': 0.02567, 'loss_vowel': 0.012205, 'loss_consonant': 0.00843, 'loss_word': 0.024497}\n",
      "    6 | 0.000371 | 160640/160678 | 0.7125 | 6.2819 | 14.41 ||\n",
      "val: {'recall': 0.995123, 'recall_grapheme': 0.994232, 'recall_vowel': 0.997835, 'recall_consonant': 0.994192, 'recall_word': 0.9942, 'acc_grapheme': 0.994273, 'acc_vowel': 0.99761, 'acc_consonant': 0.997933, 'acc_word': 0.994223, 'loss_grapheme': 0.025468, 'loss_vowel': 0.012223, 'loss_consonant': 0.00979, 'loss_word': 0.024626}\n",
      "    7 | 0.000362 | 160640/160678 | 0.7927 | 6.3900 | 14.40 ||\n",
      "val: {'recall': 0.995826, 'recall_grapheme': 0.994824, 'recall_vowel': 0.997624, 'recall_consonant': 0.996031, 'recall_word': 0.994663, 'acc_grapheme': 0.994796, 'acc_vowel': 0.997958, 'acc_consonant': 0.998282, 'acc_word': 0.994696, 'loss_grapheme': 0.029498, 'loss_vowel': 0.015673, 'loss_consonant': 0.012669, 'loss_word': 0.023798}\n",
      "    8 | 0.000352 | 160640/160678 | 0.9231 | 6.0745 | 14.42 ||\n",
      "val: {'recall': 0.994589, 'recall_grapheme': 0.99314, 'recall_vowel': 0.997642, 'recall_consonant': 0.994435, 'recall_word': 0.993457, 'acc_grapheme': 0.993352, 'acc_vowel': 0.997361, 'acc_consonant': 0.997859, 'acc_word': 0.993377, 'loss_grapheme': 0.028389, 'loss_vowel': 0.011767, 'loss_consonant': 0.0098, 'loss_word': 0.026591}\n",
      "    9 | 0.000341 | 160640/160678 | 0.9914 | 6.2843 | 14.39 ||\n",
      "val: {'recall': 0.995031, 'recall_grapheme': 0.993858, 'recall_vowel': 0.997476, 'recall_consonant': 0.994932, 'recall_word': 0.994591, 'acc_grapheme': 0.994373, 'acc_vowel': 0.997659, 'acc_consonant': 0.998182, 'acc_word': 0.994572, 'loss_grapheme': 0.031364, 'loss_vowel': 0.017955, 'loss_consonant': 0.012472, 'loss_word': 0.02658}\n",
      "   10 | 0.000330 | 160640/160678 | 0.6145 | 6.3321 | 14.37 ||\n",
      "val: {'recall': 0.995972, 'recall_grapheme': 0.993931, 'recall_vowel': 0.998041, 'recall_consonant': 0.997986, 'recall_word': 0.994603, 'acc_grapheme': 0.994622, 'acc_vowel': 0.998008, 'acc_consonant': 0.997859, 'acc_word': 0.994497, 'loss_grapheme': 0.022826, 'loss_vowel': 0.009827, 'loss_consonant': 0.008932, 'loss_word': 0.02207}\n",
      "   11 | 0.000318 | 160640/160678 | 12.8183 | 6.1120 | 14.41 |\n",
      "val: {'recall': 0.995887, 'recall_grapheme': 0.993847, 'recall_vowel': 0.998054, 'recall_consonant': 0.9978, 'recall_word': 0.994604, 'acc_grapheme': 0.994273, 'acc_vowel': 0.998033, 'acc_consonant': 0.997983, 'acc_word': 0.994672, 'loss_grapheme': 0.023806, 'loss_vowel': 0.010952, 'loss_consonant': 0.008194, 'loss_word': 0.021735}\n",
      "   12 | 0.000305 | 160640/160678 | 17.1389 | 6.1480 | 14.43 |\n",
      "val: {'recall': 0.995361, 'recall_grapheme': 0.994034, 'recall_vowel': 0.997747, 'recall_consonant': 0.995628, 'recall_word': 0.994308, 'acc_grapheme': 0.994348, 'acc_vowel': 0.997834, 'acc_consonant': 0.998083, 'acc_word': 0.994223, 'loss_grapheme': 0.023817, 'loss_vowel': 0.011081, 'loss_consonant': 0.008299, 'loss_word': 0.023455}\n",
      "   13 | 0.000291 | 160640/160678 | 6.2749 | 6.1042 | 14.39 ||\n",
      "val: {'recall': 0.995178, 'recall_grapheme': 0.993905, 'recall_vowel': 0.997502, 'recall_consonant': 0.995399, 'recall_word': 0.994588, 'acc_grapheme': 0.994423, 'acc_vowel': 0.997734, 'acc_consonant': 0.998033, 'acc_word': 0.994647, 'loss_grapheme': 0.024792, 'loss_vowel': 0.011407, 'loss_consonant': 0.008579, 'loss_word': 0.023356}\n",
      "   14 | 0.000277 | 160640/160678 | 0.1113 | 5.9577 | 14.40 ||\n",
      "val: {'recall': 0.995309, 'recall_grapheme': 0.993624, 'recall_vowel': 0.998014, 'recall_consonant': 0.995973, 'recall_word': 0.994911, 'acc_grapheme': 0.994696, 'acc_vowel': 0.997983, 'acc_consonant': 0.998431, 'acc_word': 0.994896, 'loss_grapheme': 0.022381, 'loss_vowel': 0.010808, 'loss_consonant': 0.007083, 'loss_word': 0.021954}\n",
      "   15 | 0.000264 | 133376/160678 | 0.4546 | 6.0969 | 11.98 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 0.000184 | 160640/160678 | 3.5539 | 5.8566 | 14.42 ||\n",
      "val: {'recall': 0.996555, 'recall_grapheme': 0.994989, 'recall_vowel': 0.998411, 'recall_consonant': 0.99783, 'recall_word': 0.996139, 'acc_grapheme': 0.996439, 'acc_vowel': 0.998357, 'acc_consonant': 0.99883, 'acc_word': 0.996141, 'loss_grapheme': 0.016667, 'loss_vowel': 0.007622, 'loss_consonant': 0.005235, 'loss_word': 0.016536}\n",
      "   21 | 0.000169 | 160640/160678 | 7.9928 | 5.4756 | 14.50 ||\n",
      "val: {'recall': 0.996231, 'recall_grapheme': 0.994384, 'recall_vowel': 0.998098, 'recall_consonant': 0.998057, 'recall_word': 0.995292, 'acc_grapheme': 0.995518, 'acc_vowel': 0.998282, 'acc_consonant': 0.998631, 'acc_word': 0.995319, 'loss_grapheme': 0.019995, 'loss_vowel': 0.008366, 'loss_consonant': 0.005858, 'loss_word': 0.019362}\n",
      "   22 | 0.000153 | 160640/160678 | 0.1657 | 5.4465 | 14.47 ||\n",
      "val: {'recall': 0.996016, 'recall_grapheme': 0.994153, 'recall_vowel': 0.997745, 'recall_consonant': 0.998014, 'recall_word': 0.995117, 'acc_grapheme': 0.995344, 'acc_vowel': 0.998083, 'acc_consonant': 0.998606, 'acc_word': 0.995219, 'loss_grapheme': 0.021383, 'loss_vowel': 0.009054, 'loss_consonant': 0.006116, 'loss_word': 0.020164}\n",
      "   23 | 0.000149 | 049792/160678 | 3.2188 | 5.3304 | 4.52 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 0.000070 | 160640/160678 | 7.1218 | 5.6596 | 14.44 ||\n",
      "val: {'recall': 0.997226, 'recall_grapheme': 0.995506, 'recall_vowel': 0.998533, 'recall_consonant': 0.999359, 'recall_word': 0.996388, 'acc_grapheme': 0.996315, 'acc_vowel': 0.998456, 'acc_consonant': 0.999178, 'acc_word': 0.99639, 'loss_grapheme': 0.01523, 'loss_vowel': 0.007205, 'loss_consonant': 0.004184, 'loss_word': 0.015197}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   29 | 0.000059 | 160640/160678 | 0.9150 | 5.2730 | 14.51 ||\n",
      "val: {'recall': 0.997157, 'recall_grapheme': 0.995557, 'recall_vowel': 0.998705, 'recall_consonant': 0.998809, 'recall_word': 0.99652, 'acc_grapheme': 0.996539, 'acc_vowel': 0.998581, 'acc_consonant': 0.999129, 'acc_word': 0.996539, 'loss_grapheme': 0.014689, 'loss_vowel': 0.007272, 'loss_consonant': 0.004466, 'loss_word': 0.014702}\n",
      "   30 | 0.000048 | 160640/160678 | 11.7399 | 5.5561 | 14.44 |\n",
      "val: {'recall': 0.996746, 'recall_grapheme': 0.995126, 'recall_vowel': 0.998338, 'recall_consonant': 0.998395, 'recall_word': 0.996037, 'acc_grapheme': 0.995917, 'acc_vowel': 0.998431, 'acc_consonant': 0.998979, 'acc_word': 0.996091, 'loss_grapheme': 0.017418, 'loss_vowel': 0.008465, 'loss_consonant': 0.004511, 'loss_word': 0.017066}\n",
      "   31 | 0.000038 | 160640/160678 | 9.0225 | 5.4054 | 14.45 ||\n",
      "val: {'recall': 0.997263, 'recall_grapheme': 0.996315, 'recall_vowel': 0.998725, 'recall_consonant': 0.997697, 'recall_word': 0.996861, 'acc_grapheme': 0.996788, 'acc_vowel': 0.99873, 'acc_consonant': 0.999153, 'acc_word': 0.996888, 'loss_grapheme': 0.014107, 'loss_vowel': 0.006982, 'loss_consonant': 0.004129, 'loss_word': 0.014394}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   32 | 0.000029 | 160640/160678 | 0.3071 | 5.2957 | 14.45 ||\n",
      "val: {'recall': 0.997134, 'recall_grapheme': 0.995677, 'recall_vowel': 0.998518, 'recall_consonant': 0.998664, 'recall_word': 0.996497, 'acc_grapheme': 0.996415, 'acc_vowel': 0.998581, 'acc_consonant': 0.999129, 'acc_word': 0.996539, 'loss_grapheme': 0.015279, 'loss_vowel': 0.007036, 'loss_consonant': 0.004164, 'loss_word': 0.015307}\n",
      "   33 | 0.000022 | 160640/160678 | 3.7935 | 5.5368 | 14.50 ||\n",
      "val: {'recall': 0.997125, 'recall_grapheme': 0.995583, 'recall_vowel': 0.998564, 'recall_consonant': 0.998773, 'recall_word': 0.99655, 'acc_grapheme': 0.996315, 'acc_vowel': 0.998705, 'acc_consonant': 0.999104, 'acc_word': 0.996564, 'loss_grapheme': 0.016406, 'loss_vowel': 0.007425, 'loss_consonant': 0.004671, 'loss_word': 0.01618}\n",
      "   34 | 0.000015 | 160640/160678 | 4.6784 | 5.3415 | 14.49 ||\n",
      "val: {'recall': 0.996959, 'recall_grapheme': 0.995491, 'recall_vowel': 0.998358, 'recall_consonant': 0.998496, 'recall_word': 0.996194, 'acc_grapheme': 0.996041, 'acc_vowel': 0.998506, 'acc_consonant': 0.999004, 'acc_word': 0.99624, 'loss_grapheme': 0.016998, 'loss_vowel': 0.007708, 'loss_consonant': 0.005157, 'loss_word': 0.016389}\n",
      "   35 | 0.000010 | 160640/160678 | 0.4389 | 5.3930 | 14.48 ||\n",
      "val: {'recall': 0.99747, 'recall_grapheme': 0.996203, 'recall_vowel': 0.998734, 'recall_consonant': 0.99874, 'recall_word': 0.996802, 'acc_grapheme': 0.996788, 'acc_vowel': 0.99878, 'acc_consonant': 0.999228, 'acc_word': 0.996813, 'loss_grapheme': 0.013058, 'loss_vowel': 0.006266, 'loss_consonant': 0.003827, 'loss_word': 0.013256}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   36 | 0.000006 | 160640/160678 | 2.1539 | 5.2947 | 14.51 ||\n",
      "val: {'recall': 0.997376, 'recall_grapheme': 0.995855, 'recall_vowel': 0.998534, 'recall_consonant': 0.999261, 'recall_word': 0.996643, 'acc_grapheme': 0.996763, 'acc_vowel': 0.998705, 'acc_consonant': 0.999129, 'acc_word': 0.996664, 'loss_grapheme': 0.014036, 'loss_vowel': 0.006723, 'loss_consonant': 0.003986, 'loss_word': 0.014428}\n",
      "   37 | 0.000002 | 160640/160678 | 5.6585 | 5.1120 | 14.56 ||\n",
      "val: {'recall': 0.997263, 'recall_grapheme': 0.995957, 'recall_vowel': 0.998436, 'recall_consonant': 0.9987, 'recall_word': 0.996617, 'acc_grapheme': 0.996738, 'acc_vowel': 0.998606, 'acc_consonant': 0.999203, 'acc_word': 0.996639, 'loss_grapheme': 0.013806, 'loss_vowel': 0.006645, 'loss_consonant': 0.003835, 'loss_word': 0.014233}\n",
      "   38 | 0.000001 | 160640/160678 | 0.3121 | 5.5520 | 14.42 ||\n",
      "val: {'recall': 0.997303, 'recall_grapheme': 0.996067, 'recall_vowel': 0.998472, 'recall_consonant': 0.998608, 'recall_word': 0.996668, 'acc_grapheme': 0.996738, 'acc_vowel': 0.998655, 'acc_consonant': 0.999153, 'acc_word': 0.996688, 'loss_grapheme': 0.014692, 'loss_vowel': 0.007404, 'loss_consonant': 0.004634, 'loss_word': 0.01451}\n",
      "   39 | 0.000000 | 160640/160678 | 6.3749 | 5.2954 | 14.47 ||\n",
      "val: {'recall': 0.997425, 'recall_grapheme': 0.996139, 'recall_vowel': 0.998706, 'recall_consonant': 0.998715, 'recall_word': 0.996783, 'acc_grapheme': 0.996863, 'acc_vowel': 0.99873, 'acc_consonant': 0.999253, 'acc_word': 0.996813, 'loss_grapheme': 0.013396, 'loss_vowel': 0.006534, 'loss_consonant': 0.003778, 'loss_word': 0.013921}\n",
      "CYCLE: 2\n",
      "    0 | 0.000200 | 160640/160678 | 6.9539 | 5.2088 | 14.03 ||\n",
      "val: {'recall': 0.995596, 'recall_grapheme': 0.993928, 'recall_vowel': 0.998117, 'recall_consonant': 0.996411, 'recall_word': 0.994272, 'acc_grapheme': 0.994398, 'acc_vowel': 0.998207, 'acc_consonant': 0.998108, 'acc_word': 0.994373, 'loss_grapheme': 0.025156, 'loss_vowel': 0.009795, 'loss_consonant': 0.008367, 'loss_word': 0.024994}\n",
      "    1 | 0.000199 | 160640/160678 | 6.2438 | 5.4912 | 14.07 ||\n",
      "val: {'recall': 0.996234, 'recall_grapheme': 0.994562, 'recall_vowel': 0.998059, 'recall_consonant': 0.997756, 'recall_word': 0.995258, 'acc_grapheme': 0.995518, 'acc_vowel': 0.998108, 'acc_consonant': 0.998655, 'acc_word': 0.995194, 'loss_grapheme': 0.020264, 'loss_vowel': 0.009696, 'loss_consonant': 0.006066, 'loss_word': 0.021269}\n",
      "    2 | 0.000197 | 160640/160678 | 3.9141 | 5.7145 | 14.21 ||\n",
      "val: {'recall': 0.996641, 'recall_grapheme': 0.995277, 'recall_vowel': 0.998444, 'recall_consonant': 0.997568, 'recall_word': 0.995947, 'acc_grapheme': 0.995966, 'acc_vowel': 0.998556, 'acc_consonant': 0.998631, 'acc_word': 0.995966, 'loss_grapheme': 0.017373, 'loss_vowel': 0.008496, 'loss_consonant': 0.005541, 'loss_word': 0.017459}\n",
      "    3 | 0.000195 | 160640/160678 | 6.0803 | 5.5736 | 14.32 ||\n",
      "val: {'recall': 0.996962, 'recall_grapheme': 0.995825, 'recall_vowel': 0.998569, 'recall_consonant': 0.997629, 'recall_word': 0.995894, 'acc_grapheme': 0.995966, 'acc_vowel': 0.998556, 'acc_consonant': 0.998581, 'acc_word': 0.995892, 'loss_grapheme': 0.020732, 'loss_vowel': 0.010232, 'loss_consonant': 0.007546, 'loss_word': 0.018911}\n",
      "    4 | 0.000192 | 160640/160678 | 11.8366 | 5.5904 | 14.41 |\n",
      "val: {'recall': 0.996833, 'recall_grapheme': 0.99592, 'recall_vowel': 0.99816, 'recall_consonant': 0.997335, 'recall_word': 0.995872, 'acc_grapheme': 0.995941, 'acc_vowel': 0.998108, 'acc_consonant': 0.998855, 'acc_word': 0.995867, 'loss_grapheme': 0.019467, 'loss_vowel': 0.009661, 'loss_consonant': 0.005502, 'loss_word': 0.018246}\n",
      "    5 | 0.000189 | 160640/160678 | 6.4170 | 5.8969 | 14.49 ||\n",
      "val: {'recall': 0.995721, 'recall_grapheme': 0.994637, 'recall_vowel': 0.998043, 'recall_consonant': 0.995568, 'recall_word': 0.995105, 'acc_grapheme': 0.99507, 'acc_vowel': 0.998133, 'acc_consonant': 0.998307, 'acc_word': 0.995145, 'loss_grapheme': 0.023932, 'loss_vowel': 0.009359, 'loss_consonant': 0.007154, 'loss_word': 0.022784}\n",
      "    6 | 0.000185 | 160640/160678 | 3.3140 | 5.7912 | 14.50 ||\n",
      "val: {'recall': 0.996206, 'recall_grapheme': 0.995183, 'recall_vowel': 0.998416, 'recall_consonant': 0.996044, 'recall_word': 0.99582, 'acc_grapheme': 0.995991, 'acc_vowel': 0.998456, 'acc_consonant': 0.998705, 'acc_word': 0.995842, 'loss_grapheme': 0.01999, 'loss_vowel': 0.008498, 'loss_consonant': 0.006113, 'loss_word': 0.019578}\n",
      "    7 | 0.000181 | 160640/160678 | 0.3240 | 5.8094 | 14.50 ||\n",
      "val: {'recall': 0.996435, 'recall_grapheme': 0.995468, 'recall_vowel': 0.9987, 'recall_consonant': 0.996103, 'recall_word': 0.996173, 'acc_grapheme': 0.996041, 'acc_vowel': 0.99873, 'acc_consonant': 0.99878, 'acc_word': 0.99619, 'loss_grapheme': 0.018144, 'loss_vowel': 0.006987, 'loss_consonant': 0.005395, 'loss_word': 0.017256}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 | 0.000176 | 160640/160678 | 5.2936 | 5.5808 | 14.49 ||\n",
      "val: {'recall': 0.996467, 'recall_grapheme': 0.995221, 'recall_vowel': 0.998337, 'recall_consonant': 0.997088, 'recall_word': 0.996153, 'acc_grapheme': 0.995792, 'acc_vowel': 0.998581, 'acc_consonant': 0.99883, 'acc_word': 0.996066, 'loss_grapheme': 0.018429, 'loss_vowel': 0.007584, 'loss_consonant': 0.005819, 'loss_word': 0.017307}\n",
      "    9 | 0.000171 | 160640/160678 | 14.0477 | 5.6396 | 14.49 |\n",
      "val: {'recall': 0.996437, 'recall_grapheme': 0.994835, 'recall_vowel': 0.998539, 'recall_consonant': 0.99754, 'recall_word': 0.995877, 'acc_grapheme': 0.995568, 'acc_vowel': 0.998556, 'acc_consonant': 0.99868, 'acc_word': 0.995867, 'loss_grapheme': 0.01984, 'loss_vowel': 0.007887, 'loss_consonant': 0.006512, 'loss_word': 0.018733}\n",
      "   10 | 0.000165 | 160640/160678 | 6.5161 | 5.5327 | 14.52 ||\n",
      "val: {'recall': 0.996504, 'recall_grapheme': 0.995466, 'recall_vowel': 0.998455, 'recall_consonant': 0.99663, 'recall_word': 0.996164, 'acc_grapheme': 0.996016, 'acc_vowel': 0.998506, 'acc_consonant': 0.998805, 'acc_word': 0.996141, 'loss_grapheme': 0.018552, 'loss_vowel': 0.007389, 'loss_consonant': 0.006039, 'loss_word': 0.017928}\n",
      "   11 | 0.000159 | 160640/160678 | 6.8985 | 5.6869 | 14.52 ||\n",
      "val: {'recall': 0.996515, 'recall_grapheme': 0.995365, 'recall_vowel': 0.998464, 'recall_consonant': 0.996867, 'recall_word': 0.996092, 'acc_grapheme': 0.995966, 'acc_vowel': 0.998655, 'acc_consonant': 0.998979, 'acc_word': 0.996066, 'loss_grapheme': 0.017161, 'loss_vowel': 0.006904, 'loss_consonant': 0.004592, 'loss_word': 0.017148}\n",
      "   12 | 0.000152 | 160640/160678 | 5.2916 | 5.6134 | 14.51 ||\n",
      "val: {'recall': 0.996479, 'recall_grapheme': 0.995834, 'recall_vowel': 0.998508, 'recall_consonant': 0.995739, 'recall_word': 0.996231, 'acc_grapheme': 0.99629, 'acc_vowel': 0.998705, 'acc_consonant': 0.998631, 'acc_word': 0.99624, 'loss_grapheme': 0.016378, 'loss_vowel': 0.006888, 'loss_consonant': 0.00628, 'loss_word': 0.016265}\n",
      "   13 | 0.000151 | 040576/160678 | 12.0170 | 5.4768 | 3.71 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 0.000145 | 160640/160678 | 3.6052 | 5.3858 | 14.55 ||\n",
      "val: {'recall': 0.9972, 'recall_grapheme': 0.996244, 'recall_vowel': 0.998612, 'recall_consonant': 0.9977, 'recall_word': 0.996528, 'acc_grapheme': 0.99639, 'acc_vowel': 0.998556, 'acc_consonant': 0.99868, 'acc_word': 0.996439, 'loss_grapheme': 0.01712, 'loss_vowel': 0.006885, 'loss_consonant': 0.005825, 'loss_word': 0.016743}\n",
      "   14 | 0.000138 | 160640/160678 | 2.5435 | 5.4727 | 14.51 ||\n",
      "val: {'recall': 0.997059, 'recall_grapheme': 0.995488, 'recall_vowel': 0.998863, 'recall_consonant': 0.998399, 'recall_word': 0.996368, 'acc_grapheme': 0.996464, 'acc_vowel': 0.99878, 'acc_consonant': 0.998855, 'acc_word': 0.99634, 'loss_grapheme': 0.017036, 'loss_vowel': 0.006625, 'loss_consonant': 0.005677, 'loss_word': 0.0171}\n",
      "   15 | 0.000131 | 160640/160678 | 5.5252 | 5.3911 | 14.55 ||\n",
      "val: {'recall': 0.997457, 'recall_grapheme': 0.996516, 'recall_vowel': 0.998866, 'recall_consonant': 0.997931, 'recall_word': 0.997129, 'acc_grapheme': 0.996813, 'acc_vowel': 0.998855, 'acc_consonant': 0.999054, 'acc_word': 0.997062, 'loss_grapheme': 0.013937, 'loss_vowel': 0.005958, 'loss_consonant': 0.004706, 'loss_word': 0.014113}\n",
      "   16 | 0.000123 | 160640/160678 | 0.4350 | 5.4424 | 14.53 ||\n",
      "val: {'recall': 0.997687, 'recall_grapheme': 0.996289, 'recall_vowel': 0.998834, 'recall_consonant': 0.999335, 'recall_word': 0.996599, 'acc_grapheme': 0.996788, 'acc_vowel': 0.99878, 'acc_consonant': 0.999129, 'acc_word': 0.996614, 'loss_grapheme': 0.014888, 'loss_vowel': 0.006136, 'loss_consonant': 0.004177, 'loss_word': 0.014704}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   17 | 0.000116 | 160640/160678 | 0.6492 | 5.2070 | 14.58 ||\n",
      "val: {'recall': 0.997511, 'recall_grapheme': 0.996079, 'recall_vowel': 0.999013, 'recall_consonant': 0.998873, 'recall_word': 0.996478, 'acc_grapheme': 0.996664, 'acc_vowel': 0.998954, 'acc_consonant': 0.99878, 'acc_word': 0.996439, 'loss_grapheme': 0.016234, 'loss_vowel': 0.006614, 'loss_consonant': 0.005588, 'loss_word': 0.01592}\n",
      "   18 | 0.000108 | 160640/160678 | 5.8646 | 5.2888 | 14.56 ||\n",
      "val: {'recall': 0.997721, 'recall_grapheme': 0.997028, 'recall_vowel': 0.998846, 'recall_consonant': 0.997981, 'recall_word': 0.99715, 'acc_grapheme': 0.997087, 'acc_vowel': 0.998904, 'acc_consonant': 0.999054, 'acc_word': 0.997037, 'loss_grapheme': 0.013916, 'loss_vowel': 0.006257, 'loss_consonant': 0.004717, 'loss_word': 0.014238}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   19 | 0.000100 | 160640/160678 | 5.1602 | 5.4229 | 14.52 ||\n",
      "val: {'recall': 0.99687, 'recall_grapheme': 0.995988, 'recall_vowel': 0.998911, 'recall_consonant': 0.996593, 'recall_word': 0.99629, 'acc_grapheme': 0.99624, 'acc_vowel': 0.998954, 'acc_consonant': 0.99878, 'acc_word': 0.996315, 'loss_grapheme': 0.017466, 'loss_vowel': 0.006496, 'loss_consonant': 0.005445, 'loss_word': 0.01672}\n",
      "   20 | 0.000092 | 160640/160678 | 12.9737 | 5.3834 | 14.54 |\n",
      "val: {'recall': 0.997319, 'recall_grapheme': 0.996014, 'recall_vowel': 0.998602, 'recall_consonant': 0.998645, 'recall_word': 0.9965, 'acc_grapheme': 0.99624, 'acc_vowel': 0.99878, 'acc_consonant': 0.998805, 'acc_word': 0.996439, 'loss_grapheme': 0.016159, 'loss_vowel': 0.006701, 'loss_consonant': 0.005522, 'loss_word': 0.015357}\n",
      "   21 | 0.000084 | 160640/160678 | 6.0808 | 5.4087 | 14.52 ||\n",
      "val: {'recall': 0.997287, 'recall_grapheme': 0.996237, 'recall_vowel': 0.998774, 'recall_consonant': 0.9979, 'recall_word': 0.996449, 'acc_grapheme': 0.996688, 'acc_vowel': 0.999004, 'acc_consonant': 0.998929, 'acc_word': 0.99639, 'loss_grapheme': 0.015191, 'loss_vowel': 0.005911, 'loss_consonant': 0.004574, 'loss_word': 0.015544}\n",
      "   22 | 0.000077 | 160640/160678 | 0.1458 | 5.4436 | 14.52 ||\n",
      "val: {'recall': 0.997086, 'recall_grapheme': 0.99668, 'recall_vowel': 0.998713, 'recall_consonant': 0.996273, 'recall_word': 0.99685, 'acc_grapheme': 0.997012, 'acc_vowel': 0.998855, 'acc_consonant': 0.999029, 'acc_word': 0.996838, 'loss_grapheme': 0.013239, 'loss_vowel': 0.006372, 'loss_consonant': 0.004761, 'loss_word': 0.013127}\n",
      "   23 | 0.000069 | 160640/160678 | 0.1895 | 5.3527 | 14.58 ||\n",
      "val: {'recall': 0.997648, 'recall_grapheme': 0.996932, 'recall_vowel': 0.998788, 'recall_consonant': 0.99794, 'recall_word': 0.99712, 'acc_grapheme': 0.997236, 'acc_vowel': 0.998904, 'acc_consonant': 0.999104, 'acc_word': 0.997087, 'loss_grapheme': 0.012765, 'loss_vowel': 0.006099, 'loss_consonant': 0.004467, 'loss_word': 0.012979}\n",
      "   24 | 0.000062 | 160640/160678 | 9.0428 | 5.2959 | 14.51 ||\n",
      "val: {'recall': 0.997729, 'recall_grapheme': 0.996648, 'recall_vowel': 0.998857, 'recall_consonant': 0.998762, 'recall_word': 0.996762, 'acc_grapheme': 0.996738, 'acc_vowel': 0.998954, 'acc_consonant': 0.998979, 'acc_word': 0.996738, 'loss_grapheme': 0.016292, 'loss_vowel': 0.006891, 'loss_consonant': 0.005242, 'loss_word': 0.015911}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   25 | 0.000055 | 160640/160678 | 0.5459 | 5.4209 | 14.53 ||\n",
      "val: {'recall': 0.997716, 'recall_grapheme': 0.996795, 'recall_vowel': 0.99866, 'recall_consonant': 0.998614, 'recall_word': 0.996881, 'acc_grapheme': 0.997087, 'acc_vowel': 0.998904, 'acc_consonant': 0.999178, 'acc_word': 0.996863, 'loss_grapheme': 0.013605, 'loss_vowel': 0.006141, 'loss_consonant': 0.003965, 'loss_word': 0.014069}\n",
      "   26 | 0.000048 | 160640/160678 | 14.2445 | 5.2366 | 14.59 |\n",
      "val: {'recall': 0.997007, 'recall_grapheme': 0.996253, 'recall_vowel': 0.998466, 'recall_consonant': 0.997054, 'recall_word': 0.996664, 'acc_grapheme': 0.996614, 'acc_vowel': 0.99868, 'acc_consonant': 0.99883, 'acc_word': 0.996614, 'loss_grapheme': 0.01585, 'loss_vowel': 0.007995, 'loss_consonant': 0.005488, 'loss_word': 0.015597}\n",
      "   27 | 0.000041 | 160640/160678 | 15.0516 | 5.3083 | 14.57 |\n",
      "val: {'recall': 0.99733, 'recall_grapheme': 0.996588, 'recall_vowel': 0.998489, 'recall_consonant': 0.997655, 'recall_word': 0.99673, 'acc_grapheme': 0.996863, 'acc_vowel': 0.998655, 'acc_consonant': 0.998954, 'acc_word': 0.996688, 'loss_grapheme': 0.014529, 'loss_vowel': 0.007739, 'loss_consonant': 0.005151, 'loss_word': 0.014987}\n",
      "   28 | 0.000035 | 160640/160678 | 7.2597 | 5.3415 | 14.53 ||\n",
      "val: {'recall': 0.997391, 'recall_grapheme': 0.996838, 'recall_vowel': 0.99862, 'recall_consonant': 0.997269, 'recall_word': 0.996797, 'acc_grapheme': 0.997211, 'acc_vowel': 0.998755, 'acc_consonant': 0.999004, 'acc_word': 0.996738, 'loss_grapheme': 0.014089, 'loss_vowel': 0.006257, 'loss_consonant': 0.004314, 'loss_word': 0.014753}\n",
      "   29 | 0.000029 | 160640/160678 | 2.7238 | 5.2885 | 14.58 ||\n",
      "val: {'recall': 0.997777, 'recall_grapheme': 0.997203, 'recall_vowel': 0.9987, 'recall_consonant': 0.998002, 'recall_word': 0.997111, 'acc_grapheme': 0.997311, 'acc_vowel': 0.99888, 'acc_consonant': 0.999104, 'acc_word': 0.997037, 'loss_grapheme': 0.014067, 'loss_vowel': 0.006681, 'loss_consonant': 0.004011, 'loss_word': 0.014713}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   30 | 0.000024 | 160640/160678 | 0.4135 | 5.1482 | 14.57 ||\n",
      "val: {'recall': 0.997625, 'recall_grapheme': 0.996882, 'recall_vowel': 0.998658, 'recall_consonant': 0.998078, 'recall_word': 0.997093, 'acc_grapheme': 0.997361, 'acc_vowel': 0.998904, 'acc_consonant': 0.999203, 'acc_word': 0.997037, 'loss_grapheme': 0.012089, 'loss_vowel': 0.005955, 'loss_consonant': 0.003558, 'loss_word': 0.012946}\n",
      "   31 | 0.000019 | 160640/160678 | 5.9629 | 5.1421 | 14.55 ||\n",
      "val: {'recall': 0.997335, 'recall_grapheme': 0.996434, 'recall_vowel': 0.998601, 'recall_consonant': 0.997873, 'recall_word': 0.996821, 'acc_grapheme': 0.996838, 'acc_vowel': 0.99883, 'acc_consonant': 0.999054, 'acc_word': 0.996788, 'loss_grapheme': 0.015088, 'loss_vowel': 0.006759, 'loss_consonant': 0.004305, 'loss_word': 0.014768}\n",
      "   32 | 0.000015 | 160640/160678 | 8.3845 | 5.4075 | 14.54 ||\n",
      "val: {'recall': 0.997658, 'recall_grapheme': 0.996778, 'recall_vowel': 0.9987, 'recall_consonant': 0.998375, 'recall_word': 0.997062, 'acc_grapheme': 0.997062, 'acc_vowel': 0.998929, 'acc_consonant': 0.999029, 'acc_word': 0.997012, 'loss_grapheme': 0.014847, 'loss_vowel': 0.006424, 'loss_consonant': 0.004366, 'loss_word': 0.014707}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 0.000011 | 160640/160678 | 6.0712 | 5.0062 | 14.53 ||\n",
      "val: {'recall': 0.997484, 'recall_grapheme': 0.996719, 'recall_vowel': 0.998857, 'recall_consonant': 0.997638, 'recall_word': 0.996982, 'acc_grapheme': 0.997037, 'acc_vowel': 0.999054, 'acc_consonant': 0.999228, 'acc_word': 0.996962, 'loss_grapheme': 0.014909, 'loss_vowel': 0.006764, 'loss_consonant': 0.004052, 'loss_word': 0.015049}\n",
      "   34 | 0.000008 | 160640/160678 | 12.4042 | 5.1806 | 14.50 |\n",
      "val: {'recall': 0.997746, 'recall_grapheme': 0.997055, 'recall_vowel': 0.99883, 'recall_consonant': 0.998047, 'recall_word': 0.997351, 'acc_grapheme': 0.99741, 'acc_vowel': 0.999004, 'acc_consonant': 0.999178, 'acc_word': 0.997311, 'loss_grapheme': 0.012888, 'loss_vowel': 0.006307, 'loss_consonant': 0.003611, 'loss_word': 0.013399}\n",
      "   35 | 0.000005 | 160640/160678 | 12.4352 | 5.1254 | 14.57 |"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-ebf6e9a7b296>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_start\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-ebf6e9a7b296>\u001b[0m in \u001b[0;36mvalidate_and_save\u001b[0;34m(model, model_file, val_loader, save)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbest_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nval:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5ca1aeb200dd>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1295\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth, exist: True\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth...\n",
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.863007, 'recall_grapheme': 0.799473, 'recall_vowel': 0.910495, 'recall_consonant': 0.942587, 'recall_word': 0.792659, 'acc_grapheme': 0.579279, 'acc_vowel': 0.896942, 'acc_consonant': 0.816369, 'acc_word': 0.390718, 'loss_grapheme': 1.777621, 'loss_vowel': 0.442087, 'loss_consonant': 0.433245, 'loss_word': 2.889786}\n",
      "CYCLE: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.000292 | 160640/160678 | 9.0631 | 11.0421 | 13.91 ||\n",
      "val: {'recall': 0.990122, 'recall_grapheme': 0.987137, 'recall_vowel': 0.994537, 'recall_consonant': 0.991677, 'recall_word': 0.986548, 'acc_grapheme': 0.987476, 'acc_vowel': 0.994921, 'acc_consonant': 0.995892, 'acc_word': 0.986355, 'loss_grapheme': 0.081153, 'loss_vowel': 0.043929, 'loss_consonant': 0.032938, 'loss_word': 0.071857}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "    1 | 0.000543 | 160640/160678 | 11.2862 | 7.7721 | 14.02 |\n",
      "val: {'recall': 0.99057, 'recall_grapheme': 0.985973, 'recall_vowel': 0.994439, 'recall_consonant': 0.995896, 'recall_word': 0.987708, 'acc_grapheme': 0.98765, 'acc_vowel': 0.994921, 'acc_consonant': 0.996116, 'acc_word': 0.987227, 'loss_grapheme': 0.050568, 'loss_vowel': 0.022158, 'loss_consonant': 0.018201, 'loss_word': 0.050209}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "    2 | 0.000476 | 160640/160678 | 1.3762 | 7.5592 | 14.18 ||\n",
      "val: {'recall': 0.990194, 'recall_grapheme': 0.985953, 'recall_vowel': 0.994653, 'recall_consonant': 0.994215, 'recall_word': 0.98804, 'acc_grapheme': 0.988322, 'acc_vowel': 0.995419, 'acc_consonant': 0.996066, 'acc_word': 0.987899, 'loss_grapheme': 0.055032, 'loss_vowel': 0.025479, 'loss_consonant': 0.019687, 'loss_word': 0.052394}\n",
      "    3 | 0.000393 | 160640/160678 | 7.6745 | 7.4268 | 14.27 ||\n",
      "val: {'recall': 0.992202, 'recall_grapheme': 0.989024, 'recall_vowel': 0.996775, 'recall_consonant': 0.993983, 'recall_word': 0.991499, 'acc_grapheme': 0.991136, 'acc_vowel': 0.996863, 'acc_consonant': 0.997261, 'acc_word': 0.991534, 'loss_grapheme': 0.039199, 'loss_vowel': 0.017218, 'loss_consonant': 0.013465, 'loss_word': 0.034572}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "    4 | 0.000300 | 160640/160678 | 5.6482 | 6.9655 | 14.34 ||\n",
      "val: {'recall': 0.993916, 'recall_grapheme': 0.991596, 'recall_vowel': 0.996579, 'recall_consonant': 0.995894, 'recall_word': 0.992211, 'acc_grapheme': 0.992157, 'acc_vowel': 0.997037, 'acc_consonant': 0.997012, 'acc_word': 0.992082, 'loss_grapheme': 0.041761, 'loss_vowel': 0.02089, 'loss_consonant': 0.016283, 'loss_word': 0.036556}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "    5 | 0.000207 | 160640/160678 | 0.9168 | 6.7803 | 14.48 ||\n",
      "val: {'recall': 0.994361, 'recall_grapheme': 0.992047, 'recall_vowel': 0.997427, 'recall_consonant': 0.995922, 'recall_word': 0.993398, 'acc_grapheme': 0.992605, 'acc_vowel': 0.99751, 'acc_consonant': 0.997884, 'acc_word': 0.993327, 'loss_grapheme': 0.031507, 'loss_vowel': 0.013135, 'loss_consonant': 0.010009, 'loss_word': 0.029411}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "    6 | 0.000124 | 160640/160678 | 13.3685 | 6.3333 | 14.54 |\n",
      "val: {'recall': 0.99485, 'recall_grapheme': 0.992533, 'recall_vowel': 0.997485, 'recall_consonant': 0.99685, 'recall_word': 0.994272, 'acc_grapheme': 0.993252, 'acc_vowel': 0.99751, 'acc_consonant': 0.997983, 'acc_word': 0.994298, 'loss_grapheme': 0.02986, 'loss_vowel': 0.014089, 'loss_consonant': 0.009659, 'loss_word': 0.02558}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "    7 | 0.000057 | 160640/160678 | 14.2228 | 6.1689 | 14.51 |\n",
      "val: {'recall': 0.99484, 'recall_grapheme': 0.993022, 'recall_vowel': 0.997311, 'recall_consonant': 0.996004, 'recall_word': 0.993926, 'acc_grapheme': 0.994049, 'acc_vowel': 0.99751, 'acc_consonant': 0.998182, 'acc_word': 0.993974, 'loss_grapheme': 0.025888, 'loss_vowel': 0.011827, 'loss_consonant': 0.008406, 'loss_word': 0.024524}\n",
      "    8 | 0.000015 | 160640/160678 | 5.9368 | 6.0782 | 14.51 ||\n",
      "val: {'recall': 0.994921, 'recall_grapheme': 0.992792, 'recall_vowel': 0.997397, 'recall_consonant': 0.996703, 'recall_word': 0.994053, 'acc_grapheme': 0.993701, 'acc_vowel': 0.997635, 'acc_consonant': 0.998257, 'acc_word': 0.994074, 'loss_grapheme': 0.027889, 'loss_vowel': 0.012232, 'loss_consonant': 0.008177, 'loss_word': 0.025091}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "    9 | 0.000000 | 160640/160678 | 9.9703 | 5.9798 | 14.50 ||\n",
      "val: {'recall': 0.995327, 'recall_grapheme': 0.993341, 'recall_vowel': 0.997946, 'recall_consonant': 0.996677, 'recall_word': 0.994459, 'acc_grapheme': 0.994124, 'acc_vowel': 0.997908, 'acc_consonant': 0.998332, 'acc_word': 0.994423, 'loss_grapheme': 0.024672, 'loss_vowel': 0.010698, 'loss_consonant': 0.007619, 'loss_word': 0.023081}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "CYCLE: 2\n",
      "    0 | 0.000200 | 160640/160678 | 13.1078 | 6.0285 | 14.01 |\n",
      "val: {'recall': 0.994001, 'recall_grapheme': 0.992091, 'recall_vowel': 0.99744, 'recall_consonant': 0.994381, 'recall_word': 0.993518, 'acc_grapheme': 0.993103, 'acc_vowel': 0.997386, 'acc_consonant': 0.998008, 'acc_word': 0.993526, 'loss_grapheme': 0.030174, 'loss_vowel': 0.014206, 'loss_consonant': 0.010015, 'loss_word': 0.027602}\n",
      "    1 | 0.000199 | 160640/160678 | 5.1296 | 6.1058 | 14.14 ||\n",
      "val: {'recall': 0.994466, 'recall_grapheme': 0.991894, 'recall_vowel': 0.997966, 'recall_consonant': 0.99611, 'recall_word': 0.993761, 'acc_grapheme': 0.993576, 'acc_vowel': 0.997958, 'acc_consonant': 0.998133, 'acc_word': 0.99385, 'loss_grapheme': 0.026808, 'loss_vowel': 0.011008, 'loss_consonant': 0.00962, 'loss_word': 0.026182}\n",
      "    2 | 0.000197 | 160640/160678 | 7.3127 | 6.1022 | 14.22 ||\n",
      "val: {'recall': 0.993723, 'recall_grapheme': 0.992175, 'recall_vowel': 0.997476, 'recall_consonant': 0.993066, 'recall_word': 0.993169, 'acc_grapheme': 0.992929, 'acc_vowel': 0.997535, 'acc_consonant': 0.997261, 'acc_word': 0.993128, 'loss_grapheme': 0.034796, 'loss_vowel': 0.015667, 'loss_consonant': 0.013713, 'loss_word': 0.032041}\n",
      "    3 | 0.000195 | 160640/160678 | 0.7041 | 6.3150 | 14.27 ||\n",
      "val: {'recall': 0.995323, 'recall_grapheme': 0.993593, 'recall_vowel': 0.99776, 'recall_consonant': 0.996345, 'recall_word': 0.993997, 'acc_grapheme': 0.994198, 'acc_vowel': 0.997884, 'acc_consonant': 0.997884, 'acc_word': 0.99395, 'loss_grapheme': 0.024847, 'loss_vowel': 0.011413, 'loss_consonant': 0.009732, 'loss_word': 0.024127}\n",
      "    4 | 0.000192 | 160640/160678 | 6.4187 | 6.2909 | 14.39 ||\n",
      "val: {'recall': 0.994075, 'recall_grapheme': 0.992096, 'recall_vowel': 0.997658, 'recall_consonant': 0.994452, 'recall_word': 0.993225, 'acc_grapheme': 0.993402, 'acc_vowel': 0.997585, 'acc_consonant': 0.997635, 'acc_word': 0.993277, 'loss_grapheme': 0.0286, 'loss_vowel': 0.012848, 'loss_consonant': 0.010428, 'loss_word': 0.027023}\n",
      "    5 | 0.000189 | 160640/160678 | 8.9461 | 6.1536 | 14.52 ||\n",
      "val: {'recall': 0.99493, 'recall_grapheme': 0.992452, 'recall_vowel': 0.997751, 'recall_consonant': 0.997065, 'recall_word': 0.994087, 'acc_grapheme': 0.993725, 'acc_vowel': 0.997908, 'acc_consonant': 0.998332, 'acc_word': 0.994049, 'loss_grapheme': 0.028572, 'loss_vowel': 0.011454, 'loss_consonant': 0.008411, 'loss_word': 0.025477}\n",
      "    6 | 0.000185 | 160640/160678 | 3.6986 | 6.0373 | 14.52 ||\n",
      "val: {'recall': 0.995002, 'recall_grapheme': 0.993081, 'recall_vowel': 0.997886, 'recall_consonant': 0.995962, 'recall_word': 0.993772, 'acc_grapheme': 0.99375, 'acc_vowel': 0.997759, 'acc_consonant': 0.998157, 'acc_word': 0.993775, 'loss_grapheme': 0.027058, 'loss_vowel': 0.011597, 'loss_consonant': 0.008316, 'loss_word': 0.025833}\n",
      "    7 | 0.000181 | 160640/160678 | 13.8821 | 6.2762 | 14.50 |\n",
      "val: {'recall': 0.994682, 'recall_grapheme': 0.992701, 'recall_vowel': 0.997673, 'recall_consonant': 0.995654, 'recall_word': 0.993652, 'acc_grapheme': 0.993227, 'acc_vowel': 0.997859, 'acc_consonant': 0.997834, 'acc_word': 0.993701, 'loss_grapheme': 0.032046, 'loss_vowel': 0.01285, 'loss_consonant': 0.010273, 'loss_word': 0.029059}\n",
      "    8 | 0.000176 | 160640/160678 | 15.5810 | 6.2436 | 14.51 |\n",
      "val: {'recall': 0.995613, 'recall_grapheme': 0.99415, 'recall_vowel': 0.99825, 'recall_consonant': 0.995902, 'recall_word': 0.994804, 'acc_grapheme': 0.99497, 'acc_vowel': 0.998232, 'acc_consonant': 0.998307, 'acc_word': 0.994821, 'loss_grapheme': 0.022318, 'loss_vowel': 0.009554, 'loss_consonant': 0.007905, 'loss_word': 0.022014}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 | 0.000171 | 160640/160678 | 6.6217 | 6.1082 | 14.56 ||\n",
      "val: {'recall': 0.99469, 'recall_grapheme': 0.993247, 'recall_vowel': 0.997689, 'recall_consonant': 0.994578, 'recall_word': 0.993979, 'acc_grapheme': 0.993974, 'acc_vowel': 0.997958, 'acc_consonant': 0.997834, 'acc_word': 0.993974, 'loss_grapheme': 0.028306, 'loss_vowel': 0.012581, 'loss_consonant': 0.009692, 'loss_word': 0.026933}\n",
      "   10 | 0.000165 | 160640/160678 | 13.6986 | 5.9318 | 14.58 |\n",
      "val: {'recall': 0.994702, 'recall_grapheme': 0.992307, 'recall_vowel': 0.997553, 'recall_consonant': 0.996642, 'recall_word': 0.993668, 'acc_grapheme': 0.993576, 'acc_vowel': 0.997784, 'acc_consonant': 0.997859, 'acc_word': 0.993651, 'loss_grapheme': 0.029794, 'loss_vowel': 0.013136, 'loss_consonant': 0.01068, 'loss_word': 0.02701}\n",
      "   11 | 0.000159 | 160640/160678 | 0.8778 | 6.0795 | 14.56 ||\n",
      "val: {'recall': 0.995492, 'recall_grapheme': 0.99389, 'recall_vowel': 0.998107, 'recall_consonant': 0.996083, 'recall_word': 0.994334, 'acc_grapheme': 0.994497, 'acc_vowel': 0.998033, 'acc_consonant': 0.998083, 'acc_word': 0.994273, 'loss_grapheme': 0.026226, 'loss_vowel': 0.011517, 'loss_consonant': 0.009368, 'loss_word': 0.025096}\n",
      "   12 | 0.000152 | 160640/160678 | 7.9163 | 6.1094 | 14.55 ||\n",
      "val: {'recall': 0.995257, 'recall_grapheme': 0.994539, 'recall_vowel': 0.998184, 'recall_consonant': 0.993768, 'recall_word': 0.995155, 'acc_grapheme': 0.995095, 'acc_vowel': 0.998257, 'acc_consonant': 0.998406, 'acc_word': 0.995095, 'loss_grapheme': 0.022239, 'loss_vowel': 0.010225, 'loss_consonant': 0.007804, 'loss_word': 0.022467}\n",
      "   13 | 0.000145 | 160640/160678 | 10.5042 | 5.7655 | 14.58 |\n",
      "val: {'recall': 0.995381, 'recall_grapheme': 0.99384, 'recall_vowel': 0.998227, 'recall_consonant': 0.995615, 'recall_word': 0.994532, 'acc_grapheme': 0.994248, 'acc_vowel': 0.998157, 'acc_consonant': 0.998207, 'acc_word': 0.994622, 'loss_grapheme': 0.024945, 'loss_vowel': 0.00988, 'loss_consonant': 0.00736, 'loss_word': 0.023151}\n",
      "   14 | 0.000138 | 160640/160678 | 7.8879 | 5.9783 | 14.56 ||\n",
      "val: {'recall': 0.995498, 'recall_grapheme': 0.994183, 'recall_vowel': 0.998064, 'recall_consonant': 0.995562, 'recall_word': 0.994401, 'acc_grapheme': 0.994622, 'acc_vowel': 0.998008, 'acc_consonant': 0.998257, 'acc_word': 0.994472, 'loss_grapheme': 0.025039, 'loss_vowel': 0.011692, 'loss_consonant': 0.009033, 'loss_word': 0.024837}\n",
      "   15 | 0.000131 | 160640/160678 | 7.2542 | 5.8899 | 14.53 ||\n",
      "val: {'recall': 0.995755, 'recall_grapheme': 0.994133, 'recall_vowel': 0.998066, 'recall_consonant': 0.996688, 'recall_word': 0.994865, 'acc_grapheme': 0.994896, 'acc_vowel': 0.998157, 'acc_consonant': 0.998332, 'acc_word': 0.994821, 'loss_grapheme': 0.02314, 'loss_vowel': 0.01004, 'loss_consonant': 0.007035, 'loss_word': 0.022541}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   16 | 0.000123 | 160640/160678 | 0.2984 | 5.9174 | 14.54 ||\n",
      "val: {'recall': 0.996097, 'recall_grapheme': 0.994506, 'recall_vowel': 0.998594, 'recall_consonant': 0.99678, 'recall_word': 0.995224, 'acc_grapheme': 0.995369, 'acc_vowel': 0.998307, 'acc_consonant': 0.998282, 'acc_word': 0.995244, 'loss_grapheme': 0.02125, 'loss_vowel': 0.010461, 'loss_consonant': 0.007386, 'loss_word': 0.021545}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   17 | 0.000116 | 160640/160678 | 1.0962 | 6.0137 | 14.55 ||\n",
      "val: {'recall': 0.996006, 'recall_grapheme': 0.994431, 'recall_vowel': 0.998705, 'recall_consonant': 0.996457, 'recall_word': 0.994974, 'acc_grapheme': 0.995219, 'acc_vowel': 0.998531, 'acc_consonant': 0.998481, 'acc_word': 0.99497, 'loss_grapheme': 0.021622, 'loss_vowel': 0.008793, 'loss_consonant': 0.006416, 'loss_word': 0.021025}\n",
      "   18 | 0.000108 | 160640/160678 | 10.4995 | 5.8458 | 14.61 |\n",
      "val: {'recall': 0.996226, 'recall_grapheme': 0.995589, 'recall_vowel': 0.998654, 'recall_consonant': 0.995071, 'recall_word': 0.995838, 'acc_grapheme': 0.995966, 'acc_vowel': 0.998431, 'acc_consonant': 0.998606, 'acc_word': 0.995817, 'loss_grapheme': 0.021179, 'loss_vowel': 0.011431, 'loss_consonant': 0.008254, 'loss_word': 0.019089}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   19 | 0.000100 | 160640/160678 | 5.3443 | 5.7773 | 14.56 ||\n",
      "val: {'recall': 0.995637, 'recall_grapheme': 0.994006, 'recall_vowel': 0.9982, 'recall_consonant': 0.996335, 'recall_word': 0.994873, 'acc_grapheme': 0.99502, 'acc_vowel': 0.998182, 'acc_consonant': 0.998456, 'acc_word': 0.994871, 'loss_grapheme': 0.021282, 'loss_vowel': 0.009484, 'loss_consonant': 0.006517, 'loss_word': 0.02093}\n",
      "   20 | 0.000092 | 160640/160678 | 4.9738 | 5.8126 | 14.55 ||\n",
      "val: {'recall': 0.996204, 'recall_grapheme': 0.994935, 'recall_vowel': 0.998391, 'recall_consonant': 0.996556, 'recall_word': 0.995678, 'acc_grapheme': 0.995443, 'acc_vowel': 0.998382, 'acc_consonant': 0.998556, 'acc_word': 0.995692, 'loss_grapheme': 0.0203, 'loss_vowel': 0.008735, 'loss_consonant': 0.00644, 'loss_word': 0.019608}\n",
      "   21 | 0.000084 | 160640/160678 | 8.4557 | 5.6417 | 14.57 ||\n",
      "val: {'recall': 0.995613, 'recall_grapheme': 0.994315, 'recall_vowel': 0.998414, 'recall_consonant': 0.995409, 'recall_word': 0.994898, 'acc_grapheme': 0.994995, 'acc_vowel': 0.998382, 'acc_consonant': 0.998382, 'acc_word': 0.99497, 'loss_grapheme': 0.02259, 'loss_vowel': 0.008738, 'loss_consonant': 0.00701, 'loss_word': 0.021948}\n",
      "   22 | 0.000077 | 160640/160678 | 0.8960 | 5.5953 | 14.62 ||\n",
      "val: {'recall': 0.996864, 'recall_grapheme': 0.995341, 'recall_vowel': 0.998716, 'recall_consonant': 0.998059, 'recall_word': 0.995527, 'acc_grapheme': 0.995643, 'acc_vowel': 0.998456, 'acc_consonant': 0.998531, 'acc_word': 0.995543, 'loss_grapheme': 0.021051, 'loss_vowel': 0.009045, 'loss_consonant': 0.00687, 'loss_word': 0.019851}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold2_380.pth\n",
      "   23 | 0.000069 | 160640/160678 | 13.0289 | 5.7688 | 14.60 |\n",
      "val: {'recall': 0.995879, 'recall_grapheme': 0.994317, 'recall_vowel': 0.998509, 'recall_consonant': 0.996372, 'recall_word': 0.995036, 'acc_grapheme': 0.994945, 'acc_vowel': 0.998182, 'acc_consonant': 0.998506, 'acc_word': 0.994995, 'loss_grapheme': 0.022693, 'loss_vowel': 0.009591, 'loss_consonant': 0.006772, 'loss_word': 0.021833}\n",
      "   24 | 0.000062 | 160640/160678 | 0.4707 | 5.7198 | 14.56 ||\n",
      "val: {'recall': 0.996539, 'recall_grapheme': 0.995217, 'recall_vowel': 0.998611, 'recall_consonant': 0.997109, 'recall_word': 0.995909, 'acc_grapheme': 0.995792, 'acc_vowel': 0.998431, 'acc_consonant': 0.998581, 'acc_word': 0.995917, 'loss_grapheme': 0.020573, 'loss_vowel': 0.010598, 'loss_consonant': 0.007477, 'loss_word': 0.019469}\n",
      "   25 | 0.000055 | 160640/160678 | 5.7334 | 5.7725 | 14.62 ||\n",
      "val: {'recall': 0.995746, 'recall_grapheme': 0.994081, 'recall_vowel': 0.998133, 'recall_consonant': 0.996688, 'recall_word': 0.995112, 'acc_grapheme': 0.994871, 'acc_vowel': 0.998232, 'acc_consonant': 0.998357, 'acc_word': 0.995194, 'loss_grapheme': 0.023277, 'loss_vowel': 0.01014, 'loss_consonant': 0.007531, 'loss_word': 0.021244}\n",
      "   26 | 0.000048 | 160640/160678 | 9.9945 | 5.5902 | 14.58 ||\n",
      "val: {'recall': 0.996095, 'recall_grapheme': 0.994563, 'recall_vowel': 0.998619, 'recall_consonant': 0.996633, 'recall_word': 0.995524, 'acc_grapheme': 0.995493, 'acc_vowel': 0.998506, 'acc_consonant': 0.998332, 'acc_word': 0.995543, 'loss_grapheme': 0.021117, 'loss_vowel': 0.009623, 'loss_consonant': 0.007577, 'loss_word': 0.020458}\n",
      "   27 | 0.000041 | 160640/160678 | 5.8063 | 5.7269 | 14.57 ||\n",
      "val: {'recall': 0.996072, 'recall_grapheme': 0.994879, 'recall_vowel': 0.998499, 'recall_consonant': 0.996029, 'recall_word': 0.995496, 'acc_grapheme': 0.995369, 'acc_vowel': 0.998431, 'acc_consonant': 0.998506, 'acc_word': 0.995543, 'loss_grapheme': 0.019958, 'loss_vowel': 0.009022, 'loss_consonant': 0.00636, 'loss_word': 0.01997}\n",
      "   28 | 0.000037 | 105856/160678 | 0.2673 | 5.9008 | 9.62 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-ebf6e9a7b296>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-16e5a4d95497>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth, exist: True\n",
      "loading ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth...\n",
      "model file: ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth_swa, exist: False\n",
      "\n",
      "val: {'recall': 0.796988, 'recall_grapheme': 0.763845, 'recall_vowel': 0.863414, 'recall_consonant': 0.796848, 'recall_word': 0.762264, 'acc_grapheme': 0.493819, 'acc_vowel': 0.788904, 'acc_consonant': 0.767645, 'acc_word': 0.316245, 'loss_grapheme': 1.992506, 'loss_vowel': 0.626105, 'loss_consonant': 0.522644, 'loss_word': 3.290409}\n",
      "CYCLE: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 0.000292 | 160640/160716 | 6.7174 | 10.7151 | 13.99 ||\n",
      "val: {'recall': 0.992886, 'recall_grapheme': 0.989107, 'recall_vowel': 0.996141, 'recall_consonant': 0.997187, 'recall_word': 0.9882, 'acc_grapheme': 0.989607, 'acc_vowel': 0.996087, 'acc_consonant': 0.996087, 'acc_word': 0.988212, 'loss_grapheme': 0.129831, 'loss_vowel': 0.068911, 'loss_consonant': 0.05198, 'loss_word': 0.144907}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth\n",
      "    1 | 0.000543 | 160640/160716 | 7.1504 | 7.3232 | 14.15 ||\n",
      "val: {'recall': 0.992768, 'recall_grapheme': 0.989784, 'recall_vowel': 0.995191, 'recall_consonant': 0.996311, 'recall_word': 0.989335, 'acc_grapheme': 0.99018, 'acc_vowel': 0.995364, 'acc_consonant': 0.995464, 'acc_word': 0.988884, 'loss_grapheme': 0.069323, 'loss_vowel': 0.043396, 'loss_consonant': 0.0354, 'loss_word': 0.072684}\n",
      "    2 | 0.000476 | 160640/160716 | 16.1799 | 6.6101 | 14.24 |\n",
      "val: {'recall': 0.994403, 'recall_grapheme': 0.992025, 'recall_vowel': 0.996674, 'recall_consonant': 0.996886, 'recall_word': 0.992539, 'acc_grapheme': 0.992498, 'acc_vowel': 0.996486, 'acc_consonant': 0.99686, 'acc_word': 0.992299, 'loss_grapheme': 0.043576, 'loss_vowel': 0.027332, 'loss_consonant': 0.023003, 'loss_word': 0.041019}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth\n",
      "    3 | 0.000393 | 160640/160716 | 0.9650 | 6.9003 | 14.31 ||\n",
      "val: {'recall': 0.995804, 'recall_grapheme': 0.993698, 'recall_vowel': 0.997668, 'recall_consonant': 0.998151, 'recall_word': 0.993684, 'acc_grapheme': 0.993869, 'acc_vowel': 0.997308, 'acc_consonant': 0.997857, 'acc_word': 0.993645, 'loss_grapheme': 0.036312, 'loss_vowel': 0.018685, 'loss_consonant': 0.015354, 'loss_word': 0.03357}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth\n",
      "    4 | 0.000300 | 160640/160716 | 0.7891 | 6.5326 | 14.39 ||\n",
      "val: {'recall': 0.99667, 'recall_grapheme': 0.995389, 'recall_vowel': 0.997441, 'recall_consonant': 0.99846, 'recall_word': 0.994988, 'acc_grapheme': 0.99529, 'acc_vowel': 0.997732, 'acc_consonant': 0.99828, 'acc_word': 0.994966, 'loss_grapheme': 0.02539, 'loss_vowel': 0.014059, 'loss_consonant': 0.00927, 'loss_word': 0.024518}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth\n",
      "    5 | 0.000207 | 160640/160716 | 4.0624 | 6.0675 | 14.53 ||\n",
      "val: {'recall': 0.997223, 'recall_grapheme': 0.995809, 'recall_vowel': 0.998285, 'recall_consonant': 0.998987, 'recall_word': 0.995372, 'acc_grapheme': 0.995763, 'acc_vowel': 0.998081, 'acc_consonant': 0.998804, 'acc_word': 0.995364, 'loss_grapheme': 0.026658, 'loss_vowel': 0.016551, 'loss_consonant': 0.0111, 'loss_word': 0.024834}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth\n",
      "    6 | 0.000124 | 160640/160716 | 0.2344 | 6.0926 | 14.55 ||\n",
      "val: {'recall': 0.997462, 'recall_grapheme': 0.996485, 'recall_vowel': 0.997904, 'recall_consonant': 0.998974, 'recall_word': 0.995902, 'acc_grapheme': 0.996411, 'acc_vowel': 0.997931, 'acc_consonant': 0.998953, 'acc_word': 0.995913, 'loss_grapheme': 0.017905, 'loss_vowel': 0.010713, 'loss_consonant': 0.006275, 'loss_word': 0.018051}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth\n",
      "    7 | 0.000057 | 160640/160716 | 4.9114 | 5.7432 | 14.61 ||\n",
      "val: {'recall': 0.997225, 'recall_grapheme': 0.99577, 'recall_vowel': 0.998459, 'recall_consonant': 0.998899, 'recall_word': 0.995639, 'acc_grapheme': 0.995987, 'acc_vowel': 0.998255, 'acc_consonant': 0.998854, 'acc_word': 0.995614, 'loss_grapheme': 0.01913, 'loss_vowel': 0.010592, 'loss_consonant': 0.006204, 'loss_word': 0.020083}\n",
      "    8 | 0.000015 | 160640/160716 | 0.1540 | 5.8037 | 14.59 ||\n",
      "val: {'recall': 0.997597, 'recall_grapheme': 0.996428, 'recall_vowel': 0.998394, 'recall_consonant': 0.999137, 'recall_word': 0.996368, 'acc_grapheme': 0.996735, 'acc_vowel': 0.99843, 'acc_consonant': 0.998953, 'acc_word': 0.996361, 'loss_grapheme': 0.018075, 'loss_vowel': 0.010609, 'loss_consonant': 0.006052, 'loss_word': 0.017806}\n",
      "###>>>>> saved ./model4-ckps/tf_efficientnet_b4/model4_eb4_fold3_380.pth\n",
      "    9 | 0.000000 | 160640/160716 | 5.9176 | 5.2732 | 14.64 ||\n",
      "val: {'recall': 0.997146, 'recall_grapheme': 0.995898, 'recall_vowel': 0.998289, 'recall_consonant': 0.998501, 'recall_word': 0.995932, 'acc_grapheme': 0.996237, 'acc_vowel': 0.99823, 'acc_consonant': 0.998804, 'acc_word': 0.995938, 'loss_grapheme': 0.019165, 'loss_vowel': 0.010365, 'loss_consonant': 0.006386, 'loss_word': 0.019683}\n",
      "CYCLE: 2\n",
      "    0 | 0.000001 | 001152/160716 | 6.0654 | 4.3986 | 0.14 ||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-aad596905035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-f9be614ddf4d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-16e5a4d95497>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(args, model, train_loader, epoch, optimizer, lr_scheduler, grid)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582104595.1300395"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
