{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "from argparse import Namespace\n",
    "from sklearn.utils import shuffle\n",
    "from apex import amp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_map.csv\t\t       train.csv\r\n",
      "sample_submission.csv\t       train.csv.zip\r\n",
      "test.csv\t\t       train_image_data_0.parquet\r\n",
      "test_image_data_0.parquet      train_image_data_0.parquet.zip\r\n",
      "test_image_data_0.parquet.zip  train_image_data_1.parquet\r\n",
      "test_image_data_1.parquet      train_image_data_1.parquet.zip\r\n",
      "test_image_data_1.parquet.zip  train_image_data_2.parquet\r\n",
      "test_image_data_2.parquet      train_image_data_2.parquet.zip\r\n",
      "test_image_data_2.parquet.zip  train_image_data_3.parquet\r\n",
      "test_image_data_3.parquet      train_image_data_3.parquet.zip\r\n",
      "test_image_data_3.parquet.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/chec/data/bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chec/data/bengali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "class_map_df = pd.read_csv(f'{DATA_DIR}/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "\n",
    "def get_train_augs(p=1.):\n",
    "    return albu.Compose([\n",
    "        #albu.HorizontalFlip(.5),\n",
    "        albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5 ),\n",
    "        albu.Blur(blur_limit=3, p=0.3),\n",
    "        albu.OpticalDistortion(p=0.3),\n",
    "        albu.GaussNoise(p=0.3)\n",
    "        #albu.GridDistortion(p=.33),\n",
    "        #albu.HueSaturationValue(p=.33) # not for grey scale\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, img_df, train_mode=True, test_mode=False):\n",
    "        self.df = df\n",
    "        self.img_df = img_df\n",
    "        self.train_mode = train_mode\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self.get_img(row.image_id)\n",
    "        #print(img.shape)\n",
    "        #if self.train_mode:\n",
    "        #    augs = get_train_augs()\n",
    "        #    img = augs(image=img)['image']\n",
    "        \n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        #print('###', img.shape)\n",
    "        img = np.concatenate([img, img, img], 2)\n",
    "        #print('>>>', img.shape)\n",
    "        \n",
    "        # taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "        MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "        STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "        \n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, mean=MEAN, std=STD)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor([row.grapheme_root, row.vowel_diacritic, row.consonant_diacritic])\n",
    "\n",
    "    def get_img(self, img_id):\n",
    "        return 255 - self.img_df.loc[img_id].values.reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0, dev_mode=False):\n",
    "    train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    train_df = shuffle(train_df, random_state=1234)\n",
    "    print(train_df.shape)\n",
    "\n",
    "    if dev_mode:\n",
    "        img_df = pd.read_parquet(f'{DATA_DIR}/train_image_data_0.parquet').set_index('image_id')\n",
    "        train_df = train_df.iloc[:1000]\n",
    "    else:\n",
    "        img_dfs = [pd.read_parquet(f'{DATA_DIR}/train_image_data_{i}.parquet') for i in range(4)]\n",
    "        img_df = pd.concat(img_dfs, axis=0).set_index('image_id')\n",
    "    print(img_df.shape)\n",
    "    #split_index = int(len(train_df) * 0.9)\n",
    "    \n",
    "    #train = train_df.iloc[:split_index]\n",
    "    #val = train_df.iloc[split_index:]\n",
    "    \n",
    "    kf = StratifiedKFold(5, random_state=1234, shuffle=True)\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['grapheme_root'].values)):\n",
    "        if i == ifold:\n",
    "            #print(val_idx)\n",
    "            train = train_df.iloc[train_idx]\n",
    "            val = train_df.iloc[val_idx]\n",
    "            break\n",
    "    assert i == ifold\n",
    "    print(train.shape, val.shape)\n",
    "    \n",
    "    train_ds = BengaliDataset(train, img_df, True, False)\n",
    "    val_ds = BengaliDataset(val, img_df, False, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "    train_loader.num = len(train_ds)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=val_batch_size, shuffle=False, num_workers=8, drop_last=False)\n",
    "    val_loader.num = len(val_ds)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, val_loader = get_train_val_loaders(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet').cuda()\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.features(torch.randn((2, 3, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliNet(nn.Module):\n",
    "    def __init__(self, backbone_name):\n",
    "        super(BengaliNet, self).__init__()\n",
    "        self.n_grapheme = 168\n",
    "        self.n_vowel = 11\n",
    "        self.n_consonant = 7\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        self.num_classes = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        \n",
    "        #self.conv0 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            self.backbone = EfficientNet.from_pretrained(self.backbone_name)\n",
    "            self.fc = nn.Linear(self.backbone._fc.in_features, self.num_classes)\n",
    "        else:\n",
    "            self.backbone = pretrainedmodels.__dict__[self.backbone_name](num_classes=1000, pretrained='imagenet')\n",
    "            self.fc = nn.Linear(self.backbone.last_linear.in_features, self.num_classes)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        #self.fix_input_layer()\n",
    "        \n",
    "    def fix_input_layer(self):\n",
    "        if self.backbone_name in ['se_resnext50_32x4d', 'se_resnext101_32x4d', 'se_resnet50', 'senet154', 'se_resnet152', 'nasnetmobile', 'mobilenet', 'nasnetalarge']:\n",
    "            #self.backbone = eval(backbone_name)()\n",
    "            #print(self.backbone.layer0.conv1)\n",
    "            w = self.backbone.layer0.conv1.weight.data\n",
    "            self.backbone.layer0.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            #self.backbone.layer0.conv1.weight = torch.nn.Parameter(torch.cat((w, w[:, 2, :, :].unsqueeze(1)), dim=1))\n",
    "            self.backbone.layer0.conv1.weight = torch.nn.Parameter(w[:, 0, :, :].unsqueeze(1))\n",
    "        \n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        #x = F.dropout2d(x, 0.2, self.training)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.conv0(x)\n",
    "        #print(x.size())\n",
    "        if self.backbone_name.startswith('efficient'):\n",
    "            x = self.backbone.extract_features(x)\n",
    "        else:\n",
    "            x = self.backbone.features(x)\n",
    "        x = self.logits(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './models'\n",
    "def create_model(args):\n",
    "    model = BengaliNet(backbone_name=args.backbone)\n",
    "    model_file = os.path.join(MODEL_DIR, args.backbone, args.ckp_name)\n",
    "\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "\n",
    "    print('model file: {}, exist: {}'.format(model_file, os.path.exists(model_file)))\n",
    "\n",
    "    if args.predict and (not os.path.exists(model_file)):\n",
    "        raise AttributeError('model file does not exist: {}'.format(model_file))\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        print('loading {}...'.format(model_file))\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    \n",
    "    return model, model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet = BengaliNet('se_resnext50_32x4d').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnet(torch.randn((2, 1, 137, 236)).cuda()).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    #y = y.cpu().numpy()\n",
    "    # pred_y = [p.cpu().numpy() for p in pred_y]\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y_grapheme, average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y_vowel, average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y_consonant, average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    # print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "    #       f'total {final_score}, y {y.shape}')\n",
    "    return final_score\n",
    "\n",
    "def calc_metrics(preds0, preds1, preds2, y):\n",
    "    assert len(y) == len(preds0) == len(preds1) == len(preds2)\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(preds0, y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(preds1, y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(preds2, y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_recall_score = np.average(scores, weights=[2, 1, 1])\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['recall'] = round(final_recall_score, 6)\n",
    "    metrics['recall_grapheme'] = round(recall_grapheme, 6)\n",
    "    metrics['recall_vowel'] = round(recall_vowel, 6)\n",
    "    metrics['recall_consonant'] = round(recall_consonant, 6)\n",
    "    \n",
    "    metrics['acc_grapheme'] = round((preds0 == y[:, 0]).sum() / len(y), 6)\n",
    "    metrics['acc_vowel'] = round((preds1 == y[:, 1]).sum() / len(y), 6)\n",
    "    metrics['acc_consonant'] = round((preds2 == y[:, 2]).sum() / len(y), 6)\n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, y_true):\n",
    "    # outputs: (N, 182)\n",
    "    # y_true: (N, 3)\n",
    "    \n",
    "    outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "    loss0 = F.cross_entropy(outputs[0], y_true[:, 0], reduction='mean')\n",
    "    loss1 = F.cross_entropy(outputs[1], y_true[:, 1], reduction='mean')\n",
    "    loss2 = F.cross_entropy(outputs[2], y_true[:, 2], reduction='mean')\n",
    "    \n",
    "    return loss0 + loss1 + loss2 #, loss0.item(), loss1.item(), loss2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss0, loss1, loss2 = 0., 0., 0.\n",
    "    preds0, preds1,preds2 = [], [], []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            y_true.append(y)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            outputs = model(x)\n",
    "            outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "            preds0.append(torch.max(outputs[0], dim=1)[1])\n",
    "            preds1.append(torch.max(outputs[1], dim=1)[1])\n",
    "            preds2.append(torch.max(outputs[2], dim=1)[1])\n",
    "            loss0 += F.cross_entropy(outputs[0], y[:, 0], reduction='sum').item()\n",
    "            loss1 += F.cross_entropy(outputs[1], y[:, 1], reduction='sum').item()\n",
    "            loss2 += F.cross_entropy(outputs[2], y[:, 2], reduction='sum').item()\n",
    "            \n",
    "            # for debug\n",
    "            #metrics = {}\n",
    "            #metrics['loss_grapheme'] =  F.cross_entropy(outputs[0], y[:, 0], reduction='mean').item()\n",
    "            #metrics['loss_vowel'] =  F.cross_entropy(outputs[1], y[:, 1], reduction='mean').item()\n",
    "            #metrics['loss_consonant'] =  F.cross_entropy(outputs[2], y[:, 2], reduction='mean').item()\n",
    "            #return metrics\n",
    "    \n",
    "    preds0 = torch.cat(preds0, 0).cpu().numpy()\n",
    "    preds1 = torch.cat(preds1, 0).cpu().numpy()\n",
    "    preds2 = torch.cat(preds2, 0).cpu().numpy()\n",
    "    y_true = torch.cat(y_true, 0).numpy()\n",
    "    \n",
    "    #print('y_true:', y_true.shape)\n",
    "    #print('preds0:', preds0.shape)\n",
    "    \n",
    "    metrics = calc_metrics(preds0, preds1, preds2, y_true)\n",
    "    metrics['loss_grapheme'] = round(loss0 / val_loader.num, 6)\n",
    "    metrics['loss_vowel'] = round(loss1 / val_loader.num, 6)\n",
    "    metrics['loss_consonant'] = round(loss2 / val_loader.num, 6)\n",
    "    \n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrs(optimizer):\n",
    "    lrs = []\n",
    "    for pgs in optimizer.state_dict()['param_groups']:\n",
    "        lrs.append(pgs['lr'])\n",
    "    lrs = ['{:.6f}'.format(x) for x in lrs]\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "    parent_dir = os.path.dirname(model_file)\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, targets, alpha=1):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def mixup_criterion(outputs, targets):\n",
    "    targets1, targets2, lam = targets\n",
    "    #criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    return lam * criterion(outputs, targets1) + (1 - lam) * criterion(outputs, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2588587835461107"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from over9000.over9000 import Over9000\n",
    "from over9000.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    global model\n",
    "\n",
    "    if args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    elif args.optim == 'RAdam':\n",
    "        optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "    elif args.optim == 'Over9000':\n",
    "        optimizer = Over9000(model.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.)\n",
    "\n",
    "    if args.lrs == 'plateau':\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, min_lr=args.min_lr)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.t_max, eta_min=args.min_lr)\n",
    "        \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    best_metrics = 0.\n",
    "    best_key = 'recall'\n",
    "    \n",
    "    val_metrics = validate(model, val_loader)\n",
    "    print(val_metrics)\n",
    "    best_metrics = val_metrics[best_key]\n",
    "    \n",
    "    model.train()\n",
    "    #optimizer.zero_grad()\n",
    "\n",
    "    #if args.lrs == 'plateau':\n",
    "    #    lr_scheduler.step(best_metrics)\n",
    "    #else:\n",
    "    #    lr_scheduler.step()\n",
    "    train_iter = 0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        current_lr = get_lrs(optimizer)\n",
    "        bg = time.time()\n",
    "        for batch_idx, (img, targets) in enumerate(train_loader):\n",
    "            train_iter += 1\n",
    "            img, targets  = img.cuda(), targets.cuda()\n",
    "            #do_mixup = False #(np.random.random() < 0.4)\n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    img, targets = mixup(img, targets)\n",
    "            batch_size = img.size(0)\n",
    "          \n",
    "            \n",
    "            \n",
    "            #if do_mixup:\n",
    "            #    loss = mixup_criterion(outputs, targets)\n",
    "            #else:\n",
    "            #    loss = criterion(outputs, targets)\n",
    "            r = np.random.rand()\n",
    "            #if args.beta > 0 and r < args.cutmix_prob:\n",
    "            if r < 0.5:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(args.beta, args.beta)\n",
    "                rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "                target_a = targets\n",
    "                target_b = targets[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "                img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "                # compute output\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            else:\n",
    "                img, targets = mixup(img, targets)\n",
    "                outputs = model(img)\n",
    "                loss = mixup_criterion(outputs, targets)\n",
    "                #loss = criterion(outputs, targets)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            #if batch_idx % 4 == 0:\n",
    "            #    optimizer.step()\n",
    "            #    optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            print('\\r {:4d} | {:.6f} | {:06d}/{} | {:.4f} | {:.4f} |'.format(\n",
    "                epoch, float(current_lr[0]), batch_size*(batch_idx+1), train_loader.num, \n",
    "                loss.item(), train_loss/(batch_idx+1)), end='')\n",
    "\n",
    "            if train_iter > 0 and train_iter % args.iter_val == 0:\n",
    "                #outputs = torch.split(outputs, [168, 11, 7], dim=1)\n",
    "            \n",
    "                #preds0 = (torch.max(outputs[0], dim=1)[1]).cpu().numpy()\n",
    "                #preds1 = (torch.max(outputs[1], dim=1)[1]).cpu().numpy()\n",
    "                #preds2 = (torch.max(outputs[2], dim=1)[1]).cpu().numpy()\n",
    "                #train_metrics = calc_metrics(preds0, preds1, preds2, targets.cpu().numpy())\n",
    "                #print('train:', train_metrics)\n",
    "                #save_model(model, model_file+'_latest')\n",
    "                val_metrics = validate(model, val_loader)\n",
    "                print('\\nval:', val_metrics)\n",
    "                \n",
    "                if val_metrics[best_key] > best_metrics:\n",
    "                    best_metrics = val_metrics[best_key]\n",
    "                    save_model(model, model_file)\n",
    "                    print('** saved')\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if args.lrs == 'plateau':\n",
    "                    lr_scheduler.step(best_metrics)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "                current_lr = get_lrs(optimizer)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.backbone = 'se_resnext50_32x4d'\n",
    "args.ckp_name = 'model3_se_resnext50_fold0_mixup_cutmix.pth'\n",
    "args.predict = False\n",
    "args.optim = 'Adam'\n",
    "args.lr = 4e-5\n",
    "args.lrs = 'cosine'\n",
    "args.t_max = 12\n",
    "args.factor = 0.1\n",
    "args.patience = 0\n",
    "args.min_lr = 1e-6\n",
    "args.iter_val = 200\n",
    "args.num_epochs = 100000\n",
    "args.batch_size = 1024\n",
    "args.val_batch_size = 1024\n",
    "\n",
    "args.beta = 1.0\n",
    "args.cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 5)\n",
      "(200840, 32332)\n",
      "(160596, 5) (40244, 5)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_train_val_loaders(batch_size=args.batch_size, val_batch_size=args.val_batch_size, ifold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file: ./models/se_resnext50_32x4d/model3_se_resnext50_fold0_mixup_cutmix.pth, exist: True\n",
      "loading ./models/se_resnext50_32x4d/model3_se_resnext50_fold0_mixup_cutmix.pth...\n"
     ]
    }
   ],
   "source": [
    "model, model_file = create_model(args)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    model = nn.DataParallel(model)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.984545, 'recall_grapheme': 0.977655, 'recall_vowel': 0.991144, 'recall_consonant': 0.991725, 'acc_grapheme': 0.976518, 'acc_vowel': 0.993067, 'acc_consonant': 0.991204, 'loss_grapheme': 0.173279, 'loss_vowel': 0.118327, 'loss_consonant': 0.087629}\n",
      "    1 | 0.000040 | 045056/160596 | 1.1521 | 2.3504 |\n",
      "val: {'recall': 0.98306, 'recall_grapheme': 0.974674, 'recall_vowel': 0.990755, 'recall_consonant': 0.992138, 'acc_grapheme': 0.975052, 'acc_vowel': 0.992744, 'acc_consonant': 0.991104, 'loss_grapheme': 0.199909, 'loss_vowel': 0.159334, 'loss_consonant': 0.112617}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chec/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 | 0.000039 | 090112/160596 | 3.2593 | 2.0820 |\n",
      "val: {'recall': 0.983107, 'recall_grapheme': 0.976135, 'recall_vowel': 0.990384, 'recall_consonant': 0.989775, 'acc_grapheme': 0.974903, 'acc_vowel': 0.992272, 'acc_consonant': 0.99093, 'loss_grapheme': 0.227628, 'loss_vowel': 0.170546, 'loss_consonant': 0.114405}\n",
      "    3 | 0.000037 | 135168/160596 | 1.8368 | 2.2458 |\n",
      "val: {'recall': 0.98319, 'recall_grapheme': 0.97552, 'recall_vowel': 0.989779, 'recall_consonant': 0.991943, 'acc_grapheme': 0.975947, 'acc_vowel': 0.992073, 'acc_consonant': 0.991055, 'loss_grapheme': 0.178566, 'loss_vowel': 0.130174, 'loss_consonant': 0.096297}\n",
      "    5 | 0.000034 | 020480/160596 | 1.7801 | 2.2504 |\n",
      "val: {'recall': 0.982983, 'recall_grapheme': 0.974734, 'recall_vowel': 0.991155, 'recall_consonant': 0.99131, 'acc_grapheme': 0.975574, 'acc_vowel': 0.992471, 'acc_consonant': 0.990955, 'loss_grapheme': 0.207346, 'loss_vowel': 0.135512, 'loss_consonant': 0.102086}\n",
      "    6 | 0.000030 | 065536/160596 | 1.4792 | 2.1527 |\n",
      "val: {'recall': 0.983203, 'recall_grapheme': 0.975504, 'recall_vowel': 0.990768, 'recall_consonant': 0.991033, 'acc_grapheme': 0.975723, 'acc_vowel': 0.992595, 'acc_consonant': 0.991527, 'loss_grapheme': 0.220094, 'loss_vowel': 0.169348, 'loss_consonant': 0.121339}\n",
      "    7 | 0.000026 | 110592/160596 | 4.0099 | 2.0879 |\n",
      "val: {'recall': 0.983353, 'recall_grapheme': 0.976145, 'recall_vowel': 0.990323, 'recall_consonant': 0.9908, 'acc_grapheme': 0.976071, 'acc_vowel': 0.99262, 'acc_consonant': 0.991527, 'loss_grapheme': 0.212715, 'loss_vowel': 0.166925, 'loss_consonant': 0.114408}\n",
      "    8 | 0.000021 | 155648/160596 | 1.1271 | 2.1544 |\n",
      "val: {'recall': 0.983896, 'recall_grapheme': 0.976274, 'recall_vowel': 0.990737, 'recall_consonant': 0.992298, 'acc_grapheme': 0.976319, 'acc_vowel': 0.99262, 'acc_consonant': 0.991701, 'loss_grapheme': 0.190927, 'loss_vowel': 0.139528, 'loss_consonant': 0.101917}\n",
      "   10 | 0.000015 | 040960/160596 | 1.6063 | 1.8098 |\n",
      "val: {'recall': 0.983581, 'recall_grapheme': 0.975743, 'recall_vowel': 0.990368, 'recall_consonant': 0.992469, 'acc_grapheme': 0.976195, 'acc_vowel': 0.992695, 'acc_consonant': 0.9918, 'loss_grapheme': 0.169851, 'loss_vowel': 0.116632, 'loss_consonant': 0.087571}\n",
      "   11 | 0.000011 | 086016/160596 | 0.3584 | 2.0539 |\n",
      "val: {'recall': 0.984312, 'recall_grapheme': 0.977556, 'recall_vowel': 0.99111, 'recall_consonant': 0.991027, 'acc_grapheme': 0.976667, 'acc_vowel': 0.993092, 'acc_consonant': 0.991725, 'loss_grapheme': 0.19121, 'loss_vowel': 0.137541, 'loss_consonant': 0.098111}\n",
      "   12 | 0.000007 | 131072/160596 | 1.4426 | 2.0876 |\n",
      "val: {'recall': 0.983214, 'recall_grapheme': 0.975998, 'recall_vowel': 0.990376, 'recall_consonant': 0.990482, 'acc_grapheme': 0.976121, 'acc_vowel': 0.992595, 'acc_consonant': 0.991378, 'loss_grapheme': 0.191054, 'loss_vowel': 0.143376, 'loss_consonant': 0.101982}\n",
      "   14 | 0.000004 | 016384/160596 | 1.5201 | 1.7767 |\n",
      "val: {'recall': 0.983913, 'recall_grapheme': 0.976489, 'recall_vowel': 0.99142, 'recall_consonant': 0.991253, 'acc_grapheme': 0.976245, 'acc_vowel': 0.992968, 'acc_consonant': 0.991676, 'loss_grapheme': 0.187593, 'loss_vowel': 0.130776, 'loss_consonant': 0.094554}\n",
      "   15 | 0.000002 | 061440/160596 | 1.4449 | 2.1252 |\n",
      "val: {'recall': 0.983609, 'recall_grapheme': 0.976024, 'recall_vowel': 0.990366, 'recall_consonant': 0.992023, 'acc_grapheme': 0.976146, 'acc_vowel': 0.992372, 'acc_consonant': 0.991452, 'loss_grapheme': 0.185839, 'loss_vowel': 0.139884, 'loss_consonant': 0.099773}\n",
      "   16 | 0.000001 | 106496/160596 | 3.1937 | 2.0122 |\n",
      "val: {'recall': 0.983791, 'recall_grapheme': 0.976526, 'recall_vowel': 0.990719, 'recall_consonant': 0.991392, 'acc_grapheme': 0.976195, 'acc_vowel': 0.992769, 'acc_consonant': 0.991825, 'loss_grapheme': 0.208228, 'loss_vowel': 0.163577, 'loss_consonant': 0.110752}\n",
      "   17 | 0.000002 | 151552/160596 | 0.3995 | 2.1298 |\n",
      "val: {'recall': 0.984157, 'recall_grapheme': 0.976984, 'recall_vowel': 0.991208, 'recall_consonant': 0.991453, 'acc_grapheme': 0.976618, 'acc_vowel': 0.993117, 'acc_consonant': 0.992024, 'loss_grapheme': 0.159388, 'loss_vowel': 0.116521, 'loss_consonant': 0.085447}\n",
      "   19 | 0.000004 | 036864/160596 | 1.8878 | 2.1936 |\n",
      "val: {'recall': 0.983595, 'recall_grapheme': 0.975986, 'recall_vowel': 0.990964, 'recall_consonant': 0.991446, 'acc_grapheme': 0.976369, 'acc_vowel': 0.992595, 'acc_consonant': 0.991278, 'loss_grapheme': 0.198164, 'loss_vowel': 0.145719, 'loss_consonant': 0.105189}\n",
      "   20 | 0.000007 | 081920/160596 | 1.7526 | 2.5061 |\n",
      "val: {'recall': 0.983694, 'recall_grapheme': 0.976294, 'recall_vowel': 0.990894, 'recall_consonant': 0.991292, 'acc_grapheme': 0.97627, 'acc_vowel': 0.992794, 'acc_consonant': 0.991875, 'loss_grapheme': 0.195467, 'loss_vowel': 0.148775, 'loss_consonant': 0.10575}\n",
      "   21 | 0.000011 | 126976/160596 | 3.1401 | 2.1284 |\n",
      "val: {'recall': 0.984166, 'recall_grapheme': 0.97664, 'recall_vowel': 0.991079, 'recall_consonant': 0.992307, 'acc_grapheme': 0.976071, 'acc_vowel': 0.992893, 'acc_consonant': 0.991427, 'loss_grapheme': 0.196534, 'loss_vowel': 0.147278, 'loss_consonant': 0.105899}\n",
      "   23 | 0.000015 | 012288/160596 | 1.1183 | 2.0145 |\n",
      "val: {'recall': 0.983136, 'recall_grapheme': 0.975046, 'recall_vowel': 0.990271, 'recall_consonant': 0.992183, 'acc_grapheme': 0.975947, 'acc_vowel': 0.99257, 'acc_consonant': 0.991353, 'loss_grapheme': 0.179228, 'loss_vowel': 0.135746, 'loss_consonant': 0.09828}\n",
      "   24 | 0.000021 | 057344/160596 | 0.8413 | 1.8702 |\n",
      "val: {'recall': 0.984017, 'recall_grapheme': 0.976722, 'recall_vowel': 0.990517, 'recall_consonant': 0.992107, 'acc_grapheme': 0.976493, 'acc_vowel': 0.992769, 'acc_consonant': 0.991775, 'loss_grapheme': 0.176831, 'loss_vowel': 0.128135, 'loss_consonant': 0.093915}\n",
      "   25 | 0.000026 | 102400/160596 | 2.2713 | 2.1739 |\n",
      "val: {'recall': 0.983469, 'recall_grapheme': 0.976323, 'recall_vowel': 0.990487, 'recall_consonant': 0.990742, 'acc_grapheme': 0.976319, 'acc_vowel': 0.992719, 'acc_consonant': 0.991179, 'loss_grapheme': 0.204215, 'loss_vowel': 0.163171, 'loss_consonant': 0.11918}\n",
      "   26 | 0.000030 | 147456/160596 | 1.8712 | 1.9665 |\n",
      "val: {'recall': 0.98334, 'recall_grapheme': 0.975419, 'recall_vowel': 0.991331, 'recall_consonant': 0.991191, 'acc_grapheme': 0.97545, 'acc_vowel': 0.993092, 'acc_consonant': 0.991253, 'loss_grapheme': 0.198753, 'loss_vowel': 0.150681, 'loss_consonant': 0.104451}\n",
      "   28 | 0.000034 | 032768/160596 | 1.7050 | 2.2353 |\n",
      "val: {'recall': 0.982752, 'recall_grapheme': 0.975005, 'recall_vowel': 0.990793, 'recall_consonant': 0.990204, 'acc_grapheme': 0.975947, 'acc_vowel': 0.992968, 'acc_consonant': 0.990955, 'loss_grapheme': 0.199031, 'loss_vowel': 0.149976, 'loss_consonant': 0.105871}\n",
      "   29 | 0.000037 | 077824/160596 | 2.1795 | 2.2435 |\n",
      "val: {'recall': 0.983383, 'recall_grapheme': 0.975756, 'recall_vowel': 0.990955, 'recall_consonant': 0.991062, 'acc_grapheme': 0.976071, 'acc_vowel': 0.992446, 'acc_consonant': 0.991129, 'loss_grapheme': 0.17859, 'loss_vowel': 0.12376, 'loss_consonant': 0.094904}\n",
      "   30 | 0.000039 | 122880/160596 | 4.0802 | 2.1549 |\n",
      "val: {'recall': 0.983417, 'recall_grapheme': 0.975101, 'recall_vowel': 0.991267, 'recall_consonant': 0.992197, 'acc_grapheme': 0.976245, 'acc_vowel': 0.993042, 'acc_consonant': 0.991527, 'loss_grapheme': 0.202885, 'loss_vowel': 0.168471, 'loss_consonant': 0.116755}\n",
      "   32 | 0.000040 | 008192/160596 | 2.0488 | 1.7610 |\n",
      "val: {'recall': 0.98345, 'recall_grapheme': 0.975199, 'recall_vowel': 0.991077, 'recall_consonant': 0.992323, 'acc_grapheme': 0.975326, 'acc_vowel': 0.992794, 'acc_consonant': 0.991477, 'loss_grapheme': 0.179169, 'loss_vowel': 0.127043, 'loss_consonant': 0.097279}\n",
      "   33 | 0.000039 | 053248/160596 | 1.1774 | 2.1124 |\n",
      "val: {'recall': 0.983507, 'recall_grapheme': 0.975303, 'recall_vowel': 0.990916, 'recall_consonant': 0.992506, 'acc_grapheme': 0.975524, 'acc_vowel': 0.992769, 'acc_consonant': 0.991154, 'loss_grapheme': 0.246242, 'loss_vowel': 0.189214, 'loss_consonant': 0.126007}\n",
      "   34 | 0.000037 | 098304/160596 | 2.0255 | 2.2007 |\n",
      "val: {'recall': 0.983202, 'recall_grapheme': 0.975132, 'recall_vowel': 0.990596, 'recall_consonant': 0.991948, 'acc_grapheme': 0.975972, 'acc_vowel': 0.992744, 'acc_consonant': 0.991725, 'loss_grapheme': 0.204335, 'loss_vowel': 0.157085, 'loss_consonant': 0.108745}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 0.000034 | 143360/160596 | 2.4303 | 2.2059 |\n",
      "val: {'recall': 0.983978, 'recall_grapheme': 0.976505, 'recall_vowel': 0.991757, 'recall_consonant': 0.991143, 'acc_grapheme': 0.976717, 'acc_vowel': 0.993067, 'acc_consonant': 0.991552, 'loss_grapheme': 0.211782, 'loss_vowel': 0.154665, 'loss_consonant': 0.110613}\n",
      "   37 | 0.000030 | 028672/160596 | 3.3289 | 2.2846 |\n",
      "val: {'recall': 0.983313, 'recall_grapheme': 0.975249, 'recall_vowel': 0.990985, 'recall_consonant': 0.991769, 'acc_grapheme': 0.975226, 'acc_vowel': 0.992645, 'acc_consonant': 0.991328, 'loss_grapheme': 0.221947, 'loss_vowel': 0.16989, 'loss_consonant': 0.116109}\n",
      "   38 | 0.000026 | 073728/160596 | 2.3663 | 2.0064 |\n",
      "val: {'recall': 0.983726, 'recall_grapheme': 0.975903, 'recall_vowel': 0.991326, 'recall_consonant': 0.991774, 'acc_grapheme': 0.97617, 'acc_vowel': 0.993067, 'acc_consonant': 0.991527, 'loss_grapheme': 0.195528, 'loss_vowel': 0.148875, 'loss_consonant': 0.099527}\n",
      "   39 | 0.000021 | 118784/160596 | 3.7305 | 2.1773 |\n",
      "val: {'recall': 0.983977, 'recall_grapheme': 0.976666, 'recall_vowel': 0.991464, 'recall_consonant': 0.991112, 'acc_grapheme': 0.976021, 'acc_vowel': 0.992993, 'acc_consonant': 0.991676, 'loss_grapheme': 0.214783, 'loss_vowel': 0.17802, 'loss_consonant': 0.121714}\n",
      "   41 | 0.000015 | 004096/160596 | 3.9469 | 2.6367 |\n",
      "val: {'recall': 0.983659, 'recall_grapheme': 0.975661, 'recall_vowel': 0.991434, 'recall_consonant': 0.991881, 'acc_grapheme': 0.976518, 'acc_vowel': 0.992918, 'acc_consonant': 0.991378, 'loss_grapheme': 0.188911, 'loss_vowel': 0.151331, 'loss_consonant': 0.102942}\n",
      "   42 | 0.000011 | 049152/160596 | 0.3062 | 2.0639 |\n",
      "val: {'recall': 0.983922, 'recall_grapheme': 0.975837, 'recall_vowel': 0.991567, 'recall_consonant': 0.992446, 'acc_grapheme': 0.976419, 'acc_vowel': 0.992993, 'acc_consonant': 0.991825, 'loss_grapheme': 0.168625, 'loss_vowel': 0.119488, 'loss_consonant': 0.086373}\n",
      "   43 | 0.000007 | 094208/160596 | 1.1722 | 2.3471 |\n",
      "val: {'recall': 0.984614, 'recall_grapheme': 0.977942, 'recall_vowel': 0.991463, 'recall_consonant': 0.991108, 'acc_grapheme': 0.977388, 'acc_vowel': 0.993192, 'acc_consonant': 0.991775, 'loss_grapheme': 0.230903, 'loss_vowel': 0.17986, 'loss_consonant': 0.125225}\n",
      "** saved\n",
      "   44 | 0.000004 | 139264/160596 | 3.1369 | 2.1233 |\n",
      "val: {'recall': 0.984412, 'recall_grapheme': 0.976751, 'recall_vowel': 0.991655, 'recall_consonant': 0.99249, 'acc_grapheme': 0.976717, 'acc_vowel': 0.993216, 'acc_consonant': 0.992049, 'loss_grapheme': 0.216626, 'loss_vowel': 0.16561, 'loss_consonant': 0.11366}\n",
      "   46 | 0.000002 | 024576/160596 | 3.6826 | 1.7381 |\n",
      "val: {'recall': 0.984316, 'recall_grapheme': 0.976856, 'recall_vowel': 0.99133, 'recall_consonant': 0.992219, 'acc_grapheme': 0.97699, 'acc_vowel': 0.992993, 'acc_consonant': 0.991701, 'loss_grapheme': 0.181733, 'loss_vowel': 0.136477, 'loss_consonant': 0.096074}\n",
      "   47 | 0.000001 | 069632/160596 | 2.0340 | 2.1159 |\n",
      "val: {'recall': 0.98429, 'recall_grapheme': 0.976698, 'recall_vowel': 0.991428, 'recall_consonant': 0.992335, 'acc_grapheme': 0.976891, 'acc_vowel': 0.993018, 'acc_consonant': 0.991825, 'loss_grapheme': 0.199419, 'loss_vowel': 0.161066, 'loss_consonant': 0.108818}\n",
      "   48 | 0.000002 | 114688/160596 | 2.7517 | 2.0549 |\n",
      "val: {'recall': 0.984666, 'recall_grapheme': 0.977209, 'recall_vowel': 0.991674, 'recall_consonant': 0.992573, 'acc_grapheme': 0.977214, 'acc_vowel': 0.993316, 'acc_consonant': 0.991974, 'loss_grapheme': 0.157037, 'loss_vowel': 0.114529, 'loss_consonant': 0.084651}\n",
      "** saved\n",
      "   49 | 0.000004 | 159744/160596 | 2.4991 | 2.1191 |\n",
      "val: {'recall': 0.984478, 'recall_grapheme': 0.977747, 'recall_vowel': 0.991128, 'recall_consonant': 0.99129, 'acc_grapheme': 0.977462, 'acc_vowel': 0.993067, 'acc_consonant': 0.9918, 'loss_grapheme': 0.245139, 'loss_vowel': 0.197996, 'loss_consonant': 0.132535}\n",
      "   51 | 0.000007 | 045056/160596 | 1.4078 | 2.3761 |\n",
      "val: {'recall': 0.98408, 'recall_grapheme': 0.976499, 'recall_vowel': 0.991837, 'recall_consonant': 0.991485, 'acc_grapheme': 0.976642, 'acc_vowel': 0.993316, 'acc_consonant': 0.991725, 'loss_grapheme': 0.211412, 'loss_vowel': 0.163441, 'loss_consonant': 0.114048}\n",
      "   52 | 0.000011 | 090112/160596 | 1.9105 | 2.1898 |\n",
      "val: {'recall': 0.983617, 'recall_grapheme': 0.975635, 'recall_vowel': 0.991115, 'recall_consonant': 0.992083, 'acc_grapheme': 0.976245, 'acc_vowel': 0.992893, 'acc_consonant': 0.991378, 'loss_grapheme': 0.21598, 'loss_vowel': 0.17315, 'loss_consonant': 0.120317}\n",
      "   53 | 0.000015 | 135168/160596 | 3.4939 | 2.0017 |\n",
      "val: {'recall': 0.98443, 'recall_grapheme': 0.977174, 'recall_vowel': 0.99171, 'recall_consonant': 0.991661, 'acc_grapheme': 0.977065, 'acc_vowel': 0.993142, 'acc_consonant': 0.992222, 'loss_grapheme': 0.198313, 'loss_vowel': 0.155062, 'loss_consonant': 0.108715}\n",
      "   55 | 0.000020 | 020480/160596 | 3.4886 | 1.9367 |\n",
      "val: {'recall': 0.984324, 'recall_grapheme': 0.97667, 'recall_vowel': 0.991311, 'recall_consonant': 0.992645, 'acc_grapheme': 0.976593, 'acc_vowel': 0.992918, 'acc_consonant': 0.991477, 'loss_grapheme': 0.191758, 'loss_vowel': 0.147734, 'loss_consonant': 0.099703}\n",
      "   56 | 0.000026 | 065536/160596 | 1.9028 | 2.0927 |\n",
      "val: {'recall': 0.983765, 'recall_grapheme': 0.975339, 'recall_vowel': 0.992065, 'recall_consonant': 0.992318, 'acc_grapheme': 0.976444, 'acc_vowel': 0.992719, 'acc_consonant': 0.991502, 'loss_grapheme': 0.173698, 'loss_vowel': 0.135342, 'loss_consonant': 0.10018}\n",
      "   57 | 0.000030 | 110592/160596 | 1.5985 | 2.1564 |\n",
      "val: {'recall': 0.984353, 'recall_grapheme': 0.977052, 'recall_vowel': 0.991095, 'recall_consonant': 0.992211, 'acc_grapheme': 0.976543, 'acc_vowel': 0.992943, 'acc_consonant': 0.991676, 'loss_grapheme': 0.184674, 'loss_vowel': 0.136053, 'loss_consonant': 0.096289}\n",
      "   58 | 0.000034 | 155648/160596 | 1.8582 | 2.1374 |\n",
      "val: {'recall': 0.984504, 'recall_grapheme': 0.977054, 'recall_vowel': 0.992201, 'recall_consonant': 0.991709, 'acc_grapheme': 0.976071, 'acc_vowel': 0.993042, 'acc_consonant': 0.991303, 'loss_grapheme': 0.222034, 'loss_vowel': 0.164507, 'loss_consonant': 0.116478}\n",
      "   60 | 0.000037 | 040960/160596 | 0.6291 | 2.1420 |\n",
      "val: {'recall': 0.983534, 'recall_grapheme': 0.975883, 'recall_vowel': 0.990724, 'recall_consonant': 0.991646, 'acc_grapheme': 0.97545, 'acc_vowel': 0.992545, 'acc_consonant': 0.991601, 'loss_grapheme': 0.189013, 'loss_vowel': 0.129429, 'loss_consonant': 0.096371}\n",
      "   61 | 0.000039 | 086016/160596 | 2.0438 | 1.9575 |\n",
      "val: {'recall': 0.983872, 'recall_grapheme': 0.976027, 'recall_vowel': 0.99088, 'recall_consonant': 0.992555, 'acc_grapheme': 0.976245, 'acc_vowel': 0.992695, 'acc_consonant': 0.991701, 'loss_grapheme': 0.168245, 'loss_vowel': 0.110159, 'loss_consonant': 0.082888}\n",
      "   62 | 0.000040 | 131072/160596 | 1.3166 | 1.9622 |\n",
      "val: {'recall': 0.984321, 'recall_grapheme': 0.977377, 'recall_vowel': 0.991963, 'recall_consonant': 0.990565, 'acc_grapheme': 0.976866, 'acc_vowel': 0.992993, 'acc_consonant': 0.991552, 'loss_grapheme': 0.173633, 'loss_vowel': 0.137013, 'loss_consonant': 0.099085}\n",
      "   65 | 0.000037 | 061440/160596 | 1.7415 | 2.0521 |\n",
      "val: {'recall': 0.983705, 'recall_grapheme': 0.975423, 'recall_vowel': 0.991504, 'recall_consonant': 0.992468, 'acc_grapheme': 0.975375, 'acc_vowel': 0.993067, 'acc_consonant': 0.9918, 'loss_grapheme': 0.188001, 'loss_vowel': 0.134139, 'loss_consonant': 0.099281}\n",
      "   66 | 0.000034 | 106496/160596 | 2.6750 | 2.1412 |\n",
      "val: {'recall': 0.98375, 'recall_grapheme': 0.975986, 'recall_vowel': 0.992033, 'recall_consonant': 0.990997, 'acc_grapheme': 0.975499, 'acc_vowel': 0.993316, 'acc_consonant': 0.991154, 'loss_grapheme': 0.238287, 'loss_vowel': 0.18502, 'loss_consonant': 0.1245}\n",
      "   67 | 0.000030 | 151552/160596 | 0.9322 | 2.0916 |\n",
      "val: {'recall': 0.984357, 'recall_grapheme': 0.976669, 'recall_vowel': 0.991402, 'recall_consonant': 0.992686, 'acc_grapheme': 0.976444, 'acc_vowel': 0.993018, 'acc_consonant': 0.991402, 'loss_grapheme': 0.204244, 'loss_vowel': 0.166957, 'loss_consonant': 0.11634}\n",
      "   69 | 0.000026 | 036864/160596 | 0.6086 | 1.8172 |\n",
      "val: {'recall': 0.98472, 'recall_grapheme': 0.977447, 'recall_vowel': 0.9921, 'recall_consonant': 0.991884, 'acc_grapheme': 0.976295, 'acc_vowel': 0.993142, 'acc_consonant': 0.991303, 'loss_grapheme': 0.15937, 'loss_vowel': 0.107531, 'loss_consonant': 0.078021}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "   70 | 0.000021 | 081920/160596 | 2.3546 | 2.2292 |\n",
      "val: {'recall': 0.984699, 'recall_grapheme': 0.977967, 'recall_vowel': 0.991848, 'recall_consonant': 0.991015, 'acc_grapheme': 0.976792, 'acc_vowel': 0.992893, 'acc_consonant': 0.99175, 'loss_grapheme': 0.238455, 'loss_vowel': 0.189144, 'loss_consonant': 0.130037}\n",
      "   71 | 0.000015 | 126976/160596 | 4.1406 | 2.1631 |\n",
      "val: {'recall': 0.984664, 'recall_grapheme': 0.977666, 'recall_vowel': 0.992009, 'recall_consonant': 0.991316, 'acc_grapheme': 0.976469, 'acc_vowel': 0.99339, 'acc_consonant': 0.991701, 'loss_grapheme': 0.217698, 'loss_vowel': 0.167465, 'loss_consonant': 0.115071}\n",
      "   73 | 0.000011 | 012288/160596 | 1.4217 | 1.9212 |\n",
      "val: {'recall': 0.984486, 'recall_grapheme': 0.976901, 'recall_vowel': 0.992169, 'recall_consonant': 0.991972, 'acc_grapheme': 0.977115, 'acc_vowel': 0.993291, 'acc_consonant': 0.991651, 'loss_grapheme': 0.184145, 'loss_vowel': 0.136103, 'loss_consonant': 0.097535}\n",
      "   74 | 0.000007 | 057344/160596 | 1.1709 | 1.9650 |\n",
      "val: {'recall': 0.985687, 'recall_grapheme': 0.978801, 'recall_vowel': 0.992708, 'recall_consonant': 0.99244, 'acc_grapheme': 0.977214, 'acc_vowel': 0.993539, 'acc_consonant': 0.992024, 'loss_grapheme': 0.185879, 'loss_vowel': 0.130159, 'loss_consonant': 0.093209}\n",
      "** saved\n",
      "   75 | 0.000004 | 102400/160596 | 3.5318 | 1.9858 |\n",
      "val: {'recall': 0.985104, 'recall_grapheme': 0.977791, 'recall_vowel': 0.992366, 'recall_consonant': 0.992468, 'acc_grapheme': 0.976469, 'acc_vowel': 0.99344, 'acc_consonant': 0.9918, 'loss_grapheme': 0.198147, 'loss_vowel': 0.158319, 'loss_consonant': 0.109067}\n",
      "   76 | 0.000002 | 147456/160596 | 1.9990 | 2.0929 |\n",
      "val: {'recall': 0.984798, 'recall_grapheme': 0.977931, 'recall_vowel': 0.992405, 'recall_consonant': 0.990927, 'acc_grapheme': 0.977313, 'acc_vowel': 0.993515, 'acc_consonant': 0.9918, 'loss_grapheme': 0.195675, 'loss_vowel': 0.152045, 'loss_consonant': 0.108777}\n",
      "   78 | 0.000001 | 032768/160596 | 2.9864 | 2.4562 |\n",
      "val: {'recall': 0.98506, 'recall_grapheme': 0.978448, 'recall_vowel': 0.992371, 'recall_consonant': 0.990971, 'acc_grapheme': 0.977164, 'acc_vowel': 0.993465, 'acc_consonant': 0.99175, 'loss_grapheme': 0.253634, 'loss_vowel': 0.204116, 'loss_consonant': 0.13943}\n",
      "   79 | 0.000002 | 077824/160596 | 0.3292 | 1.8300 |\n",
      "val: {'recall': 0.985127, 'recall_grapheme': 0.978069, 'recall_vowel': 0.991982, 'recall_consonant': 0.992389, 'acc_grapheme': 0.97709, 'acc_vowel': 0.993291, 'acc_consonant': 0.991875, 'loss_grapheme': 0.161711, 'loss_vowel': 0.113101, 'loss_consonant': 0.084886}\n",
      "   80 | 0.000004 | 122880/160596 | 2.1248 | 1.9991 |\n",
      "val: {'recall': 0.984889, 'recall_grapheme': 0.977649, 'recall_vowel': 0.991751, 'recall_consonant': 0.992506, 'acc_grapheme': 0.976593, 'acc_vowel': 0.993192, 'acc_consonant': 0.991949, 'loss_grapheme': 0.157997, 'loss_vowel': 0.107573, 'loss_consonant': 0.078578}\n",
      "   82 | 0.000007 | 008192/160596 | 1.5200 | 2.0578 |\n",
      "val: {'recall': 0.985053, 'recall_grapheme': 0.977883, 'recall_vowel': 0.992012, 'recall_consonant': 0.992435, 'acc_grapheme': 0.976891, 'acc_vowel': 0.993415, 'acc_consonant': 0.991899, 'loss_grapheme': 0.190092, 'loss_vowel': 0.139401, 'loss_consonant': 0.099547}\n",
      "   83 | 0.000011 | 053248/160596 | 3.5821 | 1.8038 |\n",
      "val: {'recall': 0.985165, 'recall_grapheme': 0.977983, 'recall_vowel': 0.992066, 'recall_consonant': 0.99263, 'acc_grapheme': 0.977363, 'acc_vowel': 0.993291, 'acc_consonant': 0.99185, 'loss_grapheme': 0.197401, 'loss_vowel': 0.146407, 'loss_consonant': 0.107817}\n",
      "   84 | 0.000015 | 098304/160596 | 3.2730 | 2.1121 |\n",
      "val: {'recall': 0.984667, 'recall_grapheme': 0.977932, 'recall_vowel': 0.992142, 'recall_consonant': 0.990664, 'acc_grapheme': 0.97704, 'acc_vowel': 0.993266, 'acc_consonant': 0.991552, 'loss_grapheme': 0.19801, 'loss_vowel': 0.147947, 'loss_consonant': 0.105605}\n",
      "   85 | 0.000021 | 143360/160596 | 1.2462 | 2.1299 |\n",
      "val: {'recall': 0.985148, 'recall_grapheme': 0.978067, 'recall_vowel': 0.991875, 'recall_consonant': 0.992585, 'acc_grapheme': 0.977413, 'acc_vowel': 0.993216, 'acc_consonant': 0.991527, 'loss_grapheme': 0.234361, 'loss_vowel': 0.183773, 'loss_consonant': 0.125676}\n",
      "   87 | 0.000026 | 028672/160596 | 3.5182 | 1.8713 |\n",
      "val: {'recall': 0.98499, 'recall_grapheme': 0.977848, 'recall_vowel': 0.991859, 'recall_consonant': 0.992405, 'acc_grapheme': 0.976891, 'acc_vowel': 0.993042, 'acc_consonant': 0.991427, 'loss_grapheme': 0.204666, 'loss_vowel': 0.154945, 'loss_consonant': 0.104623}\n",
      "   88 | 0.000030 | 073728/160596 | 0.0319 | 2.0183 |\n",
      "val: {'recall': 0.984794, 'recall_grapheme': 0.977265, 'recall_vowel': 0.992016, 'recall_consonant': 0.992628, 'acc_grapheme': 0.976966, 'acc_vowel': 0.993589, 'acc_consonant': 0.991626, 'loss_grapheme': 0.185338, 'loss_vowel': 0.135338, 'loss_consonant': 0.103296}\n",
      "   89 | 0.000034 | 118784/160596 | 0.6723 | 2.1245 |\n",
      "val: {'recall': 0.984222, 'recall_grapheme': 0.976464, 'recall_vowel': 0.991556, 'recall_consonant': 0.992404, 'acc_grapheme': 0.976444, 'acc_vowel': 0.992869, 'acc_consonant': 0.991576, 'loss_grapheme': 0.174633, 'loss_vowel': 0.11682, 'loss_consonant': 0.089302}\n",
      "   91 | 0.000037 | 004096/160596 | 3.6653 | 2.8991 |\n",
      "val: {'recall': 0.983747, 'recall_grapheme': 0.975714, 'recall_vowel': 0.991938, 'recall_consonant': 0.991619, 'acc_grapheme': 0.976121, 'acc_vowel': 0.992918, 'acc_consonant': 0.9918, 'loss_grapheme': 0.229217, 'loss_vowel': 0.179757, 'loss_consonant': 0.128925}\n",
      "   92 | 0.000039 | 049152/160596 | 0.8616 | 1.9677 |\n",
      "val: {'recall': 0.983891, 'recall_grapheme': 0.976745, 'recall_vowel': 0.991446, 'recall_consonant': 0.990628, 'acc_grapheme': 0.976792, 'acc_vowel': 0.992869, 'acc_consonant': 0.991452, 'loss_grapheme': 0.180711, 'loss_vowel': 0.120525, 'loss_consonant': 0.091805}\n",
      "   93 | 0.000040 | 094208/160596 | 1.2149 | 2.3107 |\n",
      "val: {'recall': 0.984127, 'recall_grapheme': 0.976413, 'recall_vowel': 0.991655, 'recall_consonant': 0.992028, 'acc_grapheme': 0.976146, 'acc_vowel': 0.993092, 'acc_consonant': 0.991676, 'loss_grapheme': 0.190482, 'loss_vowel': 0.146105, 'loss_consonant': 0.101235}\n",
      "   94 | 0.000039 | 139264/160596 | 1.3232 | 2.0533 |\n",
      "val: {'recall': 0.984308, 'recall_grapheme': 0.976887, 'recall_vowel': 0.991506, 'recall_consonant': 0.991952, 'acc_grapheme': 0.97699, 'acc_vowel': 0.992968, 'acc_consonant': 0.991626, 'loss_grapheme': 0.222566, 'loss_vowel': 0.180951, 'loss_consonant': 0.115923}\n",
      "   96 | 0.000037 | 024576/160596 | 2.7146 | 2.3803 |\n",
      "val: {'recall': 0.984877, 'recall_grapheme': 0.978026, 'recall_vowel': 0.991292, 'recall_consonant': 0.992165, 'acc_grapheme': 0.977289, 'acc_vowel': 0.993117, 'acc_consonant': 0.99185, 'loss_grapheme': 0.209782, 'loss_vowel': 0.169036, 'loss_consonant': 0.122322}\n",
      "   97 | 0.000034 | 069632/160596 | 3.6591 | 2.2508 |\n",
      "val: {'recall': 0.984701, 'recall_grapheme': 0.977368, 'recall_vowel': 0.991646, 'recall_consonant': 0.99242, 'acc_grapheme': 0.977264, 'acc_vowel': 0.993713, 'acc_consonant': 0.991402, 'loss_grapheme': 0.168277, 'loss_vowel': 0.115262, 'loss_consonant': 0.086675}\n",
      "   98 | 0.000030 | 114688/160596 | 2.9219 | 2.0327 |\n",
      "val: {'recall': 0.984983, 'recall_grapheme': 0.978054, 'recall_vowel': 0.991542, 'recall_consonant': 0.992284, 'acc_grapheme': 0.977139, 'acc_vowel': 0.993192, 'acc_consonant': 0.991999, 'loss_grapheme': 0.209731, 'loss_vowel': 0.161684, 'loss_consonant': 0.113799}\n",
      "   99 | 0.000026 | 159744/160596 | 1.3631 | 2.0675 |\n",
      "val: {'recall': 0.985109, 'recall_grapheme': 0.978241, 'recall_vowel': 0.991252, 'recall_consonant': 0.992704, 'acc_grapheme': 0.978084, 'acc_vowel': 0.993216, 'acc_consonant': 0.992173, 'loss_grapheme': 0.171513, 'loss_vowel': 0.116294, 'loss_consonant': 0.083695}\n",
      "  101 | 0.000021 | 045056/160596 | 1.1503 | 2.0532 |\n",
      "val: {'recall': 0.984516, 'recall_grapheme': 0.976847, 'recall_vowel': 0.992275, 'recall_consonant': 0.992096, 'acc_grapheme': 0.977736, 'acc_vowel': 0.99349, 'acc_consonant': 0.992123, 'loss_grapheme': 0.170137, 'loss_vowel': 0.113179, 'loss_consonant': 0.091522}\n",
      "  102 | 0.000015 | 090112/160596 | 1.5498 | 2.3180 |\n",
      "val: {'recall': 0.984795, 'recall_grapheme': 0.977519, 'recall_vowel': 0.991871, 'recall_consonant': 0.992271, 'acc_grapheme': 0.977462, 'acc_vowel': 0.99339, 'acc_consonant': 0.991701, 'loss_grapheme': 0.225432, 'loss_vowel': 0.177863, 'loss_consonant': 0.120941}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 | 0.000011 | 135168/160596 | 1.9478 | 2.0246 |\n",
      "val: {'recall': 0.984892, 'recall_grapheme': 0.977473, 'recall_vowel': 0.991793, 'recall_consonant': 0.992828, 'acc_grapheme': 0.977388, 'acc_vowel': 0.993365, 'acc_consonant': 0.991974, 'loss_grapheme': 0.167989, 'loss_vowel': 0.119791, 'loss_consonant': 0.092011}\n",
      "  105 | 0.000007 | 020480/160596 | 3.5860 | 2.2800 |\n",
      "val: {'recall': 0.984914, 'recall_grapheme': 0.977796, 'recall_vowel': 0.991765, 'recall_consonant': 0.992297, 'acc_grapheme': 0.977214, 'acc_vowel': 0.993564, 'acc_consonant': 0.992123, 'loss_grapheme': 0.212985, 'loss_vowel': 0.170657, 'loss_consonant': 0.118314}\n",
      "  106 | 0.000004 | 065536/160596 | 1.3849 | 1.9246 |\n",
      "val: {'recall': 0.985031, 'recall_grapheme': 0.978166, 'recall_vowel': 0.991633, 'recall_consonant': 0.992159, 'acc_grapheme': 0.977388, 'acc_vowel': 0.993341, 'acc_consonant': 0.99185, 'loss_grapheme': 0.163974, 'loss_vowel': 0.117736, 'loss_consonant': 0.087004}\n",
      "  107 | 0.000002 | 110592/160596 | 0.8148 | 2.1343 |\n",
      "val: {'recall': 0.98526, 'recall_grapheme': 0.978126, 'recall_vowel': 0.992208, 'recall_consonant': 0.992579, 'acc_grapheme': 0.977313, 'acc_vowel': 0.993564, 'acc_consonant': 0.991924, 'loss_grapheme': 0.191371, 'loss_vowel': 0.148157, 'loss_consonant': 0.105382}\n",
      "  108 | 0.000001 | 155648/160596 | 1.7930 | 2.0966 |\n",
      "val: {'recall': 0.984756, 'recall_grapheme': 0.977905, 'recall_vowel': 0.991944, 'recall_consonant': 0.991272, 'acc_grapheme': 0.977313, 'acc_vowel': 0.993415, 'acc_consonant': 0.992098, 'loss_grapheme': 0.220036, 'loss_vowel': 0.183654, 'loss_consonant': 0.122248}\n",
      "  110 | 0.000002 | 040960/160596 | 1.5782 | 2.0061 |\n",
      "val: {'recall': 0.985266, 'recall_grapheme': 0.9782, 'recall_vowel': 0.992021, 'recall_consonant': 0.992641, 'acc_grapheme': 0.97781, 'acc_vowel': 0.993564, 'acc_consonant': 0.992098, 'loss_grapheme': 0.19413, 'loss_vowel': 0.1537, 'loss_consonant': 0.107831}\n",
      "  111 | 0.000004 | 086016/160596 | 1.2896 | 2.0434 |\n",
      "val: {'recall': 0.985498, 'recall_grapheme': 0.978701, 'recall_vowel': 0.991941, 'recall_consonant': 0.992648, 'acc_grapheme': 0.977786, 'acc_vowel': 0.99344, 'acc_consonant': 0.992198, 'loss_grapheme': 0.206055, 'loss_vowel': 0.162003, 'loss_consonant': 0.112148}\n",
      "  112 | 0.000007 | 131072/160596 | 2.8682 | 2.0948 |\n",
      "val: {'recall': 0.984939, 'recall_grapheme': 0.978218, 'recall_vowel': 0.992057, 'recall_consonant': 0.991264, 'acc_grapheme': 0.977686, 'acc_vowel': 0.993515, 'acc_consonant': 0.992098, 'loss_grapheme': 0.244017, 'loss_vowel': 0.197354, 'loss_consonant': 0.132277}\n",
      "  114 | 0.000011 | 016384/160596 | 0.6349 | 1.8123 |\n",
      "val: {'recall': 0.984914, 'recall_grapheme': 0.977671, 'recall_vowel': 0.992044, 'recall_consonant': 0.992268, 'acc_grapheme': 0.977388, 'acc_vowel': 0.993365, 'acc_consonant': 0.991974, 'loss_grapheme': 0.172428, 'loss_vowel': 0.124754, 'loss_consonant': 0.092346}\n",
      "  115 | 0.000015 | 061440/160596 | 1.5504 | 2.1863 |\n",
      "val: {'recall': 0.984951, 'recall_grapheme': 0.977686, 'recall_vowel': 0.992336, 'recall_consonant': 0.992095, 'acc_grapheme': 0.976642, 'acc_vowel': 0.993291, 'acc_consonant': 0.991775, 'loss_grapheme': 0.212403, 'loss_vowel': 0.155532, 'loss_consonant': 0.112611}\n",
      "  116 | 0.000021 | 106496/160596 | 0.6193 | 2.0789 |\n",
      "val: {'recall': 0.985013, 'recall_grapheme': 0.977478, 'recall_vowel': 0.992148, 'recall_consonant': 0.992949, 'acc_grapheme': 0.977786, 'acc_vowel': 0.993192, 'acc_consonant': 0.991825, 'loss_grapheme': 0.1955, 'loss_vowel': 0.153589, 'loss_consonant': 0.111765}\n",
      "  117 | 0.000026 | 151552/160596 | 3.8417 | 2.1038 |\n",
      "val: {'recall': 0.985136, 'recall_grapheme': 0.977963, 'recall_vowel': 0.992134, 'recall_consonant': 0.992483, 'acc_grapheme': 0.977164, 'acc_vowel': 0.993341, 'acc_consonant': 0.991974, 'loss_grapheme': 0.177482, 'loss_vowel': 0.12141, 'loss_consonant': 0.089177}\n",
      "  119 | 0.000030 | 036864/160596 | 2.3660 | 2.4024 |\n",
      "val: {'recall': 0.98542, 'recall_grapheme': 0.978359, 'recall_vowel': 0.99235, 'recall_consonant': 0.992611, 'acc_grapheme': 0.977537, 'acc_vowel': 0.993465, 'acc_consonant': 0.992173, 'loss_grapheme': 0.258064, 'loss_vowel': 0.209889, 'loss_consonant': 0.136132}\n",
      "  120 | 0.000034 | 081920/160596 | 0.9216 | 1.9358 |\n",
      "val: {'recall': 0.984499, 'recall_grapheme': 0.977702, 'recall_vowel': 0.991269, 'recall_consonant': 0.991323, 'acc_grapheme': 0.977487, 'acc_vowel': 0.993042, 'acc_consonant': 0.991576, 'loss_grapheme': 0.156624, 'loss_vowel': 0.111099, 'loss_consonant': 0.084112}\n",
      "  121 | 0.000037 | 126976/160596 | 3.1454 | 2.0416 |\n",
      "val: {'recall': 0.985241, 'recall_grapheme': 0.977929, 'recall_vowel': 0.992258, 'recall_consonant': 0.992848, 'acc_grapheme': 0.977115, 'acc_vowel': 0.993515, 'acc_consonant': 0.992049, 'loss_grapheme': 0.190487, 'loss_vowel': 0.143704, 'loss_consonant': 0.105472}\n",
      "  123 | 0.000039 | 012288/160596 | 2.7003 | 1.6319 |\n",
      "val: {'recall': 0.984894, 'recall_grapheme': 0.977932, 'recall_vowel': 0.991926, 'recall_consonant': 0.991787, 'acc_grapheme': 0.976767, 'acc_vowel': 0.993167, 'acc_consonant': 0.991601, 'loss_grapheme': 0.173176, 'loss_vowel': 0.114603, 'loss_consonant': 0.092193}\n",
      "  124 | 0.000040 | 057344/160596 | 1.1766 | 2.0086 |\n",
      "val: {'recall': 0.984304, 'recall_grapheme': 0.976925, 'recall_vowel': 0.992087, 'recall_consonant': 0.991281, 'acc_grapheme': 0.976916, 'acc_vowel': 0.993887, 'acc_consonant': 0.991775, 'loss_grapheme': 0.179272, 'loss_vowel': 0.144389, 'loss_consonant': 0.093544}\n",
      "  125 | 0.000039 | 102400/160596 | 2.7598 | 1.8469 |\n",
      "val: {'recall': 0.983927, 'recall_grapheme': 0.976237, 'recall_vowel': 0.992244, 'recall_consonant': 0.99099, 'acc_grapheme': 0.976195, 'acc_vowel': 0.993415, 'acc_consonant': 0.991477, 'loss_grapheme': 0.191046, 'loss_vowel': 0.136696, 'loss_consonant': 0.097928}\n",
      "  126 | 0.000037 | 147456/160596 | 2.6199 | 2.0202 |\n",
      "val: {'recall': 0.984014, 'recall_grapheme': 0.976359, 'recall_vowel': 0.992269, 'recall_consonant': 0.99107, 'acc_grapheme': 0.976394, 'acc_vowel': 0.993589, 'acc_consonant': 0.99175, 'loss_grapheme': 0.196412, 'loss_vowel': 0.154426, 'loss_consonant': 0.110945}\n",
      "  128 | 0.000034 | 032768/160596 | 0.8061 | 1.7201 |\n",
      "val: {'recall': 0.983714, 'recall_grapheme': 0.975708, 'recall_vowel': 0.991188, 'recall_consonant': 0.99225, 'acc_grapheme': 0.976618, 'acc_vowel': 0.993167, 'acc_consonant': 0.991253, 'loss_grapheme': 0.151866, 'loss_vowel': 0.09303, 'loss_consonant': 0.076658}\n",
      "  129 | 0.000030 | 077824/160596 | 3.2987 | 2.1704 |\n",
      "val: {'recall': 0.984149, 'recall_grapheme': 0.976664, 'recall_vowel': 0.991206, 'recall_consonant': 0.992061, 'acc_grapheme': 0.976444, 'acc_vowel': 0.993564, 'acc_consonant': 0.991899, 'loss_grapheme': 0.2235, 'loss_vowel': 0.158523, 'loss_consonant': 0.11069}\n",
      "  130 | 0.000026 | 122880/160596 | 0.4300 | 2.0069 |\n",
      "val: {'recall': 0.984498, 'recall_grapheme': 0.976877, 'recall_vowel': 0.991756, 'recall_consonant': 0.992482, 'acc_grapheme': 0.977786, 'acc_vowel': 0.993316, 'acc_consonant': 0.992123, 'loss_grapheme': 0.169116, 'loss_vowel': 0.111339, 'loss_consonant': 0.084477}\n",
      "  132 | 0.000021 | 008192/160596 | 0.9026 | 1.7852 |\n",
      "val: {'recall': 0.985181, 'recall_grapheme': 0.977981, 'recall_vowel': 0.991833, 'recall_consonant': 0.992927, 'acc_grapheme': 0.977438, 'acc_vowel': 0.993564, 'acc_consonant': 0.992222, 'loss_grapheme': 0.183295, 'loss_vowel': 0.136316, 'loss_consonant': 0.096616}\n",
      "  133 | 0.000015 | 053248/160596 | 1.3113 | 1.9625 |\n",
      "val: {'recall': 0.984461, 'recall_grapheme': 0.976503, 'recall_vowel': 0.991824, 'recall_consonant': 0.993015, 'acc_grapheme': 0.97699, 'acc_vowel': 0.993465, 'acc_consonant': 0.991924, 'loss_grapheme': 0.193229, 'loss_vowel': 0.141103, 'loss_consonant': 0.103538}\n",
      "  134 | 0.000011 | 098304/160596 | 1.2834 | 2.0049 |\n",
      "val: {'recall': 0.985079, 'recall_grapheme': 0.978351, 'recall_vowel': 0.99205, 'recall_consonant': 0.991562, 'acc_grapheme': 0.978158, 'acc_vowel': 0.993415, 'acc_consonant': 0.992247, 'loss_grapheme': 0.187292, 'loss_vowel': 0.136747, 'loss_consonant': 0.102989}\n",
      "  135 | 0.000007 | 143360/160596 | 1.3663 | 1.9374 |\n",
      "val: {'recall': 0.984921, 'recall_grapheme': 0.978132, 'recall_vowel': 0.991736, 'recall_consonant': 0.991682, 'acc_grapheme': 0.977661, 'acc_vowel': 0.993515, 'acc_consonant': 0.992148, 'loss_grapheme': 0.20704, 'loss_vowel': 0.161268, 'loss_consonant': 0.114543}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  137 | 0.000004 | 028672/160596 | 2.2479 | 1.9912 |\n",
      "val: {'recall': 0.984948, 'recall_grapheme': 0.977878, 'recall_vowel': 0.992624, 'recall_consonant': 0.991412, 'acc_grapheme': 0.978282, 'acc_vowel': 0.993862, 'acc_consonant': 0.992073, 'loss_grapheme': 0.190926, 'loss_vowel': 0.146448, 'loss_consonant': 0.104501}\n",
      "  138 | 0.000002 | 073728/160596 | 1.6229 | 2.1266 |\n",
      "val: {'recall': 0.985144, 'recall_grapheme': 0.978284, 'recall_vowel': 0.992314, 'recall_consonant': 0.991693, 'acc_grapheme': 0.978009, 'acc_vowel': 0.993763, 'acc_consonant': 0.992148, 'loss_grapheme': 0.204986, 'loss_vowel': 0.167922, 'loss_consonant': 0.114289}\n",
      "  139 | 0.000001 | 118784/160596 | 2.4991 | 2.0289 |\n",
      "val: {'recall': 0.984906, 'recall_grapheme': 0.977896, 'recall_vowel': 0.992209, 'recall_consonant': 0.991623, 'acc_grapheme': 0.97786, 'acc_vowel': 0.993838, 'acc_consonant': 0.992148, 'loss_grapheme': 0.194758, 'loss_vowel': 0.147456, 'loss_consonant': 0.106529}\n",
      "  141 | 0.000002 | 004096/160596 | 0.2932 | 0.8967 |\n",
      "val: {'recall': 0.985007, 'recall_grapheme': 0.978234, 'recall_vowel': 0.992195, 'recall_consonant': 0.991367, 'acc_grapheme': 0.978904, 'acc_vowel': 0.993689, 'acc_consonant': 0.992396, 'loss_grapheme': 0.15923, 'loss_vowel': 0.108113, 'loss_consonant': 0.084644}\n",
      "  142 | 0.000004 | 049152/160596 | 3.2595 | 1.8126 |\n",
      "val: {'recall': 0.985755, 'recall_grapheme': 0.979045, 'recall_vowel': 0.992558, 'recall_consonant': 0.992371, 'acc_grapheme': 0.978258, 'acc_vowel': 0.993813, 'acc_consonant': 0.992322, 'loss_grapheme': 0.187748, 'loss_vowel': 0.142184, 'loss_consonant': 0.101202}\n",
      "** saved\n",
      "  143 | 0.000007 | 094208/160596 | 3.0196 | 2.1044 |\n",
      "val: {'recall': 0.985448, 'recall_grapheme': 0.978875, 'recall_vowel': 0.992568, 'recall_consonant': 0.991476, 'acc_grapheme': 0.978382, 'acc_vowel': 0.993937, 'acc_consonant': 0.992272, 'loss_grapheme': 0.236769, 'loss_vowel': 0.192165, 'loss_consonant': 0.132373}\n",
      "  144 | 0.000011 | 139264/160596 | 2.0815 | 2.0800 |\n",
      "val: {'recall': 0.984628, 'recall_grapheme': 0.97732, 'recall_vowel': 0.991704, 'recall_consonant': 0.992168, 'acc_grapheme': 0.977612, 'acc_vowel': 0.993415, 'acc_consonant': 0.991974, 'loss_grapheme': 0.179925, 'loss_vowel': 0.134039, 'loss_consonant': 0.0997}\n",
      "  146 | 0.000015 | 024576/160596 | 1.0467 | 2.2682 |\n",
      "val: {'recall': 0.984632, 'recall_grapheme': 0.977844, 'recall_vowel': 0.991959, 'recall_consonant': 0.990882, 'acc_grapheme': 0.977264, 'acc_vowel': 0.993564, 'acc_consonant': 0.992098, 'loss_grapheme': 0.188032, 'loss_vowel': 0.144155, 'loss_consonant': 0.102131}\n",
      "  147 | 0.000020 | 069632/160596 | 1.7794 | 2.0365 |\n",
      "val: {'recall': 0.985212, 'recall_grapheme': 0.977765, 'recall_vowel': 0.992589, 'recall_consonant': 0.992731, 'acc_grapheme': 0.977711, 'acc_vowel': 0.993738, 'acc_consonant': 0.991999, 'loss_grapheme': 0.213196, 'loss_vowel': 0.173865, 'loss_consonant': 0.127538}\n",
      "  148 | 0.000026 | 114688/160596 | 1.8794 | 2.1071 |\n",
      "val: {'recall': 0.984762, 'recall_grapheme': 0.977365, 'recall_vowel': 0.992176, 'recall_consonant': 0.992141, 'acc_grapheme': 0.977214, 'acc_vowel': 0.99344, 'acc_consonant': 0.991576, 'loss_grapheme': 0.229276, 'loss_vowel': 0.184152, 'loss_consonant': 0.130703}\n",
      "  149 | 0.000030 | 159744/160596 | 0.2430 | 2.0294 |\n",
      "val: {'recall': 0.98424, 'recall_grapheme': 0.976181, 'recall_vowel': 0.991961, 'recall_consonant': 0.992639, 'acc_grapheme': 0.976593, 'acc_vowel': 0.99339, 'acc_consonant': 0.992297, 'loss_grapheme': 0.164118, 'loss_vowel': 0.100336, 'loss_consonant': 0.076499}\n",
      "  151 | 0.000034 | 045056/160596 | 2.5306 | 2.0435 |\n",
      "val: {'recall': 0.983883, 'recall_grapheme': 0.976241, 'recall_vowel': 0.992305, 'recall_consonant': 0.990744, 'acc_grapheme': 0.977189, 'acc_vowel': 0.993241, 'acc_consonant': 0.991676, 'loss_grapheme': 0.197484, 'loss_vowel': 0.151243, 'loss_consonant': 0.104292}\n",
      "  152 | 0.000037 | 090112/160596 | 1.9582 | 2.1843 |\n",
      "val: {'recall': 0.984924, 'recall_grapheme': 0.977206, 'recall_vowel': 0.992404, 'recall_consonant': 0.992879, 'acc_grapheme': 0.977984, 'acc_vowel': 0.993415, 'acc_consonant': 0.992247, 'loss_grapheme': 0.192204, 'loss_vowel': 0.156669, 'loss_consonant': 0.110557}\n",
      "  153 | 0.000039 | 135168/160596 | 1.6265 | 2.0937 |\n",
      "val: {'recall': 0.984336, 'recall_grapheme': 0.976206, 'recall_vowel': 0.992865, 'recall_consonant': 0.992068, 'acc_grapheme': 0.976543, 'acc_vowel': 0.993738, 'acc_consonant': 0.991651, 'loss_grapheme': 0.201405, 'loss_vowel': 0.137202, 'loss_consonant': 0.099602}\n",
      "  155 | 0.000040 | 020480/160596 | 0.3515 | 1.9902 |\n",
      "val: {'recall': 0.98441, 'recall_grapheme': 0.976801, 'recall_vowel': 0.992487, 'recall_consonant': 0.991549, 'acc_grapheme': 0.976369, 'acc_vowel': 0.993862, 'acc_consonant': 0.991899, 'loss_grapheme': 0.175886, 'loss_vowel': 0.126905, 'loss_consonant': 0.095838}\n",
      "  156 | 0.000039 | 065536/160596 | 1.6080 | 2.1799 |\n",
      "val: {'recall': 0.984701, 'recall_grapheme': 0.977543, 'recall_vowel': 0.992315, 'recall_consonant': 0.991404, 'acc_grapheme': 0.977189, 'acc_vowel': 0.993465, 'acc_consonant': 0.991924, 'loss_grapheme': 0.202976, 'loss_vowel': 0.146165, 'loss_consonant': 0.102474}\n",
      "  157 | 0.000037 | 110592/160596 | 3.0331 | 2.2080 |\n",
      "val: {'recall': 0.984152, 'recall_grapheme': 0.977074, 'recall_vowel': 0.990996, 'recall_consonant': 0.991465, 'acc_grapheme': 0.977438, 'acc_vowel': 0.99349, 'acc_consonant': 0.992521, 'loss_grapheme': 0.217946, 'loss_vowel': 0.16508, 'loss_consonant': 0.119093}\n",
      "  158 | 0.000034 | 155648/160596 | 1.2465 | 1.9558 |\n",
      "val: {'recall': 0.984268, 'recall_grapheme': 0.977187, 'recall_vowel': 0.991839, 'recall_consonant': 0.99086, 'acc_grapheme': 0.977015, 'acc_vowel': 0.993167, 'acc_consonant': 0.991924, 'loss_grapheme': 0.220865, 'loss_vowel': 0.174251, 'loss_consonant': 0.118819}\n",
      "  160 | 0.000030 | 040960/160596 | 2.0497 | 2.0328 |\n",
      "val: {'recall': 0.985138, 'recall_grapheme': 0.979139, 'recall_vowel': 0.991453, 'recall_consonant': 0.990821, 'acc_grapheme': 0.978506, 'acc_vowel': 0.993689, 'acc_consonant': 0.992148, 'loss_grapheme': 0.192512, 'loss_vowel': 0.133471, 'loss_consonant': 0.101443}\n",
      "  161 | 0.000026 | 086016/160596 | 3.2145 | 1.8187 |\n",
      "val: {'recall': 0.985347, 'recall_grapheme': 0.978231, 'recall_vowel': 0.992068, 'recall_consonant': 0.992857, 'acc_grapheme': 0.977959, 'acc_vowel': 0.993465, 'acc_consonant': 0.992247, 'loss_grapheme': 0.164504, 'loss_vowel': 0.109518, 'loss_consonant': 0.092438}\n",
      "  162 | 0.000020 | 131072/160596 | 0.9581 | 1.9448 |\n",
      "val: {'recall': 0.985595, 'recall_grapheme': 0.97927, 'recall_vowel': 0.992702, 'recall_consonant': 0.991138, 'acc_grapheme': 0.978034, 'acc_vowel': 0.993987, 'acc_consonant': 0.992222, 'loss_grapheme': 0.167887, 'loss_vowel': 0.117219, 'loss_consonant': 0.08835}\n",
      "  164 | 0.000015 | 016384/160596 | 2.3448 | 2.1227 |\n",
      "val: {'recall': 0.985403, 'recall_grapheme': 0.978984, 'recall_vowel': 0.992636, 'recall_consonant': 0.99101, 'acc_grapheme': 0.978109, 'acc_vowel': 0.993887, 'acc_consonant': 0.992148, 'loss_grapheme': 0.212206, 'loss_vowel': 0.160943, 'loss_consonant': 0.112811}\n",
      "  165 | 0.000011 | 061440/160596 | 3.2952 | 2.1430 |\n",
      "val: {'recall': 0.985376, 'recall_grapheme': 0.978724, 'recall_vowel': 0.992573, 'recall_consonant': 0.991482, 'acc_grapheme': 0.978133, 'acc_vowel': 0.993838, 'acc_consonant': 0.992521, 'loss_grapheme': 0.215388, 'loss_vowel': 0.175605, 'loss_consonant': 0.123925}\n",
      "  166 | 0.000007 | 106496/160596 | 2.6470 | 1.9911 |\n",
      "val: {'recall': 0.984828, 'recall_grapheme': 0.978159, 'recall_vowel': 0.992189, 'recall_consonant': 0.990805, 'acc_grapheme': 0.978332, 'acc_vowel': 0.993689, 'acc_consonant': 0.992372, 'loss_grapheme': 0.184845, 'loss_vowel': 0.139415, 'loss_consonant': 0.100953}\n",
      "  167 | 0.000004 | 151552/160596 | 3.5798 | 1.9525 |\n",
      "val: {'recall': 0.984057, 'recall_grapheme': 0.976489, 'recall_vowel': 0.9924, 'recall_consonant': 0.990849, 'acc_grapheme': 0.97791, 'acc_vowel': 0.993465, 'acc_consonant': 0.992073, 'loss_grapheme': 0.199198, 'loss_vowel': 0.118581, 'loss_consonant': 0.098298}\n",
      "  169 | 0.000002 | 036864/160596 | 2.0089 | 1.7332 |\n",
      "val: {'recall': 0.985485, 'recall_grapheme': 0.978386, 'recall_vowel': 0.992306, 'recall_consonant': 0.992865, 'acc_grapheme': 0.978332, 'acc_vowel': 0.993639, 'acc_consonant': 0.992496, 'loss_grapheme': 0.177617, 'loss_vowel': 0.119612, 'loss_consonant': 0.09085}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  170 | 0.000001 | 081920/160596 | 0.9312 | 1.9516 |\n",
      "val: {'recall': 0.985514, 'recall_grapheme': 0.978801, 'recall_vowel': 0.992703, 'recall_consonant': 0.99175, 'acc_grapheme': 0.978432, 'acc_vowel': 0.993862, 'acc_consonant': 0.992496, 'loss_grapheme': 0.190729, 'loss_vowel': 0.138661, 'loss_consonant': 0.099952}\n",
      "  171 | 0.000002 | 126976/160596 | 1.6063 | 2.0181 |\n",
      "val: {'recall': 0.985266, 'recall_grapheme': 0.978077, 'recall_vowel': 0.992169, 'recall_consonant': 0.99274, 'acc_grapheme': 0.978307, 'acc_vowel': 0.993589, 'acc_consonant': 0.992396, 'loss_grapheme': 0.19008, 'loss_vowel': 0.138038, 'loss_consonant': 0.102743}\n",
      "  173 | 0.000004 | 012288/160596 | 1.6167 | 1.8774 |\n",
      "val: {'recall': 0.98541, 'recall_grapheme': 0.978169, 'recall_vowel': 0.992652, 'recall_consonant': 0.992651, 'acc_grapheme': 0.978258, 'acc_vowel': 0.993763, 'acc_consonant': 0.992222, 'loss_grapheme': 0.168332, 'loss_vowel': 0.115569, 'loss_consonant': 0.088658}\n",
      "  174 | 0.000007 | 057344/160596 | 2.8782 | 2.0232 |\n",
      "val: {'recall': 0.985217, 'recall_grapheme': 0.978026, 'recall_vowel': 0.992386, 'recall_consonant': 0.992431, 'acc_grapheme': 0.978133, 'acc_vowel': 0.993788, 'acc_consonant': 0.992446, 'loss_grapheme': 0.190471, 'loss_vowel': 0.133957, 'loss_consonant': 0.10063}\n",
      "  175 | 0.000011 | 102400/160596 | 0.8694 | 2.1210 |\n",
      "val: {'recall': 0.985971, 'recall_grapheme': 0.979424, 'recall_vowel': 0.992171, 'recall_consonant': 0.992866, 'acc_grapheme': 0.978258, 'acc_vowel': 0.993763, 'acc_consonant': 0.992297, 'loss_grapheme': 0.196077, 'loss_vowel': 0.143263, 'loss_consonant': 0.103184}\n",
      "** saved\n",
      "  176 | 0.000015 | 147456/160596 | 2.7424 | 2.0839 |\n",
      "val: {'recall': 0.984868, 'recall_grapheme': 0.977844, 'recall_vowel': 0.992492, 'recall_consonant': 0.991291, 'acc_grapheme': 0.97781, 'acc_vowel': 0.993738, 'acc_consonant': 0.992148, 'loss_grapheme': 0.195548, 'loss_vowel': 0.151015, 'loss_consonant': 0.109975}\n",
      "  178 | 0.000020 | 032768/160596 | 1.9814 | 1.8517 |\n",
      "val: {'recall': 0.984371, 'recall_grapheme': 0.976874, 'recall_vowel': 0.992778, 'recall_consonant': 0.990959, 'acc_grapheme': 0.978258, 'acc_vowel': 0.993539, 'acc_consonant': 0.992222, 'loss_grapheme': 0.181864, 'loss_vowel': 0.117606, 'loss_consonant': 0.095727}\n",
      "  179 | 0.000026 | 077824/160596 | 1.2345 | 2.0376 |\n",
      "val: {'recall': 0.985601, 'recall_grapheme': 0.979008, 'recall_vowel': 0.992058, 'recall_consonant': 0.992329, 'acc_grapheme': 0.978084, 'acc_vowel': 0.993713, 'acc_consonant': 0.992198, 'loss_grapheme': 0.177398, 'loss_vowel': 0.122926, 'loss_consonant': 0.089566}\n",
      "  180 | 0.000030 | 122880/160596 | 3.8385 | 2.0139 |\n",
      "val: {'recall': 0.984948, 'recall_grapheme': 0.978733, 'recall_vowel': 0.991815, 'recall_consonant': 0.990512, 'acc_grapheme': 0.978282, 'acc_vowel': 0.993365, 'acc_consonant': 0.991651, 'loss_grapheme': 0.206607, 'loss_vowel': 0.161875, 'loss_consonant': 0.117583}\n",
      "  182 | 0.000034 | 008192/160596 | 0.0486 | 1.9042 |\n",
      "val: {'recall': 0.985679, 'recall_grapheme': 0.97866, 'recall_vowel': 0.992518, 'recall_consonant': 0.992878, 'acc_grapheme': 0.978158, 'acc_vowel': 0.993937, 'acc_consonant': 0.992148, 'loss_grapheme': 0.166369, 'loss_vowel': 0.115187, 'loss_consonant': 0.089578}\n",
      "  183 | 0.000037 | 053248/160596 | 1.6387 | 1.9435 |\n",
      "val: {'recall': 0.985159, 'recall_grapheme': 0.978755, 'recall_vowel': 0.992455, 'recall_consonant': 0.99067, 'acc_grapheme': 0.97868, 'acc_vowel': 0.993589, 'acc_consonant': 0.992247, 'loss_grapheme': 0.193548, 'loss_vowel': 0.129677, 'loss_consonant': 0.095637}\n",
      "  184 | 0.000039 | 098304/160596 | 3.5798 | 2.0181 |\n",
      "val: {'recall': 0.98527, 'recall_grapheme': 0.978708, 'recall_vowel': 0.991445, 'recall_consonant': 0.992218, 'acc_grapheme': 0.978407, 'acc_vowel': 0.993515, 'acc_consonant': 0.992297, 'loss_grapheme': 0.171735, 'loss_vowel': 0.122242, 'loss_consonant': 0.089747}\n",
      "  185 | 0.000040 | 143360/160596 | 2.1309 | 2.0158 |\n",
      "val: {'recall': 0.985364, 'recall_grapheme': 0.977858, 'recall_vowel': 0.992804, 'recall_consonant': 0.992937, 'acc_grapheme': 0.977711, 'acc_vowel': 0.993614, 'acc_consonant': 0.992322, 'loss_grapheme': 0.188407, 'loss_vowel': 0.133228, 'loss_consonant': 0.103234}\n",
      "  187 | 0.000039 | 028672/160596 | 2.1009 | 2.0769 |\n",
      "val: {'recall': 0.985105, 'recall_grapheme': 0.97772, 'recall_vowel': 0.99225, 'recall_consonant': 0.992732, 'acc_grapheme': 0.977065, 'acc_vowel': 0.993291, 'acc_consonant': 0.992372, 'loss_grapheme': 0.215092, 'loss_vowel': 0.16924, 'loss_consonant': 0.117626}\n",
      "  188 | 0.000037 | 073728/160596 | 1.1406 | 2.1084 |\n",
      "val: {'recall': 0.985982, 'recall_grapheme': 0.979091, 'recall_vowel': 0.993116, 'recall_consonant': 0.992631, 'acc_grapheme': 0.978506, 'acc_vowel': 0.993962, 'acc_consonant': 0.992148, 'loss_grapheme': 0.175072, 'loss_vowel': 0.128514, 'loss_consonant': 0.090163}\n",
      "** saved\n",
      "  189 | 0.000034 | 118784/160596 | 0.4236 | 1.8707 |\n",
      "val: {'recall': 0.984462, 'recall_grapheme': 0.97745, 'recall_vowel': 0.992278, 'recall_consonant': 0.990671, 'acc_grapheme': 0.978282, 'acc_vowel': 0.993738, 'acc_consonant': 0.992024, 'loss_grapheme': 0.177438, 'loss_vowel': 0.114574, 'loss_consonant': 0.093204}\n",
      "  191 | 0.000030 | 004096/160596 | 1.9221 | 1.3779 |\n",
      "val: {'recall': 0.985577, 'recall_grapheme': 0.978587, 'recall_vowel': 0.992829, 'recall_consonant': 0.992305, 'acc_grapheme': 0.979475, 'acc_vowel': 0.993713, 'acc_consonant': 0.992471, 'loss_grapheme': 0.16791, 'loss_vowel': 0.116531, 'loss_consonant': 0.085827}\n",
      "  192 | 0.000026 | 049152/160596 | 3.3732 | 2.0086 |\n",
      "val: {'recall': 0.985372, 'recall_grapheme': 0.978523, 'recall_vowel': 0.992872, 'recall_consonant': 0.991572, 'acc_grapheme': 0.978804, 'acc_vowel': 0.993962, 'acc_consonant': 0.992347, 'loss_grapheme': 0.198068, 'loss_vowel': 0.156681, 'loss_consonant': 0.113321}\n",
      "  193 | 0.000021 | 094208/160596 | 1.9003 | 2.0187 |\n",
      "val: {'recall': 0.985524, 'recall_grapheme': 0.979107, 'recall_vowel': 0.992631, 'recall_consonant': 0.991252, 'acc_grapheme': 0.978804, 'acc_vowel': 0.994036, 'acc_consonant': 0.992347, 'loss_grapheme': 0.186219, 'loss_vowel': 0.144572, 'loss_consonant': 0.103534}\n",
      "  194 | 0.000015 | 139264/160596 | 1.1157 | 1.8919 |\n",
      "val: {'recall': 0.985675, 'recall_grapheme': 0.978994, 'recall_vowel': 0.992243, 'recall_consonant': 0.99247, 'acc_grapheme': 0.979252, 'acc_vowel': 0.993738, 'acc_consonant': 0.992347, 'loss_grapheme': 0.149387, 'loss_vowel': 0.102794, 'loss_consonant': 0.078977}\n",
      "  196 | 0.000011 | 024576/160596 | 1.5233 | 1.9607 |\n",
      "val: {'recall': 0.985296, 'recall_grapheme': 0.978355, 'recall_vowel': 0.992482, 'recall_consonant': 0.991992, 'acc_grapheme': 0.979003, 'acc_vowel': 0.993713, 'acc_consonant': 0.992297, 'loss_grapheme': 0.173134, 'loss_vowel': 0.129124, 'loss_consonant': 0.094997}\n",
      "  197 | 0.000007 | 069632/160596 | 1.8837 | 2.0342 |\n",
      "val: {'recall': 0.985149, 'recall_grapheme': 0.978376, 'recall_vowel': 0.99239, 'recall_consonant': 0.991453, 'acc_grapheme': 0.978456, 'acc_vowel': 0.994086, 'acc_consonant': 0.992496, 'loss_grapheme': 0.182205, 'loss_vowel': 0.131763, 'loss_consonant': 0.097786}\n",
      "  198 | 0.000004 | 114688/160596 | 1.7118 | 1.9776 |\n",
      "val: {'recall': 0.985487, 'recall_grapheme': 0.978945, 'recall_vowel': 0.992317, 'recall_consonant': 0.991741, 'acc_grapheme': 0.978606, 'acc_vowel': 0.993912, 'acc_consonant': 0.992471, 'loss_grapheme': 0.201573, 'loss_vowel': 0.154602, 'loss_consonant': 0.110813}\n",
      "  199 | 0.000002 | 159744/160596 | 2.3110 | 2.0894 |\n",
      "val: {'recall': 0.985849, 'recall_grapheme': 0.979877, 'recall_vowel': 0.992633, 'recall_consonant': 0.991011, 'acc_grapheme': 0.978879, 'acc_vowel': 0.994235, 'acc_consonant': 0.992198, 'loss_grapheme': 0.210263, 'loss_vowel': 0.169056, 'loss_consonant': 0.118232}\n",
      "  201 | 0.000001 | 045056/160596 | 1.4763 | 1.9051 |\n",
      "val: {'recall': 0.984154, 'recall_grapheme': 0.976175, 'recall_vowel': 0.992266, 'recall_consonant': 0.992001, 'acc_grapheme': 0.978357, 'acc_vowel': 0.993365, 'acc_consonant': 0.992098, 'loss_grapheme': 0.170535, 'loss_vowel': 0.09013, 'loss_consonant': 0.079925}\n",
      "  202 | 0.000002 | 090112/160596 | 2.1481 | 1.8089 |\n",
      "val: {'recall': 0.986091, 'recall_grapheme': 0.97982, 'recall_vowel': 0.992132, 'recall_consonant': 0.992591, 'acc_grapheme': 0.979177, 'acc_vowel': 0.993838, 'acc_consonant': 0.992471, 'loss_grapheme': 0.156641, 'loss_vowel': 0.115152, 'loss_consonant': 0.084554}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** saved\n",
      "  203 | 0.000004 | 135168/160596 | 4.1408 | 2.0976 |\n",
      "val: {'recall': 0.985651, 'recall_grapheme': 0.979445, 'recall_vowel': 0.992179, 'recall_consonant': 0.991536, 'acc_grapheme': 0.978829, 'acc_vowel': 0.994036, 'acc_consonant': 0.99257, 'loss_grapheme': 0.220154, 'loss_vowel': 0.174584, 'loss_consonant': 0.125366}\n",
      "  205 | 0.000007 | 020480/160596 | 2.6845 | 2.1228 |\n",
      "val: {'recall': 0.985931, 'recall_grapheme': 0.979909, 'recall_vowel': 0.99274, 'recall_consonant': 0.991165, 'acc_grapheme': 0.978829, 'acc_vowel': 0.994136, 'acc_consonant': 0.992595, 'loss_grapheme': 0.208803, 'loss_vowel': 0.164151, 'loss_consonant': 0.114046}\n",
      "  206 | 0.000011 | 065536/160596 | 0.9440 | 2.0346 |\n",
      "val: {'recall': 0.986478, 'recall_grapheme': 0.980274, 'recall_vowel': 0.992748, 'recall_consonant': 0.992615, 'acc_grapheme': 0.979028, 'acc_vowel': 0.993962, 'acc_consonant': 0.992372, 'loss_grapheme': 0.18946, 'loss_vowel': 0.145447, 'loss_consonant': 0.104203}\n",
      "** saved\n",
      "  207 | 0.000015 | 110592/160596 | 2.0997 | 1.9963 |\n",
      "val: {'recall': 0.985629, 'recall_grapheme': 0.978555, 'recall_vowel': 0.992988, 'recall_consonant': 0.99242, 'acc_grapheme': 0.979326, 'acc_vowel': 0.993962, 'acc_consonant': 0.992446, 'loss_grapheme': 0.185961, 'loss_vowel': 0.132662, 'loss_consonant': 0.10373}\n",
      "  208 | 0.000020 | 155648/160596 | 3.7571 | 2.1717 |\n",
      "val: {'recall': 0.986064, 'recall_grapheme': 0.979779, 'recall_vowel': 0.992552, 'recall_consonant': 0.992144, 'acc_grapheme': 0.979003, 'acc_vowel': 0.994161, 'acc_consonant': 0.992545, 'loss_grapheme': 0.234126, 'loss_vowel': 0.198788, 'loss_consonant': 0.137294}\n",
      "  210 | 0.000026 | 040960/160596 | 3.6377 | 1.9744 |\n",
      "val: {'recall': 0.985948, 'recall_grapheme': 0.979723, 'recall_vowel': 0.992263, 'recall_consonant': 0.992082, 'acc_grapheme': 0.978506, 'acc_vowel': 0.993689, 'acc_consonant': 0.992148, 'loss_grapheme': 0.206478, 'loss_vowel': 0.165348, 'loss_consonant': 0.12247}\n",
      "  211 | 0.000030 | 086016/160596 | 1.6005 | 1.9473 |\n",
      "val: {'recall': 0.985324, 'recall_grapheme': 0.978223, 'recall_vowel': 0.992372, 'recall_consonant': 0.992477, 'acc_grapheme': 0.977239, 'acc_vowel': 0.993738, 'acc_consonant': 0.992222, 'loss_grapheme': 0.234775, 'loss_vowel': 0.174926, 'loss_consonant': 0.125474}\n",
      "  212 | 0.000034 | 131072/160596 | 3.3900 | 2.0497 |\n",
      "val: {'recall': 0.985222, 'recall_grapheme': 0.977836, 'recall_vowel': 0.992822, 'recall_consonant': 0.992394, 'acc_grapheme': 0.978282, 'acc_vowel': 0.993689, 'acc_consonant': 0.992098, 'loss_grapheme': 0.174111, 'loss_vowel': 0.13419, 'loss_consonant': 0.095126}\n",
      "  214 | 0.000037 | 016384/160596 | 1.9070 | 1.6419 |\n",
      "val: {'recall': 0.984389, 'recall_grapheme': 0.976855, 'recall_vowel': 0.992279, 'recall_consonant': 0.991568, 'acc_grapheme': 0.977438, 'acc_vowel': 0.993465, 'acc_consonant': 0.9918, 'loss_grapheme': 0.162099, 'loss_vowel': 0.110168, 'loss_consonant': 0.080384}\n",
      "  215 | 0.000039 | 061440/160596 | 1.6626 | 1.9346 |\n",
      "val: {'recall': 0.985561, 'recall_grapheme': 0.97846, 'recall_vowel': 0.992713, 'recall_consonant': 0.992609, 'acc_grapheme': 0.978233, 'acc_vowel': 0.993987, 'acc_consonant': 0.992421, 'loss_grapheme': 0.161838, 'loss_vowel': 0.115195, 'loss_consonant': 0.089014}\n",
      "  216 | 0.000040 | 106496/160596 | 2.7297 | 1.8490 |\n",
      "val: {'recall': 0.985893, 'recall_grapheme': 0.979619, 'recall_vowel': 0.99222, 'recall_consonant': 0.992112, 'acc_grapheme': 0.978829, 'acc_vowel': 0.993763, 'acc_consonant': 0.992198, 'loss_grapheme': 0.167841, 'loss_vowel': 0.116466, 'loss_consonant': 0.085415}\n",
      "  217 | 0.000039 | 115712/160596 | 0.5581 | 2.1415 |"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.978358, 'recall_grapheme': 0.967606, 'recall_vowel': 0.987796, 'recall_consonant': 0.990422, 'acc_grapheme': 0.967374, 'acc_vowel': 0.989241, 'acc_consonant': 0.987998, 'loss_grapheme': 0.33989, 'loss_vowel': 0.214178, 'loss_consonant': 0.145039}\n",
      "    1 | 0.000040 | 045056/160596 | 4.0782 | 3.0389 |\n",
      "val: {'recall': 0.97827, 'recall_grapheme': 0.967657, 'recall_vowel': 0.987124, 'recall_consonant': 0.99064, 'acc_grapheme': 0.967225, 'acc_vowel': 0.988918, 'acc_consonant': 0.987576, 'loss_grapheme': 0.370762, 'loss_vowel': 0.25688, 'loss_consonant': 0.164513}\n",
      "    2 | 0.000039 | 090112/160596 | 5.0198 | 2.5940 |\n",
      "val: {'recall': 0.976955, 'recall_grapheme': 0.965596, 'recall_vowel': 0.988205, 'recall_consonant': 0.988424, 'acc_grapheme': 0.966927, 'acc_vowel': 0.989241, 'acc_consonant': 0.987973, 'loss_grapheme': 0.266497, 'loss_vowel': 0.173287, 'loss_consonant': 0.117974}\n",
      "    3 | 0.000037 | 135168/160596 | 0.2808 | 2.7450 |\n",
      "val: {'recall': 0.978897, 'recall_grapheme': 0.96761, 'recall_vowel': 0.989154, 'recall_consonant': 0.991215, 'acc_grapheme': 0.967647, 'acc_vowel': 0.989564, 'acc_consonant': 0.987601, 'loss_grapheme': 0.34978, 'loss_vowel': 0.228437, 'loss_consonant': 0.154353}\n",
      "** saved\n",
      "    5 | 0.000034 | 020480/160596 | 2.0417 | 2.4258 |\n",
      "val: {'recall': 0.978008, 'recall_grapheme': 0.967326, 'recall_vowel': 0.988321, 'recall_consonant': 0.989059, 'acc_grapheme': 0.967772, 'acc_vowel': 0.989439, 'acc_consonant': 0.987849, 'loss_grapheme': 0.285588, 'loss_vowel': 0.186266, 'loss_consonant': 0.123907}\n",
      "    6 | 0.000030 | 065536/160596 | 2.2940 | 2.4711 |\n",
      "val: {'recall': 0.978002, 'recall_grapheme': 0.967485, 'recall_vowel': 0.988718, 'recall_consonant': 0.988322, 'acc_grapheme': 0.968269, 'acc_vowel': 0.989912, 'acc_consonant': 0.988346, 'loss_grapheme': 0.235778, 'loss_vowel': 0.144534, 'loss_consonant': 0.105477}\n",
      "    7 | 0.000026 | 110592/160596 | 4.2652 | 2.6139 |\n",
      "val: {'recall': 0.978407, 'recall_grapheme': 0.96844, 'recall_vowel': 0.98753, 'recall_consonant': 0.98922, 'acc_grapheme': 0.969064, 'acc_vowel': 0.98939, 'acc_consonant': 0.988147, 'loss_grapheme': 0.382445, 'loss_vowel': 0.247027, 'loss_consonant': 0.163535}\n",
      "    8 | 0.000021 | 155648/160596 | 4.0500 | 2.7280 |\n",
      "val: {'recall': 0.979161, 'recall_grapheme': 0.968221, 'recall_vowel': 0.988376, 'recall_consonant': 0.991824, 'acc_grapheme': 0.968964, 'acc_vowel': 0.989812, 'acc_consonant': 0.988247, 'loss_grapheme': 0.377234, 'loss_vowel': 0.259652, 'loss_consonant': 0.171094}\n",
      "** saved\n",
      "   10 | 0.000015 | 040960/160596 | 3.9817 | 2.3739 |\n",
      "val: {'recall': 0.978385, 'recall_grapheme': 0.968064, 'recall_vowel': 0.988437, 'recall_consonant': 0.988976, 'acc_grapheme': 0.968616, 'acc_vowel': 0.989912, 'acc_consonant': 0.988595, 'loss_grapheme': 0.287094, 'loss_vowel': 0.191446, 'loss_consonant': 0.126343}\n",
      "   11 | 0.000011 | 086016/160596 | 2.4822 | 2.5080 |\n",
      "val: {'recall': 0.978685, 'recall_grapheme': 0.967647, 'recall_vowel': 0.988603, 'recall_consonant': 0.990842, 'acc_grapheme': 0.968766, 'acc_vowel': 0.990036, 'acc_consonant': 0.988445, 'loss_grapheme': 0.280403, 'loss_vowel': 0.173945, 'loss_consonant': 0.117916}\n",
      "   12 | 0.000007 | 131072/160596 | 3.2570 | 2.5867 |\n",
      "val: {'recall': 0.978953, 'recall_grapheme': 0.968261, 'recall_vowel': 0.988817, 'recall_consonant': 0.990475, 'acc_grapheme': 0.969635, 'acc_vowel': 0.990135, 'acc_consonant': 0.988371, 'loss_grapheme': 0.277725, 'loss_vowel': 0.183022, 'loss_consonant': 0.126947}\n",
      "   14 | 0.000004 | 016384/160596 | 0.6678 | 2.2922 |\n",
      "val: {'recall': 0.979008, 'recall_grapheme': 0.968197, 'recall_vowel': 0.989176, 'recall_consonant': 0.990462, 'acc_grapheme': 0.969014, 'acc_vowel': 0.990284, 'acc_consonant': 0.988719, 'loss_grapheme': 0.258868, 'loss_vowel': 0.167907, 'loss_consonant': 0.11786}\n",
      "   15 | 0.000002 | 061440/160596 | 0.2844 | 2.7617 |\n",
      "val: {'recall': 0.97904, 'recall_grapheme': 0.968083, 'recall_vowel': 0.988741, 'recall_consonant': 0.991253, 'acc_grapheme': 0.969138, 'acc_vowel': 0.990085, 'acc_consonant': 0.988893, 'loss_grapheme': 0.248713, 'loss_vowel': 0.163932, 'loss_consonant': 0.113782}\n",
      "   16 | 0.000001 | 106496/160596 | 2.1970 | 2.5988 |\n",
      "val: {'recall': 0.978869, 'recall_grapheme': 0.967777, 'recall_vowel': 0.988428, 'recall_consonant': 0.991494, 'acc_grapheme': 0.969014, 'acc_vowel': 0.990061, 'acc_consonant': 0.988619, 'loss_grapheme': 0.291226, 'loss_vowel': 0.189334, 'loss_consonant': 0.129243}\n",
      "   17 | 0.000002 | 151552/160596 | 1.7373 | 2.6143 |\n",
      "val: {'recall': 0.979219, 'recall_grapheme': 0.968525, 'recall_vowel': 0.988787, 'recall_consonant': 0.991038, 'acc_grapheme': 0.969412, 'acc_vowel': 0.990085, 'acc_consonant': 0.988719, 'loss_grapheme': 0.301614, 'loss_vowel': 0.201219, 'loss_consonant': 0.133668}\n",
      "** saved\n",
      "   19 | 0.000004 | 036864/160596 | 0.1587 | 2.2570 |\n",
      "val: {'recall': 0.978683, 'recall_grapheme': 0.968342, 'recall_vowel': 0.988319, 'recall_consonant': 0.989731, 'acc_grapheme': 0.970033, 'acc_vowel': 0.990409, 'acc_consonant': 0.988719, 'loss_grapheme': 0.214575, 'loss_vowel': 0.132401, 'loss_consonant': 0.097253}\n",
      "   20 | 0.000007 | 081920/160596 | 1.7773 | 2.5063 |\n",
      "val: {'recall': 0.979566, 'recall_grapheme': 0.969369, 'recall_vowel': 0.988498, 'recall_consonant': 0.991028, 'acc_grapheme': 0.970008, 'acc_vowel': 0.990061, 'acc_consonant': 0.988619, 'loss_grapheme': 0.274943, 'loss_vowel': 0.181556, 'loss_consonant': 0.121885}\n",
      "** saved\n",
      "   21 | 0.000011 | 126976/160596 | 2.9161 | 2.4496 |\n",
      "val: {'recall': 0.979856, 'recall_grapheme': 0.969899, 'recall_vowel': 0.988973, 'recall_consonant': 0.990653, 'acc_grapheme': 0.970207, 'acc_vowel': 0.990309, 'acc_consonant': 0.988744, 'loss_grapheme': 0.262216, 'loss_vowel': 0.177634, 'loss_consonant': 0.123565}\n",
      "** saved\n",
      "   23 | 0.000015 | 012288/160596 | 1.2768 | 2.4120 |\n",
      "val: {'recall': 0.979547, 'recall_grapheme': 0.969335, 'recall_vowel': 0.989007, 'recall_consonant': 0.990509, 'acc_grapheme': 0.970008, 'acc_vowel': 0.990359, 'acc_consonant': 0.988644, 'loss_grapheme': 0.298815, 'loss_vowel': 0.186659, 'loss_consonant': 0.127236}\n",
      "   24 | 0.000021 | 057344/160596 | 3.8492 | 2.7056 |\n",
      "val: {'recall': 0.978689, 'recall_grapheme': 0.967482, 'recall_vowel': 0.988805, 'recall_consonant': 0.990987, 'acc_grapheme': 0.968542, 'acc_vowel': 0.990036, 'acc_consonant': 0.988172, 'loss_grapheme': 0.344807, 'loss_vowel': 0.234183, 'loss_consonant': 0.149462}\n",
      "   25 | 0.000026 | 102400/160596 | 1.5645 | 2.5854 |\n",
      "val: {'recall': 0.978437, 'recall_grapheme': 0.967319, 'recall_vowel': 0.989062, 'recall_consonant': 0.990047, 'acc_grapheme': 0.969213, 'acc_vowel': 0.99016, 'acc_consonant': 0.988744, 'loss_grapheme': 0.263472, 'loss_vowel': 0.177579, 'loss_consonant': 0.123001}\n",
      "   26 | 0.000030 | 147456/160596 | 0.3124 | 2.5800 |\n",
      "val: {'recall': 0.979733, 'recall_grapheme': 0.970693, 'recall_vowel': 0.988601, 'recall_consonant': 0.988948, 'acc_grapheme': 0.971076, 'acc_vowel': 0.990682, 'acc_consonant': 0.989216, 'loss_grapheme': 0.222262, 'loss_vowel': 0.136649, 'loss_consonant': 0.099742}\n",
      "   28 | 0.000034 | 032768/160596 | 0.3339 | 2.8528 |\n",
      "val: {'recall': 0.979355, 'recall_grapheme': 0.968797, 'recall_vowel': 0.989182, 'recall_consonant': 0.990643, 'acc_grapheme': 0.969188, 'acc_vowel': 0.990533, 'acc_consonant': 0.988843, 'loss_grapheme': 0.287023, 'loss_vowel': 0.1792, 'loss_consonant': 0.13589}\n",
      "   29 | 0.000037 | 077824/160596 | 3.1922 | 2.3029 |\n",
      "val: {'recall': 0.979785, 'recall_grapheme': 0.969361, 'recall_vowel': 0.989458, 'recall_consonant': 0.99096, 'acc_grapheme': 0.970256, 'acc_vowel': 0.990682, 'acc_consonant': 0.988619, 'loss_grapheme': 0.270546, 'loss_vowel': 0.181984, 'loss_consonant': 0.129741}\n",
      "   30 | 0.000039 | 122880/160596 | 1.7871 | 2.5876 |\n",
      "val: {'recall': 0.978206, 'recall_grapheme': 0.966785, 'recall_vowel': 0.989744, 'recall_consonant': 0.989509, 'acc_grapheme': 0.969089, 'acc_vowel': 0.990384, 'acc_consonant': 0.988868, 'loss_grapheme': 0.21805, 'loss_vowel': 0.136317, 'loss_consonant': 0.100354}\n",
      "   32 | 0.000040 | 008192/160596 | 2.7412 | 3.3444 |\n",
      "val: {'recall': 0.978617, 'recall_grapheme': 0.968308, 'recall_vowel': 0.988228, 'recall_consonant': 0.989624, 'acc_grapheme': 0.970008, 'acc_vowel': 0.989986, 'acc_consonant': 0.988694, 'loss_grapheme': 0.34676, 'loss_vowel': 0.255174, 'loss_consonant': 0.169079}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 0.000039 | 053248/160596 | 1.0196 | 2.7549 |\n",
      "val: {'recall': 0.979197, 'recall_grapheme': 0.968548, 'recall_vowel': 0.989231, 'recall_consonant': 0.990463, 'acc_grapheme': 0.970232, 'acc_vowel': 0.990558, 'acc_consonant': 0.989216, 'loss_grapheme': 0.269461, 'loss_vowel': 0.194371, 'loss_consonant': 0.132939}\n",
      "   34 | 0.000037 | 098304/160596 | 1.2563 | 2.5426 |\n",
      "val: {'recall': 0.979079, 'recall_grapheme': 0.968473, 'recall_vowel': 0.989393, 'recall_consonant': 0.989979, 'acc_grapheme': 0.96961, 'acc_vowel': 0.990185, 'acc_consonant': 0.988868, 'loss_grapheme': 0.277417, 'loss_vowel': 0.199627, 'loss_consonant': 0.146769}\n",
      "   35 | 0.000034 | 143360/160596 | 1.6984 | 2.5205 |\n",
      "val: {'recall': 0.978954, 'recall_grapheme': 0.969456, 'recall_vowel': 0.988736, 'recall_consonant': 0.988169, 'acc_grapheme': 0.970082, 'acc_vowel': 0.990061, 'acc_consonant': 0.988619, 'loss_grapheme': 0.258687, 'loss_vowel': 0.163272, 'loss_consonant': 0.114384}\n",
      "   37 | 0.000030 | 028672/160596 | 3.7338 | 2.8644 |\n",
      "val: {'recall': 0.980477, 'recall_grapheme': 0.972146, 'recall_vowel': 0.988976, 'recall_consonant': 0.988638, 'acc_grapheme': 0.971275, 'acc_vowel': 0.990707, 'acc_consonant': 0.98929, 'loss_grapheme': 0.280292, 'loss_vowel': 0.192013, 'loss_consonant': 0.135345}\n",
      "** saved\n",
      "   38 | 0.000026 | 073728/160596 | 2.2006 | 2.6525 |\n",
      "val: {'recall': 0.980064, 'recall_grapheme': 0.97116, 'recall_vowel': 0.989061, 'recall_consonant': 0.988875, 'acc_grapheme': 0.970902, 'acc_vowel': 0.990732, 'acc_consonant': 0.989415, 'loss_grapheme': 0.249868, 'loss_vowel': 0.187772, 'loss_consonant': 0.126631}\n",
      "   39 | 0.000021 | 118784/160596 | 1.9516 | 2.5248 |\n",
      "val: {'recall': 0.979627, 'recall_grapheme': 0.970753, 'recall_vowel': 0.989344, 'recall_consonant': 0.987658, 'acc_grapheme': 0.9713, 'acc_vowel': 0.990856, 'acc_consonant': 0.989564, 'loss_grapheme': 0.217175, 'loss_vowel': 0.144902, 'loss_consonant': 0.10412}\n",
      "   41 | 0.000015 | 004096/160596 | 2.5540 | 2.6453 |\n",
      "val: {'recall': 0.979861, 'recall_grapheme': 0.970725, 'recall_vowel': 0.989113, 'recall_consonant': 0.988883, 'acc_grapheme': 0.97125, 'acc_vowel': 0.990707, 'acc_consonant': 0.989241, 'loss_grapheme': 0.239702, 'loss_vowel': 0.160635, 'loss_consonant': 0.114686}\n",
      "   42 | 0.000011 | 049152/160596 | 4.0702 | 2.5038 |\n",
      "val: {'recall': 0.980445, 'recall_grapheme': 0.971918, 'recall_vowel': 0.989555, 'recall_consonant': 0.988388, 'acc_grapheme': 0.971598, 'acc_vowel': 0.991328, 'acc_consonant': 0.989514, 'loss_grapheme': 0.272897, 'loss_vowel': 0.19506, 'loss_consonant': 0.13477}\n",
      "   43 | 0.000007 | 094208/160596 | 2.5673 | 2.3655 |\n",
      "val: {'recall': 0.980675, 'recall_grapheme': 0.971867, 'recall_vowel': 0.989224, 'recall_consonant': 0.989743, 'acc_grapheme': 0.972145, 'acc_vowel': 0.991005, 'acc_consonant': 0.989738, 'loss_grapheme': 0.265116, 'loss_vowel': 0.186204, 'loss_consonant': 0.130145}\n",
      "** saved\n",
      "   44 | 0.000004 | 139264/160596 | 3.3356 | 2.6768 |\n",
      "val: {'recall': 0.980969, 'recall_grapheme': 0.97267, 'recall_vowel': 0.989392, 'recall_consonant': 0.989143, 'acc_grapheme': 0.972766, 'acc_vowel': 0.991179, 'acc_consonant': 0.989738, 'loss_grapheme': 0.26501, 'loss_vowel': 0.18439, 'loss_consonant': 0.129118}\n",
      "** saved\n",
      "   46 | 0.000002 | 024576/160596 | 3.8491 | 2.5187 |\n",
      "val: {'recall': 0.980588, 'recall_grapheme': 0.972385, 'recall_vowel': 0.989435, 'recall_consonant': 0.988147, 'acc_grapheme': 0.972369, 'acc_vowel': 0.991353, 'acc_consonant': 0.989688, 'loss_grapheme': 0.270833, 'loss_vowel': 0.191441, 'loss_consonant': 0.131319}\n",
      "   47 | 0.000001 | 069632/160596 | 1.0471 | 2.1798 |\n",
      "val: {'recall': 0.979761, 'recall_grapheme': 0.971257, 'recall_vowel': 0.989266, 'recall_consonant': 0.987266, 'acc_grapheme': 0.971722, 'acc_vowel': 0.99098, 'acc_consonant': 0.989688, 'loss_grapheme': 0.223474, 'loss_vowel': 0.1551, 'loss_consonant': 0.110659}\n",
      "   48 | 0.000002 | 114688/160596 | 4.4217 | 2.6030 |\n",
      "val: {'recall': 0.979733, 'recall_grapheme': 0.970852, 'recall_vowel': 0.989465, 'recall_consonant': 0.987764, 'acc_grapheme': 0.971847, 'acc_vowel': 0.991204, 'acc_consonant': 0.989464, 'loss_grapheme': 0.23429, 'loss_vowel': 0.163562, 'loss_consonant': 0.115988}\n",
      "   49 | 0.000004 | 159744/160596 | 1.5848 | 2.6858 |\n",
      "val: {'recall': 0.980249, 'recall_grapheme': 0.971224, 'recall_vowel': 0.989658, 'recall_consonant': 0.988888, 'acc_grapheme': 0.972021, 'acc_vowel': 0.991353, 'acc_consonant': 0.989415, 'loss_grapheme': 0.244444, 'loss_vowel': 0.168512, 'loss_consonant': 0.117884}\n",
      "   51 | 0.000007 | 045056/160596 | 2.0775 | 2.7919 |\n",
      "val: {'recall': 0.981012, 'recall_grapheme': 0.97251, 'recall_vowel': 0.989377, 'recall_consonant': 0.989651, 'acc_grapheme': 0.972567, 'acc_vowel': 0.991303, 'acc_consonant': 0.989688, 'loss_grapheme': 0.25787, 'loss_vowel': 0.181922, 'loss_consonant': 0.126349}\n",
      "** saved\n",
      "   52 | 0.000011 | 090112/160596 | 1.7099 | 2.4513 |\n",
      "val: {'recall': 0.980925, 'recall_grapheme': 0.972389, 'recall_vowel': 0.989474, 'recall_consonant': 0.989448, 'acc_grapheme': 0.972493, 'acc_vowel': 0.99103, 'acc_consonant': 0.989762, 'loss_grapheme': 0.251644, 'loss_vowel': 0.182988, 'loss_consonant': 0.128058}\n",
      "   53 | 0.000015 | 135168/160596 | 1.9627 | 2.4180 |\n",
      "val: {'recall': 0.979585, 'recall_grapheme': 0.970961, 'recall_vowel': 0.989492, 'recall_consonant': 0.986925, 'acc_grapheme': 0.97135, 'acc_vowel': 0.990756, 'acc_consonant': 0.989415, 'loss_grapheme': 0.229746, 'loss_vowel': 0.157324, 'loss_consonant': 0.10715}\n",
      "   55 | 0.000020 | 020480/160596 | 1.0667 | 2.6022 |\n",
      "val: {'recall': 0.9804, 'recall_grapheme': 0.971323, 'recall_vowel': 0.989529, 'recall_consonant': 0.989425, 'acc_grapheme': 0.971673, 'acc_vowel': 0.991079, 'acc_consonant': 0.989564, 'loss_grapheme': 0.246975, 'loss_vowel': 0.172498, 'loss_consonant': 0.11493}\n",
      "   56 | 0.000026 | 065536/160596 | 2.6358 | 2.5982 |\n",
      "val: {'recall': 0.979685, 'recall_grapheme': 0.970157, 'recall_vowel': 0.988618, 'recall_consonant': 0.989806, 'acc_grapheme': 0.971722, 'acc_vowel': 0.991104, 'acc_consonant': 0.989439, 'loss_grapheme': 0.246829, 'loss_vowel': 0.182886, 'loss_consonant': 0.125092}\n",
      "   57 | 0.000030 | 110592/160596 | 2.6014 | 2.4698 |\n",
      "val: {'recall': 0.980156, 'recall_grapheme': 0.970762, 'recall_vowel': 0.988939, 'recall_consonant': 0.99016, 'acc_grapheme': 0.971747, 'acc_vowel': 0.991129, 'acc_consonant': 0.989439, 'loss_grapheme': 0.24665, 'loss_vowel': 0.16459, 'loss_consonant': 0.125555}\n",
      "   58 | 0.000034 | 155648/160596 | 2.6586 | 2.2848 |\n",
      "val: {'recall': 0.979289, 'recall_grapheme': 0.969282, 'recall_vowel': 0.989128, 'recall_consonant': 0.989462, 'acc_grapheme': 0.971176, 'acc_vowel': 0.991353, 'acc_consonant': 0.989241, 'loss_grapheme': 0.206662, 'loss_vowel': 0.136223, 'loss_consonant': 0.101799}\n",
      "   60 | 0.000037 | 040960/160596 | 1.4154 | 2.3311 |\n",
      "val: {'recall': 0.980446, 'recall_grapheme': 0.971071, 'recall_vowel': 0.989248, 'recall_consonant': 0.990395, 'acc_grapheme': 0.971573, 'acc_vowel': 0.991378, 'acc_consonant': 0.988918, 'loss_grapheme': 0.229699, 'loss_vowel': 0.169125, 'loss_consonant': 0.126583}\n",
      "   61 | 0.000039 | 086016/160596 | 2.3391 | 2.3494 |\n",
      "val: {'recall': 0.980055, 'recall_grapheme': 0.970783, 'recall_vowel': 0.989766, 'recall_consonant': 0.988889, 'acc_grapheme': 0.970902, 'acc_vowel': 0.991179, 'acc_consonant': 0.989564, 'loss_grapheme': 0.264373, 'loss_vowel': 0.181119, 'loss_consonant': 0.125486}\n",
      "   62 | 0.000040 | 131072/160596 | 1.3996 | 2.3823 |\n",
      "val: {'recall': 0.980678, 'recall_grapheme': 0.972395, 'recall_vowel': 0.989907, 'recall_consonant': 0.988016, 'acc_grapheme': 0.972418, 'acc_vowel': 0.991378, 'acc_consonant': 0.98939, 'loss_grapheme': 0.222425, 'loss_vowel': 0.147125, 'loss_consonant': 0.104143}\n",
      "   64 | 0.000039 | 016384/160596 | 3.1762 | 2.3442 |\n",
      "val: {'recall': 0.98116, 'recall_grapheme': 0.973303, 'recall_vowel': 0.989449, 'recall_consonant': 0.988585, 'acc_grapheme': 0.972319, 'acc_vowel': 0.991552, 'acc_consonant': 0.989265, 'loss_grapheme': 0.242935, 'loss_vowel': 0.164112, 'loss_consonant': 0.108491}\n",
      "** saved\n",
      "   65 | 0.000037 | 061440/160596 | 3.0532 | 2.4885 |\n",
      "val: {'recall': 0.980773, 'recall_grapheme': 0.972098, 'recall_vowel': 0.989562, 'recall_consonant': 0.989333, 'acc_grapheme': 0.973064, 'acc_vowel': 0.99175, 'acc_consonant': 0.989688, 'loss_grapheme': 0.264159, 'loss_vowel': 0.187472, 'loss_consonant': 0.13546}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   66 | 0.000034 | 106496/160596 | 4.7684 | 2.3626 |\n",
      "val: {'recall': 0.980162, 'recall_grapheme': 0.971361, 'recall_vowel': 0.98908, 'recall_consonant': 0.988848, 'acc_grapheme': 0.97217, 'acc_vowel': 0.991477, 'acc_consonant': 0.989265, 'loss_grapheme': 0.241574, 'loss_vowel': 0.176307, 'loss_consonant': 0.122269}\n",
      "   67 | 0.000030 | 151552/160596 | 0.2235 | 2.5852 |\n",
      "val: {'recall': 0.9805, 'recall_grapheme': 0.971908, 'recall_vowel': 0.989568, 'recall_consonant': 0.988616, 'acc_grapheme': 0.972369, 'acc_vowel': 0.99175, 'acc_consonant': 0.989589, 'loss_grapheme': 0.236197, 'loss_vowel': 0.168501, 'loss_consonant': 0.116279}\n",
      "   69 | 0.000026 | 036864/160596 | 3.6408 | 2.5842 |\n",
      "val: {'recall': 0.980308, 'recall_grapheme': 0.971174, 'recall_vowel': 0.989555, 'recall_consonant': 0.989331, 'acc_grapheme': 0.971847, 'acc_vowel': 0.99175, 'acc_consonant': 0.989986, 'loss_grapheme': 0.258804, 'loss_vowel': 0.188044, 'loss_consonant': 0.133333}\n",
      "   70 | 0.000021 | 081920/160596 | 1.7791 | 2.5399 |\n",
      "val: {'recall': 0.981183, 'recall_grapheme': 0.97271, 'recall_vowel': 0.98947, 'recall_consonant': 0.989843, 'acc_grapheme': 0.973313, 'acc_vowel': 0.991676, 'acc_consonant': 0.990359, 'loss_grapheme': 0.290547, 'loss_vowel': 0.218717, 'loss_consonant': 0.147555}\n",
      "** saved\n",
      "   71 | 0.000015 | 126976/160596 | 3.7096 | 2.3301 |\n",
      "val: {'recall': 0.980769, 'recall_grapheme': 0.971857, 'recall_vowel': 0.990186, 'recall_consonant': 0.989177, 'acc_grapheme': 0.972716, 'acc_vowel': 0.991949, 'acc_consonant': 0.990458, 'loss_grapheme': 0.24618, 'loss_vowel': 0.17463, 'loss_consonant': 0.122759}\n",
      "   73 | 0.000011 | 012288/160596 | 1.9036 | 2.3068 |\n",
      "val: {'recall': 0.980352, 'recall_grapheme': 0.971452, 'recall_vowel': 0.989473, 'recall_consonant': 0.98903, 'acc_grapheme': 0.972667, 'acc_vowel': 0.991701, 'acc_consonant': 0.989912, 'loss_grapheme': 0.214448, 'loss_vowel': 0.150988, 'loss_consonant': 0.109164}\n",
      "   74 | 0.000007 | 057344/160596 | 2.6247 | 2.4980 |\n",
      "val: {'recall': 0.981402, 'recall_grapheme': 0.97318, 'recall_vowel': 0.989614, 'recall_consonant': 0.989635, 'acc_grapheme': 0.973512, 'acc_vowel': 0.991775, 'acc_consonant': 0.990135, 'loss_grapheme': 0.248746, 'loss_vowel': 0.174327, 'loss_consonant': 0.125693}\n",
      "** saved\n",
      "   75 | 0.000004 | 102400/160596 | 1.1767 | 2.2442 |\n",
      "val: {'recall': 0.980492, 'recall_grapheme': 0.971537, 'recall_vowel': 0.989628, 'recall_consonant': 0.989265, 'acc_grapheme': 0.973114, 'acc_vowel': 0.99175, 'acc_consonant': 0.990334, 'loss_grapheme': 0.200829, 'loss_vowel': 0.132463, 'loss_consonant': 0.098993}\n",
      "   76 | 0.000002 | 147456/160596 | 2.3185 | 2.2629 |\n",
      "val: {'recall': 0.981285, 'recall_grapheme': 0.972425, 'recall_vowel': 0.990357, 'recall_consonant': 0.989933, 'acc_grapheme': 0.973686, 'acc_vowel': 0.992049, 'acc_consonant': 0.990483, 'loss_grapheme': 0.229078, 'loss_vowel': 0.162396, 'loss_consonant': 0.1166}\n",
      "   78 | 0.000001 | 032768/160596 | 3.1901 | 2.3532 |\n",
      "val: {'recall': 0.981291, 'recall_grapheme': 0.972897, 'recall_vowel': 0.990047, 'recall_consonant': 0.989322, 'acc_grapheme': 0.973611, 'acc_vowel': 0.991949, 'acc_consonant': 0.989986, 'loss_grapheme': 0.233333, 'loss_vowel': 0.17135, 'loss_consonant': 0.120643}\n",
      "   79 | 0.000002 | 077824/160596 | 1.7359 | 2.3157 |\n",
      "val: {'recall': 0.980669, 'recall_grapheme': 0.971772, 'recall_vowel': 0.989696, 'recall_consonant': 0.989438, 'acc_grapheme': 0.972716, 'acc_vowel': 0.991725, 'acc_consonant': 0.99021, 'loss_grapheme': 0.236088, 'loss_vowel': 0.17339, 'loss_consonant': 0.120594}\n",
      "   80 | 0.000004 | 122880/160596 | 2.6300 | 2.4537 |\n",
      "val: {'recall': 0.981568, 'recall_grapheme': 0.973452, 'recall_vowel': 0.99002, 'recall_consonant': 0.98935, 'acc_grapheme': 0.973586, 'acc_vowel': 0.991924, 'acc_consonant': 0.99016, 'loss_grapheme': 0.256475, 'loss_vowel': 0.187316, 'loss_consonant': 0.131532}\n",
      "** saved\n",
      "   82 | 0.000007 | 008192/160596 | 0.3533 | 1.9218 |\n",
      "val: {'recall': 0.981221, 'recall_grapheme': 0.973178, 'recall_vowel': 0.989626, 'recall_consonant': 0.9889, 'acc_grapheme': 0.973735, 'acc_vowel': 0.991875, 'acc_consonant': 0.989912, 'loss_grapheme': 0.187402, 'loss_vowel': 0.127088, 'loss_consonant': 0.094679}\n",
      "   83 | 0.000011 | 053248/160596 | 3.0247 | 2.4431 |\n",
      "val: {'recall': 0.981242, 'recall_grapheme': 0.972733, 'recall_vowel': 0.989991, 'recall_consonant': 0.98951, 'acc_grapheme': 0.973064, 'acc_vowel': 0.991974, 'acc_consonant': 0.989812, 'loss_grapheme': 0.317041, 'loss_vowel': 0.235925, 'loss_consonant': 0.161034}\n",
      "   84 | 0.000015 | 098304/160596 | 1.7916 | 2.3891 |\n",
      "val: {'recall': 0.980848, 'recall_grapheme': 0.972067, 'recall_vowel': 0.989967, 'recall_consonant': 0.98929, 'acc_grapheme': 0.97299, 'acc_vowel': 0.991601, 'acc_consonant': 0.99021, 'loss_grapheme': 0.201719, 'loss_vowel': 0.142759, 'loss_consonant': 0.104599}\n",
      "   85 | 0.000021 | 143360/160596 | 2.2779 | 2.5097 |\n",
      "val: {'recall': 0.981071, 'recall_grapheme': 0.973038, 'recall_vowel': 0.989473, 'recall_consonant': 0.988737, 'acc_grapheme': 0.97294, 'acc_vowel': 0.99175, 'acc_consonant': 0.990135, 'loss_grapheme': 0.230712, 'loss_vowel': 0.158345, 'loss_consonant': 0.115441}\n",
      "   87 | 0.000026 | 028672/160596 | 2.2260 | 2.3648 |\n",
      "val: {'recall': 0.981089, 'recall_grapheme': 0.971922, 'recall_vowel': 0.990422, 'recall_consonant': 0.990089, 'acc_grapheme': 0.97217, 'acc_vowel': 0.991875, 'acc_consonant': 0.989912, 'loss_grapheme': 0.241341, 'loss_vowel': 0.17049, 'loss_consonant': 0.127029}\n",
      "   88 | 0.000030 | 073728/160596 | 4.6422 | 2.3737 |\n",
      "val: {'recall': 0.982312, 'recall_grapheme': 0.974103, 'recall_vowel': 0.990406, 'recall_consonant': 0.990635, 'acc_grapheme': 0.973313, 'acc_vowel': 0.992098, 'acc_consonant': 0.990011, 'loss_grapheme': 0.309158, 'loss_vowel': 0.217984, 'loss_consonant': 0.166312}\n",
      "** saved\n",
      "   89 | 0.000034 | 118784/160596 | 3.3836 | 2.5481 |\n",
      "val: {'recall': 0.98117, 'recall_grapheme': 0.971907, 'recall_vowel': 0.99029, 'recall_consonant': 0.990574, 'acc_grapheme': 0.972841, 'acc_vowel': 0.991701, 'acc_consonant': 0.989688, 'loss_grapheme': 0.278873, 'loss_vowel': 0.191793, 'loss_consonant': 0.145025}\n",
      "   91 | 0.000037 | 004096/160596 | 0.5117 | 2.2088 |\n",
      "val: {'recall': 0.980825, 'recall_grapheme': 0.972462, 'recall_vowel': 0.989731, 'recall_consonant': 0.988648, 'acc_grapheme': 0.97294, 'acc_vowel': 0.991452, 'acc_consonant': 0.990061, 'loss_grapheme': 0.202828, 'loss_vowel': 0.137856, 'loss_consonant': 0.098418}\n",
      "   92 | 0.000039 | 049152/160596 | 1.1825 | 2.3927 |\n",
      "val: {'recall': 0.981815, 'recall_grapheme': 0.973617, 'recall_vowel': 0.989988, 'recall_consonant': 0.990036, 'acc_grapheme': 0.973164, 'acc_vowel': 0.991626, 'acc_consonant': 0.989936, 'loss_grapheme': 0.265043, 'loss_vowel': 0.177913, 'loss_consonant': 0.125145}\n",
      "   93 | 0.000040 | 094208/160596 | 0.6546 | 2.3896 |\n",
      "val: {'recall': 0.980736, 'recall_grapheme': 0.972434, 'recall_vowel': 0.989887, 'recall_consonant': 0.988187, 'acc_grapheme': 0.97299, 'acc_vowel': 0.991974, 'acc_consonant': 0.990061, 'loss_grapheme': 0.279427, 'loss_vowel': 0.201261, 'loss_consonant': 0.138032}\n",
      "   94 | 0.000039 | 139264/160596 | 2.1371 | 2.3803 |\n",
      "val: {'recall': 0.981738, 'recall_grapheme': 0.973543, 'recall_vowel': 0.990381, 'recall_consonant': 0.989485, 'acc_grapheme': 0.972741, 'acc_vowel': 0.991875, 'acc_consonant': 0.990284, 'loss_grapheme': 0.233949, 'loss_vowel': 0.172914, 'loss_consonant': 0.11774}\n",
      "   96 | 0.000037 | 024576/160596 | 2.7162 | 2.2711 |\n",
      "val: {'recall': 0.98147, 'recall_grapheme': 0.972827, 'recall_vowel': 0.99047, 'recall_consonant': 0.989755, 'acc_grapheme': 0.973114, 'acc_vowel': 0.991999, 'acc_consonant': 0.990533, 'loss_grapheme': 0.224045, 'loss_vowel': 0.173863, 'loss_consonant': 0.118572}\n",
      "   97 | 0.000034 | 069632/160596 | 2.2984 | 2.4210 |\n",
      "val: {'recall': 0.980983, 'recall_grapheme': 0.971861, 'recall_vowel': 0.991018, 'recall_consonant': 0.989193, 'acc_grapheme': 0.972766, 'acc_vowel': 0.992322, 'acc_consonant': 0.989812, 'loss_grapheme': 0.213414, 'loss_vowel': 0.163408, 'loss_consonant': 0.109851}\n",
      "   98 | 0.000030 | 114688/160596 | 3.6187 | 2.4957 |\n",
      "val: {'recall': 0.981822, 'recall_grapheme': 0.973436, 'recall_vowel': 0.990245, 'recall_consonant': 0.990171, 'acc_grapheme': 0.973859, 'acc_vowel': 0.991924, 'acc_consonant': 0.990483, 'loss_grapheme': 0.227715, 'loss_vowel': 0.166565, 'loss_consonant': 0.123256}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99 | 0.000026 | 159744/160596 | 2.7826 | 2.4088 |\n",
      "val: {'recall': 0.981572, 'recall_grapheme': 0.972929, 'recall_vowel': 0.990296, 'recall_consonant': 0.990135, 'acc_grapheme': 0.973338, 'acc_vowel': 0.992024, 'acc_consonant': 0.990284, 'loss_grapheme': 0.26153, 'loss_vowel': 0.198119, 'loss_consonant': 0.149081}\n",
      "  101 | 0.000021 | 045056/160596 | 0.9083 | 2.5024 |\n",
      "val: {'recall': 0.982115, 'recall_grapheme': 0.973911, 'recall_vowel': 0.990267, 'recall_consonant': 0.990374, 'acc_grapheme': 0.974158, 'acc_vowel': 0.992073, 'acc_consonant': 0.99021, 'loss_grapheme': 0.232243, 'loss_vowel': 0.167849, 'loss_consonant': 0.117313}\n",
      "  102 | 0.000015 | 090112/160596 | 3.7902 | 2.4828 |\n",
      "val: {'recall': 0.982729, 'recall_grapheme': 0.975183, 'recall_vowel': 0.989947, 'recall_consonant': 0.990602, 'acc_grapheme': 0.975052, 'acc_vowel': 0.991899, 'acc_consonant': 0.990309, 'loss_grapheme': 0.283059, 'loss_vowel': 0.20083, 'loss_consonant': 0.142793}\n",
      "** saved\n",
      "  103 | 0.000011 | 135168/160596 | 2.1367 | 2.4217 |\n",
      "val: {'recall': 0.983072, 'recall_grapheme': 0.975533, 'recall_vowel': 0.990205, 'recall_consonant': 0.991015, 'acc_grapheme': 0.975052, 'acc_vowel': 0.992222, 'acc_consonant': 0.990508, 'loss_grapheme': 0.279314, 'loss_vowel': 0.205736, 'loss_consonant': 0.148146}\n",
      "** saved\n",
      "  105 | 0.000007 | 020480/160596 | 1.8012 | 2.4383 |\n",
      "val: {'recall': 0.982302, 'recall_grapheme': 0.974572, 'recall_vowel': 0.98993, 'recall_consonant': 0.990134, 'acc_grapheme': 0.974481, 'acc_vowel': 0.992148, 'acc_consonant': 0.990359, 'loss_grapheme': 0.245152, 'loss_vowel': 0.172014, 'loss_consonant': 0.126458}\n",
      "  106 | 0.000004 | 065536/160596 | 4.0285 | 2.4395 |\n",
      "val: {'recall': 0.983286, 'recall_grapheme': 0.976384, 'recall_vowel': 0.989874, 'recall_consonant': 0.990501, 'acc_grapheme': 0.975301, 'acc_vowel': 0.991974, 'acc_consonant': 0.99021, 'loss_grapheme': 0.266469, 'loss_vowel': 0.192753, 'loss_consonant': 0.137667}\n",
      "** saved\n",
      "  107 | 0.000002 | 110592/160596 | 1.8044 | 2.3117 |\n",
      "val: {'recall': 0.983185, 'recall_grapheme': 0.975405, 'recall_vowel': 0.990418, 'recall_consonant': 0.991512, 'acc_grapheme': 0.974729, 'acc_vowel': 0.992198, 'acc_consonant': 0.990334, 'loss_grapheme': 0.218305, 'loss_vowel': 0.160594, 'loss_consonant': 0.117355}\n",
      "  108 | 0.000001 | 155648/160596 | 3.8134 | 2.2058 |\n",
      "val: {'recall': 0.982876, 'recall_grapheme': 0.974844, 'recall_vowel': 0.990674, 'recall_consonant': 0.991143, 'acc_grapheme': 0.974804, 'acc_vowel': 0.992347, 'acc_consonant': 0.990458, 'loss_grapheme': 0.206585, 'loss_vowel': 0.148292, 'loss_consonant': 0.108268}\n",
      "  110 | 0.000002 | 040960/160596 | 1.5334 | 2.5390 |\n",
      "val: {'recall': 0.983247, 'recall_grapheme': 0.975386, 'recall_vowel': 0.990521, 'recall_consonant': 0.991695, 'acc_grapheme': 0.974978, 'acc_vowel': 0.992222, 'acc_consonant': 0.990433, 'loss_grapheme': 0.26182, 'loss_vowel': 0.193223, 'loss_consonant': 0.136649}\n",
      "  111 | 0.000004 | 086016/160596 | 2.6448 | 2.2734 |\n",
      "val: {'recall': 0.982277, 'recall_grapheme': 0.974681, 'recall_vowel': 0.989948, 'recall_consonant': 0.989797, 'acc_grapheme': 0.97453, 'acc_vowel': 0.991999, 'acc_consonant': 0.990458, 'loss_grapheme': 0.214565, 'loss_vowel': 0.148052, 'loss_consonant': 0.108039}\n",
      "  112 | 0.000007 | 131072/160596 | 2.4572 | 2.3185 |\n",
      "val: {'recall': 0.982479, 'recall_grapheme': 0.974017, 'recall_vowel': 0.990971, 'recall_consonant': 0.990911, 'acc_grapheme': 0.97458, 'acc_vowel': 0.992272, 'acc_consonant': 0.990483, 'loss_grapheme': 0.193153, 'loss_vowel': 0.134415, 'loss_consonant': 0.100452}\n",
      "  114 | 0.000011 | 016384/160596 | 4.2782 | 2.5731 |\n",
      "val: {'recall': 0.982078, 'recall_grapheme': 0.973663, 'recall_vowel': 0.990843, 'recall_consonant': 0.990142, 'acc_grapheme': 0.974555, 'acc_vowel': 0.99262, 'acc_consonant': 0.990359, 'loss_grapheme': 0.244365, 'loss_vowel': 0.181408, 'loss_consonant': 0.12581}\n",
      "  115 | 0.000015 | 061440/160596 | 1.6750 | 2.2352 |\n",
      "val: {'recall': 0.982741, 'recall_grapheme': 0.974316, 'recall_vowel': 0.990611, 'recall_consonant': 0.991722, 'acc_grapheme': 0.974456, 'acc_vowel': 0.992322, 'acc_consonant': 0.990831, 'loss_grapheme': 0.210156, 'loss_vowel': 0.152251, 'loss_consonant': 0.11175}\n",
      "  116 | 0.000021 | 106496/160596 | 1.3168 | 2.1465 |\n",
      "val: {'recall': 0.981119, 'recall_grapheme': 0.972223, 'recall_vowel': 0.989742, 'recall_consonant': 0.990288, 'acc_grapheme': 0.973512, 'acc_vowel': 0.992073, 'acc_consonant': 0.990185, 'loss_grapheme': 0.24035, 'loss_vowel': 0.175461, 'loss_consonant': 0.122214}\n",
      "  117 | 0.000026 | 151552/160596 | 3.0009 | 2.3277 |\n",
      "val: {'recall': 0.982993, 'recall_grapheme': 0.975518, 'recall_vowel': 0.990681, 'recall_consonant': 0.990254, 'acc_grapheme': 0.974754, 'acc_vowel': 0.992297, 'acc_consonant': 0.990732, 'loss_grapheme': 0.241079, 'loss_vowel': 0.183692, 'loss_consonant': 0.131359}\n",
      "  119 | 0.000030 | 036864/160596 | 2.3555 | 2.1396 |\n",
      "val: {'recall': 0.982487, 'recall_grapheme': 0.974118, 'recall_vowel': 0.990439, 'recall_consonant': 0.991274, 'acc_grapheme': 0.974431, 'acc_vowel': 0.992173, 'acc_consonant': 0.990458, 'loss_grapheme': 0.169699, 'loss_vowel': 0.119266, 'loss_consonant': 0.091108}\n",
      "  120 | 0.000034 | 081920/160596 | 1.3853 | 2.3154 |\n",
      "val: {'recall': 0.98225, 'recall_grapheme': 0.973617, 'recall_vowel': 0.990612, 'recall_consonant': 0.991154, 'acc_grapheme': 0.974282, 'acc_vowel': 0.992198, 'acc_consonant': 0.990384, 'loss_grapheme': 0.221743, 'loss_vowel': 0.158822, 'loss_consonant': 0.112999}\n",
      "  121 | 0.000037 | 126976/160596 | 4.4253 | 2.4438 |\n",
      "val: {'recall': 0.98244, 'recall_grapheme': 0.974043, 'recall_vowel': 0.990753, 'recall_consonant': 0.990921, 'acc_grapheme': 0.974555, 'acc_vowel': 0.992024, 'acc_consonant': 0.990607, 'loss_grapheme': 0.208729, 'loss_vowel': 0.153129, 'loss_consonant': 0.104306}\n",
      "  123 | 0.000039 | 012288/160596 | 3.9369 | 2.4588 |\n",
      "val: {'recall': 0.981479, 'recall_grapheme': 0.973049, 'recall_vowel': 0.990019, 'recall_consonant': 0.989798, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992297, 'acc_consonant': 0.990732, 'loss_grapheme': 0.238828, 'loss_vowel': 0.176632, 'loss_consonant': 0.127252}\n",
      "  124 | 0.000040 | 057344/160596 | 1.7793 | 2.3869 |\n",
      "val: {'recall': 0.981732, 'recall_grapheme': 0.972378, 'recall_vowel': 0.9904, 'recall_consonant': 0.991771, 'acc_grapheme': 0.974058, 'acc_vowel': 0.992098, 'acc_consonant': 0.990831, 'loss_grapheme': 0.195421, 'loss_vowel': 0.140894, 'loss_consonant': 0.104158}\n",
      "  125 | 0.000039 | 102400/160596 | 1.8291 | 2.2006 |\n",
      "val: {'recall': 0.981055, 'recall_grapheme': 0.971534, 'recall_vowel': 0.990542, 'recall_consonant': 0.99061, 'acc_grapheme': 0.973114, 'acc_vowel': 0.991949, 'acc_consonant': 0.990135, 'loss_grapheme': 0.19629, 'loss_vowel': 0.150754, 'loss_consonant': 0.112379}\n",
      "  126 | 0.000037 | 147456/160596 | 1.9903 | 2.3494 |\n",
      "val: {'recall': 0.98154, 'recall_grapheme': 0.972328, 'recall_vowel': 0.990161, 'recall_consonant': 0.991344, 'acc_grapheme': 0.973686, 'acc_vowel': 0.992222, 'acc_consonant': 0.990781, 'loss_grapheme': 0.21248, 'loss_vowel': 0.148949, 'loss_consonant': 0.099298}\n",
      "  128 | 0.000034 | 032768/160596 | 3.4493 | 2.1583 |\n",
      "val: {'recall': 0.98209, 'recall_grapheme': 0.973581, 'recall_vowel': 0.991278, 'recall_consonant': 0.98992, 'acc_grapheme': 0.974381, 'acc_vowel': 0.99257, 'acc_consonant': 0.990657, 'loss_grapheme': 0.236258, 'loss_vowel': 0.189133, 'loss_consonant': 0.127654}\n",
      "  129 | 0.000030 | 077824/160596 | 2.7326 | 2.2232 |\n",
      "val: {'recall': 0.982036, 'recall_grapheme': 0.973234, 'recall_vowel': 0.990976, 'recall_consonant': 0.990697, 'acc_grapheme': 0.974406, 'acc_vowel': 0.992645, 'acc_consonant': 0.990955, 'loss_grapheme': 0.254359, 'loss_vowel': 0.188628, 'loss_consonant': 0.13235}\n",
      "  130 | 0.000026 | 122880/160596 | 2.0574 | 2.2787 |\n",
      "val: {'recall': 0.981642, 'recall_grapheme': 0.972608, 'recall_vowel': 0.990803, 'recall_consonant': 0.99055, 'acc_grapheme': 0.973412, 'acc_vowel': 0.992347, 'acc_consonant': 0.990309, 'loss_grapheme': 0.201671, 'loss_vowel': 0.143847, 'loss_consonant': 0.105664}\n",
      "  132 | 0.000021 | 008192/160596 | 2.8688 | 2.6746 |\n",
      "val: {'recall': 0.982587, 'recall_grapheme': 0.974778, 'recall_vowel': 0.990441, 'recall_consonant': 0.990353, 'acc_grapheme': 0.975301, 'acc_vowel': 0.992446, 'acc_consonant': 0.991179, 'loss_grapheme': 0.237467, 'loss_vowel': 0.182889, 'loss_consonant': 0.125284}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  133 | 0.000015 | 053248/160596 | 1.1055 | 2.3244 |\n",
      "val: {'recall': 0.982106, 'recall_grapheme': 0.973416, 'recall_vowel': 0.990781, 'recall_consonant': 0.990809, 'acc_grapheme': 0.974729, 'acc_vowel': 0.992421, 'acc_consonant': 0.991253, 'loss_grapheme': 0.211503, 'loss_vowel': 0.166163, 'loss_consonant': 0.111303}\n",
      "  134 | 0.000011 | 098304/160596 | 2.0396 | 2.2117 |\n",
      "val: {'recall': 0.982572, 'recall_grapheme': 0.974751, 'recall_vowel': 0.990227, 'recall_consonant': 0.990558, 'acc_grapheme': 0.975326, 'acc_vowel': 0.992297, 'acc_consonant': 0.991154, 'loss_grapheme': 0.219274, 'loss_vowel': 0.157781, 'loss_consonant': 0.109228}\n",
      "  135 | 0.000007 | 143360/160596 | 3.6337 | 2.3152 |\n",
      "val: {'recall': 0.982873, 'recall_grapheme': 0.974579, 'recall_vowel': 0.990673, 'recall_consonant': 0.991662, 'acc_grapheme': 0.975027, 'acc_vowel': 0.992446, 'acc_consonant': 0.99098, 'loss_grapheme': 0.202821, 'loss_vowel': 0.147704, 'loss_consonant': 0.105511}\n",
      "  137 | 0.000004 | 028672/160596 | 2.3300 | 2.0614 |\n",
      "val: {'recall': 0.982898, 'recall_grapheme': 0.975125, 'recall_vowel': 0.990203, 'recall_consonant': 0.99114, 'acc_grapheme': 0.974978, 'acc_vowel': 0.992421, 'acc_consonant': 0.991055, 'loss_grapheme': 0.209285, 'loss_vowel': 0.155366, 'loss_consonant': 0.109096}\n",
      "  138 | 0.000002 | 073728/160596 | 1.7348 | 2.3050 |\n",
      "val: {'recall': 0.982601, 'recall_grapheme': 0.974693, 'recall_vowel': 0.990417, 'recall_consonant': 0.9906, 'acc_grapheme': 0.974903, 'acc_vowel': 0.992471, 'acc_consonant': 0.99103, 'loss_grapheme': 0.238174, 'loss_vowel': 0.184012, 'loss_consonant': 0.127025}\n",
      "  139 | 0.000001 | 118784/160596 | 2.1725 | 2.3987 |\n",
      "val: {'recall': 0.982788, 'recall_grapheme': 0.974858, 'recall_vowel': 0.990663, 'recall_consonant': 0.990774, 'acc_grapheme': 0.974829, 'acc_vowel': 0.99267, 'acc_consonant': 0.990955, 'loss_grapheme': 0.261676, 'loss_vowel': 0.2036, 'loss_consonant': 0.139213}\n",
      "  141 | 0.000002 | 004096/160596 | 2.1491 | 1.2327 |\n",
      "val: {'recall': 0.982565, 'recall_grapheme': 0.974071, 'recall_vowel': 0.990429, 'recall_consonant': 0.991687, 'acc_grapheme': 0.974829, 'acc_vowel': 0.992446, 'acc_consonant': 0.991079, 'loss_grapheme': 0.157391, 'loss_vowel': 0.10557, 'loss_consonant': 0.080734}\n",
      "  142 | 0.000004 | 049152/160596 | 2.1834 | 2.0640 |\n",
      "val: {'recall': 0.982793, 'recall_grapheme': 0.974672, 'recall_vowel': 0.990184, 'recall_consonant': 0.991645, 'acc_grapheme': 0.975425, 'acc_vowel': 0.992396, 'acc_consonant': 0.991204, 'loss_grapheme': 0.163627, 'loss_vowel': 0.113267, 'loss_consonant': 0.085353}\n",
      "  143 | 0.000007 | 094208/160596 | 3.4348 | 2.3168 |\n",
      "val: {'recall': 0.983355, 'recall_grapheme': 0.975833, 'recall_vowel': 0.990699, 'recall_consonant': 0.991053, 'acc_grapheme': 0.976096, 'acc_vowel': 0.99257, 'acc_consonant': 0.99103, 'loss_grapheme': 0.246898, 'loss_vowel': 0.198971, 'loss_consonant': 0.136673}\n",
      "** saved\n",
      "  144 | 0.000011 | 139264/160596 | 3.7507 | 2.3433 |\n",
      "val: {'recall': 0.982163, 'recall_grapheme': 0.973968, 'recall_vowel': 0.990777, 'recall_consonant': 0.989939, 'acc_grapheme': 0.974605, 'acc_vowel': 0.992521, 'acc_consonant': 0.991005, 'loss_grapheme': 0.225382, 'loss_vowel': 0.177839, 'loss_consonant': 0.122175}\n",
      "  146 | 0.000015 | 024576/160596 | 2.8998 | 1.9082 |\n",
      "val: {'recall': 0.983035, 'recall_grapheme': 0.975287, 'recall_vowel': 0.99042, 'recall_consonant': 0.991145, 'acc_grapheme': 0.975077, 'acc_vowel': 0.992396, 'acc_consonant': 0.991353, 'loss_grapheme': 0.187231, 'loss_vowel': 0.127998, 'loss_consonant': 0.094506}\n",
      "  147 | 0.000020 | 069632/160596 | 3.8948 | 2.2966 |\n",
      "val: {'recall': 0.982813, 'recall_grapheme': 0.975117, 'recall_vowel': 0.990007, 'recall_consonant': 0.991011, 'acc_grapheme': 0.975127, 'acc_vowel': 0.992421, 'acc_consonant': 0.99093, 'loss_grapheme': 0.227941, 'loss_vowel': 0.168666, 'loss_consonant': 0.120393}\n",
      "  148 | 0.000026 | 114688/160596 | 2.8450 | 2.2117 |\n",
      "val: {'recall': 0.98259, 'recall_grapheme': 0.974287, 'recall_vowel': 0.991198, 'recall_consonant': 0.990589, 'acc_grapheme': 0.975176, 'acc_vowel': 0.992819, 'acc_consonant': 0.990682, 'loss_grapheme': 0.217844, 'loss_vowel': 0.162802, 'loss_consonant': 0.117773}\n",
      "  149 | 0.000030 | 159744/160596 | 3.6692 | 2.3527 |\n",
      "val: {'recall': 0.982347, 'recall_grapheme': 0.973398, 'recall_vowel': 0.99068, 'recall_consonant': 0.991911, 'acc_grapheme': 0.974207, 'acc_vowel': 0.992396, 'acc_consonant': 0.99093, 'loss_grapheme': 0.223422, 'loss_vowel': 0.173141, 'loss_consonant': 0.119233}\n",
      "  151 | 0.000034 | 045056/160596 | 1.2698 | 1.8770 |\n",
      "val: {'recall': 0.982492, 'recall_grapheme': 0.974011, 'recall_vowel': 0.990659, 'recall_consonant': 0.991286, 'acc_grapheme': 0.974158, 'acc_vowel': 0.992123, 'acc_consonant': 0.990409, 'loss_grapheme': 0.159572, 'loss_vowel': 0.097708, 'loss_consonant': 0.076445}\n",
      "  152 | 0.000037 | 090112/160596 | 2.8706 | 2.2840 |\n",
      "val: {'recall': 0.982924, 'recall_grapheme': 0.974849, 'recall_vowel': 0.99027, 'recall_consonant': 0.99173, 'acc_grapheme': 0.974282, 'acc_vowel': 0.992545, 'acc_consonant': 0.991154, 'loss_grapheme': 0.188932, 'loss_vowel': 0.1336, 'loss_consonant': 0.10471}\n",
      "  153 | 0.000039 | 135168/160596 | 1.6638 | 2.1592 |\n",
      "val: {'recall': 0.982962, 'recall_grapheme': 0.974949, 'recall_vowel': 0.990668, 'recall_consonant': 0.991281, 'acc_grapheme': 0.975002, 'acc_vowel': 0.99262, 'acc_consonant': 0.991104, 'loss_grapheme': 0.203394, 'loss_vowel': 0.141853, 'loss_consonant': 0.102676}\n",
      "  155 | 0.000040 | 020480/160596 | 3.1995 | 2.5686 |\n",
      "val: {'recall': 0.982568, 'recall_grapheme': 0.974133, 'recall_vowel': 0.991419, 'recall_consonant': 0.990585, 'acc_grapheme': 0.974083, 'acc_vowel': 0.992148, 'acc_consonant': 0.990533, 'loss_grapheme': 0.241509, 'loss_vowel': 0.19327, 'loss_consonant': 0.122985}\n",
      "  156 | 0.000039 | 065536/160596 | 3.8559 | 2.3161 |\n",
      "val: {'recall': 0.982794, 'recall_grapheme': 0.974043, 'recall_vowel': 0.990968, 'recall_consonant': 0.992122, 'acc_grapheme': 0.973859, 'acc_vowel': 0.992446, 'acc_consonant': 0.991005, 'loss_grapheme': 0.24194, 'loss_vowel': 0.175966, 'loss_consonant': 0.130356}\n",
      "  157 | 0.000037 | 110592/160596 | 0.7816 | 2.4139 |\n",
      "val: {'recall': 0.982543, 'recall_grapheme': 0.974529, 'recall_vowel': 0.990741, 'recall_consonant': 0.990373, 'acc_grapheme': 0.974605, 'acc_vowel': 0.992272, 'acc_consonant': 0.990607, 'loss_grapheme': 0.224742, 'loss_vowel': 0.157238, 'loss_consonant': 0.1151}\n",
      "  158 | 0.000034 | 155648/160596 | 2.9652 | 2.2131 |\n",
      "val: {'recall': 0.981858, 'recall_grapheme': 0.972751, 'recall_vowel': 0.990201, 'recall_consonant': 0.991729, 'acc_grapheme': 0.973859, 'acc_vowel': 0.992173, 'acc_consonant': 0.991278, 'loss_grapheme': 0.195253, 'loss_vowel': 0.151608, 'loss_consonant': 0.105343}\n",
      "  160 | 0.000030 | 040960/160596 | 2.3013 | 2.2452 |\n",
      "val: {'recall': 0.982939, 'recall_grapheme': 0.974849, 'recall_vowel': 0.990296, 'recall_consonant': 0.991762, 'acc_grapheme': 0.97545, 'acc_vowel': 0.992421, 'acc_consonant': 0.990781, 'loss_grapheme': 0.221495, 'loss_vowel': 0.157089, 'loss_consonant': 0.114117}\n",
      "  161 | 0.000026 | 086016/160596 | 2.8352 | 2.1147 |\n",
      "val: {'recall': 0.983252, 'recall_grapheme': 0.975562, 'recall_vowel': 0.989835, 'recall_consonant': 0.992049, 'acc_grapheme': 0.975201, 'acc_vowel': 0.992073, 'acc_consonant': 0.991005, 'loss_grapheme': 0.191947, 'loss_vowel': 0.1325, 'loss_consonant': 0.099259}\n",
      "  162 | 0.000020 | 131072/160596 | 0.9095 | 2.3219 |\n",
      "val: {'recall': 0.983478, 'recall_grapheme': 0.975089, 'recall_vowel': 0.991358, 'recall_consonant': 0.992374, 'acc_grapheme': 0.975226, 'acc_vowel': 0.99262, 'acc_consonant': 0.991502, 'loss_grapheme': 0.195182, 'loss_vowel': 0.14595, 'loss_consonant': 0.104877}\n",
      "** saved\n",
      "  164 | 0.000015 | 016384/160596 | 1.1934 | 2.2742 |\n",
      "val: {'recall': 0.983636, 'recall_grapheme': 0.975649, 'recall_vowel': 0.991029, 'recall_consonant': 0.992218, 'acc_grapheme': 0.975251, 'acc_vowel': 0.992545, 'acc_consonant': 0.991253, 'loss_grapheme': 0.213258, 'loss_vowel': 0.156147, 'loss_consonant': 0.111282}\n",
      "** saved\n",
      "  165 | 0.000011 | 061440/160596 | 1.2953 | 2.0910 |\n",
      "val: {'recall': 0.983112, 'recall_grapheme': 0.975243, 'recall_vowel': 0.99082, 'recall_consonant': 0.99114, 'acc_grapheme': 0.975276, 'acc_vowel': 0.992545, 'acc_consonant': 0.990856, 'loss_grapheme': 0.144272, 'loss_vowel': 0.090035, 'loss_consonant': 0.069467}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  165 | 0.000007 | 130048/160596 | 0.0454 | 2.0883 |"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
